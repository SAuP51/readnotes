1 第 9 章曾经提到，网关也是一种专用的计算机。如果两个网络不直接相连，也可以用 VPN 在它们各自的网关之间建立加密通道，从而实现网络到网络的安全通信。—— 译者注

颇具讽刺意味的是，制造出业界广泛使用的双因子认证设备 SecureID 的 RSA 公司 [2] 在 2011 年 3 月遭遇入侵，安全信息失窃，从而使某些 SecureID 设备不再安全。随后，军火商洛克希德·马丁公司受到攻击，看样子黑客充分利用了 SecureID 失窃案中得到的信息。

[2] 即 10.9.2 节提到的 RSA 加密算法的三个发明人所创建的公司，现已被 EMC 收购。—— 译者注

10.8.4 自我防御

个人计算机用户如何进行自我防御？有人向我征求这个意见时，我会用本节的内容告诉他。我把计算机用户的防御手段分成三类：第一类非常重要，第二类中等重要，第三类则要看你的偏执程度。（如你所料，第三类我就不细讲了，因为大多数人根本不会偏执到这种程度。）

非常重要

选择安全的口令，让别人不会轻易猜中，即使反复尝试也不至于马上就被破解。一串随机的大小写字母、数字、特殊字符混搭而成的口令，显然要比词典里的单词、生日、家人和宠物名来得安全。至于信奉「最危险的才是最安全的」，从而用「password」作为口令的搞笑念头，还是及早打住为妙。

不要在重要网站和无关紧要的网站用同一口令，前者包括银行网站和电子邮件，后者譬如在线报纸。工作账号和私人账号不要用同一口令。经常修改口令，但不要改得太有规律，比如在最后一位数加 1。

不要用开放的无线网络做重要的事。保证用 HTTPS 连接无线网络，但别忘了 HTTPS 只加密内容。

收到来历不明的邮件不要打开附件。收到朋友寄来的邮件，如果发现有意想不到的附件，也不要打开。不要因为软件提示你接受、点击或安装就全部照做。不要从可疑来源下载软件，除了可信来源之外，下载和安装软件都要保持警惕。

使用 Windows 要安装防毒软件并保持更新，不要去点那些声称要对你的计算机进行安全检查的网站链接。关闭微软 Office 程序的宏，尽量禁用 ActiveX 控件。如果用的是苹果电脑，现在还不太需要防病毒软件，但同样要小心。其他软件，比如浏览器和操作系统本身，既然厂家经常发布安全补丁，就可经常更新。

中等重要

关闭浏览器弹窗和第三方 cookie（讨厌的是，每个浏览器都分别保存自己的 cookie，所以每个浏览器要分别设置一遍）。用 Adblock 或 Flashblock 等软件拒绝广告图片。

用垃圾邮件过滤器筛选电子邮件。

关闭 Adobe Reader 的 JavaScript。

关掉不用的服务。比如我的苹果电脑可以共享打印机、文件和设备，还能从别的计算机远程登录进来管理我的计算机。Windows 也有类似的一套服务。我只保留了打印机共享，其他统统关掉了 [1]。

[1] 需要注意的是，网上流传的一些关闭 Windows 服务的「教程」（尤其是转来转去不知出处的中文教程）不求甚解、以讹传讹，而且通常是为了「精简」系统运行时的资源占用，不是出于安全考虑，甚至还为了躲避正版验证而关掉自动更新，因此使用 Windows 的服务管理器关闭服务时务必慎重。—— 译者注

打开计算机上的防火墙程序，监控进出的网络连接，禁止违反访问规则的连接。

只要有可能，就对重要账户使用双因子认证。

偏执狂专用

禁用邮件阅读程序读取 HTML 和 JavaScript。

用 NoScript 限制 JavaScript，用 Ghostery 限制跟踪。

关掉所有 cookie，只对自己明确想启用的网站打开。

选用那些不易成为攻击目标的系统，比如用 Linux 或 Mac OS X 系统而不是 Windows。使用 Chrome、Firefox、Safari 和 Opera 等浏览器，而不使用 Internet Explorer。

鉴于手机也越来越多地成为攻击目标，在手机上采用类似的预防措施也是很必要的。

10.9 密码术

密码术被称为「秘密书写」的技艺，用以和别人交换私密信息，已有数千年历史。尤利乌斯·凯撒大帝曾用过一种简单的密码方案（后人称之为凯撒密码）：把消息原文中的字母向后移动三个位置，于是 A 变成 D、B 变成 E......，「HI JULIUS」就变成了「KL MXOLXV」[1]。这种算法现在仍然有生命力，有个叫 rot13 的程序就是把字母移动 13 个位置进行变换，常用在新闻组里，隐藏冒昧言论或者剧透，以防被人意外看到，并不是真的用来加密。

[1] 这里作者用现代英语字母举例，事实上古拉丁语字母并没有 J 和 U。—— 译者注

在人类运用密码术的历史长河中，涌现出了丰富多彩故事。有些轻信加密就能保密的主人公，还曾因此丢了性命。1587 年，苏格兰女王玛丽就因为加密不当而命丧断头台。当时，她和密谋罢黜英格兰女王伊丽莎白一世、把她本人推上英格兰王位的同谋者通信，然而密码系统被破解，阴谋内容和同谋者名字在中间人攻击下暴露出来，他们在劫难逃，被斩首示众。1943 年，由于日本的军用加密系统不够安全，日本联合舰队总司令山本五十六大将一命呜呼。美国情报机关破解了山本的飞行计划，于是派飞行员击落了他的座机。夸张一点说，正是由于英国人靠阿兰·图灵的计算知识和技术破解了恩尼格玛密码机，解密了德军的军事情报，才使得二战结束时间大大提前。

加密的基本思路是，张三和李四 [2] 想互相交换消息，要求通信内容保密，但并不掩盖他们正在通信的事实。要做到这一点，他们需要共享用来扰乱以及随后恢复要传递消息的同一段密文，这样，别人就看不懂他们写了什么，只有两位当事人自己看得懂。用来加密消息的密文被称为密钥。例如，在凯撒密码里，密钥就是字母移位的距离，3 表示把 A 换成 D。对于恩尼格玛密码机这种复杂的机械加密设备来说，密钥就是若干代码转子设置和一组插头接线方式的组合。基于计算机的现代密码系统则使用巨大的秘密数字作为密钥，把秘密数字作为变换消息中比特流的复杂算法的输入。这样，如果不知道这个数字，就不可能还原消息。

[2] 原文使用的人物角色是爱丽丝（Alice）和鲍勃（Bob），这是英文资料在描述加密算法时常用的两个虚构角色，其英语名字分别以 A 和 B 开头，表示最先介入通信的两个人，类似汉语中的「张三和李四」。其他角色详见 http://en.wikipedia.org/wiki/Alice_and_Bob 的描述。—— 译者注

有多种方法用来对加密算法实施攻击。频率分析法统计密码中每个符号出现的频率，可以轻松干掉凯撒密码和报纸上填字游戏所用的简单替换密码。要抵御频率分析，加密算法必须要做到让密文中所有符号都以大致相等的机会出现，以做到没有模式可供分析。但有时候，攻击者可能知道与待破解密钥加密的密文相对应的明文；即使不知道，他们还可能会选取一段明文，诱使被攻击者用待破解密钥加密这段明文，从而两相对照，达到破解的目的。好的算法要能有效抵御所有这些攻击。

现代密码学必须假定攻击者知道并完全理解密码系统的工作原理，从而将所有的安全性都寄托在密钥上。与此相反的做法是假定对手不知道系统用什么加密方案、如何破解，这被称为隐匿式安全，只要时间一长，这种做法肯定要完蛋。苏格兰女王玛丽、山本五十六和德军都没有重视这个至关重要的事实，并为此付出了致命的代价。实际上，如果有人鼓吹他们的加密系统十分安全，却不愿说出其工作原理，那就可以确信它并不安全。

这年头，加密故障通常不会给身体带来危险，但会让那些盲目相信加密系统没有缺陷的人颜面扫地。最好的例子是用来加密电影 DVD 的内容扰乱系统（Content Scrambling System，CSS）。1999 年，一位年仅 15 岁的挪威学生约恩·莱克·约翰森（Jon Lech Johansen）发布了破解 DVD 的 DeCSS 程序，随后这个程序广为流传，他也被人们称为「DVD 约恩」。后来约翰森再接再厉，又用逆向工程破解了一些别的加密系统。

目前使用的加密系统基本可分成两类。一类是历史较长的密钥加密，也称对称密钥加密，因为加密和解密要使用相同的钥匙。「对称」这个词能更好地描述其本质，但「密钥」则让人更容易区分它与另一类加密系统：公钥加密。

10.9.1 密钥加密

在密钥加密系统中，使用同一个密钥对消息进行加密和解密，这个密钥由参与消息交换的各方共享。假定选用的算法完全为人所理解，而且也没有任何缺陷和弱点，那么破解消息的唯一方法就是蛮力攻击（brute force attack），即尝试所有可能的密钥，直到找出用来加密的那个。蛮力攻击很耗时间，如果密钥有 N 位，穷举时间就和 2N 成正比。然而蛮力攻击也并非没有用，因为攻击者可以先尝试短密钥，再尝试长的；先尝试可能性大的密钥，再尝试可能性小的。比如字典攻击（dictionary attack）就是尝试用「password」和「123456」这些常见单词和数字形式攻击。如果我们选择密钥时偷懒或粗心，就会让这种攻击得手。

从 1976 年到 2000 年代初，最常用的密钥加密算法是 DES（Data Encryption Standard，数据加密标准），该算法由 IBM 和 NSA（National Security Agency，美国国家安全局）共同开发。尽管有人怀疑 NSA 在 DES 里埋了一个秘密的陷门机制，这样他们就能轻松破解用 DES 加密的信息，但这种怀疑从未得到证实。DES 总是使用 56 位密钥，随着计算机的运算速度越来越快，这个密钥长度显然已经太短了。早在 1999 年，计算机使用蛮力攻击，穷举一天就能破解 DES 密钥。一些使用更长密钥的新加密算法应运而生。

这些算法中使用最多的是 AES（Advanced Encryption Standard，高级加密标准）。该算法是为解答一道全球公开竞赛的题目而开发的，竞赛的赞助方为美国国家标准技术研究所（National Institute of Standards and Technology，NIST）。当时，来自全世界的参赛选手提交了几十个算法。经过激烈的公开评测，比利时密码学家琼·德门（Joan Daemen）和文森特·赖伊曼（Vincent Rijmen）发明的 Rijndael 算法摘取桂冠，并于 2002 年成为美国政府的官方标准 [1]。这个算法已归入公有领域 [2]，任何人都可以无偿使用。AES 支持 128、192 和 256 位三种密钥长度，可能的密钥数量非常多，用蛮力攻击算很多年也不会有结果，除非能发现算法有弱点。

[1] 严格说来，最终的 AES 标准是 Rijndael 算法的特例，因为 Rijndael 允许的密钥长度比 AES 更灵活。—— 译者注

[2] public domain，是一个知识产权概念。对于公有领域内的知识财产，任何个人或团体都不具所有权益，这些知识属于公有文化财产，任何人可以不受限制地使用和加工它们。作品归于公有领域的原因一般包括无相关法律保护、专有权利期满、作者自愿放弃、作者无资格占有等。—— 译者注

AES 和其他密钥加密系统面临的一个大问题是密钥分发：参与秘密通信的每一方必须知道所用的密钥，所以必须有绝对安全的渠道把密钥送到通信参与方。这看似很简单，就像把大家都请到家里来聚餐一样，可如果来的人里有间谍或敌人，显然就无法保证分发密钥时的安全性了。还有一个问题是密钥增生：要保证与彼此间无关的多方相互独立地秘密会话，就要为每组会话准备不同的密钥。这就导致密钥分发更加困难。密钥加密系统的上述困难导致了公钥加密的诞生，我们将在下一节讨论。

10.9.2 公钥加密

公钥加密是怀特菲尔德·迪菲（Whitfield Diffie）和马丁·赫尔曼（Martin Hellman）在 1970 年代中期发明的，采用了与密钥加密完全不同的思想。差不多同时，英国一所情报机构的密码学家詹姆斯·埃利斯（James Ellis）和克利福德·柯克斯（Clifford Cocks）也独立发现了同样的方法，但他们的工作被视为绝密，不能发表，因此与大部分荣誉失之交臂 1。

1 实际上，埃利斯和柯克斯的成果比他们的美国同行早了 3 年。但由于保密的原因，在 1990 年代末才得以发表。两人为此获得了 IEEE（美国电子与电气工程师协会）的里程碑奖。—— 译者注

在公钥加密系统里，每个人都有一个密钥对，包含一个公钥和一个私钥。这对密钥是在数学上有关联的整数，具有如下性质：用其中一个密钥加密过的消息只能用另一个密钥解密，反之亦然。在公钥加密系统里，只要密钥足够长，不论是蛮力攻击还是从一个密钥推算另一个密钥，都将是徒劳的。

在实际使用中，公钥真的是开诚布公：任何人都能拿到，一般是公布在网站上；私钥则一定要金屋藏娇，只有这个密钥对的主人才知道它。

设想以下场景：张三想给李四发一条消息，该消息要加密，保证只有李四自己才能看到。张三先到李四的网站上找到他的公钥，用这个公钥把消息加密后发给他。消息发出的时候，王五在偷听，他发现张三正在给李四发消息，但因为内容加密了，所以不知道发出的是什么内容。

李四能用自己的私钥解开张三发来的消息。私钥只有李四自己知道，而且只有用这个私钥才能解开用他的公钥加密过的消息。反过来，如果李四要给张三发一条加密的回信，就要用张三的公钥来加密该消息。这次，王五仍然知道有消息发回来，但他同样只能看到加密过的密文，不知道内容写的是什么。张三收到消息后，用只有自己知道的私钥解就可以解开李四的回信。

由于不需要传送共享的密钥，公钥方案有效解决了密钥分发的问题。张三和李四把各自的公钥放在网站上，任何人都可以给他们发送秘密消息，既不需要事先商定，也不需要交换任何密钥。实际上，参与通信的各方甚至根本不需要认识。

公钥加密是在互联网上进行安全通信的关键要素。设想我上网买一本书。我得告诉亚马逊网站我的信用卡号，但我并不想发送明文，这样就需要使用加密的通信通道。直接使用 AES 是不可能的，因为我和亚马逊之间没有共享密钥。为了商定共享密钥，我的浏览器必须首先随机生成一个临时口令，并用亚马逊的公钥加密这个临时口令，然后把加密后的结果传给亚马逊。亚马逊用它的私钥解出临时口令后，我的浏览器和亚马逊就可以在 AES 算法中用这个临时口令来加密要传送的信息（比如我的信用卡号）。

公钥加密的主要缺点是算法的运算速度慢，比 AES 这种密钥加密算法要慢好几个数量级。所以，通常不会用公钥加密算法加密全部数据，而是分两步走：先用公钥加密协商出一个共享的会话密钥，再用 AES 加密接下来批量传输的数据。

上述加密过程的两个阶段 —— 首先是用公钥加密算法设置临时口令，然后再用 AES 交换大量数据 —— 都是安全的。当我们访问网上商店、电子邮件服务和很多别的网站时，都要跟这种技术打交道。你能在浏览器上看出它在运行，因为浏览器会显示正在用 HTTPS（即安全的 HTTP）协议连接，还会显示门锁图标，表示这个连接是加密过的：

公钥加密还有其他有趣的用途。例如，可以用做数字签名方案。设想张三想签署一条消息，以便让收信人能确定该消息是他本人签字认可，而不是别人假冒的。张三首先用自己的私钥对消息进行加密，然后把结果公布出去，然后任何人都能用张三的公钥来解密该消息。因为除了张三之外再也没有别人知道他的私钥，因此接收者可以断定这条消息一定是张三加密过的。显然，这只有在张三的私钥没有泄露的情况下才成立。另外，张三还可以只给李四签署一条消息，让除李四之外的人都无法看到，而李四不仅能看到该消息，还能验证确实是张三发给他的。具体做法是：张三先用自己的私钥签署这条消息，然后用李四的公钥加密签署后的结果。王五虽然发现张三给李四发了一些信息，但只有李四能用自己的私钥解开密文，然后再用张三的公钥继续解密，同时证明了消息真是张三发来的。

当然，公钥加密方案也不是完美无缺的。如果张三的私钥泄露了，之前别人发给他的消息就形同明文，而他之前的签名也就不可信了。另外，尽管大多数密钥生成方案都包括密钥生成时间和失效时间，但真正撤销一个密钥（即宣布某个密钥从此以后失效），却是很困难的。

最常用的公钥加密算法是 RSA，这个算法是麻省理工学院的三位计算机科学家罗纳德·李维斯特（Ronald L. Rivest）、阿迪·沙米尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）在 1978 年发明的，RSA 就是这三位发明人姓氏的首字母缩写。RSA 算法的可靠性来自于对巨大合数做因数分解的难度。RSA 的工作原理是生成一个很大的整数（比如长度为 300 位），这个整数要有两个素因子（长度约为二者乘积的一半），以此作为生成公钥和私钥的基础。知道这两个素因子的人（即私钥的主人）能迅速解开密文，其他人要解密就得先分解素因子。由于计算量过大，这实际上是不可能完成的，或者最起码是我们认为无法完成的。李维斯特、沙米尔和阿德曼因为发明 RSA 而获得了 2002 年图灵奖。

在 RSA 算法中，密钥的长度很重要。据我们目前所知，分解大整数的运算量随整数长度的增长而呈指数增长。我曾经为了演示 RSA 而生成过 512 位密钥，这个长度也是 RSA 标准密钥生成程序的默认值。然而到了 2008 年左右，生成程序已经不让我用 512 位的密钥了，因为不够长，于是我用了 1024 位的。看样子，过不了几年，1024 位也要嫌短了。RSA 实验室是持有 RSA 专利的公司 [2]，它曾举办过一个分解素因子大赛，从 1991 年一直办到 2007 年。它公布了一个列表，上面是越来越长的巨大合数，设立奖金悬赏能分解开每个合数的第一人。最小的合数有 100 多位，很快就分解开了。2007 年这个竞赛停办之时，分解出来的最大合数有 193 位（二进制 640 位），奖金是 2 万美元。（这个列表还挂在网上，感兴趣的读者不妨一试。）

[2] 2000 年前，RSA 专利在美国有效，但在大多数其他国家都无效。由于专利问题，历史上曾经有很多涉及到数据加密的开源软件采取在美国之外运营、分别发布美国版和国际版、默认发行不包括 RSA 但允许用户从源代码自己编译等办法来规避在美国的专利限制，如 OpenBSD 操作系统 http://www.openbsd.org/27.html 。2000 年，RSA 专利在美国已到期。—— 译者注

现代密码术尽管有这些神奇的特性，但在实际应用时仍然需要一定程度的信任来支撑，特别是需要可信的第三方存在。举个例子，我在网上买书时，如何确定我是在和亚马逊对话，而不是和一个精于伪装的冒牌货往来？为了解决这个问题，我访问亚马逊时，该网站发送给我一个证书来证明它的身份。证书是由独立的权威机构签署的一组信息，用来证明亚马逊网站的身份。浏览器用权威机构发布的公钥来检查网站发来的证书，确认它属于亚马逊而不是其他机构。理论上，我可以相信：如果权威机构说它是亚马逊，那它一定就是。但我首先要信任权威机构本身，如果是权威机构是假冒的，那我就不能信任用它签署的任何网站证书。令人诧异的是，常见的浏览器包含了很多证书，比如我用的 Firefox 版本里有 80 多个，其中大多数来自我从没听说过的组织，比如中国台湾的中华电信公司和斯洛伐克的 Disig a.s. 公司。2011 年 8 月，黑客入侵了荷兰的一家证书权威机构 DigiNotar，因而他就能生成包括 Google 在内的很多网站的假冒证书。

因为公钥算法很慢，所以一般不直接用公钥算法对文档签名，而是签署从原始文档提取出来的小得多的文档。选用适当方法生成的这种小文档无法伪造，也无法从其他文档生成同样的签名值。这样的小文档就叫做消息摘要或密码学散列，其创建方法是用某种算法把任意输入的比特流变换成固定长度的比特流，也就是摘要或散列，最终得到的结果具有如下特性：无法通过计算找到别的输入来生成同样的摘要。此外，输入中最轻微的改变都会让输出摘要中大约一半的比特发生变化。这样，通过比较接收者计算生成的文档摘要与原始摘要是否匹配，就能有效检测文档是否遭到了篡改。下面来看一下字母 x 和 X 的密码学散列值（用十六进制表示）：

x 9DD4E461268C8034F5C8564E155C67A6 X 02129BB861061D1A052C592E2DC6B383

这两个字母的 ASCII 值只差一位，散列值却大不相同。根本无法通过计算找到别的输入，使得输出的散列值和这两者中的一个相同，也无法从散列值反推回原始输入。

目前广泛使用的消息摘要算法有两个。一个是罗纳德·李维斯特开发的 MD5，生成 128 位的摘要。另一个是 SHA-1，来自 NIST（美国国家标准技术研究所），生成 160 位的摘要。已有研究表明 MD5 和 SHA-1 都有弱点 [3]，因此不适合用于对安全性要求较高的场合。NIST 正在举办一场比赛，寻找新的算法 SHA-3 来解决 SHA-1 存在的问题 [4]。

[3] 根据抽屉原理，理论上，任何散列函数都必然存在碰撞，但一直以来，没有人成功构造出密码学散列函数的碰撞例子。2004 年，中国科学家王小云针对 MD5 等函数，成功构造出了这样的碰撞例子。随后，王小云又与其他科学家一起设计了计算量少于 263 步的 SHA-1 碰撞算法。—— 译者注

[4] 这场比赛已于 2012 年 10 月结束，四位科学家设计的 Keccak 算法获胜，但截至本书中文版定稿时，NIST 尚未公布 SHA-3 标准。考虑到 Rijndael 和 AES 的前例，最终的 SHA-3 标准可能会和 Keccak 有出入。SHA 算法家族还有 SHA-2 系列的 4 个算法，是 SHA-1 的变体，分别把摘要长度扩大到 224、256、384 和 512 位。SHA-3 不是为了取代 SHA-2，因为目前尚未出现对 SHA-2 的有效攻击。SHA-3 是为了寻找和 SHA-1 思路完全不一样的安全散列算法。参见 http://en.wikipedia.org/wiki/Secure_Hash_Algorithm 。—— 译者注

在任何安全系统中，最薄弱的环节都是作为用户的人，人会破坏那些他们觉得复杂难用的系统。设想一下，如果有人逼着你改密码，尤其是新密码必须马上想出来，而且要满足一些古怪的限制，比如要包含大小写字母、数字、某些特殊字符，但又不能包含另外一些字符，你会怎么做？你可能会像我那样用公式来生成新密码，或者把无规律的新密码写在纸上，但这两种做法都会带来潜在的安全风险。（问问你自己：如果攻击者得到你的两个密码，能不能猜出你的其他密码？）就算每个人都能坚守安全防线，志在必得的敌人还可以用收买、讹诈、盗窃、暴打这四大武器来攻破城防。而像政府这样合法的暴力机构，则越来越多地用牢狱之灾来恐吓那些不肯说出密码的人。

10.10 小结

1990 年以来，万维网从无到有，发展到如今已然无处不在了。万维网改变了商业，也改变了我们的很多习惯。尤其是在消费行为方面，过去谁能想到搜索、网上商店、评级系统、比价网站和产品试用网站的威力呢。

机遇和利益总是与问题和风险相逐又相随。万维网扩展了我们的生存空间，但也前所未有地让我们在陌生人面前暴露无遗，因此伤害也可能不期而至。

万维网引发了很多难解的司法管辖权问题。例如在美国，很多州对其境内的买卖征收营业税，但是亚马逊这样的网上商店，并不会对来自大部分州的买家收营业税，依据是他们在买家所在的州并没有实体商铺，因而无需帮那个州的税务局代为收税。按理说，买家应该自己上报外地购物记录并依法纳税，但没人这么做。

另外，诽谤罪的定罪也牵扯到司法管辖权。在有些国家，告某人诽谤只要能在该国看到载有相关言论的网站（无论网站在哪儿），就能胜诉，而被告是否到过这个国家都无所谓。

有些行为在某国合法，换一个国家可能就是非法的。常见的两个例子是色情业和在线赌博。一国公民在互联网上干了在本国犯法的事儿（比如到外国网站赌博），这个国家对他如何执法？有些国家仅为进出国门的互联网留下了有限的几条通路，以此来屏蔽他们不认可的网络访问，但这样做的国家在世界上也并非绝无仅有。对政府来说，还有一个办法是让人们用实名上网。这看上去是个防止匿名辱骂和骚扰的好办法，但却让持激进观点的人和异见人士发言时如履薄冰 [1]。

[1] 2007 年 7 月，韩国正式推行了网络实名制，要求后台实名，前台可以使用化名。但对 Twitter、Fackbook 等社交网络不作实名要求，理由是社交网站属私人领域，不适用实名制。2012 年 8 月，韩国宪法裁判所裁定网络实名制违宪，韩国广播通信委员会将按要求修改相关法规并废除实名制。—— 译者注

个人、政府（不论是不是国民支持的）和企业（其利益往往跨越国界）之间总是充满了合法权益的纠葛。互联网则让这些问题更加错综复杂。

第 11 章 数据、信息和隐私

数字技术为人类带来了无数便利，少了它，我们的生活会平淡乏味很多。与此同时，数字技术也给每个人的隐私带来了空前的威胁。而且，（用本书责任编辑的话来说）这种情况只会越来越糟糕。对个人隐私的这种侵害，有些是因为互联网及其应用，有些则是数字设备变得越来越小、越来越便宜、越来越快带来的副作用。与日俱增的处理能力、存储容量和通信带宽，使采集和保留各种信息、高效地分析数据，然后无远弗届地传播变得易如反掌，而且成本几乎可以忽略不计。

隐私常常就是安全的同义词。至少对每个个体而言，如果自己的生活信息被传播得随处可见，那怎么会让人感觉安全无忧呢？特别是互联网，它对个人安全已经产生了重大影响。这种影响更多体现在财务风险而非人身安全方面。因为互联网让人们从各种来源收集和整理信息变得异常容易，从而为电子入侵大开方便之门。

这一章，我们讨论几个有关隐私和安全的话题，跟大家讲讲应对措施，虽然长远来看无法完全避免，但至少可以知道如何降低风险。不过，安全毕竟是一个非常复杂的话题，所以本章只能粗略地讲个大概。而且，我们的内容也将主要围绕本书其他章节的话题展开，而不会在社会、经济、政治和法律等应对技术变革的这些方面着墨太多。

我看报纸上最近有一个广告，说人类将在接下来几年产生大约 2.5 泽字节的数据。很多人对泽字节没有什么概念，「泽」是 1021，不管怎么说这都不是个小数字了。这么多的数据从哪来，利用它们能干什么？这个问题的答案耐人寻味，而且很可能隐藏着很多严重的问题。因为其中有些数据虽然我们用不到，但却可能与我们息息相关。与我们相关的数据越多，陌生人掌握我们信息的可能性也就越大。

本章先从搜索开始讲，因为在我们使用搜索引擎寻找要浏览的网站时，收集数据的过程通常就开始了。从搜索开始，就会引出跟踪的话题，比如你访问了哪些站点，在浏览网站时都做了什么。然后，自然就是数据库的话题，涉及很多利益主体收集的各种数据。接着是数据汇总和数据挖掘，因为数据的价值只有在兼收并蓄且被找出规律的情况下才会显现出来。而这也正是隐私问题的高发地带，有关我们的多方的数据汇集起来，会让我们的隐私信息暴露无遗。接下来，我们聊聊为了享受娱乐或便捷服务，我们情愿告诉别人的个人信息。这些个人信息让汇总数据更容易也更具有商业价值，当然对我们隐私的威胁也更大。最后要讨论一下云计算。云计算公司在自己的服务器上提供存储和处理服务，而我们要把自己的数据完全交给这些公司。

11.1 搜索

上网搜索的历史可以追溯到 1994 年前后。按照现在的规模来看，当时的 Web 渺小得几乎可以忽略不计。接下来几年间，网页和查询的数量均快速增长。谷歌公司的一篇论文（谢尔盖·布林和拉里·佩奇发表于 1998 年初的「The anatomy of a large-scale hypertextual web search engine」）中曾提到一个最成功的早期搜索引擎 Altavista，说它在 1997 年年底时每天要处理 2000 万个查询。这篇论文还准确地预言了 2000 年的 Web 将有 10 亿网页，每天要处理数亿次查询。《经济学人》2010 年底的一篇文章指出，仅谷歌公司一家每天就要处理 20 亿次搜索。

搜索是个大买卖，它从无到有，短短十年就成为一个产业。最典型的例子是谷歌，它成立于 1998 年，上市于 2004 年，到 2011 年上半年，市值已经达到 2000 亿美元。这个规模超过了很多传统的老牌公司。百年老店福特汽车公司的市值只相当于谷歌的四分之一，而赫赫有名的通用电气也只与谷歌打个平手。谷歌的创收能力超强，增长迅猛，但竞争对手林立，所以很难说将来会怎么样。（在此必须得声明一下：我有时候也会为谷歌提供咨询服务，甚至做它的兼职。显然，本书中的任何观点都只代表我自己，与谷歌公司无关。）

搜索引擎怎么工作？从用户角度来看，他们会在网页上的表单中填写查询条件，然后把这个条件发送给服务器。服务器差不多马上就会返回一组链接和文本摘要。从服务器的角度看则要复杂得多。服务器会生成一组包含查询关键词的页面，按照相关程度进行排序，再在 HTML 中附上页面的摘要，然后再发给用户。互联网实在太大了，每个用户在查询时不可能直接搜索整个互联网。搜索引擎的主要任务就是为满足查询需求，事先把所有网页的副本有组织地保存在服务器上。为此，搜索引擎需要利用爬虫程序采集互联网上的所有页面，把它们的内容保存到数据库中，以便后续查询可以迅速返回结果。（并不是所有人都明白搜索结果是以预先计算好的缓存页面的索引为依托的。就在几年前，美国一家国家级电视台的新闻节目称：「输入‘帕丽斯·希尔顿’，谷歌的计算机就会搜索整个互联网，只要半秒钟就能找到所有提到她的网页和她在网上的所有照片。」）

下面这张示意图可以大致说明搜索引擎的工作过程，包括在结果页面中插入广告：

关键是规模太大。用户几十亿，网页不知道有多少个几十亿。谷歌以前总爱公布它为构建索引采集了多少多少页面，但在这个数字超过 100 亿之后，就没见他们再公布过。如果一个网页平均 10 到 20KB，那么存储 500 或 1000 亿页面就要占用上拍字节的磁盘空间。虽然有些页面是静态的，也就是说几个月甚至几年都不会更新，但也有相当多的页面更新得非常快（股票报价、新网站、博客、Twitter 消息等），因此爬虫的采集工作一刻也不能停。一停，索引信息就面临过时的风险。搜索引擎每天要处理几十亿次查询，每次查询都必须扫描数据库、搜索相关页面、按一定规则排序。在此期间还要精心选择与搜索结果匹配的广告，在后台把整个过程涉及的一切都记录下来，从而进一步改进搜索质量，领先于竞争对手，卖出更多广告。

从本书的角度来说，搜索引擎是实际应用算法的一个典型案例。但巨大的通信量决定了简单的算法难以满足高性能的需求。

仅仅是与采集网页相关的算法就有一整套。有的用于判断下一次采集哪个页面，有的用于从网页中提取可供索引的信息（词、链接、图片等），有的用于把这些信息发送给索引构建器。首先从提取 URL 开始，然后剔除其中重复或无关的，剩下的才会添加到采集队列中。采集过程中比较棘手的问题在于不能过于频繁地爬一个站点，否则会显著增加站点负载，没准还会惹恼网站所有者（最终导致爬虫被拒之门外）。由于页面变化的速度千差万别，因此算法必须准确判断页面变化的频率，从而保证对变化快的站点提高采集频率。

采集来页面之后就要构建索引。这个阶段要从爬虫采集的页面中提取要索引的页面内容，然后在索引中记录这些内容，以及它们在页面中的位置和相应的 URL。这一阶段的具体处理方式取决于要索引的内容是文本、图片，还是 PDF 等标准文档格式。本质上，索引就是为网页中出现的词或其他可索引项创建一组页面和位置，并以相应的方式保存起来，以便通过任何具体的关键词都能够迅速地找到它们。

最后一步就是针对具体的查询组合响应页面。简单来讲，就是以查询中所有的关键词为依据，通过索引列表迅速找到匹配的 URL，然后（同样也是迅速地）选择匹配度最高的 URL。这个过程涉及的技术是搜索引擎运营商的核心竞争力所在，在网上不大可能搜索到相关的技术文档。同样，规模过大仍然是问题的关键。任何一个关键词都可能出现在数百万个页面中，两个关键词同时出现在上百万个页面中的概率也很高。关键在于怎么才能迅速从这些页面中筛选出最为匹配的十个页面。谁能把最佳匹配结果排在前头，谁的响应速度快，谁就能赢得用户。

第一批搜索引擎只会显示一组包含搜索关键词的页面，而随着网页数量激增，搜索结果中就会混入大量无关页面。谷歌的 PageRank 算法会给每个页面赋予一个权重，权重大小取决于是否有其他页面引用该页面，以及引用该页面的其他页面自身的权重。从理论上讲，权重越大的页面与查询的相关度就越高。正如布林和佩奇所说：「凭直觉，那些经常被其他网页提及和引用的页面的价值一定更高一些。」当然，要产生高质量的搜索结果绝对不会只靠这一点。搜索引擎公司会不断采取措施来改进自己的结果质量，以期超越对手。

面对如此巨大的数据量，要提供搜索服务也必须拥有庞大的计算资源。处理器要数百万，内存要以太字节计，硬盘要以拍字节计，带宽要达到每秒数吉比特，耗电量也要数十亿瓦。当然，还需要大量的人。这些投入都要花钱，而钱通常来自广告收入。简单来说，搜索引擎的广告模式是这样的。广告客户付钱在网页上显示广告，价格由多少人看过以及什么样的人看到该网页来决定。这种定价模式叫按页面浏览量收费，即按「展示」，也就是按广告在页面上被展示的次数收费。另一种模式是按点击收费，即按浏览者点击广告的次数收费。对广告感兴趣的浏览者无疑是有价值的，因此搜索引擎的广告模式，说到底就是拍卖搜索关键词。广告客户出价购买的是在特定关键词的搜索结果旁边显示广告的权利，而浏览者点击了广告，搜索引擎公司就会向广告客户收钱。

举个例子，假设有人搜索「车祸」，那这个人很可能是想找一位熟稔责任界定的律师。如果知道搜索人的地理位置信息，那么结果就会更精准，因为律师通常都希望本地人能看到自己的广告。同样，如果知道搜索人的其他一些情况，比如性别、婚否和年龄，那么他的搜索关键词就会更有价值。下面是我在马萨诸塞州坎布里奇（Cambridge, Massachusetts）搜索「car accident」（车祸）得到的结果。仔细看一看，尽管我没有提供地理位置信息，但搜索引擎是大概知道这个信息的。

最前面的搜索结果（不算广告）与防止发生交通事故有关，可见搜索结果并没有倾向于广告客户，这些人基本都是律师。（右侧的广告看起来跟请律师也没关系，但只要我不点它，广告客户就不会花钱。）如果我点了其中一个广告，投放该广告的人就要根据自己的出价付钱给谷歌。搜索引擎公司都有完备的手段避免虚假点击，这其中的技术细节同样是秘而不宣的，特别是顾及到很多虚假点击都由僵尸网络产生的背景，这个问题我们在上一章里讲到过。

谷歌的 AdWords 简化了在线投放广告的评估过程，比如其估算工具会告诉你关键词「kernighan」的费用大约为每次点击 65 美分。换句话说，每当有人搜索 kernighan 并点击了我的广告（应该是最上面的两个结果中的一个），那我就得付谷歌 65 美分。这个工具还会估计出每天可能有 600 次搜索，当然谁也不可能知道有多少人会点击我的广告，我因此一天要花多少钱。我从来也没做过这个试验，因此结果至今还是未知数。

广告客户可以花钱让搜索结果倾向自己而不是竞争对手吗？布林和佩奇同样担心过这个问题，他们曾写道：「我们认为靠广告支撑的搜索引擎会本能地偏向广告客户，而远离消费者需求。」谷歌的大部分收入来自广告，但该公司会严格区分搜索结果和广告，其他主流搜索引擎也会这么做。

我们这里讨论的虽然是搜索，但同样的考量对任何广告行为也都适用：定位越精准，效果越明显。

11.2 跟踪

只要上网，我们的信息就免不了被收集。不留下蛛丝马迹，几乎什么也干不了。使用其他系统时也一样，特别是使用手机的时候，手机网络随时都知道我们的位置在哪里。如果是在户外，支持 GPS 的手机（现在的智能手机几乎都支持）定位用户的误差不超过 10 米，而且随时都会报告你的位置。（我在办公室时，我的手机报告我的位置误差也只有 20 米，而办公室所在的大楼属于中等规模建筑。）有些数码相机也带 GPS，可以在照片中编入地理位置信息，这种做法被称为打地理标签。

把多个来源的跟踪信息汇总起来，就可以绘制一幅关于个人的活动、喜好、财务状况，以及其他很多方面的信息图。这些信息最起码可以让广告客户更精准地定位我们，让我们看到乐意点击的广告。不过，跟踪数据的应用可远不止于此。这些数据还可能被用在很多我们意想不到的地方。比如根据收入把人分成三六九等，在贷款时区别对待，或者更糟糕地，被人冒名顶替，被政府监控，被人谋财，甚至害命。

怎么收集我们的浏览信息呢？有些信息会随着浏览器的每一次请求发送给服务器，包括你的 IP 地址、正在浏览的页面（即来源页）、浏览器的类型和版本、操作系统，还有语言偏好。

此外，如果计算机中保存着服务器域的 cookie，那么这些「小甜饼」也会随浏览器请求一块发送。根据 cookie 的规范，只能把这些保存用户信息的小文件发给最初生成它们的域。那还怎么利用 cookie 跟踪我对其他网站的访问呢？

要知道答案，就得明白链接的工作原理。每个网页都包含指向其他页面的链接（这正是「超链接」的本义）。我们都知道链接必须由我们主动点击，然后浏览器才会打开或转向新页面。但图片不需要任何人点击，它会随着页面加载而自动下载。网页中引用的图片可以来自任何域。于是，浏览器在取得图片时，提供该图片的域（根据请求中的来源页信息）就知道我访问过哪个页面了。而且这个域也可以在我的计算机上存放 cookie，并且收到之前访问该域时生成的 cookie。

以上就是实现跟踪的秘密所在，下面我们再通过例子来解释一下。假设我想买一辆新车，因此访问了 toyota.com。我的浏览器因此会下载 60 KB 的 HTML 文件，还有一些 JavaScript，以及 40 张图片。其中一张图片的源代码如下：

<img src="http://ad.doubleclick.net/ad/ N2724.deduped_spotlight/B1009212; sz=1x1;tag=total_traffic;ord=1?" width=1 height=1 border=0>

这个 <img> 标签会让浏览器从 ad.doubleclick.net 下载一张图片。这张图片的宽和高都只有 1 个像素，没有边框，而且很可能是透明的，总之页面上看不见它。当然，这张图片根本就没想让人看到。当我的浏览器请求它时，DoubleClick 会知道我正在浏览丰田汽车公司网站的某个页面，而且（如果我允许）还会在我的计算机中保存一个 cookie 文件。要是我随后又访问了一个内置 DoubleClick 图片的网站，DoubleClick 就可以绘制一张我的「足迹图」。如果我的「足迹」大都留在汽车网站上，DoubleClick 会把这个信息透露给自己的广告客户。于是乎，我就能看到汽车经销商、购车贷款、修车服务、汽车配件等等各种广告。如果我的「足迹」更多与交通事故或止疼有关，那么就会看到律师和医生投放的广告。

拿到用户访问过的站点信息后，DoubleClick（现为谷歌所有）会根据这些信息向丰田等广告客户推销广告位。丰田公司继而利用这些信息定向投放广告，而且（可能）会参考包括我的 IP 地址在内的其他信息。（DoubleClick 不会把这些信息卖给任何人。）随着我访问的页面越来越多，DoubleClick 就可以绘制出一幅关于我的形象，借以推断我的个性、爱好，甚至知道我已经 60 多岁了，性别男，收入中上，住在新泽西中部，就职于普林斯顿大学。知道我的信息越多，DoubleClick 的广告客户投放的广告就越精准。到了某个时刻，DoubleClick 甚至可以确定那个人就是我。尽管大多数公司都声称不会这么做，可假如我的确在某些网页中填过自己的名字和电子邮件地址，那谁也不敢保证这些信息不会被传播得到处都是。

这套互联网广告系统设计得极其精密。打开一个网页，这个网页的发布者会立即通知雅虎的 Right Media 或谷歌的 Ad Exchange，说这个网页上有一个空地儿正虚位以待，可以显示广告。同时发过去的还有浏览者的信息（例如，25 到 40 岁之间、单身女子、住在旧金山，是个技术宅，喜欢泡馆子）。于是，广告客户会为这个广告位而竞价，胜出者的广告将被插入到这个网页中。整个过程只有零点几秒。

有不少公司在做收集网民「足迹」的业务，不过这个行业也在整合。DoubleClick 原先是一家独立公司，后来在 2008 年被谷歌花 31 亿美元收购了。最近有一篇论文提到，一半以上最受欢迎的网站都开启了跟踪机制。有些跟踪技术比所谓的「第三方」cookie（即像 DoubleClick 保存到本地计算机上的与网页不在同一个域的 cookie）更难觉察，也更难禁止。许多网站都含有多家公司的跟踪程序，我前些天访问的一个网站就有 12 个。给大家推荐一个浏览器扩展 Ghostery，通过它可以禁用 JavaScript 跟踪代码，还能查看被阻止的跟踪器。装上它，你会惊讶于互联网上潜伏着多少「间谍」。

要是你不喜欢被跟踪，完全可以把它们纠出来制服，或者至少暂时甩开它们。当然，这样做会耗费你的一些精力和体力。浏览器其实允许你完全关闭 cookie，或者禁用第三方 cookie，或者在浏览器关闭时自动把 cookie 删除。长时间保存的 cookie 会存储在计算机的文件系统中。若要删除它们，可以通过浏览器中的某个按钮，也可以直接找到并删除那些保存它们的文件。大多数公司的跟踪程序都支持自愿回避（opt-out）机制。也就是说，如果跟踪程序在你的计算机中碰到了一个特殊的 cookie，那它们就不会再为了定向广告而记录你的行踪，但还是有可能记录你的 IP 地址。我在使用 Firefox 的一个扩展 TACO（Target Advertising Cookie Opt-out，定向广告 Cookie 自愿回避），这个扩展维护着一个 cookie 跟踪站点的列表（目前有大约 150 个名字），在浏览器中保存着它们的自愿回避 cookie。而我呢，同时对大多数网站都选择关闭 cookie。

这些机制在不同的浏览器中并不兼容，甚至同一款浏览器的不同版本之间都不兼容，而浏览器默认的设置通常是允许 cookie 的读写。

封掉第三方 cookie 有时候也没用，因为浏览器中显示的网页好像是来自一个站点，但实际却是从其他站点转发过来的。比如下面这个假想的 URL：

http://www.bigcorp.com/relay?doubleclick.net/whatever

它首先会被 BigCorp 域中的服务器解析，然后转给 DoubleClick，而后者仍然会提供相同的 cookie 信息，通过 BigCorp 服务器加载到你的浏览器中。这种技术实际上是把第三方 cookie 打扮成了第一方 cookie。

遗憾的是，很多站点离开 cookie 都无法运行。当然有时候是合情合理的，比如服务器需要知道你是不是已经登录过了，而有时候则就是想要跟踪你。这让我很恼火，所以我一般对这样的网站都敬而远之。

前面介绍过，一个像素大的图片或者叫网页信标（web beacon）也可以用来跟踪你。用于取得像素图片的 URL 可以包含一个标识码，表示你正在浏览什么网页，还可以包含一个标识符，表示特定的用户。这两个标志就足以跟踪你的浏览活动了。

互联网视频网站普遍使用的 Adobe Flash 技术能够实现动画广告，该技术也会在你的计算机中保存 Flash cookie。这种 cookie 与前面所说的 cookie 不是一回事，在文件系统中跟它们也不是保存在一个地方。Flash cookie 本来是用于缓存数据以便更流畅地播放视频，但也会被用于跟踪。Adobe 提供了禁用它们的方法，为此需要访问 adobe.com 并完成几个页面的设置。说来也怪，我发现关闭 Flash cookie 并不影响性能（对每台新电脑我都会这么做）。换句话说，这种缓存好像没什么效果。

JavaScript 也是常用的一种跟踪技术。不管是包含在 HTML 中的 JavaScript 脚本代码，还是通过 <script> 标签中 src="name.js" 属性的 URL 下载的脚本文件，浏览器都会立即执行。JavaScript 最主要用于「分析」用户浏览特定网页的行为。比如，下面这行代码会从谷歌服务器加载并运行一段 JavaScript 脚本：

<script type="text/javascript" src="http://pagead2.googlesyndication.com/pagead/show_ads.js"> </script>

JavaScript 代码可以读写 cookie，有时候还可以读写浏览器访问过哪些页面的历史记录。它还可以持续监视鼠标在屏幕上的位置，并将这些信息发回服务器，以便推断网页的哪些部分更吸引用户，哪些部分用户很少关注；还可以监视鼠标点击了哪些位置（即使这些位置不是链接等能够作出反应的区域）。现在，偷偷摸摸使用 JavaScript 的情况有越来越多的趋势。如果网页中有 JavaScript，那么发生恶意攻击的可能性也会增大。

2010 年底有一篇文章谈到 evercookie，文中列举了在客户计算机上保存跟踪信息的十几种可能的方式 [1]，有些已经超出了浏览器的控制范围。就算是这方面的专家，想把它们都清除干净也很困难。而只要有一个地方有残留，其他地方的跟踪功能就可以全部恢复。很快，有关防护措施的文章也见诸报端，但其揭示的问题确实无法否认：除了得到人们正式认可的地方之外，还有很多地方可以保存这些信息。比如，有的跟踪手段是收集某人使用的操作系统、浏览器、版本号、语言偏好、安装的软件等特征，这些都与 cookie 无关。收集到足够的特征信息后，就有可能据以区分和识别某个人。广告客户和其他机构对这种精确的身份识别自然是欣赏有加的。

[1] 参见 http://en.wikipedia.org/wiki/Evercookie。—— 译者注

并不是只有浏览器可以跟踪用户，邮件阅读器、视频播放器等等使用 HTTP 和 HTML 的软件也可以。如果你的邮件阅读器解析 HTML，那它就有可能「显示」那些 1 个像素大的图片，于是你就被别人给跟踪了。

一个为害特别大的跟踪和监视手段时不时就会浮出水面，它就是深度包检测（deep packet inspection）。前面不是说过嘛，每个 IP 数据包从你的计算机出发，通常都要经过 15~20 个网关才能到达目的地，反过来也差不多。这条路径上的每个网关都有可能检查这些数据包，看到里面的信息，甚至还能以某种方式修改它们。一般来说，这种入侵都是你的 ISP 发起的，因为在那里最容易认出你来。广告客户和政府部门尤其喜欢这种信息，因为这些信息已经超出了上网浏览的范畴，而是涉及你在互联网上的一举一动。

关于个人身份的哪些信息可以收集，可以怎么使用，不同国家有不同的规定。以美国为例，简言之，怎么都行！任何公司或机构都可以收集和传播关于你的信息，不用通知你，也不需要给你提供自愿选择的机会。而在欧盟（同样简言之），隐私是一个严肃得多的话题：在没有得到个人明确许可的情况下，任何公司都不能收集或使用个人数据。

谷歌街景（Street View）的不同遭遇，就足以表现出这种法律和文化上的差异。谷歌的街景服务在世界很多地方提供街道的全景照片。而对所有照片，谷歌都会通过算法来模糊人脸以防这个人被认出来，同样也会模糊车牌。尽管如此，它在很多国家还是引发了隐私问题。但这些国家在看待街景服务的价值和它暴露个人隐私的风险上所采取的立场却又各不相同。

11.3 数据库、信息与聚合

互联网和 Web 已经彻底改变了人们收集、存储和展现信息的方式。搜索引擎和数据库对每个人都具有不可估量的价值。很难想象之前没有互联网的时代我们是怎么过来的。凡事都有两面，现在这样数据在网上随意传播也有问题，尤其是那些可能会过多暴露我们的信息如果传出去，会令人相当不自在。

有些信息明显就是公开的，还有些信息收集起来就是为了供人搜索和索引的。如果我写了一个网页，希望大家都能看到，假设就是这本书的页面吧，那么我肯定愿意人们通过搜索引擎可以轻易发现它。

那怎么看待公共档案呢？法律上，某些信息属于「公共档案」（public records），任何人通过申请都可以查阅。在美国，公共档案包括可以公开的庭审记录、抵押文件、房价、地方房产税、出生和死亡记录、结婚证、政治捐助，等等。（查阅出生记录通常是为了知道「妈妈婚前的姓氏」，以便辅助确认一个人的身份。）很早以前，要知道这些信息必须不辞劳苦，亲自前往当地政府驻地查阅。因此，虽然这些档案名义上是「公开」的，但不付出点代价也不可能看到。谁要想获得这些数据，就得亲自跑一趟，或许需要出示身份证件，要想复制一份可能还得花点钱。今天，如果这些数据上了网，我坐在自己家里就可以轻轻松松查阅这些公共档案。我甚至可以开个公司，收集汇总这些信息，然后与其他信息整合起来。比如很多人都知道的 zillow.com，就整合了地图、房地产广告、有关财产和交易的公开数据，通过地图来直观地显示房价。如果你想买房或者想卖房，它对你了解市场很有用；否则，你可能会觉得它暴露了人家太多的信息。通过查询联邦选举委员会（FEC，Federal Election Commission）的选举捐款数据库（fec.gov），可以知道哪位候选人得到哪些朋友和要人的捐赠，或许可以查到他们的家庭住址等信息。在 FEC 提供信息的基础上，fundrace.huffingtonpost.com 在一张地图上给我们标出了这些人的名字、地址、职业。这种做法让人们对如何平衡公众知情权和个人隐私权有了新的认识。

什么样的信息才应该让人如此轻而易举地得到？这个问题很难回答。政治捐款应该公开，但门牌号码可能就应该稍加隐藏。包含美国社会保险号等个人身份识别信息的公共档案似乎不该放在网上，因为这就给盗用别人身份打开了方便之门。可当前的法律无法完全阻止这种信息的公布，而这种信息一旦上网，就覆水难收了。

随着在多个各不相关的来源都能查到同一类信息，这个问题就变得愈发严重了。比如，很多提供 Web 服务的公司都有自己大量的客户信息。搜索引擎会记录所有查询，也包括查询人的许多信息。最低限度也会记录查询人的 IP 地址，还有用户之前访问过网站时保存在计算机上的 cookie。

2006 年 8 月，AOL 出于好意而公开了一大批查询日志样本，供人研究。这些日志涉及三个多月以来 65 万用户的 2000 万查询，已经做了匿名处理，因此从理论上讲，不存在任何可以用于辨识个人身份的信息。尽管是善意之举，但人们也很快就发现这些日志在实践中不会像 AOL 想象的那样做到完全匿名。每个用户在查询时都会被赋予一个随机但唯一的标识符，有了这个标识符，就很容易知道同一个人都查询过什么内容。进而，确定一些人的身份也就成为可能。因为不少人都搜索过自己名字、地址、社会保险号以及其他个人信息，通过搜索相关性分析暴露出来的信息比 AOL 认为的多，也肯定比原始用户自己想到的多得多。AOL 很快从自己网站上删除了这些日志，当然为时已晚。这些数据早已被传播得满世界都是了，而且至今仍可以找到，甚至还附有帮你分析它们的一些工具。

查询日志对经营企业和改进服务有价值，但很明显其中可能包含敏感的个人信息。谷歌、雅虎、微软这些提供搜索服务的公司会把查询日志保留多长时间？这里有个矛盾：考虑个人隐私则保留的时间应该短，而考虑执法目的则保留的时间应该长。为了达到一定的匿名程度，这些公司内部该对数据进行怎样的处理？虽然他们全都声称会删除每条查询对应 IP 的部分信息（一般是最右边那一字节），但仅仅如此似乎还不够，还达不到反识别用户的目的。政府机关查询这些信息的权限有多大？打一次官司会查询多少信息？所有这些问题都没有明确的答案。AOL 公布的查询日志中有些是很吓人的，比如有人查询怎么杀死自己的配偶。因此，有限度地向司法机关开放这些数据是合理的，但问题是这个限度应该放多大，很难说清楚。

AOL 事件揭示了一个广泛存在的问题，即真正做到数据匿名化是非常困难的。删除身份识别信息可以降低识别度，单就特定的数据而言，确实无法定位到用户，因此可以说它是无害的。但现实当中信息的来源是多方面的，把多个来源的信息组合起来则很可能挖掘出更多身份特征。而且某些来源的信息甚至连提供者自己都不知道，这些信息将来也未必还能找得到。举个例子，假设搜索引擎会删除每条查询对应 IP 的最右边一个字节，但根据剩下的三个字节仍然可知它来自普林斯顿大学计算机科学系，如果再结合普林斯顿日志中我什么时候使用过该 IP 上网的记录，那就可以把具体的查询跟我挂上钩了。

有关这种再识别（re-identify）问题，下面可以给大家讲一个真实的案例。1997 年，当时在 MIT 读博士的拉坦娅·斯威尼（Latanya Sweeney）分析了马萨诸塞州 135 000 名雇员的体检记录，这些记录都做了反识别处理。数据来源是该州的保险委员会，可用于研究目的，甚至被卖给了私人公司。每条体检记录中除了大量其他信息外，都包括生日、性别和邮政编码。斯威尼发现有 6 个人的生日都是 1945 年 7 月 31 日，其中 3 个男性，而只有 1 人住在坎布里奇。把这些信息和公开的选民登记名单一对照，她便知道了这个人就是时任州长威廉·韦尔德（William Weld）。

匿名处理数据与混淆保证安全（前一章刚介绍过）多少有些类似之处，这两者都是基于没有足够信息无法解密数据的考虑。问题是，这两种情况下敌人掌握的信息，很可能比我们想象的多。而且就算眼下他们不知道，将来也有可能知道。

11.4 隐私失控

不久前，我在网上看到一篇文章，大概是这么写的：「有一次面试，他们问了一些我简历上没写的问题。原来他们看了我的 Facebook 主页，这太让人意外了。Facebook 上可都是我个人隐私啊，跟他们有什么关系！」这个人很傻很天真，但我想很多 Facebook 用户在这种情况下可能都会有一种被冒犯的感觉，尽管他们清楚地知道公司人力资源部和大学招生办会例行通过搜索引擎、社交网站及其他类似工具来了解申请人的更多信息。在美国，面试时问一个人的民族、宗教信仰、性取向等很多关乎个人的问题都是非法的，但这些问题通过社交网站和搜索引擎都可以不费吹灰之力就找到答案。

最重要的是要知道，跟踪我们浏览的网站只是收集我们信息的诸多方式中的一种。毋庸置疑，随着社交网站的流行，为了娱乐和与其他人联系，我们自愿放弃了很多个人隐私。

社交网站存在隐私问题是毫无疑义的，因为它们会收集注册用户的大量信息，而且是通过把这些信息卖给广告客户来赚钱。尽管出现的时间不长，但它们的用户规模增长迅猛。Facebook 成立于 2004 年，现在据说已经有了 7.5 亿用户，相当于全世界人口的十分之一还多。如此之快的增长速度，不可能有太多时间考虑隐私政策，也不可能从容不迫地开发出稳定可靠的计算机程序。于是，每个社交网站都面临着因功能不完善而泄露用户隐私、用户不清楚该如何选择自己的隐私设置（变得太快）、软件出错，以及由于系统固有问题而暴露数据等问题。

作为最大也最成功的社交网站，Facebook 的问题也最明显。Facebook 给第三方提供了 API，以方便编写 Facebook 用户可以使用的应用。但这些 API 有时候会违背公司隐私政策透露一些隐私信息。当然，并非只有 Facebook 一家如此。做地理定位服务的 Foursquare 会在手机上显示用户的位置，能够为找朋友和基于位置的游戏提供方便。在知道潜在用户位置的情况下，定向广告的效果特别好。如果你走到一家餐馆的门口，而手机上恰好是关于这家餐馆的报道，那你很可能就会推门进去体验一下。虽然让朋友知道你在哪儿没什么问题，但把自己的位置昭告天下则非明智之举。比如，有人做了一个示范性的网站叫「来抢劫我吧」（Please Rob Me），该网站根据 Foursquare 用户在 Twitter 上发表的微博可以推断出他们什么时候不在家，这就为入室行窃提供了机会。

「位置隐私」—— 保证自己位置信息保密的权利 —— 在我们日常使用的很多系统中并没有得到保障，比如信用卡支付系统、高速公路和公交车刷卡收费系统，当然还有手机网络。要想让人对你都去过哪儿一点都不知情越来越困难。手机应用经常会要求访问你在手机上存储的一切信息，包括通话记录、本地存储的信息、当前位置，等等。在我看来，这些应用想知道的已经超出了它们应该知道的。

社交网站和其他一些站点甚至会泄漏非用户的个人信息。举个例子，假如一位好心的朋友发给我一份电子请柬（e-vite），请我去参加某个聚会。就算我不答复这个邀请，也没有允许别人使用我的电子邮件地址，运营该邀请服务的公司就已经得到了我准确的电子邮件地址。如果一位朋友从他的 Gmail 或雅虎账号给我发了封邮件，那么我的邮件地址就在没得到我许可的情况下被别人知道了。如果一位朋友在一张照片中给我打上标签，然后将它发布到 Facebook 或 Flickr（或两个地方都发），那我的隐私就在没有我同意的情况下暴露了。Facebook 有图像识别功能，因而那位朋友在给我加标签时会更方便，而且这个操作默认无需经过我这个被标签人同意。所以说，社交网站很容易根据自己的用户构建一个交往群体的「社交图谱」，其中包括被这些用户牵连进来但并未同意甚至毫不知情的人。在以上几种情形下，任何人都束手无策，而且在自己的信息公开后也没有办法删除它们。

情报机关早就知道通过流量分析来了解大量内幕消息，只要知道谁跟谁有联系即可，都不用知道当事人说了什么。同样，通过人们在社交网站或明或暗的联系也可以掌握很多「情报」。比如，2009 年两名 MIT 学生声称可以根据人们在 Facebook 上朋友的性取向推断出这些人的性取向。无论能否准确推断出某个人的性取向，但至少这种推断是可行的。可以肯定的是，美国政府早已着手挖掘异议人士在 Facebook 网页上的信息，借以了解还有谁跟他们「同流合污」。

