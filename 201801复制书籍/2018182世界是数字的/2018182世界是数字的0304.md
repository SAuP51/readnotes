# 11 数据、信息和隐私

数字技术为人类带来了无数便利，少了它，我们的生活会平淡乏味很多。与此同时，数字技术也给每个人的隐私带来了空前的威胁。而且，（用本书责任编辑的话来说）这种情况只会越来越糟糕。对个人隐私的这种侵害，有些是因为互联网及其应用，有些则是数字设备变得越来越小、越来越便宜、越来越快带来的副作用。与日俱增的处理能力、存储容量和通信带宽，使采集和保留各种信息、高效地分析数据，然后无远弗届地传播变得易如反掌，而且成本几乎可以忽略不计。

隐私常常就是安全的同义词。至少对每个个体而言，如果自己的生活信息被传播得随处可见，那怎么会让人感觉安全无忧呢？特别是互联网，它对个人安全已经产生了重大影响。这种影响更多体现在财务风险而非人身安全方面。因为互联网让人们从各种来源收集和整理信息变得异常容易，从而为电子入侵大开方便之门。

这一章，我们讨论几个有关隐私和安全的话题，跟大家讲讲应对措施，虽然长远来看无法完全避免，但至少可以知道如何降低风险。不过，安全毕竟是一个非常复杂的话题，所以本章只能粗略地讲个大概。而且，我们的内容也将主要围绕本书其他章节的话题展开，而不会在社会、经济、政治和法律等应对技术变革的这些方面着墨太多。

我看报纸上最近有一个广告，说人类将在接下来几年产生大约 2.5 泽字节的数据。很多人对泽字节没有什么概念，「泽」是 1021，不管怎么说这都不是个小数字了。这么多的数据从哪来，利用它们能干什么？这个问题的答案耐人寻味，而且很可能隐藏着很多严重的问题。因为其中有些数据虽然我们用不到，但却可能与我们息息相关。与我们相关的数据越多，陌生人掌握我们信息的可能性也就越大。

本章先从搜索开始讲，因为在我们使用搜索引擎寻找要浏览的网站时，收集数据的过程通常就开始了。从搜索开始，就会引出跟踪的话题，比如你访问了哪些站点，在浏览网站时都做了什么。然后，自然就是数据库的话题，涉及很多利益主体收集的各种数据。接着是数据汇总和数据挖掘，因为数据的价值只有在兼收并蓄且被找出规律的情况下才会显现出来。而这也正是隐私问题的高发地带，有关我们的多方的数据汇集起来，会让我们的隐私信息暴露无遗。接下来，我们聊聊为了享受娱乐或便捷服务，我们情愿告诉别人的个人信息。这些个人信息让汇总数据更容易也更具有商业价值，当然对我们隐私的威胁也更大。最后要讨论一下云计算。云计算公司在自己的服务器上提供存储和处理服务，而我们要把自己的数据完全交给这些公司。

## 11.1 搜索

上网搜索的历史可以追溯到 1994 年前后。按照现在的规模来看，当时的 Web 渺小得几乎可以忽略不计。接下来几年间，网页和查询的数量均快速增长。谷歌公司的一篇论文（谢尔盖·布林和拉里·佩奇发表于 1998 年初的「The anatomy of a large-scale hypertextual web search engine」）中曾提到一个最成功的早期搜索引擎 Altavista，说它在 1997 年年底时每天要处理 2000 万个查询。这篇论文还准确地预言了 2000 年的 Web 将有 10 亿网页，每天要处理数亿次查询。《经济学人》2010 年底的一篇文章指出，仅谷歌公司一家每天就要处理 20 亿次搜索。

搜索是个大买卖，它从无到有，短短十年就成为一个产业。最典型的例子是谷歌，它成立于 1998 年，上市于 2004 年，到 2011 年上半年，市值已经达到 2000 亿美元。这个规模超过了很多传统的老牌公司。百年老店福特汽车公司的市值只相当于谷歌的四分之一，而赫赫有名的通用电气也只与谷歌打个平手。谷歌的创收能力超强，增长迅猛，但竞争对手林立，所以很难说将来会怎么样。（在此必须得声明一下：我有时候也会为谷歌提供咨询服务，甚至做它的兼职。显然，本书中的任何观点都只代表我自己，与谷歌公司无关。）

搜索引擎怎么工作？从用户角度来看，他们会在网页上的表单中填写查询条件，然后把这个条件发送给服务器。服务器差不多马上就会返回一组链接和文本摘要。从服务器的角度看则要复杂得多。服务器会生成一组包含查询关键词的页面，按照相关程度进行排序，再在 HTML 中附上页面的摘要，然后再发给用户。互联网实在太大了，每个用户在查询时不可能直接搜索整个互联网。搜索引擎的主要任务就是为满足查询需求，事先把所有网页的副本有组织地保存在服务器上。为此，搜索引擎需要利用爬虫程序采集互联网上的所有页面，把它们的内容保存到数据库中，以便后续查询可以迅速返回结果。（并不是所有人都明白搜索结果是以预先计算好的缓存页面的索引为依托的。就在几年前，美国一家国家级电视台的新闻节目称：「输入‘帕丽斯·希尔顿’，谷歌的计算机就会搜索整个互联网，只要半秒钟就能找到所有提到她的网页和她在网上的所有照片。」）

下面这张示意图可以大致说明搜索引擎的工作过程，包括在结果页面中插入广告：

关键是规模太大。用户几十亿，网页不知道有多少个几十亿。谷歌以前总爱公布它为构建索引采集了多少多少页面，但在这个数字超过 100 亿之后，就没见他们再公布过。如果一个网页平均 10 到 20KB，那么存储 500 或 1000 亿页面就要占用上拍字节的磁盘空间。虽然有些页面是静态的，也就是说几个月甚至几年都不会更新，但也有相当多的页面更新得非常快（股票报价、新网站、博客、Twitter 消息等），因此爬虫的采集工作一刻也不能停。一停，索引信息就面临过时的风险。搜索引擎每天要处理几十亿次查询，每次查询都必须扫描数据库、搜索相关页面、按一定规则排序。在此期间还要精心选择与搜索结果匹配的广告，在后台把整个过程涉及的一切都记录下来，从而进一步改进搜索质量，领先于竞争对手，卖出更多广告。

从本书的角度来说，搜索引擎是实际应用算法的一个典型案例。但巨大的通信量决定了简单的算法难以满足高性能的需求。

仅仅是与采集网页相关的算法就有一整套。有的用于判断下一次采集哪个页面，有的用于从网页中提取可供索引的信息（词、链接、图片等），有的用于把这些信息发送给索引构建器。首先从提取 URL 开始，然后剔除其中重复或无关的，剩下的才会添加到采集队列中。采集过程中比较棘手的问题在于不能过于频繁地爬一个站点，否则会显著增加站点负载，没准还会惹恼网站所有者（最终导致爬虫被拒之门外）。由于页面变化的速度千差万别，因此算法必须准确判断页面变化的频率，从而保证对变化快的站点提高采集频率。

采集来页面之后就要构建索引。这个阶段要从爬虫采集的页面中提取要索引的页面内容，然后在索引中记录这些内容，以及它们在页面中的位置和相应的 URL。这一阶段的具体处理方式取决于要索引的内容是文本、图片，还是 PDF 等标准文档格式。本质上，索引就是为网页中出现的词或其他可索引项创建一组页面和位置，并以相应的方式保存起来，以便通过任何具体的关键词都能够迅速地找到它们。

最后一步就是针对具体的查询组合响应页面。简单来讲，就是以查询中所有的关键词为依据，通过索引列表迅速找到匹配的 URL，然后（同样也是迅速地）选择匹配度最高的 URL。这个过程涉及的技术是搜索引擎运营商的核心竞争力所在，在网上不大可能搜索到相关的技术文档。同样，规模过大仍然是问题的关键。任何一个关键词都可能出现在数百万个页面中，两个关键词同时出现在上百万个页面中的概率也很高。关键在于怎么才能迅速从这些页面中筛选出最为匹配的十个页面。谁能把最佳匹配结果排在前头，谁的响应速度快，谁就能赢得用户。

第一批搜索引擎只会显示一组包含搜索关键词的页面，而随着网页数量激增，搜索结果中就会混入大量无关页面。谷歌的 PageRank 算法会给每个页面赋予一个权重，权重大小取决于是否有其他页面引用该页面，以及引用该页面的其他页面自身的权重。从理论上讲，权重越大的页面与查询的相关度就越高。正如布林和佩奇所说：「凭直觉，那些经常被其他网页提及和引用的页面的价值一定更高一些。」当然，要产生高质量的搜索结果绝对不会只靠这一点。搜索引擎公司会不断采取措施来改进自己的结果质量，以期超越对手。

面对如此巨大的数据量，要提供搜索服务也必须拥有庞大的计算资源。处理器要数百万，内存要以太字节计，硬盘要以拍字节计，带宽要达到每秒数吉比特，耗电量也要数十亿瓦。当然，还需要大量的人。这些投入都要花钱，而钱通常来自广告收入。简单来说，搜索引擎的广告模式是这样的。广告客户付钱在网页上显示广告，价格由多少人看过以及什么样的人看到该网页来决定。这种定价模式叫按页面浏览量收费，即按「展示」，也就是按广告在页面上被展示的次数收费。另一种模式是按点击收费，即按浏览者点击广告的次数收费。对广告感兴趣的浏览者无疑是有价值的，因此搜索引擎的广告模式，说到底就是拍卖搜索关键词。广告客户出价购买的是在特定关键词的搜索结果旁边显示广告的权利，而浏览者点击了广告，搜索引擎公司就会向广告客户收钱。

举个例子，假设有人搜索「车祸」，那这个人很可能是想找一位熟稔责任界定的律师。如果知道搜索人的地理位置信息，那么结果就会更精准，因为律师通常都希望本地人能看到自己的广告。同样，如果知道搜索人的其他一些情况，比如性别、婚否和年龄，那么他的搜索关键词就会更有价值。下面是我在马萨诸塞州坎布里奇（Cambridge, Massachusetts）搜索「car accident」（车祸）得到的结果。仔细看一看，尽管我没有提供地理位置信息，但搜索引擎是大概知道这个信息的。

最前面的搜索结果（不算广告）与防止发生交通事故有关，可见搜索结果并没有倾向于广告客户，这些人基本都是律师。（右侧的广告看起来跟请律师也没关系，但只要我不点它，广告客户就不会花钱。）如果我点了其中一个广告，投放该广告的人就要根据自己的出价付钱给谷歌。搜索引擎公司都有完备的手段避免虚假点击，这其中的技术细节同样是秘而不宣的，特别是顾及到很多虚假点击都由僵尸网络产生的背景，这个问题我们在上一章里讲到过。

谷歌的 AdWords 简化了在线投放广告的评估过程，比如其估算工具会告诉你关键词「kernighan」的费用大约为每次点击 65 美分。换句话说，每当有人搜索 kernighan 并点击了我的广告（应该是最上面的两个结果中的一个），那我就得付谷歌 65 美分。这个工具还会估计出每天可能有 600 次搜索，当然谁也不可能知道有多少人会点击我的广告，我因此一天要花多少钱。我从来也没做过这个试验，因此结果至今还是未知数。

广告客户可以花钱让搜索结果倾向自己而不是竞争对手吗？布林和佩奇同样担心过这个问题，他们曾写道：「我们认为靠广告支撑的搜索引擎会本能地偏向广告客户，而远离消费者需求。」谷歌的大部分收入来自广告，但该公司会严格区分搜索结果和广告，其他主流搜索引擎也会这么做。

我们这里讨论的虽然是搜索，但同样的考量对任何广告行为也都适用：定位越精准，效果越明显。

## 11.2 跟踪

只要上网，我们的信息就免不了被收集。不留下蛛丝马迹，几乎什么也干不了。使用其他系统时也一样，特别是使用手机的时候，手机网络随时都知道我们的位置在哪里。如果是在户外，支持 GPS 的手机（现在的智能手机几乎都支持）定位用户的误差不超过 10 米，而且随时都会报告你的位置。（我在办公室时，我的手机报告我的位置误差也只有 20 米，而办公室所在的大楼属于中等规模建筑。）有些数码相机也带 GPS，可以在照片中编入地理位置信息，这种做法被称为打地理标签。

把多个来源的跟踪信息汇总起来，就可以绘制一幅关于个人的活动、喜好、财务状况，以及其他很多方面的信息图。这些信息最起码可以让广告客户更精准地定位我们，让我们看到乐意点击的广告。不过，跟踪数据的应用可远不止于此。这些数据还可能被用在很多我们意想不到的地方。比如根据收入把人分成三六九等，在贷款时区别对待，或者更糟糕地，被人冒名顶替，被政府监控，被人谋财，甚至害命。

怎么收集我们的浏览信息呢？有些信息会随着浏览器的每一次请求发送给服务器，包括你的 IP 地址、正在浏览的页面（即来源页）、浏览器的类型和版本、操作系统，还有语言偏好。

此外，如果计算机中保存着服务器域的 cookie，那么这些「小甜饼」也会随浏览器请求一块发送。根据 cookie 的规范，只能把这些保存用户信息的小文件发给最初生成它们的域。那还怎么利用 cookie 跟踪我对其他网站的访问呢？

要知道答案，就得明白链接的工作原理。每个网页都包含指向其他页面的链接（这正是「超链接」的本义）。我们都知道链接必须由我们主动点击，然后浏览器才会打开或转向新页面。但图片不需要任何人点击，它会随着页面加载而自动下载。网页中引用的图片可以来自任何域。于是，浏览器在取得图片时，提供该图片的域（根据请求中的来源页信息）就知道我访问过哪个页面了。而且这个域也可以在我的计算机上存放 cookie，并且收到之前访问该域时生成的 cookie。

以上就是实现跟踪的秘密所在，下面我们再通过例子来解释一下。假设我想买一辆新车，因此访问了 toyota.com。我的浏览器因此会下载 60 KB 的 HTML 文件，还有一些 JavaScript，以及 40 张图片。其中一张图片的源代码如下：

<img src="http://ad.doubleclick.net/ad/ N2724.deduped_spotlight/B1009212; sz=1x1;tag=total_traffic;ord=1?" width=1 height=1 border=0>

这个 <img> 标签会让浏览器从 ad.doubleclick.net 下载一张图片。这张图片的宽和高都只有 1 个像素，没有边框，而且很可能是透明的，总之页面上看不见它。当然，这张图片根本就没想让人看到。当我的浏览器请求它时，DoubleClick 会知道我正在浏览丰田汽车公司网站的某个页面，而且（如果我允许）还会在我的计算机中保存一个 cookie 文件。要是我随后又访问了一个内置 DoubleClick 图片的网站，DoubleClick 就可以绘制一张我的「足迹图」。如果我的「足迹」大都留在汽车网站上，DoubleClick 会把这个信息透露给自己的广告客户。于是乎，我就能看到汽车经销商、购车贷款、修车服务、汽车配件等等各种广告。如果我的「足迹」更多与交通事故或止疼有关，那么就会看到律师和医生投放的广告。

拿到用户访问过的站点信息后，DoubleClick（现为谷歌所有）会根据这些信息向丰田等广告客户推销广告位。丰田公司继而利用这些信息定向投放广告，而且（可能）会参考包括我的 IP 地址在内的其他信息。（DoubleClick 不会把这些信息卖给任何人。）随着我访问的页面越来越多，DoubleClick 就可以绘制出一幅关于我的形象，借以推断我的个性、爱好，甚至知道我已经 60 多岁了，性别男，收入中上，住在新泽西中部，就职于普林斯顿大学。知道我的信息越多，DoubleClick 的广告客户投放的广告就越精准。到了某个时刻，DoubleClick 甚至可以确定那个人就是我。尽管大多数公司都声称不会这么做，可假如我的确在某些网页中填过自己的名字和电子邮件地址，那谁也不敢保证这些信息不会被传播得到处都是。

这套互联网广告系统设计得极其精密。打开一个网页，这个网页的发布者会立即通知雅虎的 Right Media 或谷歌的 Ad Exchange，说这个网页上有一个空地儿正虚位以待，可以显示广告。同时发过去的还有浏览者的信息（例如，25 到 40 岁之间、单身女子、住在旧金山，是个技术宅，喜欢泡馆子）。于是，广告客户会为这个广告位而竞价，胜出者的广告将被插入到这个网页中。整个过程只有零点几秒。

有不少公司在做收集网民「足迹」的业务，不过这个行业也在整合。DoubleClick 原先是一家独立公司，后来在 2008 年被谷歌花 31 亿美元收购了。最近有一篇论文提到，一半以上最受欢迎的网站都开启了跟踪机制。有些跟踪技术比所谓的「第三方」cookie（即像 DoubleClick 保存到本地计算机上的与网页不在同一个域的 cookie）更难觉察，也更难禁止。许多网站都含有多家公司的跟踪程序，我前些天访问的一个网站就有 12 个。给大家推荐一个浏览器扩展 Ghostery，通过它可以禁用 JavaScript 跟踪代码，还能查看被阻止的跟踪器。装上它，你会惊讶于互联网上潜伏着多少「间谍」。

要是你不喜欢被跟踪，完全可以把它们纠出来制服，或者至少暂时甩开它们。当然，这样做会耗费你的一些精力和体力。浏览器其实允许你完全关闭 cookie，或者禁用第三方 cookie，或者在浏览器关闭时自动把 cookie 删除。长时间保存的 cookie 会存储在计算机的文件系统中。若要删除它们，可以通过浏览器中的某个按钮，也可以直接找到并删除那些保存它们的文件。大多数公司的跟踪程序都支持自愿回避（opt-out）机制。也就是说，如果跟踪程序在你的计算机中碰到了一个特殊的 cookie，那它们就不会再为了定向广告而记录你的行踪，但还是有可能记录你的 IP 地址。我在使用 Firefox 的一个扩展 TACO（Target Advertising Cookie Opt-out，定向广告 Cookie 自愿回避），这个扩展维护着一个 cookie 跟踪站点的列表（目前有大约 150 个名字），在浏览器中保存着它们的自愿回避 cookie。而我呢，同时对大多数网站都选择关闭 cookie。

这些机制在不同的浏览器中并不兼容，甚至同一款浏览器的不同版本之间都不兼容，而浏览器默认的设置通常是允许 cookie 的读写。

封掉第三方 cookie 有时候也没用，因为浏览器中显示的网页好像是来自一个站点，但实际却是从其他站点转发过来的。比如下面这个假想的 URL：

http://www.bigcorp.com/relay?doubleclick.net/whatever

它首先会被 BigCorp 域中的服务器解析，然后转给 DoubleClick，而后者仍然会提供相同的 cookie 信息，通过 BigCorp 服务器加载到你的浏览器中。这种技术实际上是把第三方 cookie 打扮成了第一方 cookie。

遗憾的是，很多站点离开 cookie 都无法运行。当然有时候是合情合理的，比如服务器需要知道你是不是已经登录过了，而有时候则就是想要跟踪你。这让我很恼火，所以我一般对这样的网站都敬而远之。

前面介绍过，一个像素大的图片或者叫网页信标（web beacon）也可以用来跟踪你。用于取得像素图片的 URL 可以包含一个标识码，表示你正在浏览什么网页，还可以包含一个标识符，表示特定的用户。这两个标志就足以跟踪你的浏览活动了。

互联网视频网站普遍使用的 Adobe Flash 技术能够实现动画广告，该技术也会在你的计算机中保存 Flash cookie。这种 cookie 与前面所说的 cookie 不是一回事，在文件系统中跟它们也不是保存在一个地方。Flash cookie 本来是用于缓存数据以便更流畅地播放视频，但也会被用于跟踪。Adobe 提供了禁用它们的方法，为此需要访问 adobe.com 并完成几个页面的设置。说来也怪，我发现关闭 Flash cookie 并不影响性能（对每台新电脑我都会这么做）。换句话说，这种缓存好像没什么效果。

JavaScript 也是常用的一种跟踪技术。不管是包含在 HTML 中的 JavaScript 脚本代码，还是通过 <script> 标签中 src="name.js" 属性的 URL 下载的脚本文件，浏览器都会立即执行。JavaScript 最主要用于「分析」用户浏览特定网页的行为。比如，下面这行代码会从谷歌服务器加载并运行一段 JavaScript 脚本：

<script type="text/javascript" src="http://pagead2.googlesyndication.com/pagead/show_ads.js"> </script>

JavaScript 代码可以读写 cookie，有时候还可以读写浏览器访问过哪些页面的历史记录。它还可以持续监视鼠标在屏幕上的位置，并将这些信息发回服务器，以便推断网页的哪些部分更吸引用户，哪些部分用户很少关注；还可以监视鼠标点击了哪些位置（即使这些位置不是链接等能够作出反应的区域）。现在，偷偷摸摸使用 JavaScript 的情况有越来越多的趋势。如果网页中有 JavaScript，那么发生恶意攻击的可能性也会增大。

2010 年底有一篇文章谈到 evercookie，文中列举了在客户计算机上保存跟踪信息的十几种可能的方式 [1]，有些已经超出了浏览器的控制范围。就算是这方面的专家，想把它们都清除干净也很困难。而只要有一个地方有残留，其他地方的跟踪功能就可以全部恢复。很快，有关防护措施的文章也见诸报端，但其揭示的问题确实无法否认：除了得到人们正式认可的地方之外，还有很多地方可以保存这些信息。比如，有的跟踪手段是收集某人使用的操作系统、浏览器、版本号、语言偏好、安装的软件等特征，这些都与 cookie 无关。收集到足够的特征信息后，就有可能据以区分和识别某个人。广告客户和其他机构对这种精确的身份识别自然是欣赏有加的。

[1] 参见 http://en.wikipedia.org/wiki/Evercookie。—— 译者注

并不是只有浏览器可以跟踪用户，邮件阅读器、视频播放器等等使用 HTTP 和 HTML 的软件也可以。如果你的邮件阅读器解析 HTML，那它就有可能「显示」那些 1 个像素大的图片，于是你就被别人给跟踪了。

一个为害特别大的跟踪和监视手段时不时就会浮出水面，它就是深度包检测（deep packet inspection）。前面不是说过嘛，每个 IP 数据包从你的计算机出发，通常都要经过 15~20 个网关才能到达目的地，反过来也差不多。这条路径上的每个网关都有可能检查这些数据包，看到里面的信息，甚至还能以某种方式修改它们。一般来说，这种入侵都是你的 ISP 发起的，因为在那里最容易认出你来。广告客户和政府部门尤其喜欢这种信息，因为这些信息已经超出了上网浏览的范畴，而是涉及你在互联网上的一举一动。

关于个人身份的哪些信息可以收集，可以怎么使用，不同国家有不同的规定。以美国为例，简言之，怎么都行！任何公司或机构都可以收集和传播关于你的信息，不用通知你，也不需要给你提供自愿选择的机会。而在欧盟（同样简言之），隐私是一个严肃得多的话题：在没有得到个人明确许可的情况下，任何公司都不能收集或使用个人数据。

谷歌街景（Street View）的不同遭遇，就足以表现出这种法律和文化上的差异。谷歌的街景服务在世界很多地方提供街道的全景照片。而对所有照片，谷歌都会通过算法来模糊人脸以防这个人被认出来，同样也会模糊车牌。尽管如此，它在很多国家还是引发了隐私问题。但这些国家在看待街景服务的价值和它暴露个人隐私的风险上所采取的立场却又各不相同。

## 11.3 数据库、信息与聚合

互联网和 Web 已经彻底改变了人们收集、存储和展现信息的方式。搜索引擎和数据库对每个人都具有不可估量的价值。很难想象之前没有互联网的时代我们是怎么过来的。凡事都有两面，现在这样数据在网上随意传播也有问题，尤其是那些可能会过多暴露我们的信息如果传出去，会令人相当不自在。

有些信息明显就是公开的，还有些信息收集起来就是为了供人搜索和索引的。如果我写了一个网页，希望大家都能看到，假设就是这本书的页面吧，那么我肯定愿意人们通过搜索引擎可以轻易发现它。

那怎么看待公共档案呢？法律上，某些信息属于「公共档案」（public records），任何人通过申请都可以查阅。在美国，公共档案包括可以公开的庭审记录、抵押文件、房价、地方房产税、出生和死亡记录、结婚证、政治捐助，等等。（查阅出生记录通常是为了知道「妈妈婚前的姓氏」，以便辅助确认一个人的身份。）很早以前，要知道这些信息必须不辞劳苦，亲自前往当地政府驻地查阅。因此，虽然这些档案名义上是「公开」的，但不付出点代价也不可能看到。谁要想获得这些数据，就得亲自跑一趟，或许需要出示身份证件，要想复制一份可能还得花点钱。今天，如果这些数据上了网，我坐在自己家里就可以轻轻松松查阅这些公共档案。我甚至可以开个公司，收集汇总这些信息，然后与其他信息整合起来。比如很多人都知道的 zillow.com，就整合了地图、房地产广告、有关财产和交易的公开数据，通过地图来直观地显示房价。如果你想买房或者想卖房，它对你了解市场很有用；否则，你可能会觉得它暴露了人家太多的信息。通过查询联邦选举委员会（FEC，Federal Election Commission）的选举捐款数据库（fec.gov），可以知道哪位候选人得到哪些朋友和要人的捐赠，或许可以查到他们的家庭住址等信息。在 FEC 提供信息的基础上，fundrace.huffingtonpost.com 在一张地图上给我们标出了这些人的名字、地址、职业。这种做法让人们对如何平衡公众知情权和个人隐私权有了新的认识。

什么样的信息才应该让人如此轻而易举地得到？这个问题很难回答。政治捐款应该公开，但门牌号码可能就应该稍加隐藏。包含美国社会保险号等个人身份识别信息的公共档案似乎不该放在网上，因为这就给盗用别人身份打开了方便之门。可当前的法律无法完全阻止这种信息的公布，而这种信息一旦上网，就覆水难收了。

随着在多个各不相关的来源都能查到同一类信息，这个问题就变得愈发严重了。比如，很多提供 Web 服务的公司都有自己大量的客户信息。搜索引擎会记录所有查询，也包括查询人的许多信息。最低限度也会记录查询人的 IP 地址，还有用户之前访问过网站时保存在计算机上的 cookie。

2006 年 8 月，AOL 出于好意而公开了一大批查询日志样本，供人研究。这些日志涉及三个多月以来 65 万用户的 2000 万查询，已经做了匿名处理，因此从理论上讲，不存在任何可以用于辨识个人身份的信息。尽管是善意之举，但人们也很快就发现这些日志在实践中不会像 AOL 想象的那样做到完全匿名。每个用户在查询时都会被赋予一个随机但唯一的标识符，有了这个标识符，就很容易知道同一个人都查询过什么内容。进而，确定一些人的身份也就成为可能。因为不少人都搜索过自己名字、地址、社会保险号以及其他个人信息，通过搜索相关性分析暴露出来的信息比 AOL 认为的多，也肯定比原始用户自己想到的多得多。AOL 很快从自己网站上删除了这些日志，当然为时已晚。这些数据早已被传播得满世界都是了，而且至今仍可以找到，甚至还附有帮你分析它们的一些工具。

查询日志对经营企业和改进服务有价值，但很明显其中可能包含敏感的个人信息。谷歌、雅虎、微软这些提供搜索服务的公司会把查询日志保留多长时间？这里有个矛盾：考虑个人隐私则保留的时间应该短，而考虑执法目的则保留的时间应该长。为了达到一定的匿名程度，这些公司内部该对数据进行怎样的处理？虽然他们全都声称会删除每条查询对应 IP 的部分信息（一般是最右边那一字节），但仅仅如此似乎还不够，还达不到反识别用户的目的。政府机关查询这些信息的权限有多大？打一次官司会查询多少信息？所有这些问题都没有明确的答案。AOL 公布的查询日志中有些是很吓人的，比如有人查询怎么杀死自己的配偶。因此，有限度地向司法机关开放这些数据是合理的，但问题是这个限度应该放多大，很难说清楚。

AOL 事件揭示了一个广泛存在的问题，即真正做到数据匿名化是非常困难的。删除身份识别信息可以降低识别度，单就特定的数据而言，确实无法定位到用户，因此可以说它是无害的。但现实当中信息的来源是多方面的，把多个来源的信息组合起来则很可能挖掘出更多身份特征。而且某些来源的信息甚至连提供者自己都不知道，这些信息将来也未必还能找得到。举个例子，假设搜索引擎会删除每条查询对应 IP 的最右边一个字节，但根据剩下的三个字节仍然可知它来自普林斯顿大学计算机科学系，如果再结合普林斯顿日志中我什么时候使用过该 IP 上网的记录，那就可以把具体的查询跟我挂上钩了。

有关这种再识别（re-identify）问题，下面可以给大家讲一个真实的案例。1997 年，当时在 MIT 读博士的拉坦娅·斯威尼（Latanya Sweeney）分析了马萨诸塞州 135 000 名雇员的体检记录，这些记录都做了反识别处理。数据来源是该州的保险委员会，可用于研究目的，甚至被卖给了私人公司。每条体检记录中除了大量其他信息外，都包括生日、性别和邮政编码。斯威尼发现有 6 个人的生日都是 1945 年 7 月 31 日，其中 3 个男性，而只有 1 人住在坎布里奇。把这些信息和公开的选民登记名单一对照，她便知道了这个人就是时任州长威廉·韦尔德（William Weld）。

匿名处理数据与混淆保证安全（前一章刚介绍过）多少有些类似之处，这两者都是基于没有足够信息无法解密数据的考虑。问题是，这两种情况下敌人掌握的信息，很可能比我们想象的多。而且就算眼下他们不知道，将来也有可能知道。

## 11.4 隐私失控

不久前，我在网上看到一篇文章，大概是这么写的：「有一次面试，他们问了一些我简历上没写的问题。原来他们看了我的 Facebook 主页，这太让人意外了。Facebook 上可都是我个人隐私啊，跟他们有什么关系！」这个人很傻很天真，但我想很多 Facebook 用户在这种情况下可能都会有一种被冒犯的感觉，尽管他们清楚地知道公司人力资源部和大学招生办会例行通过搜索引擎、社交网站及其他类似工具来了解申请人的更多信息。在美国，面试时问一个人的民族、宗教信仰、性取向等很多关乎个人的问题都是非法的，但这些问题通过社交网站和搜索引擎都可以不费吹灰之力就找到答案。

最重要的是要知道，跟踪我们浏览的网站只是收集我们信息的诸多方式中的一种。毋庸置疑，随着社交网站的流行，为了娱乐和与其他人联系，我们自愿放弃了很多个人隐私。

社交网站存在隐私问题是毫无疑义的，因为它们会收集注册用户的大量信息，而且是通过把这些信息卖给广告客户来赚钱。尽管出现的时间不长，但它们的用户规模增长迅猛。Facebook 成立于 2004 年，现在据说已经有了 7.5 亿用户，相当于全世界人口的十分之一还多。如此之快的增长速度，不可能有太多时间考虑隐私政策，也不可能从容不迫地开发出稳定可靠的计算机程序。于是，每个社交网站都面临着因功能不完善而泄露用户隐私、用户不清楚该如何选择自己的隐私设置（变得太快）、软件出错，以及由于系统固有问题而暴露数据等问题。

作为最大也最成功的社交网站，Facebook 的问题也最明显。Facebook 给第三方提供了 API，以方便编写 Facebook 用户可以使用的应用。但这些 API 有时候会违背公司隐私政策透露一些隐私信息。当然，并非只有 Facebook 一家如此。做地理定位服务的 Foursquare 会在手机上显示用户的位置，能够为找朋友和基于位置的游戏提供方便。在知道潜在用户位置的情况下，定向广告的效果特别好。如果你走到一家餐馆的门口，而手机上恰好是关于这家餐馆的报道，那你很可能就会推门进去体验一下。虽然让朋友知道你在哪儿没什么问题，但把自己的位置昭告天下则非明智之举。比如，有人做了一个示范性的网站叫「来抢劫我吧」（Please Rob Me），该网站根据 Foursquare 用户在 Twitter 上发表的微博可以推断出他们什么时候不在家，这就为入室行窃提供了机会。

「位置隐私」—— 保证自己位置信息保密的权利 —— 在我们日常使用的很多系统中并没有得到保障，比如信用卡支付系统、高速公路和公交车刷卡收费系统，当然还有手机网络。要想让人对你都去过哪儿一点都不知情越来越困难。手机应用经常会要求访问你在手机上存储的一切信息，包括通话记录、本地存储的信息、当前位置，等等。在我看来，这些应用想知道的已经超出了它们应该知道的。

社交网站和其他一些站点甚至会泄漏非用户的个人信息。举个例子，假如一位好心的朋友发给我一份电子请柬（e-vite），请我去参加某个聚会。就算我不答复这个邀请，也没有允许别人使用我的电子邮件地址，运营该邀请服务的公司就已经得到了我准确的电子邮件地址。如果一位朋友从他的 Gmail 或雅虎账号给我发了封邮件，那么我的邮件地址就在没得到我许可的情况下被别人知道了。如果一位朋友在一张照片中给我打上标签，然后将它发布到 Facebook 或 Flickr（或两个地方都发），那我的隐私就在没有我同意的情况下暴露了。Facebook 有图像识别功能，因而那位朋友在给我加标签时会更方便，而且这个操作默认无需经过我这个被标签人同意。所以说，社交网站很容易根据自己的用户构建一个交往群体的「社交图谱」，其中包括被这些用户牵连进来但并未同意甚至毫不知情的人。在以上几种情形下，任何人都束手无策，而且在自己的信息公开后也没有办法删除它们。

情报机关早就知道通过流量分析来了解大量内幕消息，只要知道谁跟谁有联系即可，都不用知道当事人说了什么。同样，通过人们在社交网站或明或暗的联系也可以掌握很多「情报」。比如，2009 年两名 MIT 学生声称可以根据人们在 Facebook 上朋友的性取向推断出这些人的性取向。无论能否准确推断出某个人的性取向，但至少这种推断是可行的。可以肯定的是，美国政府早已着手挖掘异议人士在 Facebook 网页上的信息，借以了解还有谁跟他们「同流合污」。

## 11.5 云计算

大家先回忆一下第 6 章介绍的计算模型。相信你至少有一台电脑，也许更多。在电脑上，不同的任务需要使用不同的软件来完成，比如用 Word 来创建文档、用 Quicken 或电子表格软件记账、用 iPhoto 或 Picasa 管理照片。虽然这些软件在你电脑上运行，但它们有可能会上网使用某些服务。你可能经常要下载这些软件的一些补丁以修复 bug，偶尔还会为了得到某些新功能而购买它们的升级版。

这种计算模型的本质是程序及其数据都保存在你的计算机中。如果你在公司或在路上，突然需要一个保存在你家里计算机中的文件，那对不起，没办法。如果你想在 PC 和 Mac 上都使用 Excel 或 PowerPoint，那就得一台机器买一个。如果你在一台计算机上修改了文件，然后想在另一台计算机上使用该文件，那得自己想法办拷过去。

与此同时，另外一种计算模型越来越普及，那就是使用浏览器来访问和操作在互联网服务器上保存的信息。Gmail 和雅虎等邮件服务是比较常见的例子。任何计算机，甚至很多手机都可以收发邮件。当然，把在本地写的邮件上传到服务器，或把邮件下载保存到本地文件系统都没问题，但这不是必须的。更多的时候，只要把邮件保存在服务器上就行了。不用考虑升级软件，但新功能照样不期而至。而且这些服务几乎全都是免费的，唯一的「成本」就是在你看邮件的时候瞄两眼广告。当然，你也可以像我一样，对广告视而不见。（偶尔我也会看一看广告，但通常都会觉得莫名其妙。比如，我收到朋友的邮件，感谢我阅读了一份手稿，同时显示的广告则是关于心理咨询的，很明显是因为邮件里包含「阅读」两个字。）

这种模型通常被称为云计算，也就是把互联网比喻成了不会固定在某个地理位置的「云」，而信息都保存在「云端」。邮件是最常见的云服务，但其他类型的也非常多。比如，Flickr、Dropbox、在线日历和社交网站。数据不保存在本地，而是保存在云上。换句话说，就是保存在服务提供商的服务器上，比如 Gmail 邮件保存在谷歌服务器上，照片保存在 Flickr 服务器上。云计算模型下的软件通常是由本地部分（在客户端运行）加云端部分（在服务器端运行）构成，但都是从云下载到浏览器的。

云计算成为现实有赖于多方面条件的成熟。个人计算机能力越来越强，浏览器也一样日新月异。现在的浏览器已经可以高效地运行涉及大量显示处理的大型程序，而编程语言使用的仍然是解释型的 JavaScript。与 10 年前相比，服务器到客户端的带宽和延迟有了明显改善。这就为快速地发送和取回数据提供了保障，就算是响应一次次的键盘敲击都不成问题。于是，原先必须依靠独立的软件才能处理好的大部分用户交互功能，现在通过浏览器就可以搞定，而且可以把大量数据保存在服务器上。

以浏览器为运行环境的应用，其响应速度几乎与桌面应用一般无二，但却可以访问保存在任何地方的数据。举一个最有代表性的例子吧。Google Docs 就是一个云办公系统，包括文字处理、电子表格和 PPT 程序。至少粗略来看，它已经完全可以代替 Microsoft Office，而且支持随处访问和多用户同步更新等功能。这里面最有意思的问题是，云办公系统最终能否抢滩桌面版。不用说，微软最关心这个问题，因为其 Office 产品收入在总收入中占有相当份额。而且，Office 主要在 Windows 上运行，而 Windows 又是微软另一个主要收入来源。浏览器版的文字处理和电子表格应用不依赖微软的任何产品，因而直接威胁这两块核心利益。目前，Google Docs 及类似的系统还不具备 Word 和 Excel 的全部功能。然而，纵观技术发展史，明显不如前一代产品完善的新产品，从更完善的老产品那抢夺用户，逐渐将其挤出市场，这样的事例俯拾皆是。（克莱顿·克里斯坦森的《创新者的窘境》一书对此有深刻的分析。）微软显然对这些程序的云端版非常在意，而且事实上也提供了 Office 的在线版。

云计算依赖客户端的快速处理和大量内存，以及服务器端的高带宽。客户端代码用 JavaScript 编写，通常会非常复杂。JavaScript 代码无疑会要求浏览器快速刷新图形显示，并对用户的操作（如拖放）和服务器端操作（如更新内容）迅速作出响应。要做到这一点很困难，而浏览器与 JavaScript 版本的不兼容则雪上加霜。为此，开发人员必须知道如何有效地把正确的代码传送给客户端。不过，这两方面的问题都会得到解决，因为计算机越来越快，而标准也越来越得人心。

云计算可以转移计算的负载，转移处理过程中数据存储的位置。比如，为了让 JavaScript 代码适应更多的浏览器，可以在代码中使用条件判断，类似于「如果当前浏览器是 Internet Explorer 8，则执行如下代码；如果是 Safari 5，则执行如下代码；否则，执行如下代码」。这种代码经常一写就是一堆，而代码一多，就要占用更多服务器到浏览器的带宽。同时，一次次的检测也会导致浏览器运行变慢。换一种思路，可以把负载转移到服务器。让服务器询问客户端正使用什么浏览器，然后只将适合该浏览器的代码发过来。这样可以保证代码尽可能少，运行尽可能快（当然，程序规模不大时，差别可能不明显）。

网页内容可以不压缩，这样前后端处理速度都很快，但占用带宽多。如果压缩，占用的带宽少，但会影响前后端的处理速度。有时候，只在一端压缩也可以。比如对大型 JavaScript 程序，开发人员经常会去除所有不必要的空格，使用两个字母来代替变量和函数名，以此来压缩代码。虽然压缩后人很难看懂，但丝毫不影响浏览器执行。

尽管技术实现上有一些挑战，但云计算好处多多，你若经常上网定能有所体会。软件任何时候都是最新版本，信息保存在由专业人员管理的服务器上，而且容量不成问题。客户端数据可以实时备份，丢失信息的几率大大降低。任何文档可以只有一份，而不是在多个电脑里保存许多不一致的版本。共享文档很容易，即使基于同一份文档展开协作也易如反掌。云计算的价格呢，又十分低廉。

另一方面，云计算也带来了难以保护隐私和安全的问题。谁掌控着保存在云端的数据？谁可以读取它，什么情况下可以读取它？如果信息被意外泄露是否需要承担责任？谁有权强制公开数据？比如，在什么情况下，你的邮件服务商可以自愿或在法律诉讼的胁迫下向政府机关公开你的通信记录，或者在打官司时这么做？如果真发生了这种事，你会知道吗？这个问题的答案与你碰上了哪个国家的政府，以及你住在哪里有什么关系？如果你住在欧盟国家，那里关于个人数据隐私的规定相对严苛，而你的云数据保存在美国的服务器上，受《爱国者法案》（Patriot Act）管制，那该怎么办？

这些问题可不是凭空臆想出来的。身为大学教授，我自然有权读取通过邮件发过来的和保存在大学计算机中的学生信息，当然包括成绩，偶尔还有个人和家庭的敏感信息。我使用 Gmail 来收发邮件，使用 Google Docs 来保存和处理学生的成绩和信件是否合法？如果由于我个人方面的原因，导致这些信息可以被全世界看到，那会有什么后果？如果 Google 收到执法部门的传票，要求查询某个或一批学生的信息，那又该如何？我不是律师，也不知道答案。可是我担心这些事发生，所以我不使用云服务来保存学生档案和通信记录。如果我把这些信息都保存在单位配给我的计算机里，那至少由于单位管理疏忽或有错导致某些隐私泄露，我可以不承担责任。当然，如果是我自己把事情搞砸，那么无论数据保存在哪里，我都难逃其咎。

谁可以看你的邮件，有什么前提条件？这个问题部分涉及技术，部分涉及法律，而对法律方面的回答取决于你居住在哪个司法管辖区。在美国，我的理解是，如果你是一名公司员工，你的老板可以随便看你公司账号下的邮件，不用跟你打招呼，这不犯法。无论你的邮件是否与公司业务有关，老板都有这个权力。从理论上讲，你的邮件账号是老板为方便你开展工作才给你开立的，因此他有权确保这个便利工具被用于开展业务，而且不违反公司规定和法律条款。

我的邮件通常没什么好看的，但如果校领导没有特殊原因随便就看，那即使他们有这个权力我也会非常不舒服。如果你是学生，你应该知道很多大学都把学生邮件当成个人隐私，跟普通的信件一样。根据我的经验，学生除了转发之外都不太常用他们的校园邮箱，他们把所有邮件都转到 Gmail，但这样就失去了本来会有的保护。

如果你像大多数人一样通过 ISP 或云服务来托管自己的邮件（比如使用 Gmail、雅虎、Hotmail、Verizon、AOL 和其他很多小一些的邮件服务），那隐私就只涉及你和它们。一般来说，这些服务商都公开宣称用户的邮件属于隐私。因此，除非接到传票，他们一般不会查看或泄露你的邮件。可他们也不会说明是否会拒绝那些拉大旗做虎皮，随随便便就以「国家安全」名义发来的传票。这些完全取决于服务商自己抗拒强权的意愿。反正美国政府已经多次试探舆论，想要更方便地查询邮件。9·11 之前的名义是打击有组织犯罪，之后则是反恐。来自政府的这种监控压力势必还会加大。

「云计算」这个术语也被用来称呼亚马逊等公司提供的服务。这类服务的基础是虚拟机，而任何人都可以使用亚马逊的计算机、存储系统和带宽。亚马逊的 EC2 或 Elastic Compute Cloud（弹性计算云），可以随着用户负载变化相应地增加或减少容量，而收费则是按实际使用量计价。亚马逊拥有的资源足以让任何个人用户瞬间扩展或收缩计算资源。

假设我想使用 EC2 开发一个服务，就叫「Space in the Cloud」吧。这个服务可以让我的用户把自己的任何信息上传到云端，并自动同步到他的所有设备上。我会给用户的数据加密，以确保不会被外人偷看到。为此，我为这个云服务写了一个程序，把它上传到亚马逊服务器，然后发布。现在，谁对用户隐私负有保密义务和责任呢？如果有人利用亚马逊服务中的一个 bug 偷走了用户文件，或我的付费用户的信用卡信息，或他们的纳税申报表，谁来负责？如果我的创业计划失败，那么谁能继续访问我已经收集的数据？如果政府找我配合调查可疑用户的行踪，我该怎么办？因为我有加密密钥，我的服务是提供加密保护的。

抛开隐私和安全问题，亚马逊或者其他提供商还应该负有什么责任？比如，2011 年 4 月亚马逊的部分服务宕机一天多时间，导致一些主流站点无法访问。如果因为一个配置错误导致这些站点的访问受阻，难以接受，那这些站点应该向谁索赔？标准的做法是将这些内容写到服务协议中，但协议不能保证好的服务，它只能在事情发展到严重地步时为打官司提供一个依据。

维基解密（Wikileaks）这个站点曾公开过美国秘密外交电报，导致政府无地自容。2010 年年底，亚马逊终止向维基解密提供服务，称对方违反服务条款，公布了自己不拥有或没有权力公布的内容，而且这样做也可能导致其他人受到伤害。亚马逊在政府并未提出要求的情况下自行采取了这一措施，但似乎这一举措源自政府暗中的压力。与此同时，一些财务金融机构，包括 PayPal、万事达卡、维萨卡和美国银行，都停止为维基解密提供付款服务，维基解密的一个域名解析服务提供商也停止了对它的服务。在此期间，美国政府要求 Twitter 提供一些维基解密涉案人员的所有记录，却遭到了 Twitter 抵制，Twitter 也没有答应替政府保密的请求。但任何时候都不能寄希望于任何组织的反抗。当然啦，世界上有「善意的」异议人士（如突尼斯和埃及），也有「恶意的」异议人士（如维基解密）。至少从哲学立场一致的角度来说，支持谁或打击谁并不容易抉择。

服务提供商对其客户有什么义务？什么时候应该拍案而起、据理力争，什么时候可能会向法律威胁或来自「权威人士」的声音低头？诸如此类的问题还可以提出一箩筐，但极少能给出清晰明确的回答。

本书由「行行」整理，如果你不知道读什么书或者想获得更多免费电子书请加小编微信或 QQ：491256034 小编也和结交一些喜欢读书的朋友 或者关注小编个人微信公众号 id：d716-716 为了方便书友朋友找书和看书，小编自己做了一个电子书下载网站，网址：www.ireadweek.com QQ 群：550338315

## 11.6 小结

「举手之劳，无不可及」（Reach out and touch someone）曾是 1980 年代 AT&T 效果很好的一句广告语。今天，Web、电子邮件、社交网站、云计算，以及各种端到端的系统都可以实现这个愿景。有时候，这幅图景很美好。你可以在比以前大得多的圈子里交朋友，分享自己的兴趣爱好。然而，举手之劳也可以让你在世界面前暴露无遗，此时可不是人人都会只念你的好。垃圾邮件、欺诈、间谍软件、病毒、监视、冒名顶替、泄漏隐私信息，甚至遗失财产，种种不幸都会接踵而来。小心谨慎才是明智之举。


