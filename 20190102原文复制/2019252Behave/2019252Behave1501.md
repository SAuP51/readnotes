# 
> 2018000模板



Fifteen


			Metaphors We Kill By



EXAMPLE 1


			Stretching back at least to that faux pas about the golden calf at Mt. Sinai, various branches of Abrahamic religions have had a thing about graven images. Which has given us aniconism, the banning of icons, and iconoclasts, who destroy offensive images on religious grounds. Orthodox Judaism has been into that at times; ditto for Calvinists, especially when it came to those idolatrous Catholics. Currently it’s branches of Sunni Islam that deploy literal graven-image police and consider the height of offense to be images of Allah and Muhammad.

			In September 2005 the Danish newspaper Jyllands-Posten published cartoon images of Muhammad on its editorial page. It was a protest against Danish censorship and self-censorship about the subject, against Islam being a sacred cow in a Western democracy where other religions are readily criticized satirically. None of the cartoons suggested reverence or respect. Many explicitly linked Muhammad with terrorism (e.g., him wearing a bomb as a turban). Many were ironic about the ban—Muhammad as a stick figure with a turban, Muhammad (armed with a sword) with a blackened rectangle over his eyes, Muhammad in a police lineup alongside other bearded men with turbans.

			And as a direct result of the cartoons, Western embassies and consulates were attacked, even burned, in Lebanon, Syria, Iraq, and Libya. Churches were burned in northern Nigeria. Protesters were killed in Afghanistan, Egypt, Gaza, Iran, Iraq, Lebanon, Libya, Nigeria, Pakistan, Somalia, and Turkey (typically either by mob stampedes or by police containing rioters). And non-Muslims were killed in Nigeria, Italy, Turkey, and Egypt as revenge for the cartoons.

			In July 2007 drawings by a Swedish artist of Muhammad’s head with a dog’s body provoked much the same. In addition to deadly protests, the Islamic State of Iraq offered $100,000 for the artist’s killing, Al-Qaeda targeted the artist for death (along with staffers from Jyllands-Posten), assassination plots were stopped by Western authorities, and one attempt killed two bystanders.

			In May 2015 two gunmen attacked an antianiconist event in Texas where a $10,000 prize was offered for the “best” depiction of Muhammad. One person was injured before the gunmen were killed by police.

			And, of course, on January 7, 2015, two brothers, French-born sons of Algerian immigrants, massacred the staff of Charlie Hebdo, killing twelve.





EXAMPLE 2


			In the Battle of Gettysburg fierce fighting occurred between the Union First Minnesota Volunteer Infantry and Confederate Twenty-eighth Virginia Volunteer Infantry Regiment.1 At one point Confederate soldier John Eakin, carrying the regimental flag of the Twenty-eighth Virginia, was shot three times (a typical fate of soldiers carrying the colors, who were preferential targets). Mortally wounded, Eakin handed the flag to a comrade, who was promptly killed. The flag was then taken up and displayed by Colonel Robert Allen, who was soon killed, then by Lieutenant John Lee, who was soon injured. A Union soldier, attempting to seize the colors, was killed by Confederates. Finally Private Marshall Sherman of the First Minnesota captured the flag, along with Lee.





EXAMPLES 3, 4, AND 5


			In mid-2015 Tavin Price, a mentally challenged nineteen-year-old, was killed by gangbangers in Los Angeles for wearing red shoes, a rival gang’s color. His dying words, in front of his mother, were “Mommy, please. I don’t want to die. Mommy, please.”2

			In October 1980 Irish Republican prisoners at the Maze Prison in Northern Ireland began a hunger strike protesting, among other things, their being denied political-prisoner status by having to wear prison garb. The British government acceded to their demands as a first prisoner slipped into a coma fifty-three days later. In a similar strike a year later in the Maze, ten Irish political prisoners starved themselves to death over forty-six to seventy-three days.

			By 2010 karaoke clubs throughout the Philippines had removed the Frank Sinatra song “My Way” from their playlists because of violent responses to the singing of it, including a dozen killings. Some of the “‘My Way’ killings” were due to poor renditions (which apparently often results in killings), but most were thought linked to the macho lyrics. “‘I did it my way’—it’s so arrogant. The lyrics evoke feelings of pride and arrogance in the singer, as if you’re somebody when you’re really nobody. It covers up your failures. That’s why it leads to fights,” explained the owner of a singing school in Manila to the New York Times.

			—

			In other words, people are willing to kill or be killed over a cartoon, a flag, a piece of clothing, a song. We have some explaining to do.

			—

			Throughout this book we’ve repeatedly gained insights into humans by examining other species. Some of the time the similarities have been most pertinent—dopamine is dopamine in a human or a mouse. Sometimes the interesting thing is our unique use of the identical substrate—dopamine facilitates a mouse’s pressing of a lever in the hopes of getting some food and a human’s praying in the hopes of entering heaven.

			But some human behaviors stand alone, without precedent in another species. One of the most important realms of human uniqueness comes down to one simple fact, namely that this is not a horse:



			Anatomically modern humans emerged around 200,000 years ago. But behavioral modernity had to wait more than another 150,000 years, as evidenced by the appearance in the archaeological record of composite tools, ornamentation, ritualistic burial, and that stunning act of putting pigment on the wall of a cave.*3 This is not a horse. It’s a great picture of a horse.

			When René Magritte placed the words “Ceci n’est pas une pipe” (“This is not a pipe”) beneath a picture of a pipe, in his 1928 painting The Treachery of Images, he was highlighting the shaky nature of imagery. The art historian Robert Hughes writes that this painting is a “visual booby-trap” set off by thought, and that “this sense of slippage between image and object is one of the sources of modernist disquiet.”4



			Magritte’s goal was to magnify and play with the distance between an object and its representation; these are coping mechanisms against that modernist disquiet. But for that human putting pigment to wall in Lascaux Cave more than seventeen thousand years ago, the point was the opposite: to minimize the distance between the two, to be as close as possible to possessing the real horse. As we say, to capture its likeness. To gain its power, as imbued in a symbol.

			The clearest human mastery of symbolism comes with our use of language. Suppose you are being menaced by something and thus scream your head off. Someone listening can’t tell if the blood-curdling “Aiiiii!” is in response to an approaching comet, suicide bomber, or Komodo dragon. It just means that things are majorly not right; the message is the meaning. Most animal communication is about such present-tense emotionality.

			Symbolic language brought huge evolutionary advantages. This can be seen even in the starts of symbolism of other species. When vervet monkeys, for instance, spot a predator, they don’t generically scream. They use distinct vocalizations, different “protowords,” where one means “Predator on the ground, run up the tree!” and another means “Predator in the air, run down the tree!” Evolving the cognitive capacity to make that distinction is mighty useful, as it prompts you to run away from, rather than toward, something intent on eating you.

			Language pries apart a message from its meaning, and as our ancestors improved at this separation, advantages accrued.5 We became capable of representing past and future emotions, as well as messages unrelated to emotion. We evolved great expertise at separating message from reality, which, as we’ve seen, requires the frontal cortex to regulate the nuances of face, body, and voice: lying. This capacity creates complexities that no one else—from slime mold to chimp—deals with in life’s Prisoner’s Dilemmas.

			The height of the symbolic features of language is our use of metaphor. And this is not just flourish metaphors, when we declare that life is a bowl of cherries. Metaphors are everywhere in language—we may literally and physically be “in” a room, but we are only metaphorically inside something when we are “in” a good mood, “in” cahoots with someone, “in” luck, a funk, a groove,* or love. We are only metaphorically standing under something when we “understand” it.*6 The renowned cognitive linguist George Lakoff of UC Berkeley has explored the ubiquity of metaphor in language in books such as Metaphors We Live By (with philosopher Mark Johnson), and Moral Politics: How Liberals and Conservatives Think (where he demonstrates how political power involves controlling metaphors—do you favor “choice” or “life”? are you “tough on” crime, or does your “heart bleed”? are you loyal to a “fatherland” or a “motherland”? and have you captured the flag of “family values” from your opponent?). For Lakoff language is always a metaphor, transferring information from one individual to another by putting thought into words, as if words were shopping bags.7

			Symbols, metaphors, analogies, parables, synecdoche, figures of speech. We understand that a captain wants more than just hands when ordering all of them on deck, that Kafka’s Metamorphosis isn’t really about a cockroach, and that June doesn’t really bust out all over. If we are of a certain theological ilk, we see bread and wine intertwined with body and blood. We learn that the orchestral sounds constituting the 1812 Overture represent Napoleon getting his ass kicked when retreating from Moscow. And that “Napoleon getting his ass kicked” represents thousands of soldiers dying cold and hungry, far from home.

			This chapter explores the neurobiology of some of the most interesting outposts of symbolic and metaphorical thinking. It makes a key point: these capacities evolved so recently that our brains are, if you will, winging it and improvising on the fly when dealing with metaphor. As a result, we are actually pretty lousy at distinguishing between the metaphorical and literal, at remembering that “it’s only a figure of speech”—with enormous consequences for our best and worst behaviors.

			We start with examples of odd ways our brains handle metaphor, and the behavioral manifestations of those oddities; some have been introduced previously.





FEELING SOMEONE ELSE’S PAIN


			Consider the following: You stub your toe. Pain receptors there send messages to the spine and on up to the brain, where various regions kick into action. Some of these areas tell you about the location, intensity, and quality of the pain. Is it your left toe or right ear that hurts? Was your toe stubbed or crushed by a tractor-trailer? These various pain-ometers, the meat and potatoes of pain processing, are found in every mammal.

			As we first learned in chapter 2, the frontal cortical anterior cingulate cortex (ACC) also plays a role, assessing the meaning of the pain.8 Maybe it’s bad news: your painful toe signals the start of some unlikely disease. Or maybe it’s good news: you’re going to get your fire-walker diploma because the hot coals only made your toes throb. As we saw in the last chapter, the ACC is heavily involved in “error detection,” noting discrepancies between what is anticipated and what occurs. And pain from out of nowhere surely represents a discrepancy between the pain-free setting that you anticipate versus a painful reality.

			But the ACC does more than just tell you the meaning of a painful toe. As we saw in chapter 6, put a subject in a brain scanner, make them think they’re tossing a Cyberball back and forth with two other players, and then make them feel excluded—the other two stop throwing the ball to them. “Hey, how come they don’t want to play with me?” And the ACC activates.

			In other words, rejection hurts. “Well, yeah,” you might say. “But that’s not like stubbing your toe.” But as far as those neurons in the ACC are concerned, social and literal pain are the same. And as proof of the rooting of the former in sociality, there isn’t ACC activation if the subject believes the ball isn’t being thrown to them because of a glitch connecting them to the other two subjects’ computers.

			And the ACC can take things a step further, as we saw in chapter 14. Receive a mild shock, and there’s activation of your ACC (along with activation of the more mundane pain-ometer regions). Now instead watch your beloved get shocked in the same way. Pain-ometer brain regions are silent, but the ACC activates. For those neurons, feeling someone else’s pain isn’t just a figure of speech.

			Moreover, the brain intermixes literal and psychic pain.9 The neurotransmitter substance P plays a central role in communicating painful signals from pain receptors in skin, muscles, and joints up into the brain. It’s got pain-ometer written all over it. And remarkably, its levels are elevated in clinical depression, and drugs that block the actions of substance P can have marked antidepressant properties. Stubbed toe, stubbed psyche. Moreover, there is activation of the cortical parts of pain networks when we feel dread—anticipating an impending shock.

			Furthermore, the brain becomes literal when we do the flip side of empathy.10 It’s painful watching a hated competitor succeed, and we activate the ACC at that time. Conversely, if he fails, we gloat, feel schadenfreude, get pleasure from his pain, and activate dopaminergic reward pathways. Forget “Your pain is my pain.” Your pain is my gain.





DISGUST AND PURITY


			This is our familiar domain of the insular cortex. If you bite into rancid food, the insula activates, just as in every other mammal. You wrinkle your nose, raise your upper lip, narrow your eyes, all to protect mouth, eyes, and nasal cavities. Your heart slows. You reflexively spit out the food, gag, perhaps even vomit. All to protect yourself from toxins and infectious pathogens.11

			As humans we do some fancier things: Think about rancid food, and the insula activates. Look at faces showing disgust, or subjectively unattractive faces, and the same occurs. And most important, if you think about a truly reprehensible act, the same occurs. The insula mediates visceral responses to norm violations, and the more activation, the more condemnation. And this is visceral, not just metaphorically visceral—for example, when I heard about the Sandy Hook Elementary School massacre, “feeling sick to my stomach” wasn’t a mere figure of speech. When I imagined the reality of the murder of twenty first-graders and the six adults protecting them, I felt nauseous. The insula not only prompts the stomach to purge itself of toxic food; it prompts the stomach to purge the reality of a nightmarish event. The distance between the symbolic message and the meaning disappears.12

			The linking of visceral and moral disgust is bidirectional. As shown in a number of studies, contemplating a morally disgusting act leaves more than a metaphorical bad taste in your mouth—people eat less immediately afterward, and a neutral-tasting beverage drunk afterward is rated as having a more negative taste (and, conversely, hearing about virtuous moral acts made the drink taste better).13

			In chapters 12 and 13 we saw the political implications of our brains intermixing visceral and moral disgust—social conservatives have a lower threshold for visceral disgust than do social progressives; the “wisdom of repugnance” school posits that being viscerally disgusted by something is a pretty good indicator that it is morally wrong; implicitly evoking a sense of visceral disgust (e.g., by sitting in close proximity to a foul odor) makes us more socially conservative.14 This is not merely because visceral disgust is an aversive state—inducing a sense of sadness, rather than disgust, doesn’t have the same effect; moreover, moralizing about purity, while predicted by people’s propensity toward feeling disgust, is not predicted by propensities toward fear or anger.*

			The physiological core of gustatory disgust is to protect yourself against pathogens. The core of the intermixing of visceral and moral disgust is a sense of threat as well. A socially conservative stance about, say, gay marriage is not just that it is simply wrong in an abstract sense, or even “disgusting,” but that it constitutes a threat—to the sanctity of marriage and family values. This element of threat is shown in a great study in which subjects either did or didn’t read an article about the health risks of airborne bacteria.15 All then read a history article that used imagery of America as a living organism, with statements like “Following the Civil War, the United States underwent a growth spurt.” Those who read about scary bacteria before thinking about the United States as an organism were then more likely to express negative views about immigration (without changing attitudes about an economic issue). My guess is that people with a stereotypically conservative exclusionary stance about immigration rarely have the sense that they feel disgusted that people elsewhere in the world would want to come to the United States for better lives. Instead there is threat by the rabble, the unwashed masses, to the nebulous entity that is the American way of life.

			How cerebral is this intertwining of moral and visceral disgust? Does the insula get involved in moral disgust only if it’s of a particularly visceral nature—blood and guts, coprophagia, body parts? Paul Bloom suggests this is the case. In contrast, Jonathan Haidt feels that even the most cognitive forms of moral disgust (“He’s a chess grand master and he shows off by beating that eight-year-old in three moves and reducing her to tears—that’s disgusting”) are heavily intertwined.16 In support of that, something as unvisceral as getting a lousy offer in an economic game activates the insula (a lousy offer from another human, rather than a computer, that is); the more insula activation, the greater the likelihood of the offer being rejected. Amid this debate, it is clear that the intertwining of visceral and moral disgust is, at the least, greatest when the latter taps into core disgust. To repeat a neat quote from Paul Rozin, introduced in chapter 11, “Disgust serves as an ethnic or out-group marker.” First you’re disgusted by how Others smell, a gateway to then being disgusted by how Others think.

			Of course, insofar as metaphorically being dirty and disorderly = bad, metaphorically being clean and orderly = good.*17 Just consider the use of the word “neat” in the previous paragraph. Similarly, in Swahili the word safi, meaning “clean” (from kusafisha, “to clean”), is used in the same slangy metaphorical sense of “neat” in English. Once while in Kenya, I was hitching a ride to Nairobi from somewhere out in the boondocks and got to chatting with a local teenager who was curious about me. “Where are you going?” he asked. Nairobi. “Nairobi ni [is] safi,” he said wistfully about the far-off metropolis. How are you going to keep them down on the farm once they’ve seen the neatness of Nairobi?

			Literal cleanliness and orderliness can release us from abstract cognitive and affective distress—just consider how, during moments where life seems to be spiraling out of control, it can be calming to organize your clothes, clean the living room, get the car washed.18 And consider how the displaced need to impose cleanliness and order runs and ruins the lives of people suffering from the archetypal anxiety disorder, obsessive-compulsive disorder. The ability of literal cleanliness to alter cognition was shown in one study. Subjects examined an array of music CDs, picked ten that they liked, and ranked them in order of liking; they were then offered a free copy of one of their midrange choices (number five or six). Subjects were then distracted with some other task and then asked to rerank the ten CDs. And they showed a common psychological phenomenon, which was to now overvalue the CD they’d been given, ranking it higher on the list than before. Unless they had just washed their hands (ostensibly to try a new brand of soap), in which case no reranking occurred. Clean hands, clean slate.

			But beginning much further back than the “social hygiene” movement of the turn of the twentieth century, being metaphorically neat, pure, and hygienic could be a moral state as well—cleanliness was not just a good way to avoid uncontrolled diarrhea, dehydration, and serious electrolyte imbalance, but was also ideal for cozying up to a god.

			One study was built around the phenomenon of visceral disgust making people harsher in their moral judgments. The authors first replicated this effect, showing that watching a short film clip of something physically disgusting made subjects more morally judgmental—unless they had washed their hands after watching the film. Another study suggests that the washing decreases emotional arousal, as it decreased the diameter of subjects’ pupils.19

			We intertwine physical and moral purity when it comes to our own actions. In one of my all-time favorite psychology studies, Chen-Bo Zhong of the University of Toronto and Katie Liljenquist of Northwestern University demonstrated that the brain has trouble distinguishing between being a dirty scoundrel and being in need of a bath. Subjects were asked to recount either a moral or an immoral act in their past. Afterward, as a token of appreciation, the researchers offered the volunteers a choice between the gift of a pencil and a package of antiseptic wipes. And the folks who had just wallowed in their ethical failures were more likely to go for the wipes. Another study, showing the same effect when people were instructed to lie, demonstrated that the more adversely consequential the lie was presented as being, the more washing subjects did. Lady Macbeth and Pontius Pilate weren’t the only ones to at least try to absolve their sins by washing their hands, and this phenomenon of embodied cognition is referred to as the “Macbeth effect.”20

			This effect is remarkably concrete. In another study subjects were instructed to lie about something—with either their mouths (i.e., to tell a lie) or their hands (i.e., to write down a lie).21 Afterward, remarkably, liars were more likely to pick complementary cleansing products than control subjects who communicated something truthful: the immoral mouth-ers were more likely to pick a mouthwash sample; the immoral scribes, hand soap. Furthermore, as shown with neuroimaging, when contemplating mouthwash versus soap, those who had just spoken a lie activated parts of the sensorimotor cortex related to the mouth (i.e., the subjects were more aware of their mouths at the time); those who had written the lie activated the cortical regions mapping onto their hand. Embodied cognition can be specific to parts of the body.

			Another fascinating study showed the influence of culture in the Macbeth effect. The studies just cited were carried out with European or American subjects. When the same is done with East Asian subjects, the urge afterward is to wash the face, rather than the hands. If you are going to save face, it should be a clean one.22

			Finally, most important, this intermixing of moral and physical hygiene affects the way we actually behave. That original study on contemplating one’s moral failings and the subsequent desire to wash hands included a second experiment. As before, subjects were told to recall an immoral act of theirs. Afterward subjects either did or didn’t have the opportunity to clean their hands. Those who were able to wash were less likely to respond to a subsequent (experimentally staged) request for help. In another study merely watching someone else wash their hands in this situation (versus watching them type) also decreased helpfulness afterward (although to a lesser extent than the subject washing).23

			Many of our moments of prosociality, of altruism and Good Samaritanism, are acts of restitution, attempts to counter our antisocial moments. What these studies show is that if those metaphorically dirtied hands have been unmetaphorically washed in the interim, they’re less likely to reach out to try to balance the scales.





REAL VERSUS METAPHORICAL SENSATION


			Then there are ways in which we confuse literal with metaphorical sensation.

			A brilliant study by John Bargh of Yale concerned haptic sensations (I had to look the word up—haptic: related to the sense of touch). Volunteers evaluated the résumés of supposed job applicants; crucially, the résumé was attached to a clipboard of one of two weights. When subjects held the heavier clipboard, they tended to judge candidates as more “serious” (while clipboard weight had no effect on other perceived traits). When you next apply for a job, hope that your résumé will be attached to a heavy clipboard. How else would the evaluator figure out that you can appreciate the gravity of a situation and deal with weighty matters, rather than being a lightweight?24

			In the next study subjects assembled a puzzle with pieces that were either smooth or rough as sandpaper, then observed a socially ambiguous interaction. Handle the rough puzzle pieces and the interactions were rated as less coordinated, smooth, or successful (it’s not clear, however, if those subjects were more likely, at home that evening, to use coarse language in describing their rough day).

			Next, subjects sat in either a hard or a soft chair (to quote the authors, “We primed subjects by the seat of their pants”). Sit in the former and they were more likely to perceive individuals as stable and unemotional, to be less flexible in economic game play. This is remarkable—haptic sensations in your butt influencing whether you think someone is a hard-ass. Or hard-hearted instead of a softie.

			Similar intermixing of the real and the metaphorical occurs with temperature sensation. In another study from Bargh’s group, the researcher, hands full with something, would ask a subject to briefly hold a cup of coffee for them. Half the subjects held warm coffee, half iced coffee. Subjects then read about some individual and answered questions about them. Subjects who held the warm cup rated the individual as having a warmer personality (without altering ratings about other characteristics). In the next part of the study, the temperature of a held object altered subjects’ generosity and levels of trust—cold hands, cold heart. And a more activated insula, as shown in a follow-up study.25

			Our brains also confuse metaphorical and literal interoceptive information. Recall that remarkable study showing that in a real-world situation, a major predictor of whether a prisoner would be granted parole was how recently the judge had eaten. Empty stomach, harsher judgment. Other work has shown that when people are hungry, they become less generous with money and show more future discounting (i.e., are more likely to want reward X now, rather than wait for reward 2X). Hungering for fame and fortune are just metaphors—yet our brain pulls circuits related to real hunger into the mix. Moreover, we use more abstract levels of cognition when thinking about distant events. Ask people to make a list of the items they’d bring on a camping trip taking place either tomorrow or in a month; if the former, the list contains more specific subcategories. In another study subjects were shown a graph of the average amount of paper used by an office over time. There is a steady increase until the most recent time period:26



			Subjects were then asked to predict what would happen in the next time period. Half the subjects were told that the office was nearby. Result: those subjects did a microanalysis, preferentially paying attention to that final X trending downward, perceiving it to be meaningful, the start of a pattern:



					Down the hall



			But subjects told that the office was on the other side of the planet tended to view the data points at a macro level of analysis, paying attention to the overall pattern and seeing that downturn as a mere aberration:





					Far away



			What’s going on in these studies? Metaphors about weight, density, texture, temperature, interoceptive sensations, time, and distance are just figures of speech. Yet the brain confusedly processes them with some of the same circuits that deal with the physical properties of objects.





DUCT TAPE


			The essence of a symbol is its ability to serve as a stand-in for the real thing and, remarkably, we’re not the only species where a signifier, independent of what it signifies, can gain a power of its own. As discussed in chapter 2, if you condition a rat to associate a bell with a reward, about half of rats eventually come to find the bell itself rewarding.

			So we’ve now examined cold drinks and cold personalities; lying through your teeth and then yearning for mouthwash; our hearts aching for someone else’s pain. Our metaphorical symbols can gain a power all their own. But insofar as metaphors are the apogee of our capacity for symbolic thought, it’s thoroughly weird that our top-of-the-line brains can’t quite keep things straight and remember that those metaphors aren’t literal. Why?

			The answer harks back to a concept first introduced in chapter 10—evolution is a tinkerer, an improviser. So humans are evolving capacities for abstractions like morality and deep violations of it, for experiencing empathy of unprecedented intensity, and for conscious assessment of the affiliative nature of someone’s temperament—moral disgust, feeling someone’s pain, warm and cold personalities. Given how short a time behaviorally modern humans have existed, this has occurred in a blink of an eye. There hasn’t been enough time to evolve completely new brain regions and circuits for handling these novelties. Instead, tinkering occurred—“Hmm, extreme negative affect elicited by violations of shared behavioral norms. Let’s see . . . Who has any pertinent experience? I know, the insula! It does extreme negative sensory stimuli—that’s, like, all that it does—so let’s expand its portfolio to include this moral disgust business. That’ll work. Hand me a shoehorn and some duct tape.”

			The key to evolution as an improviser rather than inventor is chapter 10’s concept of exaptation—some trait evolves for some purpose and is co-opted when it turns out to be useful for something else. And soon feathers are aiding flight, in addition to regulating body temperature, and the insula helps get us into heaven, in addition to purging our guts of toxins. The latter is a case of what has been called “neural reuse.”27

			This isn’t to say it’s been an easy process, that magically one day neurons that help make you puke are suddenly involved in running the president’s bioethics panel. It is insanely interesting to me that the most unique neurons in our brains, the recently evolved and slow-developing von Economo neurons, are predominantly housed in the anterior cingulate and insula. And that the neurodegenerative disease frontotemporal dementia, destined to eventually destroy the entire fancy neocortex, takes out von Economo neurons first—there’s something extra fancy (and thus expensive and vulnerable) about those cells. The tinkering and improvising was inspired.

			What’s most interesting is that we see the beginnings of the “I know, let’s persuade the ACC and insula to volunteer for these new jobs” in other species. As we saw in chapter 14, the emotional contagion and protoempathy that a rodent can feel for another one in pain is centered in the anterior cingulate. And full-blown von Economo neurons are also found in those same brain regions in the other apes, elephants, and cetaceans—evolution’s Mensa club—and exist in rudimentary forms in monkeys. It’s unclear if, say, a blue whale wants to wash its flippers after a social-norm violation, but a handful of other species seem to have taken the first steps into this strange new territory along with us.





THE METAPHORICAL DARK SIDE


			Our brains’ confusion of the metaphorical with the literal literally matters. Back to chapter 10 and the evolutionary emphasis on kin selection. We saw the array of mechanisms used by various species for recognizing kin and degree of relatedness—e.g., genetically shaped pheromonal signatures and imprinting on the female whose birdsong you heard a lot while you were still inside an egg. And we saw that among other primates there are cognitive components as well (recall male baboons’ degree of paternalism being predicted by their likelihood of being the father). By the time we get to humans, the process is mostly cognitive—we can think our way to deciding who is a relative, who is an Us. And thus, as we saw, we can be manipulated into thinking that some individuals are more related to us, and others less so, than they actually are—pseudokinship and pseudospeciation. There are numerous ways to get someone to think that an Other is so different that they barely count as human. But as propagandists and ideologues have long known, if you want to get someone to feel that an Other hardly counts as human, there’s only one way to do it—engage the insula. And the surest way to do that is with metaphor.

			In 1994 many Westerners became aware of the existence of the nation of Rwanda for the first time. The mountainous Central African country is tiny, with one of the highest population densities in the world. Way back when, it had been filled with hunter-gatherers who, as per usual, had been displaced over the last millennium by agriculturalists and pastoralists, who came to form the Hutu and Tutsi tribes, respectively. It remains debated whether they arrived around the same century and whether they were actually ethnically distinct groups, but the Hutu and Tutsi Us/Them-ed with a vengeance. The minority Tutsi traditionally dominated the Hutu, reflecting the common herdsman/farmer power dynamics of Africa; German and Belgian colonials, in the classic divide and conquer, exploited and inflamed the tribal animosities further.

			With independence in 1962 came a turning of tables and Hutu domination of the government. Discrimination and violence against Tutsis drove many out of the country; over the subsequent years, many Tutsi refugee populations in neighboring countries gave rise to rebel groups seeking to invade Rwanda and establish safe havens there for Tutsis. Predictably, this increased anti-Tutsi militancy among Hutus and resulted in further discrimination and massacres. One of the ironies of what was to come, reflecting the uncertainty as to whether the Hutu and Tutsi were historically even separate people, was that it wasn’t always possible to distinguish the two—identity cards were required to indicate ethnicity.

			By 1994 the Rwandan president, the dictator Juvénal Habyarimana, a Hutu military man who had seized power in 1973, was under sufficient pressure from Tutsi rebel groups that he signed a power-sharing peace accord with the rebels. This was viewed as a sellout by the growing “Hutu Power” extremist bloc. On April 6, 1994, Habyarimana’s plane was shot down by a missile as it approached the capital, Kigali, killing all on board. It is still unclear whether the assassination was carried out by Tutsi rebels or Hutu Power elements in the military who were intent on both eliminating Habyarimana and laying the blame on Tutsis. In any case, within a day Hutu militants had killed essentially all moderate Hutus in the government, seized power, officially laid blame for the assassination on Tutsis, and urged all Hutus to take revenge. And most Hutus complied. Thus began what is now known as the Rwandan genocide.*

			The killing ran for approximately one hundred days (until it was finally halted by Tutsi rebels gaining control). During that time, there was not only a Final Solution–style attempt to kill every Tutsi in Rwanda but also killing of Hutus who were married to Tutsis, who attempted to protect Tutsis, or who refused to participate in killings. By the time it was done, approximately 75 percent of Tutsis—between 800,000 and 1,000,000 people—and around 100,000 Hutu had been killed. Roughly one out of every seven Rwandans. This translated into five times the rate of killing during the Nazi Holocaust. It was mostly ignored by the West.28

			Five times the rate. For those of us schooled in the modern Western world’s atrocities, some translation is needed. The Rwandan genocide did not involve tanks, airplanes dropping bombs, or shelling of civilians. There were no concentration camps, no transport trains, no Zyklon B. There was no bureaucratic banality of evil. There were hardly even many guns. Instead Hutu—from peasant farmers to urban professionals—bludgeoned their Tutsi neighbors, friends, spouses, business partners, patients, teachers, students. Tutsis were beaten with sticks until they were dead, killed with machetes after being gang-raped and sexually mutilated, trapped in sanctuaries that were then burned to the ground. An average of roughly ten thousand people per day. As perhaps the genocide’s single most shocking atrocity, in the town of Nyange, the local Catholic priest, a Hutu named Athanase Seromba, gave sanctuary to between 1,500 and 2,000 Tutsi, many of them his parishioners, and then led the Hutu militia that ultimately killed every person inside his church. Rivers ran red, not just metaphorically.*

			How could this have happened? There are many components to the answer. The populace had a long tradition of unquestioning obedience to authority, a helpful trait to develop in a brutally dictatorial nation. Hutu militants had for months before been distributing machetes to the Hutu populace. The government-controlled radio station (the main form of mass media in this marginally literate country) proclaimed that the intent of the invading Tutsi rebels was to kill every Hutu, and that one’s Tutsi neighbors were a fifth column preparing to join in. And there was another meaningful factor. The anti-Tutsi propaganda was ceaselessly dehumanizing, with the infamous pseudospeciation of Tutsis being referred to only as “cockroaches.” Stamp out the cockroaches. The cockroaches are planning to kill your children. The cockroaches [the supposedly devious and seductive Tutsi women] will steal your husbands. The cockroaches [Tutsi men] will rape your wives and daughters. Stamp out the cockroaches, save yourselves, kill the cockroaches. And with insular cortices ablaze, machetes in one hand and transistor radios in the other, most Hutus did.*



				The aftermath





			Dehumanization, pseudospeciation. The tools of the propagandists of hate. Thems as disgusting. Thems as rodents, as a cancer, as a transitional species, Thems as reekingly malodorous, as living in hives of chaos that no normal human would. Thems as shit. Get the insulae of your followers to confuse the literal and metaphorical, and you’re 99 percent of the way there.





A GLIMMER


			A goal might be to use the good side of a double-edged sword to cut loose the silver linings of clouds and save them for rainy days. Or something metaphorically like that. The tool of the propagandist is to effectively exploit symbols of revulsion in the service of hate. But the odd literal metaphoring of our brains can also provide the peacemaker with a highly effective tool.

			In a moving, important 2007 paper in Science, the American/French anthropologist Scott Atran, along with Robert Axelrod (of chapter 10’s Prisoner’s Dilemma fame) and Richard Davis, a conflict expert at Arizona State University, considered the power of what they called “sacred values” in conflict resolution.29 These are straight out of Greene’s world of two different cultures of shepherds fighting over a commons, each with a different moral vision as to what is correct, each passionately focused on “rights” whose meaning and power are incomprehensible to the other side. Sacred values are defended far out of proportion to their material or instrumental importance or likelihood of success, because to any group such values define “who we are.” And therefore, not only are attempts to reach compromises on such issues by using material incentives unlikely to be productive, but they can be insultingly counterproductive. You can’t buy us off into dishonoring that which we hold sacred.

			Atran and colleagues have studied the roles played by sacred values in the context of Middle East conflict. In a world of sheer rationality where the brain didn’t confuse reality with symbols, bringing peace to Israel and Palestine would revolve solely around the concrete, practical, and specific—placement of borders, reparations for Palestinian land lost in 1948, water rights, the extent of militarization allowed to Palestinian police, and so on. Solving those nuts-and-bolts issues may be a way of ending war, but peace is not the mere absence of war, and making true peace requires acknowledging and respecting the sacred values of Them. Atran and colleagues found that, from the person in the street to the highest offices of power, sacred values loomed large. They interviewed senior Hamas leader Ghazi Hamad, asking what he sees as a requirement for true peace. This included, of course, reparations to Palestinians for the homes and lands they lost almost seventy years ago. Necessary but not sufficient. “Let Israel apologize for our tragedy in 1948,” he added. And current Israeli prime minister Benjamin Netanyahu, in discussing with them what was needed for true peace, cited not only instrumental issues of security but also how the Palestinians must “change their textbooks and anti-Semitic characterizations.” As the authors state, “In rational-choice models of decision-making, something as intangible as an apology [or getting the likes of the Protocols of the Elders of Zion out of schoolbooks] could not stand in the way of peace.” Yet they do, because in recognizing the enemy’s sacred symbols, you are de facto recognizing their humanity, their capacity for pride, unity, and connection to their past and, probably most of all, their capacity for experiencing pain.*



			“Symbolic concessions of no apparent material benefit may be key in helping to solve seemingly intractable conflicts,” write the authors. In 1994 the Kingdom of Jordan became the second Arab country to sign a peace treaty with Israel. It ended war, bringing to an end decades of hostilities. And it created a successful road map for the two nations to coexist, built around addressing material and instrumental issues—water rights (e.g., Israel would give Jordan fifty million cubic meters of water annually), joint efforts to combat terrorism, joint efforts to facilitate tourism between the countries. But it wasn’t until a year later that one saw evidence that something resembling a true peace was forming. It followed the creation of yet another martyr for peace, the assassination of Israeli prime minister Yitzhak Rabin, one of the architects of the Oslo Peace Accord, by a right-wing Israeli extremist. Extraordinarily, King Hussein came to Rabin’s funeral and eulogized him, addressing his widow in the front row:


My sister, Mrs. Leah Rabin, my friends, I had never thought that the moment would come like this when I would grieve the loss of a brother, a colleague and a friend.

			Hussein’s presence and words were obviously irrelevant to any of the rational stumbling blocks to peace. And were immeasurably important.30

			A similar arc can be seen in Northern Ireland, where an IRA ceasefire in 1994 facilitated an end to the violence of the Troubles and the 1998 Good Friday Agreement laid the groundwork for Republicans and Unionists to coexist, for ex-Unionist demagogues and ex-IRA gunmen to serve in a government together. Much of the agreement was material or instrumental, but there were elements of sacred values addressed—for example, the establishment of a Parades Commission to ensure that neither group had inflammatory, symbol-laden parades in the other’s neighborhoods in Belfast. But in many ways the most palpable sign of a lasting peace came from an unexpected corner. The unity government formed after the agreement was led by Peter Robinson as first minister and Martin McGuinness as deputy first minister. The former had been a Unionist firebrand, the latter a leader of the political wing of the IRA; they were two men who epitomized the hatreds of the Troubles. They had a functional working relationship but nothing more than that and had famously refused to ever actually shake hands (something that even Rabin and Yasir Arafat had managed). What finally broke the ice? In 2010 Robinson was upended in a major scandal involving his politician wife, who had committed some major financial improprieties in the name of another type of impropriety—funneling money to her nineteen-year-old lover. And history was then made when McGuinness offered, and Robinson accepted, a commiserative handshake. A guy-code sacred-value moment.*31

			Something similar happened in South Africa, much of it promulgated by Nelson Mandela, a genius at appreciating sacred values.32 Mandela, while at Robben Island, had taught himself the Afrikaans language and studied Afrikaans culture—not just to literally understand what his captors were saying among themselves at the prison but to understand the people and their mind-set. At one point just before the birth of a free South Africa, Mandela entered into secret negotiations with the Afrikaans leader General Constand Viljoen. The latter, chief of the apartheid-era South African Defence Force and founder of the Afrikaner Volksfront group opposed to the dismantling of apartheid, commanded an Afrikaans militia of fifty to sixty thousand men. He was therefore in a position to doom South Africa’s impending first free election and probably trigger a civil war that would kill thousands.

			They met in Mandela’s house, with the general apparently anticipating tense negotiations across a conference table. Instead the smiling, cordial Mandela led him to the warm, homey living room, sat beside him on a comfy couch designed to soften the hardest of asses, and spoke to the man in Afrikaans, including small talk about sports, leaping up now and then to get the two of them tea and snacks. While the general did not quite wind up as Mandela’s soul mate, and it is impossible to assess the importance of any single thing that Mandela said or did, Viljoen was stunned by Mandela’s use of Afrikaans and warm, chatty familiarity with Afrikaans culture. An act of true respect for sacred values. “Mandela wins over all who meet him,” he later said. And over the course of the conversation, Mandela persuaded Viljoen to call off the armed insurrection and to instead run in the upcoming election as an opposition leader. When Mandela retired from his presidency in 1999, Viljoen gave a short, halting speech in Parliament praising Mandela . . . in the latter’s native language, Xhosa.*

			The successful birth of the new South Africa was rife with acts of respect for sacred values. Perhaps the most famous was Mandela’s public embrace of rugby, a sport highly symbolic of Afrikaans culture and historically disdained by black South Africans. And famously, as depicted in book and film, among the consequences was the tectonically symbolic act of the heavily Afrikaans national rugby team singing the ANC anthem, the hymn “Nkosi Sikelel’ iAfrika,” followed by a black choir singing the Afrikaans anthem, “Die Stem van Suid-Afrika,” a craggy song with references to the country’s craggy mountains.* This came before the South African host team’s mythic underdog winning of the World Cup in 1995 in Johannesburg.

			I could watch that YouTube clip of the anthems being sung at the World Cup all day long, especially after having to write the section on Rwanda. What do Hussein, McGuinness, Robinson, Viljoen, and Mandela show? That our confusion of the literal and the metaphorical, our granting of life-threatening sanctity to the symbolic, can be used to bring about the best of our behaviors. Which prepares us for the final chapter, soon to come.





