## 记忆时间

## 卡片

### 0101. 反常识卡——

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

#### 01. 常识

#### 02. 反常识

#### 03. 知识来源

比如提出者，如何演化成型的；书或专栏具体出现的地方。

#### 04. 例子

### 0201. 术语卡——

根据反常识，再补充三个证据——就产生三张术语卡。

例子。

### 0202. 术语卡——

### 0203. 术语卡——

### 0301. 人名卡——冯·诺依曼

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

[约翰·冯·诺伊曼 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC)

#### 01. 出生日期

约翰·冯·诺伊曼（德语：John von Neumann，1903-1957），天才中的天才，电子计算机的鼻祖人物。

#### 02. 贡献及经历

原名诺依曼·亚诺什·拉约什（匈牙利语：Neumann János Lajos，出生于匈牙利的美国籍犹太人数学家，现代电子计算机与博弈论的重要创始人，在泛函分析、遍历理论、几何学、拓扑学和数值分析等众多数学领域及计算机学、量子力学和经济学中都有重大贡献。

冯·诺伊曼从小就以过人的智力与记忆力而闻名。冯·诺伊曼一生中发表了大约 150 篇论文，其中有 60 篇纯数学论文，20 篇物理学以及 60 篇应用数学论文。他最后的作品是一个在医院未完成的手稿，后来以书名《计算机与人脑》发布，表现了他生命最后时光的兴趣方向。他先后任职于美国普林斯顿大学、美国普林斯顿高等研究院等机构。[2][3]

冯·诺伊曼出生在布达佩斯富裕的犹太家庭，是诺依曼·米克萨（Neumann Miksa）和坎恩·玛吉特（Kann Margit）的 3 个孩子中最大的一个。他小时候外号「扬奇」（"Jancsi"，即 "János" 的昵称），当时已经显出惊人的记忆力。他 6 岁时已能用古希腊语同父亲闲谈，还可以心算 8 位数除法，8 岁时自学微积分。年少时的他不但对数学很有兴趣，亦喜欢阅读历史和社会方面的书籍，读过的书籍和论文能很快一句不漏地将内容复述出来，而且多年以后仍是如此。1913 年，他的父亲马克斯·诺伊曼被授予世袭贵族头衔，这样在德国他的后代可以以「冯·诺伊曼」为姓 [4]，冯·诺伊曼晋身贵族。约翰加上头衔后的全名成为「Margittai Neumann János」。后来约翰把名字改成德语名「Johann von Neumann」。其名「John」（约翰）意为「主是仁慈的」，姓氏中的「von」是德语介词，而「Neumann」意为「neu」（new）+「Mann」（man），即「新人」。

1926 年，冯·诺伊曼以 22 岁的年龄获得了布达佩斯大学数学博士学位，相继在柏林大学和汉堡大学担任数学讲师。

1930 年，冯·诺伊曼接受了普林斯顿大学客座教授的职位。初到美国时，他在纽约对当地居民表演过默记电话簿的惊人记忆力。1931 年，冯·诺伊曼成为普林斯顿大学终身教授。1933 年转入普林斯顿高等研究院，与爱因斯坦等人成为该院最初的四位教授之一，不须上课。这一年，他部分解决了希尔伯特第五问题，证明了局部欧几里得紧群是李群。1937 年成为美国公民，1938 年获博修奖。

1954 年，冯·诺伊曼任美国原子能委员会委员。1954 年夏天，右肩受伤，手术时发现患有骨癌，治疗期间，依然参加每周三次的原子能委员会会议，甚至美国国防部长，陆、海、空三军参谋长聚集在病房开会。晚年，有学生请教他做事的方法，他说：简单（simple）。

1957 年 2 月 8 日，冯·诺伊曼在华盛顿瓦尔特·立德军医中心去世，享年 53 岁。他死后葬于新泽西州默瑟县的普林斯顿公墓 (Princeton Cemetery)。

#### 03. 论文及书籍

1945 年 6 月，冯·诺伊曼与戈德斯坦、勃克斯等人，联名发表了一篇长达 101 页纸的报告，即计算机史上著名的「101页报告」，是现代计算机科学发展里程碑式的文献。明确规定用二进制替代十进制运算，并将计算机分成 5 大组件，这一卓越的思想为电子计算机的逻辑结构设计奠定了基础，已成为计算机设计的基本原则。1951 年，EDVAC 计算机宣告完成。（[EDVAC报告书的第一份草案 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/EDVAC%E5%A0%B1%E5%91%8A%E6%9B%B8%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E8%8D%89%E6%A1%88)）

John von Neumann. The Computer and the Brain [计算机与人脑]. 1958 （英语）. (去世后出版)

2020006John_von_Neumann_Selected_Letters

其余很多详见维基百科原文。

### 0302. 人名卡——

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

维基百科链接：有的话。

#### 01. 出生日期

用一句话描述你对这个大牛的印象。

#### 02. 贡献及经历

#### 03. 论文及书籍

#### 04. 演讲汇总

找一个他的 TED 演讲，有的话。

### 0401. 金句卡——

最后根据他写的非常震撼的话语——产生一张金句卡。

### 0501. 行动卡——

行动卡是能够指导自己的行动的卡。

### 0601. 任意卡——

最后还有一张任意卡，记录个人阅读感想。

## 模板

### 1. 逻辑脉络

用自己的话总结主题，梳理逻辑脉络，也就是这本书整个地图里这一章所在的节点。

### 2. 摘录及评论

1『自己的观点』

2『行动指南』

3『与其他知识的连接』

## 前言

如今，计算机、通信系统，以及由它们支撑的数字产品已经无所不在了！笔记本电脑、手机和互联网，这些都是显而易见的。更多的则是我们平常看不见的，比如那些栖身于电子设备、汽车、火车、飞机、电力系统、医疗设备中的计算机。偶尔，透过某些提示，你会得知世界上有无数系统正在悄悄收集、分享你的个人信息，这些信息甚至会被用在违背你意愿的地方。

《世界是数字的》简明扼要但又深入全面地解释了计算机和通信系统背后的秘密，旨在让没有技术背景的读者更好地理解自己生活的这个数字世界。这本书解释了如今计算和通信的运作方式，包括硬件、软件、互联网，还有万维网，同时还探讨了新技术引发的社会、政治和法律问题，让你明白现实当中的一些难题和迫不得已的折中。

很多人对普林斯顿大学的认知来自获得奥斯卡金像奖的电影《美丽心灵》。这部电影以 1994 年获得诺贝尔经济学奖的数学家小约翰·福布斯·纳什（Jr.John Forbes Nash）为原型。1950 年代，20 出头的纳什在普林斯顿攻读博士期间，发表了一篇关于非合作博弈的博士论文，确立了他博弈论大师的地位。而同时代的普林斯顿可谓大师云集，爱因斯坦、冯·诺依曼、列夫谢茨（数学系主任）、阿尔伯特·塔克、阿伦佐·切奇、哈罗德·库恩…… 都在这里。普林斯顿大学直到今天的在校学生也不过 7000 多人，但却人才辈出：两位美国总统、44 位州长、33 位诺贝尔奖得主。

但这只是计算机时代的一个小小的缩影，不为人知的部分就像隐藏在海平面之下的冰山一样巨大。因为看不到，所以我们并不觉得家用电器、汽车、飞机，以及无所不在、司空见惯的电子设备 —— 照相机、摄像机、游戏机、DVD 播放机、GPS 导航仪中都隐藏着计算机。

不经意间，对这些设备品头论足的信息也会进入我们的视野。就像有一次某报道引用了惠普一位高层领导的话：「本质上，数码相机就是一台带镜头的计算机。」同一篇报道中也引用了一位用户的话，这位用户好像不怎么高兴：「这哪是相机啊，根本就是一台计算机！」这是在抱怨有时候使用计算机也不容易。而且，电话网络、电视和有线网络、空中交通管制、电网，还有银行和金融服务等公共设施对计算机的依赖程度也超出了我们的想象。

理查德·穆勒（Richard Muller）的那本《未来总统的物理课》解释了作为国家领导人应该知道的科学和技术造成的社会问题，比如核威胁、恐怖主义、能源、全球变暖，等等。不想当总统但生活在信息时代的公民也应该很好地了解这些问题。虽然科学原理与推理论证有很多不同，但穆勒却能够很好聚焦于每个主题，聚焦于每个人都应该了解的物理常识。他的写作手法启发我让这本书成为「未来总统的计算机与通信」。作为总统应该了解哪些计算机和通信知识？一位信息时代的公民应该知道哪些？虽然每个人心目中的想法不一样，但这本书是我给出的答案。

2『已下载书籍「2020004未来总统的物理课」和原文「2020004Physics_and_Technology_for_Future_Presidents」。』

这本书涵盖了三个核心技术领域：硬件、软件和通信。整本书都围绕这三个主题展开。

硬件是看得见摸得着的。不管是在家里，还是在办公室，计算机都是我们可以看到，可以触摸的。当然，还有我们每天随身携带的手机。计算机的内部都有什么，它是怎么运转的，是根据什么原理制造的？它怎么保存和处理信息？什么是比特，什么是字节？怎么用它们来表示音乐、电影，还有一切？

软件是告诉计算机做什么的指令，几乎看不见，摸不着。通过计算可以做什么，计算速度可以有多快？怎么告诉计算机做什么？为什么让软件不出错很难？为什么它们有时候很难用？

通信就是计算机、手机和其他设备之间为了我们的需要而进行的对话，同时也让我们人和人之间能够交流，涉及互联网、万维网、电子邮件、社交网络等多种途径。这些东西的工作原理是什么？它们的好处显而易见，但有什么风险吗？特别是隐私和安全方面，该怎么解决呢？

在这三个主题之外，人们通常都会想到数据。数据指的是通过硬件及软件收集、存储和处理的，以及通信系统传送到世界各地的全部信息。其中部分数据是自愿公开的，主要是用户上传的照片和视频，有率性而为、不顾及后果的，也有时时警惕、谨小慎微的。还有一些是我们个人的信息，通常是在我们并不知情的情况下被收集和共享，根本没得商量。

无论你是总统，还是平民百姓，都应该了解这个计算机世界，因为它对每个人都有切身影响。无论工作和生活与技术距离有多遥远，你总有机会接触技术和搞技术的人。了解一些计算机和通信的常识都将对你大有助益，最低限度也能让你知道推销人员或服务热线什么时候向你隐瞒了事实。没错，无知有害。假如你不知道病毒、网络钓鱼以及类似的风险是怎么回事，那你受害的机率一定会大大增加；假如你不知道社交网络怎么泄露甚至任意传播你认为是个人隐私的信息，那你无意间泄露的很可能比自己想象的还要多；假如你对商业利益集团不顾一切从你的个人信息中挖掘线索这件事毫不知情，那你就会为了蝇头小利而出卖自己的隐私；假如你不知道在咖啡店和飞机上使用个人银行服务是有风险的，那么你的钱和身份就会让网络窃贼有可乘之机。

3『作者的书籍网站：[kernighan.{com,org,net,ca}](http://kernighan.com/)』

2『已下载书籍：「2020001The_Go_Programming_Language」、「2020002Millions_Billions_Zillions」、「2020003UNIX_A_History_And_A_Memoir」。』

任何足够先进的技术都与魔术无异。

—— 阿瑟·C. 克拉克，「技术及未来前景」，《三号行星的报告》，1972 年

电话。在 1990 年，电话机还都是傻大个儿，用转盘或者 12 个数字按钮拨号，没有显示面板。它通过电话线连到家里或办公室墙上的插座，只能用来跟人讲话，或者通过特殊设备连接传真机和计算机。到了 2000 年，手机已经流行起来，但也只能打打电话。而现在手机已经非常普及，在几乎所有地方都超过了固定电话装机数量。比如埃及和突尼斯，有手机的人已经分别占总人口数的 80% 和 75% 之多。智能手机则可以通过从应用市场下载并安装程序来扩展出各种神奇的功能，例如苹果公司在 2007 年中发布了 iPhone 手机，2008 年 App Store 开张，为 iPhone 提供各种软件；安卓市场也类似。

相片。在 1990 年，大部分相机都使用胶卷来拍摄相片。胶卷就是一卷柔软的塑料片，上面覆盖了特殊成分的感光材料。拍摄的时候，光线照射到底片上，化学性质发生改变，留下影像；拍摄完后，需要利用一系列精致的化学反应进行冲洗显影。一卷胶卷最多可以拍摄 36 张照片，冲洗之前并不能看到照出来的是什么样子，并且冲洗过程在任何地方最短也要一个小时，多的长达一星期。这一切都完成之后，你得到的也只不过是一份印好的相纸。如果想和朋友分享，你只能把相片拿给他们看，或者装在信封里寄过去。你的相片可能放在纸袋子或者相册里，散落在家中的各处。若是想再多要一份相片，你就要奔波到照相馆去花额外的钱。那时候摄影开销相当贵，导致大多数人并不会去拍很多相片。但那时数码相机已经露出取代胶片相机的苗头，从慢慢入侵到迅速占领，直到后来，胶卷从普通人的视线中几近消失。如今，相片已经可以用电子邮件发送给别人或上传到 Facebook、Flickr 等网站，并且可以下载到数码相框来充分展示。如果你还需要纸质相片，那么可以用高品质的相片打印机，它也已经很便宜了。手机摄像头则正在取代廉价的傻瓜相机。

音乐。在 1990 年，音乐是通过 CD 或录音带专辑来发行的，密纹唱片（LP）虽然还很常见，但已经快要过时了。如果你想要复制一首歌和朋友分享，或者放在车里听，那么最常见的办法是使用卡带录音机，尽管也有办法复制 CD 盘片。那时候还没有下载音乐这一说。在 1999 年，Napster 横空出世改变了一切，让大家可以通过网络共享音乐。不过，它很快就关闭了，或者准确点说，被唱片界的传统势力所扼杀。但后来的在线销售单曲服务却把它的遗志发扬光大，比如 2003 年开张的 iTunes 商店就很红火。在便携式硬件方面，我们则经历了便携式收录机、卡带随身听、CD 播放机、以 iPod 为代表的 MP3 播放器，直到后来用手机来听歌。

电子邮件。20 年前用电子邮件的人屈指可数，大多数人甚至都对此一无所知。1998 年，梅格·瑞恩和汤姆·汉克斯主演的《电子情书》才让电子邮件走入公众视野，而之前人们对「邮件」一词的认识仅限于邮递员送来的信件。现如今，大多数人都用 Gmail 之类的在线邮件服务进行个人通信。他们的邮件保存在互联网上，这样用手机也可以访问。

语音处理。在 1990 年，几乎不可能让计算机理解口语，后来也仅仅是在实验室环境下才能识别有限的词汇。现在，只要给商家打个技术支持或投诉电话，就不可避免要和语音识别系统进行「交谈」，遇到真人接线员的机会则变得极少。这并不算什么了不起的进步。机器翻译也差不多是同样的情况，虽然尚未达到完美，但已经很实用：它可以把将近 60 种语言中的任意一种翻译成其他语种。语音合成，也就是根据文本发出语音，尽管还很容易听出与真人语音的差别，但也已经很常用了。

地图。在 1990 年，如果你不知道如何到一个地方去，那就要先在电话黄页本上找到地址，打开纸质地图找找看在哪里，然后一边开车一边对着地图人肉导航。迷路之后要自己弄明白身处何地，如何回到正确路线。还要事先猜测交通路况，或者寄希望于交通广播台。如果想知道从天上看道路是什么样子，那只能去包飞机了！10 年前出现的 GPS 导航设备为行车人解决了大部分导航问题，如今手机内部已经集成了具有类似功能的系统。用街景地图就可以在到达一个地方之前先观其大略。

本书的目的就是揭开魔法的神秘帷幕，让读者了解这些系统是如何运作的。相片、音乐和电影如何能一瞬间传遍全球？电子邮件是如何运转的？你的电子邮件私密性如何？为什么垃圾邮件容易发送却难以清除？手机真的知道你的位置吗？iPhone 和安卓手机有什么区别，为什么它们在根本上又是一回事？读过本书之后，你将会对计算机和通信系统的运转有相当靠谱的了解，并知道这些技术如何影响我们的生活。

首先是信息的通用数字表示。传统上用来存储相片、音乐等不同类型信息的机制是错综复杂的，而现在它们已经被一种统一的机制所取代。这种取代之所以可行，是因为信息被表示为数字形式而不是专门形式（比如底片上曝过光的感光材料，或者录音带上的磁化布局）。纸质邮件被数字邮件所取代，纸质地图被电子地图所取代。总之，信息的不同模拟表示形式被统一的数字表示形式所取代。

其次是通用数字处理器。所有的信息都用数字计算机这样一种统一的设备进行处理。处理信息通用数字表示的数字计算机代替了处理专门的模拟信息所用的实体机器。行文至此，我一直在竭力避免使用「计算机」这个词，但实际上手机就是相当复杂的计算机，其运算能力已经比得上五六年前的笔记本电脑。我们稍后会发现，不同的计算机在「能计算什么」上的能力是一样的，差别只在于计算速度有多快，能存储的数据有多少。以前只能在台式机和笔记本电脑上做的事，必然会越来越多地可以在手机上完成。如果有什么要特别指出的话，那就是，这个趋同化的过程只会越来越快。

1『从模拟信号到数字信号的转变。』

再次是通用数字网络。互联网把处理数字表示的数字计算机联接在一起。计算机、手机被联到邮件、搜索、社交网络、购物、网上银行等各种服务上。与别人互发电子邮件的时候，完全不需要考虑对方在哪里、选择用什么方式存取电子邮件。用笔记本电脑、手机、平板电脑都可以搜索商品、比较价格、下单购物。社交网络也让你通过手机和计算机与家人朋友保持联系。显然，要让所有这些计算服务正常工作，网络这个基础设施的影响是巨大的。

最后，海量的数字化数据也在持续不断地被收集和更新。全球的地图、航线和街区照片都可以免费获取。搜索引擎为了有效地应对查询而孜孜不倦地扫描着整个互联网。成千上万的书都做成了数字形式。社交网络和资源分享站点为我们保存了关于我们自己的巨量数据。当我们访问网上商店和服务时，它们一方面让我们读取其后台数据，另一方面又在搜索引擎和社交网络的协助和怂恿下默默记录着我们的一举一动。互联网服务供应商记录下我们在网上所有互动操作的联接信息，或许甚至更多。

对硬件部分来说，应该明白计算机的构成，它如何表示和处理信息，某些术语和数字的含义，以及计算机随着时间推移都有了哪些变化。

软件方面，关键是要知道怎么精确地描述任务，包括抽象的算法（同时考虑数据量的增加在多大程度上延长计算时间）和具体的程序。知道软件是由什么构成的，不同的编程语言怎么编写程序，程序怎么变成软件（通常是基于组件构建起来的），这样就能理解我们所用软件背后的秘密。但愿讲编程的那几章也会让你跃跃欲试，亲自动手写出一些代码来。

通信系统是无远弗届，无所不在的。重要的是理解其中的信息流动、谁能够查看这些信息，以及信息是如何得到控制的。协议，即系统之间交换信息的规则，也非常重要。协议的内容影响深远，由今天互联网中的身份认证问题可见一斑。

不少计算方面的概念对理解这个世界很有帮助。比如，我经常会区分逻辑结构与具体实现。这个根本问题有无数种表现方式。计算机就是一个典型的例子。无论其制造方式变化得有多快，其逻辑架构一直以来并没有太大不同。甚至可以认为，所有计算机的逻辑特征都是一样的，即它们都可以完成相同的计算。从软件角度看，代码作为一个抽象层，隔离了具体的实现。实现可以改变，而使用它们的代码可以不变。虚拟机、虚拟操作系统，甚至真正的操作系统都是利用接口来分离逻辑结构与具体实现的。想一想，编程语言也具备这个功能，有了它我们才可以跟计算机对话，就好像所有计算机都能听懂我们的话一样。当然，编程语言也是我们人类可以理解的。

计算机系统是设计上多方权衡、不断取舍的极佳范例，提醒我们设计中永远不可能处处如意，天下没有免费的午餐。桌面电脑、笔记本电脑、平板电脑、手机，同是计算设备，但它们在尺寸、重量、计算能力和成本等约束条件上，则分别作出了明显不一样的取舍。

计算机系统也是把大型、复杂系统切分成小型、易管理（可独立创建）组件的好例子。软件分层、API、协议和标准莫不如此。

我在导论中提到的「通用」对于理解数字技术同样重要。下面就来概括一下。

首先是通用的数字信息表示。化学有 100 多个元素，物理有十几个基本粒子。而数字计算机只有两个元素，0 和 1，其他一切都由此衍生出来。比特可用来表示任何信息，从最简单的真假、是否、对错之类的二元选择，到数字、字母，乃至一切事物。复杂的事物比如购物、浏览和手机历史中关于你生活的点点滴滴，则是由简单的数据项组成，后者又可以用更简单的形式来表示，如此往复，直到表示成一个一个的比特。

其次是通用的数字处理器。计算机是操作比特的数字设备。告诉处理器做什么的指令，被编码为比特，而且通常与数据保存在同样的存储器中。改变指令可以改变计算机行为，而这也正是计算机之所以成为通用机器的原因所在。比特的含义取决于上下文，一个人的指令可能是另一个人的数据。虽然有适合处理某种数据的特定技术存在，但复制、加密、压缩、错误检测等等操作全都可以在比特的层面上执行，与比特所表示的事物无关。运行通用操作系统的通用计算机取代各种专用设备的进程还将继续。未来很可能出现根据生物计算原理设计的其他处理器，或许还会出现量子计算机。但是，数字计算机还会伴随我们很长时间。

第三是通用的数字网络，网络中从一个处理器传输到另一个处理器的数据和指令，同样也都是比特。互联网和电话网有可能融合为一个更通用的网络，恰似我们亲眼见证的计算和通信功能融合于今天的手机。互联网肯定会向前发展，至于是沿续其随心所欲、自由发展的特点，还是会受到商业和政府更多的制约，并没有明确的答案。（我想多半是后者，很不幸啊。）

最后，通用的数字系统无所不在。在整合多领域技术进步的基础上，数字设备向着小型、廉价和高性能的方向发展。某一领域的技术进步，比如存储密度，经常会影响到所有数字设备。

1『通用的数字信息编码、通用的数字处理器、通用的数字网络，世界是数字的。』

最后，读者诸君务必牢记一点，无论今天的技术多么千变万化，人是不变的。无论从哪方面来看，现代的人类与几千年前的人类并没有太大区别。抚今追昔，历史上干好事的人有多大比例，今天也差不多；历史上干坏事的人有多大比例，今天同样也差不多。没错，社会、法律和政治都在适应技术变革，但这是个缓慢的过程，步调并不一致，而且世界不同角落的解决方案也各不相同。

## 硬件

然而，有些历史趋势却值得我们关注，尤其是这一点：以一定的成本，在给定大小的空间内能装进电路和设备的数量，随着时间而呈指数式增长。随着数字设备越来越强大和廉价，林林总总的机械系统已经被更为统一的电子系统所代替。

计算设备的历史悠久，不过早期的计算设备大多数是专用的，通常用于预测天文事件及其发生方位。例如，关于巨石阵，一个尚未证实的推测就认为它是一座天文观测站。公元前 100 年制造的安提基瑟拉机器就是一台天文计算机，其机械结构之精妙令人叹为观止。算盘之类的演算工具也已经使用了近千年时间，在亚洲尤为流行。计算尺发明于 17 世纪早期，也就是约翰·纳皮尔提出对数概念没多久之后。

虽然尚存在争议，但一般认为，当今意义上的计算机始于 19 世纪的英国，由查尔斯·巴贝奇提出。巴贝奇是一位科学家，对航海和天文学感兴趣，而这两项事业都需要通过写满了数值的表格来计算方位。巴贝奇花费了毕生精力来制造用于计算的设备，试图把冗长乏味、易出错的手工算术运算机械化。但由于各种原因，包括与资助人之间的关系疏离，他的雄心壮志始终没有得偿所愿。不过，他的设计是正确的，现代人利用他那个时代的工具和材料按其设计可以制造出他的机器。如今，在伦敦的科学博物馆、加州山景城的计算机历史博物馆等地，都能看到这样的机器。

一位年轻的女士受巴贝奇鼓舞而对数学和他那个计算设备产生了兴趣。这位女士就是诗人乔治·拜伦的女儿，奥古斯塔·爱达·拜伦，也就是后来的勒芙蕾丝伯爵夫人。她写过一份详细说明，讲述如何用分析引擎（巴贝奇所计划制造机器里最高级的一个）进行科学计算，并推测这种机器也可用于非数值计算，比如作曲。爱达·勒芙蕾丝通常被认为是世界上第一位程序员，编程语言 Ada 也是以她的名字而命名的。

在 19 世纪后期，赫尔曼·何乐礼为美国人口统计局设计并制造了制表机，用它制作人口统计数据表格要比手工快得多。何乐礼借用了雅卡尔织布机的思路，用卡片纸上的孔洞把人口统计数据编码成他的机器能处理的格式。令何乐礼名声大噪的是，1880 年的人口数据花了六年才制成表，而用了他的穿孔卡片和制表机之后，1890 年的数据仅一年就完工。他创立了一家公司，经过多次并购之后成为国际商业机器公司，也就是我们现在熟知的 IBM。

巴贝奇的机器是由齿轮、转轮、杠杆、拉杆组合起来的复杂机械，而 20 世纪电子学的发展使得人们有条件去设想没有运动部件的计算机会是什么样子。到了 20 世纪 40 年代，在费城的宾夕法尼亚大学，由布莱斯波·埃克特和约翰·莫奇利设计制造的 ENIAC（电子数值积分计算机的英文首字母缩写）横空出世，成为全电子计算机的最重要标志。ENIAC 占满了一间大屋，需要消耗很多电力，每秒钟能做大约五千次加法。它本来是为了计算弹道等军事用途而制造的，但直到 1946 年「二战」已结束多时它才完工。ENIAC 的一些部件，现存放在宾大的摩尔工程学院作展览。

巴贝奇清楚地意识到，计算设备可以把操作指令和数据保存为同样的形式，但 ENIAC 并没有把指令像数据那样保存在存储器中，而是通过扳动开关和重新连线来实现编程。第一台真正实现了存储程序的计算机于 1949 年在英国面世，称为 EDSAC（延迟存储电子自动计算机的英文首字母缩写）。

早期的电子计算机使用电子管作为基本计算元件。电子管是一种大小和形状类似于柱形电灯泡的电子设备，缺点是昂贵、易碎、笨重、费电。而随着 1947 年晶体管和 1958 年集成电路的相继发明，计算机的新时代才真正开始。用此技术制造的设备是当今的电子系统越来越小、越来越迅速以及越来越便宜的原因所在。

3『

[电子管_百度百科](https://baike.baidu.com/item/%E7%94%B5%E5%AD%90%E7%AE%A1)

电子管，是一种最早期的电信号放大器件。 被封闭在玻璃容器（一般为玻璃管）中的阴极电子发射部分、控制栅极、加速栅极、阳极（屏极）引线被焊在管基上。利用电场对真空中的控制栅极注入电子调制信号，并在阳极获得对信号放大或反馈振荡后的不同参数信号数据。

』

1、数字计算机包含处理器和存储器。处理器执行简单的指令，速度非常快。它可以根据早先计算的结果以及外界的输入，决定接下来做什么。存储器包含数据和处理数据的指令。

2、计算机是一种通用的机器。它从存储器中读取指令，而人把不同的指令放到存储器中，可以改变它要执行的计算。指令和数据要通过使用场景区分，一个人的指令可以是另一个人的数据。

3、图灵的结论：从能够执行完全相同的计算的意义上说，这种结构的所有计算机（包括你以后可能会看到的任何计算机）具有完全相同的计算能力。当然，它们的性能可能千差万别，但在不考虑速度和存储器容量的前提下，它们的能力则是等价的。最小最简单的计算机也能够完成大计算机所能完成的计算。的确，可以通过编程让任何计算机模拟其他计算机，而图灵正是这样证明了他的结论。

4、计算机的逻辑结构自冯·诺依曼之后并没有太大改变，但物理结构已经发生了巨大变化。摩尔定律已经应验了大约 50 年，成为迄今为止几乎完全兑现的预言。摩尔定律预言了在既定的空间和成本之下，个别器件的大小和价格会呈指数级下降，而它们的计算能力呈指数级增长。它们都是数字计算机：所有一切最终都要化简为比特，单独或成组地以数字形式表示信息，所谓信息可能是指令也可能是数据。这些比特的含义取决于它们的上下文。可以化简为比特的任何事物，都可以通过数字计算机来重现和处理。

从某种角度讲，互译结果相当不错，甚至还考虑到了一些语法问题。然而，翻译过程忽略了一个谈论计算机时至关重要的事实，即「比特」（bit）并不等同于「碎块」（piece），而「化简为比特」（reduced to bits）与「切分成碎块」（cut in pieces）的意思也完全不同。类似的结论同样适用于今天的语音识别、面部识别及其他图像处理：计算机可以做得很出色，但没人会说它们的能力可以与人类比肩。顺便说一下，如果你再试一次，翻译的结果又会不一样，其算法和底层的数据好像变化很频繁。

计算机可以下出特级大师水平的国际象棋，但在人脸识别上却不及幼儿。早些时候，计算机下国际象棋的水平其实很烂，但随着机器的速度不断加快，它下棋的水平明显提高，但这一切几乎完全是因为它比人类对手能够多看几步。类似地，语言翻译、语音识别等领域最大的进步，主要还体现在庞大的数据量（比如不同语言的平行文本数量），而有了这些数据计算机才能接近人的表现。

图灵测试想做的，就是在隐身、忽略响应时间等因素的前提下，通过对人和计算机提问，看看能否区分哪个是人，哪个是计算机。

尽管如此，我们还是有太多太多的事物不知道怎么用比特来表示，更不必说怎么用计算机来处理了。比如，日常生活中最重要的一些事物：艺术、创意力、真理、美、爱、荣誉和价值。我想在一定的时期内，这些事物仍将超出计算机的能力之外。

## 01. 计算机里有什么

### 1. 逻辑脉络

计算机里有什么可以从 2 个维度来看。功能组成上看，计算机里有什么组件、是做什么的、它们是如何连接起来的；从物理结构上看，这些东西是啥样子的，它们是如何被制作出来的。前一个维度的功能组成一直没变过，而后一个维度的物理结构一直在更新，典型如摩尔定律。

### 2. 摘录及评论

先大略看看计算机里面都有些什么东西。这个问题可以从两方面来看：逻辑上或者说功能上的组成，即每一部分是什么、做什么、怎样做、之间如何连接；以及物理上的结构，即每一部分长什么样子、如何建造起来的。

这些计算机看起来很不一样，用起来也感觉不一样，但这仅仅是表象，其实根本没区别。为什么这么说呢？可以拿汽车来打个大致的比方。在功能构成上，这一百多年来的汽车都是一样的。每辆汽车都有个发动机，通过燃烧某种燃料来驱动发动机运转，这样车就能开了；都有个方向盘，这样司机（也许可以比作软件）就能操纵车的方向；还有储存燃料的地方，以及留给乘客和行李的位置。但是这一个多世纪以来汽车在物理构成上却变化巨大：造车的材料日新月异，行驶越来越快，越来越安全，可靠性和舒适性与过去不可同日而语。

计算机也是一样的道理。当今的计算机在逻辑结构上和 20 世纪 50 年代的非常相似，但是物理指标的进步却远甚于汽车。当今的计算机和 50 年前的比起来，体积更小，价格更廉，运行更快，也更可靠，有些字面上的指标甚至提高了百万倍。计算机如此普及，其根本原因就在于此。

一件东西的功能表现与物理特性之间的区别，也就是说它能做什么与它是怎样建造起来的（或者说内部的工作方式）之间的区分，是很重要的。就计算机而言，「它是如何建造出来的」这个问题的答案在以惊人的速度变化着，「它运行起来有多快」也是如此，但是「它能做什么」的答案却没什么变化。后面将会反复提到这两方面的区别。

如果我们画一张抽象图展示计算机内部有什么，也就是它逻辑上或者功能上的体系结构，那么 Mac 和 PC 的结构都是如下图所示：一个处理器（CPU）、一些主存储器（内存）、一些大容量存储器（磁盘）和各种各样的其他部件，一组叫做总线的线缆把所有这些连接起来，在各部件之间传输信息。

计算机的基本组成，包括处理器、存放指令和数据的存储器以及输入输出设备，在 60 多年前就已经是标准了。这种体系结构通常称为冯·诺依曼体系结构，以约翰·冯·诺依曼的名字命名。他在 1946 年与阿瑟·勃克斯、赫尔曼·戈德斯坦共同撰写的论文《电子计算仪器逻辑设计的初步讨论》中描述了这种体系结构。尽管目前人们对于以冯·诺依曼来命名这种体系结构是否掩盖了其他人的贡献尚有争议，但这篇论文条理清晰，见解深刻，即便在今天也值得一读。例如，论文的第一句就指出：「为了让这台完整的设备成为通用的计算机器，它必须包含某些主要元件用于运算、存储数据、控制以及连接操作人员。」翻译成现在的术语就是，CPU 提供运算和控制功能，内存和磁盘用于存储数据，键盘、鼠标和显示器用于连接操作人员。

2『已下载论文「2020001Logical_Design_of_an_Electronic_Computing_Instrument」；已下载书籍「2020005计算机与人脑」；已下载原文书籍「2020005The_Computer_and_the Brain」、「2020006John_von_Neumann_Selected_Letters」。』

如果我们说计算机有大脑的话，处理器，或者叫中央处理单元（缩写为 CPU）就是计算机的大脑。处理器进行运算，来回搬运数据，并控制着一切别的操作。CPU 有一张指令表，它可以执行的操作是有限的，但执行起来速度异常之快，高达每秒钟几十亿次。它可以根据先前的计算结果决定接下来执行什么指令，所以在很大程度上，它可以主宰自己的命运。

比如你可能看到对 CPU 的描述是「英特尔双核酷睿 2.1 GHz」。这是什么意思呢？这款 CPU 是英特尔制造的，一片封装的内部实际上有两个 CPU。在这句话里，「核」的意思就是处理器。2.1 GHz 看起来更有趣。CPU 的速度大体上是以每秒钟执行的操作数量、指令数量或更小的动作数量来度量的。CPU 使用一个跟心跳或者钟表嘀嗒类似的内部时钟来控制基本操作的节拍，度量 CPU 速度的指标之一就是看这个内部时钟每秒振动多少次。每秒钟心跳一次或者嘀嗒一次就是 1 赫兹，记为 1 Hz。这个单位名称是为了纪念德国工程师海因里希·赫兹，他在 1888 年发现了产生电磁辐射的方法，由此直接导致无线电广播和其他无线系统的诞生。广播电台发射的广播信号频率为兆赫（百万赫兹），比如 102.3 MHz。现在的计算机通常运行在十亿赫兹的数量级上，也就是吉赫，记为 GHz。

主存储器，也就是随机访问存储器（缩写为 RAM，即内存 ），里面保存了处理器和计算机的其他部件正在活跃使用的信息；CPU 可以改变内存里的内容。内存里不仅保存了 CPU 正在处理的数据，还保存了让 CPU 如何处理数据所需运行的指令。这一点至关重要：通过把不同的指令加载进内存，就可以让计算机做不同的计算。这样，存储程序型计算机就成为通用的设备：同一台计算机，只要在内存里放上适当的指令，就可以运行文字处理程序、制作数据表格、上网浏览、收发电子邮件、计算纳税款，还可以播放电影。存储程序这个理念的重要性怎么强调都不为过。

内存是计算机运行的时候存储信息的地方。运行中的程序，比如 Word、iTunes 或浏览器，它们的指令就放在内存里；这些程序操作的数据，比如屏幕上显示的照片、正在编辑的文档、正在播放的音乐等，也是放在内存里的；而 Windows、Mac OS X 或其他操作系统，也就是能让你在同一时间运行多个应用程序的幕后功臣，它们运行时的指令还是放在内存里。

内存之所以被称为「随机访问」，是因为 CPU 能以同样的速度快速访问其中任何地方的信息。以任何顺序随机访问不同位置时，速度不会受到任何影响。与之相比，老式录像带的访问方式则称为「顺序访问」，比如想观看电影尾声的时候只能从头开始慢悠悠地「快进」，跳过前面的内容。

内存是易失性的，也就是掉电之后里面的内容会消失，当前活跃的信息就都丢掉了。所以要养成小心谨慎的好习惯，经常保存正在做的工作，尤其是在台式机上，不小心踢掉电源线可不是闹着玩的。

你计算机上的内存大小是有限的。表示容量的单位是字节。一字节大小的内存，可以放入单个字符（比如 W 或者 @），可以放入一个整数比如 42，还可以放入大数值的一部分。第 2 章会展示内存或者计算机其他部件中的信息是如何表示的，因为这是计算的一个基础问题，但在此之前，你可以把内存想象成一大堆完全一样的小盒子，上面从 1 开始编号到一二十亿，每个盒子里可以放进一小片信息。

内存的容量有多大？我正在用的这台笔记本电脑，内存有 20 亿个字节，或者说 2 吉字节，也就是 2 GB。有很多人还认为这么些内存太小了点。原因是，虽然所有程序同时开起来的时候，内存再多也不够用，但是内存越大，可供发挥的空间就越大，而这往往也可以说成是计算得越快。如果你想要计算机运行更快的话，多买内存看起来是最佳策略。

内存的容量很大，但还是有限的，并且掉电之后内容会消失。大容量存储器则能在掉电后仍保存着里面的信息。最常见的大容量级存储是磁盘，有时也称为硬盘或硬驱。磁盘能保存的信息比内存大得多，并且是非易失性的，也就是说，磁盘上的信息不论通电还是断电都一直在那里。于是数据、指令和其他信息都长期保存在磁盘上，仅在需要时临时读入内存。磁盘空间比内存便宜 100 倍，只是访问起来要慢得多。磁盘保存信息的方法是对旋转的金属盘片表面的磁性材料上的微小区间进行不同方向的磁化。计算机工作时的嗡嗡声和咔嗒声就是磁盘把磁头移向盘片表面正确位置时发出来的。

硬盘是用来展示逻辑结构和物理实现之区别的好例子。在 Windows 下运行资源管理器或者在 Mac OS X 下运行 Finder，可以看到硬盘里的内容组织为层次分明的文件夹和文件，但真正的数据是完全存放在旋转的机械装置、没有活动部件的集成电路或者其他存储设备里的。计算机里装的究竟是哪种「磁盘」其实无关紧要，事实上是硬盘里的硬件电路和操作系统里称为文件系统的重要软件一起创建了这种有组织的结构。

这种逻辑结构跟人的思维相当匹配，或者更合适的说法是，到如今我们已经完全习惯了这种组织方式，所以别的存储设备也提供了同样的组织方式，哪怕是它们使用了完全不同的物理方法来实现存储。比如说，CD-ROM 或者 DVD 使用了看起来跟硬盘上的文件系统一样的方式来储存信息；USB 设备、数码相机和可插存储卡等其他小玩意也都这样；就连现在已经完全淘汰的老古董软盘，在逻辑层次上看起来也完全一样。

在体系结构示意图里，这些设备看上去是通过一组线缆连接在一起的。借用电气工程的术语，这组线缆称为总线。实际上，计算机内部有好几组总线，每组总线都具有适合其功能的特性。比如 CPU 和内存之间的总线，线路短，传输快，但是价格贵；而连接到耳机插孔的总线，线路长，传输慢，但是价格便宜。有些总线在机箱外也露出了一部分，比如无所不在的通用串行总线，也就是把外设插入计算机所用的 USB 总线。

手机没有硬盘，但是有非易失性的闪存，这样它就能够在关机时仍保存电话本、应用程序和其他信息。手机能连接的外部设备没那么多，但还是可能有蓝牙、耳机和外部话筒插孔和 USB 接口等。

由于计算机里面的很多东西都抽象成了逻辑结构，所以能实际观察和触摸硬盘、集成电路芯片、制造芯片所用的晶圆等东西对于学习计算机是很有用的，而观察一些设备的进化史也很有趣。比如现在的笔记本电脑硬盘跟 10 年前的没什么区别，只是容量增大了 10 倍或者 100 倍，但从外表根本看不出来。另一方面，承载计算机部件的电路板却能看出明显的发展。部件的数量在减少，因为更多的电路被做到了内部，布线更加精细，电路的引脚比起 20 年前多了很多，也密集了很多。下图展示了一块 20 世纪 90 年代后期的台式机电路板，CPU、内存等部件安装或者插入到电路板上，通过反面的印刷线路连接起来。

计算机里的电子线路是由大量基本元件搭建起来的，但基本元件的类型却只有很少几种。其中最重要的一种是逻辑门电路，用来根据一个或两个输入值计算一个输出值，也就是用输入的电压或电流信号来控制输出的电压或电流信号。只要把足够多的门电路用正确的方式连接起来，就能执行任何计算。查尔斯·佩措尔德的《编码》是介绍这方面知识的好书，还有一些网站用图形动画的方式演示逻辑电路如何进行数学运算和其他计算。

2『已下载书籍「2020004编码」和原书「2020004Code」。』

当今最重要的电路元件是晶体管，是 1947 年由约翰·巴丁、瓦尔特·布拉顿和威廉·肖克利在贝尔实验室发明的，他们因此获得了 1956 年的诺贝尔物理学奖。在计算机里面，晶体管基本上就是个开关，也就是用电压控制电流通断的设备。任何复杂系统都可以构建在这么简单的基础之上。

门电路过去是用分立元件搭建的。制造 ENIAC 的时候，用的是跟灯泡差不多大小的电子管，而 20 世纪 60 年代的计算机则用的是铅笔上橡皮头那么大的单独的晶体管。下图展示了第一颗晶体管的仿制品（左边）、电子管和封装起来的 CPU 芯片。电子管大约 10 厘米长，CPU 实际的电路部分是在中间，大约 1 平方厘米。图上这么大的现代 CPU 芯片里则可以集成上亿颗晶体管。

如今的逻辑门电路是创建在集成电路上的。集成电路（integrated circuits）缩写为 IC，通常也称为芯片或微芯片。集成电路在一个平面里（很薄的硅片）包含了电路板的所有部件和布线，通过一系列复杂的光学和化学流程制造出来，这样就得到了没有分立元件也没有传统布线的电路。因此，集成电路比分立部件的电路小得多也可靠得多。芯片是在直径 12 英寸（30 厘米）的晶圆上批量制造的，然后把晶圆切割成独立的芯片，单独包装。芯片通常安装在比它大很多的封装壳上，用几十到几百条引脚连接到系统的其他部分。下图展示了一片封装起来的集成电路。实际的电路部分在中心，大约 1 平方厘米。

集成电路是 1958 年由罗伯特·诺伊斯和杰克·基尔比各自独立发明的。诺伊斯在 1990 年逝世，基尔比则在 2000 年因此获得了诺贝尔物理学奖。集成电路是数字电子设备的主角，但其他技术也发挥了作用，包括硬盘中的磁存储、CD 和 DVD 中的激光、光纤网络中的激光等。过去 50 年里，所有这一切都在尺寸、容量和价格方面发生了惊人的改进。

1965 年的时候，戈登·摩尔，也就是后来的 Intel 公司联合创始人及长期 CEO，发表了一篇文章《在集成电路里填入更多部件》。他注意到，随着技术的发展，在给定大小的集成电路内部可以制造的设备（主要是晶体管）数量大约每年翻一番。后来他又把这个速率修正为两年，另外有些人则认为是 18 个月。由于计算能力大体上可以用晶体管数量来代表，这就意味着计算能力只要两年或更短时间就能翻倍，也就是说，20 年下来可以翻十番，集成度提高 2 的 10 次方也就是大约 1000 倍，经过 40 年则可以提高 100 万倍或更多。

这种指数式增长，也就是通常说的摩尔定律，已经持续了 50 年，于是当今集成电路里的晶体管数量早已超过了 1965 年那时候的 100 万倍。巨大的量变引发了质变。摩尔定律的实际图表，尤其是处理器芯片的数据，显示出晶体管数量从 20 世纪 70 年代早期 Intel 8008 CPU 的几千个晶体管，已经发展到现在廉价家用笔记本电脑的处理器的上亿个。

用来描述电路规模的基本数值是集成电路里的特征尺寸（即其中的最小尺寸），比如导线的宽度。在过去的很多年里，这个数值在稳步缩减。我在 1980 年设计的第一片集成电路（也是我设计的唯一一片）用的是 3.5 微米的特征尺寸；如今的很多集成电路，特征尺寸是 32 纳米，也就是 32 米的 10 亿分之一，下一步将会是 22 纳米。对比一下，一张纸的厚度或者一根头发的粗细是 100 微米，即十分之一毫米。

1『之前在电脑报里看到的，CPU多少多少 nm 工艺，知道就是特征尺寸，即导线的宽度。』

集成电路的设计和制造是相当复杂的业务，竞争异常激烈。而且制造运行（生产线）也很昂贵，新建的工厂可以轻而易举花掉几十亿美元。如果一个公司的技术和资金跟不上，就会在竞争中严重处于劣势。如果一个国家没有这样的资源，就要为了这些技术依赖外国，存在严重的战略问题。

到某个阶段，摩尔定律会失效。以前曾多次有人断定摩尔定律的极限已到来，但后来又发现了突破极限的方法。然而现在，我们已经到了这样的阶段：有的电路里仅包含极少数原子，这么小的结构已经很难控制。CPU 速度已经不再每两年翻一番（部分原因是芯片越快散热越多），但是内存容量仍然在按这个规律翻倍。与此同时，现在的处理器在一片芯片里可以有多颗 CPU。

比较一下今天的个人电脑和 1981 年最初的 IBM PC，对比是惊人的：第一代 PC 的处理器主频是 4.77 MHz，现在一片 2.3 GHz CPU 的时钟频率快了大约 500 倍；第一代 PC 有 64 千字节内存（「千」缩写为 K），现在一台 4 GB 内存的计算机大约是它的 6 万倍；第一代 PC 至多有 750 KB 软盘，没有硬盘，现在机器的磁盘空间则增加了 100 万倍；第一代 PC 的显示器是 11 英寸的，只能在黑色背景上显示 24 行 80 列的绿色字符，而我写这本书的时候所用的 24 英寸显示器能显示 1600 万颜色；在 1981 年，买一台配备了 64 KB 内存、160 KB 单软驱的 PC 要花 3000 美元，相当于 30 年后的 5000-10000 美元，而现在买一台 2 GHz 处理器、4 GB 内存、400 GB 硬盘的笔记本电脑只要花几百美元。

1『老的显示器显示的是 80 列的绿色字符。原来这就是代码习惯设置 80 个字符一行的来源，至少算一个来源，还有个原因是方便多屏显示，细长的比较合适。』

20 世纪计算机科学的伟大发现之一是，现在的数字计算机、最初的 PC 以及再往前体积更大、计算能力更弱的老式计算机器，它们在逻辑或者功能上的特性是完全一样的。如果我们不考虑速度、存储容量这些因素，这些计算机可以做完全一样的计算。

## 02. 比特、字节与信息表示

### 1. 逻辑脉络

有关计算机表示信息的三个核心思想：计算机处理的信息是数字信息而非模拟信息；计算机处理的信息是二进制编码的；较大的信息用比特组来表示。

### 2. 摘录及评论

计算机表示信息的三个基本思想。首先，计算机是数字处理器。它们存储和处理离散的信息，这些信息表现为不连续的块，具有不连续的值，基本上就是一个个数值。而与之相对的模拟信息，则是平滑变化的值。其次，计算机用比特表示信息。比特就是二进制数字，即一个非 0 即 1 的值。计算机中的一切都用比特来表示。计算机内部使用二进制，而不是人们所熟悉的十进制。再次，较大的信息以比特组表示。数值、字母、单词、姓名、声音、照片、电影，以及处理这些信息的程序所包含的指令，都是用比特组来表示的。

为什么用二进制而不用十进制？因为制造只有两种状态（如开和关）的物理设备，比制造有十种状态的设备更容易。这种简单的性质在数不清的技术中都得到了利用，比如：电流（流动或不流动）、电压（高或低）、电荷（存在或不存在）、磁性（南或北）、光（亮或暗）、反射率（反光或不反光）。约翰·冯·诺依曼很早就清楚地认识到了这一点，他在 1946 年说过：「我们储存器中最基本的单位自然是采用二进制系统，因为我们不打算度量电荷的不同级别。」

为什么我们要知道或者要关心二进制数呢？这个问题问得好。至少在我的课上，理解另一种不熟悉的数制，相当于做了一次量化推理的练习，而有了这个训练之后，对我们习以为常的十进制的理解也将更深一层。除此之外，另一个意义在于，比特的数量在一定程度上揭示了涉及的空间、时间或者复杂性。再从根本上说，计算机值得我们花时间去理解，而二进制正是其运作的核心所在。

现实生活中也能找到一些与计算机无关的应用二进制的场景，或许是因为人们都认为大小、长短的加倍、减半是一种自然而然的运算。比如，高德纳在《计算机程序设计艺术》中描述了 14 世纪英国的酒器单位，分为 13 个二进制量级：2 吉耳是 1 超品（chopin），2 超品是 1 品脱，2 品脱是 1 夸脱，依此类推，直到 2 百瑞尔（barrel）是 1 豪格海（hogshead），2 豪格海是 1 派普（pipe），2 派普是 1 坦恩（tun）。这些单位中差不多还有一半仍然在英制液体度量体系中使用。当然，其中一些很令人陶醉的词，比如费尔金（firkin）和基尔德坎（kilderki）（2 费尔金是 1 百瑞尔），今天已经很难得见了。

2『已下载书籍「2020007计算机程序设计艺术」和原文书籍「2020007The_Art_of_Computer_Programming」。』

首先，我们谈一谈模拟与数字的区别。「模拟」（analog）与「类似的」（analogous）词根相同，表达的意思是：值随着其他因素变化而平滑变化。现实生活中的很多事物都具有模拟性质，比如水龙头或汽车方向盘。如果你想让车转个小弯，轻轻打一打方向盘即可，打多打少由你自己来定。拿它跟转向灯作个比较，后者要么开要么关，没有中间状态。在模拟装置中，某些事物（汽车转弯幅度）会随另一些事物（方向盘转动幅度）的变化平滑而连续地变化。变化过程没有间断，一个事物的微小变化就意味着另一个事物的微小变化。

数字系统处理的是离散值：可能的取值是有限的（转向灯只可能是关闭的或在左右方向打开）。某个事物小小的变化，要么不引发其他事物变化，要么就引发其他事物的突变，使其从一个离散的值跳到另一个离散的值。

比如手表。「模拟」手表有时针、分针和秒针，秒针每分钟转一圈。虽然现代的手表都由内部的数字电路控制，但时针和分针仍然随着时间流逝而平滑移动，而且三根表针都能走遍所有可能的位置。数字手表或手机时钟显示的时间只有数值。显示屏每秒变化一次，每分钟更新一次分钟的值，但不会显示分钟的小数位。

有人要问，为什么用数字而不用模拟呢？我们这个世界可是模拟的呀，而且手表、速度表等等模拟设备也更容易让人一目了然。但不管怎样，很多现代的技术都是数字的，而且我们这本书也是在讲述数字的故事。外部世界的数据 —— 声音、图片、运动、温度，等等一切，在输入端都会尽可能早地转换为数字形式，而在输出端则会尽可能晚地转换回模拟形式。原因就在于数字化的数据容易处理，无论最初来源是什么，数字化数据都可以用多种方式来存储、传输和处理，但模拟信息则不行。第 9 章将会介绍，通过删除冗余和不重要的信息，还可以压缩数字化信息。为了安全和隐私可以对它进行加密，可以将它与其他数据合并，可以复制它而不出错，可以通过互联网把它发送到任何地方，可以将它保存到几乎无限种设备中。而对于模拟信息，上述很多做法是根本行不通的。

与模拟系统相比，数字系统还有另一个优势，就是它更容易扩展。比如说，给模拟天文馆增加一颗新发现的星星，专业人员必须辛苦地做出光照效果来；而在数字天文馆，只要在数据文件里添加一行信息即可。我的数字手表可以连续不断地以百分之一秒显示时间流逝，而要让模拟手表做到这一点可就太难了。不过，模拟系统有时候也有它的优势，像泥版、石雕、羊皮纸、图书和照片等古老的媒体，都经历了数字格式未曾经历过的时间考验。

把照片转换为数字形式，应该是最容易想象的了。假设我们给自家的小猫拍张照片。胶卷相机的成像，是通过把胶片感光区曝露给被拍物体反射的光线实现的，胶片上不同区域接收到的不同颜色的光量不同，从而影响胶片上的染料。在胶片显影、印相时，彩色染料数量决定了显示出来的颜色变化。

对数码相机来说，镜头把影像聚焦到一块位于红、绿、蓝滤镜后面的矩形感光器阵列上，感光器由微小的光敏探测器组成。每个探测器存储一定数量的电荷，与落在它上面的光量成正比。这些电荷被转换为数字值，照片的数字表示就是这些表现光强度的数值序列。探测器越小，数量越多，电荷测量的结果就越精细，数字化图像就能越精确地反映原始的影像。

传感器阵列的每个单元都由一组能够捕获红、绿、蓝光的探测器构成，每个单元对应一个像素，即像元。3000×2000 像素的图像，包含 600 万个像元，或 600 万像素，对今天的数码相机而言并不算大。像素的颜色通常由三个值表示，分别代表红、绿、蓝光的强度，因此 600 万像素的图像总共要存储 1800 万个颜色值。屏幕在显示图像时，使用的是红、绿、蓝光三元组的阵列，其亮度与像素亮度一致。如果你用放大镜仔细观察手机或电脑屏幕，很容易看到每个独立的彩色块。

第二个模数转换的例子是声音，尤其是音乐。之所以说音乐是个不错的例子，原因在于以它为代表的数字信息的所有权，第一次引起了社会、经济和法律上的广泛关注。数字音乐与唱片或磁带不同，你可以在自己家的计算机里无限次地复制它，完全免费，而且还可以通过互联网把它复制发送到世界的任何角落，不会有任何音质损失，同样完全免费。唱片业把这当成了严重的威胁，试图通过法律或政治手段阻止数字音乐的拷贝。

什么是声音？音源通过振动或快速运动引起空气压力的波动，人的耳朵把这种压力变化转换为神经活动，经大脑解释之后就形成了「声音」。1870 年代，托马斯·爱迪生制造了一个叫做「留声机」的机器，这台机器能把声波转换为蜡筒上类似的螺旋沟槽，而通过这些沟槽又能再次创造出同样的气压波动来。把声音转换为沟槽就是「录音」，而从沟槽换回到气压波动就是「回放」。爱迪生的发明迅速地得到改进，1940 年代就出现了密纹唱片（long-playing record）或简称 LP，而且至今还在使用（尽管数量已经不多了）。麦克风随着时间推移把变化的声压转换为变化的值并记录下来，然后根据这些值在乙烯基的盘片上压制出与声压一致的螺旋沟槽。播放 LP 时，唱针随着沟槽起伏，其运动轨迹被转换为波动的电流，电流经过放大后驱动扬声器或耳机，通过它们的振动薄膜产生声音。

把空气压力随时间的变化形象地绘制出来并不难。其中压力可以用任何物理方法来表示，在此我们假设用电路中的电压。当然，电流、光的亮度，以及爱迪生发明的留声机中的纯机制装置都没有问题。

图中声波的高度表示声音强度或大小，水平方向的坐标轴表示时间：每秒钟声波的数量就是声调或频率。假设我们以固定时间间隔连续测量这条曲线的高度（在这里就是电压值），就会得到下图所示的这些垂直线条。

测量得到的数值连接起来与曲线近似，测量越频繁，越准确，结果也就越吻合。测量得到的数值序列是波形的数字化表示，可以存储、复制、操作它们，也可以把它们发送到任何地方。如果有设备把这些数值转换成对应的电压或电流，然后再通过电压或电流驱动音箱或耳机，就能够实现回放。从声波到数值是模数转换，相应的设备叫 A/D 转换器；反过来当然是数模转换，或者叫 D/A。转换过程并不是完美无缺的，两个方向的转换都会损失一点信息。但大多数情况下，这种损失是人所觉察不到的。

与 LP 唱片上的模拟沟槽不同，CD 用长长的螺旋状轨道在盘面的一侧记录数值。轨道上任意一个区块的表面要么平滑，要么是一个微小的凹坑。这些下凹或平滑的区块就是用来编码声波的数字值的，每个区块是一位，连续的多位表示二进制编码中的一个数值。光盘旋转时，一束激光照射到轨道上，而光电传感器则检测每个区块上反射回来的光量多少。如果光量不多，说明是凹坑；如果反射光很强，说明不是凹坑。标准 CD 编码采样率为每秒 44 100 次，而每次采样获得两个振幅值（立体声的左、右声道），精确度为 65 536（即 216，这并非巧合）分之一。轨道上的每个区块非常非常小，小到只有用显微镜才能看见，一张 CD 的表面上有 60 亿个小区块。（DVD 中的区块更小，由于区块更小，激光束频率更高，DVD 的存储容量近 5GB，而 CD 大约为 700MB。）

音频 CD 的出现几乎让 LP 没有了立足之地，相比之下，CD 的优点实在太多了：落上点灰尘也不用太担心了，更没有磨损一说，而且绝对小巧。但到了我写这本书的时候，LP 开始在某种程度上复苏，流行音乐 CD 的人气则日渐衰退。有朝一日，CD 很可能也会像 LP 一样变成古董，这倒让我很高兴，因为我收藏的音乐全部都是 CD 格式的。我现在完全拥有它们，而它们的存在将比我的生命更久远。CD 还有第二个用途，那就是作为存储、分发软件及数据的介质，不过这个功能已经被 DVD 取代，而 DVD 很可能又会被下载所取代。

声音和图片经常会被压缩，因为这两种媒体包含很多人类根本感知不到的细节。对于音乐，典型的压缩技术是 MP3，大约能把音频文件的体积压缩到原来的十分之一，同时几乎让人感觉不到音质下降。对于图片，最常用的压缩技术是 JPEG（是制定该标准的联合图像专家组 ——Joint Photographic Experts Group 的英文字头），它的压缩率也能达到 10 倍甚至更高。上文提到很多处理对数字信息能做，但对模拟信息却很难（或不可能），压缩就是一个例子。

1870 年代，摄影师埃德沃德·迈布里奇向世人证明，快速连续地显示一系列静态图片能够创造出运动的错觉。今天，电影显示影像的速度是每秒 24 帧，而电视大约是 25 到 30 帧，这个速度足以让人的眼睛把顺序播放的影像感知为动画。而通过组合（并同步）声音和影像，就可以创造出数字电影。而利用压缩技术减少空间占用，则催生了包括 MPEG（代表 Moving Picture Experts Group）在内的标准电影格式。实际上，视频的表示要比单纯的音频表示更复杂，一方面是它本身就复杂，另一方面很大程度上还因为它受到了电视的拖累，而电视在其存在的大部分时间内都是模拟的。模拟电视在世界范围内正逐渐被淘汰，而美国 2009 年已经将广播电视切换成了数字信号。

还有一些信息很方便以数字形式来表示，因为除了想好如何表示它之外，根本不需要做什么转换。比如这本书中的文字、字母、数字和标点符号，我们称为其普通文本。可以为其中每个字母指定一个唯一的数值，如 A 是 1，B 是 2 等等，这不就是一种数字化表示方法嘛。而事实也正是如此，只不过在表示标准中，A 到 Z 用的是 65 到 90，a 到 z 用的是 97 到 122，数字 0 到 9 用的是 48 到 57，而标点符号等其他字符用的是其他数值。这个表示标准叫做 ASCII，即 American Standard Code for Information Interchange（美国信息交换标准代码）。

不同地区有不同的字符集标准，但也有一个世界通用的标准叫 Unicode，它为所有语言的所有字符都规定了一个唯一的数值。这是一个非常庞大的字符集，人类的创造力是无穷无尽的，但在建立自身书写系统方面却很少有规则。目前，Unicode 涵盖的字符远远超过 100 000 个，而且这个数字还在稳步增长。可想而知，Unicode 中的大部分都是包括中文在内的亚洲字符集，但决不限于此。要了解 Unicode 都包含哪些字符集，可以访问 unicode.org，这个站点内容丰富。

3『[Unicode – The World Standard for Text and Emoji](https://home.unicode.org/) 和 [Overview – Unicode](https://home.unicode.org/basic-info/overview/)』

 表示数字信息的最基本单位是比特（bit）。英文 bit 是合并 binary digit（二进制数字）之后造出来的，造这个词的人是统计学家约翰·图基，时间是 1940 年代中期。（图基还在 1958 年发明了单词 software—— 软件。）
 
 一个比特表示开 / 关、真 / 假之类的二选一的情形没有问题，但我们经常还要面对更多选项，表示更复杂的事物。为此，可以使用一组比特，然后为不同的 0 和 1 的组合赋予不同的含义。比如，可以用两个比特来表示大学四年：新生（00）、大二（01）、大三（10）和毕业班（11）。如果再多考虑一种情况，比如研究生，那两个比特就不够用了，因为两个比特只有 4 种组合，没有第五种可能。但是三个比特没问题，实际上三个比特能表示 8 种不同的情况，这样我们就可以把教师、教工和博士后都包含进来。三个比特的全部组合为：000、001、010、011、100、101、110 和 111。比特数与它们所能表示的情况数之间有一个关系，很简单：N 个比特能表示 2^N 种组合，即 2×2×2…×2（乘 N 次）。
 
 由于计算机中的一切都是以二进制形式来处理，因此像大小、容量等概念一般都是用 2 的几次幂来表达的。如果有 N 比特，那么就有 2^N 种可能的值，所以知道 2 的幂是多少（比如到 2^10）是很有用的。但随着数值越来越大，完全记住它们也没有什么必要。好在有一种简便的方法，可以得到它们的近似值：2 的某次幂与 10 的某次幂接近，它们的对应关系严格有序，容易记忆.
 
 1『2 的 10 次方、20 次方、30 次方、40 次方、50 次方（每个幕隔 10 次方），分别对应于 10 的 3 次方、6 次方、9 次方、12 次方、15 次方（每个幕隔 3 次方）。这个真是相当的有趣啊，哈哈。』
 
 （这个对照表最后包含的表示大小的单位叫「拍」或 10^15，其英文单词发音不是「皮」而是「拍」。另外，书后附有一个更全的词汇表，列出了更多单位。）随着数值增长，这个近似值的误差也会增大，不过到了 10^15 这么大的时候误差也就 12.6%，所以还是可以在很大范围内使用的。经常会有人混淆上述 2 的幂与 10 的幂之间的关系（有时候是想用来支持他们的观点），于是 kilo 或 1K 可能是指 1000，但也可能指 2^10 即 1024。一般来说，这种混淆导致的误差并不大，因此在涉及很大的比特数时，用 2 和 10 的幂来做心算没什么问题。
 
 在所有现代计算机中，数据处理及内存组织的基本单位都是 8 个比特。8 比特被称为 1 字节，而字节（byte）这个词是由 IBM 的计算机设计师维尔纳·巴克霍尔兹（Werner Buchholz）在 1956 年发明的。一个字节可以编码 256 个不同的值（28，即 8 个 0 和 1 的所有不同组合），这个值可以是一个 0 到 255 间的整数，也可以是 ASCII 字符集中的一个字符，或者其他什么。通常，为了表示更大或更复杂的数据，需要用到多个字节的字节组。两个字节有 16 比特，也就是 16 位，可以表示 0 到 2^16-1（65 535）之间的数值。两个字节也可以表示 Unicode 字符集中的一个字符。
 
 1『Unicode 字符是 16 位编码的。』
 
 这是两个字符，即「东京」，每个字符占两个字节。四个字节是 32 位，既可以表示「东京」，也可以表示最大直至 2^32-1 的值，这个最大值大约是 43 亿。用一组字节表示什么都可以，但 CPU 自己特别定义了一些适中的字节组（比如表示不同大小的整数），以及处理这些字节组的指令。

二进制写起来太长了，比十进制格式长三倍还多，因此我们常用另一种替代数制，即十六进制。十六进制的基数是 16，因此也就有 16 个数字（就像十进制有 10 个数字，二进制有 2 个数字一样），分别是 0、1、…、9、A、B、C、D、E、F。每个十六进制数字表示 4 个比特，对于一般的数值，十六进制 0 相当于二进制 0000，依此类推，十六进制 9 相当于二进制 1001。接下去，十六进制 A 相当于二进制 1010（十进制 10），十六进制 B 相当于二进制 1011（十进制 11），依此类推，十六进制 F 相当于二进制 1111（十进制 15）。

除非你是程序员，否则能看到十六进制数的机会并不多。一个例子就是网页中的颜色值。前面说过，计算机中一个像素的颜色值大都使用三个字节来表示，一个表示红色分量，一个表示绿色分量，最后一个表示蓝色分量，这就是所谓的 RGB 编码。红绿蓝三个组分分别用一个字节表示，因此红色分量就有 256 种可能的值，三个组分中的绿色分量也有 256 种可能的值，同样，三个组分中的蓝色分量也有 256 种可能的值。于是一个像素可能的颜色值就是 256×256×256 种，听起来好多啊。我们可以用 2 和 10 的幂来简单估计一下这个数有多大。这个数是 2^8×2^8×2^8，即 2^24 或 2^4×2^20，大约是 16×10^6，即 1600 万。在描述计算机显示器的情况下，你可能听说过这个数（超过 1600 万种颜色！）。

一个深红色的像素可以表示为 FF0000，换句话说，就是红色分量最多，没有绿色和蓝色；而一个鲜蓝色（并非深蓝色），即类似很多网页中链接的颜色，可以表示为 0000CC。黄色是红加绿，因此 FFFF00 就是最深的黄色。阴影的灰色具有等量的红、绿、蓝组分，因此一个中等灰度的像素应该是 808080，也就是红、绿、蓝组分的数量都相等。黑色和白色分别是 000000 和 FFFFFF。

有时候，在某计算机的广告中，我们会看到「64 位」这个说法（Windows 7 家庭高级版 64 位）。什么意思呢？计算机在内部操作数据时，是以不同大小的块为单位的，这些块包含数值（32 位和 64 位表示数值比较方便）和地址，而地址也就是信息在 RAM 中的位置。前面所说的 64 位，指就是地址。大约 25 年前，16 位地址升级到了 32 位地址（足够访问 4GB 的 RAM），而现在 32 位又升级到 64 位。我不想预测什么时候会从 64 变成 128，总得过上好一阵子吧，先不必想那么多。

1『解答了很早之前的一个疑问。电脑多少位指的是地址的编码位数。』

关于比特和字节，我们讨论到现在最重要的是必须知道，一组比特的含义取决于它们的上下文，光看这些比特看不出来。一个字节可以只用 1 个比特来表示男或女，另外 7 个空闲不用，也可以用来保存一个不大的整数，或者一个 # 之类的 ASCII 字符，它还可能是另一种书写系统中一个字符的一部分，或者用 2、4 或 8 个字节表示的一个大数的一部分，一张照片或一段音乐的一部分，甚至是供 CPU 执行的一条指令的一部分。

事实上，一个程序的指令就是另一个程序的数据。从网上下载一个新程序，或者从 CD-ROM 或 DVD 中安装该程序时，它就是数据，所有比特将无一例外地被复制一遍。但在运行这个程序时，它的比特会被当成指令，CPU 在处理这些比特时，又会把它们当成数据。

## 03. 深入了解 CPU

### 1. 逻辑脉络




### 2. 摘录及评论









