1.1 计算机视觉（Computer vision）

欢迎参加这次的卷积神经网络课程，计算机视觉是一个飞速发展的一个领域，这多亏了 深度学习。深度学习与计算机视觉可以帮助汽车，查明周围的行人和汽车，并帮助汽车避开 它们。还使得人脸识别技术变得更加效率和精准，你们即将能够体验到或早已体验过仅仅通 过刷脸就能解锁手机或者门锁。当你解锁了手机，我猜手机上一定有很多分享图片的应用。在上面，你能看到美食，酒店或美丽风景的图片。有些公司在这些应用上使用了深度学习技 术来向你展示最为生动美丽以及与你最为相关的图片。机器学习甚至还催生了新的艺术类 型。深度学习之所以让我兴奋有下面两个原因，我想你们也是这么想的。

第一，计算机视觉的高速发展标志着新型应用产生的可能，这是几年前，人们所不敢想 象的。通过学习使用这些工具，你也许能够创造出新的产品和应用。

其次，即使到头来你未能在计算机视觉上有所建树，但我发现，人们对于计算机视觉的 研究是如此富有想象力和创造力，由此衍生出新的神经网络结构与算法，这实际上启发人们 去创造出计算机视觉与其他领域的交叉成果。举个例子，之前我在做语音识别的时候，我经 常从计算机视觉领域中寻找灵感，并将其应用于我的文献当中。所以即使你在计算机视觉 方面没有做出成果，我也希望你也可以将所学的知识应用到其他算法和结构。就介绍到这儿，让我们开始学习吧。

这是我们本节课将要学习的一些问题，你应该早就听说过图片分类，或者说图片识别。

341 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

比如给出这张 64×64 的图片，让计算机去分辨出这是一只猫。

还有一个例子，在计算机视觉中有个问题叫做目标检测，比如在一个无人驾驶项目中，你不一定非得识别出图片中的物体是车辆，但你需要计算出其他车辆的位置，以确保自己能 够避开它们。所以在目标检测项目中，首先需要计算出图中有哪些物体，比如汽车，还有图 片中的其他东西，再将它们模拟成一个个盒子，或用一些其他的技术识别出它们在图片中的 位置。注意在这个例子中，在一张图片中同时有多个车辆，每辆车相对与你来说都有一个确 切的距离。

还有一个更有趣的例子，就是神经网络实现的图片风格迁移，比如说你有一张图片，但 你想将这张图片转换为另外一种风格。所以图片风格迁移，就是你有一张满意的图片和一张 风格图片，实际上右边这幅画是毕加索的画作，而你可以利用神经网络将它们融合到一起，描绘出一张新的图片。它的整体轮廓来自于左边，却是右边的风格，最后生成下面这张图片。这种神奇的算法创造出了新的艺术风格，所以在这门课程中，你也能通过学习做到这样的事 情。

但在应用计算机视觉时要面临一个挑战，就是数据的输入可能会非常大。举个例子，在

342 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

过去的课程中，你们一般操作的都是 64×64 的小图片，实际上，它的数据量是 64×64×3，因 为每张图片都有 3 个颜色通道。如果计算一下的话，可得知数据量为 12288，所以我们的特 征向量𝑥维度为 12288。这其实还好，因为 64×64 真的是很小的一张图片。

如果你要操作更大的图片，比如一张 1000×1000 的图片，它足有 1 兆那么大，但是特征 向量的维度达到了 1000×1000×3，因为有 3 个 RGB 通道，所以数字将会是 300 万。如果你 在尺寸很小的屏幕上观察，可能察觉不出上面的图片只有 64×64 那么大，而下面一张是 1000×1000 的大图。

如果你要输入 300 万的数据量，这就意味着，特征向量𝑥的维度高达 300 万。所以在第 一隐藏层中，你也许会有 1000 个隐藏单元，而所有的权值组成了矩阵 𝑊 [1] 。如果你使用了 标准的全连接网络，就像我们在第一门和第二门的课程里说的，这个矩阵的大小将会是 1000×300 万。因为现在𝑥的维度为 3𝑚，3𝑚通常用来表示 300 万。这意味着矩阵𝑊 [1] 会有 30 亿个参数，这是个非常巨大的数字。在参数如此大量的情况下，难以获得足够的数据来防止 神经网络发生过拟合和竞争需求，要处理包含 30 亿参数的神经网络，巨大的内存需求让人 不太能接受。

343 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

但对于计算机视觉应用来说，你肯定不想它只处理小图片，你希望它同时也要能处理大 图。为此，你需要进行卷积计算，它是卷积神经网络中非常重要的一块。下节课中，我会为 你介绍如何进行这种运算，我将用边缘检测的例子来向你说明卷积的含义。

344 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.2 边缘检测示例（Edge detection example）

卷积运算是卷积神经网络最基本的组成部分，使用边缘检测作为入门样例。在这个视频 中，你会看到卷积是如何进行运算的。

在之前的视频中，我说过神经网络的前几层是如何检测边缘的，然后，后面的层有可能 检测到物体的部分区域，更靠后的一些层可能检测到完整的物体，这个例子中就是人脸。在 这个视频中，你会看到如何在一张图片中进行边缘检测。

让我们举个例子，给了这样一张图片，让电脑去搞清楚这张照片里有什么物体，你可能 做的第一件事是检测图片中的垂直边缘。比如说，在这张图片中的栏杆就对应垂直线，与此 同时，这些行人的轮廓线某种程度上也是垂线，这些线是垂直边缘检测器的输出。同样，你 可能也想检测水平边缘，比如说这些栏杆就是很明显的水平线，它们也能被检测到，结果在 这。所以如何在图像中检测这些边缘？

看一个例子，这是一个 6×6 的灰度图像。因为是灰度图像，所以它是 6×6×1 的矩阵，而 不是 6×6×3 的，因为没有 RGB 三通道。为了检测图像中的垂直边缘，你可以构造一个 3×3 矩阵。在共用习惯中，在卷积神经网络的术语中，它被称为过滤器。我要构造一个 3×3 的过

345 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1 滤器，像这样 [ 1 1

−1 −1 ]。在论文它有时候会被称为核，而不是过滤器，但在这个视频中，−1 我将使用过滤器这个术语。对这个 6×6 的图像进行卷积运算，卷积运算用「∗」来表示，用 3×3 的过滤器对其进行卷积。

0 0 0 

关于符号表示，有一些问题，在数学中「∗」就是卷积的标准标志，但是在 Python 中，这 个标识常常被用来表示乘法或者元素乘法。所以这个「∗」有多层含义，它是一个重载符号，在这个视频中，当「∗」表示卷积的时候我会特别说明。

这个卷积运算的输出将会是一个 4×4 的矩阵，你可以将它看成一个 4×4 的图像。下面来 说明是如何计算得到这个 4×4 矩阵的。为了计算第一个元素，在 4×4 左上角的那个元素，使 用 3×3 的过滤器，将其覆盖在输入图像，如下图所示。然后进行元素乘法（element-wise 3 0 −1 products）运算，所以 [1 × 1 5 × 0 8 × (−1) ] = [1 0 −8]，然后将该矩阵每个元素相加 2 0 −2

3 × 1 0 × 0 1 × (1) 

2 × 1 7 × 0 2 × (−1) 

346 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

得到最左上角的元素，即 3 + 1 + 2 + 0 + 0 + 0 + (−1) + (−8) + (−2) = −5。

把这 9 个数加起来得到 - 5，当然，你可以把这 9 个数按任何顺序相加，我只是先写了第 一列，然后第二列，第三列。

接下来，为了弄明白第二个元素是什么，你要把蓝色的方块，向右移动一步，像这样，把这些绿色的标记去掉：

继续做同样的元素乘法，然后加起来，所以是 0 × 1 + 5 × 1 + 7 × 1 + 1 × 0 + 8 × 0 +

2 × 0 + 2 × (−1) + 9 × (−1) + 5 × (−1) = −4。

347 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

接下来也是一样，继续右移一步，把 9 个数的点积加起来得到 0。

继续移得到 8，验证一下：2 × 1 + 9 × 1 + 5 × 1 + 7 × 0 + 3 × 0 + 1 × 0 + 4 × (−1) +

1 × (−1) + 3 × (−1) = 8。

接下来为了得到下一行的元素，现在把蓝色块下移，现在蓝色块在这个位置：

348 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

重复进行元素乘法，然后加起来。通过这样做得到 - 10。再将其右移得到 - 2，接着是 2，3。以此类推，这样计算完矩阵中的其他元素。

为了说得更清楚一点，这个 - 16 是通过底部右下角的 3×3 区域得到的。因此 6×6 矩阵和 3×3 矩阵进行卷积运算得到 4×4 矩阵。这些图片和过滤器是不同维度 的矩阵，但左边矩阵容易被理解为一张图片，中间的这个被理解为过滤器，右边的图片我们 可以理解为另一张图片。这个就是垂直边缘检测器，下一页中你就会明白。

在往下讲之前，多说一句，如果你要使用编程语言实现这个运算，不同的编程语言有不 同的函数，而不是用「∗」来表示卷积。所以在编程练习中，你会使用一个叫 conv_forward 的 函数。如果在 tensorflow 下，这个函数叫 tf.conv2d。在其他深度学习框架中，在后面的课程 中，你将会看到 Keras 这个框架，在这个框架下用 Conv2D 实现卷积运算。所有的编程框架 都有一些函数来实现卷积运算。

349 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

为什么这个可以做垂直边缘检测呢？让我们来看另外一个例子。为了讲清楚，我会用一 个简单的例子。这是一个简单的 6×6 图像，左边的一半是 10，右边一般是 0。如果你把它当 成一个图片，左边那部分看起来是白色的，像素值 10 是比较亮的像素值，右边像素值比较 暗，我使用灰色来表示 0，尽管它也可以被画成黑的。图片里，有一个特别明显的垂直边缘 在图像中间，这条垂直线是从黑到白的过渡线，或者从白色到深色。

所以，当你用一个 3×3 过滤器进行卷积运算的时候，这个 3×3 的过滤器可视化为下面这 个样子，在左边有明亮的像素，然后有一个过渡，0 在中间，然后右边是深色的。卷积运算 后，你得到的是右边的矩阵。如果你愿意，可以通过数学运算去验证。举例来说，最左上角 的元素 0，就是由这个 3×3 块（绿色方框标记）经过元素乘积运算再求和得到的，10 × 1 +

10 × 1 + 10 × 1 + 10 × 0 + 10 × 0 + 10 × 0 + 10 × (−1) + 10 × (−1) + 10 × (−1) = 0 

。相反这个 30 是由这个（红色方框标记）得到的，

10 × 1 + 10 × 1 + 10 × 1 + 10 × 0 + 10 × 0 + 10 × 0 + 0 × (−1) + 0 × (−1) + 0 × 

(−1) = 30。

350 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

如果把最右边的矩阵当成图像，它是这个样子。在中间有段亮一点的区域，对应检查到 这个 6×6 图像中间的垂直边缘。这里的维数似乎有点不正确，检测到的边缘太粗了。因为在 这个例子中，图片太小了。如果你用一个 1000×1000 的图像，而不是 6×6 的图片，你会发现 其会很好地检测出图像中的垂直边缘。在这个例子中，在输出图像中间的亮处，表示在图像 中间有一个特别明显的垂直边缘。从垂直边缘检测中可以得到的启发是，因为我们使用 3×3 的矩阵（过滤器），所以垂直边缘是一个 3×3 的区域，左边是明亮的像素，中间的并不需要 考虑，右边是深色像素。在这个 6×6 图像的中间部分，明亮的像素在左边，深色的像素在右 边，就被视为一个垂直边缘，卷积运算提供了一个方便的方法来发现图像中的垂直边缘。

所以你已经了解卷积是怎么工作的，在下一个视频中，你将会看到如何使用卷积运算作 为卷积神经网络的基本模块的。

351 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.3 更多边缘检测内容（More edge detection）

你已经见识到用卷积运算实现垂直边缘检测，在本视频中，你将学习如何区分正边和负 边，这实际就是由亮到暗与由暗到亮的区别，也就是边缘的过渡。你还能了解到其他类型的 边缘检测以及如何去实现这些算法，而不要总想着去自己编写一个边缘检测程序，让我们开 始吧。

还是上一个视频中的例子，这张 6×6 的图片，左边较亮，而右边较暗，将它与垂直边缘 检测滤波器进行卷积，检测结果就显示在了右边这幅图的中间部分。

现在这幅图有什么变化呢？它的颜色被翻转了，变成了左边比较暗，而右边比较亮。现 在亮度为 10 的点跑到了右边，为 0 的点则跑到了左边。如果你用它与相同的过滤器进行卷 积，最后得到的图中间会是 - 30，而不是 30。如果你将矩阵转换为图片，就会是该矩阵下面 图片的样子。现在中间的过渡部分被翻转了，之前的 30 翻转成了 - 30，表明是由暗向亮过渡，而不是由亮向暗过渡。

如果你不在乎这两者的区别，你可以取出矩阵的绝对值。但这个特定的过滤器确实可以 为我们区分这两种明暗变化的区别。

再来看看更多的边缘检测的例子，我们已经见过这个 3×3 的过滤器，它可以检测出垂直 的边缘。所以，看到右边这个过滤器，我想你应该猜出来了，它能让你检测出水平的边缘。提醒一下，一个垂直边缘过滤器是一个 3×3 的区域，它的左边相对较亮，而右边相对较暗。

352 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

相似的，右边这个水平边缘过滤器也是一个 3×3 的区域，它的上边相对较亮，而下方相对较 暗。

这里还有个更复杂的例子，左上方和右下方都是亮度为 10 的点。如果你将它绘成图片，右上角是比较暗的地方，这边都是亮度为 0 的点，我把这些比较暗的区域都加上阴影。而左 上方和右下方都会相对较亮。如果你用这幅图与水平边缘过滤器卷积，就会得到右边这个矩 阵。

再举个例子，这里的 30（右边矩阵中绿色方框标记元素）代表了左边这块 3×3 的区域 （左边矩阵绿色方框标记部分），这块区域确实是上边比较亮，而下边比较暗的，所以它在 这里发现了一条正边缘。而这里的 - 30（右边矩阵中紫色方框标记元素）又代表了左边另一 块区域（左边矩阵紫色方框标记部分），这块区域确实是底部比较亮，而上边则比较暗，所 以在这里它是一条负边。

再次强调，我们现在所使用的都是相对很小的图片，仅有 6×6。但这些中间的数值，比 如说这个 10（右边矩阵中黄色方框标记元素）代表的是左边这块区域（左边 6×6 矩阵中黄 色方框标记的部分）。这块区域左边两列是正边，右边一列是负边，正边和负边的值加在一

353 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

起得到了一个中间值。但假如这个一个非常大的 1000×1000 的类似这样棋盘风格的大图，就 不会出现这些亮度为 10 的过渡带了，因为图片尺寸很大，这些中间值就会变得非常小。总而言之，通过使用不同的过滤器，你可以找出垂直的或是水平的边缘。但事实上，对 于这个 3×3 的过滤器来说，我们使用了其中的一种数字组合。

但在历史上，在计算机视觉的文献中，曾公平地争论过怎样的数字组合才是最好的，所 1 0 −1 以你还可以使用这种：[2 0 −2]，叫做 Sobel 的过滤器，它的优点在于增加了中间一行元 1 0 −1 素的权重，这使得结果的鲁棒性会更高一些。3 0 −3

但计算机视觉的研究者们也会经常使用其他的数字组合，比如这种：[10 0 −10]，3 0 −3

这叫做 Scharr 过滤器，它有着和之前完全不同的特性，实际上也是一种垂直边缘检测，如果 你将其翻转 90 度，你就能得到对应水平边缘检测。随着深度学习的发展，我们学习的其中一件事就是当你真正想去检测出复杂图像的边缘，你不一定要去使用那些研究者们所选择的这九个数字，但你可以从中获益匪浅。把这矩阵中 的 9 个数字当成 9 个参数，并且在之后你可以学习使用反向传播算法，其目标就是去理解这 9 个参数。

当你得到左边这个 6×6 的图片，将其与这个 3×3 的过滤器进行卷积，将会得到一个出色 的边缘检测。这就是你在下节视频中将会看到的，把这 9 个数字当成参数的过滤器，通过反 1 0 −1 向传播，你可以学习这种 [1 0 −1] 的过滤器，或者 Sobel 过滤器和 Scharr 过滤器。还有另 1 0 −1 一种过滤器，这种过滤器对于数据的捕捉能力甚至可以胜过任何之前这些手写的过滤器。相

354 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

比这种单纯的垂直边缘和水平边缘，它可以检测出 45° 或 70° 或 73°，甚至是任何角度的边缘。所以将矩阵的所有数字都设置为参数，通过数据反馈，让神经网络自动去学习它们，我们会 发现神经网络可以学习一些低级的特征，例如这些边缘的特征。尽管比起那些研究者们，我 们要更费劲一些，但确实可以动手写出这些东西。不过构成这些计算的基础依然是卷积运算，使得反向传播算法能够让神经网络学习任何它所需要的 3×3 的过滤器，并在整幅图片上去 应用它。这里，这里，还有这里（左边矩阵蓝色方框标记部分），去输出这些，任何它所检 测到的特征，不管是垂直的边缘，水平的边缘，还有其他奇怪角度的边缘，甚至是其它的连 名字都没有的过滤器。所以这种将这 9 个数字当成参数的思想，已经成为计算机视觉中最为有效的思想之一。在接下来的课程中，也就是下个星期，我们将详细去探讨如何使用反向传播去让神经网络学 习这 9 个数字。但在此之前，我们需要先讨论一些其它细节，比如一些基础的卷积运算的变 量。在下面两节视频中，我将与你们讨论如何去使用 padding，以及卷积各种不同的发展，这两节内容将会是卷积神经网络中卷积模块的重要组成部分，所以我们下节视频再见。

355 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.4 Padding 

为了构建深度神经网络，你需要学会使用的一个基本的卷积操作就是 padding，让我们 来看看它是如何工作的。

我们在之前视频中看到，如果你用一个 3×3 的过滤器卷积一个 6×6 的图像，你最后会得 到一个 4×4 的输出，也就是一个 4×4 矩阵。那是因为你的 3×3 过滤器在 6×6 矩阵中，只可能 有 4×4 种可能的位置。这背后的数学解释是，如果我们有一个𝑛 × 𝑛的图像，用𝑓 × 𝑓的过滤 器做卷积，那么输出的维度就是 (𝑛 − 𝑓 + 1) × (𝑛 − 𝑓 + 1)。在这个例子里是 6 − 3 + 1 = 4，因此得到了一个 4×4 的输出。

这样的话会有两个缺点，第一个缺点是每次做卷积操作，你的图像就会缩小，从 6×6 缩 小到 4×4，你可能做了几次之后，你的图像就会变得很小了，可能会缩小到只有 1×1 的大小。你可不想让你的图像在每次识别边缘或其他特征时都缩小，这就是第一个缺点。

第二个缺点时，如果你注意角落边缘的像素，这个像素点（绿色阴影标记）只被一个输 出所触碰或者使用，因为它位于这个 3×3 的区域的一角。但如果是在中间的像素点，比如这 个（红色方框标记），就会有许多 3×3 的区域与之重叠。所以那些在角落或者边缘区域的像 素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。

356 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

为了解决这两个问题，一是输出缩小。当我们建立深度神经网络时，你就会知道你为什 么不希望每进行一步操作图像都会缩小。比如当你有 100 层深层的网络，如果图像每经过一 层都缩小的话，经过 100 层网络后，你就会得到一个很小的图像，所以这是个问题。另一个 问题是图像边缘的大部分信息都丢失了。

为了解决这些问题，你可以在卷积操作之前填充这幅图像。在这个案例中，你可以沿着 图像边缘再填充一层像素。如果你这样操作了，那么 6×6 的图像就被你填充成了一个 8×8 的 图像。如果你用 3×3 的图像对这个 8×8 的图像卷积，你得到的输出就不是 4×4 的，而是 6×6 的图像，你就得到了一个尺寸和原始图像 6×6 的图像。习惯上，你可以用 0 去填充，如果𝑝 是填充的数量，在这个案例中，𝑝 = 1，因为我们在周围都填充了一个像素点，输出也就变 成了 (𝑛 + 2𝑝 − 𝑓 + 1) × (𝑛 + 2𝑝 − 𝑓 + 1)，所以就变成了 (6 + 2 × 1 − 3 + 1) × (6 + 2 × 1 3 + 1) = 6 × 6，和输入的图像一样大。这个涂绿的像素点（左边矩阵）影响了输出中的这些 格子（右边矩阵）。这样一来，丢失信息或者更准确来说角落或图像边缘的信息发挥的作用 较小的这一缺点就被削弱了。

刚才我已经展示过用一个像素点来填充边缘，如果你想的话，也可以填充两个像素点，也就是说在这里填充一层。实际上你还可以填充更多像素。我这里画的这种情况，填充后𝑝 = 2。

357 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

至于选择填充多少像素，通常有两个选择，分别叫做 Valid 卷积和 Same 卷积。Valid 卷积意味着不填充，这样的话，如果你有一个𝑛 × 𝑛的图像，用一个𝑓 × 𝑓的过滤器 卷积，它将会给你一个 (𝑛 − 𝑓 + 1) × (𝑛 − 𝑓 + 1) 维的输出。这类似于我们在前面的视频中展 示的例子，有一个 6×6 的图像，通过一个 3×3 的过滤器，得到一个 4×4 的输出。

另一个经常被用到的填充方法叫做 Same 卷积，那意味你填充后，你的输出大小和输入 大小是一样的。根据这个公式𝑛 − 𝑓 + 1，当你填充𝑝个像素点，𝑛就变成了𝑛 + 2𝑝，最后公式 变为𝑛 + 2𝑝 − 𝑓 + 1。因此如果你有一个𝑛 × 𝑛的图像，用𝑝个像素填充边缘，输出的大小就 是这样的 (𝑛 + 2𝑝 − 𝑓 + 1) × (𝑛 + 2𝑝 − 𝑓 + 1)。如果你想让𝑛 + 2𝑝 − 𝑓 + 1 = 𝑛的话，使得输

出和输入大小相等，如果你用这个等式求解𝑝，那么𝑝 = (𝑓 − 1)/2。所以当𝑓是一个奇数的时 候，只要选择相应的填充尺寸，你就能确保得到和输入相同尺寸的输出。这也是为什么前面 的例子，当过滤器是 3×3 时，和上一张幻灯片的例子一样，使得输出尺寸等于输入尺寸，所 需要的填充是 (3-1)/2，也就是 1 个像素。另一个例子，当你的过滤器是 5×5，如果𝑓 = 5，然

358 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

后代入那个式子，你就会发现需要 2 层填充使得输出和输入一样大，这是过滤器 5×5 的情 况。

习惯上，计算机视觉中，𝑓通常是奇数，甚至可能都是这样。你很少看到一个偶数的过 滤器在计算机视觉里使用，我认为有两个原因。

其中一个可能是，如果𝑓是一个偶数，那么你只能使用一些不对称填充。只有𝑓是奇数的 情况下，Same 卷积才会有自然的填充，我们可以以同样的数量填充四周，而不是左边填充 多一点，右边填充少一点，这样不对称的填充。

第二个原因是当你有一个奇数维过滤器，比如 3×3 或者 5×5 的，它就有一个中心点。有 时在计算机视觉里，如果有一个中心像素点会更方便，便于指出过滤器的位置。

也许这些都不是为什么𝑓通常是奇数的充分原因，但如果你看了卷积的文献，你经常会 看到 3×3 的过滤器，你也可能会看到一些 5×5，7×7 的过滤器。后面我们也会谈到 1×1 的过 滤器，以及什么时候它是有意义的。但是习惯上，我推荐你只使用奇数的过滤器。我想如果 你使用偶数 f 也可能会得到不错的表现，如果遵循计算机视觉的惯例，我通常使用奇数值的 𝑓。

你已经看到如何使用 padding 卷积，为了指定卷积操作中的 padding，你可以指定𝑝的 值。也可以使用 Valid 卷积，也就是𝑝 = 0。也可使用 Same 卷积填充像素，使你的输出和输 入大小相同。以上就是 padding，在接下来的视频中我们讨论如何在卷积中设置步长。

359 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.5 卷积步长（Strided convolutions）

卷积中的步幅是另一个构建卷积神经网络的基本操作，让我向你展示一个例子。

如果你想用 3×3 的过滤器卷积这个 7×7 的图像，和之前不同的是，我们把步幅设置成了 2。你还和之前一样取左上方的 3×3 区域的元素的乘积，再加起来，最后结果为 91。

只是之前我们移动蓝框的步长是 1，现在移动的步长是 2，我们让过滤器跳过 2 个步长，注意一下左上角，这个点移动到其后两格的点，跳过了一个位置。然后你还是将每个元素相 乘并求和，你将会得到的结果是 100。

360 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

现在我们继续，将蓝色框移动两个步长，你将会得到 83 的结果。当你移动到下一行的 时候，你也是使用步长 2 而不是步长 1，所以我们将蓝色框移动到这里：

注意到我们跳过了一个位置，得到 69 的结果，现在你继续移动两个步长，会得到 91，127，最后一行分别是 44，72，74。

所以在这个例子中，我们用 3×3 的矩阵卷积一个 7×7 的矩阵，得到一个 3×3 的输出。输 入和输出的维度是由下面的公式决定的。如果你用一个𝑓 × 𝑓的过滤器卷积一个𝑛 × 𝑛的图像，你的 padding 为𝑝，步幅为𝑠，在这个例子中𝑠 = 2，你会得到一个输出，因为现在你不是一 次移动一个步子，而是一次移动𝑠个步子，输出于是变为 𝑛+2𝑝−𝑓 𝑠 + 1 × 𝑛+2𝑝−𝑓 𝑠 + 1

361 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

在我们的这个例子里，𝑛 = 7，𝑝 = 0，𝑓 = 3，𝑠 = 2，7+0−3 + 1 = 3，即 3×3 的输出。

2 

现在只剩下最后的一个细节了，如果商不是一个整数怎么办？在这种情况下，我们向下 取整。⌊ ⌋这是向下取整的符号，这也叫做对𝑧进行地板除 (floor)，这意味着𝑧向下取整到最近 的整数。这个原则实现的方式是，你只在蓝框完全包括在图像或填充完的图像内部时，才对 它进行运算。如果有任意一个蓝框移动到了外面，那你就不要进行相乘操作，这是一个惯例。你的 3×3 的过滤器必须完全处于图像中或者填充之后的图像区域内才输出相应结果，这就 是惯例。因此正确计算输出维度的方法是向下取整，以免𝑛+2𝑝−𝑓 不是整数。

𝑠 

总结一下维度情况，如果你有一个𝑛 × 𝑛的矩阵或者𝑛 × 𝑛的图像，与一个𝑓 × 𝑓的矩阵卷

积，或者说𝑓 × 𝑓的过滤器。Padding 是𝑝，步幅为𝑠没输出尺寸就是这样：

362 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

可以选择所有的数使结果是整数是挺不错的，尽管一些时候，你不必这样做，只要向下 取整也就可以了。你也可以自己选择一些𝑛，𝑓，𝑝和𝑠的值来验证这个输出尺寸的公式是对 的。

在讲下一部分之前，这里有一个关于互相关和卷积的技术性建议，这不会影响到你构建 卷积神经网络的方式，但取决于你读的是数学教材还是信号处理教材，在不同的教材里符号 可能不一致。如果你看的是一本典型的数学教科书，那么卷积的定义是做元素乘积求和，实 际上还有一个步骤是你首先要做的，也就是在把这个 6×6 的矩阵和 3×3 的过滤器卷积之前，3 4 5 7 2 5 首先你将 3×3 的过滤器沿水平和垂直轴翻转，所以 [1 0 2] 变为 [9 0 4]，这相当于 −1 9 7 −1 1 3 将 3×3 的过滤器做了个镜像，在水平和垂直轴上（整理者注：此处应该是先顺时针旋转 90

−1 1 3 7 2 5 得到 [9 0 4]，再水平翻转得到 [9 0 4]）。然后你再把这个翻转后的矩阵复制到这

7 2 5 −1 1 3 

363 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

里（左边的图像矩阵），你要把这个翻转矩阵的元素相乘来计算输出的 4×4 矩阵左上角的元 素，如图所示。然后取这 9 个数字，把它们平移一个位置，再平移一格，以此类推。

所以我们在这些视频中定义卷积运算时，我们跳过了这个镜像操作。从技术上讲，我们 实际上做的，我们在前面视频中使用的操作，有时被称为互相关（cross-correlation）而不是 卷积（convolution）。但在深度学习文献中，按照惯例，我们将这（不进行翻转操作）叫做 卷积操作。

总结来说，按照机器学习的惯例，我们通常不进行翻转操作。从技术上说，这个操作可 能叫做互相关更好。但在大部分的深度学习文献中都把它叫做卷积运算，因此我们将在这些 视频中使用这个约定。如果你读了很多机器学习文献的话，你会发现许多人都把它叫做卷积 运算，不需要用到这些翻转。

事实证明在信号处理中或某些数学分支中，在卷积的定义包含翻转，使得卷积运算符拥 有这个性质，即 (𝐴 ∗ 𝐵) ∗ 𝐶 = 𝐴 ∗ (𝐵 ∗ 𝐶)，这在数学中被称为结合律。这对于一些信号处理 应用来说很好，但对于深度神经网络来说它真的不重要，因此省略了这个双重镜像操作，就 简化了代码，并使神经网络也能正常工作。

根据惯例，我们大多数人都叫它卷积，尽管数学家们更喜欢称之为互相关，但这不会影 响到你在编程练习中要实现的任何东西，也不会影响你阅读和理解深度学习文献。

现在你已经看到了如何进行卷积，以及如何使用填充，如何在卷积中选择步幅。但到目 前为止，我们所使用的是关于矩阵的卷积，例如 6×6 的矩阵。在下一集视频中，你将看到如 何对立体进行卷积，这将会使你的卷积变得更加强大，让我们继续下一个视频。

364 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.6 三维卷积（Convolutions over volumes）

你已经知道如何对二维图像做卷积了，现在看看如何执行卷积不仅仅在二维图像上，而 是三维立体上。

我们从一个例子开始，假如说你不仅想检测灰度图像的特征，也想检测 RGB 彩色图像 的特征。彩色图像如果是 6×6×3，这里的 3 指的是三个颜色通道，你可以把它想象成三个 6×6 图像的堆叠。为了检测图像的边缘或者其他的特征，不是把它跟原来的 3×3 的过滤器做卷 积，而是跟一个三维的过滤器，它的维度是 3×3×3，这样这个过滤器也有三层，对应红绿、 蓝三个通道。

给这些起个名字（原图像），这里的第一个 6 代表图像高度，第二个 6 代表宽度，这个 3 代表通道的数目。同样你的过滤器也有高，宽和通道数，并且图像的通道数必须和过滤器 的通道数匹配，所以这两个数（紫色方框标记的两个数）必须相等。下个幻灯片里，我们就 会知道这个卷积操作是如何进行的了，这个的输出会是一个 4×4 的图像，注意是 4×4×1，最 后一个数不是 3 了。

我们研究下这背后的细节，首先先换一张好看的图片。这个是 6×6×3 的图像，这个是 3×3×3 的过滤器，最后一个数字通道数必须和过滤器中的通道数相匹配。为了简化这个 3×3×3

365 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

过滤器的图像，我们不把它画成 3 个矩阵的堆叠，而画成这样，一个三维的立方体。

为了计算这个卷积操作的输出，你要做的就是把这个 3×3×3 的过滤器先放到最左上角 的位置，这个 3×3×3 的过滤器有 27 个数，27 个参数就是 3 的立方。依次取这 27 个数，然 后乘以相应的红绿蓝通道中的数字。先取红色通道的前 9 个数字，然后是绿色通道，然后再 是蓝色通道，乘以左边黄色立方体覆盖的对应的 27 个数，然后把这些数都加起来，就得到 了输出的第一个数字。

如果要计算下一个输出，你把这个立方体滑动一个单位，再与这 27 个数相乘，把它们 都加起来，就得到了下一个输出，以此类推。

那么，这个能干什么呢？举个例子，这个过滤器是 3×3×3 的，如果你想检测图像红色通 1 0 −1 道的边缘，那么你可以将第一个过滤器设为 [1 0 −1]，和之前一样，而绿色通道全为 0，1 0 −1

366 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

0 [ 0 0 

1 [ 1 1 

0 0 ]，蓝色也全为 0。如果你把这三个堆叠在一起形成一个 3×3×3 的过滤器，那么这 0 就是一个检测垂直边界的过滤器，但只对红色通道有用。

0 0 0 

或者如果你不关心垂直边界在哪个颜色通道里，那么你可以用一个这样的过滤器，0 −1 1 0 −1 1 0 −1 0 −1 ]，[1 0 −1]，[1 0 −1]，所有三个通道都是这样。所以通过设置第二个过 0 −1 1 0 −1 1 0 −1

滤器参数，你就有了一个边界检测器，3×3×3 的边界检测器，用来检测任意颜色通道里的边 界。参数的选择不同，你就可以得到不同的特征检测器，所有的都是 3×3×3 的过滤器。

按照计算机视觉的惯例，当你的输入有特定的高宽和通道数时，你的过滤器可以有不同 的高，不同的宽，但是必须一样的通道数。理论上，我们的过滤器只关注红色通道，或者只 关注绿色或者蓝色通道也是可行的。

再注意一下这个卷积立方体，一个 6×6×6 的输入图像卷积上一个 3×3×3 的过滤器，得到 一个 4×4 的二维输出。

现在你已经了解了如何对立方体卷积，还有最后一个概念，对建立卷积神经网络至关重 要。就是，如果我们不仅仅想要检测垂直边缘怎么办？如果我们同时检测垂直边缘和水平边 缘，还有 45° 倾斜的边缘，还有 70° 倾斜的边缘怎么做？换句话说，如果你想同时用多个过 滤器怎么办？

这是我们上一张幻灯片的图片，我们让这个 6×6×3 的图像和这个 3×3×3 的过滤器卷积，得到 4×4 的输出。（第一个）这可能是一个垂直边界检测器或者是学习检测其他的特征。第 二个过滤器可以用橘色来表示，它可以是一个水平边缘检测器。

367 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

所以和第一个过滤器卷积，可以得到第一个 4×4 的输出，然后卷积第二个过滤器，得到 一个不同的 4×4 的输出。我们做完卷积，然后把这两个 4×4 的输出，取第一个把它放到前 面，然后取第二个过滤器输出，我把它画在这，放到后面。所以把这两个输出堆叠在一起，这样你就都得到了一个 4×4×2 的输出立方体，你可以把这个立方体当成，重新画在这，就是 一个这样的盒子，所以这就是一个 4×4×2 的输出立方体。它用 6×6×3 的图像，然后卷积上这 两个不同的 3×3 的过滤器，得到两个 4×4 的输出，它们堆叠在一起，形成一个 4×4×2 的立方 体，这里的 2 的来源于我们用了两个不同的过滤器。

我们总结一下维度，如果你有一个𝑛 × 𝑛 × 𝑛 𝑐 （通道数）的输入图像，在这个例子中就 是 6×6×3，这里的𝑛 𝑐 就是通道数目，然后卷积上一个𝑓 × 𝑓 × 𝑛 𝑐 ，这个例子中是 3×3×3，按照 惯例，这个（前一个𝑛 𝑐 ）和这个（后一个𝑛 𝑐 ）必须数值相同。然后你就得到了（𝑛 − 𝑓 + 1）

368 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

× （𝑛 − 𝑓 + 1） × 𝑛 𝑐 ′ ，这里𝑛 𝑐 ′ 其实就是下一层的通道数，它就是你用的过滤器的个数，在

我们的例子中，那就是 4×4×2。我写下这个假设时，用的步幅为 1，并且没有 padding。如果 你用了不同的步幅或者 padding，那么这个𝑛 − 𝑓 + 1 数值会变化，正如前面的视频演示的那 样。

这个对立方体卷积的概念真的很有用，你现在可以用它的一小部分直接在三个通道的 RGB 图像上进行操作。更重要的是，你可以检测两个特征，比如垂直和水平边缘或者 10 个 或者 128 个或者几百个不同的特征，并且输出的通道数会等于你要检测的特征数。

对于这里的符号，我一直用通道数（𝑛 𝑐 ）来表示最后一个维度，在文献里大家也把它叫 做 3 维立方体的深度。这两个术语，即通道或者深度，经常被用在文献中。但我觉得深度容 易让人混淆，因为你通常也会说神经网络的深度。所以，在这些视频里我会用通道这个术语 来表示过滤器的第三个维度的大小。

所以你已经知道怎么对立方体做卷积了，你已经准备好了实现卷积神经其中一层了，在 下个视频里让我们看看是怎么做的。

369 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.7 单层卷积网络（One layer of a convolutional network）

今天我们要讲的是如何构建卷积神经网络的卷积层，下面来看个例子。

上节课，我们已经讲了如何通过两个过滤器卷积处理一个三维图像，并输出两个不同的 4×4 矩阵。假设使用第一个过滤器进行卷积，得到第一个 4×4 矩阵。使用第二个过滤器进行 卷积得到另外一个 4×4 矩阵。

最终各自形成一个卷积神经网络层，然后增加偏差，它是一个实数，通过 Python 的广 播机制给这 16 个元素都加上同一偏差。然后应用非线性函数，为了说明，它是一个非线性 激活函数 ReLU，输出结果是一个 4×4 矩阵。

对于第二个 4×4 矩阵，我们加上不同的偏差，它也是一个实数，16 个数字都加上同一 个实数，然后应用非线性函数，也就是一个非线性激活函数 ReLU，最终得到另一个 4×4 矩 阵。然后重复我们之前的步骤，把这两个矩阵堆叠起来，最终得到一个 4×4×2 的矩阵。我们 通过计算，从 6×6×3 的输入推导出一个 4×4×2 矩阵，它是卷积神经网络的一层，把它映射到 标准神经网络中四个卷积层中的某一层或者一个非卷积神经网络中。

370 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

注意前向传播中一个操作就是𝑧 [1] = 𝑊 [1] 𝑎 [0] + 𝑏 [1] ，其中𝑎 [0] = 𝑥，执行非线性函数得 到𝑎 [1] ，即𝑎 [1] = 𝑔(𝑧 [1] )。这里的输入是𝑎 [0] ，也就是𝑥，这些过滤器用变量𝑊 [1] 表示。在卷 积过程中，我们对这 27 个数进行操作，其实是 27×2，因为我们用了两个过滤器，我们取这 些数做乘法。实际执行了一个线性函数，得到一个 4×4 的矩阵。卷积操作的输出结果是一个 4×4 的矩阵，它的作用类似于𝑊 [1] 𝑎 [0] ，也就是这两个 4×4 矩阵的输出结果，然后加上偏差。

这一部分（图中蓝色边框标记的部分）就是应用激活函数 ReLU 之前的值，它的作用类 似于𝑧 [1] ，最后应用非线性函数，得到的这个 4×4×2 矩阵，成为神经网络的下一层，也就是 激活层。

这就是𝑎 [0] 到𝑎 [1] 的演变过程，首先执行线性函数，然后所有元素相乘做卷积，具体做法 是运用线性函数再加上偏差，然后应用激活函数 ReLU。这样就通过神经网络的一层把一个 6×6×3 的维度𝑎 [0] 演化为一个 4×4×2 维度的𝑎 [1] ，这就是卷积神经网络的一层。

示例中我们有两个过滤器，也就是有两个特征，因此我们才最终得到一个 4×4×2 的输

371 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

出。但如果我们用了 10 个过滤器，而不是 2 个，我们最后会得到一个 4×4×10 维度的输出图 像，因为我们选取了其中 10 个特征映射，而不仅仅是 2 个，将它们堆叠在一起，形成一个 4×4×10 的输出图像，也就是𝑎 [1] 。

为了加深理解，我们来做一个练习。假设你有 10 个过滤器，而不是 2 个，神经网络的 一层是 3×3×3，那么，这一层有多少个参数呢？我们来计算一下，每一层都是一个 3×3×3 的 矩阵，因此每个过滤器有 27 个参数，也就是 27 个数。然后加上一个偏差，用参数𝑏表示，现在参数增加到 28 个。上一页幻灯片里我画了 2 个过滤器，而现在我们有 10 个，加在一起 是 28×10，也就是 280 个参数。

请注意一点，不论输入图片有多大，1000×1000 也好，5000×5000 也好，参数始终都是 280 个。用这 10 个过滤器来提取特征，如垂直边缘，水平边缘和其它特征。即使这些图片 很大，参数却很少，这就是卷积神经网络的一个特征，叫作「避免过拟合」。你已经知道到如 何提取 10 个特征，可以应用到大图片中，而参数数量固定不变，此例中只有 28 个，相对较 少。

最后我们总结一下用于描述卷积神经网络中的一层（以𝑙层为例），也就是卷积层的各 种标记。

372 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

这一层是卷积层，用𝑓 [𝑙] 表示过滤器大小，我们说过过滤器大小为𝑓 × 𝑓，上标 [𝑙] 表示𝑙层 中过滤器大小为𝑓 × 𝑓。通常情况下，上标 [𝑙] 用来标记𝑙层。用𝑝 [𝑙] 来标记 padding 的数量，padding 数量也可指定为一个 valid 卷积，即无 padding。或是 same 卷积，即选定 padding，如此一来，输出和输入图片的高度和宽度就相同了。用𝑠 [𝑙] 标记步幅。

这一层的输入会是某个维度的数据，表示为𝑛 × 𝑛 × 𝑛 𝑐 ，𝑛 𝑐 某层上的颜色通道数。

我们要稍作修改，增加上标 [𝑙 − 1]，即𝑛 [𝑙−1] × 𝑛 [𝑙−1] × 𝑛𝑐 [𝑙−1] ，因为它是上一层的激活值。

此例中，所用图片的高度和宽度都一样，但它们也有可能不同，所以分别用上下标𝐻和 𝑊来标记，即𝑛 𝐻 [𝑙−1] × 𝑛 𝑊 [𝑙−1] × 𝑛 𝑐 [𝑙−1] 。那么在第𝑙层，图片大小为𝑛 𝐻 [𝑙−1] × 𝑛 𝑊 [𝑙−1] × 𝑛 𝑐 [𝑙−1] ，𝑙层的 输入就是上一层的输出，因此上标要用 [𝑙 − 1]。神经网络这一层中会有输出，它本身会输出

图像。其大小为𝑛 𝐻 [𝑙] × 𝑛 𝑊 [𝑙] × 𝑛 𝑐 [𝑙] ，这就是输出图像的大小。

前面我们提到过，这个公式给出了输出图片的大小，至少给出了高度和宽度，⌊ 𝑛+2𝑝−𝑓 𝑠 +

1⌋（注意：(𝑛+2𝑝−𝑓 𝑠 + 1) 直接用这个运算结果，也可以向下取整）。在这个新表达式中，𝑙层

输出图像的高度，即𝑛 𝐻 [𝑙] = ⌊ 𝑠 [𝑙] 𝑛 𝐻 [𝑙−1] +2𝑝 [𝑙] −𝑓 [𝑙] + 1⌋，同样我们可以计算出图像的宽度，用𝑊替换

参数𝐻，即𝑛 𝑊 [𝑙] = ⌊ 𝑠 [𝑙] 𝑛 𝑊 [𝑙−1] +2𝑝 [𝑙] −𝑓 [𝑙] + 1⌋，公式一样，只要变化高度和宽度的参数我们便能计算

输出图像的高度或宽度。这就是由𝑛 𝐻 [𝑙−1] 推导𝑛 𝐻 [𝑙] 以及𝑛 𝑊 [𝑙−1] 推导𝑛 𝑊 [𝑙] 的过程。那么通道数量又是什么？这些数字从哪儿来的？我们来看一下。输出图像也具有深度，通过上一个示例，我们知道它等于该层中过滤器的数量，如果有 2 个过滤器，输出图像就是 4×4×2，它是二维的，如果有 10 个过滤器，输出图像就是 4×4×10。输出图像中的通道数量 就是神经网络中这一层所使用的过滤器的数量。如何确定过滤器的大小呢？我们知道卷积一 个 6×6×3 的图片需要一个 3×3×3 的过滤器，因此过滤器中通道的数量必须与输入中通道的

373 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

数量一致。因此，输出通道数量就是输入通道数量，所以过滤器维度等于𝑓 [𝑙] × 𝑓 [𝑙] × 𝑛 𝑐 [𝑙−1] 。

应用偏差和非线性函数之后，这一层的输出等于它的激活值𝑎 [𝑙] ，也就是这个维度（输

出维度）。𝑎 [𝑙] 是一个三维体，即𝑛 𝐻 [𝑙] × 𝑛 𝑊 [𝑙] × 𝑛 𝑐 [𝑙] 。当你执行批量梯度下降或小批量梯度下降

时，如果有𝑚个例子，就是有𝑚个激活值的集合，那么输出𝐴 [𝑙] = 𝑚 × 𝑛 𝐻 [𝑙] × 𝑛 𝑊 [𝑙] × 𝑛 𝑐 [𝑙] 。如果 采用批量梯度下降，变量的排列顺序如下，首先是索引和训练示例，然后是其它三个变量。

该如何确定权重参数，即参数 W 呢？过滤器的维度已知，为𝑓 [𝑙] × 𝑓 [𝑙] × 𝑛 𝑐 [𝑙−1] ，这只是 一个过滤器的维度，有多少个过滤器，这（𝑛 𝑐 [𝑙] ）是过滤器的数量，权重也就是所有过滤器 的集合再乘以过滤器的总数量，即𝑓 [𝑙] × 𝑓 [𝑙] × 𝑛 𝑐 [𝑙−1] × 𝑛 𝑐 [𝑙] ，损失数量 L 就是𝑙层中过滤器的 个数。

最后我们看看偏差参数，每个过滤器都有一个偏差参数，它是一个实数。偏差包含了这 些变量，它是该维度上的一个向量。后续课程中我们会看到，为了方便，偏差在代码中表示 为一个 1×1×1×𝑛 𝑐 [𝑙] 的四维向量或四维张量。

卷积有很多种标记方法，这是我们最常用的卷积符号。大家在线搜索或查看开源代码时，关于高度，宽度和通道的顺序并没有完全统一的标准卷积，所以在查看 GitHub 上的源代码 或阅读一些开源实现的时候，你会发现有些作者会采用把通道放在首位的编码标准，有时所 有变量都采用这种标准。实际上在某些架构中，当检索这些图片时，会有一个变量或参数来

374 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

标识计算通道数量和通道损失数量的先后顺序。只要保持一致，这两种卷积标准都可用。很 遗憾，这只是一部分标记法，因为深度学习文献并未对标记达成一致，但课上我会采用这种 卷积标识法，按高度，宽度和通道损失数量的顺序依次计算。

我知道，忽然间接触到这么多新的标记方法，你可能会说，这么多怎么记呢？别担心，不用全都记住，你可以通过本周的练习来熟悉它们。而这节课我想讲的重点是，卷积神经网 络的某一卷积层的工作原理，以及如何计算某一卷积层的激活函数，并映射到下一层的激活 值。了解了卷积神经网络中某一卷积层的工作原理，我们就可以把它们堆叠起来形成一个深 度卷积神经网络，我们下节课再讲。

375 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.8 简 单 卷 积 网 络 示 例 （ A simple convolution network example）

上节课，我们讲了如何为卷积网络构建一个卷积层。今天我们看一个深度卷积神经网络 的具体示例，顺便练习一下我们上节课所学的标记法。

假设你有一张图片，你想做图片分类或图片识别，把这张图片输入定义为𝑥，然后辨别 图片中有没有猫，用 0 或 1 表示，这是一个分类问题，我们来构建适用于这项任务的卷积神 经网络。针对这个示例，我用了一张比较小的图片，大小是 39×39×3，这样设定可以使其中

一些数字效果更好。所以𝑛 𝐻 [0] = 𝑛 𝑊 [0] ，即高度和宽度都等于 39，𝑛 𝑐 [0] = 3，即 0 层的通道数为 3。

假设第一层我们用一个 3×3 的过滤器来提取特征，那么𝑓 [1] = 3，因为过滤器时 3×3 的 矩阵。𝑠 [1] = 1，𝑝 [1] = 0，所以高度和宽度使用 valid 卷积。如果有 10 个过滤器，神经网络 下一层的激活值为 37×37×10，写 10 是因为我们用了 10 个过滤器，37 是公式 𝑛+2𝑝−𝑓 𝑠 + 1 的

计算结果，也就是 39+0−3 1 + 1 = 37，所以输出是 37×37，它是一个 vaild 卷积，这是输出结果

的大小。第一层标记为𝑛 𝐻 [1] = 𝑛 𝑊 [1] = 37，𝑛 𝑐 [1] = 10，𝑛 𝑐 [1] 等于第一层中过滤器的个数，这 （37×37×10）是第一层激活值的维度。

376 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

假设还有另外一个卷积层，这次我们采用的过滤器是 5×5 的矩阵。在标记法中，神经网 络下一层的𝑓 = 5，即𝑓 [2] = 5 步幅为 2，即𝑠 [2] = 2。padding 为 0，即𝑝 [2] = 0，且有 20 个过 滤器。所以其输出结果会是一张新图像，这次的输出结果为 17×17×20，因为步幅是 2，维度 缩小得很快，大小从 37×37 减小到 17×17，减小了一半还多，过滤器是 20 个，所以通道数 也是 20，17×17×20 即激活值𝑎 [2] 的维度。因此𝑛 𝐻 [2] = 𝑛 𝑊 [2] = 17，𝑛 𝑐 [2] = 20。

我们来构建最后一个卷积层，假设过滤器还是 5×5，步幅为 2，即𝑓 [2] = 5，𝑠 [3] = 2，计 算过程我跳过了，最后输出为 7×7×40，假设使用了 40 个过滤器。padding 为 0，40 个过滤 器，最后结果为 7×7×40。

到此，这张 39×39×3 的输入图像就处理完毕了，为图片提取了 7×7×40 个特征，计算出 来就是 1960 个特征。然后对该卷积进行处理，可以将其平滑或展开成 1960 个单元。平滑处

377 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

理后可以输出一个向量，其填充内容是 logistic 回归单元还是 softmax 回归单元，完全取决 于我们是想识图片上有没有猫，还是想识别𝐾种不同对象中的一种，用𝑦表示最终神经网络 的预测输出。明确一点，最后这一步是处理所有数字，即全部的 1960 个数字，把它们展开 成一个很长的向量。为了预测最终的输出结果，我们把这个长向量填充到 softmax 回归函数 中。这是卷积神经网络的一个典型范例，设计卷积神经网络时，确定这些超参数比较费工夫。要决定过滤器的大小、步幅、padding 以及使用多少个过滤器。这周和下周，我会针对选择 参数的问题提供一些建议和指导。

而这节课你要掌握的一点是，随着神经网络计算深度不断加深，通常开始时的图像也要 更大一些，初始值为 39×39，高度和宽度会在一段时间内保持一致，然后随着网络深度的加 深而逐渐减小，从 39 到 37，再到 17，最后到 7。而通道数量在增加，从 3 到 10，再到 20，最后到 40。在许多其它卷积神经网络中，你也可以看到这种趋势。关于如何确定这些参数，后面课上我会更详细讲解，这是我们讲的第一个卷积神经网络示例。

一个典型的卷积神经网络通常有三层，一个是卷积层，我们常常用 Conv 来标注。上一 个例子，我用的就是 CONV。还有两种常见类型的层，我们留在后两节课讲。一个是池化层，我们称之为 POOL。最后一个是全连接层，用 FC 表示。虽然仅用卷积层也有可能构建出很好 的神经网络，但大部分神经望楼架构师依然会添加池化层和全连接层。幸运的是，池化层和 全连接层比卷积层更容易设计。后两节课我们会快速讲解这两个概念以便你更好的了解神经 网络中最常用的这几种层，你就可以利用它们构建更强大的网络了。

378 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

再次恭喜你已经掌握了第一个卷积神经网络，本周后几节课，我们会学习如何训练这些 卷积神经网络。不过在这之前，我还要简单介绍一下池化层和全连接层。然后再训练这些网 络，到时我会用到大家熟悉的反向传播训练方法。那么下节课，我们就先来了解如何构建神 经网络的池化层。

379 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.9 池化层（Pooling layers）

除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高 所提取特征的鲁棒性，我们来看一下。

先举一个池化层的例子，然后我们再讨论池化层的必要性。假如输入是一个 4×4 矩阵，用到的池化类型是最大池化（max pooling）。执行最大池化的树池是一个 2×2 矩阵。执行过 程非常简单，把 4×4 的输入拆分成不同的区域，我把这个区域用不同颜色来标记。对于 2×2 的输出，输出的每个元素都是其对应颜色区域中的最大元素值。

左上区域的最大值是 9，右上区域的最大元素值是 2，左下区域的最大值是 6，右下区 域的最大值是 3。为了计算出右侧这 4 个元素值，我们需要对输入矩阵的 2×2 区域做最大值 运算。这就像是应用了一个规模为 2 的过滤器，因为我们选用的是 2×2 区域，步幅是 2，这 些就是最大池化的超参数。

因为我们使用的过滤器为 2×2，最后输出是 9。然后向右移动 2 个步幅，计算出最大值 2。然后是第二行，向下移动 2 步得到最大值 6。最后向右移动 3 步，得到最大值 3。这是一 个 2×2 矩阵，即𝑓 = 2，步幅是 2，即𝑠 = 2。

380 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

这是对最大池化功能的直观理解，你可以把这个 4×4 输入看作是某些特征的集合，也许 不是。你可以把这个 4×4 区域看作是某些特征的集合，也就是神经网络中某一层的非激活值 集合。数字大意味着可能探测到了某些特定的特征，左上象限具有的特征可能是一个垂直边 缘，一只眼睛，或是大家害怕遇到的 CAP 特征。显然左上象限中存在这个特征，这个特征可 能是一只猫眼探测器。然而，右上象限并不存在这个特征。最大化操作的功能就是只要在任 何一个象限内提取到某个特征，它都会保留在最大化的池化输出里。所以最大化运算的实际 作用就是，如果在过滤器中提取到某个特征，那么保留其最大值。如果没有提取到这个特征，可能在右上象限中不存在这个特征，那么其中的最大值也还是很小，这就是最大池化的直观 理解。

必须承认，人们使用最大池化的主要原因是此方法在很多实验中效果都很好。尽管刚刚 描述的直观理解经常被引用，不知大家是否完全理解它的真正原因，不知大家是否理解最大 池化效率很高的真正原因。

其中一个有意思的特点就是，它有一组超参数，但并没有参数需要学习。实际上，梯度 下降没有什么可学的，一旦确定了𝑓和𝑠，它就是一个固定运算，梯度下降无需改变任何值。

我们来看一个有若干个超级参数的示例，输入是一个 5×5 的矩阵。我们采用最大池化 法，它的过滤器参数为 3×3，即𝑓 = 3，步幅为 1，𝑠 = 1，输出矩阵是 3×3。之前讲的计算卷 积层输出大小的公式同样适用于最大池化，即 𝑛+2𝑝−𝑓 𝑠 + 1，这个公式也可以计算最大池化的

381 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

输出大小。

此例是计算 3×3 输出的每个元素，我们看左上角这些元素，注意这是一个 3×3 区域，因 为有 3 个过滤器，取最大值 9。然后移动一个元素，因为步幅是 1，蓝色区域的最大值是 9. 继续向右移动，蓝色区域的最大值是 5。然后移到下一行，因为步幅是 1，我们只向下移动 一个格，所以该区域的最大值是 9。这个区域也是 9。这两个区域的最大值都是 5。最后这 三个区域的最大值分别为 8，6 和 9。超参数𝑓 = 3，𝑠 = 1，最终输出如图所示。

以上就是一个二维输入的最大池化的演示，如果输入是三维的，那么输出也是三维的。例如，输入是 5×5×2，那么输出是 3×3×2。计算最大池化的方法就是分别对每个通道执行刚 刚的计算过程。如上图所示，第一个通道依然保持不变。对于第二个通道，我刚才画在下面 的，在这个层做同样的计算，得到第二个通道的输出。一般来说，如果输入是 5×5×𝑛 𝑐 ，输出 就是 3×3×𝑛 𝑐 ，𝑛 𝑐 个通道中每个通道都单独执行最大池化计算，以上就是最大池化算法。

382 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

另外还有一种类型的池化，平均池化，它不太常用。我简单介绍一下，这种运算顾名思 义，选取的不是每个过滤器的最大值，而是平均值。示例中，紫色区域的平均值是 3.75，后 面依次是 1.25、4 和 2。这个平均池化的超级参数𝑓 = 2，𝑠 = 2，我们也可以选择其它超级 参数。

目前来说，最大池化比平均池化更常用。但也有例外，就是深度很深的神经网络，你可 以用平均池化来分解规模为 7×7×1000 的网络的表示层，在整个空间内求平均值，得到 1×1×1000，一会我们看个例子。但在神经网络中，最大池化要比平均池化用得更多。

总结一下，池化的超级参数包括过滤器大小𝑓和步幅𝑠，常用的参数值为𝑓 = 2，𝑠 = 2，应用频率非常高，其效果相当于高度和宽度缩减一半。也有使用𝑓 = 3，𝑠 = 2 的情况。至于 其它超级参数就要看你用的是最大池化还是平均池化了。你也可以根据自己意愿增加表示 padding 的其他超级参数，虽然很少这么用。最大池化时，往往很少用到超参数 padding，当 然也有例外的情况，我们下周会讲。大部分情况下，最大池化很少用 padding。目前𝑝最常用 的值是 0，即𝑝 = 0。最大池化的输入就是𝑛 𝐻 × 𝑛 𝑊 × 𝑛 𝑐 ，假设没有 padding，则输出⌊ 𝑠 𝑛 𝐻 −𝑓 +

383 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1⌋ × ⌊ 𝑠 𝑛 𝑤 −𝑓 + 1⌋ × 𝑛 𝑐 。输入通道与输出通道个数相同，因为我们对每个通道都做了池化。需

要注意的一点是，池化过程中没有需要学习的参数。执行反向传播时，反向传播没有参数适 用于最大池化。只有这些设置过的超参数，可能是手动设置的，也可能是通过交叉验证设置 的。

除了这些，池化的内容就全部讲完了。最大池化只是计算神经网络某一层的静态属性，没有什么需要学习的，它只是一个静态属性。

关于池化我们就讲到这儿，现在我们已经知道如何构建卷积层和池化层了。下节课，我 们会分析一个更复杂的可以引进全连接层的卷积网络示例。

384 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.10 卷 积 神 经 网 络 示 例 （ Convolutional neural network example）

构建全卷积神经网络的构造模块我们已经掌握得差不多了，下面来看个例子。假设，有一张大小为 32×32×3 的输入图片，这是一张 RGB 模式的图片，你想做手写体 数字识别。32×32×3 的 RGB 图片中含有某个数字，比如 7，你想识别它是从 0-9 这 10 个数 字中的哪一个，我们构建一个神经网络来实现这个功能。

我用的这个网络模型和经典网络 LeNet-5 非常相似，灵感也来源于此。LeNet-5 是多年 前 Yann LeCun 创建的，我所采用的模型并不是 LeNet-5，但是受它启发，许多参数选择都与 LeNet-5 相似。输入是 32×32×3 的矩阵，假设第一层使用过滤器大小为 5×5，步幅是 1，padding 是 0，过滤器个数为 6，那么输出为 28×28×6。将这层标记为 CONV1，它用了 6 个过滤器，增加了偏差，应用了非线性函数，可能是 ReLU 非线性函数，最后输出 CONV1 的结果。

然后构建一个池化层，这里我选择用最大池化，参数𝑓 = 2，𝑠 = 2，因为 padding 为 0，我就不写出来了。现在开始构建池化层，最大池化使用的过滤器为 2×2，步幅为 2，表示层 的高度和宽度会减少一半。因此，28×28 变成了 14×14，通道数量保持不变，所以最终输出 为 14×14×6，将该输出标记为 POOL1。

人们发现在卷积神经网络文献中，卷积有两种分类，这与所谓层的划分存在一致性。一

385 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

类卷积是一个卷积层和一个池化层一起作为一层，这就是神经网络的 Layer1。另一类卷积是 把卷积层作为一层，而池化层单独作为一层。人们在计算神经网络有多少层时，通常只统计 具有权重和参数的层。因为池化层没有权重和参数，只有一些超参数。这里，我们把 CONV1 和 POOL1 共同作为一个卷积，并标记为 Layer1。虽然你在阅读网络文章或研究报告时，你 可能会看到卷积层和池化层各为一层的情况，这只是两种不同的标记术语。一般我在统计网 络层数时，只计算具有权重的层，也就是把 CONV1 和 POOL1 作为 Layer1。这里我们用 CONV1 和 POOL1 来标记，两者都是神经网络 Layer1 的一部分，POOL1 也被划分在 Layer1 中，因为 它没有权重，得到的输出是 14×14×6。

我们再为它构建一个卷积层，过滤器大小为 5×5，步幅为 1，这次我们用 10 个过滤器，最后输出一个 10×10×10 的矩阵，标记为 CONV2。

然后做最大池化，超参数𝑓 = 2，𝑠 = 2。你大概可以猜出结果，𝑓 = 2，𝑠 = 2，高度和 宽度会减半，最后输出为 5×5×10，标记为 POOL2，这就是神经网络的第二个卷积层，即 Layer2。

如果对 Layer1 应用另一个卷积层，过滤器为 5×5，即𝑓 = 5，步幅是 1，padding 为 0，所以这里省略了，过滤器 16 个，所以 CONV2 输出为 10×10×16。我们看看 CONV2，这是

386 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

CONV2 层。

继续执行做大池化计算，参数𝑓 = 2，𝑠 = 2，你能猜到结果么？对 10×10×16 输入执行 最大池化计算，参数𝑓 = 2，𝑠 = 2，高度和宽度减半，计算结果猜到了吧。最大池化的参数 𝑓 = 2，𝑠 = 2，输入的高度和宽度会减半，结果为 5×5×16，通道数和之前一样，标记为 POOL2。这是一个卷积，即 Layer2，因为它只有一个权重集和一个卷积层 CONV2。

5×5×16 矩阵包含 400 个元素，现在将 POOL2 平整化为一个大小为 400 的一维向量。我 们可以把平整化结果想象成这样的一个神经元集合，然后利用这 400 个单元构建下一层。下 一层含有 120 个单元，这就是我们第一个全连接层，标记为 FC3。这 400 个单元与 120 个单 元紧密相连，这就是全连接层。它很像我们在第一和第二门课中讲过的单神经网络层，这是 一个标准的神经网络。它的权重矩阵为𝑊 [3] ，维度为 120×400。这就是所谓的「全连接」，因 为这 400 个单元与这 120 个单元的每一项连接，还有一个偏差参数。最后输出 120 个维度，因为有 120 个输出。

然后我们对这个 120 个单元再添加一个全连接层，这层更小，假设它含有 84 个单元，标记为 FC4。

387 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

最后，用这 84 个单元填充一个 softmax 单元。如果我们想通过手写数字识别来识别手 写 0-9 这 10 个数字，这个 softmax 就会有 10 个输出。

此例中的卷积神经网络很典型，看上去它有很多超参数，关于如何选定这些参数，后面 我提供更多建议。常规做法是，尽量不要自己设置超参数，而是查看文献中别人采用了哪些 超参数，选一个在别人任务中效果很好的架构，那么它也有可能适用于你自己的应用程序，这块下周我会细讲。

现在，我想指出的是，随着神经网络深度的加深，高度𝑛 𝐻 和宽度𝑛 𝑊 通常都会减少，前 面我就提到过，从 32×32 到 28×28，到 14×14，到 10×10，再到 5×5。所以随着层数增加，高 度和宽度都会减小，而通道数量会增加，从 3 到 6 到 16 不断增加，然后得到一个全连接层。在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，然后一个或

388 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个 softmax。这是神经网 络的另一种常见模式。接下来我们讲讲神经网络的激活值形状，激活值大小和参数数量。输入为 32×32×3，这 些数做乘法，结果为 3072，所以激活值𝑎 [0] 有 3072 维，激活值矩阵为 32×32×3，输入层没有 参数。计算其他层的时候，试着自己计算出激活值，这些都是网络中不同层的激活值形状和 激活值大小。

有几点要注意，第一，池化层和最大池化层没有参数；第二卷积层的参数相对较少，前 面课上我们提到过，其实许多参数都存在于神经网络的全连接层。观察可发现，随着神经网 络的加深，激活值尺寸会逐渐变小，如果激活值尺寸下降太快，也会影响神经网络性能。示 例中，激活值尺寸在第一层为 6000，然后减少到 1600，慢慢减少到 84，最后输出 softmax 结果。我们发现，许多卷积网络都具有这些属性，模式上也相似。

神经网络的基本构造模块我们已经讲完了，一个卷积神经网络包括卷积层、池化层和全 连接层。许多计算机视觉研究正在探索如何把这些基本模块整合起来，构建高效的神经网络，整合这些基本模块确实需要深入的理解。根据我的经验，找到整合基本构造模块最好方法就 是大量阅读别人的案例。下周我会演示一些整合基本模块，成功构建高效神经网络的具体案 例。我希望下周的课程可以帮助你找到构建有效神经网络的感觉，或许你也可以将别人开发 的框架应用于自己的应用程序，这是下周的内容。下节课，也是本周最后一节课，我想花点 时间讨论下，为什么大家愿意使用卷积，使用卷积的好处和优势是什么，以及如何整合多个 卷积，如何检验神经网络，如何在训练集上训练神经网络来识别图片或执行其他任务，我们 下节课继续讲。

389 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

1.11 为什么使用卷积？（Why convolutions?）

这是本周最后一节课，我们来分析一下卷积在神经网络中如此受用的原因，然后对如何 整合这些卷积，如何通过一个标注过的训练集训练卷积神经网络做个简单概括。和只用全连 接层相比，卷积层的两个主要优势在于参数共享和稀疏连接，举例说明一下。

假设有一张 32×32×3 维度的图片，这是上节课的示例，假设用了 6 个大小为 5×5 的过 滤器，输出维度为 28×28×6。32×32×3=3072，28×28×6=4704。我们构建一个神经网络，其中 一层含有 3072 个单元，下一层含有 4074 个单元，两层中的每个神经元彼此相连，然后计算 权重矩阵，它等于 4074×3072≈1400 万，所以要训练的参数很多。虽然以现在的技术，我们 可以用 1400 多万个参数来训练网络，因为这张 32×32×3 的图片非常小，训练这么多参数没 有问题。如果这是一张 1000×1000 的图片，权重矩阵会变得非常大。我们看看这个卷积层的 参数数量，每个过滤器都是 5×5，一个过滤器有 25 个参数，再加上偏差参数，那么每个过 滤器就有 26 个参数，一共有 6 个过滤器，所以参数共计 156 个，参数数量还是很少。

卷积网络映射这么少参数有两个原因：

一是参数共享。观察发现，特征检测如垂直边缘检测如果适用于图片的某个区域，那么 它也可能适用于图片的其他区域。也就是说，如果你用一个 3×3 的过滤器检测垂直边缘，那 么图片的左上角区域，以及旁边的各个区域（左边矩阵中蓝色方框标记的部分）都可以使用 这个 3×3 的过滤器。每个特征检测器以及输出都可以在输入图片的不同区域中使用同样的 参数，以便提取垂直边缘或其它特征。它不仅适用于边缘特征这样的低阶特征，同样适用于 高阶特征，例如提取脸上的眼睛，猫或者其他特征对象。即使减少参数个数，这 9 个参数同

390 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

样能计算出 16 个输出。直观感觉是，一个特征检测器，如垂直边缘检测器用于检测图片左 上角区域的特征，这个特征很可能也适用于图片的右下角区域。因此在计算图片左上角和右 下角区域时，你不需要添加其它特征检测器。假如有一个这样的数据集，其左上角和右下角 可能有不同分布，也有可能稍有不同，但很相似，整张图片共享特征检测器，提取效果也很 好。

第二个方法是使用稀疏连接，我来解释下。这个 0 是通过 3×3 的卷积计算得到的，它只 依赖于这个 3×3 的输入的单元格，右边这个输出单元（元素 0）仅与 36 个输入特征中 9 个 相连接。而且其它像素值都不会对输出产生任影响，这就是稀疏连接的概念。

再举一个例子，这个输出（右边矩阵中红色标记的元素 30）仅仅依赖于这 9 个特征（左 边矩阵红色方框标记的区域），看上去只有这 9 个输入特征与输出相连接，其它像素对输出 没有任何影响。

391 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

神经网络可以通过这两种机制减少参数，以便我们用更小的训练集来训练它，从而预防 过度拟合。你们也可能听过，卷积神经网络善于捕捉平移不变。通过观察可以发现，向右移 动两个像素，图片中的猫依然清晰可见，因为神经网络的卷积结构使得即使移动几个像素，这张图片依然具有非常相似的特征，应该属于同样的输出标记。实际上，我们用同一个过滤 器生成各层中，图片的所有像素值，希望网络通过自动学习变得更加健壮，以便更好地取得 所期望的平移不变属性。

这就是卷积或卷积网络在计算机视觉任务中表现良好的原因。

最后，我们把这些层整合起来，看看如何训练这些网络。比如我们要构建一个猫咪检测 器，我们有下面这个标记训练集，𝑥表示一张图片，𝑦是二进制标记或某个重要标记。我们选 定了一个卷积神经网络，输入图片，增加卷积层和池化层，然后添加全连接层，最后输出一 个 softmax，即𝑦。卷积层和全连接层有不同的参数𝑤和偏差𝑏，我们可以用任何参数集合来 定义代价函数。一个类似于我们之前讲过的那种代价函数，并随机初始化其参数𝑤和𝑏，代 价 函 数 𝐽 等 于 神 经 网 络 对 整 个 训 练 集 的 预 测 的 损 失 总 和 再 除 以 𝑚 （ 即 Cost 𝐽 = 1 ∑ 𝑖=1 𝑚 𝐿(𝑦 , 𝑦 (𝑖) )）。所以训练神经网络，你要做的就是使用梯度下降法，或其它算法，例 𝑚 如 Momentum 梯度下降法，含 RMSProp 或其它因子的梯度下降来优化神经网络中所有参 数，以减少代价函数𝐽的值。通过上述操作你可以构建一个高效的猫咪检测器或其它检测器。

恭喜你完成了这一周的课程，你已经学习了卷积神经网络的所有基本构造模块，以及如 何在高效图片识别系统中整合这些模块。透过本周编程练习，你可以更加具体了解这些概念，试着整合这些构造模块，并用它们解决自己的问题。

下周，我们将继续深入学习卷积神经网络。我曾提到卷积神经网络中有很多超参数，下 周，我打算具体展示一些最有效的卷积神经网络示例，你也可以尝试去判断哪些网络架构类 型效率更高。人们通常的做法是将别人发现和发表在研究报告上的架构应用于自己的应用程

392 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第一周 卷积神经网络（Foundations of Convolutional Neural Networks）

序。下周看过更多具体的示例后，相信你会做的更好。此外，下星期我们也会深入分析卷积 神经网络如此高效的原因，同时讲解一些新的计算机视觉应用程序，例如，对象检测和神经 风格迁移以及如何利用这些算法创造新的艺术品形式。

393 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.1 为什么要进行实例探究？（Why look at case studies?）

这周我们首先来看看一些卷积神经网络的实例分析，为什么要看这些实例分析呢？上周 我们讲了基本构建，比如卷积层、池化层以及全连接层这些组件。事实上，过去几年计算机 视觉研究中的大量研究都集中在如何把这些基本构件组合起来，形成有效的卷积神经网络。最直观的方式之一就是去看一些案例，就像很多人通过看别人的代码来学习编程一样，通过 研究别人构建有效组件的案例是个不错的办法。实际上在计算机视觉任务中表现良好的神经 网络框架往往也适用于其它任务，也许你的任务也不例外。也就是说，如果有人已经训练或 者计算出擅长识别猫、狗、人的神经网络或者神经网络框架，而你的计算机视觉识别任务是 构建一个自动驾驶汽车，你完全可以借鉴别人的神经网络框架来解决自己的问题。

最后，学完这几节课，你应该可以读一些计算机视觉方面的研究论文了，我希望这也是 你学习本课程的收获。当然，读论文并不是必须的，但是我希望当你发现你可以读懂一些计 算机视觉方面的研究论文或研讨会内容时会有一种满足感。言归正传，我们进入主题。

这是后面几节课的提纲，首先我们来看几个经典的网络。

LeNet-5 网络，我记得应该是 1980 年代的，经常被引用的 AlexNet，还有 VGG 网络。这 些都是非常有效的神经网络范例，当中的一些思路为现代计算机视觉技术的发展奠定了基 础。论文中的这些想法可能对你大有裨益，对你的工作也可能有所帮助。

然后是 ResNet，又称残差网络。神经网络正在不断加深，对此你可能有所了解。ResNet

394 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

神经网络训练了一个深达 152 层的神经网络，并且在如何有效训练方面，总结出了一些有趣 的想法和窍门。课程最后，我们还会讲一个 Inception 神经网络的实例分析。了解了这些神经网络，我相信你会对如何构建有效的卷积神经网络更有感觉。即使计算 机视觉并不是你的主要方向，但我相信你会从 ResNet 和 Inception 网络这样的实例中找到一 些不错的想法。这里面有很多思路都是多学科融合的产物。总之，即便你不打算构建计算机 视觉应用程序，试着从中发现一些有趣的思路，对你的工作也会有所帮助。

395 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.2 经典网络（Classic networks）

这节课，我们来学习几个经典的神经网络结构，分别是 LeNet-5、AlexNet 和 VGGNet，开始吧。

首先看看 LeNet-5 的网络结构，假设你有一张 32×32×1 的图片，LeNet-5 可以识别图中 的手写数字，比如像这样手写数字 7。LeNet-5 是针对灰度图片训练的，所以图片的大小只 有 32×32×1。实际上 LeNet-5 的结构和我们上周讲的最后一个范例非常相似，使用 6 个 5×5 的过滤器，步幅为 1。由于使用了 6 个过滤器，步幅为 1，padding 为 0，输出结果为 28×28×6，图像尺寸从 32×32 缩小到 28×28。然后进行池化操作，在这篇论文写成的那个年代，人们更 喜欢使用平均池化，而现在我们可能用最大池化更多一些。在这个例子中，我们进行平均池 化，过滤器的宽度为 2，步幅为 2，图像的尺寸，高度和宽度都缩小了 2 倍，输出结果是一 个 14×14×6 的图像。我觉得这张图片应该不是完全按照比例绘制的，如果严格按照比例绘 制，新图像的尺寸应该刚好是原图像的一半。

接下来是卷积层，我们用一组 16 个 5×5 的过滤器，新的输出结果有 16 个通道。LeNet5 的论文是在 1998 年撰写的，当时人们并不使用 padding，或者总是使用 valid 卷积，这就 是为什么每进行一次卷积，图像的高度和宽度都会缩小，所以这个图像从 14 到 14 缩小到了 10×10。然后又是池化层，高度和宽度再缩小一半，输出一个 5×5×16 的图像。将所有数字相 乘，乘积是 400。

下一层是全连接层，在全连接层中，有 400 个节点，每个节点有 120 个神经元，这里已 经有了一个全连接层。但有时还会从这 400 个节点中抽取一部分节点构建另一个全连接层，就像这样，有 2 个全连接层。

最后一步就是利用这 84 个特征得到最后的输出，我们还可以在这里再加一个节点用来 预测𝑦的值，𝑦有 10 个可能的值，对应识别 0-9 这 10 个数字。在现在的版本中则使用 softmax

396 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

函数输出十种分类结果，而在当时，LeNet-5 网络在输出层使用了另外一种，现在已经很少 用到的分类器。

相比现代版本，这里得到的神经网络会小一些，只有约 6 万个参数。而现在，我们经常 看到含有一千万到一亿个参数的神经网络，比这大 1000 倍的神经网络也不在少数。

不管怎样，如果我们从左往右看，随着网络越来越深，图像的高度和宽度在缩小，从最 初的 32×32 缩小到 28×28，再到 14×14、10×10，最后只有 5×5。与此同时，随着网络层次的 加深，通道数量一直在增加，从 1 增加到 6 个，再到 16 个。

这个神经网络中还有一种模式至今仍然经常用到，就是一个或多个卷积层后面跟着一个 池化层，然后又是若干个卷积层再接一个池化层，然后是全连接层，最后是输出，这种排列 方式很常用。

对于那些想尝试阅读论文的同学，我再补充几点。接下来的部分主要针对那些打算阅读 经典论文的同学，所以会更加深入。这些内容你完全可以跳过，算是对神经网络历史的一种 回顾吧，听不懂也不要紧。

读到这篇经典论文时，你会发现，过去，人们使用 sigmoid 函数和 tanh 函数，而不是 ReLu 函数，这篇论文中使用的正是 sigmoid 函数和 tanh 函数。这种网络结构的特别之处还 在于，各网络层之间是有关联的，这在今天看来显得很有趣。

比如说，你有一个𝑛 𝐻 × 𝑛 𝑊 × 𝑛 𝐶 的网络，有𝑛 𝐶 个通道，使用尺寸为𝑓 × 𝑓 × 𝑛 𝐶 的过滤器，每个过滤器的通道数和它上一层的通道数相同。这是由于在当时，计算机的运行速度非常慢，为了减少计算量和参数，经典的 LeNet-5 网络使用了非常复杂的计算方式，每个过滤器都采

397 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

用和输入模块一样的通道数量。论文中提到的这些复杂细节，现在一般都不用了。我认为当时所进行的最后一步其实到现在也还没有真正完成，就是经典的 LeNet-5 网络 在池化后进行了非线性函数处理，在这个例子中，池化层之后使用了 sigmoid 函数。如果你 真的去读这篇论文，这会是最难理解的部分之一，我们会在后面的课程中讲到。

下面要讲的网络结构简单一些，幻灯片的大部分类容来自于原文的第二段和第三段，原 文的后几段介绍了另外一种思路。文中提到的这种图形变形网络如今并没有得到广泛应用，所以在读这篇论文的时候，我建议精读第二段，这段重点介绍了这种网络结构。泛读第三段，这里面主要是一些有趣的实验结果。

我要举例说明的第二种神经网络是 AlexNet，是以论文的第一作者 Alex Krizhevsky 的名 字命名的，另外两位合著者是 Ilya Sutskever 和 Geoffery Hinton。

AlexNet 首先用一张 227×227×3 的图片作为输入，实际上原文中使用的图像是 224×224×3，但是如果你尝试去推导一下，你会发现 227×227 这个尺寸更好一些。第一层我们使用 96 个 11×11 的过滤器，步幅为 4，由于步幅是 4，因此尺寸缩小到 55×55，缩小了 4 倍左右。然后 用一个 3×3 的过滤器构建最大池化层，𝑓 = 3，步幅𝑠为 2，卷积层尺寸缩小为 27×27×96。接 着再执行一个 5×5 的卷积，padding 之后，输出是 27×27×276。然后再次进行最大池化，尺 寸缩小到 13×13。再执行一次 same 卷积，相同的 padding，得到的结果是 13×13×384，384 个过滤器。再做一次 same 卷积，就像这样。再做一次同样的操作，最后再进行一次最大池 化，尺寸缩小到 6×6×256。6×6×256 等于 9216，将其展开为 9216 个单元，然后是一些全连 接层。最后使用 softmax 函数输出识别的结果，看它究竟是 1000 个可能的对象中的哪一个。

实际上，这种神经网络与 LeNet 有很多相似之处，不过 AlexNet 要大得多。正如前面讲 到的 LeNet 或 LeNet-5 大约有 6 万个参数，而 AlexNet 包含约 6000 万个参数。当用于训练图 像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含着大量的隐

398 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

藏单元或数据，这一点 AlexNet 表现出色。AlexNet 比 LeNet 表现更为出色的另一个原因是 它使用了 ReLu 激活函数。

同样的，我还会讲一些比较深奥的内容，如果你并不打算阅读论文，不听也没有关系。第一点，在写这篇论文的时候，GPU 的处理速度还比较慢，所以 AlexNet 采用了非常复杂的 方法在两个 GPU 上进行训练。大致原理是，这些层分别拆分到两个不同的 GPU 上，同时还 专门有一个方法用于两个 GPU 进行交流。

论文还提到，经典的 AlexNet 结构还有另一种类型的层，叫作「局部响应归一化层」（Local Response Normalization），即 LRN 层，这类层应用得并不多，所以我并没有专门讲。局部响 应归一层的基本思路是，假如这是网络的一块，比如是 13×13×256，LRN 要做的就是选取一 个位置，比如说这样一个位置，从这个位置穿过整个通道，能得到 256 个数字，并进行归一 化。进行局部响应归一化的动机是，对于这张 13×13 的图像中的每个位置来说，我们可能并 不需要太多的高激活神经元。但是后来，很多研究者发现 LRN 起不到太大作用，这应该是被 我划掉的内容之一，因为并不重要，而且我们现在并不用 LRN 来训练网络。

如果你对深度学习的历史感兴趣的话，我认为在 AlexNet 之前，深度学习已经在语音识 别和其它几个领域获得了一些关注，但正是通过这篇论文，计算机视觉群体开始重视深度学 习，并确信深度学习可以应用于计算机视觉领域。此后，深度学习在计算机视觉及其它领域

399 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

的影响力与日俱增。如果你并不打算阅读这方面的论文，其实可以不用学习这节课。但如果 你想读懂一些相关的论文，这是比较好理解的一篇，学起来会容易一些。AlexNet 网络结构看起来相对复杂，包含大量超参数，这些数字（55×55×96、27×27×96、 27×27×256……）都是 Alex Krizhevsky 及其合著者不得不给出的。

这节课要讲的第三个，也是最后一个范例是 VGG，也叫作 VGG-16 网络。值得注意的一 点是，VGG-16 网络没有那么多超参数，这是一种只需要专注于构建卷积层的简单网络。首 先用 3×3，步幅为 1 的过滤器构建卷积层，padding 参数为 same 卷积中的参数。然后用一个 2×2，步幅为 2 的过滤器构建最大池化层。因此 VGG 网络的一大优点是它确实简化了神经网 络结构，下面我们具体讲讲这种网络结构。

假设要识别这个图像，在最开始的两层用 64 个 3×3 的过滤器对输入图像进行卷积，输 出结果是 224×224×64，因为使用了 same 卷积，通道数量也一样。VGG-16 其实是一个很深 的网络，这里我并没有把所有卷积层都画出来。

假设这个小图是我们的输入图像，尺寸是 224×224×3，进行第一个卷积之后得到 224×224×64 的特征图，接着还有一层 224×224×64，得到这样 2 个厚度为 64 的卷积层，意 味着我们用 64 个过滤器进行了两次卷积。正如我在前面提到的，这里采用的都是大小为 3×3，步幅为 1 的过滤器，并且都是采用 same 卷积，所以我就不再把所有的层都画出来了，只用 一串数字代表这些网络。

400 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

接下来创建一个池化层，池化层将输入图像进行压缩，从 224×224×64 缩小到多少呢？ 没错，减少到 112×112×64。然后又是若干个卷积层，使用 129 个过滤器，以及一些 same 卷 积，我们看看输出什么结果，112×112×128. 然后进行池化，可以推导出池化后的结果是这样 （56×56×128）。接着再用 256 个相同的过滤器进行三次卷积操作，然后再池化，然后再卷 积三次，再池化。如此进行几轮操作后，将最后得到的 7×7×512 的特征图进行全连接操作，得到 4096 个单元，然后进行 softmax 激活，输出从 1000 个对象中识别的结果。

顺便说一下，VGG-16 的这个数字 16，就是指在这个网络中包含 16 个卷积层和全连接 层。确实是个很大的网络，总共包含约 1.38 亿个参数，即便以现在的标准来看都算是非常 大的网络。但 VGG-16 的结构并不复杂，这点非常吸引人，而且这种网络结构很规整，都是 几个卷积层后面跟着可以压缩图像大小的池化层，池化层缩小图像的高度和宽度。同时，卷 积层的过滤器数量变化存在一定的规律，由 64 翻倍变成 128，再到 256 和 512。作者可能认 为 512 已经足够大了，所以后面的层就不再翻倍了。无论如何，每一步都进行翻倍，或者说 在每一组卷积层进行过滤器翻倍操作，正是设计此种网络结构的另一个简单原则。这种相对 一致的网络结构对研究者很有吸引力，而它的主要缺点是需要训练的特征数量非常巨大。

401 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

有些文章还介绍了 VGG-19 网络，它甚至比 VGG-16 还要大，如果你想了解更多细节，请参考幻灯片下方的注文，阅读由 Karen Simonyan 和 Andrew Zisserman 撰写的论文。由于 VGG-16 的表现几乎和 VGG-19 不分高下，所以很多人还是会使用 VGG-16。我最喜欢它的一 点是，文中揭示了，随着网络的加深，图像的高度和宽度都在以一定的规律不断缩小，每次 池化后刚好缩小一半，而通道数量在不断增加，而且刚好也是在每组卷积操作后增加一倍。也就是说，图像缩小的比例和通道数增加的比例是有规律的。从这个角度来看，这篇论文很 吸引人。

以上就是三种经典的网络结构，如果你对这些论文感兴趣，我建议从介绍 AlexNet 的论 文开始，然后就是 VGG 的论文，最后是 LeNet 的论文。虽然有些晦涩难懂，但对于了解这 些网络结构很有帮助。

学过这些经典的网络之后，下节课我们会学习一些更先高级更强大的神经网络结构，下 节课见。

402 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.3 残差网络 (ResNets)(Residual Networks (ResNets))

非常非常深的神经网络是很难训练的，因为存在梯度消失和梯度爆炸问题。这节课我们 学习跳跃连接（Skip connection），它可以从某一层网络层获取激活，然后迅速反馈给另外 一层，甚至是神经网络的更深层。我们可以利用跳跃连接构建能够训练深度网络的 ResNets，有时深度能够超过 100 层，让我们开始吧。

ResNets 是由残差块（Residual block）构建的，首先我解释一下什么是残差块。

这是一个两层神经网络，在𝐿层进行激活，得到𝑎 [𝑙+1] ，再次进行激活，两层之后得到𝑎 [𝑙+2] 。计算过程是从𝑎 [𝑙] 开始，首先进行线性激活，根据这个公式：𝑧 [𝑙+1] = 𝑊 [𝑙+1] 𝑎 [𝑙] + 𝑏 [𝑙+1] ，通 过𝑎 [𝑙] 算出𝑧 [𝑙+1] ，即𝑎 [𝑙] 乘以权重矩阵，再加上偏差因子。然后通过 ReLU 非线性激活函数得 到 𝑎 [𝑙+1] ，𝑎 [𝑙+1] = 𝑔(𝑧 [𝑙+1] ) 计 算 得 出 。接 着 再 次 进 行 线 性 激 活 ，依 据 等 式 𝑧 [𝑙+2] = 𝑊 [2+1] 𝑎 [𝑙+1] + 𝑏 [𝑙+2] ，最后根据这个等式再次进行 ReLu 非线性激活，即𝑎 [𝑙+2] = 𝑔(𝑧 [𝑙+2] )，这里的𝑔是指 ReLU 非线性函数，得到的结果就是𝑎 [𝑙+2] 。换句话说，信息流从𝑎 [𝑙] 到𝑎 [𝑙+2] 需 要经过以上所有步骤，即这组网络层的主路径。

403 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

在残差网络中有一点变化，我们将𝑎 [𝑙] 直接向后，拷贝到神经网络的深层，在 ReLU 非线 性激活函数前加上𝑎 [𝑙] ，这是一条捷径。𝑎 [𝑙] 的信息直接到达神经网络的深层，不再沿着主路 径传递，这就意味着最后这个等式 (𝑎 [𝑙+2] = 𝑔(𝑧 [𝑙+2] )) 去掉了，取而代之的是另一个 ReLU 非 线性函数，仍然对𝑧 [𝑙+2] 进行 𝑔函数处理，但这次要加上𝑎 [𝑙] ，即： 𝑎 [𝑙+2] = 𝑔(𝑧 [𝑙+2] + 𝑎 [𝑙] )，也就是加上的这个𝑎 [𝑙] 产生了一个残差块。

在上面这个图中，我们也可以画一条捷径，直达第二层。实际上这条捷径是在进行 ReLU 非线性激活函数之前加上的，而这里的每一个节点都执行了线性函数和 ReLU 激活函数。所 以𝑎 [𝑙] 插入的时机是在线性激活之后，ReLU 激活之前。除了捷径，你还会听到另一个术语「跳 跃连接」，就是指𝑎 [𝑙] 跳过一层或者好几层，从而将信息传递到神经网络的更深层。

ResNet 的发明者是何恺明（Kaiming He）、张翔宇（Xiangyu Zhang）、任少卿（Shaoqing Ren）和孙剑（Jiangxi Sun），他们发现使用残差块能够训练更深的神经网络。所以构建一个

404 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

ResNet 网络就是通过将很多这样的残差块堆积在一起，形成一个很深神经网络，我们来看 看这个网络。

这并不是一个残差网络，而是一个普通网络（Plain network），这个术语来自 ResNet 论 文。

把它变成 ResNet 的方法是加上所有跳跃连接，正如前一张幻灯片中看到的，每两层增 加一个捷径，构成一个残差块。如图所示，5 个残差块连接在一起构成一个残差网络。

如果我们使用标准优化算法训练一个普通网络，比如说梯度下降法，或者其它热门的优 化算法。如果没有残差，没有这些捷径或者跳跃连接，凭经验你会发现随着网络深度的加深，训练错误会先减少，然后增多。而理论上，随着网络深度的加深，应该训练得越来越好才对。也就是说，理论上网络深度越深越好。但实际上，如果没有残差网络，对于一个普通网络来 说，深度越深意味着用优化算法越难训练。实际上，随着网络深度的加深，训练错误会越来 越多。

405 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

但有了 ResNets 就不一样了，即使网络再深，训练的表现却不错，比如说训练误差减少，就算是训练深达 100 层的网络也不例外。有人甚至在 1000 多层的神经网络中做过实验，尽 管目前我还没有看到太多实际应用。但是对𝑥的激活，或者这些中间的激活能够到达网络的 更深层。这种方式确实有助于解决梯度消失和梯度爆炸问题，让我们在训练更深网络的同时，又能保证良好的性能。也许从另外一个角度来看，随着网络越来深，网络连接会变得臃肿，但是 ResNet 确实在训练深度网络方面非常有效。

现在大家对 ResNet 已经有了一个大致的了解，通过本周的编程练习，你可以尝试亲自 实现一下这些想法。至于为什么 ResNets 能有如此好的表现，接下来我会有更多更棒的内容 分享给大家，我们下个视频见。

406 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.4 残差网络为什么有用？（Why ResNets work?）

为什么 ResNets 能有如此好的表现，我们来看个例子，它解释了其中的原因，至少可以 说明，如何构建更深层次的 ResNets 网络的同时还不降低它们在训练集上的效率。希望你已 经通过第三门课了解到，通常来讲，网络在训练集上表现好，才能在 Hold-Out 交叉验证集 或 dev 集和测试集上有好的表现，所以至少在训练集上训练好 ResNets 是第一步。

先来看个例子，上节课我们了解到，一个网络深度越深，它在训练集上训练的效率就会 有所减弱，这也是有时候我们不希望加深网络的原因。而事实并非如此，至少在训练 ResNets 网络时，并非完全如此，举个例子。

假设有一个大型神经网络，其输入为𝑋，输出激活值𝑎 [𝑙] 。假如你想增加这个神经网络的 深度，那么用 Big NN 表示，输出为𝑎 [𝑙] 。再给这个网络额外添加两层，依次添加两层，最后 输出为𝑎 [𝑙+2] ，可以把这两层看作一个 ResNets 块，即具有捷径连接的残差块。为了方便说 明，假设我们在整个网络中使用 ReLU 激活函数，所以激活值都大于等于 0，包括输入𝑋的非 零异常值。因为 ReLU 激活函数输出的数字要么是 0，要么是正数。

我们看一下𝑎 [𝑙+2] 的值，也就是上节课讲过的表达式，即𝑎 [𝑙+2] = 𝑔(𝑧 [𝑙+2] + 𝑎 [𝑙] )，添加项 𝑎 [𝑙] 是刚添加的跳跃连接的输入。展开这个表达式𝑎 [𝑙+2] = 𝑔(𝑊 [𝑙+2] 𝑎 [𝑙+1] + 𝑏 [𝑙+2] + 𝑎 [𝑙] )，其

407 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

中𝑧 [𝑙+2] = 𝑊 [𝑙+2] 𝑎 [𝑙+1] + 𝑏 [𝑙+2] 。注意一点，如果使用 L2 正则化或权重衰减，它会压缩𝑊[𝑙+2] 的值。如果对𝑏应用权重衰减也可达到同样的效果，尽管实际应用中，你有时会对𝑏应用权重 衰减，有时不会。这里的𝑊是关键项，如果𝑊 [𝑙+2] = 0，为方便起见，假设𝑏 [𝑙+2] = 0，这几 项就没有了，因为它们（𝑊 [𝑙+2] 𝑎 [𝑙+1] + 𝑏 [𝑙+2] ）的值为 0。最后𝑎 [𝑙+2] = 𝑔(𝑎 [𝑙] ) = 𝑎 [𝑙] ，因为 我们假定使用 ReLU 激活函数，并且所有激活值都是非负的，𝑔(𝑎 [𝑙] ) 是应用于非负数的 ReLU 函数，所以𝑎 [𝑙+2] = 𝑎 [𝑙] 。

结果表明，残差块学习这个恒等式函数并不难，跳跃连接使我们很容易得出𝑎 [𝑙+2] = 𝑎 [𝑙] 。这意味着，即使给神经网络增加了这两层，它的效率也并不逊色于更简单的神经网络，因为 学习恒等函数对它来说很简单。尽管它多了两层，也只把𝑎 [𝑙] 的值赋值给𝑎 [𝑙+2] 。所以给大型 神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络 的表现。

当然，我们的目标不仅仅是保持网络的效率，还要提升它的效率。想象一下，如果这些 隐藏层单元学到一些有用信息，那么它可能比学习恒等函数表现得更好。而这些不含有残差 块或跳跃连接的深度普通网络情况就不一样了，当网络不断加深时，就算是选用学习恒等函 数的参数都很困难，所以很多层最后的表现不但没有更好，反而更糟。

我认为残差网络起作用的主要原因就是这些残差块学习恒等函数非常容易，你能确定网 络性能不会受到影响，很多时候甚至可以提高效率，或者说至少不会降低网络的效率，因此 创建类似残差网络可以提升网络性能。

408 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

除此之外，关于残差网络，另一个值得探讨的细节是，假设𝑧 [𝑙+2] 与𝑎 [𝑙] 具有相同维度，所以 ResNets 使用了许多 same 卷积，所以这个𝑎 [𝑙] 的维度等于这个输出层的维度。之所以能 实现跳跃连接是因为 same 卷积保留了维度，所以很容易得出这个捷径连接，并输出这两个 相同维度的向量。

如果输入和输出有不同维度，比如输入的维度是 128，𝑎 [𝑙+2] 的维度是 256，再增加一个 矩阵，这里标记为𝑊 ，𝑊 是一个 256×128 维度的矩阵，所以𝑊 𝑎 [𝑙] 的维度是 256，这个新增 𝑠 𝑠 𝑠 项是 256 维度的向量。你不需要对𝑊 做任何操作，它是网络通过学习得到的矩阵或参数，它 𝑠 是一个固定矩阵，padding 值为 0，用 0 填充𝑎 [𝑙] ，其维度为 256，所以者几个表达式都可以。

最后，我们来看看 ResNets 的图片识别。这些图片是我从何凯明等人论文中截取的，这 是一个普通网络，我们给它输入一张图片，它有多个卷积层，最后输出了一个 Softmax。

如何把它转化为 ResNets 呢？只需要添加跳跃连接。这里我们只讨论几个细节，这个网 络有很多层 3×3 卷积，而且它们大多都是 same 卷积，这就是添加等维特征向量的原因。所

409 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

以这些都是卷积层，而不是全连接层，因为它们是 same 卷积，维度得以保留，这也解释了 添加项𝑧 [𝑙+2] + 𝑎 [𝑙] （维度相同所以能够相加）。

ResNets 类似于其它很多网络，也会有很多卷积层，其中偶尔会有池化层或类池化层的 层。不论这些层是什么类型，正如我们在上一张幻灯片看到的，你都需要调整矩阵𝑊 的维度。𝑠 普通网络和 ResNets 网络常用的结构是：卷积层 - 卷积层 - 卷积层 - 池化层 - 卷积层 - 卷积层 - 卷积 层 - 池化层…… 依此重复。直到最后，有一个通过 softmax 进行预测的全连接层。

以上就是 ResNets 的内容。使用 1×1 的过滤器，即 1×1 卷积，这个想法很有意思，为什 么呢？我们下节课再讲。

410 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.5 网络中的网络以及 1×1 卷积（Network in Network and 1×1 convolutions）

在架构内容设计方面，其中一个比较有帮助的想法是使用 1×1 卷积。也许你会好奇，1×1 的卷积能做什么呢？不就是乘以数字么？听上去挺好笑的，结果并非如此，我们来具体 看看。

过滤器为 1×1，这里是数字 2，输入一张 6×6×1 的图片，然后对它做卷积，起过滤器大 小为 1×1×1，结果相当于把这个图片乘以数字 2，所以前三个单元格分别是 2、4、6 等等。用 1×1 的过滤器进行卷积，似乎用处不大，只是对输入矩阵乘以某个数字。但这仅仅是对于 6×6×1 的一个通道图片来说，1×1 卷积效果不佳。

如果是一张 6×6×32 的图片，那么使用 1×1 过滤器进行卷积效果更好。具体来说，1×1 卷 积所实现的功能是遍历这 36 个单元格，计算左图中 32 个数字和过滤器中 32 个数字的元素 积之和，然后应用 ReLU 非线性函数。

我们以其中一个单元为例，它是这个输入层上的某个切片，用这 36 个数字乘以这个输 入层上 1×1 切片，得到一个实数，像这样把它画在输出中。

这个 1×1×32 过滤器中的 32 个数字可以这样理解，一个神经元的输入是 32 个数字（输 入图片中左下角位置 32 个通道中的数字），即相同高度和宽度上某一切片上的 32 个数字，

411 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

这 32 个数字具有不同通道，乘以 32 个权重（将过滤器中的 32 个数理解为权重），然后应 用 ReLU 非线性函数，在这里输出相应的结果。

一般来说，如果过滤器不止一个，而是多个，就好像有多个输入单元，其输入内容为一 个切片上所有数字，输出结果是 6×6 过滤器数量。

所以 1×1 卷积可以从根本上理解为对这 32 个不同的位置都应用一个全连接层，全连接 层的作用是输入 32 个数字（过滤器数量标记为𝑛 𝐶 [𝑙+1] ，在这 36 个单元上重复此过程）, 输出 结果是 6×6×#filters（过滤器数量），以便在输入层上实施一个非平凡（non-trivial）计算。

这种方法通常称为 1×1 卷积，有时也被称为 Network in Network，在林敏、陈强和颜水 成的论文中有详细描述。虽然论文中关于架构的详细内容并没有得到广泛应用，但是 1×1 卷 积或 Network in Network 这种理念却很有影响力，很多神经网络架构都受到它的影响，包括 下节课要讲的 Inception 网络。

举个 1×1 卷积的例子，相信对大家有所帮助，这是它的一个应用。

假设这是一个 28×28×192 的输入层，你可以使用池化层压缩它的高度和宽度，这个过程 我们很清楚。但如果通道数量很大，该如何把它压缩为 28×28×32 维度的层呢？你可以用 32 个大小为 1×1 的过滤器，严格来讲每个过滤器大小都是 1×1×192 维，因为过滤器中通道数量 必须与输入层中通道的数量保持一致。但是你使用了 32 个过滤器，输出层为 28×28×32，这

412 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

就是压缩通道数（𝑛 𝑐 ）的方法，对于池化层我只是压缩了这些层的高度和宽度。

在之后我们看到在某些网络中 1×1 卷积是如何压缩通道数量并减少计算的。当然如果 你想保持通道数 192 不变，这也是可行的，1×1 卷积只是添加了非线性函数，当然也可以让 网络学习更复杂的函数，比如，我们再添加一层，其输入为 28×28×192，输出为 28×28×192。

1×1 卷积层就是这样实现了一些重要功能的（doing something pretty non-trivial），它给

神经网络添加了一个非线性函数，从而减少或保持输入层中的通道数量不变，当然如果你愿 意，也可以增加通道数量。后面你会发现这对构建 Inception 网络很有帮助，我们放在下节 课讲。这节课我们演示了如何根据自己的意愿通过 1×1 卷积的简单操作来压缩或保持输入层 中的通道数量，甚至是增加通道数量。下节课，我们再讲讲 1×1 卷积是如何帮助我们构建 Inception 网络的，下节课见。

413 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.6 谷歌 Inception 网络简介（Inception network motivation）

构建卷积层时，你要决定过滤器的大小究竟是 1×1（原来是 1×3，猜测为口误），3×3 还 是 5×5，或者要不要添加池化层。而 Inception 网络的作用就是代替你来决定，虽然网络架 构因此变得更加复杂，但网络表现却非常好，我们来了解一下其中的原理。

例如，这是你 28×28×192 维度的输入层，Inception 网络或 Inception 层的作用就是代替 人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层，我们演示一下。

如果使用 1×1 卷积，输出结果会是 28×28×#（某个值），假设输出为 28×28×64，并且这 里只有一个层。

如果使用 3×3 的过滤器，那么输出是 28×28×128。然后我们把第二个值堆积到第一个值 上，为了匹配维度，我们应用 same 卷积，输出维度依然是 28×28，和输入维度相同，即高 度和宽度相同。

或许你会说，我希望提升网络的表现，用 5×5 过滤器或许会更好，我们不妨试一下，输 出变成 28×28×32，我们再次使用 same 卷积，保持维度不变。

414 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

或许你不想要卷积层，那就用池化操作，得到一些不同的输出结果，我们把它也堆积起 来，这里的池化输出是 28×28×32。为了匹配所有维度，我们需要对最大池化使用 padding，它是一种特殊的池化形式，因为如果输入的高度和宽度为 28×28，则输出的相应维度也是 28×28。然后再进行池化，padding 不变，步幅为 1。

这个操作非常有意思，但我们要继续学习后面的内容，一会再实现这个池化过程。

有了这样的 Inception 模块，你就可以输入某个量，因为它累加了所有数字，这里的最 终输出为 32+32+128+64=256。Inception 模块的输入为 28×28×192，输出为 28×28×256。这就 是 Inception 网络的核心内容，提出者包括 Christian Szegedy、刘伟、贾扬清、Pierre Sermanet、 Scott Reed、Dragomir Anguelov、Dumitru Erhan、Vincent Vanhoucke 和 Andrew Rabinovich。基本思想是 Inception 网络不需要人为决定使用哪个过滤器或者是否需要池化，而是由网络 自行确定这些参数，你可以给网络添加这些参数的所有可能值，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。

不难发现，我所描述的 Inception 层有一个问题，就是计算成本，下一张幻灯片，我们 就来计算这个 5×5 过滤器在该模块中的计算成本。

415 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

我们把重点集中在前一张幻灯片中的 5×5 的过滤器，这是一个 28×28×192 的输入块，执 行一个 5×5 卷积，它有 32 个过滤器，输出为 28×28×32。前一张幻灯片中，我用一个紫色的 细长块表示，这里我用一个看起来更普通的蓝色块表示。我们来计算这个 28×28×32 输出的 计算成本，它有 32 个过滤器，因为输出有 32 个通道，每个过滤器大小为 5×5×192，输出大 小为 28×28×32，所以你要计算 28×28×32 个数字。对于输出中的每个数字来说，你都需要执 行 5×5×192 次乘法运算，所以乘法运算的总次数为每个输出值所需要执行的乘法运算次数 （5×5×192）乘以输出值个数（28×28×32），把这些数相乘结果等于 1.2 亿（120422400）。即使在现在，用计算机执行 1.2 亿次乘法运算，成本也是相当高的。下一张幻灯片会介绍 1×1 卷积的应用，也就是我们上节课所学的。为了降低计算成本，我们用计算成本除以因子 10，结果它从 1.2 亿减小到原来的十分之一。请记住 120 这个数字，一会还要和下一页看到的数 字做对比。

这里还有另外一种架构，其输入为 28×28×192，输出为 28×28×32。其结果是这样的，对 于输入层，使用 1×1 卷积把输入值从 192 个通道减少到 16 个通道。然后对这个较小层运行 5×5 卷积，得到最终输出。请注意，输入和输出的维度依然相同，输入是 28×28×192，输出 是 28×28×32，和上一页的相同。但我们要做的就是把左边这个大的输入层压缩成这个较小 的的中间层，它只有 16 个通道，而不是 192 个。

416 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

有时候这被称为瓶颈层，瓶颈通常是某个对象最小的部分，假如你有这样一个玻璃瓶，这是瓶塞位置，瓶颈就是这个瓶子最小的部分。

同理，瓶颈层也是网络中最小的部分，我们先缩小网络表示，然后再扩大它。接下来我们看看这个计算成本，应用 1×1 卷积，过滤器个数为 16，每个过滤器大小为 1×1×192，这两个维度相匹配（输入通道数与过滤器通道数），28×28×16 这个层的计算成本 是，输出 28×28×192 中每个元素都做 192 次乘法，用 1×1×192 来表示，相乘结果约等于 240 万。

那第二个卷积层呢？240 万只是第一个卷积层的计算成本，第二个卷积层的计算成本又 是多少呢？这是它的输出，28×28×32，对每个输出值应用一个 5×5×16 维度的过滤器，计算 结果为 1000 万。

所以所需要乘法运算的总次数是这两层的计算成本之和，也就是 1204 万，与上一张幻 灯片中的值做比较，计算成本从 1.2 亿下降到了原来的十分之一，即 1204 万。所需要的加

417 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

法运算与乘法运算的次数近似相等，所以我只统计了乘法运算的次数。总结一下，如果你在构建神经网络层的时候，不想决定池化层是使用 1×1，3×3 还是 5×5 的过滤器，那么 Inception 模块就是最好的选择。我们可以应用各种类型的过滤器，只需要 把输出连接起来。之后我们讲到计算成本问题，我们学习了如何通过使用 1×1 卷积来构建瓶 颈层，从而大大降低计算成本。

你可能会问，仅仅大幅缩小表示层规模会不会影响神经网络的性能？事实证明，只要合 理构建瓶颈层，你既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算。

这就是 Inception 模块的主要思想，我们在这总结一下。下节课，我们将演示一个完整 的 Inception 网络。

418 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.7 Inception 网络（Inception network）

在上节视频中，你已经见到了所有的 Inception 网络基础模块。在本视频中，我们将学 习如何将这些模块组合起来，构筑你自己的 Inception 网络。

Inception 模块会将之前层的激活或者输出作为它的输入，作为前提，这是一个 28×28×192 的输入，和我们之前视频中的一样。我们详细分析过的例子是，先通过一个 1×1 的层，再通过一个 5×5 的层，1×1 的层可能有 16 个通道，而 5×5 的层输出为 28×28×32，共 32 个通道，这就是上个视频最后讲到的我们处理的例子。

为了在这个 3×3 的卷积层中节省运算量，你也可以做相同的操作，这样的话 3×3 的层将 会输出 28×28×128。

或许你还想将其直接通过一个 1×1 的卷积层，这时就不必在后面再跟一个 1×1 的层了，这样的话过程就只有一步，假设这个层的输出是 28×28×64。

419 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

最后是池化层。

这里我们要做些有趣的事情，为了能在最后将这些输出都连接起来，我们会使用 same 类型的 padding 来池化，使得输出的高和宽依然是 28×28，这样才能将它与其他输出连接起 来。但注意，如果你进行了最大池化，即便用了 same padding，3×3 的过滤器，stride 为 1，其输出将会是 28×28×192，其通道数或者说深度与这里的输入（通道数）相同。所以看起来 它会有很多通道，我们实际要做的就是再加上一个 1×1 的卷积层，去进行我们在 1×1 卷积层 的视频里所介绍的操作，将通道的数量缩小，缩小到 28×28×32。也就是使用 32 个维度为 1×1×192 的过滤器，所以输出的维度其通道数缩小为 32。这样就避免了最后输出时，池化层 占据所有的通道。

420 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

最后，将这些方块全都连接起来。在这过程中，把得到的各个层的通道都加起来，最后 得到一个 28×28×256 的输出。通道连接实际就是之前视频中看到过的，把所有方块连接在一 起的操作。这就是一个 Inception 模块，而 Inception 网络所做的就是将这些模块都组合到一 起。

这是一张取自 Szegety et al 的论文中关于 Inception 网络的图片，你会发现图中有许多 重复的模块，可能整张图看上去很复杂，但如果你只截取其中一个环节（编号 1），就会发 现这是在前一页 ppt 中所见的 Inception 模块。

我们深入看看里边的一些细节，这是另一个 Inception 模块（编号 2），这也是一个 Inception 模块（编号 3）。这里有一些额外的最大池化层（编号 6）来修改高和宽的维度。这是另外一个 Inception 模块（编号 4），这是另外一个最大池化层（编号 7），它改变了高 和宽。而这里又是另一个 Inception 模块（编号 5）。

所以 Inception 网络只是很多这些你学过的模块在不同的位置重复组成的网络，所以如 果你理解了之前所学的 Inception 模块，你就也能理解 Inception 网络。

421 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

事实上，如果你读过论文的原文，你就会发现，这里其实还有一些分支，我现在把它们 加上去。所以这些分支有什么用呢？在网络的最后几层，通常称为全连接层，在它之后是一 个 softmax 层（编号 1）来做出预测，这些分支（编号 2）所做的就是通过隐藏层（编号 3） 来做出预测，所以这其实是一个 softmax 输出（编号 2），这（编号 1）也是。这是另一条 分支（编号 4），它也包含了一个隐藏层，通过一些全连接层，然后有一个 softmax 来预测，输出结果的标签。

你应该把它看做 Inception 网络的一个细节，它确保了即便是隐藏单元和中间层（编号 5）也参与了特征计算，它们也能预测图片的分类。它在 Inception 网络中，起到一种调整的 效果，并且能防止网络发生过拟合。

还有这个特别的 Inception 网络是由 Google 公司的作者所研发的，它被叫做 GoogleLeNet，这个名字是为了向 LeNet 网络致敬。在之前的视频中你应该了解了 LeNet 网络。我觉得这样 非常好，因为深度学习研究人员是如此重视协作，深度学习工作者对彼此的工作成果有一种 强烈的敬意。

最后，有个有趣的事实，Inception 网络这个名字又是缘何而来呢？Inception 的论文特 地提到了这个模因（meme，网络用语即「梗」），就是「我们需要走的更深」（We need to go deeper），论文还引用了这个网址（http://knowyourmeme.com/memes/we-need-to-go-deeper），连接到这幅图片上，如果你看过 Inception（盗梦空间）这个电影，你应该能看懂这个由来。作者其实是通过它来表明了建立更深的神经网络的决心，他们正是这样构建了 Inception。我想一般研究论文，通常不会引用网络流行模因（梗），但这里显然很合适。

422 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

最后总结一下，如果你理解了 Inception 模块，你就能理解 Inception 网络，无非是很多 个 Inception 模块一环接一环，最后组成了网络。自从 Inception 模块诞生以来，经过研究者 们的不断发展，衍生了许多新的版本。所以在你们看一些比较新的 Inception 算法的论文时，会发现人们使用这些新版本的算法效果也一样很好，比如 Inception V2、V3 以及 V4，还有 一个版本引入了跳跃连接的方法，有时也会有特别好的效果。但所有的这些变体都建立在同 一种基础的思想上，在之前的视频中你就已经学到过，就是把许多 Inception 模块通过某种 方式连接到一起。通过这个视频，我想你应该能去阅读和理解这些 Inception 的论文，甚至 是一些新版本的论文。

直到现在，你已经了解了许多专用的神经网络结构。在下节视频中，我将会告诉你们如 何真正去使用这些算法来构建自己的计算机视觉系统，我们下节视频再见。

423 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.8 使 用 开 源 的 实 现 方 案 （ Using implementations）

open-source 

你现在已经学过几个非常有效的神经网络和 ConvNet 架构，在接下来的几段视频中我 想与你分享几条如何使用它们的实用性建议，首先从使用开放源码的实现开始。

事实证明很多神经网络复杂细致，因而难以复制，因为一些参数调整的细节问题，例如 学习率衰减等等，会影响性能。所以我发现有些时候，甚至在顶尖大学学习 AI 或者深度学 习的博士生也很难通过阅读别人的研究论文来复制他人的成果。幸运的是有很多深度学习的 研究者都习惯把自己的成果作为开发资源，放在像 GitHub 之类的网站上。当你自己编写代 码时，我鼓励你考虑一下将你的代码贡献给开源社区。如果你看到一篇研究论文想应用它的 成果，你应该考虑做一件事，我经常做的就是在网络上寻找一个开源的实现。因为你如果能 得到作者的实现，通常要比你从头开始实现要快得多，虽然从零开始实现肯定可以是一个很 好的锻炼。

如果你已经熟悉如何使用 GitHub，这段视频对你来说可能没什么必要或者没那么重要。但是如果你不习惯从 GitHub 下载开源代码，让我来演示一下。

（整理者注：ResNets 实现的 GitHub 地址 https://github.com/KaimingHe/deep-residualnetworks）

假设你对残差网络感兴趣，那就让我们搜索 GitHub 上的 ResNets，那么你可以在 GitHub 看到很多不同的 ResNet 的实现。我就打开这里的第一个网址，这是一个 ResNets 实现的 GitHub 资源库。在很多 GitHub 的网页上往下翻，你会看到一些描述，这个实现的文字说明。这个 GitHub 资源库，实际上是由 ResNet 论文原作者上传的。这些代码，这里有麻省理工学

424 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

院的许可，你可以点击查看此许可的含义，MIT 许可是比较开放的开源许可之一。我将下载 代码，点击这里的链接，它会给你一个 URL，通过这个你可以下载这个代码。

我点击这里的按钮（Clone or download），将这个 URL 复制到我的剪切板里。

（整理者注：NG 此处使用的是 linux 系统的 bash 命令行，对于 win10 系统，可以开启 linux 子系统功能，然后在 win10 应用商店下载 ubuntu 安装，运行 CMD，输入命令 bash 即 可进入 linux 的 bash 命令行）

接着到这里，接下来你要做的就是输入 git clone，接着粘贴 URL，按下回车，几秒之内 就将这个资源库的副本下载到我的本地硬盘里。

让我们进入目录，让我们看一下，比起 Windows，我更习惯用 Mac，不过没关系，让我 们试一下，让我们进入 prototxt，我认为这就是存放这些网络文件的地方。让我们看一下这 个文件。因为这个文件很长，包含了 ResNet 里 101 层的详细配置。我记得，从这个网页上 看到这个特殊实现使用了 Caffe 框架。但如果你想通过其它编程框架来实现这一代码，你也

425 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

可以尝试寻找一下。

如果你在开发一个计算机视觉应用，一个常见的工作流程是，先选择一个你喜欢的架构，

426 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

或许是你在这门课中学习到的，或者是你从朋友那听说的，或者是从文献中看到的，接着寻 找一个开源实现，从 GitHub 下载下来，以此基础开始构建。这样做的优点在于，这些网络 通常都需要很长的时间来训练，而或许有人已经使用多个 GPU，通过庞大的数据集预先训练 了这些网络，这样一来你就可以使用这些网络进行迁移学习，我们将在下一节课讨论这些内 容。当然，如果你是一名计算机视觉研究员，从零来实现这些，那么你的工作流程将会不同，如果你自己构建，那么希望你将工作成果贡献出来，放到开源社区。因为已经有如此多计算 机视觉研究者为了实现这些架构做了如此之多的工作，我发现从开源项目上开始是一个更好 的方法，它也确实是一个更快开展新项目的方法。

427 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.9 迁移学习（Transfer Learning）

如果你要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开 始，如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预 训练，然后转换到你感兴趣的任务上。计算机视觉的研究社区非常喜欢把许多数据集上传到 网上，如果你听说过，比如 ImageNet，或者 MS COCO，或者 Pascal 类型的数据集，这些都 是不同数据集的名字，它们都是由大家上传到网络的，并且有大量的计算机视觉研究者已经 用这些数据集训练过他们的算法了。有时候这些训练过程需要花费好几周，并且需要很多的 GPU，其它人已经做过了，并且经历了非常痛苦的寻最优过程，这就意味着你可以下载花费 了别人好几周甚至几个月而做出来的开源的权重参数，把它当作一个很好的初始化用在你自 己的神经网络上。用迁移学习把公共的数据集的知识迁移到你自己的问题上，让我们看一下 怎么做。

举个例子，假如说你要建立一个猫咪检测器，用来检测你自己的宠物猫。比如网络上的 Tigger，是一个常见的猫的名字，Misty 也是比较常见的猫名字。假如你的两只猫叫 Tigger 和 Misty，还有一种情况是，两者都不是。所以你现在有一个三分类问题，图片里是 Tigger 还 是 Misty，或者都不是，我们忽略两只猫同时出现在一张图片里的情况。现在你可能没有 Tigger 或者 Misty 的大量的图片，所以你的训练集会很小，你该怎么办呢？

我建议你从网上下载一些神经网络开源的实现，不仅把代码下载下来，也把权重下载下 来。有许多训练好的网络，你都可以下载。举个例子，ImageNet 数据集，它有 1000 个不同 的类别，因此这个网络会有一个 Softmax 单元，它可以输出 1000 个可能类别之一。

428 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

你可以去掉这个 Softmax 层，创建你自己的 Softmax 单元，用来输出 Tigger、Misty 和 neither 三个类别。就网络而言，我建议你把所有的层看作是冻结的，你冻结网络中所有层 的参数，你只需要训练和你的 Softmax 层有关的参数。这个 Softmax 层有三种可能的输出，Tigger、Misty 或者都不是。

通过使用其他人预训练的权重，你很可能得到很好的性能，即使只有一个小的数据集。幸运的是，大多数深度学习框架都支持这种操作，事实上，取决于用的框架，它也许会有 trainableParameter=0 这样的参数，对于这些前面的层，你可能会设置这个参数。为了 不训练这些权重，有时也会有 freeze=1 这样的参数。不同的深度学习编程框架有不同的 方式，允许你指定是否训练特定层的权重。在这个例子中，你只需要训练 softmax 层的权重，把前面这些层的权重都冻结。

另一个技巧，也许对一些情况有用，由于前面的层都冻结了，相当于一个固定的函数，不需要改变。因为你不需要改变它，也不训练它，取输入图像𝑋，然后把它映射到这层（softmax 的前一层）的激活函数。所以这个能加速训练的技巧就是，如果我们先计算这一层（紫色箭 头标记），计算特征或者激活值，然后把它们存到硬盘里。你所做的就是用这个固定的函数，在这个神经网络的前半部分（softmax 层之前的所有层视为一个固定映射），取任意输入图 像𝑋，然后计算它的某个特征向量，这样你训练的就是一个很浅的 softmax 模型，用这个特 征向量来做预测。对你的计算有用的一步就是对你的训练集中所有样本的这一层的激活值进 行预计算，然后存储到硬盘里，然后在此之上训练 softmax 分类器。所以，存储到硬盘或者 说预计算方法的优点就是，你不需要每次遍历训练集再重新计算这个激活值了。

因此如果你的任务只有一个很小的数据集，你可以这样做。要有一个更大的训练集怎么 办呢？根据经验，如果你有一个更大的标定的数据集，也许你有大量的 Tigger 和 Misty 的照 片，还有两者都不是的，这种情况，你应该冻结更少的层，比如只把这些层冻结，然后训练

429 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

后面的层。如果你的输出层的类别不同，那么你需要构建自己的输出单元，Tigger、Misty 或 者两者都不是三个类别。有很多方式可以实现，你可以取后面几层的权重，用作初始化，然 后从这里开始梯度下降。

或者你可以直接去掉这几层，换成你自己的隐藏单元和你自己的 softmax 输出层，这些 方法值得一试。但是有一个规律，如果你有越来越多的数据，你需要冻结的层数越少，你能 够训练的层数就越多。这个理念就是，如果你有一个更大的数据集，也许有足够多的数据，那么不要单单训练一个 softmax 单元，而是考虑训练中等大小的网络，包含你最终要用的网 络的后面几层。

最后，如果你有大量数据，你应该做的就是用开源的网络和它的权重，把这、所有的权 重当作初始化，然后训练整个网络。再次注意，如果这是一个 1000 节点的 softmax，而你只 有三个输出，你需要你自己的 softmax 输出层来输出你要的标签。

如果你有越多的标定的数据，或者越多的 Tigger、Misty 或者两者都不是的图片，你可 以训练越多的层。极端情况下，你可以用下载的权重只作为初始化，用它们来代替随机初始 化，接着你可以用梯度下降训练，更新网络所有层的所有权重。

这就是卷积网络训练中的迁移学习，事实上，网上的公开数据集非常庞大，并且你下载 的其他人已经训练好几周的权重，已经从数据中学习了很多了，你会发现，对于很多计算机 视觉的应用，如果你下载其他人的开源的权重，并用作你问题的初始化，你会做的更好。在 所有不同学科中，在所有深度学习不同的应用中，我认为计算机视觉是一个你经常用到迁移 学习的领域，除非你有非常非常大的数据集，你可以从头开始训练所有的东西。总之，迁移 学习是非常值得你考虑的，除非你有一个极其大的数据集和非常大的计算量预算来从头训练 你的网络。

430 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.10 数据增强（Data augmentation）

大部分的计算机视觉任务使用很多的数据，所以数据增强是经常使用的一种技巧来提高 计算机视觉系统的表现。我认为计算机视觉是一个相当复杂的工作，你需要输入图像的像素 值，然后弄清楚图片中有什么，似乎你需要学习一个复杂方程来做这件事。在实践中，更多 的数据对大多数计算机视觉任务都有所帮助，不像其他领域，有时候得到充足的数据，但是 效果并不怎么样。但是，当下在计算机视觉方面，计算机视觉的主要问题是没有办法得到充 足的数据。对大多数机器学习应用，这不是问题，但是对计算机视觉，数据就远远不够。所 以这就意味着当你训练计算机视觉模型的时候，数据增强会有所帮助，这是可行的，无论你 是使用迁移学习，使用别人的预训练模型开始，或者从源代码开始训练模型。让我们来看一 下计算机视觉中常见的数据增强的方法。

或许最简单的数据增强方法就是垂直镜像对称，假如，训练集中有这张图片，然后将其 翻转得到右边的图像。对大多数计算机视觉任务，左边的图片是猫，然后镜像对称仍然是猫，如果镜像操作保留了图像中想识别的物体的前提下，这是个很实用的数据增强技巧。

另一个经常使用的技巧是随机裁剪，给定一个数据集，然后开始随机裁剪，可能修剪这 个（编号 1），选择裁剪这个（编号 2），这个（编号 3），可以得到不同的图片放在数据集

431 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

中，你的训练集中有不同的裁剪。随机裁剪并不是一个完美的数据增强的方法，如果你随机 裁剪的那一部分（红色方框标记部分，编号 4），这部分看起来不像猫。但在实践中，这个 方法还是很实用的，随机裁剪构成了很大一部分的真实图片。

镜像对称和随机裁剪是经常被使用的。当然，理论上，你也可以使用旋转，剪切（shearing： 此处并非裁剪的含义，图像仅水平或垂直坐标发生变化）图像，可以对图像进行这样的扭曲 变形，引入很多形式的局部弯曲等等。当然使用这些方法并没有坏处，尽管在实践中，因为 太复杂了所以使用的很少。

第二种经常使用的方法是彩色转换，有这样一张图片，然后给 R、G 和 B 三个通道上加 上不同的失真值。

在这个例子中（编号 1），要给红色、蓝色通道加值，给绿色通道减值。红色和蓝色会 产生紫色，使整张图片看起来偏紫，这样训练集中就有失真的图片。为了演示效果，我对图 片的颜色进行改变比较夸张。在实践中，对 R、G 和 B 的变化是基于某些分布的，这样的改 变也可能很小。

这么做的目的就是使用不同的 R、G 和 B 的值，使用这些值来改变颜色。在第二个例子

432 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

中（编号 2），我们少用了一点红色，更多的绿色和蓝色色调，这就使得图片偏黄一点。在这（编号 3）使用了更多的蓝色，仅仅多了点红色。在实践中，R、G 和 B 的值是根 据某种概率分布来决定的。这么做的理由是，可能阳光会有一点偏黄，或者是灯光照明有一 点偏黄，这些可以轻易的改变图像的颜色，但是对猫的识别，或者是内容的识别，以及标签 𝑦，还是保持不变的。所以介绍这些，颜色失真或者是颜色变换方法，这样会使得你的学习 算法对照片的颜色更改更具鲁棒性。

这是对更高级的学习者的一些注意提醒，你可以不理解我用红色标出来的内容。对 R、 G 和 B 有不同的采样方式，其中一种影响颜色失真的算法是 PCA，即主成分分析，我在机器 学习的 mooc 中讲过，在 Coursera ml-class.Org 机器学习这门课中。但具体颜色改变的细节 在 AlexNet 的论文中有时候被称作 PCA 颜色增强，PCA 颜色增强的大概含义是，比如说，如 果你的图片呈现紫色，即主要含有红色和蓝色，绿色很少，然后 PCA 颜色增强算法就会对红 色和蓝色增减很多，绿色变化相对少一点，所以使总体的颜色保持一致。如果这些你都不懂，不需要担心，可以在网上搜索你想要了解的东西，如果你愿意的话可以阅读 AlexNet 论文中 的细节，你也能找到 PCA 颜色增强的开源实现方法，然后直接使用它。

你可能有存储好的数据，你的训练数据存在硬盘上，然后使用符号，这个圆桶来表示你

433 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

的硬盘。如果你有一个小的训练数据，你可以做任何事情，这些数据集就够了。

但是你有特别大的训练数据，接下来这些就是人们经常使用的方法。你可能会使用 CPU 线程，然后它不停的从硬盘中读取数据，所以你有一个从硬盘过来的图片数据流。你可以用 CPU 线程来实现这些失真变形，可以是随机裁剪、颜色变化，或者是镜像。但是对每张图片 得到对应的某一种变形失真形式，看这张图片（编号 1），对其进行镜像变换，以及使用颜 色失真，这张图最后会颜色变化（编号 2），从而得到不同颜色的猫。

与此同时，CPU 线程持续加载数据，然后实现任意失真变形，从而构成批数据或者最小 批数据，这些数据持续的传输给其他线程或者其他的进程，然后开始训练，可以在 CPU 或 者 GPU 上实现训一个大型网络的训练。

常用的实现数据增强的方法是使用一个线程或者是多线程，这些可以用来加载数据，实 现变形失真，然后传给其他的线程或者其他进程，来训练这个（编号 2）和这个（编号 1），可以并行实现。

这就是数据增强，与训练深度神经网络的其他部分类似，在数据增强过程中也有一些超

434 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

参数，比如说颜色变化了多少，以及随机裁剪的时候使用的参数。与计算机视觉其他部分类 似，一个好的开始可能是使用别人的开源实现，了解他们如何实现数据增强。当然如果你想 获得更多的不变特性，而其他人的开源实现并没有实现这个，你也可以去调整这些参数。因 此，我希望你们可以使用数据增强使你的计算机视觉应用效果更好。

435 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

2.11 计算机视觉现状（The state of computer vision）

深度学习已经成功地应用于计算机视觉、自然语言处理、语音识别、在线广告、物流还 有其他许多问题。在计算机视觉的现状下，深度学习应用于计算机视觉应用有一些独特之处。在这个视频中，我将和你们分享一些我对深度学习在计算机视觉方面应用的认识，希望能帮 助你们更好地理解计算机视觉作品（此处指计算机视觉或者数据竞赛中的模型）以及其中的 想法，以及如何自己构建这些计算机视觉系统。

你可以认为大部分机器学习问题是介于少量数据和大量数据范围之间的。举个例子，我 认为今天我们有相当数量的语音识别数据，至少相对于这个问题的复杂性而言。虽然现在图 像识别或图像分类方面有相当大的数据集，因为图像识别是一个复杂的问题，通过分析像素 并识别出它是什么，感觉即使在线数据集非常大，如超过一百万张图片，我们仍然希望我们 能有更多的数据。还有一些问题，比如物体检测，我们拥有的数据更少。提醒一下，图像识 别其实是如何看图片的问题，并且告诉你这张图是不是猫，而对象检测则是看一幅图，你画 一个框，告诉你图片里的物体，比如汽车等等。因为获取边框的成本比标记对象的成本更高，所以我们进行对象检测的数据往往比图像识别数据要少，对象检测是我们下周要讨论的内 容。

所以，观察一下机器学习数据范围图谱，你会发现当你有很多数据时，人们倾向于使用 更简单的算法和更少的手工工程，因为我们不需要为这个问题精心设计特征。当你有大量的 数据时，只要有一个大型的神经网络，甚至一个更简单的架构，可以是一个神经网络，就可 以去学习它想学习的东西。

436 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

相反当你没有那么多的数据时，那时你会看到人们从事更多的是手工工程，低调点说就 是你有很多小技巧可用（整理者注：在机器学习或者深度学习中，一般更崇尚更少的人工处 理，而手工工程更多依赖人工处理，注意领会 Andrew NG 的意思）。但我认为当你没有太 多数据时，手工工程实际上是获得良好表现的最佳方式。

所以当我看机器学习应用时，我们认为通常我们的学习算法有两种知识来源，一个来源 是被标记的数据，就像 (𝑥，𝑦) 应用在监督学习。第二个知识来源是手工工程，有很多方法去 建立一个手工工程系统，它可以是源于精心设计的特征，手工精心设计的网络体系结构或者 是系统的其他组件。所以当你没有太多标签数据时，你只需要更多地考虑手工工程。

所以我认为计算机视觉是在试图学习一个非常复杂的功能，我们经常感觉我们没有足够 的数据，即使获得了更多数据，我们还是经常觉得还是没有足够的数据来满足需求。这就是 为什么计算机视觉，从过去甚至到现在都更多地依赖于手工工程。我认为这也是计算机视觉 领域发展相当复杂网络架构地原因，因为在缺乏更多数据的情况下，获得良好表现的方式还 是花更多时间进行架构设计，或者说在网络架构设计上浪费（贬义褒用，即需要花费更多时 间的意思）更多时间。

如果你认为我是在贬低手工工程，那并不是我的意思，当你没有足够的数据时，手工工 程是一项非常困难，非常需要技巧的任务，它需要很好的洞察力，那些对手工工程有深刻见

437 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

解的人将会得到更好的表现。当你没有足够的数据时，手工工程对一个项目来说贡献就很大。当你有很多数据的时候我就不会花时间去做手工工程，我会花时间去建立学习系统。但我认 为从历史而言，计算机视觉领域还只是使用了非常小的数据集，因此从历史上来看计算机视 觉还是依赖于大量的手工工程。甚至在过去的几年里，计算机视觉任务的数据量急剧增加，我认为这导致了手工工程量大幅减少，但是在计算机视觉上仍然有很多的网络架构使用手工 工程，这就是为什么你会在计算机视觉中看到非常复杂的超参数选择，比你在其他领域中要 复杂的多。实际上，因为你通常有比图像识别数据集更小的对象检测数据集，当我们谈论对 象检测时，其实这是下周的任务，你会看到算法变得更加复杂，而且有更多特殊的组件。

幸运的是，当你有少量的数据时，有一件事对你很有帮助，那就是迁移学习。我想说的 是，在之前的幻灯片中，Tigger、Misty 或者二者都不是的检测问题中，我们有这么少的数据，迁移学习会有很大帮助。这是另一套技术，当你有相对较少的数据时就可以用很多相似的数 据。

如果你看一下计算机视觉方面的作品，看看那里的创意，你会发现人们真的是踌躇满志，他们在基准测试中和竞赛中表现出色。对计算机视觉研究者来说，如果你在基准上做得很好 了，那就更容易发表论文了，所以有许多人致力于这些基准上，把它做得很好。积极的一面 是，它有助于整个社区找出最有效得算法。但是你在论文上也看到，人们所做的事情让你在 数据基准上表现出色，但你不会真正部署在一个实际得应用程序用在生产或一个系统上。

（整理着注：Benchmark 基准测试，Benchmark 是一个评价方式，在整个计算机领域有 着长期的应用。维基百科上解释：「As computer architecture advanced, it became more difficult to compare the performance of various computer systems simply by looking at their specifications.Therefore, tests were developed that allowed comparison of different architectures.」Benchmark 在计算机领域应用最成功的就是性能测试，主要测试负载的执行时 间、传输速度、吞吐量、资源占用率等。）

下面是一些有助于在基准测试中表现出色的小技巧，这些都是我自己从来没使用过的东 西，如果我把一个系统投入生产，那就是为客户服务。

438 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

其中一个是集成，这就意味着在你想好了你想要的神经网络之后，可以独立训练几个神 经网络，并平均它们的输出。比如说随机初始化三个、五个或者七个神经网络，然后训练所 有这些网络，然后平均它们的输出。另外对他们的输出𝑦进行平均计算是很重要的，不要平 均他们的权重，这是行不通的。看看你的 7 个神经网络，它们有 7 个不同的预测，然后平均 他们，这可能会让你在基准上提高 1%，2% 或者更好。这会让你做得更好，也许有时会达到 1% 或 2%，这真的能帮助你赢得比赛。但因为集成意味着要对每张图片进行测试，你可能需 要在从 3 到 15 个不同的网络中运行一个图像，这是很典型的，因为这 3 到 15 个网络可能 会让你的运行时间变慢，甚至更多时间，所以技巧之一的集成是人们在基准测试中表现出色 和赢得比赛的利器，但我认为这几乎不用于生产服务于客户的，我想除非你有一个巨大的计 算预算而且不介意在每个用户图像数据上花费大量的计算。

你在论文中可以看到在测试时，对进准测试有帮助的另一个技巧就是 Multi-crop at test time，我的意思是你已经看到了如何进行数据增强，Multi-crop 是一种将数据增强应用到你 的测试图像中的一种形式。

439 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

举个例子，让我们看看猫的图片，然后把它复制四遍，包括它的两个镜像版本。有一种 叫作 10-crop 的技术（crop 理解为裁剪的意思），它基本上说，假设你取这个中心区域，裁 剪，然后通过你的分类器去运行它，然后取左上角区域，运行你的分类器，右上角用绿色表 示，左下方用黄色表示，右下方用橙色表示，通过你的分类器来运行它，然后对镜像图像做 同样的事情对吧？所以取中心的 crop，然后取四个角落的 crop。

这是这里（编号 1）和这里（编号 3）就是中心 crop，这里（编号 2）和这里（编号 4） 就是四个角落的 crop。如果把这些加起来，就会有 10 种不同的图像的 crop，因此命名为 10crop。所以你要做的就是，通过你的分类器来运行这十张图片，然后对结果进行平均。如果 你有足够的计算预算，你可以这么做，也许他们需要 10 个 crops，你可以使用更多，这可能 会让你在生产系统中获得更好的性能。如果是生产的话，我的意思还是实际部署用户的系统。但这是另一种技术，它在基准测试上的应用，要比实际生产系统中好得多。

集成的一个大问题是你需要保持所有这些不同的神经网络，这就占用了更多的计算机内 存。对于 multi-crop，我想你只保留一个网络，所以它不会占用太多的内存，但它仍然会让 你的运行时间变慢。

这些是你看到的小技巧，研究论文也可以参考这些，但我个人并不倾向于在构建生产系 统时使用这些方法，尽管它们在基准测试和竞赛上做得很好。

由于计算机视觉问题建立在小数据集之上，其他人已经完成了大量的网络架构的手工工 程。一个神经网络在某个计算机视觉问题上很有效，但令人惊讶的是它通常也会解决其他计 算机视觉问题。

所以，要想建立一个实用的系统，你最好先从其他人的神经网络架构入手。如果可能的 话，你可以使用开源的一些应用，因为开放的源码实现可能已经找到了所有繁琐的细节，比 如学习率衰减方式或者超参数。

最后，其他人可能已经在几路 GPU 上花了几个星期的时间来训练一个模型，训练超过 一百万张图片，所以通过使用其他人的预先训练得模型，然后在数据集上进行微调，你可以

440 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第二周 深度卷积网络：实例探究（Deep convolutional models: case studies）

在应用程序上运行得更快。当然如果你有电脑资源并且有意愿，我不会阻止你从头开始训练 你自己的网络。事实上，如果你想发明你自己的计算机视觉算法，这可能是你必须要做的。这就是本周的学习，我希望看到大量的计算机视觉架构能够帮助你理解什么是有效的。在本周的编程练习中，你实际上会学习另一种编程框架，并使用它来实现 ResNets。所以我 希望你们喜欢这个编程练习，我期待下周还能见到你们。

参考文献：

• Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - Deep Residual Learning for Image Recognition (2015) 

• Francois Chollet's github repository: https://github.com/fchollet/deep-learningmodels/blob/master/resnet50.py 

441 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

第三周 目标检测（Object detection）

3.1 目标定位（Object localization）

这一周我们学习的主要内容是对象检测，它是计算机视觉领域中一个新兴的应用方向，相比前两年，它的性能越来越好。在构建对象检测之前，我们先了解一下对象定位，首先我 们看看它的定义。

图片分类任务我们已经熟悉了，就是算法遍历图片，判断其中的对象是不是汽车，这就 是图片分类。这节课我们要学习构建神经网络的另一个问题，即定位分类问题。这意味着，我们不仅要用算法判断图片中是不是一辆汽车，还要在图片中标记出它的位置，用边框或红 色方框把汽车圈起来，这就是定位分类问题。其中「定位」的意思是判断汽车在图片中的具体 位置。这周后面几天，我们再讲讲当图片中有多个对象时，应该如何检测它们，并确定出位 置。比如，你正在做一个自动驾驶程序，程序不但要检测其它车辆，还要检测其它对象，如 行人、摩托车等等，稍后我们再详细讲。

本周我们要研究的分类定位问题，通常只有一个较大的对象位于图片中间位置，我们要 对它进行识别和定位。而在对象检测问题中，图片可以含有多个对象，甚至单张图片中会有 多个不同分类的对象。因此，图片分类的思路可以帮助学习分类定位，而对象定位的思路又 有助于学习对象检测，我们先从分类和定位开始讲起。

图片分类问题你已经并不陌生了，例如，输入一张图片到多层卷积神经网络。这就是卷 积神经网络，它会输出一个特征向量，并反馈给 softmax 单元来预测图片类型。

442 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

如果你正在构建汽车自动驾驶系统，那么对象可能包括以下几类：行人、汽车、摩托车 和背景，这意味着图片中不含有前三种对象，也就是说图片中没有行人、汽车和摩托车，输 出结果会是背景对象，这四个分类就是 softmax 函数可能输出的结果。

这就是标准的分类过程，如果你还想定位图片中汽车的位置，该怎么做呢？我们可以让 神经网络多输出几个单元，输出一个边界框。具体说就是让神经网络再多输出 4 个数字，标 记为𝑏 𝑥 ,𝑏 𝑦 ,𝑏 ℎ 和𝑏 𝑤 ，这四个数字是被检测对象的边界框的参数化表示。

我们先来约定本周课程将使用的符号表示，图片左上角的坐标为 (0,0)，右下角标记为 (1,1)。要确定边界框的具体位置，需要指定红色方框的中心点，这个点表示为 (𝑏 𝑥 ,𝑏 𝑦)，边界 框的高度为𝑏 ℎ ，宽度为𝑏 𝑤 。因此训练集不仅包含神经网络要预测的对象分类标签，还要包含 表示边界框的这四个数字，接着采用监督学习算法，输出一个分类标签，还有四个参数值，从而给出检测对象的边框位置。此例中，𝑏 𝑥 的理想值是 0.5，因为它表示汽车位于图片水平 方向的中间位置；𝑏 𝑦 大约是 0.7，表示汽车位于距离图片底部 10 3 的位置；𝑏 ℎ 约为 0.3，因为红 色方框的高度是图片高度的 0.3 倍；𝑏 𝑤 约为 0.4，红色方框的宽度是图片宽度的 0.4 倍。

443 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

下面我再具体讲讲如何为监督学习任务定义目标标签 𝑦。

请注意，这有四个分类，神经网络输出的是这四个数字和一个分类标签，或分类标签出 𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 现的概率。目标标签𝑦的定义如下：𝑦 = 𝑏𝑤 𝑐1 𝑐2

[ 𝑐 3 ] 

它是一个向量，第一个组件𝑝 𝑐 表示是否含有对象，如果对象属于前三类（行人、汽车、 摩托车），则𝑝 𝑐 = 1，如果是背景，则图片中没有要检测的对象，则𝑝 𝑐 = 0。我们可以这样 理解𝑝 𝑐 ，它表示被检测对象属于某一分类的概率，背景分类除外。

如果检测到对象，就输出被检测对象的边界框参数𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 。最后，如果存在某 个对象，那么𝑝 𝑐 = 1，同时输出𝑐 1 、𝑐 2 和𝑐 3 ，表示该对象属于 1-3 类中的哪一类，是行人，汽 车还是摩托车。鉴于我们所要处理的问题，我们假设图片中只含有一个对象，所以针对这个

444 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

分类定位问题，图片最多只会出现其中一个对象。

我们再看几个样本，假如这是一张训练集图片，标记为𝑥，即上图的汽车图片。而在𝑦当 中，第一个元素𝑝 𝑐 = 1，因为图中有一辆车，𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 会指明边界框的位置，所以标 签训练集需要标签的边界框。图片中是一辆车，所以结果属于分类 2，因为定位目标不是行 人或摩托车，而是汽车，所以𝑐 1 = 0，𝑐 2 = 1，𝑐 3 = 0，𝑐 1 、𝑐 2 和𝑐 3 中最多只有一个等于 1。

这是图片中只有一个检测对象的情况，如果图片中没有检测对象呢？如果训练样本是这 样一张图片呢？

这种情况下，𝑝 𝑐 = 0，𝑦的其它参数将变得毫无意义，这里我全部写成问号，表示「毫无 意义」的参数，因为图片中不存在检测对象，所以不用考虑网络输出中边界框的大小，也不 用考虑图片中的对象是属于𝑐 1 、𝑐 2 和𝑐 3 中的哪一类。针对给定的被标记的训练样本，不论图 片中是否含有定位对象，构建输入图片𝑥和分类标签𝑦的具体过程都是如此。这些数据最终定 义了训练集。

445 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

最后，我们介绍一下神经网络的损失函数，其参数为类别𝑦和网络输出𝑦，如果采用平方 误差策略，则𝐿(𝑦 , 𝑦) = (𝑦 1 − 𝑦 1) 2 + (𝑦 2 − 𝑦 2) 2 + ⋯ (𝑦 8 − 𝑦 8) 2 ，损失值等于每个元素相应

差值的平方和。

如果图片中存在定位对象，那么𝑦 1 = 1，所以𝑦 1 = 𝑝 𝑐 ，同样地，如果图片中存在定位对 象，𝑝 𝑐 = 1，损失值就是不同元素的平方和。另一种情况是，𝑦 1 = 0，也就是𝑝 𝑐 = 0，损失值是 (𝑦 1 − 𝑦 1) 2 ，因为对于这种情况，我们

不用考虑其它元素，只需要关注神经网络输出𝑝 𝑐 的准确度。回顾一下，当𝑦 1 = 1 时，也就是这种情况（编号 1），平方误差策略可以减少这 8 个元 素预测值和实际输出结果之间差值的平方。如果𝑦 1 = 0，𝑦 矩阵中的后 7 个元素都不用考虑 （编号 2），只需要考虑神经网络评估𝑦 1 （即𝑝 𝑐 ）的准确度。

为了让大家了解对象定位的细节，这里我用平方误差简化了描述过程。实际应用中，你 可以不对𝑐 1 、𝑐 2 、𝑐 3 和 softmax 激活函数应用对数损失函数，并输出其中一个元素值，通常 做法是对边界框坐标应用平方差或类似方法，对𝑝 𝑐 应用逻辑回归函数，甚至采用平方预测误 差也是可以的。

以上就是利用神经网络解决对象分类和定位问题的详细过程，结果证明，利用神经网络 输出批量实数来识别图片中的对象是个非常有用的算法。下节课，我想和大家分享另一种思 路，就是把神经网络输出的实数集作为一个回归任务，这个思想也被应用于计算机视觉的其 它领域，也是非常有效的，所以下节课见。

446 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.2 特征点检测（Landmark detection）

上节课，我们讲了如何利用神经网络进行对象定位，即通过输出四个参数值𝑏 𝑥 、𝑏 𝑦 、𝑏ℎ 和𝑏 𝑤 给出图片中对象的边界框。更概括地说，神经网络可以通过输出图片上特征点的 (𝑥, 𝑦) 坐标来实现对目标特征的识别，我们看几个例子。

假设你正在构建一个人脸识别应用，出于某种原因，你希望算法可以给出眼角的具体位 置。眼角坐标为 (𝑥, 𝑦)，你可以让神经网络的最后一层多输出两个数字𝑙 𝑥 和𝑙 𝑦 ，作为眼角的坐 标值。如果你想知道两只眼睛的四个眼角的具体位置，那么从左到右，依次用四个特征点来 表示这四个眼角。对神经网络稍做些修改，输出第一个特征点（𝑙 1𝑥 ，𝑙 1𝑦 ），第二个特征点 （𝑙 2𝑥 ，𝑙 2𝑦 ），依此类推，这四个脸部特征点的位置就可以通过神经网络输出了。

（编者注：图中的模特是吴恩达老师的夫人 Carol Reiley）

447 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

也许除了这四个特征点，你还想得到更多的特征点输出值，这些（图中眼眶上的红色特 征点）都是眼睛的特征点，你还可以根据嘴部的关键点输出值来确定嘴的形状，从而判断人 物是在微笑还是皱眉，也可以提取鼻子周围的关键特征点。为了便于说明，你可以设定特征 点的个数，假设脸部有 64 个特征点，有些点甚至可以帮助你定义脸部轮廓或下颌轮廓。选 定特征点个数，并生成包含这些特征点的标签训练集，然后利用神经网络输出脸部关键特征 点的位置。

具体做法是，准备一个卷积网络和一些特征集，将人脸图片输入卷积网络，输出 1 或 0，1 表示有人脸，0 表示没有人脸，然后输出（𝑙 1𝑥 ，𝑙 1𝑦 ）…… 直到（𝑙 64𝑥 ，𝑙 64𝑦 ）。这里我用𝑙代 表一个特征，这里有 129 个输出单元，其中 1 表示图片中有人脸，因为有 64 个特征，64×2=128，所以最终输出 128+1=129 个单元，由此实现对图片的人脸检测和定位。这只是一个识别脸部 表情的基本构造模块，如果你玩过 Snapchat 或其它娱乐类应用，你应该对 AR（增强现实） 过滤器多少有些了解，Snapchat 过滤器实现了在脸上画皇冠和其他一些特殊效果。检测脸部 特征也是计算机图形效果的一个关键构造模块，比如实现脸部扭曲，头戴皇冠等等。当然为 了构建这样的网络，你需要准备一个标签训练集，也就是图片𝑥和标签𝑦的集合，这些点都是 人为辛苦标注的。

最后一个例子，如果你对人体姿态检测感兴趣，你还可以定义一些关键特征点，如胸部 的中点，左肩，左肘，腰等等。然后通过神经网络标注人物姿态的关键特征点，再输出这些 标注过的特征点，就相当于输出了人物的姿态动作。当然，要实现这个功能，你需要设定这 些关键特征点，从胸部中心点 (𝑙 1𝑥 ，𝑙 1𝑦) 一直往下，直到 (𝑙 32𝑥 ，𝑙 32𝑦)。

448 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

一旦了解如何用二维坐标系定义人物姿态，操作起来就相当简单了，批量添加输出单元，用以输出要识别的各个特征点的 (𝑥, 𝑦) 坐标值。要明确一点，特征点 1 的特性在所有图片中 必须保持一致，就好比，特征点 1 始终是右眼的外眼角，特征点 2 是右眼的内眼角，特征点 3 是左眼内眼角，特征点 4 是左眼外眼角等等。所以标签在所有图片中必须保持一致，假如 你雇用他人或自己标记了一个足够大的数据集，那么神经网络便可以输出上述所有特征点，你可以利用它们实现其他有趣的效果，比如判断人物的动作姿态，识别图片中的人物表情等 等。

以上就是特征点检测的内容，下节课我们将利用这些构造模块来构建对象检测算法。

449 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.3 目标检测（Object detection）

学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学 习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。

假如你想构建一个汽车检测算法，步骤是，首先创建一个标签训练集，也就是𝑥和𝑦表示 适当剪切的汽车图片样本，这张图片（编号 1）𝑥是一个正样本，因为它是一辆汽车图片，这几张图片（编号 2、3）也有汽车，但这两张（编号 4、5）没有汽车。出于我们对这个训 练集的期望，你一开始可以使用适当剪切的图片，就是整张图片𝑥几乎都被汽车占据，你可 以照张照片，然后剪切，剪掉汽车以外的部分，使汽车居于中间位置，并基本占据整张图片。有了这个标签训练集，你就可以开始训练卷积网络了，输入这些适当剪切过的图片（编号 6），卷积网络输出𝑦，0 或 1 表示图片中有汽车或没有汽车。训练完这个卷积网络，就可以用它 来实现滑动窗口目标检测，具体步骤如下。

假设这是一张测试图片，首先选定一个特定大小的窗口，比如图片下方这个窗口，将这

450 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

个红色小方块输入卷积神经网络，卷积网络开始进行预测，即判断红色方框内有没有汽车。

滑动窗口目标检测算法接下来会继续处理第二个图像，即红色方框稍向右滑动之后的区 域，并输入给卷积网络，因此输入给卷积网络的只有红色方框内的区域，再次运行卷积网络，然后处理第三个图像，依次重复操作，直到这个窗口滑过图像的每一个角落。

为了滑动得更快，我这里选用的步幅比较大，思路是以固定步幅移动窗口，遍历图像的 每个区域，把这些剪切后的小图像输入卷积网络，对每个位置按 0 或 1 进行分类，这就是所 谓的图像滑动窗口操作。

重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神 经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出 0 或 1。

再以某个固定步幅滑动窗口，重复以上操作，遍历整个图像，输出结果。

451 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

然后第三次重复操作，这次选用更大的窗口。如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。

比如，将这个窗口（编号 1）输入卷积网络，希望卷积网络对该输入区域的输出结果为 1，说明网络检测到图上有辆车。

这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，对这些方形区域进行分类，判断里面有没有汽车。

滑动窗口目标检测算法也有很明显的缺点，就是计算成本，因为你在图片中剪切出太多 小方块，卷积网络要一个个地处理。如果你选用的步幅很大，显然会减少输入卷积网络的窗 口个数，但是粗糙间隔尺寸可能会影响性能。反之，如果采用小粒度或小步幅，传递给卷积 网络的小窗口会特别多，这意味着超高的计算成本。

所以在神经网络兴起之前，人们通常采用更简单的分类器进行对象检测，比如通过采用 手工处理工程特征的简单的线性分类器来执行对象检测。至于误差，因为每个分类器的计算 成本都很低，它只是一个线性函数，所以滑动窗口目标检测算法表现良好，是个不错的算法。然而，卷积网络运行单个分类人物的成本却高得多，像这样滑动窗口太慢。除非采用超细粒 度或极小步幅，否则无法准确定位图片中的对象。

不过，庆幸的是，计算成本问题已经有了很好的解决方案，大大提高了卷积层上应用滑 动窗口目标检测器的效率，关于它的具体实现，我们下节课再讲。

452 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.4 滑动窗口的卷积实现（Convolutional implementation of sliding windows）

上节课，我们学习了如何通过卷积网络实现滑动窗口对象检测算法，但效率很低。这节 课我们讲讲如何在卷积层上应用这个算法。

为了构建滑动窗口的卷积应用，首先要知道如何把神经网络的全连接层转化成卷积层。我们先讲解这部分内容，下一张幻灯片，我们将按照这个思路来演示卷积的应用过程。

假设对象检测算法输入一个 14×14×3 的图像，图像很小，不过演示起来方便。在这里过 滤器大小为 5×5，数量是 16，14×14×3 的图像在过滤器处理之后映射为 10×10×16。然后通过 参数为 2×2 的最大池化操作，图像减小到 5×5×16。然后添加一个连接 400 个单元的全连接 层，接着再添加一个全连接层，最后通过 softmax 单元输出𝑦。为了跟下图区分开，我先做 一点改动，用 4 个数字来表示𝑦，它们分别对应 softmax 单元所输出的 4 个分类出现的概率。这 4 个分类可以是行人、汽车、摩托车和背景或其它对象。

现在我要演示的就是如何把这些全连接层转化为卷积层，画一个这样的卷积网络，它的

453 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

前几层和之前的一样，而对于下一层，也就是这个全连接层，我们可以用 5×5 的过滤器来实 现，数量是 400 个（编号 1 所示），输入图像大小为 5×5×16，用 5×5 的过滤器对它进行卷 积操作，过滤器实际上是 5×5×16，因为在卷积过程中，过滤器会遍历这 16 个通道，所以这 两处的通道数量必须保持一致，输出结果为 1×1。假设应用 400 个这样的 5×5×16 过滤器，输出维度就是 1×1×400，我们不再把它看作一个含有 400 个节点的集合，而是一个 1×1×400 的输出层。从数学角度看，它和全连接层是一样的，因为这 400 个节点中每个节点都有一个 5×5×16 维度的过滤器，所以每个值都是上一层这些 5×5×16 激活值经过某个任意线性函数的 输出结果。

我们再添加另外一个卷积层（编号 2 所示），这里用的是 1×1 卷积，假设有 400 个 1×1 的过滤器，在这 400 个过滤器的作用下，下一层的维度是 1×1×400，它其实就是上个网络中 的这一全连接层。最后经由 1×1 过滤器的处理，得到一个 softmax 激活值，通过卷积网络，我们最终得到这个 1×1×4 的输出层，而不是这 4 个数字（编号 3 所示）。

以上就是用卷积层代替全连接层的过程，结果这几个单元集变成了 1×1×400 和 1×1×4 的 维度。

参考论文：Sermanet, Pierre, et al. "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks." Eprint Arxiv (2013).

掌握了卷积知识，我们再看看如何通过卷积实现滑动窗口对象检测算法。讲义中的内容 借鉴了屏幕下方这篇关于 OverFeat 的论文，它的作者包括 Pierre Sermanet，David Eigen，张 翔，Michael Mathieu，Rob Fergus，Yann LeCun。

假设向滑动窗口卷积网络输入 14×14×3 的图片，为了简化演示和计算过程，这里我们依 然用 14×14 的小图片。和前面一样，神经网络最后的输出层，即 softmax 单元的输出是 1×1×4，我画得比较简单，严格来说，14×14×3 应该是一个长方体，第二个 10×10×16 也是一个长方 体，但为了方便，我只画了正面。所以，对于 1×1×400 的这个输出层，我也只画了它 1×1 的 那一面，所以这里显示的都是平面图，而不是 3D 图像。

454 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

假设输入给卷积网络的图片大小是 14×14×3，测试集图片是 16×16×3，现在给这个输入 图片加上黄色条块，在最初的滑动窗口算法中，你会把这片蓝色区域输入卷积网络（红色笔 标记）生成 0 或 1 分类。接着滑动窗口，步幅为 2 个像素，向右滑动 2 个像素，将这个绿框 区域输入给卷积网络，运行整个卷积网络，得到另外一个标签 0 或 1。继续将这个橘色区域 输入给卷积网络，卷积后得到另一个标签，最后对右下方的紫色区域进行最后一次卷积操作。我们在这个 16×16×3 的小图像上滑动窗口，卷积网络运行了 4 次，于是输出了了 4 个标签。

结果发现，这 4 次卷积操作中很多计算都是重复的。所以执行滑动窗口的卷积时使得卷 积网络在这 4 次前向传播过程中共享很多计算，尤其是在这一步操作中（编号 1），卷积网 络运行同样的参数，使得相同的 5×5×16 过滤器进行卷积操作，得到 12×12×16 的输出层。然 后执行同样的最大池化（编号 2），输出结果 6×6×16。照旧应用 400 个 5×5 的过滤器（编号 3），得到一个 2×2×400 的输出层，现在输出层为 2×2×400，而不是 1×1×400。应用 1×1 过滤 器（编号 4）得到另一个 2×2×400 的输出层。再做一次全连接的操作（编号 5），最终得到 2×2×4 的输出层，而不是 1×1×4。最终，在输出层这 4 个子方块中，蓝色的是图像左上部分 14×14 的输出（红色箭头标识），右上角方块是图像右上部分（绿色箭头标识）的对应输出，左下角方块是输入层左下角（橘色箭头标识），也就是这个 14×14 区域经过卷积网络处理后 的结果，同样，右下角这个方块是卷积网络处理输入层右下角 14×14 区域 (紫色箭头标识) 的 结果。

455 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

如果你想了解具体的计算步骤，以绿色方块为例，假设你剪切出这块区域（编号 1），传递给卷积网络，第一层的激活值就是这块区域（编号 2），最大池化后的下一层的激活值 是这块区域（编号 3），这块区域对应着后面几层输出的右上角方块（编号 4，5，6）。

所以该卷积操作的原理是我们不需要把输入图像分割成四个子集，分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算，其中的公共区域可以共享很多计算，就 像这里我们看到的这个 4 个 14×14 的方块一样。

下面我们再看一个更大的图片样本，假如对一个 28×28×3 的图片应用滑动窗口操作，如 果以同样的方式运行前向传播，最后得到 8×8×4 的结果。跟上一个范例一样，以 14×14 区域 滑动窗口，首先在这个区域应用滑动窗口，其结果对应输出层的左上角部分。接着以大小为 2 的步幅不断地向右移动窗口，直到第 8 个单元格，得到输出层的第一行。然后向图片下方 移动，最终输出这个 8×8×4 的结果。因为最大池化参数为 2，相当于以大小为 2 的步幅在原 始图片上应用神经网络。

456 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

总结一下滑动窗口的实现过程，在图片上剪切出一块区域，假设它的大小是 14×14，把 它输入到卷积网络。继续输入下一块区域，大小同样是 14×14，重复操作，直到某个区域识 别到汽车。

但是正如在前一页所看到的，我们不能依靠连续的卷积操作来识别图片中的汽车，比如，我们可以对大小为 28×28 的整张图片进行卷积操作，一次得到所有预测值，如果足够幸运，神经网络便可以识别出汽车的位置。

以上就是在卷积层上应用滑动窗口算法的内容，它提高了整个算法的效率。不过这种算 法仍然存在一个缺点，就是边界框的位置可能不够准确。下节课，我们将学习如何解决这个 问题。

457 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.5 Bounding Box 预测（Bounding box predictions）

在上一个视频中，你们学到了滑动窗口法的卷积实现，这个算法效率更高，但仍然存在 问题，不能输出最精准的边界框。在这个视频中，我们看看如何得到更精准的边界框。

在滑动窗口法中，你取这些离散的位置集合，然后在它们上运行分类器，在这种情况下，这些边界框没有一个能完美匹配汽车位置，也许这个框（编号 1）是最匹配的了。还有看起 来这个真实值，最完美的边界框甚至不是方形，稍微有点长方形（红色方框所示），长宽比 有点向水平方向延伸，有没有办法让这个算法输出更精准的边界框呢？

其中一个能得到更精准边界框的算法是 YOLO 算法，YOLO (You only look once) 意思是你 只看一次，这是由 Joseph Redmon，Santosh Divvala，Ross Girshick 和 Ali Farhadi 提出的算

458 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

法。

是这么做的，比如你的输入图像是 100×100 的，然后在图像上放一个网格。为了介绍起 来简单一些，我用 3×3 网格，实际实现时会用更精细的网格，可能是 19×19。基本思路是使 用图像分类和定位算法，前几个视频介绍过的，然后将算法应用到 9 个格子上。（基本思路 是，采用图像分类和定位算法，本周第一个视频中介绍过的，逐一应用在图像的 9 个格子 中。）更具体一点，你需要这样定义训练标签，所以对于 9 个格子中的每一个指定一个标签 𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 𝑦，𝑦是 8 维的，和你之前看到的一样，𝑦 = ，𝑝 𝑐 等于 0 或 1 取决于这个绿色格子中是否 𝑏𝑤 𝑐1 𝑐2

[ 𝑐 3 ] 

有图像。然后𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 作用就是，如果那个格子里有对象，那么就给出边界框坐标。然后𝑐 1 、𝑐 2 和𝑐 3 就是你想要识别的三个类别，背景类别不算，所以你尝试在背景类别中识别 行人、汽车和摩托车，那么𝑐 1 、𝑐 2 和𝑐 3 可以是行人、汽车和摩托车类别。这张图里有 9 个格 子，所以对于每个格子都有这么一个向量。

我们看看左上方格子，这里这个（编号 1），里面什么也没有，所以左上格子的标签向 0 ?

? 

? 量𝑦是 。然后这个格子（编号 2）的输出标签𝑦也是一样，这个格子（编号 3），还有其他？

? 

? 

[?] 什么也没有的格子都一样。现在这个格子呢？讲的更具体一点，这张图有两个对象，YOLO 算法做的就是，取两个

459 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

对象的中点，然后将这个对象分配给包含对象中点的格子。所以左边的汽车就分配到这个格 子上（编号 4），然后这辆 Condor（车型：神鹰）中点在这里，分配给这个格子（编号 6）。所以即使中心格子（编号 5）同时有两辆车的一部分，我们就假装中心格子没有任何我们感 兴趣的对象，所以对于中心格子，分类标签𝑦和这个向量类似，和这个没有对象的向量类似，

0 

? 

? 

? 即𝑦 = 。而对于这个格子，这个用绿色框起来的格子（编号 4），目标标签就是这样的，

? 

? 

? 

[?] 这里有一个对象，𝑝 𝑐 = 1，然后你写出𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 来指定边界框位置，然后还有类别 1 是行人，那么𝑐 1 = 0，类别 2 是汽车，所以𝑐 2 = 1，类别 3 是摩托车，则数值𝑐 3 = 0，即𝑦 = 1 𝑏𝑥 𝑏𝑦 𝑏 ℎ 。右边这个格子（编号 6）也是类似的，因为这里确实有一个对象，它的向量应该是这 𝑏𝑤 0 1 [0] 1 𝑏𝑥 𝑏𝑦 个样子的，𝑦 = 𝑏ℎ 𝑏𝑤 0 1 [0]

作为目标向量对应右边的格子。

所以对于这里 9 个格子中任何一个，你都会得到一个 8 维输出向量，因为这里是 3×3 的 网格，所以有 9 个格子，总的输出尺寸是 3×3×8，所以目标输出是 3×3×8。因为这里有 3×3 格子，然后对于每个格子，你都有一个 8 维向量𝑦，所以目标输出尺寸是 3×3×8。

对于这个例子中，左上格子是 1×1×8，对应的是 9 个格子中左上格子的输出向量。所以 对于这 3×3 中每一个位置而言，对于这 9 个格子，每个都对应一个 8 维输出目标向量𝑦，其 中一些值可以是 dont care-s（即？），如果这里没有对象的话。所以总的目标输出，这个图

460 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

片的输出标签尺寸就是 3×3×8。

如果你现在要训练一个输入为 100×100×3 的神经网络，现在这是输入图像，然后你有一 个普通的卷积网络，卷积层，最大池化层等等，最后你会有这个，选择卷积层和最大池化层，这样最后就映射到一个 3×3×8 输出尺寸。所以你要做的是，有一个输入𝑥，就是这样的输入 图像，然后你有这些 3×3×8 的目标标签𝑦。当你用反向传播训练神经网络时，将任意输入𝑥映 射到这类输出向量𝑦。

所以这个算法的优点在于神经网络可以输出精确的边界框，所以测试的时候，你做的是 喂入输入图像𝑥，然后跑正向传播，直到你得到这个输出𝑦。然后对于这里 3×3 位置对应的 9 个输出，我们在输出中展示过的，你就可以读出 1 或 0（编号 1 位置），你就知道 9 个位置 之一有个对象。如果那里有个对象，那个对象是什么（编号 3 位置），还有格子中这个对象 的边界框是什么（编号 2 位置）。只要每个格子中对象数目没有超过 1 个，这个算法应该是 没问题的。一个格子中存在多个对象的问题，我们稍后再讨论。但实践中，我们这里用的是 比较小的 3×3 网格，实践中你可能会使用更精细的 19×19 网格，所以输出就是 19×19×8。这 样的网格精细得多，那么多个对象分配到同一个格子得概率就小得多。

重申一下，把对象分配到一个格子的过程是，你观察对象的中点，然后将这个对象分配 到其中点所在的格子，所以即使对象可以横跨多个格子，也只会被分配到 9 个格子其中之 一，就是 3×3 网络的其中一个格子，或者 19×19 网络的其中一个格子。在 19×19 网格中，两 个对象的中点（图中蓝色点所示）处于同一个格子的概率就会更低。

461 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

所以要注意，首先这和图像分类和定位算法非常像，我们在本周第一节课讲过的，就是 它显式地输出边界框坐标，所以这能让神经网络输出边界框，可以具有任意宽高比，并且能 输出更精确的坐标，不会受到滑动窗口分类器的步长大小限制。其次，这是一个卷积实现，你并没有在 3×3 网格上跑 9 次算法，或者，如果你用的是 19×19 的网格，19 平方是 361 次，所以你不需要让同一个算法跑 361 次。相反，这是单次卷积实现，但你使用了一个卷积网 络，有很多共享计算步骤，在处理这 3×3 计算中很多计算步骤是共享的，或者你的 19×19 的 网格，所以这个算法效率很高。

事实上 YOLO 算法有一个好处，也是它受欢迎的原因，因为这是一个卷积实现，实际上 它的运行速度非常快，可以达到实时识别。在结束之前我还想给你们分享一个小细节，如何 编码这些边界框𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 ，我们在下一张幻灯片上讨论。

这里有两辆车，我们有个 3×3 网格，我们以右边的车为例（编号 1），红色格子里有个 对象，所以目标标签𝑦就是，𝑝 𝑐 = 1，然后𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 ，然后𝑐 1 = 0，𝑐 2 = 1，𝑐 3 = 0，

462 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

即𝑦 =

1 𝑏𝑥 𝑏𝑦 𝑏ℎ 𝑏𝑤 0 1 [ 0 

。你怎么指定这个边界框呢？

] 

Specify the bounding boxes： 

在 YOLO 算法中，对于这个方框（编号 1 所示），我们约定左上这个点是 (0,0)，然后右 下这个点是 (1,1), 要指定橙色中点的位置，𝑏 𝑥 大概是 0.4，因为它的位置大概是水平长度的 0.4，然后𝑏 𝑦 大概是 0.3，然后边界框的高度用格子总体宽度的比例表示，所以这个红框的宽 度可能是蓝线（编号 2 所示的蓝线）的 90%，所以𝑏 ℎ 是 0.9，它的高度也许是格子总体高度 的一半，这样的话𝑏 𝑤 就是 0.5。换句话说，𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 单位是相对于格子尺寸的比例，所以𝑏 𝑥 和𝑏 𝑦 必须在 0 和 1 之间，因为从定义上看，橙色点位于对象分配到格子的范围内，如 果它不在 0 和 1 之间，如果它在方块外，那么这个对象就应该分配到另一个格子上。这个值 （𝑏 ℎ 和𝑏 𝑤 ）可能会大于 1，特别是如果有一辆汽车的边界框是这样的（编号 3 所示），那么 边界框的宽度和高度有可能大于 1。

指定边界框的方式有很多，但这种约定是比较合理的，如果你去读 YOLO 的研究论文，YOLO 的研究工作有其他参数化的方式，可能效果会更好，我这里就只给出了一个合理的约 定，用起来应该没问题。不过还有其他更复杂的参数化方式，涉及到 sigmoid 函数，确保这 个值（𝑏 𝑥 和𝑏 𝑦 ）介于 0 和 1 之间，然后使用指数参数化来确保这些（𝑏 ℎ 和𝑏 𝑤 ）都是非负数，因为 0.9 和 0.5，这个必须大于等于 0。还有其他更高级的参数化方式，可能效果要更好一 点，但我这里讲的办法应该是管用的。

463 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

这就是 YOLO 算法，你只看一次算法，在接下来的几个视频中，我会告诉你一些其他的 思路可以让这个算法做的更好。在此期间，如果你感兴趣，也可以看看 YOLO 的论文，在前 几张幻灯片底部引用的 YOLO 论文。

Redmon, Joseph, et al. "You Only Look Once: Unified, Real-Time Object Detection." (2015):779-788. 

不过看这些论文之前，先给你们提个醒，YOLO 论文是相对难度较高的论文之一，我记 得我第一次读这篇论文的时候，我真的很难搞清楚到底是怎么实现的，我最后问了一些我认 识的研究员，看看他们能不能给我讲清楚，即使是他们，也很难理解这篇论文的一些细节。所以如果你看论文的时候，发现看不懂，这是没问题的，我希望这种场合出现的概率要更低 才好，但实际上，即使是资深研究员也有读不懂研究论文的时候，必须去读源代码，或者联 系作者之类的才能弄清楚这些算法的细节。但你们不要被我吓到，你们可以自己看看这些论 文，如果你们感兴趣的话，但这篇论文相对较难。现在你们了解了 YOLO 算法的基础，我们 继续讨论别的让这个算法效果更好的研究。

464 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.6 交并比（Intersection over union）

你如何判断对象检测算法运作良好呢？在本视频中，你将了解到并交比函数，可以用来 评价对象检测算法。在下一个视频中，我们用它来插入一个分量来进一步改善检测算法，我 们开始吧。

在对象检测任务中，你希望能够同时定位对象，所以如果实际边界框是这样的，你的算 法给出这个紫色的边界框，那么这个结果是好还是坏？所以交并比（loU）函数做的是计算 两个边界框交集和并集之比。两个边界框的并集是这个区域，就是属于包含两个边界框区域 （绿色阴影表示区域），而交集就是这个比较小的区域（橙色阴影表示区域），那么交并比 就是交集的大小，这个橙色阴影面积，然后除以绿色阴影的并集面积。

参考：

交并比：IOU=(A∩B)/(A∪B)

一般约定，在计算机检测任务中，如果𝑙𝑜𝑈 ≥ 0.5，就说检测正确，如果预测器和实际边 界框完美重叠，loU 就是 1，因为交集就等于并集。但一般来说只要𝑙𝑜𝑈 ≥ 0.5，那么结果是 可以接受的，看起来还可以。一般约定，0.5 是阈值，用来判断预测的边界框是否正确。一

465 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

般是这么约定，但如果你希望更严格一点，你可以将 loU 定得更高，比如说大于 0.6 或者更 大的数字，但 loU 越高，边界框越精确。

所以这是衡量定位精确度的一种方式，你只需要统计算法正确检测和定位对象的次数，你就可以用这样的定义判断对象定位是否准确。再次，0.5 是人为约定，没有特别深的理论 依据，如果你想更严格一点，可以把阈值定为 0.6。有时我看到更严格的标准，比如 0.6 甚 至 0.7，但很少见到有人将阈值降到 0.5 以下。

人们定义 loU 这个概念是为了评价你的对象定位算法是否精准，但更一般地说，loU 衡 量了两个边界框重叠地相对大小。如果你有两个边界框，你可以计算交集，计算并集，然后 求两个数值的比值，所以这也可以判断两个边界框是否相似，我们将在下一个视频中再次用 到这个函数，当我们讨论非最大值抑制时再次用到。

好，这就是 loU，或者说交并比，不要和借据中提到的我欠你钱的这个概念所混淆，如 果你借钱给别人，他们会写给你一个借据，说：「我欠你这么多钱（I own you this much money）。」，这也叫做 loU。这是完全不同的概念，这两个概念重名。

现在介绍了 loU 交并比的定义之后，在下一个视频中，我想讨论非最大值抑制，这个工 具可以让 YOLO 算法输出效果更好，我们下一个视频继续。

466 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.7 非极大值抑制（Non-max suppression）

到目前为止你们学到的对象检测中的一个问题是，你的算法可能对同一个对象做出多次 检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以 确保你的算法对每个对象只检测一次，我们讲一个例子。

假设你需要在这张图片里检测行人和汽车，你可能会在上面放个 19×19 网格，理论上这 辆车只有一个中点，所以它应该只被分配到一个格子里，左边的车子也只有一个中点，所以 理论上应该只有一个格子做出有车的预测。

实践中当你运行对象分类和定位算法时，对于每个格子都运行一次，所以这个格子（编 号 1）可能会认为这辆车中点应该在格子内部，这几个格子（编号 2、3）也会这么认为。对 于左边的车子也一样，所以不仅仅是这个格子，如果这是你们以前见过的图像，不仅这个格

467 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

（编号 4）子会认为它里面有车，也许这个格子（编号 5）和这个格子（编号 6）也会，也许 其他格子也会这么认为，觉得它们格子内有车。我们分步介绍一下非极大抑制是怎么起效的，因为你要在 361 个格子上都运行一次图 像检测和定位算法，那么可能很多格子都会举手说我的𝑝 𝑐 ，我这个格子里有车的概率很高，而不是 361 个格子中仅有两个格子会报告它们检测出一个对象。所以当你运行算法的时候，最后可能会对同一个对象做出多次检测，所以非极大值抑制做的就是清理这些检测结果。这 样一辆车只检测一次，而不是每辆车都触发多次检测。

所以具体上，这个算法做的是，首先看看每次报告每个检测结果相关的概率𝑝 𝑐 ，在本周 的编程练习中有更多细节，实际上是𝑝 𝑐 乘以𝑐 1 、𝑐 2 或𝑐 3 。现在我们就说，这个𝑝 𝑐 检测概率，首先看概率最大的那个，这个例子（右边车辆）中是 0.9，然后就说这是最可靠的检测，所 以我们就用高亮标记，就说我这里找到了一辆车。这么做之后，非极大值抑制就会逐一审视 剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出 就会被抑制。所以这两个矩形𝑝 𝑐 分别是 0.6 和 0.7，这两个矩形和淡蓝色矩形重叠程度很高，所以会被抑制，变暗，表示它们被抑制了。

接下来，逐一审视剩下的矩形，找出概率最高，𝑝 𝑐 最高的一个，在这种情况下是 0.8，我们就认为这里检测出一辆车（左边车辆），然后非极大值抑制算法就会去掉其他 loU 值很 高的矩形。所以现在每个矩形都会被高亮显示或者变暗，如果你直接抛弃变暗的矩形，那就 剩下高亮显示的那些，这就是最后得到的两个预测结果。

所以这就是非极大值抑制，非最大值意味着你只输出概率最大的分类结果，但抑制很接 近，但不是最大的其他预测结果，所以这方法叫做非极大值抑制。

468 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

我们来看看算法的细节，首先这个 19×19 网格上执行一下算法，你会得到 19×19×8 的输 出尺寸。不过对于这个例子来说，我们简化一下，就说你只做汽车检测，我们就去掉𝑐 1 、𝑐2 和𝑐 3 ，然后假设这条线对于 19×19 的每一个输出，对于 361 个格子的每个输出，你会得到这 样的输出预测，就是格子中有对象的概率（𝑝 𝑐 ），然后是边界框参数（𝑏 𝑥 、𝑏 𝑦 、𝑏 ℎ 和𝑏 𝑤 ）。如果你只检测一种对象，那么就没有𝑐 1 、𝑐 2 和𝑐 3 这些预测分量。多个对象处于同一个格子中 的情况，我会放到编程练习中，你们可以在本周末之前做做。

现在要实现非极大值抑制，你可以做的第一件事是，去掉所有边界框，我们就将所有的 预测值，所有的边界框𝑝 𝑐 小于或等于某个阈值，比如𝑝 𝑐 ≤ 0.6 的边界框去掉。

我们就这样说，除非算法认为这里存在对象的概率至少有 0.6，否则就抛弃，所以这就 抛弃了所有概率比较低的输出边界框。所以思路是对于这 361 个位置，你输出一个边界框，还有那个最好边界框所对应的概率，所以我们只是抛弃所有低概率的边界框。

接下来剩下的边界框，没有抛弃没有处理过的，你就一直选择概率𝑝 𝑐 最高的边界框，然 后把它输出成预测结果，这个过程就是上一张幻灯片，取一个边界框，让它高亮显示，这样 你就可以确定输出做出有一辆车的预测。

469 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

接下来去掉所有剩下的边界框，任何没有达到输出标准的边界框，之前没有抛弃的边界 框，把这些和输出边界框有高重叠面积和上一步输出边界框有很高交并比的边界框全部抛 弃。所以 while 循环的第二步是上一张幻灯片变暗的那些边界框，和高亮标记的边界重叠面 积很高的那些边界框抛弃掉。在还有剩下边界框的时候，一直这么做，把没处理的都处理完，直到每个边界框都判断过了，它们有的作为输出结果，剩下的会被抛弃，它们和输出结果重 叠面积太高，和输出结果交并比太高，和你刚刚输出这里存在对象结果的重叠程度过高。

在这张幻灯片中，我只介绍了算法检测单个对象的情况，如果你尝试同时检测三个对象，比如说行人、汽车、摩托，那么输出向量就会有三个额外的分量。事实证明，正确的做法是 独立进行三次非极大值抑制，对每个输出类别都做一次，但这个细节就留给本周的编程练习 吧，其中你可以自己尝试实现，我们可以自己试试在多个对象类别检测时做非极大值抑制。

这就是非极大值抑制，如果你能实现我们说过的对象检测算法，你其实可以得到相当不 错的结果。但结束我们对 YOLO 算法的介绍之前，最后我还有一个细节想给大家分享，可以 进一步改善算法效果，就是 anchor box 的思路，我们下一个视频再介绍。

470 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.8 Anchor Boxes 

到目前为止，对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让 一个格子检测出多个对象，你可以这么做，就是使用 anchor box 这个概念，我们从一个例子 开始讲吧。

假设你有这样一张图片，对于这个例子，我们继续使用 3×3 网格，注意行人的中点和汽 车的中点几乎在同一个地方，两者都落入到同一个格子中。所以对于那个格子，如果 𝑦 输 𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 出这个向量𝑦 = ，你可以检测这三个类别，行人、汽车和摩托车，它将无法输出检测结 𝑏𝑤 𝑐1 𝑐2

[ 𝑐 3 ] 

果，所以我必须从两个检测结果中选一个。

而 anchor box 的思路是，这样子，预先定义两个不同形状的 anchor box，或者 anchor box 形状，你要做的是把预测结果和这两个 anchor box 关联起来。一般来说，你可能会用更 多的 anchor box，可能要 5 个甚至更多，但对于这个视频，我们就用两个 anchor box，这样 介绍起来简单一些。

471 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

你要做的是定义类别标签，用的向量不再是上面这个：

[ 𝑝 𝑐 𝑏 𝑥 𝑏 𝑦 𝑏 ℎ 𝑏 𝑤 𝑐 1 𝑐 2 𝑐 3 ]𝑇 

而是重复两次：

𝑦 = [ 𝑝 𝑐 𝑏 𝑥 𝑏 𝑦 𝑏 ℎ 𝑏 𝑤 𝑐 1 𝑐 2 𝑐 3 𝑝 𝑐 𝑏 𝑥 𝑏 𝑦 𝑏 ℎ 𝑏 𝑤 𝑐 1 𝑐 2 𝑐 3 ]𝑇 

前面的𝑝 𝑐 , 𝑏 𝑥 , 𝑏 𝑦 ,𝑏 ℎ , 𝑏 𝑤 , 𝑐 1 , 𝑐 2 , 𝑐 3 （绿色方框标记的参数）是和 anchor box 1 关联的 8 个 参数，后面的 8 个参数（橙色方框标记的元素）是和 anchor box 2 相关联。因为行人的形状

更类似于 anchor box 1 的形状，而不是 anchor box 2 的形状，所以你可以用这 8 个数值（前 8 个参数），这么编码𝑝 𝑐 = 1，是的，代表有个行人，用𝑏 𝑥 , 𝑏 𝑦 , 𝑏 ℎ 和𝑏 𝑤 来编码包住行人的边 界框，然后用𝑐 1 , 𝑐 2 , 𝑐 3 (𝑐 1 = 1, 𝑐 2 = 0, 𝑐 3 = 0) 来说明这个对象是个行人。然后是车子，因为车子的边界框比起 anchor box 1 更像 anchor box 2 的形状，你就可以 这么编码，这里第二个对象是汽车，然后有这样的边界框等等，这里所有参数都和检测汽车

相关 (𝑝 𝑐 = 1, 𝑏 𝑥 , 𝑏 𝑦 , 𝑏 ℎ , 𝑏 𝑤 ,𝑐 1 = 0, 𝑐 2 = 1, 𝑐 3 = 0)。

总结一下，用 anchor box 之前，你做的是这个，对于训练集图像中的每个对象，都根据

472 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

那个对象中点位置分配到对应的格子中，所以输出𝑦就是 3×3×8，因为是 3×3 网格，对于每 个网格位置，我们有输出向量，包含𝑝 𝑐 ，然后边界框参数𝑏 𝑥 , 𝑏 𝑦 ,𝑏 ℎ 和𝑏 𝑤 ，然后𝑐 1 , 𝑐 2 , 𝑐 3 。现在用到 anchor box 这个概念，是这么做的。现在每个对象都和之前一样分配到同一 个格子中，分配到对象中点所在的格子中，以及分配到和对象形状交并比最高的 anchor box 中。所以这里有两个 anchor box，你就取这个对象，如果你的对象形状是这样的（编号 1，红色框），你就看看这两个 anchor box，anchor box 1 形状是这样（编号 2，紫色框），anchor box 2 形状是这样（编号 3，紫色框），然后你观察哪一个 anchor box 和实际边界框（编号 1，红色框）的交并比更高，不管选的是哪一个，这个对象不只分配到一个格子，而是分配 到一对，即（grid cell，anchor box）对，这就是对象在目标标签中的编码方式。所以现在输 出 𝑦 就是 3×3×16，上一张幻灯片中你们看到 𝑦 现在是 16 维的，或者你也可以看成是 3×3×2×8，因为现在这里有 2 个 anchor box，而 𝑦 是 8 维的。𝑦 维度是 8，因为我们有 3 个 对象类别，如果你有更多对象，那么𝑦 的维度会更高。

所以我们来看一个具体的例子，对于这个格子（编号 2），我们定义一下𝑦，：

𝑦 = [ 𝑝 𝑐 𝑏 𝑥 𝑏 𝑦 𝑏 ℎ 𝑏 𝑤 𝑐 1 𝑐 2 𝑐 3 𝑝 𝑐 𝑏 𝑥 𝑏 𝑦 𝑏 ℎ 𝑏 𝑤 𝑐 1 𝑐 2 𝑐 3 ] 𝑇 。

所以行人更类似于 anchor box 1 的形状，所以对于行人来说，我们将她分配到向量的上 半部分。是的，这里存在一个对象，即𝑝 𝑐 = 1，有一个边界框包住行人，如果行人是类别 1，那么 𝑐 1 = 1, 𝑐 2 = 0,𝑐 3 = 0（编号 1 所示的橙色参数）。车子的形状更像 anchor box 2，所以 这个向量剩下的部分是 𝑝 𝑐 = 1，然后和车相关的边界框，然后𝑐 1 = 0, 𝑐 2 = 1, 𝑐 3 = 0（编号 1 所示的绿色参数）。所以这就是对应中下格子的标签 𝑦，这个箭头指向的格子（编号 2 所

473 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

示）。现在其中一个格子有车，没有行人，如果它里面只有一辆车，那么假设车子的边界框形 状是这样，更像 anchor box 2，如果这里只有一辆车，行人走开了，那么 anchor box 2 分量 还是一样的，要记住这是向量对应 anchor box 2 的分量和 anchor box 1 对应的向量分量，你 要填的就是，里面没有任何对象，所以 𝑝 𝑐 = 0，然后剩下的就是 don’t care-s (即？)（编号 3 所示）。

现在还有一些额外的细节，如果你有两个 anchor box，但在同一个格子中有三个对象，这种情况算法处理不好，你希望这种情况不会发生，但如果真的发生了，这个算法并没有很 好的处理办法，对于这种情况，我们就引入一些打破僵局的默认手段。还有这种情况，两个 对象都分配到一个格子中，而且它们的 anchor box 形状也一样，这是算法处理不好的另一 种情况，你需要引入一些打破僵局的默认手段，专门处理这种情况，希望你的数据集里不会 出现这种情况，其实出现的情况不多，所以对性能的影响应该不会很大。

这就是 anchor box 的概念，我们建立 anchor box 这个概念，是为了处理两个对象出现 在同一个格子的情况，实践中这种情况很少发生，特别是如果你用的是 19×19 网格而不是 3×3 的网格，两个对象中点处于 361 个格子中同一个格子的概率很低，确实会出现，但出现 频率不高。也许设立 anchor box 的好处在于 anchor box 能让你的学习算法能够更有征对性，特别是如果你的数据集有一些很高很瘦的对象，比如说行人，还有像汽车这样很宽的对象，这样你的算法就能更有针对性的处理，这样有一些输出单元可以针对检测很宽很胖的对象，比如说车子，然后输出一些单元，可以针对检测很高很瘦的对象，比如说行人。

最后，你应该怎么选择 anchor box 呢？人们一般手工指定 anchor box 形状，你可以选 择 5 到 10 个 anchor box 形状，覆盖到多种不同的形状，可以涵盖你想要检测的对象的各种 形状。还有一个更高级的版本，我就简单说一句，你们如果接触过一些机器学习，可能知道 后期 YOLO 论文中有更好的做法，就是所谓的 k - 平均算法，可以将两类对象形状聚类，如果 我们用它来选择一组 anchor box，选择最具有代表性的一组 anchor box，可以代表你试图检 测的十几个对象类别，但这其实是自动选择 anchor box 的高级方法。如果你就人工选择一 些形状，合理的考虑到所有对象的形状，你预计会检测的很高很瘦或者很宽很胖的对象，这 应该也不难做。

所以这就是 anchor box，在下一个视频中，我们把学到的所有东西一起融入到 YOLO 算 法中。

474 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.9 YOLO 算法（Putting it together: YOLO algorithm）

你们已经学到对象检测算法的大部分组件了，在这个视频里，我们会把所有组件组装在 一起构成 YOLO 对象检测算法。

我们先看看如何构造你的训练集，假设你要训练一个算法去检测三种对象，行人、汽车 和摩托车，你还需要显式指定完整的背景类别。这里有 3 个类别标签，如果你要用两个 anchor box，那么输出 𝑦 就是 3×3×2×8，其中 3×3 表示 3×3 个网格，2 是 anchor box 的数量，8 是 向量维度，8 实际上先是 5（𝑝 𝑐 , 𝑏 𝑥 , 𝑏 𝑦 , 𝑏 ℎ , 𝑏 𝑤 ）再加上类别的数量（𝑐 1 , 𝑐 2 , 𝑐 3 ）。你可以将它 看成是 3×3×2×8，或者 3×3×16。要构造训练集，你需要遍历 9 个格子，然后构成对应的目标 向量𝑦。

475 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

所以先看看第一个格子（编号 1），里面没什么有价值的东西，行人、车子和摩托车，三 个 类 别 都 没有 出 现 在左 上 格 子 中 ，所 以 对 应那 个 格 子 目 标 𝑦 就 是 这样 的 ，𝑦 = [0 ? ? ? ? ? ? ? 0 ? ? ? ? ? ? ?] 𝑇 ，第一个 anchor box 的 𝑝 𝑐 是 0，因为 没什么和第一个 anchor box 有关的，第二个 anchor box 的 𝑝 𝑐 也是 0，剩下这些值是 don’t care-s。

现在网格中大多数格子都是空的，但那里的格子（编号 2）会有这个目标向量𝑦，𝑦 = [0 ? ? ? ? ? ? ? 1 𝑏 𝑥 𝑏 𝑦 𝑏 ℎ 𝑏 𝑤 0 1 0] 𝑇 ，所以假设你的训练集中，对于 车子有这样一个边界框（编号 3），水平方向更长一点。所以如果这是你的 anchor box，这 是 anchor box 1（编号 4），这是 anchor box 2（编号 5），然后红框和 anchor box 2 的交并 比更高，那么车子就和向量的下半部分相关。要注意，这里和 anchor box 1 有关的 𝑝 𝑐 是 0，剩下这些分量都是 don’t care-s，然后你的第二个 𝑝 𝑐 = 1，然后你要用这些（𝑏 𝑥 , 𝑏 𝑦 , 𝑏 ℎ , 𝑏 𝑤 ） 来指定红边界框的位置，然后指定它的正确类别是 2 (𝑐 1 = 0, 𝑐 2 = 1,𝑐 3 = 0)，对吧，这是一 辆汽车。

所以你这样遍历 9 个格子，遍历 3×3 网格的所有位置，你会得到这样一个向量，得到一 个 16 维向量，所以最终输出尺寸就是 3×3×16。和之前一样，简单起见，我在这里用的是 3×3 网格，实践中用的可能是 19×19×16，或者需要用到更多的 anchor box，可能是 19×19×5×8，即 19×19×40，用了 5 个 anchor box。这就是训练集，然后你训练一个卷积网络，输入是图 片，可能是 100×100×3，然后你的卷积网络最后输出尺寸是，在我们例子中是 3×3×16 或者 3×3×2×8。

接下来我们看看你的算法是怎样做出预测的，输入图像，你的神经网络的输出尺寸是这 个 3××3×2×8，对于 9 个格子，每个都有对应的向量。对于左上的格子（编号 1），那里没有 任何对象，那么我们希望你的神经网络在那里（第一个𝑝 𝑐 ）输出的是 0，这里（第二个𝑝 𝑐 ） 是 0，然后我们输出一些值，你的神经网络不能输出问号，不能输出 don’t care-s，剩下的我 输入一些数字，但这些数字基本上会被忽略，因为神经网络告诉你，那里没有任何东西，所 以输出是不是对应一个类别的边界框无关紧要，所以基本上是一组数字，多多少少都是噪音 （输出 𝑦 如编号 3 所示）。

476 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

和这里的边界框不大一样，希望𝑦的值，那个左下格子（编号 2）的输出𝑦（编号 4 所 示），形式是，对于边界框 1 来说（𝑝 𝑐 ）是 0，然后就是一组数字，就是噪音（anchor box 1 对应行人，此格子中无行人，𝑝 𝑐 = 0, 𝑏 𝑥 =? , 𝑏 𝑦 =? , 𝑏 ℎ =? , 𝑏 𝑤 =? , 𝑐 1 =? 𝑐 2 =? , 𝑐 3 =?）。希望

你的算法能输出一些数字，可以对车子指定一个相当准确的边界框（anchor box 2 对应汽车，此格子中有车，𝑝 𝑐 = 1, 𝑏 𝑥 , 𝑏 𝑦 , 𝑏 ℎ , 𝑏 𝑤 ,𝑐 1 = 0, 𝑐 2 = 1, 𝑐 3 = 0），这就是神经网络做出预测的过

程。

最后你要运行一下这个非极大值抑制，为了让内容更有趣一些，我们看看一张新的测试 图像，这就是运行非极大值抑制的过程。如果你使用两个 anchor box，那么对于 9 个格子中 任何一个都会有两个预测的边界框，其中一个的概率𝑝 𝑐 很低。但 9 个格子中，每个都有两个 预测的边界框，比如说我们得到的边界框是是这样的，注意有一些边界框可以超出所在格子 的高度和宽度（编号 1 所示）。接下来你抛弃概率很低的预测，去掉这些连神经网络都说，这里很可能什么都没有，所以你需要抛弃这些（编号 2 所示）。

477 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

最后，如果你有三个对象检测类别，你希望检测行人，汽车和摩托车，那么你要做的是，对于每个类别单独运行非极大值抑制，处理预测结果所属类别的边界框，用非极大值抑制来 处理行人类别，用非极大值抑制处理车子类别，然后对摩托车类别进行非极大值抑制，运行 三次来得到最终的预测结果。所以算法的输出最好能够检测出图像里所有的车子，还有所有 的行人（编号 3 所示）。

这就是 YOLO 对象检测算法，这实际上是最有效的对象检测算法之一，包含了整个计算 机视觉对象检测领域文献中很多最精妙的思路。你可以在本周的编程作业中尝试现实这个算 法，所以我希望你喜欢本周的编程练习，这里还有一个可选的视频，你们可以看，也可以不 看，总之，我们下周见。

478 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

3.10 候选区域（选修）（Region proposals (Optional)）

如果你们阅读一下对象检测的文献，可能会看到一组概念，所谓的候选区域，这在计算 机视觉领域是非常有影响力的概念。我把这个视频定为可选视频是因为我用到候选区域这一 系列算法的频率没有那么高，但当然了，这些工作是很有影响力的，你们在工作中也可能会 碰到，我们来看看。

你们还记得滑动窗法吧，你使用训练过的分类器，在这些窗口中全部运行一遍，然后运 行一个检测器，看看里面是否有车辆，行人和摩托车。现在你也可以运行一下卷积算法，这 个算法的其中一个缺点是，它在显然没有任何对象的区域浪费时间，对吧。

所以这里这个矩形区域（编号 1）基本是空的，显然没有什么需要分类的东西。也许算 法会在这个矩形上（编号 2）运行，而你知道上面没有什么有趣的东西。

[Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 580-587.] 

所以 Ross Girshick，Jeff Donahue，Trevor Darrell，Jitendra Malik，在本幻灯片底部引用 到的论文中提出一种叫做 R-CNN 的算法，意思是带区域的卷积网络，或者说带区域的 CNN。这个算法尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的，所以这里不再 针对每个滑动窗运行检测算法，而是只选择一些窗口，在少数窗口上运行卷积网络分类器。

479 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

选出候选区域的方法是运行图像分割算法，分割的结果是下边的图像，为了找出可能存 在对象的区域。比如说，分割算法在这里得到一个色块，所以你可能会选择这样的边界框（编 号 1），然后在这个色块上运行分类器，就像这个绿色的东西（编号 2），在这里找到一个 色块，接下来我们还会在那个矩形上（编号 2）运行一次分类器，看看有没有东西。在这种 情况下，如果在蓝色色块上（编号 3）运行分类器，希望你能检测出一个行人，如果你在青 色色块 (编号 4) 上运行算法，也许你可以发现一辆车，我也不确定。

所以这个细节就是所谓的分割算法，你先找出可能 2000 多个色块，然后在这 2000 个色 块上放置边界框，然后在这 2000 个色块上运行分类器，这样需要处理的位置可能要少的多，可以减少卷积网络分类器运行时间，比在图像所有位置运行一遍分类器要快。特别是这种情 况，现在不仅是在方形区域（编号 5）中运行卷积网络，我们还会在高高瘦瘦（编号 6）的 区域运行，尝试检测出行人，然后我们在很宽很胖的区域（编号 7）运行，尝试检测出车辆，同时在各种尺度运行分类器。

这就是 R-CNN 或者区域 CNN 的特色概念，现在看来 R-CNN 算法还是很慢的。所以有一 系列的研究工作去改进这个算法，所以基本的 R-CNN 算法是使用某种算法求出候选区域，然后对每个候选区域运行一下分类器，每个区域会输出一个标签，有没有车子？有没有行人？ 有没有摩托车？并输出一个边界框，这样你就能在确实存在对象的区域得到一个精确的边界 框。

澄清一下，R-CNN 算法不会直接信任输入的边界框，它也会输出一个边界框𝑏 𝑥 ，𝑏 𝑦 ，𝑏ℎ 和𝑏 𝑤 ，这样得到的边界框比较精确，比单纯使用图像分割算法给出的色块边界要好，所以它 可以得到相当精确的边界框。

现在 R-CNN 算法的一个缺点是太慢了，所以这些年来有一些对 R-CNN 算法的改进工作，Ross Girshik 提出了 Fast R-CNN 算法，它基本上是 R-CNN 算法，不过用卷积实现了滑动窗法。最初的算法是逐一对区域分类的，所以 Fast R-CNN 用的是滑动窗法的一个卷积实现，这和

480 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

你在本周第四个视频（3.4 卷积的滑动窗口实现）中看到的大致相似，这显著提升了 R-CNN 的速度。

事实证明，Fast R-CNN 算法的其中一个问题是得到候选区域的聚类步骤仍然非常缓慢，所以另一个研究组，任少卿（Shaoqing Ren）、何凯明（Kaiming He）、Ross Girshick 和孙剑 （Jiangxi Sun）提出了更快的 R-CNN 算法 (Faster R-CNN)，使用的是卷积神经网络，而不是更 传统的分割算法来获得候选区域色块，结果比 Fast R-CNN 算法快得多。不过我认为大多数 Faster R-CNN 的算法实现还是比 YOLO 算法慢很多。

候选区域的概念在计算机视觉领域的影响力相当大，所以我希望你们能了解一下这些算 法，因为你可以看到还有人在用这些概念。对我个人来说，这是我的个人看法而不是整个计 算机视觉研究界的看法，我觉得候选区域是一个有趣的想法，但这个方法需要两步，首先得 到候选区域，然后再分类，相比之下，能够一步做完，类似于 YOLO 或者你只看一次（You only look once）这个算法，在我看来，是长远而言更有希望的方向。但这是我的个人看法，而不是整个计算机视觉研究界的看法，所以你们最好批判接受。但我想这个 R-CNN 概念，你可能会想到，或者碰到其他人在用，所以这也是值得了解的，这样你可以更好地理解别人 的算法。

现在我们就讲完这周对象检测的材料了，我希望你们喜欢本周的编程练习，我们下周见。

参考文献：

• Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015) 

481 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第三周 目标检测（Object detection）

• Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016) 

• Allan Zelener - YAD2K: Yet Another Darknet 2 Keras 

• The official YOLO website (https://pjreddie.com/darknet/yolo/) 

482 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

第四周 特殊应用：人脸识别和神经风格转换（ Special applications: Face recognition &Neural style transfer）

4.1 什么是人脸识别？（What is face recognition?）

欢迎来到第四周，即这门课卷积神经网络课程的最后一周。到目前为止，你学了很多卷 积神经网络的知识。我这周准备向你展示一些重要的卷积神经网络的特殊应用，我们将从人 脸识别开始，之后讲神经风格迁移，你将有机会在编程作业中实现这部分内容，创造自己的 艺术作品。

让我们先从人脸识别开始，我这里有一个有意思的演示。我在领导百度 AI 团队的时候，其中一个小组由林元庆带领的，做过一个人脸识别系统，这个系统非常棒，让我们来看一下。

（以下内容为演示视频内容）

视频开始： 我想演示一个人脸识别系统，我现在在百度的中国总部，很多公司要求进入公司的时候 要刷工卡，但是在这里我们并不需要它，使用人脸识别，看看我能做什么。当我走近的时候，它会识别我的脸，然后说欢迎我（Andrew NG），不需要工卡，我就能通过了。

让我们看看另一种情况，在旁边的是林元庆，IDL（百度深度学习实验室）的主管，他领 导开发了这个人脸识别系统，我把我的工卡给他，上面有我的头像，他会试着用我的头像照 片，而不是真人来通过。

483 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

（林元庆语：我将尝试用 Andrew 的工卡骗过机器，看看发生什么，系统不会识别，系 统拒绝识别。现在我要用我自己的脸，（系统语音：「欢迎您」）（林元庆顺利通过）） 类似于这样的人脸识别系统在中国发展很快，我希望这个技术也可以在其他的国家使用。#视频结束 挺厉害的吧，你刚看到的这个视频展示了人脸识别和活体检测，后一项技术确认你是一 个活人。事实上，活体检测可以使用监督学习来实现，去预测是不是一个真人，这个方面我 就不多说了。我主要想讲的是，如何构造这个系统中的人脸识别这一部分。首先，让我们了解一下人脸识别的一些术语。在人脸识别的相关文献中，人们经常提到人脸验证（face verification）和人脸识别（face recognition）。

这是人脸验证问题，如果你有一张输入图片，以及某人的 ID 或者是名字，这个系统要 做的是，验证输入图片是否是这个人。有时候也被称作 1 对 1 问题，只需要弄明白这个人是 否和他声称的身份相符。

而人脸识别问题比人脸验证问题难很多（整理者注：1 对多问题（1: 𝐾）），为什么呢？ 假设你有一个验证系统，准确率是 99%，还可以。但是现在，假设在识别系统中，𝐾 = 100，如果你把这个验证系统应用在 100 个人身上，人脸识别上，你犯错的机会就是 100 倍了。如 果每个人犯错的概率是 1%，如果你有一个上百人的数据库，如果你想得到一个可接受的识 别误差，你要构造一个验证系统，其准确率为 99.9% 或者更高，然后才可以在 100 人的数据

484 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

库上运行，而保证有很大几率不出错。事实上，如果我们有一个 100 人的数据库，正确率可 能需要远大于 99%，才能得到很好的效果。

在之后的几个视频中，我们主要讲构造一个人脸验证，作为基本模块，如果准确率够高，你就可以把它用在识别系统上。

下一个视频中，我们将开始讨论如何构造人脸验证系统，人脸验证之所以难，原因之一 在于要解决「一次学」（one-shot learning problem）问题。让我们看下一个视频，什么是一次 学习问题。

485 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.2 One-Shot 学习（One-shot learning）

人脸识别所面临的一个挑战就是你需要解决一次学习问题，这意味着在大多数人脸识别 应用中，你需要通过单单一张图片或者单单一个人脸样例就能去识别这个人。而历史上，当 深度学习只有一个训练样例时，它的表现并不好，让我们看一个直观的例子，并讨论如何去 解决这个问题。

假设你的数据库里有 4 张你们公司的员工照片，实际上他们确实是我们 deeplearning.ai 的员工，分别是 Kian，Danielle，Younes 和 Tian。现在假设有个人（编号 1 所示）来到办公 室，并且她想通过带有人脸识别系统的栅门，现在系统需要做的就是，仅仅通过一张已有的 Danielle 照片，来识别前面这个人确实是她。相反，如果机器看到一个不在数据库里的人（编 号 2 所示），机器应该能分辨出她不是数据库中四个人之一。

所以在一次学习问题中，只能通过一个样本进行学习，以能够认出同一个人。大多数人 脸识别系统都需要解决这个问题，因为在你的数据库中每个雇员或者组员可能都只有一张照 片。

486 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

有一种办法是，将人的照片放进卷积神经网络中，使用 softmax 单元来输出 4 种，或者 说 5 种标签，分别对应这 4 个人，或者 4 个都不是，所以 softmax 里我们会有 5 种输出。但 实际上这样效果并不好，因为如此小的训练集不足以去训练一个稳健的神经网络。

而且，假如有新人加入你的团队，你现在将会有 5 个组员需要识别，所以输出就变成了 6 种，这时你要重新训练你的神经网络吗？这听起来实在不像一个好办法。

所以要让人脸识别能够做到一次学习，为了能有更好的效果，你现在要做的应该是学习 Similarity 函数。详细地说，你想要神经网络学习这样一个用𝑑表示的函数，𝑑(𝑖𝑚𝑔1,𝑖𝑚𝑔2) = 𝑑𝑒𝑔𝑟𝑒𝑒 𝑜𝑓 𝑑𝑖𝑓𝑓𝑒𝑟𝑒𝑛𝑐𝑒 𝑏𝑒𝑡𝑤𝑒𝑒𝑛 𝑖𝑚𝑎𝑔𝑒𝑠，它以两张图片作为输入，然后输出这两张图片的 差异值。如果你放进同一个人的两张照片，你希望它能输出一个很小的值，如果放进两个长 相差别很大的人的照片，它就输出一个很大的值。所以在识别过程中，如果这两张图片的差 异值小于某个阈值𝜏，它是一个超参数，那么这时就能预测这两张图片是同一个人，如果差 异值大于 τ，就能预测这是不同的两个人，这就是解决人脸验证问题的一个可行办法。

487 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

要将它应用于识别任务，你要做的是拿这张新图片（编号 6），然后用𝑑函数去比较这 两张图片（编号 1 和编号 6），这样可能会输出一个非常大的数字，在该例中，比如说这个 数字是 10。之后你再让它和数据库中第二张图（编号 2）片比较，因为这两张照片是同一个 人，所以我们希望会输出一个很小的数。然后你再用它与数据库中的其他图片（编号 3、4） 进行比较，通过这样的计算，最终你能够知道，这个人确实是 Danielle。

对应的，如果某个人（编号 7）不在你的数据库中，你通过函数𝑑将他们的照片两两进 行比较，最后我们希望𝑑会对所有的比较都输出一个很大的值，这就证明这个人并不是数据 库中 4 个人的其中一个。

要注意在这过程中你是如何解决一次学习问题的，只要你能学习这个函数𝑑，通过输入 一对图片，它将会告诉你这两张图片是否是同一个人。如果之后有新人加入了你的团队（编 号 5），你只需将他的照片加入你的数据库，系统依然能照常工作。

现在你已经知道函数 d 是如何工作的，通过输入两张照片，它将让你能够解决一次学习 问题。那么，下节视频中，我们将会学习如何训练你的神经网络学会这个函数𝑑。

488 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.3 Siamese 网络（Siamese network）

上个视频中你学到的函数𝑑的作用就是输入两张人脸，然后告诉你它们的相似度。实现 这个功能的一个方式就是用 Siamese 网络，我们看一下。

你经常看到这样的卷积网络，输入图片𝑥 (1) ，然后通过一些列卷积，池化和全连接层，最终得到这样的特征向量（编号 1）。有时这个会被送进 softmax 单元来做分类，但在这个 视频里我们不会这么做。我们关注的重点是这个向量（编号 1），加如它有 128 个数，它是 由网络深层的全连接层计算出来的，我要给这 128 个数命个名字，把它叫做𝑓(𝑥 (1) )。你可以 把𝑓(𝑥 (1) ) 看作是输入图像𝑥 (1) 的编码，取这个输入图像（编号 2），在这里是 Kian 的图片，然后表示成 128 维的向量。

建立一个人脸识别系统的方法就是，如果你要比较两个图片的话，例如这里的第一张（编 号 1）和第二张图片（编号 2），你要做的就是把第二张图片喂给有同样参数的同样的神经 网络，然后得到一个不同的 128 维的向量（编号 3），这个向量代表或者编码第二个图片，我要把第二张图片的编码叫做𝑓(𝑥 (2) )。这里我用𝑥 (1) 和𝑥 (2) 仅仅代表两个输入图片，他们没 必要非是第一个和第二个训练样本，可以是任意两个图片。

489 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

最后如果你相信这些编码很好地代表了这两个图片，你要做的就是定义𝑑，将𝑥 (1) 和𝑥(2) 的距离定义为这两幅图片的编码之差的范数，𝑑(𝑥 (1) ,𝑥 (2) ) = ||𝑓(𝑥 (1) ) − 𝑓(𝑥 (2) )||2 2 。

对于两个不同的输入，运行相同的卷积神经网络，然后比较它们，这一般叫做 Siamese 网络架构。这里提到的很多观点，都来自于 Yaniv Taigman，Ming Yang，Marc’ Aurelio Ranzato，Lior Wolf 的这篇论文，他们开发的系统叫做 DeepFace。

怎么训练这个 Siamese 神经网络呢？不要忘了这两个网络有相同的参数，所以你实际要 做的就是训练一个网络，它计算得到的编码可以用于函数𝑑，它可以告诉你两张图片是否是 同一个人。更准确地说，神经网络的参数定义了一个编码函数𝑓(𝑥 (𝑖) )，如果给定输入图像𝑥 (𝑖) ，这个网络会输出𝑥 (𝑖) 的 128 维的编码。你要做的就是学习参数，使得如果两个图片𝑥 (𝑖) 和𝑥(𝑗) 是同一个人，那么你得到的两个编码的距离就小。前面几个幻灯片我都用的是𝑥 (1) 和𝑥 (2) ，其 实训练集里任意一对𝑥 (𝑖) 和𝑥 (𝑗) 都可以。相反，如果𝑥 (𝑖) 和𝑥 (𝑗) 是不同的人，那么你会想让它们 之间的编码距离大一点。

如果你改变这个网络所有层的参数，你会得到不同的编码结果，你要做的就是用反向传 播来改变这些所有的参数，以确保满足这些条件。

你已经了解了 Siamese 网络架构，并且知道你想要网络输出什么，即什么是好的编码。但是如何定义实际的目标函数，能够让你的神经网络学习并做到我们刚才讨论的内容呢？在 下一个视频里，我们会看到如何用三元组损失函数达到这个目的。

490 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.4 Triplet 损失（Triplet 损失）

要想通过学习神经网络的参数来得到优质的人脸图片编码，方法之一就是定义三元组损 失函数然后应用梯度下降。

我们看下这是什么意思，为了应用三元组损失函数，你需要比较成对的图像，比如这个 图片，为了学习网络的参数，你需要同时看几幅图片，比如这对图片（编号 1 和编号 2），你想要它们的编码相似，因为这是同一个人。然而假如是这对图片（编号 3 和编号 4），你 会想要它们的编码差异大一些，因为这是不同的人。

用三元组损失的术语来说，你要做的通常是看一个 Anchor 图片，你想让 Anchor 图片 和 Positive 图片（Positive 意味着是同一个人）的距离很接近。然而，当 Anchor 图片与 Negative 图片（Negative 意味着是非同一个人）对比时，你会想让他们的距离离得更远一点。

这就是为什么叫做三元组损失，它代表你通常会同时看三张图片，你需要看 Anchor 图 片、Postive 图片，还有 Negative 图片，我要把 Anchor 图片、Positive 图片和 Negative 图片 简写成𝐴、𝑃、𝑁。

把这些写成公式的话，你想要的是网络的参数或者编码能够满足以下特性，也就是说你 想要 ||𝑓(𝐴) − 𝑓(𝑃)||2 ，你希望这个数值很小，准确地说，你想让它小于等𝑓(𝐴) 和𝑓(𝑁) 之间的 距离，或者说是它们的范数的平方（即：||𝑓(𝐴) − 𝑓(𝑃)|| 2 ≤ ||𝑓(𝐴) − 𝑓(𝑁)||2 ）。（||𝑓(𝐴) 𝑓(𝑃)||2 ）当然这就是𝑑(𝐴, 𝑃)，（||𝑓(𝐴) − 𝑓(𝑁)|| 2 ）这是𝑑(𝐴, 𝑁)，你可以把𝑑看作是距离 (distance)

491 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

函数，这也是为什么我们把它命名为𝑑。

现在如果我把方程右边项移到左边，最终就得到：

||𝑓(𝐴) − 𝑓(𝑃)|| 2 ≤ ||𝑓(𝐴) − 𝑓(𝑁)||2 

现在我要对这个表达式做一些小的改变，有一种情况满足这个表达式，但是没有用处，就是把所有的东西都学成 0，如果𝑓总是输出 0，即 0-0≤0，这就是 0 减去 0 还等于 0，如果 所有图像的𝑓都是一个零向量，那么总能满足这个方程。所以为了确保网络对于所有的编码 不会总是输出 0，也为了确保它不会把所有的编码都设成互相相等的。另一种方法能让网络 得到这种没用的输出，就是如果每个图片的编码和其他图片一样，这种情况，你还是得到 00。

为了阻止网络出现这种情况，我们需要修改这个目标，也就是，这个不能是刚好小于等 于 0，应该是比 0 还要小，所以这个应该小于一个−𝑎值（即 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) 𝑓(𝑁)|| 2 ≤ −𝑎），这里的𝑎是另一个超参数，这个就可以阻止网络输出无用的结果。按照惯 例，我们习惯写 +𝑎（即 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎 ≤ 0），而不是把−𝑎写在后 面，它也叫做间隔 (margin)，这个术语你会很熟悉，如果你看过关于支持向量机 (SVM) 的文 献，没看过也不用担心。我们可以把上面这个方程（||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)||2 ）也 修改一下，加上这个间隔参数。

举个例子，假如间隔设置成 0.2，如果在这个例子中，𝑑(𝐴, 𝑃) = 0.5，如果 Anchor 和 Negative 图片的𝑑，即𝑑(𝐴, 𝑁) 只大一点，比如说 0.51，条件就不能满足。虽然 0.51 也是大于 0.5 的，但还是不够好，我们想要𝑑(𝐴, 𝑁) 比𝑑(𝐴, 𝑃) 大很多，你会想让这个值（𝑑(𝐴, 𝑁)）至少 是 0.7 或者更高，或者为了使这个间隔，或者间距至少达到 0.2，你可以把这项调大或者这

492 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

个调小，这样这个间隔𝑎，超参数𝑎 至少是 0.2，在𝑑(𝐴, 𝑃) 和𝑑(𝐴, 𝑁) 之间至少相差 0.2，这就 是间隔参数𝑎的作用。它拉大了 Anchor 和 Positive 图片对和 Anchor 与 Negative 图片对之 间的差距。取下面的这个方框圈起来的方程式，在下个幻灯片里，我们会更公式化表示，然 后定义三元组损失函数。

三元组损失函数的定义基于三张图片，假如三张图片𝐴、𝑃、𝑁，即 anchor 样本、positive 样本和 negative 样本，其中 positive 图片和 anchor 图片是同一个人，但是 negative 图片和 anchor 不是同一个人。

接下来我们定义损失函数，这个例子的损失函数，它的定义基于三元图片组，我先从前 一张幻灯片复制过来一些式子，就是 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎 ≤ 0。所以为了

定义这个损失函数，我们取这个和 0 的最大值：

𝐿(𝐴, 𝑃, 𝑁) = 𝑚𝑎𝑥(||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎, 0) 

这个𝑚𝑎𝑥函数的作用就是，只要这个 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎 ≤ 0，那么 损失函数就是 0。只要你能使画绿色下划线部分小于等于 0，只要你能达到这个目标，那么 这个例子的损失就是 0。

493 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

另一方面如果这个 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎 ≤ 0，然后你取它们的最大值，最终你会得到绿色下划线部分（即 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎）是最大值，这样

你会得到一个正的损失值。通过最小化这个损失函数达到的效果就是使这部分 ||𝑓(𝐴) 𝑓(𝑃)|| 2 − ||𝑓(𝐴) − 𝑓(𝑁)|| 2 + 𝑎成为 0，或者小于等于 0。只要这个损失函数小于等于 0，网 络不会关心它负值有多大。

这是一个三元组定义的损失，整个网络的代价函数应该是训练集中这些单个三元组损失 的总和。假如你有一个 10000 个图片的训练集，里面是 1000 个不同的人的照片，你要做的 就是取这 10000 个图片，然后生成这样的三元组，然后训练你的学习算法，对这种代价函数 用梯度下降，这个代价函数就是定义在你数据集里的这样的三元组图片上。

注意，为了定义三元组的数据集你需要成对的𝐴和𝑃，即同一个人的成对的图片，为了 训练你的系统你确实需要一个数据集，里面有同一个人的多个照片。这是为什么在这个例子 中，我说假设你有 1000 个不同的人的 10000 张照片，也许是这 1000 个人平均每个人 10 张 照片，组成了你整个数据集。如果你只有每个人一张照片，那么根本没法训练这个系统。当 然，训练完这个系统之后，你可以应用到你的一次学习问题上，对于你的人脸识别系统，可 能你只有想要识别的某个人的一张照片。但对于训练集，你需要确保有同一个人的多个图片，至少是你训练集里的一部分人，这样就有成对的 Anchor 和 Positive 图片了。

494 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

现在我们来看，你如何选择这些三元组来形成训练集。一个问题是如果你从训练集中，随机地选择𝐴、𝑃和𝑁，遵守𝐴和𝑃是同一个人，而𝐴和𝑁是不同的人这一原则。有个问题就是，如果随机的选择它们，那么这个约束条件（𝑑(𝐴, 𝑃) + 𝑎 ≤ 𝑑(𝐴, 𝑁)）很容易达到，因为随机 选择的图片，𝐴和𝑁比𝐴和𝑃差别很大的概率很大。我希望你还记得这个符号𝑑(𝐴, 𝑃) 就是前几 个幻灯片里写的 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 ，𝑑(𝐴, 𝑁) 就是 ||𝑓(𝐴) − 𝑓(𝑁)|| 2 ，𝑑(𝐴, 𝑃) + 𝑎 ≤ 𝑑(𝐴, 𝑁) 即 ||𝑓(𝐴) − 𝑓(𝑃)|| 2 + 𝑎 ≤ ||𝑓(𝐴) − 𝑓(𝑁)||2 。但是如果𝐴和𝑁是随机选择的不同的人，有很大的 可能性 ||𝑓(𝐴) − 𝑓(𝑁)||2 会比左边这项 ||𝑓(𝐴) − 𝑓(𝑃)||2 大，而且差距远大于𝑎，这样网络并不 能从中学到什么。

所以为了构建一个数据集，你要做的就是尽可能选择难训练的三元组𝐴、𝑃和𝑁。具体而 言，你想要所有的三元组都满足这个条件（𝑑(𝐴, 𝑃) + 𝑎 ≤ 𝑑(𝐴, 𝑁)），难训练的三元组就是，你的𝐴、𝑃和𝑁的选择使得𝑑(𝐴, 𝑃) 很接近𝑑(𝐴, 𝑁)，即𝑑(𝐴, 𝑃) ≈ 𝑑(𝐴, 𝑁)，这样 你的学习算法 会竭尽全力使右边这个式子变大（𝑑(𝐴, 𝑁)），或者使左边这个式子（𝑑(𝐴, 𝑃)）变小，这样左 右两边至少有一个𝑎的间隔。并且选择这样的三元组还可以增加你的学习算法的计算效率，如果随机的选择这些三元组，其中有太多会很简单，梯度算法不会有什么效果，因为网络总 是很轻松就能得到正确的结果，只有选择难的三元组梯度下降法才能发挥作用，使得这两边 离得尽可能远。

如果你对此感兴趣的话，这篇论文中有更多细节，作者是 Florian Schroff, Dmitry Kalenichenko, James Philbin，他们建立了这个叫做 FaceNet 的系统，我视频里许多的观点都 是来自于他们的工作。·Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). FaceNet: A Unified Embedding

for Face Recognition and Clustering 

顺便说一下，这有一个有趣的事实，关于在深度学习领域，算法是如何命名的。如果你

495 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

研究一个特定的领域，假如说「某某」领域，通常会将系统命名为「某某」网络或者深度「某某」，我们一直讨论人脸识别，所以这篇论文叫做 FaceNet (人脸网络)，上个视频里你看到过 DeepFace (深度人脸)。「某某」网络或者深度「某某」，是深度学习领域流行的命名算法的方式，你可以看一下这篇论文，如果你想要了解更多的关于通过选择最有用的三元组训练来加速算 法的细节，这是一个很棒的论文。总结一下，训练这个三元组损失你需要取你的训练集，然后把它做成很多三元组，这就 是一个三元组（编号 1），有一个 Anchor 图片和 Positive 图片，这两个（Anchor 和 Positive） 是同一个人，还有一张另一个人的 Negative 图片。这是另一组（编号 2），其中 Anchor 和 Positive 图片是同一个人，但是 Anchor 和 Negative 不是同一个人，等等。

定义了这些包括𝐴、𝑃和𝑁图片的数据集之后，你还需要做的就是用梯度下降最小化我们 之前定义的代价函数𝐽，这样做的效果就是反向传播到网络中的所有参数来学习到一种编码，使得如果两个图片是同一个人，那么它们的𝑑就会很小，如果两个图片不是同一个人，它们 的𝑑就会很大。

这就是三元组损失，并且如何用它来训练网络输出一个好的编码用于人脸识别。现在的 人脸识别系统，尤其是大规模的商业人脸识别系统都是在很大的数据集上训练，超过百万图 片的数据集并不罕见，一些公司用千万级的图片，还有一些用上亿的图片来训练这些系统。这些是很大的数据集，即使按照现在的标准，这些数据集并不容易获得。幸运的是，一些公 司已经训练了这些大型的网络并且上传了模型参数。所以相比于从头训练这些网络，在这一 领域，由于这些数据集太大，这一领域的一个实用操作就是下载别人的预训练模型，而不是 一切都要从头开始。但是即使你下载了别人的预训练模型，我认为了解怎么训练这些算法也 是有用的，以防针对一些应用你需要从头实现这些想法。

496 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

这就是三元组损失，下个视频中，我会给你展示 Siamese 网络的一些其他变体，以及如 何训练这些网络。

497 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.5 人 脸 验 证 与 二 分 类 （ Face verification and binary classification）

Triplet loss 是一个学习人脸识别卷积网络参数的好方法，还有其他学习参数的方法，让 我们看看如何将人脸识别当成一个二分类问题。

另一个训练神经网络的方法是选取一对神经网络，选取 Siamese 网络，使其同时计算这 些嵌入，比如说 128 维的嵌入（编号 1），或者更高维，然后将其输入到逻辑回归单元，然 后进行预测，如果是相同的人，那么输出是 1，若是不同的人，输出是 0。这就把人脸识别 问题转换为一个二分类问题，训练这种系统时可以替换 Triplet loss 的方法。

最后的逻辑回归单元是怎么处理的？输出𝑦会变成，比如说 sigmoid 函数应用到某些特 征上，相比起直接放入这些编码（𝑓(𝑥 (𝑖) ),𝑓(𝑥 (𝑗) )），你可以利用编码之间的不同。

128 

𝑦 = 𝜎(∑ 𝑤 𝑖 |𝑓(𝑥 (𝑖) ) 𝑘 − 𝑓(𝑥 (𝑗) ) 𝑘 | + 𝑏) 

𝑘=1 

我解释一下，符号𝑓(𝑥 (𝑖) ) 𝑘 代表图片𝑥 (𝑖) 的编码，下标𝑘代表选择这个向量中的第𝑘个元素，|𝑓(𝑥 (𝑖) ) 𝑘 − 𝑓(𝑥 (𝑗) ) 𝑘 | 对这两个编码取元素差的绝对值。你可能想，把这 128 个元素当作特征，然后把他们放入逻辑回归中，最后的逻辑回归可以增加参数𝑤 𝑖 和𝑏，就像普通的逻辑回归一 样。你将在这 128 个单元上训练合适的权重，用来预测两张图片是否是一个人，这是一个很 合理的方法来学习预测 0 或者 1，即是否是同一个人。

还有其他不同的形式来计算绿色标记的这部分公式（|𝑓(𝑥 (𝑖) ) 𝑘 − 𝑓(𝑥 (𝑗) ) 𝑘 |），比如说，

498 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

(𝑓(𝑥 (𝑖) ) 𝑘 −𝑓(𝑥 (𝑗) ) 𝑘 ) 2 公式可以是 (𝑖) 𝑓(𝑥) 𝑘 +𝑓(𝑥 (𝑗) )𝑘

，这个公式也被叫做𝜒2 公式，是一个希腊字母𝜒，也被称为

𝜒平方相似度。·Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). DeepFace: Closing the gap to human-level performance in face verification

这些公式及其变形在这篇 DeepFace 论文中有讨论，我之前也引用过。

但是在这个学习公式中，输入是一对图片，这是你的训练输入𝑥（编号 1、2），输出𝑦 是 0 或者 1，取决于你的输入是相似图片还是非相似图片。与之前类似，你正在训练一个 Siamese 网络，意味着上面这个神经网络拥有的参数和下面神经网络的相同（编号 3 和 4 所 示的网络），两组参数是绑定的，这样的系统效果很好。

之前提到一个计算技巧可以帮你显著提高部署效果，如果这是一张新图片（编号 1），当员工走进门时，希望门可以自动为他们打开，这个（编号 2）是在数据库中的图片，不需 要每次都计算这些特征（编号 6），不需要每次都计算这个嵌入，你可以提前计算好，那么 当一个新员工走近时，你可以使用上方的卷积网络来计算这些编码（编号 5），然后使用它，和预先计算好的编码进行比较，然后输出预测值𝑦。

因为不需要存储原始图像，如果你有一个很大的员工数据库，你不需要为每个员工每次 都计算这些编码。这个预先计算的思想，可以节省大量的计算，这个预训练的工作可以用在 Siamese 网路结构中，将人脸识别当作一个二分类问题，也可以用在学习和使用 Triplet loss 函数上，我在之前的视频中描述过。

总结一下，把人脸验证当作一个监督学习，创建一个只有成对图片的训练集，不是三个 一组，而是成对的图片，目标标签是 1 表示一对图片是一个人，目标标签是 0 表示图片中是 不同的人。利用不同的成对图片，使用反向传播算法去训练神经网络，训练 Siamese 神经网 络。

499 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

这个你看到的版本，处理人脸验证和人脸识别扩展为二分类问题，这样的效果也很好。我希望你知道，在一次学习时，你需要什么来训练人脸验证，或者人脸识别系统。

500 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.6 什么是神经风格迁移？（What is neural style transfer?）

最近，卷积神经网络最有趣的应用是神经风格迁移，在编程作业中，你将自己实现这部 分并创造出你的艺术作品。

什么是神经风格迁移？让我们来看几个例子，比如这张照片，照片是在斯坦福大学拍摄 的，离我的办公室不远，你想利用右边照片的风格来重新创造原本的照片，右边的是梵高的 星空，神经风格迁移可以帮你生成下面这张照片。

这仍是斯坦福大学的照片，但是用右边图像的风格画出来。为了描述如何实现神经网络迁移，我将使用𝐶来表示内容图像，𝑆表示风格图像，𝐺表示 生成的图像。

501 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

另一个例子，比如，这张图片，𝐶代表在旧金山的金门大桥，还有这张风格图片，是毕 加索的风格，然后把两张照片结合起来，得到𝐺这张毕加索风格的的金门大桥。

这页中展示的例子，是由 Justin Johnson 制作，在下面几个视频中你将学到如何自己生 成这样的图片。

为了实现神经风格迁移，你需要知道卷积网络提取的特征，在不同的神经网络，深层的、 浅层的。在深入了解如何实现神经风格迁移之前，我将在下一个视频中直观地介绍卷积神经 网络不同层之间的具体运算，让我们来看下一个视频。

502 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.7 深度卷积网络学习什么？（What are deep ConvNets learning?）

深度卷积网络到底在学什么？在这个视频中我将展示一些可视化的例子，可以帮助你理 解卷积网络中深度较大的层真正在做什么，这样有助于理解如何实现神经风格迁移。

来看一个例子，假如你训练了一个卷积神经网络，是一个 Alexnet，轻量级网络，你希 望将看到不同层之间隐藏单元的计算结果。

你可以这样做，从第一层的隐藏单元开始，假设你遍历了训练集，然后找到那些使得单 元激活最大化的一些图片，或者是图片块。换句话说，将你的训练集经过神经网络，然后弄 明白哪一张图片最大限度地激活特定的单元。注意在第一层的隐藏单元，只能看到小部分卷 积神经，如果要画出来哪些激活了激活单元，只有一小块图片块是有意义的，因为这就是特 定单元所能看到的全部。你选择一个隐藏单元，发现有 9 个图片最大化了单元激活，你可能 找到这样的 9 个图片块（编号 1），似乎是图片浅层区域显示了隐藏单元所看到的，找到了 像这样的边缘或者线（编号 2），这就是那 9 个最大化地激活了隐藏单元激活项的图片块。

然后你可以选一个另一个第一层的隐藏单元，重复刚才的步骤，这是另一个隐藏单元，似乎第二个由这 9 个图片块（编号 1）组成。看来这个隐藏单元在输入区域，寻找这样的线 条（编号 2），我们也称之为接受域。

503 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

对其他隐藏单元也进行处理，会发现其他隐藏单元趋向于激活类似于这样的图片。这个 似乎对垂直明亮边缘左边有绿色的图片块（编号 1）感兴趣，这一个隐藏单元倾向于橘色，这是一个有趣的图片块（编号 2），红色和绿色混合成褐色或者棕橙色，但是神经元仍可以 激活它。

以此类推，这是 9 个不同的代表性神经元，每一个不同的图片块都最大化地激活了。你 可以这样理解，第一层的隐藏单元通常会找一些简单的特征，比如说边缘或者颜色阴影。

我在这个视频中使用的所有例子来自于 Matthew Zener 和 Rob Fergus 的这篇论文，题目 是（Zeiler M D, Fergus R. Visualizing and Understanding Convolutional Networks [J]. 2013, 8689:818-833.）《可视化理解卷积神经网络》，我会使用一种更简单的方法来可视化神经网 络隐藏单元的计算内容。如果你读过他们的论文，他们提出了一些更复杂的方式来可视化卷 积神经网络的计算。

你已经在第一层的 9 个隐藏单元重复了这个过程好几遍，如果在深层的隐藏单元中进 行这样的计算呢？卷积神经网络的深层部分学到了什么？在深层部分，一个隐藏单元会看到 一张图片更大的部分，在极端的情况下，可以假设每一个像素都会影响到神经网络更深层的 输出，靠后的隐藏单元可以看到更大的图片块，我还会画出和这页中的大小相同的图片块。

但如果我们重复这一过程，这（Layer 1 所示图片）是之前第一层得到的，这个（Layer

504 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

2 所示图片）是可视化的第 2 层中最大程度激活的 9 个隐藏单元。我想解释一下这个可视 化，这是（编号 2 所示）使一个隐藏单元最大激活的 9 个图片块，每一个组合，这是另一组 （编号 2），使得一个隐藏单元被激活的 9 个图片块，这个可视化展示了第二层的 9 个隐藏 单元，每一个又有 9 个图片块使得隐藏单元有较大的输出或是较大的激活。

在更深的层上，你可以重复这个过程。

在这页里很难看清楚，这些微小的浅层图片块，让我们放大一些，这是第一层，这是第 一个被高度激活的单元，你能在输入图片的区域看到，大概是这个角度的边缘（编号 1）放 大第二层的可视化图像。

有意思了，第二层似乎检测到更复杂的形状和模式，比如说这个隐藏单元（编号 1），它会找到有很多垂线的垂直图案，这个隐藏单元（编号 2）似乎在左侧有圆形图案时会被高 度激活，这个的特征（编号 3）是很细的垂线，以此类推，第二层检测的特征变得更加复杂。

505 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

看看第三层我们将其放大，放得更大一点，看得更清楚一点，这些东西激活了第三层。再放大一点，这又很有趣了，这个隐藏单元（编号 1）似乎对图像左下角的圆形很敏感，所 以检测到很多车。这一个（编号 2）似乎开始检测到人类，这个（编号 3）似乎检测特定的 图案，蜂窝形状或者方形，类似这样规律的图案。有些很难看出来，需要手动弄明白检测到 什么，但是第三层明显，检测到更复杂的模式。

下一层呢？这是第四层，检测到的模式和特征更加复杂，这个（编号 1）学习成了一个 狗的检测器，但是这些狗看起来都很类似，我并不知道这些狗的种类，但是你知道这些都是 狗，他们看起来也类似。第四层中的这个（编号 2）隐藏单元它检测什么？水吗？这个（编 号 3）似乎检测到鸟的脚等等。

506 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

第五层检测到更加复杂的事物，注意到这（编号 1）也有一个神经元，似乎是一个狗检 测器，但是可以检测到的狗似乎更加多样性。这个（编号 2）可以检测到键盘，或者是键盘 质地的物体，可能是有很多点的物体。我认为这个神经元（编号 3）可能检测到文本，但是 很难确定，这个（编号 4）检测到花。我们已经有了一些进展，从检测简单的事物，比如说，第一层的边缘，第二层的质地，到深层的复杂物体。

我希望这让你可以更直观地了解卷积神经网络的浅层和深层是如何计算的，接下来让我 们使用这些知识开始构造神经风格迁移算法。

507 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.8 代价函数（Cost function）

要构建一个神经风格迁移系统，让我们为生成的图像定义一个代价函数，你接下看到的 是，通过最小化代价函数，你可以生成你想要的任何图像。

记住我们的问题，给你一个内容图像𝐶，给定一个风格图片𝑆，而你的目标是生成一个新 图片𝐺。为了实现神经风格迁移，你要做的是定义一个关于𝐺的代价函数𝐽用来评判某个生成 图像的好坏，我们将使用梯度下降法去最小化𝐽(𝐺)，以便于生成这个图像。

怎么判断生成图像的好坏呢？我们把这个代价函数定义为两个部分。

𝐽 content (𝐶, 𝐺) 

第一部分被称作内容代价，这是一个关于内容图片和生成图片的函数，它是用来度量生 成图片𝐺的内容与内容图片𝐶的内容有多相似。

𝐽 style (𝑆, 𝐺) 

然后我们会把结果加上一个风格代价函数，也就是关于𝑆和𝐺的函数，用来度量图片𝐺的 风格和图片𝑆的风格的相似度。

𝐽(𝐺) = 𝑎𝐽 content (𝐶, 𝐺) + 𝛽𝐽 style (𝑆, 𝐺) 

最后我们用两个超参数𝑎和𝛽来来确定内容代价和风格代价，两者之间的权重用两个超 参数来确定。两个代价的权重似乎是多余的，我觉得一个超参数似乎就够了，但提出神经风 格迁移的原始作者使用了两个不同的超参数，我准备保持一致。

关于神经风格迁移算法我将在接下来几段视频中展示的，是基于 Leon Gatys，Alexandra Ecker 和 Matthias Bethge 的这篇论文。Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style (https://arxiv.org/abs/1508.06576)

508 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

这篇论文并不是很难读懂，如果你愿意，看完这些视频，我也非常推荐你去看看他们的 论文。

算法的运行是这样的，对于代价函数𝐽(𝐺)，为了生成一个新图像，你接下来要做的是随 机初始化生成图像𝐺，它可能是 100×100×3，可能是 500×500×3，又或者是任何你想要的尺 寸。

然后使用在之前的幻灯片上定义的代价函数𝐽(𝐺)，你现在可以做的是使用梯度下降的方 𝜕 法将其最小化，更新𝐺: = 𝐺 − 𝜕𝐺 𝐽(𝐺)。在这个步骤中，你实际上更新的是图像𝐺的像素值，也就是 100×100×3，比如 RGB 通道的图片。

这里有个例子，假设你从这张内容图片（编号 1）和风格（编号 2）图片开始，这是另 一张公开的毕加索画作，当你随机初始化𝐺，你随机初始化的生成图像就是这张随机选取像 素的白噪声图（编号 3）。接下来运行梯度下降算法，最小化代价函数𝐽(𝐺)，逐步处理像素，这样慢慢得到一个生成图片（编号 4、5、6），越来越像用风格图片的风格画出来的内容图 片。

在这段视频中你看到了神经风格迁移算法的概要，定义一个生成图片𝐺的代价函数，并 将其最小化。接下来我们需要了解怎么去定义内容代价函数和风格代价函数，让我们从下一 个视频开始学习这部分内容吧。

509 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.9 内容代价函数（Content cost function）

风格迁移网络的代价函数有一个内容代价部分，还有一个风格代价部分。

𝐽(𝐺) = 𝛼𝐽 content (𝐶, 𝐺) + 𝛽𝐽 style (𝑆, 𝐺) 

我们先定义内容代价部分，不要忘了这就是我们整个风格迁移网络的代价函数，我们看 看内容代价函数应该是什么。

假如说，你用隐含层𝑙来计算内容代价，如果𝑙是个很小的数，比如用隐含层 1，这个代 价函数就会使你的生成图片像素上非常接近你的内容图片。然而如果你用很深的层，那么那 就会问，内容图片里是否有狗，然后它就会确保生成图片里有一个狗。所以在实际中，这个 层𝑙在网络中既不会选的太浅也不会选的太深。因为你要自己做这周结束的编程练习，我会 让你获得一些直觉，在编程练习中的具体例子里通常𝑙会选择在网络的中间层，既不太浅也 不很深，然后用一个预训练的卷积模型，可以是 VGG 网络或者其他的网络也可以。

现在你需要衡量假如有一个内容图片和一个生成图片他们在内容上的相似度，我们令这 个𝑎 [𝑙][𝐶] 和𝑎 [𝑙][𝐺] ，代表这两个图片𝐶和𝐺的𝑙层的激活函数值。如果这两个激活值相似，那么 就意味着两个图片的内容相似。

1 我们定义这个：𝐽 content (𝐶, 𝐺) = 2 ||𝑎 [𝑙][𝐶] − 𝑎 [𝑙][𝐺] ||2 ，为两个激活值不同或者相似的程度，我们取𝑙层的隐含单元的激活值，按元素相减，内容图片的激活值与生成图片相比较，然后

510 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

取平方，也可以在前面加上归一化或者不加，比如 1 或者其他的，都影响不大，因为这都可以 2 由这个超参数 α 来调整（𝐽(𝐺) = 𝑎𝐽 content (𝐶, 𝐺) + 𝛽𝐽 style (𝑆, 𝐺)）。

要清楚我这里用的符号都是展成向量形式的，这个就变成了这一项（𝑎 [𝑙][𝐶] ）减这一项 （𝑎 [𝑙][𝐶] ）的𝐿2 范数的平方，在把他们展成向量后。这就是两个激活值间的差值平方和，这 就是两个图片之间𝑙层激活值差值的平方和。后面如果对𝐽(𝐺) 做梯度下降来找𝐺的值时，整个 代价函数会激励这个算法来找到图像𝐺，使得隐含层的激活值和你内容图像的相似。

这就是如何定义风格迁移网络的内容代价函数，接下来让我们学习风格代价函数。

511 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.10 风格代价函数（Style cost function）

在上节视频中，我们学习了如何为神经风格迁移定义内容代价函数，这节课我们来了解 风格代价函数。那么图片的风格到底是什么意思呢？

这么说吧，比如你有这样一张图片，你可能已经对这个计算很熟悉了，它能算出这里是 否含有不同隐藏层。现在你选择了某一层𝑙（编号 1），比如这一层去为图片的风格定义一个 深度测量，现在我们要做的就是将图片的风格定义为𝑙层中各个通道之间激活项的相关系数。

我来详细解释一下，现在你将𝑙层的激活项取出，这是个𝑛 𝐻 × 𝑛 𝑊 × 𝑛 𝐶 的激活项，它是一 个三维的数据块。现在问题来了，如何知道这些不同通道之间激活项的相关系数呢？

为了解释这些听起来很含糊不清的词语，现在注意这个激活块，我把它的不同通道渲染 成不同的颜色。在这个例子中，假如我们有 5 个通道为了方便讲解，我将它们染成了五种颜 色。一般情况下，我们在神经网络中会有许多通道，但这里只用 5 个通道，会更方便我们理 解。

为了能捕捉图片的风格，你需要进行下面这些操作，首先，先看前两个通道，前两个通 道（编号 1、2）分别是图中的红色和黄色部分，那我们该如何计算这两个通道间激活项的相 关系数呢？

512 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

举个例子，在视频的左下角在第一个通道中含有某个激活项，第二个通道也含有某个激 活项，于是它们组成了一对数字（编号 1 所示）。然后我们再看看这个激活项块中其他位置 的激活项，它们也分别组成了很多对数字（编号 2，3 所示），分别来自第一个通道，也就 是红色通道和第二个通道，也就是黄色通道。现在我们得到了很多个数字对，当我们取得这 两个𝑛 𝐻 × 𝑛 𝑊 的通道中所有的数字对后，现在该如何计算它们的相关系数呢？它是如何决定 图片风格的呢？

我们来看一个例子，这是之前视频中的一个可视化例子，它来自一篇论文，作者是 Matthew Zeile 和 Rob Fergus 我之前有提到过。我们知道，这个红色的通道（编号 1）对应 的是这个神经元，它能找出图片中的特定位置是否含有这些垂直的纹理（编号 3），而第二 个通道也就是黄色的通道（编号 2），对应这个神经元（编号 4），它可以粗略地找出橙色 的区域。什么时候两个通道拥有高度相关性呢？如果它们有高度相关性，那么这幅图片中出 现垂直纹理的地方（编号 2），那么这块地方（编号 4）很大概率是橙色的。如果说它们是 不相关的，又是什么意思呢？显然，这意味着图片中有垂直纹理的地方很大概率不是橙色的。而相关系数描述的就是当图片某处出现这种垂直纹理时，该处又同时是橙色的可能性。

相关系数这个概念为你提供了一种去测量这些不同的特征的方法，比如这些垂直纹理，这些橙色或是其他的特征去测量它们在图片中的各个位置同时出现或不同时出现的频率。

如果我们在通道之间使用相关系数来描述通道的风格，你能做的就是测量你的生成图像 中第一个通道（编号 1）是否与第二个通道（编号 2）相关，通过测量，你能得知在生成的 图像中垂直纹理和橙色同时出现或者不同时出现的频率，这样你将能够测量生成的图像的风

513 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

格与输入的风格图像的相似程度。

现在我们来证实这种说法，对于这两个图像，也就是风格图像与生成图像，你需要计算 一个风格矩阵，说得更具体一点就是用𝑙层来测量风格。

- 

我们设𝑎 𝑖, 𝑗, 𝑘 [𝑙] ，设它为隐藏层𝑙中 (𝑖, 𝑗, 𝑘) 位置的激活项，𝑖，𝑗，𝑘分别代表该位置的高度、

宽度以及对应的通道数。现在你要做的就是去计算一个关于𝑙层和风格图像的矩阵，即𝐺[𝑙](𝑆) （𝑙表示层数，𝑆表示风格图像），这（𝐺 [𝑙](𝑆) ）是一个𝑛 𝑐 × 𝑛 𝑐 的矩阵，同样地，我们也对生 成的图像进行这个操作。但是现在我们先来定义风格图像，设这个关于𝑙层和风格图像的，𝐺是一个矩阵，这个矩 阵的高度和宽度都是𝑙层的通道数。在这个矩阵中𝑘和𝑘′元素被用来描述𝑘通道和𝑘′通道之间 的相关系数。具体地：

[𝑙] [𝑙] 𝑛 𝐻 𝑛 𝑊 

𝐺 𝑘𝑘 ′ [𝑙](𝑆) = ∑ ∑ 𝑎 𝑖, 𝑗, 𝑘 [𝑙](𝑆) 𝑎𝑖, 𝑗, 𝑘 ′ [𝑙](𝑆) 

𝑖=1 𝑗=1 

用符号𝑖，𝑗表示下界，对𝑖，𝑗，𝑘位置的激活项𝑎 𝑖, 𝑗, 𝑘 [𝑙] ，乘以同样位置的激活项，也就是

𝑖,𝑗,𝑘′位置的激活项，即𝑎 𝑖,𝑗,𝑘 ′ [𝑙] ，将它们两个相乘。然后𝑖和𝑗分别加到 l 层的高度和宽度，即𝑛𝐻 [𝑙]

和𝑛 𝑊 [𝑙] ，将这些不同位置的激活项都加起来。(𝑖, 𝑗, 𝑘) 和 (𝑖, 𝑗, 𝑘′) 中𝑥坐标和𝑦坐标分别对应高度 和宽度，将𝑘通道和𝑘′通道上这些位置的激活项都进行相乘。我一直以来用的这个公式，严 格来说，它是一种非标准的互相关函数，因为我们没有减去平均数，而是将它们直接相乘。

514 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

这就是输入的风格图像所构成的风格矩阵，然后，我们再对生成图像做同样的操作。

[𝑙] [𝑙] 𝑛 𝐻 𝑛 𝑊 

𝐺 𝑘𝑘 ′ [𝑙](𝐺) = ∑ ∑ 𝑎 𝑖, 𝑗, 𝑘 [𝑙](𝐺) 𝑎𝑖, 𝑗, 𝑘 ′ [𝑙](𝐺) 

𝑖=1 𝑗=1 

𝑎 𝑖, 𝑗, 𝑘 [𝑙](𝑆) 和𝑎 𝑖,𝑗,𝑘 [𝑙](𝐺) 中的上标 (𝑆) 和 (𝐺) 分别表示在风格图像 S 中的激活项和在生成图像𝐺的激

活项。我们之所以用大写字母𝐺来代表这些风格矩阵，是因为在线性代数中这种矩阵有时也 叫 Gram 矩阵，但在这里我只把它们叫做风格矩阵。

所以你要做的就是计算出这张图像的风格矩阵，以便能够测量出刚才所说的这些相关系 数。更正规地来表示，我们用𝑎 𝑖,𝑗,𝑘 [𝑙] 来记录相应位置的激活项，也就是𝑙层中的𝑖, 𝑗, 𝑘位置，所 以𝑖代表高度，𝑗代表宽度，𝑘代表着𝑙中的不同通道。之前说过，我们有 5 个通道，所以𝑘就代 表这五个不同的通道。

对于这个风格矩阵，你要做的就是计算这个矩阵也就是𝐺 [𝑙] 矩阵，它是个𝑛 𝑐 × 𝑛 𝑐 的矩阵，也就是一个方阵。记住，因为这里有𝑛 𝑐 个通道，所以矩阵的大小是𝑛 𝑐 × 𝑛 𝑐 。以便计算每一对

激活项的相关系数，所以𝐺 kk ′ [𝑙] 可以用来测量𝑘通道与𝑘′通道中的激活项之间的相关系数，𝑘和 𝑘′会在 1 到𝑛 𝑐 之间取值，𝑛 𝑐 就是𝑙层中通道的总数量。

当在计算𝐺 [𝑙] 时，我写下的这个符号（下标𝑘𝑘’）只代表一种元素，所以我要在右下角标

明是𝑘𝑘′元素，和之前一样𝑖，𝑗从一开始往上加，对应 (𝑖, 𝑗, 𝑘) 位置的激活项与对应 (𝑖, 𝑗, 𝑘′) 位置

的激活项相乘。记住，这个𝑖和𝑗是激活块中对应位置的坐标，也就是该激活项所在的高和宽，

所以𝑖会从 1 加到𝑛 𝐻 [𝑙] ，𝑗会从 1 加到𝑛 𝑊 [𝑙] ，𝑘和𝑘′则表示对应的通道，所以𝑘和𝑘′值的范围是从

1 开始到这个神经网络中该层的通道数量𝑛 𝐶 [𝑙] 。这个式子就是把图中各个高度和宽度的激活

515 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

项都遍历一遍，并将𝑘和𝑘′通道中对应位置的激活项都进行相乘，这就是𝐺 𝑘𝑘 ′ [𝑙] 的定义。通过对 𝑘和𝑘′通道中所有的数值进行计算就得到了𝐺矩阵，也就是风格矩阵。

[𝑙] [𝑙] 𝑛 𝐻 𝑛 𝑊 

𝐺 𝑘𝑘 ′ [𝑙] = ∑ ∑ 𝑎 𝑖, 𝑗, 𝑘 [𝑙] 𝑎𝑖, 𝑗, 𝑘 ′ [𝑙] 

𝑖=1 𝑗=1 

要注意，如果两个通道中的激活项数值都很大，那么𝐺 𝑘𝑘 ′ [𝑙] 也会变得很大，对应地，如果

他们不相关那么𝐺 𝑘𝑘 ′ [𝑙] 就会很小。严格来讲，我一直使用这个公式来表达直觉想法，但它其实 是一种非标准的互协方差，因为我们并没有减去均值而只是把这些元素直接相乘，这就是计 算图像风格的方法。

[𝑙] [𝑙] 𝑛 𝐻 𝑛 𝑊 

𝐺 𝑘𝑘 ′ [𝑙](𝑆) = ∑ ∑ 𝑎 𝑖, 𝑗, 𝑘 [𝑙](𝑆) 𝑎𝑖, 𝑗, 𝑘 ′ [𝑙](𝑆) 

𝑖=1 𝑗=1 

你要同时对风格图像𝑆和生成图像𝐺都进行这个运算，为了区分它们，我们在它的右上 角加一个 (𝑆)，表明它是风格图像𝑆，这些都是风格图像 S 中的激活项，之后你需要对生成图 像也做相同的运算。

[𝑙] [𝑙] 𝑛 𝐻 𝑛 𝑊 

𝐺 𝑘𝑘 ′ [𝑙](𝐺) = ∑ ∑ 𝑎 𝑖, 𝑗, 𝑘 [𝑙](𝐺) 𝑎𝑖, 𝑗, 𝑘 ′ [𝑙](𝐺) 

𝑖=1 𝑗=1 

和之前一样，再把公式都写一遍，把这些都加起来，为了区分它是生成图像，在这里放 一个 (𝐺)。

现在，我们有 2 个矩阵，分别从风格图像𝑆和生成图像𝐺。

再提醒一下，我们一直使用大写字母𝐺来表示矩阵，是因为在线性代数中，这种矩阵被 称为 Gram 矩阵，但在本视频中我把它叫做风格矩阵，我们取了 Gram 矩阵的首字母𝐺来表 示这些风格矩阵。（过程见下图）

516 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

最后，如果我们将𝑆和𝐺代入到风格代价函数中去计算，这将得到这两个矩阵之间的误 差，因为它们是矩阵，所以在这里加一个𝐹（Frobenius 范数，编号 1 所示），这实际上是计 算两个矩阵对应元素相减的平方的和，我们把这个式子展开，从𝑘和𝑘′开始作它们的差，把 对应的式子写下来，然后把得到的结果都加起来，作者在这里使用了一个归一化常数，也就 是 2𝑛 𝐻 [𝑙]𝑙 𝑛 𝑊 [𝑙] 𝑛 𝐶 [𝑙] 1 ，再在外面加一个平方，但是一般情况下你不用写这么多，一般我们只要将它乘

以一个超参数𝛽就行。

最后，这是对𝑙层定义的风格代价函数，和之前你见到的一样，这是两个矩阵间一个基 本的 Frobenius 范数，也就是𝑆图像和𝐺图像之间的范数再乘上一个归一化常数，不过这不是 很重要。实际上，如果你对各层都使用风格代价函数，会让结果变得更好。如果要对各层都 使用风格代价函数，你可以这么定义代价函数，把各个层的结果（各层的风格代价函数）都 加起来，这样就能定义它们全体了。我们还需要对每个层定义权重，也就是一些额外的超参

517 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

数，我们用𝜆 [𝑙] 来表示，这样将使你能够在神经网络中使用不同的层，包括之前的一些可以 测量类似边缘这样的低级特征的层，以及之后的一些能测量高级特征的层，使得我们的神经 网络在计算风格时能够同时考虑到这些低级和高级特征的相关系数。这样，在基础的训练中 你在定义超参数时，可以尽可能的得到更合理的选择。为了把这些东西封装起来，你现在可以定义一个全体代价函数：

𝐽(𝐺) = 𝑎𝐽 content(𝐶,𝐺) + 𝛽𝐽 𝑠𝑡𝑦𝑙𝑒 (𝑆, 𝐺) 

之后用梯度下降法，或者更复杂的优化算法来找到一个合适的图像𝐺，并计算𝐽(𝐺) 的最 小值，这样的话，你将能够得到非常好看的结果，你将能够得到非常漂亮的结果。

这节神经风格迁移的内容就讲到这里，希望你能愉快地在本周的基础训练中进行实践。在本周结束之前，还有最后一节内容想告诉你们，就是如何对 1D 和 3D 的数据进行卷积，之前我们处理的都是 2D 图片，我们下节视频再见。

518 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

4.11 一维到三维推广（1D and 3D generalizations of models）

你已经学习了许多关于卷积神经网络（ConvNets）的知识，从卷积神经网络框架，到如 何使用它进行图像识别、对象检测、人脸识别与神经网络转换。即使我们大部分讨论的图像 数据，某种意义上而言都是 2D 数据，考虑到图像如此普遍，许多你所掌握的思想不仅局限 于 2D 图像，甚至可以延伸至 1D，乃至 3D 数据。

让我们回头看看在第一周课程中你所学习关于 2D 卷积，你可能会输入一个 14×14 的图 像，并使用一个 5×5 的过滤器进行卷积，接下来你看到了 14×14 图像是如何与 5×5 的过滤 器进行卷积的，通过这个操作你会得到 10×10 的输出。

如果你使用了多通道，比如 14×14×3，那么相匹配的过滤器可能是 5×5×3，如果你使用 了多重过滤，比如 16，最终你得到的是 10×10×16。

事实证明早期想法也同样可以用于 1 维数据，举个例子，左边是一个 EKG 信号，或者 说是心电图，当你在你的胸部放置一个电极，电极透过胸部测量心跳带来的微弱电流，正因 为心脏跳动，产生的微弱电波能被一组电极测量，这就是人心跳产生的 EKG，每一个峰值都 对应着一次心跳。

519 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

如果你想使用 EKG 信号，比如医学诊断，那么你将处理 1 维数据，因为 EKG 数据是由 时间序列对应的每个瞬间的电压组成，这次不是一个 14×14 的尺寸输入，你可能只有一个 14 尺寸输入，在这种情况下你可能需要使用一个 1 维过滤进行卷积，你只需要一个 1×5 的 过滤器，而不是一个 5×5 的。

二维数据的卷积是将同一个 5×5 特征检测器应用于图像中不同的位置（编号 1 所示），你最后会得到 10×10 的输出结果。1 维过滤器可以取代你的 5 维过滤器（编号 2 所示），可 在不同的位置中应用类似的方法（编号 3，4，5 所示）。

当你对这个 1 维信号使用卷积，你将发现一个 14 维的数据与 5 维数据进行卷积，并产 生一个 10 维输出。

再一次如果你使用多通道，在这种场景下可能会获得一个 14×1 的通道。如果你使用一

520 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

个 EKG，就是 5×1 的，如果你有 16 个过滤器，可能你最后会获得一个 10×16 的数据，这可 能会是你卷积网络中的某一层。

对于卷积网络的下一层，如果输入一个 10×16 数据，你也可以使用一个 5 维过滤器进行 卷积，这需要 16 个通道进行匹配，如果你有 32 个过滤器，另一层的输出结果就是 6×32，如果你使用了 32 个过滤器的话。

对于 2D 数据而言，当你处理 10×10×16 的数据时也是类似的，你可以使用 5×5×16 进行 卷积，其中两个通道数 16 要相匹配，你将得到一个 6×6 的输出，如果你用的是 32 过滤器，输出结果就是 6×6×32，这也是 32 的来源。

所有这些方法也可以应用于 1 维数据，你可以在不同的位置使用相同的特征检测器，比 如说，为了区分 EKG 信号中的心跳的差异，你可以在不同的时间轴位置使用同样的特征来 检测心跳。

所以卷积网络同样可以被用于 1D 数据，对于许多 1 维数据应用，你实际上会使用递归 神经网络进行处理，这个网络你会在下一个课程中学到，但是有些人依旧愿意尝试使用卷积 网络解决这些问题。

下一门课将讨论序列模型，包括递归神经网络、LCM 与其他类似模型。我们将探讨使用 1D 卷积网络的优缺点，对比于其它专门为序列数据而精心设计的模型。

这也是 2D 向 1D 的进化，对于 3D 数据来说如何呢？什么是 3D 数据？与 1D 数列或数 字矩阵不同，你现在有了一个 3D 块，一个 3D 输入数据。以你做 CT 扫描为例，这是一种使 用 X 光照射，然后输出身体的 3D 模型，CT 扫描实现的是它可以获取你身体不同片段（图片

521 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

信息）。

当你进行 CT 扫描时，与我现在做的事情一样，你可以看到人体躯干的不同切片（整理 者注：图中所示为人体躯干中不同层的切片，附 CT 扫描示意图，图片源于互联网），本质 上这个数据是 3 维的。

一种对这份数据的理解方式是，假设你的数据现在具备一定长度、宽度与高度，其中每 一个切片都与躯干的切片对应。

如果你想要在 3D 扫描或 CT 扫描中应用卷积网络进行特征识别，你也可以从第一张幻 灯片（Convolutions in 2D and 1D）里得到想法，并将其应用到 3D 卷积中。为了简单起见，如果你有一个 3D 对象，比如说是 14×14×14，这也是输入 CT 扫描的宽度与深度（后两个 14）。再次提醒，正如图像不是必须以矩形呈现，3D 对象也不是一定是一个完美立方体，所以长 和宽可以不一样，同样 CT 扫描结果的长宽高也可以是不一致的。为了简化讨论，我仅使用 14×14×14 为例。

522 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

如果你现在使用 5×5×5 过滤器进行卷积，你的过滤器现在也是 3D 的，这将会给你一个 10×10×10 的结果输出，技术上来说你也可以再 ×1（编号 1 所示），如果这有一个 1 的通道。这仅仅是一个 3D 模块，但是你的数据可以有不同数目的通道，那种情况下也是乘 1（编号 2 所示），因为通道的数目必须与过滤器匹配。如果你使用 16 过滤器处理 5×5×5×1，接下来 的输出将是 10×10×10×16，这将成为你 3D 数据卷积网络上的一层。

如果下一层卷积使用 5×5×5×16 维度的过滤器再次卷积，通道数目也与往常一样匹配，如果你有 32 个过滤器，操作也与之前相同，最终你得到一个 6×6×6×32 的输出。

某种程度上 3D 数据也可以使用 3D 卷积网络学习，这些过滤器实现的功能正是通过你 的 3D 数据进行特征检测。CT 医疗扫描是 3D 数据的一个实例，另一个数据处理的例子是你 可以将电影中随时间变化的不同视频切片看作是 3D 数据，你可以将这个技术用于检测动作 及人物行为。

总而言之这就是 1D、2D 及 3D 数据处理，图像数据无处不在，以至于大多数卷积网络 都是基于图像上的 2D 数据，但我希望其他模型同样会对你有帮助。

这是本周最后一次视频，也是最后一次关于卷积神经网络的课程，你已经学习了许多关 于卷积网络的知识，我希望你能够在未来工作中发现许多思想对你有所裨益，祝贺你完成了 这些视频学习，我希望你能喜欢这周的课后练习，接下来关于顺序模型的课程我们不见不散。

523 

第四门课 卷积神经网络（Convolutional Neural Networks）- 第四周 特殊应用：人脸识别和神经风格转换 （Special applications: Face recognition &Neural style transfer）

参考文献：

• Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). FaceNet: A Unified Embedding for Face Recognition and Clustering 

• Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). DeepFace: Closing the gap to human-level performance in face verification 

• The pretrained model we use is inspired by Victor Sy Wang's implementation and was loaded using his code: https://github.com/iwantooxxoox/Keras-OpenFace. 

• Our implementation also took a lot of inspiration from the official FaceNet github repository: https://github.com/davidsandberg/facenet 

• Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style (https://arxiv.org/abs/1508.06576) 

• Harish Narayanan, Convolutional neural networks for artistic style transfer. 

https://harishnarayanan.org/writing/artistic-style-transfer/ 

• Log0, TensorFlow Implementation of "A Neural Algorithm of Artistic Style". 

http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style 

• Karen Simonyan and Andrew Zisserman (2015). Very deep convolutional networks for largescale image recognition (https://arxiv.org/pdf/1409.1556.pdf) 

• MatConvNet. http://www.vlfeat.org/matconvnet/pretrained/ 

524 

第五门课 序列模型 (Sequence Models)- 第一周 循环序列模型（Recurrent Neural Networks）

第五门课 序列模型 (Sequence Models)

第一周 循环序列模型（Recurrent Neural Networks）

