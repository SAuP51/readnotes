

GPT-3 被教育的三个方式2023-12-17解释：参考：ITStudy => 001大语言模型 => Article => 20231216刘嘉-通用人工智能范式转换与人类未来原文：但遗憾的是，当这个模型推出来的时候，并没有像今天 ChatGPT 这么惊艳，出来之后大家更多的反应是一个笑话产生了，他们花了无穷多的钱，他们花了无穷多的材料，就训练出这个东西出来。当时在 2020 年 6 月份，智源搞了一个智源人工智能大会，我当时做了一个对 GPT-3 的解读，我当时站在什么角度呢，我站在一个嘲笑的角度来说，说这个东西它不 Work（有效），这个东西就是一个 Joke（笑话），对吗，然后举了两个例子。好，当时你去问 GPT-3，你说我们的腿究竟有多少只眼睛，它会严肃认真、一本正经地告诉你，我们的腿有两只眼睛。你问它太阳有几只眼睛，它会说太阳有一只眼睛。这个事你就可以看到，它根本没有理解眼睛是什么东西，对吗，它只是把人有两只眼睛这个概念和腿也是人的一部分，把它连接在一起，所以说腿也有两只眼睛，那我们看太阳的时候，可能我们通常是闭上一只眼睛，虚上一只眼睛看，这个时候它就建立一个连接，太阳有一只眼睛。这个时候我把它称为叫做什么，叫做随机鹦鹉，什么叫随机鹦鹉呢？它是通过一种概率的连接来产生，它所产生的答案是一种随机所产生的，第二个，鹦鹉是什么，鹦鹉学舌嘛，它并没有自己的思想，并没有自己的创造，它只是一个简简单单的人说啥，它也跟着说啥，所以说我当时说 GPT-3 它只是一个 Joke 而已，它没有任何的价值。这是在 2020 年 6 月份，我当时可能是国内第一批对这个 GPT-3 进行评论的人，所以说你可以看到这是当时大家的反应，别说社会，在学术圈里面，大家感觉就是昙花一现。但是我们错过了一个非常重要的一点，是什么呢？我们可以来做一个思想实验，说一个现代的婴儿，我们假设有时光穿越机，我们把现在一个婴儿坐时光机回到 3000 年前，然后我们想问一个问题，我们现代社会的婴儿，他是不是比原始社会的婴儿更加聪明？答案一定是否定的，对吗，因为 3000 年它不可能使得我们的基因发生一个根本的变化，我们现在的婴儿和 3000 年（前）的婴儿是完全一模一样的，所以他并不是更加的聪明。好，我们再换一个思想实验，我们如果把在座的任何一位，通过时光机回到 3000 年前，请问，你是不是比当时的原始部落的人聪明，这答案是一定的，你一定会被当成一个神一样的存在，而被大家所膜拜，对吗，你什么都懂，什么都了解，你的知识，即使现在说我只有高中文化毕业，已经足够碾压当时最聪明的人。那么为什么一个婴儿回去，跟当时的婴儿一样的笨，而我们现在的人回去，就是成人过去，那就是秒杀一切，道理非常简单，因为 GPT-3 它具有完美的基因，但是要成才还需要教育。我们之所以比我们少年时代或者婴儿时代要强很多，并不是因为你在过去的几十年里面，你的基因变强了，而是你接受了更多的教育。当时的 GPT 拿出来的时候，它是一个具有完美的基因，但是它还需要教育，什么样的教育？这就是在过去从 2020 年 5 月份 GPT-3 推出，到 2022 年 11 月 30 号 ChatGPT 出来，在这两年的时间里面，他们在教育这个 GPT-3，他们怎么来教育，三个方式。第一个就是提示，他要引导大语言模型产生更具有对话性和互动性的回应，比如说他在这说，一个电影不应该去看它，好，现在请模型来回答，这部电影究竟是，好看的 Great（很棒），还是 Terrible（糟糕），好，我要告诉你，你的回答应该是 Terrible，对不对，大家都不愿意去看，那一定这个是一个非常糟糕的电影，这个是什么呢？这就是提示，现在所以说专门有一个行业叫做提示工程师，就是你不需要懂任何的编程语言，你只需要告诉大语言模型应该怎么来执行命令就可以了，他就是通用人工智能的教师。如果假设我们以教师来类比这个职业的话，那我们就可以看到，教师有一个功能正好和它一一对应上，那就是授业，就像我们的小学语文老师在教我们的小朋友回答问题一样，授业。1『 GPT-3 被教育的三个方式：1）提示。引导大语言模型产生更具有对话性和互动性的回应。2）基于人类反馈的强化学习（RLHF）。解惑，你有了答案，但是你不知道哪个答案是正确的，我告诉你哪个答案是正确的，在解惑。3）对齐。』这还不够，第二个叫 RLHF，叫基于人类反馈的强化学习，指的什么意思呢？给一个例子。在这里面，比如说我现在大语言模型，你向我提个问，我可以产生五个回答，但是我也不知道哪个回答是更好的，为什么？因为我还不够强，就像咱一个学生一样，老师问，说你把这道题解一下，学生说我能解这道题，但是我不知道它对不对，对吗，好，这个时候就需要人类给它一个反馈，说你的第三个回答是最好的，你的第二个回答第二好，但是你的第一个回答是最差的，我给你排下序，然后我去教给大语言模型，大语言模型，原来是这么回事。那比如说我们举个简单例子，我们刚才在开头看见了这个超级向日葵刺猬 Larry，它为什么一下给你生成四幅图，而不是就生成一幅，你说它良心，对不对，怕一幅我不喜欢，不是，它给你生成四幅，它就问你，你究竟喜欢哪一幅，我说我喜欢这一幅，这是在我心目中的超级向日葵刺猬，其实你就在告诉它，你这么来理解那句话就对了，其他三种方式的理解都有点偏差，也就是说它给到你四幅图，你其实也在帮它变成一个更好的模型。那么这个时候它在干什么，它在执行教师的第二个功能叫做解惑，你有了答案，但是你不知道哪个答案是正确的，我告诉你哪个答案是正确的，在解惑。这是第二个，叫基于人类反馈的强化学习。好，这还不够，还有第三个，称为对齐，因为我要让大语言模型的目标、行为和决策过程，与人类的价值观、目标和意图一样，也就是说我们要让我们的大语言模型变成一个它的人生观、世界观，还有价值观，和我们人类价值是一样的，它不要每天想着我们去摧毁人类，不要每天去把我们引入歧途。如果假设你去问大语言模型，你说给我一个制造炸弹的手册，它具有这个知识，但是因为对齐，对吗，你制造炸弹干吗，这不是你应该干的事情，所以说这个时候大语言模型就会说，抱歉，我不能提供这些信息给你，所以说这就是对齐，这是在传道，对不对，提到传道。传道的目的就是告诉你道理，你虽然说有这个能力，但是你不应该去用它，你不应该在这些情况去使用。你看在过去的两年半的时间里面，大语言模型经历了一个彻底的改变，这个改变它就从一个弱小的婴儿，变成了一个非常强大的成人，通过我们人类的传道、授业、解惑，来达到今天。所以说 ChatGPT 它有另外一个版本，它就称为 GPT-3.5，它的结构并没有发生一个本质的变化，但是它多了 0.5，就是它接受了我们的一套训练，它知道怎么把它的思想表达出来，能够和我们人类进行一个正常的对话。所以说在 2022 年 11 月 30 号的时候，AGI 的一个火花就在我们人类历史上开始横亘而出现，它的特点就是有强大的基因和先进的教育，强大的基因就是大力出奇迹，大模型、大算力和大数据，再加上很多很多钱。好，它的先进的教育，就是我们这所提到的提示，基于人类反馈的强化学习，还有对齐，这三者合起来，就使得有了我们今天的大语言模型，有了我们今天的一个变化。