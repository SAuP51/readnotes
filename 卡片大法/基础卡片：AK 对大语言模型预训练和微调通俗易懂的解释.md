

基础卡片：AK 对大语言模型预训练和微调通俗易懂的解释2024-04-09原文：简单来说，预训练阶段是在大量互联网数据上进行训练，主要目的是知识积累。而微调阶段则专注于对齐和调整，把模型的输出从普通的互联网文本转变为更具针对性、更像助手的问答格式。评论：。参考：ITstudy => 001 大语言模型 => 13Article-LLM => 20240408为忙碌人士准备的大语言模型速览原文：在我们深入了解神经网络的过程中，我们大多关注它们在互联网文档生成方面的作用。但其实，这些模型的能力远不止于此。现在，我们正步入训练的关键第二阶段 —— 精调，这一阶段将把这些网络从简单的内容生成器转变成更具实用性的 AI 助手。目前为止，我们观察到神经网络能够生成类似互联网上的文本内容，这被称为预训练阶段。但对于许多任务来说，仅仅生成文本是远远不够的。更有价值的是，能够回答问题并基于这些问题提供信息的 AI 助手模型。开发这类 AI 助手的过程非常有趣。优化过程依然聚焦于下一个单词预测任务，但数据集发生了变化。与其在海量的互联网文档上进行训练，不如转向更为专门且手动收集的数据集。那么，这些新训练集是如何构建的呢？这需要很多人的参与。通常，公司会组建专门团队来整理这些数据集。这些团队按照详细的标注指引工作，负责提出问题并设计合适的答案。比如，训练数据可能是这样的：一个用户问，「能否写一段关于经济学中‘垄断性买方市场'重要性的简介？」然后，根据标注指引，有人会编写 AI 助手应给出的理想答案。这些答案的性质和质量都受到了像 OpenAI 或 Anthropic 这样的公司工程师提供的详细指导文件的影响。图片：~100,000 条由人工编写的对话，用于对模型进行精调如果说预训练阶段是处理大量互联网上参差不齐的文本，那么精调阶段则更注重质量而非数量。在这里，我们可能只关注少量的文档 —— 比如说 100,000 条 —— 但每一条都是精心制作的高质量对话，严格遵循标注指引。这一阶段对于将神经网络从泛泛的文档生成器转化为能够精确理解和回应特定问题的专业 AI 助手来说，至关重要。从文档生成器到 AI 助手的转变在神经网络向 AI 助手演变的过程中，微调 (fine-tuning) 是一个关键步骤。这个步骤的核心是改变训练数据集的内容。我们不再使用预训练 (pre-training) 阶段的普通互联网文本，而是转向专注于问答 (Q&A) 文档。正是这种训练材料的改变，让我们得以构建所谓的助手模型。在微调过程中，神经网络学习如何适应这些新的训练文档格式。比如，当你问：「能帮我看看这段代码吗？似乎有个 bug：print("Hello World)"，微调后的模型会理解它应当以一个助手的身份提供帮助。这种能力非常惊人，尤其是当这个具体问题可能并未出现在其训练集中时。模型能够逐字逐句地生成回答，制造出与问题相匹配的答复。这些模型如何能够从制造普通互联网内容转变为一个有帮助的助手，这一点仍然充满神奇。它们通过在微调阶段吸收问答文档的风格和结构来实现这种转变。更令人印象深刻的是，它们依然保持并运用了在预训练阶段积累的丰富知识。简单来说，预训练阶段是在大量互联网数据上进行训练，主要目的是知识积累。而微调阶段则专注于对齐和调整，把模型的输出从普通的互联网文本转变为更具针对性、更像助手的问答格式。总结来说，打造像 ChatGPT 这样的产品，包含了两个关键阶段。首先是预训练阶段，这时网络被大量互联网文本所充斥。此过程需要用到 GPU 集群，这些专业计算机专为并行处理任务而设计。它们远非日常电脑，而是价格高昂的高端设备。在此阶段，互联网文本被压缩进神经网络的参数中，通常耗资上百万美元。这样，我们就得到了基础模型，一个计算成本极高的过程，通常由公司每年甚至更少频率进行，主要因为涉及的成本。基础模型开发完毕后，接下来是精调阶段，这个阶段的计算需求相对较低。重点转向如何定义 AI 助理的行为。这包括编写具体的标注指令，并雇用人员制作符合这些指令的文档。例如，可能需要收集 10 万条高质量的理想问答，用于对基础模型进行精调。这个过程不仅成本更低，而且速度更快 —— 可能只需一天，而预训练阶段则需几个月。其成果是一款高效的助理模型。一旦助理模型准备就绪，它就会经历评估、部署和持续监控。针对每一次不当行为，都会采取相应的纠正措施。这一过程包括对助理给出错误回应的对话进行改写，以正确的回应取代。这些改正后的回应随后纳入训练数据，使得下一轮精调时，模型能在这些特定场景下得到改善。由于精调成本较低，它让公司能够更频繁地迭代更新，使 AI 模型相较于预训练阶段能够更加规律地得到优化。值得一提的是 Meta 在其 Llama 2 系列中采取的策略。Meta 发布此系列时，不仅包含了基础模型，还有可直接用于问答应用的助理模型。尽管基础模型不适合直接回答问题（它们更多生成问题或无关内容，因为本质上是互联网文档采样器），但它们仍具有重要价值。Meta 承担了开发过程中成本高昂、资源密集的第一阶段，为其他人提供了坚实的基础，进一步精调提供了广阔的自由度。此外，Meta 还发布了可立即用于问答应用的助理模型。这一不断进步的迭代过程以及微调模型的能力，极大地提高了发展 AI 助手的灵活性和效率。公司通过定期更新和精细化这些模型，可以持续提高 AI 的性能，使其在交互中更加迅速、精准。