

术语卡片：大模型的量化2023-12-21解释：参考：selfstudy => 003Paper => 2023046A-Survey-of-Large-Language-Models原文：In this part, we present a general introduction of quantization techniques for neural networks.In neural network compression, quantization often refers to the mapping process from floating-point numbers to integers [412], especially the 8-bit integer quantization (i.e., INT8 quantization). For neural network models, there are typically two kinds of data to be quantized, namely weights (model parameters) and activations (hidden activations), which are originally represented in floating-point numbers. To illustrate the essential idea of model quantization, we introduce a simple yet popular quantization function: x q = R(x/S)−Z , which transforms a floating number x into a quantized value x q . In this function, S and Z denote the scaling factor (involving two parameters α and β that determine the clipping range) and zero-point factor (determining symmetric or asymmetric quantization), respectively, and R(·) denotes the rounding operation that maps a scaled floating value to an approximate integer.As the reverse process, dequantization recovers the original value from the quantized value accordingly: ˜x = S · (x q + Z). The quantization error is calculated as the numerical difference between the original value x and the recovered value ˜x. The range parameters α and β have a large impact on the quantization performance, which often need to be calibrated according to real data distributions, in either a static (offline) or dynamic way (runtime).For more details, we refer to the readers to the excellent survey [412] about quantization methods on neural networks.在这部分内容中，我们将对神经网络的量化技术进行概述性介绍。这种技术旨在通过减少模型的数据表示精度，来降低模型的内存占用和加快计算速度，从而使模型在资源受限的环境中更加高效地运行。在神经网络压缩领域，量化通常指的是将浮点数映射为整数的过程 [412]，特别是 8 位整数量化（即 INT8 量化）。在神经网络模型中，需要量化的数据通常包括权重（模型参数）和激活（隐藏激活），它们原本以浮点数形式表示。为了说明模型量化的核心思想，我们引入了一个简单但广泛使用的量化函数：xq=R(x/S)−Z，它将浮点数 x 转换为量化值 xq 。在该函数中，S 和 Z 分别代表缩放因子（涉及 α 和 β 两个参数，决定剪切范围）和零点因子（决定量化是对称还是非对称），R (·) 表示将缩放后的浮点值映射为近似整数的舍入操作。作为反向过程，反量化从量化值恢复原始值：˜x=S·(xq+Z)。量化误差是指原始值 x 与恢复值 ˜x 之间的数值差。范围参数 α 和 β 对量化性能有显著影响，通常需要根据实际数据分布进行静态（离线）或动态（运行时）校准。更多细节，请参考关于神经网络量化方法的详尽综述[412]。