

基础卡片：GPT-3 的神经网络层级以及向量的维度2023-11-23已知：一个 3x2 的矩阵，列向量是三维了，那么其线性组合应该也是三维的新知：一个 3x2 的矩阵只能描述一个二维空间解释：参考：ITStduy => 001大语言模型 => Article => 20231121Understanding-AI原文：Each layer of an LLM is a transformer, a neural network architecture that was first introduced by Google in a landmark 2017 paper.The model’s input, shown at the bottom of the diagram, is the partial sentence “John wants his bank to cash the.” These words, represented as word2vec-style vectors, are fed into the first transformer.The transformer figures out that wants and cash are both verbs (both words can also be nouns). We’ve represented this added context as red text in parentheses, but in reality the model would store it by modifying the word vectors in ways that are difficult for humans to interpret. These new vectors, known as a hidden state, are passed to the next transformer in the stack.The second transformer adds two other bits of context: it clarifies that bank refers to a financial institution rather than a river bank, and that his is a pronoun that refers to John. The second transformer produces another set of hidden state vectors that reflect everything the model has learned up to that point.The above diagram depicts a purely hypothetical LLM, so don’t take the details too seriously. We’ll take a look at research into real language models shortly. Real LLMs tend to have a lot more than two layers. The most powerful version of GPT-3, for example, has 96 layers.Research suggests that the first few layers focus on understanding the syntax of the sentence and resolving ambiguities like we’ve shown above. Later layers (which we’re not showing to keep the diagram a manageable size) work to develop a high-level understanding of the passage as a whole.For example, as an LLM “reads through” a short story, it appears to keep track of a variety of information about the story’s characters: sex and age, relationships with other characters, past and current location, personalities and goals, and so forth.Researchers don’t understand exactly how LLMs keep track of this information, but logically speaking the model must be doing it by modifying the hidden state vectors as they get passed from one layer to the next. It helps that in modern LLMs, these vectors are extremely large.For example, the most powerful version of GPT-3 uses word vectors with 12,288 dimensions—that is, each word is represented by a list of 12,288 numbers. That’s 20 times larger than Google’s 2013 word2vec scheme. You can think of all those extra dimensions as a kind of “scratch space” that GPT-3 can use to write notes to itself about the context of each word. Notes made by earlier layers can be read and modified by later layers, allowing the model to gradually sharpen its understanding of the passage as a whole.So suppose we changed our diagram above to depict a 96-layer language model interpreting a 1,000-word story. The 60th layer might include a vector for John with a parenthetical comment like “(main character, male, married to Cheryl, cousin of Donald, from Minnesota, currently in Boise, trying to find his missing wallet).” Again, all of these facts (and probably a lot more) would somehow be encoded as a list of 12,288 numbers corresponding to the word John. Or perhaps some of this information might be encoded in the 12,288-dimensional vectors for Cheryl, Donald, Boise, wallet, or other words in the story.The goal is for the 96th and final layer of the network to output a hidden state for the final word that includes all of the information necessary to predict the next word.LLM 的每一层都是一个变换器，这是一种神经网络架构，最初由谷歌在 2017 年的一篇里程碑式论文中引入。模型的输入，如图底部所示，是部分句子「John wants his bank to cash the。」这些单词以 word2vec 风格的向量表示，被送入第一个变换器。变换器确定 wants 和 cash 都是动词（这两个词也可以是名词）。我们用括号中的红色文本表示这些添加的上下文，但实际上模型会通过修改词向量的方式来存储它，这些修改方式对人类来说难以解释。这些新向量，被称为隐藏状态，传递给堆栈中的下一个变换器。第二个变换器添加了另外两个上下文信息：它澄清了 bank 指的是金融机构而不是河岸，以及 his 是指代 John 的代词。第二个变换器产生了另一组反映模型到目前为止所学内容的隐藏状态向量。上面的图表描述了一个纯粹假设的 LLM，所以不要太认真对待细节。我们将很快看看关于真实语言模型的研究。真正的 LLMs 往往有两层以上。例如，GPT-3 最强大的版本有 96 层。研究表明，前几层专注于理解句子的语法和解决我们上面展示的歧义。后面的层次（我们没有展示以保持图表的可管理大小）则致力于对整个段落进行高层次的理解。例如，当 LLM「阅读」一篇短篇小说时，它似乎会跟踪关于故事角色的各种信息：性别和年龄、与其他角色的关系、过去和当前位置、个性和目标等等。研究人员并不完全明白 LLMs 是如何跟踪这些信息的，但从逻辑上讲，模型必须是通过在从一层传递到下一层的过程中修改隐藏状态向量来实现的。在现代 LLMs 中，这些向量极其庞大，这一点是有帮助的。例如，GPT-3 最强大的版本使用具有 12,288 维的词向量 —— 也就是说，每个单词由一个包含 12,288 个数字的列表表示。这比谷歌 2013 年的 word2vec 方案大 20 倍。你可以将所有这些额外的维度视为一种「划痕空间」，GPT-3 可以用它来记录关于每个词的上下文的笔记。前面层次做的笔记可以被后面的层次读取和修改，使得模型能逐渐加深对整个段落的理解。所以假设我们改变上面的图表，描绘一个解释 1000 字故事的 96 层语言模型。第 60 层可能包括一个关于 John 的向量，附有类似（主角，男性，与 Cheryl 结婚，Donald 的表亲，来自明尼苏达，目前在博伊西，正在寻找他的遗失钱包）的括号内注释。再次强调，所有这些事实（可能还有更多）将以与单词 John 相对应的 12,288 个数字的列表的形式进行编码。或许，其中一些信息可能会编码在故事中的 Cheryl、Donald、Boise、wallet 或其他单词的 12,288 维向量中。目标是网络的第 96 层和最后一层输出最后一个单词的隐藏状态，其中包含预测下一个单词所需的所有信息。