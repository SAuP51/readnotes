

术语卡片：模型误差分解定理2024-01-15定义：参考：斯科特·佩奇.(2019).模型思维.(贾拥民译).浙江人民出版社 => 0301. 多模型思维原文：Pxx模型的另外 3 种用途 —— 预测、设计和行动，却可以因高保真模型而受益。因此，如果有大数据，那么就应该利用它。根据经验，我们拥有的数据越多，模型就越精细。这一点可以通过用来梳理思维的分类模型来说明。假设我们想构建一个模型来解释数据集中的变化。为了给问题提供一个背景，不妨再假设我们从很多杂货店获取了大量数据，详细列出了数百万家庭每个月的食品支出。这些家庭的消费金额不同，我们用变差（variation）来衡量这种变化，也就是每个家庭的支出与所有家庭的平均支出之间的差的平方和。如果每个月的平均支出是 500 美元，而某个特定家庭每个月的支出为 520 美元，那么这个家庭对总变差（total variation）的「贡献」就是 400（202）。统计学家把一个模型中能够解释的变差比例称为该模型的 R2。如果数据的总变差为 10 亿，而模型解释了其中的 8 亿，那么这个模型的 R2 是 0.8。解释的变差比例对应于模型在平均估计上的改进程度。如果某个模型估计某家庭每个月的支出为 600 美元，而且这个家庭的实际支出确实为每个月 600 美元，那么这个模型就解释了该家庭对总变差的全部贡献。如果家庭支出为 800 美元，但是模型的预测是 700 美元，那么对总变差的贡献就从原来的 9 万［(800-500)2］，变成了 1 万［(800-700)^2］。从而模型解释了 8/9 的变差。R^2：解释变差的百分比其中，V(x) 等于 X 中的 x 的值，xx 等于平均值，M(x) 等于模型的估值。在这种情况下，分类模型将家庭划分为不同类别，并估计了每个类别的值。更精细的模型会创建更多的类别，而要创建这些类别就需要更多的家庭属性。如果加入了更多的类别，可以解释的变差比例就会更大。如果我们像博尔赫斯所说的那些制图师一样思考，将每个家庭都分为一类，我们就可以解释所有的变差。但是，这种解释，就像比例为 1:1 的地图一样，没有多大用处。创造过多的类别会导致对数据的过度拟合，而过度拟合会破坏对未来事件的预测。假设我们想利用上个月的食品采购数据来预测本月的数据，而家庭每月的支出是会有变化的。如果一个模型将每个家庭都分为一类，那么就可以预测家庭的支出与上个月相同。由于存在月度波动，这个模型并不是一个好的预测器。通过将某个家庭与其他类似的家庭归入同一个类别中，我们可以通过对类似家庭在食品上的平均支出来构建一个更准确的预测器。为此，我们假设每个家庭的月支出是从某个分布中抽取出来的（我们将在第 5 章详细讨论各种分布），再假设分布的均值和方差已知。创建分类模型的目的是根据属性构建类别，使同一类别中的家庭具有类似的均值。如果能做到这一点，那么某个家庭在第一个月内的消费就能够告诉我们其他家庭在第二个月的支出大概是多少。当然，没有任何一种分类方法是完美的。在每个类别中，家庭的均值可能会略有不同，我们称这种情况称为分类误差（categorization error）。构建的类别越大，分类误差就越大，因为类别越大，我们就越可能将具有不同均值的家庭集中到同一个类别中。但是，更大的类别依赖更多的数据，又可以使我们对每个类别均值的估计更加准确（参见第 5 章中讨论的平方根规则）。因估计均值错误而出现的误差称为估值误差（valuation error）。估值误差随类别数量的增加而减少。如果不同家庭的月支出不同，那么包含一个家庭的类别（甚至包含 10 个家庭的类别也一样）将无法准确估计均值，但包含 1 000 个家庭的类别则能够准确地估计均值。现在，我们已经得到了关键的直觉：增加类别的数量能够通过将具有不同均值的家庭归入同一个类别减少分类误差。统计学家将这种情况称为模型偏差（model bias）。但是同时，构建更多类别则会增加对每个类别均值估计的误差，统计学家将这种情况称为均值方差的增加。因此，我们在决定要构建许多个类别时就面临着一个权衡。对于这种权衡，我们将它总结为模型误差分解定理（model error decomposition theorem），统计学家则将这个结果称为偏差-方差权衡（bias-variance trade-off）。模型误差分解定理偏差-方差权衡模型误差 = 分类误差 + 估值误差其中，M(x) 和 Mi 分别表示数据点 x 和类别 Si 和 V(x) 的模型值，Vi 表示它们的实际值。[6]