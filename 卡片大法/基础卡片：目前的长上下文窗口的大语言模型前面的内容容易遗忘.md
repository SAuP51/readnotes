

基础卡片：目前的长上下文窗口的大语言模型前面的内容容易遗忘2024-05-01原文：。评论：。参考：ITstudy => 001 大语言模型 => 13Article-LLM => 20240501RAG在长上下文大语言模型中的应用探讨原文：这里面的推理挑战很简单，只需要返回每个成分的首字母。基本上涉及到两个问题：随着「针」数量的增加，检索出的「针」的比例会下降。这是直观可理解的。事实越多，性能越差；如果进行推理，情况则更糟。比如，如果指令是仅返回「针」，效果会比同时要求返回「针」的首字母要好。这就是所谓的推理叠加。这是我们的初步观察结果。更多的事实和推理任务，都比简单的检索要困难。接下来的问题是，那些我们没能检索到的「针」具体遗漏在哪里？例如，我们知道检索 10 个「针」的成功率约为 60%。那些遗漏的「针」具体在哪里？从右侧的结果可以看到，这些「针」分布在文档的哪些部分。当上下文长度为 1000 个词符时，你可以找到所有的「针」。然而，实际上我要关注的是 120000 个词符的情况。较小的上下文有助于更好的检索。随着上下文窗口的扩大，文档开始部分的「针」检索失败的情况有所增加，这一点从图中的红色区域可见。这是一个引人注目的发现，并且与 Greg 在单一「针」实验中的观察相符。这表明，如果你阅读了一本书后被问到关于第一章的问题，可能会记得不太清楚。相似的情况也出现在这里，文档前端的「针」似乎容易被忘记，或者检索不够精确。这是我们在使用 GPT-4 时观察到的一个现象，已经多次被验证。我这里进行了九次实验，Greg 在他的实验中也有相似的发现。这看起来是一个非常稳定的结果。