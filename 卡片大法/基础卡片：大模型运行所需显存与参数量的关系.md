

基础卡片：大模型运行所需显存与参数量的关系2023-12-13解释：参考：ITStduy => 001大语言模型 => Article => 20231101从大模型角度看苹果M3系列芯片/20231213大语言模型LLM推理及训练显存计算方法原文：信息源1：20231101从大模型角度看苹果M3系列芯片拿 LLaMA-65B 来说，它有 650 亿参数，显存需求是 130 GB，这还真就能直接装得下。在大模型越来越流行的今天，苹果的这套架构就非常具有想象空间了。信息源2：20231213大语言模型LLM推理及训练显存计算方法全精度乘以 4，半精度16bit 的乘以 2，INT8 的乘以 1，INT4 的乘以 0.5。7B 参数的 4 种常见类型所需推理显存计算如下：float 7 * 4 = 28 GBhalf / BF16 7 * 2 = 14 GBint8 7 * 1 = 7 GBint4 7 * 0.5 = 3.5 GBphi-2微软的这个 20 亿参数的大模型，理论上全精度跑 8G 显存（或内存）就够了，半精度16bit 的跑 4G 显存。