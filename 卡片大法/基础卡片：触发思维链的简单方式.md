

基础卡片：触发思维链的简单方式2023-12-24解释：让我们一步一步地思；深呼吸，逐步解决这个问题。参考：selfstudy => 003Paper => 2023046A-Survey-of-Large-Language-Models原文：6.3.1 Basic CoT Prompting ApproachCoT prompting is first proposed as an extension of ICL [33], which augments each demonstration ⟨ input, output ⟩ as ⟨ input, CoT, output ⟩ . A CoT is a series of intermediate reasoning steps for connecting the input and output. With these augmented demonstrations, LLMs can follow them to generate CoTs and the answer for a new input. However, unlike ⟨ input, output ⟩ pairs in ICL, CoTs are difficult to obtain and usually require human annotation. Fortunately, it has been found that LLMs can be triggered to generate CoTs through simple instructions like “Let’s think step by step.” [505], making CoT prompting easy to use. There are also alternative magic prompts that can elicit the ability of CoT reasoning and further improve the performance of LLMs, such as “Take a deep breath and work on this problem step-by-step.” [473].As illustrated in Figure 15, the generation process of CoT follows a chain structure in the basic CoT prompting approach, where LLMs generate CoTs step by step. Typically, CoT takes the format of natural language text. However, textual CoTs may not work well on complex tasks that require rigorous logic for reasoning. Considering this, some work uses code [506, 507] due to its structured and precise nature. Furthermore, the authors in [508] propose to dynamically select text or code as the format of CoTs to combine their advantages.Fig. 15: An illustration of the evolution of CoT prompting strategies. It begins with the basic CoT approach and progresses to enhanced CoT generation techniques, including sampling-based and verification-based methods. Finally, it extends to variations of the chain structure, such as trees and graphs. Here, “thought” refers to an intermediate reasoning step as stated in [33, 451].6.3.1 基本 CoT 提示方法CoT 提示最初作为 ICL 的扩展而提出 [33]，它将每个演示（输入，输出）增强为（输入，CoT, 输出）。CoT 是连接输入和输出的一系列中间推理步骤。有了这些增强的演示，LLMs 可以遵循它们来为新输入生成 CoTs 和答案。然而，与 ICL 中的（输入，输出）对不同，CoTs 通常难以获得，一般需要人工注释。幸运的是，已发现 LLMs 可以通过如「让我们一步一步地思考」[505] 这样的简单指令来触发生成 CoTs，使 CoT 提示变得易于使用。还有其他「神奇提示」，如「深呼吸，逐步解决这个问题」[473]，可以激发 CoT 推理能力并进一步提高 LLMs 的表现。如图 15 所示，在基本 CoT 提示方法中，CoT 的生成过程遵循链式结构，LLMs 逐步生成 CoTs。通常，CoT 采用自然语言文本的格式。然而，文本形式的 CoTs 可能在需要严谨逻辑推理的复杂任务上不太有效。因此，一些研究选择使用代码 [506, 507] 作为 CoTs 的格式，由于其结构化和精确性。此外，[508] 中的作者提出动态选择文本或代码作为 CoTs 的格式，以结合它们的优点。图 15：CoT 提示策略演变的示意图。它从基本的 CoT 方法开始，发展到增强的 CoT 生成技术，包括基于抽样和验证的方法。最终，它扩展到链结构的变种，如树和图形结构。这里，「思维」指的是[33, 451]中所述的中间推理步骤。