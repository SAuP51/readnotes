

基础卡片：神经网络的不可解释性2023-11-27解释：参考：ITStduy => 001大语言模型 => Article => 20231124对话图灵奖得主希发基思原文：这里有很多问题，包括系统工程的问题。仅仅拥有一个超级智能代理是不够的，因为你还必须保证可以解释它的行为。这也是我在我的论文中广泛讨论的一个问题，就是大家都在谈论的可解释人工智能或安全人工智能的问题。人们不理解的是，对于神经网络来说，我们是无法理解它们的行为的。显然你无法解释为什么它会做出如此输出，因为你不能有一个数学模型来描述它们的行为。当然，我们完全理解神经网络的每个节点的数学函数是怎么计算的。它就是输入的线性组合，加上一些非线性函数，所以我们可以理解每一个节点的行为。但是当我们试图理解整个神经网络的涌现属性时，我们会感到绝望。但这不是一个特定于人工智能的问题，这是科学中的一个普遍问题。你不能仅仅从氧原子和氢原子的性质来推断水的性质。即使你完全理解这一点，还有一个尺度和复杂性的问题。这是令人绝望的点。我们无法用技术组合的逻辑或还原论的方法来通过神经网络中元素的行为去理解它的整体行为。所以我们唯一能应用于神经网络的方法是测试，因为我们无法验证它的行为，也没法通过推理理解它。但是如果只应用测试，这意味着你采用了一种纯粹的实验方法，而非理论理解。所以你实际上能够测试的内容类型会变的很不同：例如，你无法测试整体性的安全问题，因为你无法分析整体行为。但你可以防御性的进行安全测试。我们一直将测试应用于硬件和软件。但是为了进行测试，你得有测试应该持续的时间的标准。对于硬件和软件，我们有模型和覆盖标准。但对于神经网络来说，我们没有这种标准。我不是说这是一个非常难解决的问题，对于神经网络来说，我们有一些备选的可能，比如说是对抗性样本。但这些操作会破坏它们行为中的某种鲁棒性。所以你看，如果我问你一个问题，你会给出一个答案。如果我稍微修改你的问题，如果你是个人类的话，你会给出一些类似的答案。但我们知道，当我们稍微改变神经元的输入时，响应可能会有很大的不同。所以这也是需要考虑的。