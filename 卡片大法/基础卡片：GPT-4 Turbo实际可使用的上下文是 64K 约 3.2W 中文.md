

基础卡片：GPT-4 Turbo实际可使用的上下文是 64K 约 3.2W 中文2023-12-13解释：参考：ITStduy => 001大语言模型 => Article => 20231213GPT4-Turbo的128K上下文是鸡肋么原文：无疑，更长的上下文长度是能够完成更加复杂任务的必要条件，上下文长度从 32k 到 128k 的变化，不仅仅是「输入更多」的更新，更应该是「能做更多」的进化。而从「输入更多」到「能做更多」，其中一个核心问题便是：「GPT-4 Turbo 真有能力处理差不多近 300 页的长文本的阅读、理解与推理任务吗？」面对这个问题，推特大佬 Greg Kamradt 针对 GPT-4 Turbo 进行了一场压力测试，流程很简单，Kamradt 使用硅谷创业教父 Paul Graham 的 218 篇文章（长度超过 128k）输入 GPT-4 Turbo，在总体输入的不同长度的段落随机植入下面这段话：The best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day然后再去问 GPT-4 Turbo「在旧金山最美好的事情是什么？」，并且要求模型只根据上下文回答此问题，同时使用另一个模型（GPT-4）评估答案的质量。结果如下图所示：简述这个小实验的结果，大概是以下三点：当植入位置超过 73k 长度后，GPT-4 Turbo 的性能开始下降；相对来说，当插入位置在文档深度的 7%~50% 之间时，模型表现不佳；1『他这里的深度 7%~50%，看图片其实是指后半段，这样就符合逻辑了。总结说，上下文砍一半。（2023-12-13）』如果插入位置在文档开头，那么模型总能正确找到答案。由此，Kamradt 认为这项价值 200 刀的实验似乎可以说明：只要问题的答案不是包含在开头，那么 GPT-4 Turbo 并不能保证总能找到答案；更少的上下文长度 = 更高的准确性，减少向 GPT-4 Turbo 的输入，总会提升其表现；GPT-4 Turbo 还是偏好于在文档的开头与结尾寻找答案。无独有偶，推特网友 Louis Knight-Webb 进行了另一项实验，通过在文档中随机插入：My name is {randomCountry} and I have a pet ${randomAnimal}.再让 GPT-4 Turbo 进行名称的问题回答，Louis 发现，相比 GPT-4，GPT-4 Turbo 的能力有巨大的提升，在上下文长度为 32k 的条件下，GPT-4 Turbo 的平均检索正确 2.4 个人名、城市名与动物名，而 GPT-4 仅为 1.1 个。但是，和 Kamradt 一样，Louis 同样发现，即使是 GPT-4 Turbo，在更大的上下文大小上仍然表现不佳：事实上，早在 7 月份，来自斯坦福的一篇论文《Lost in the Middle: How Language Models Use Long Contexts》便揭示了 GPT-4 的性能随着上下文长度以及答案在上下文中的位置发生的变化的现象，这篇论文的作者们发现相关信息的位置和提供的上下文的长度可以极大的影响大模型的性能，几乎所有大模型都出现了「Lost in the Middle」的现象，甚至在一些情况下，当问题答案在文档中间时，其性能甚至弱于 Zero-shot 的版本。那么为什么会出现这种模型性能随上下文长度出现 U 型曲线的现象呢？很遗憾目前这个问题还属于一个开放问题。