

基础卡片：上下文学习（ICL）的有效性极大地受到演示设计的影响2023-12-22解释：参考：selfstudy => 003Paper => 2023046A-Survey-of-Large-Language-Models原文：6.2.2 Demonstration Design Several studies have shown that the effectiveness of ICL is highly affected by the design of demonstrations [432, 478, 479] Following the discussion in Section 6.2.1, we will introduce the demonstration design of ICL from three major aspects, i.e., demonstration selection, format, and order.6.2.2 演示设计一些研究显示，ICL 的有效性极大地受到演示设计的影响 [432, 478, 479]。接着 6.2.1 节的讨论，我们将从三个主要方面介绍 ICL 的演示设计，即演示的选择、格式和顺序。Demonstration Selection. The performance of ICL tends to have a large variance with different demonstration examples [428], so it is important to select a subset of examples that can effectively leverage the ICL capability of LLMs. There are two main demonstration selection approaches, namely heuristic and LLM-based approaches:• Heuristic approaches. Due to their simplicity and low costs, existing work widely adopts heuristic methods to select demonstrations. Several studies employ a k -NN based retriever to select examples that are semantically relevant to the query [428, 480]. However, they perform the selection individually for each example, rather than evaluating the example set as a whole. To resolve this issue, diversitybased selection strategies are proposed to choose the most representative set of examples for specific tasks [481, 482]. Furthermore, in [483], both relevance and diversity are taken into consideration when selecting demonstrations.• LLM-based approaches. Another line of work selects demonstrations by making use of LLMs. For example, LLMs can be utilized to directly measure the informativeness of each example according to the performance gain after adding the example [484]. In addition, EPR [429] proposes a two-stage retrieval approach that first recalls similar examples with an unsupervised method (e.g., BM25) and then ranks them using a dense retriever (trained with positive and negative examples labeled by LLMs). As an alternative approach, the task of demonstration selection can be formulated into a RL problem, where LLMs serve as the reward function to provide feedback for training the policy model [485]. Since LLMs perform well for text annotation [486], some recent studies employ LLM itself as the demonstration generator without human intervention [487].To summarize, as discussed in [488], the selected demonstration examples in ICL should contain sufficient information about the task to solve as well as be relevant to the test query, for the above two selection approaches.01 演示选择。ICL 的性能在不同示例演示中通常存在较大差异 [428]，因此选择一组能够有效发挥 LLMs ICL 能力的示例子集至关重要。目前主要有两种演示选择方法，分别是启发式方法和基于 LLM 的方法：1、启发式方法。由于其简单性和低成本，许多现有研究广泛采用启发式方法来选择演示。一些研究使用基于 k-NN 的检索器来选择与查询语义相关的示例 [428, 480]。然而，这些方法通常是针对每个示例单独进行选择，而不是评估整个示例集。为解决这个问题，提出了基于多样性的选择策略，目的是为特定任务选择最具代表性的示例集 [481, 482]。另外，在 [483] 中，选择演示时同时考虑了相关性和多样性。2、基于 LLM 的方法。另一种方法是利用 LLMs 来选择演示。例如，可以利用 LLMs 直接评估每个示例的信息量，根据添加该示例后的性能提升来判断 [484]。此外，EPR [429] 提出了一种两阶段检索方法，首先使用非监督方法（如 BM25）找到类似的示例，然后使用经过训练的密集检索器（使用 LLMs 标记的正负示例）进行排序。还有一种方法是将演示选择任务构造成一个强化学习问题，其中 LLMs 作为奖励函数，提供训练策略模型所需的反馈 [485]。鉴于 LLMs 在文本注释方面的出色表现 [486]，一些最新的研究将 LLM 本身用作演示生成器，无需人工干预 [487]。总结而言，如 [488] 所讨论的，ICL 中选择的演示示例应该包含解决任务所需的充足信息，并且与测试查询相关，这适用于上述两种选择方法。Demonstration Format. After selecting task examples, the next step is to integrate and format them into a natural language prompt for LLMs. A straightforward method is to instantiate a pre-defined template with the corresponding input-output pairs [36]. To construct more informative templates, recent studies consider adding task descriptions [69] or enhancing the reasoning capability of LLMs with chainof-thought prompts [33]. For instance, in [166], the authors collect a large-scale dataset with task descriptions written by humans. After tuning with this dataset, the performance on seen tasks can be boosted, and LLMs can also generalize to unseen tasks to some extent. To reduce the annotation costs, a semi-automated approach has been proposed in [143] by employing a seed set consisting of human-written task descriptions to guide LLMs to generate task descriptions for new tasks. Since it is costly to manually annotate demonstration formats for different tasks, some work also studies how to automatically generate high-quality ones. As two representative methods, Auto-CoT [434] leverages LLMs with the zero-shot prompt “Let’s think step by step” for generating intermediate reasoning steps, while least-to-most prompting [439] first queries LLMs to perform problem decomposition and then utilizes LLMs to sequentially solve sub-problems based on the intermediate answers to previously solved ones.02 演示格式。选择任务示例后，下一步是将它们整合并格式化成适合 LLMs 的自然语言提示。一种简单的方法是使用预定义模板并填入相应的输入-输出对 [36]。为了构建更具信息量的模板，最近的研究考虑添加任务描述 [69] 或使用思维链提示（chain-of-thought prompts）[33] 来增强 LLMs 的推理能力。例如，在 [166] 中，作者收集了一个由人类编写的任务描述的大型数据集。使用这个数据集进行调整后，不仅可以提升已见任务的性能，LLMs 也能在一定程度上泛化到未见任务。为了减少注释成本，[143] 中提出了一种半自动方法，使用包含人类编写的任务描述的种子集来指导 LLMs 为新任务生成任务描述。鉴于为不同任务手动注释演示格式的成本较高，一些研究也探讨了如何自动生成高质量的演示格式。作为两种代表性方法，Auto-CoT [434] 使用零射击提示「让我们一步步思考」来生成中间推理步骤，而最小至最多提示（least-to-most prompting）[439] 首先要求 LLMs 进行问题分解，然后利用 LLMs 根据之前解决问题的中间答案依次解决子问题。Demonstration Order. LLMs are shown to sometimes suffer from the recency bias, i.e., they are prone to repeat answers that are near the end of demonstrations [479]. Thus, it is important to arrange demonstrations (i.e., task examples) in a reasonable order. Early work proposes several heuristic methods to quickly find a good order. For example, demonstrations can be directly organized according to their similarity to the query in the embedding space [428]: the more similar, the closer to the end. In addition, global and local entropy metrics can be used to score different demonstration orders [432]. To integrate more task information, some recent studies propose to minimize the code length required to compress and transmit task labels, which is inspired by information theory [489]. However, these methods need additional labeled data as the validation set to evaluate the performance of specific demonstration orders. To eliminate this need, the authors in [432] propose to sample the validation data from the LLM itself.03 演示顺序。LLMs 有时会表现出近因偏见，即它们倾向于重复靠近演示末尾的答案 [479]。因此，合理安排演示（即任务示例）的顺序显得尤为重要。早期研究提出了几种启发式方法来快速找到合适的顺序。例如，演示可以根据它们在嵌入空间中与查询的相似性来进行组织：相似性越高，排列越靠近末尾 [428]。此外，可以利用全局和局部熵度量来对不同演示顺序进行评分 [432]。为了融入更多的任务信息，一些最新研究提出根据信息论的启发，最小化压缩和传输任务标签所需的代码长度 [489]。然而，这些方法需要额外的标记数据作为验证集来评估特定演示顺序的性能。为了消除这一需求，[432] 中的研究者提出从 LLM 本身抽样验证数据。