

基础卡片：上下文学习（ICL）与思维链（CoT）提示的比较2023-12-22解释：参考：selfstudy => 003Paper => 2023046A-Survey-of-Large-Language-Models原文：Fig. 14: A comparative illustration of in-context learning (ICL) and chain-of-thought (CoT) prompting. ICL prompts LLMs with a natural language description, several demonstrations, and a test query, while CoT prompting involves a series of intermediate reasoning steps in prompts.In-Context LearningAnswer the following mathematical reasoning questions:Nx Q&A{Q: If you have 12 candies and you give 4 candies to your friend, how many candies do you have left?A: The answer is 8.Q: If a rectangle has a length of 6 cm and a width of 3 cm, what is the perimeter of the rectangle?A: The answer is 18 cm.}Q: Sam has 12 marbles. He gives 1/4 of them to his sister. How many marbles does Sam have left?A: The answer is 9.Chain-of-Thought PromptingAnswer the following mathematical reasoning questions:Nx Q&A{Q: If a rectangle has a length of 6 cm and a width of 3 cm, what is the perimeter of the rectangle?A:For a rectangle, add up the length and width and double it. So, the perimeter of this rectangle is (6 + 3) x 2 = 18 cm.The answer is 18 cm.}Q: Sam has 12 marbles. He gives 1/4 of them to his sister. How many marbles does Sam have left?A: He gives (1 / 4) x 12 = 3 marbles. So Sam is left with 12 – 3 = 9 marbles.The answer is 9.1『上面思维链的举例，核心信息是 Q 和 A 之间的「For a rectangle, add up the length and width and double it. So, the perimeter of this rectangle is (6 + 3) x 2 = 18 cm.」CoT 提示最初作为 ICL 的扩展而提出 [33]，它将每个演示（输入，输出）增强为（输入，CoT, 输出）。CoT 是连接输入和输出的一系列中间推理步骤。有了这些增强的演示，LLMs 可以遵循它们来为新输入生成 CoTs 和答案。（2023-12-22）』图 14：上下文学习（ICL）与思维链（CoT）提示的比较示意图。ICL 通过自然语言描述、几个演示和一个测试查询来提示 LLMs，而 CoT 提示则涉及在提示中加入一系列中间推理步骤。6.3 Chain-of-Thought PromptingChain-of-Thought (CoT) prompting [33, 502] is an improved prompting strategy to boost the performance of LLMs on complex reasoning tasks, such as arithmetic reasoning [503], commonsense reasoning [504], and symbolic reasoning [33]. Instead of simply constructing the prompts with input-output pairs like ICL, CoT prompting further incorporates intermediate reasoning steps, which serve as the bridge between inputs and outputs. Figure 14 presents an illustration of CoT. In the following part, we will first elaborate on the basic CoT prompting approach and its improved strategies, then discuss when and why CoT prompting works.思维链（CoT）提示 [33, 502] 是一种改进的提示策略，旨在提高 LLMs 在复杂推理任务（如算术推理 [503]、常识推理 [504] 和符号推理 [33]）上的表现。与仅使用输入-输出对构建提示的 ICL 不同，CoT 提示进一步结合了中间推理步骤，作为输入和输出之间的桥梁。图 14 展示了 CoT 的示意图。在以下部分中，我们将首先详细阐述基本的 CoT 提示方法及其改进策略，然后讨论 CoT 提示何时以及为何有效。6.3.1 Basic CoT Prompting ApproachCoT prompting is first proposed as an extension of ICL [33], which augments each demonstration ⟨ input, output ⟩ as ⟨ input, CoT, output ⟩ . A CoT is a series of intermediate reasoning steps for connecting the input and output. With these augmented demonstrations, LLMs can follow them to generate CoTs and the answer for a new input. However, unlike ⟨ input, output ⟩ pairs in ICL, CoTs are difficult to obtain and usually require human annotation. Fortunately, it has been found that LLMs can be triggered to generate CoTs through simple instructions like “Let’s think step by step.” [505], making CoT prompting easy to use. There are also alternative magic prompts that can elicit the ability of CoT reasoning and further improve the performance of LLMs, such as “Take a deep breath and work on this problem step-by-step.” [473].As illustrated in Figure 15, the generation process of CoT follows a chain structure in the basic CoT prompting approach, where LLMs generate CoTs step by step. Typically, CoT takes the format of natural language text. However, textual CoTs may not work well on complex tasks that require rigorous logic for reasoning. Considering this, some work uses code [506, 507] due to its structured and precise nature. Furthermore, the authors in [508] propose to dynamically select text or code as the format of CoTs to combine their advantages.6.3.1 基本 CoT 提示方法CoT 提示最初作为 ICL 的扩展而提出 [33]，它将每个演示（输入，输出）增强为（输入，CoT, 输出）。CoT 是连接输入和输出的一系列中间推理步骤。有了这些增强的演示，LLMs 可以遵循它们来为新输入生成 CoTs 和答案。然而，与 ICL 中的（输入，输出）对不同，CoTs 通常难以获得，一般需要人工注释。幸运的是，已发现 LLMs 可以通过如「让我们一步一步地思考」[505] 这样的简单指令来触发生成 CoTs，使 CoT 提示变得易于使用。还有其他「神奇提示」，如「深呼吸，逐步解决这个问题」[473]，可以激发 CoT 推理能力并进一步提高 LLMs 的表现。如图 15 所示，在基本 CoT 提示方法中，CoT 的生成过程遵循链式结构，LLMs 逐步生成 CoTs。通常，CoT 采用自然语言文本的格式。然而，文本形式的 CoTs 可能在需要严谨逻辑推理的复杂任务上不太有效。因此，一些研究选择使用代码[506, 507]作为 CoTs 的格式，由于其结构化和精确性。此外，[508]中的作者提出动态选择文本或代码作为 CoTs 的格式，以结合它们的优点。