

基础卡片：微调时指令的质量和多样性比数量更重要2023-12-19解释：参考：selfstudy => 003Paper => 2023046A-Survey-of-Large-Language-Models原文：Key Factors for Instance Construction.The quality of instruction instances has an important impact on the performance of the model. Here, we discuss some essential factors for instance construction.• Scaling the instructions. It has been widely shown that scaling the number of tasks can largely enhance the generalization ability of LLMs [28, 67, 88]. With the increasing of the task number, the model performance initially shows a continuous growth pattern, while the gain becomes negligible when it reaches a certain level [69, 88]. A plausible speculation is that a certain number of representative tasks can provide relatively sufficient knowledge and adding more tasks may not bring additional gains [69]. Also, it is beneficial to enhance the diversity of the task descriptions in several aspects, such as length, structure, and creativity [28]. As for the number of instances per task, it has been found that a small number of instances can usually saturate the generalization performance of the model to perform a specific task [67, 69]. Specially, several recent work [349, 350] has explored the effect of fine-tuning with a small amount of high-quality instruction data (e.g., one or a few thousand instances), showing very promising results on the evaluation tasks. In contrast, another line of studies continue to explore the scaling effect of instruction data [351, 352]. For example, Orca [351] scales up the synthesized instances to 5 million with step-by-step explanations, and it achieves superior performance across a wide range of tasks compared to the methods tuned with instruction data.• Formatting design. As an important factor, the design of natural language format also highly impacts the generalization performance of LLMs [88]. Typically, we can add task descriptions and optional demonstrations to the input-output pairs of existing datasets, where the task description is the most key part for LLMs to understand the task [88]. Further, it can lead to substantial improvements by using an appropriate number of exemplars as demonstrations [69], which also alleviates the model sensitivity to instruction engineering [67, 69]. However, incorporating other components (e.g., things to avoid, reasons, and suggestions) into instructions may have a negligible or even adverse effect on the performance of LLMs [88, 166]. Recently, to elicit the step-by-step reasoning ability of LLMs, some work [69] proposes to include chain-of-thought (CoT) examples for some reasoning datasets, such as arithmetic reasoning. It has been shown that fine-tuning LLMs with both CoT and non-CoT examples can lead to a good performance across various reasoning tasks, including those that require multihop reasoning ability (e.g., commonsense question answering and arithmetic reasoning) as well as those without the need for such a reasoning way (e.g., sentiment analysis and extractive question answering) [69, 95].To summarize, diversity and quality of instructions seem to be more important than the number of instances [349] since the well-performing InstructGPT [66] and LLaMA-2Chat [99] utilize fewer but more diverse instructions (or instances) than the Flan-series LLMs [67, 69]. However, a large amount of training data may compensate for the absence of high-quality data [351]. Further, it is more useful to invite labelers to compose human-need tasks than using dataset-specific tasks. However, it still lacks general guidelines to annotate human-need instances, making the task composition somehow heuristic. To reduce human efforts, we can either reuse existing formatted datasets (Table 3) or automatically construct the instructions using existing LLMs [143]. We conduct a preliminary experiment to show the effectiveness of different construction methods in Section 5.1.4.实例构建的关键因素。指令实例的质量对模型性能有重大影响。以下是实例构建的一些关键因素。1、扩大指令范围。研究广泛表明，增加任务数量可大幅提升 LLM 的泛化能力 [28, 67, 88]。随着任务数量增加，模型性能最初呈连续增长趋势，但当达到一定水平后，增益变得微不足道 [69, 88]。一个合理的假设是，一定数量的代表性任务可以提供足够的知识，增加更多任务可能无法带来额外收益 [69]。此外，增加任务描述的多样性（如长度、结构和创造性）也有益 [28]。至于每个任务的实例数量，发现少量实例通常可使模型在执行特定任务时达到泛化性能饱和 [67, 69]。特别是，最近一些工作 [349, 350] 探究了使用少量高质量指令数据（如一千或几千个实例）进行微调的效果，在评估任务上表现出色。相比之下，另一些研究继续探讨指令数据的规模效应 [351, 352]。例如，Orca [351] 将合成实例扩大到 500 万，配有逐步解释，在各种任务中的表现优于使用指令数据微调的方法。2、格式化设计。作为一个重要因素，自然语言格式的设计对 LLM 的泛化性能产生显著影响 [88]。通常，我们可以在现有数据集的输入输出对中添加任务描述和可选示例，任务描述是 LLM 理解任务的关键部分 [88]。此外，使用适量示例作为示范可以显著改善表现 [69]，这也减少了模型对指令工程的敏感性 [67, 69]。然而，将其他组件（如避免的事项、原因和建议）纳入指令可能对 LLM 性能产生微小或不利影响 [88, 166]。最近，一些工作 [69] 提议为某些推理数据集（如算术推理）包含思考链（CoT）示例，以激发 LLM 的逐步推理能力。研究显示，使用 CoT 和非 CoT 示例微调 LLM 可以在多种推理任务中取得良好表现，包括需要多跳推理的任务（如常识问答和算术推理）以及不需要此类推理方式的任务（如情感分析和提取式问答）[69, 95]。总结而言，指令的多样性和质量似乎比实例数量更重要[349]，因为表现良好的 InstructGPT [66]和 LLaMA-2Chat [99]使用的指令（或实例）比 Flan 系列 LLM [67, 69]更少但更多样。然而，大量训练数据可以弥补高质量数据的缺失[351]。此外，邀请标注者编写符合人类需求的任务比使用特定数据集任务更有用。但目前仍缺少标注符合人类需求实例的通用指南，使得任务构建有些启发式。为减少人力，我们可以重用现有的格式化数据集（表 3）或使用现有 LLM 自动构建指令[143]。我们在第 5.1.4 节进行了一个初步实验，展示了不同构建方法的有效性。