

基础卡片：对于垂直领域的大模型 loRA 微调，其超参数 R 设大一些2023-11-22内容：loRA 微调超参数的注意事项，训练的领域越垂直，R 设的大点，反之，通用领域的微调设小一些。参考：ITStduy => 001大语言模型 => Video => 2023020卢菁大模型教程 => 0401卢菁-模型微调实战和经验分享原文：12.10minloRA 微调超参数的注意事项：第三种技术叫做 LoRA。它也是通过添加外挂部分来实现，但与适配器不同的是，如果适配器是通过串联方式加入外挂，LoRA 则是以并联方式加入外挂。在进行各种方法的实验时，我们尝试了这三种技术，并最终发现 LoRA 的效果最为显著，它不仅易于上手，而且训练过程相对较快。然而，使用 LoRA 时有一个超参数需要特别关注，那就是 rank 的设置问题。基于我的经验，如果你的训练数据领域是垂直的，例如公司的专有数据，适当增大 rank 的值可能会更为合适。如果你所使用的训练数据相对通用，例如我们所开发的大型运维模型所包含的，很多是客观的普适性知识，并非仅限于我们公司内部的专有信息。在这种情况下，我们对数据质量的排名标准（rank）可以设定得相对较低。