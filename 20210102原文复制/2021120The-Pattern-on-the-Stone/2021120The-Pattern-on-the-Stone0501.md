ALGORITHMS AND HEURISTICS

W hen I was an undergraduate at MIT, one of my roommates had several dozen pairs of socks, each pair with a slightly different color or design. He frequently postponed doing his laundry until he was completely out of clean socks, so whenever he washed them he had the not inconsiderable task of matching them all up again in pairs. Here is the way he would do it: First, he would pull a random sock out of the pile of clean laundry, then he would extract another sock at random and compare it to the first to see if it matched. If it didn't, he would throw the second sock back and pull out another one. He would keep doing this until he found a match, and then he would go through the same sequence all over again with a new sock. Since he had to look though a lot of laundry, the process went very slowly — especially at the beginning, because there were a lot more socks to be examined before a match turned up.

He was studying for a degree in mathematics, and was apparently taking some kind of course in computers. One day when he had hauled his laundry basket back to our rooms, he announced,「I have decided to use a better algorithm for matching my socks.」What he meant was that he was now going to use a procedure of a fundamentally different nature. He pulled out the first sock and set it on the table, then he pulled out the next sock and compared it with the first sock; since it didn't match, he set it next to the first. Now each time he pulled out a sock he would compare it to the growing row of socks on the table. When he found a match, he would bundle that pair together and throw them in his sock drawer. When he didn't, he would add the unmatched sock to the row. Using this method, he was able to pair up his socks in a small fraction of the time it had previously required. His parents, who had paid a great deal of money for his college education, would have been proud to know that he was putting his newfound learning to such practical use.

THE ALGORITHMIC GUARANTEE

With or without socks, an algorithm is a fail-safe procedure, guaranteed to achieve a specific goal. The word「algorithm」comes from the name of the Arabian mathematician al-Khwarizmi, who wrote down an extensive collection of algorithms in the ninth century. The word「algebra,」in fact, comes from al jabr (「the transposition」), a term in the title of one of his books. Many of al-Khwarizmi's algorithms are still used today. He described them, of course, in Arabic, which may be why this language gained a reputation as the language of magic spells. (It has even been suggested that the incantation「abracadabra」is a corruption of al-Khwarizmi's full name, Abu Abdullah abu Jafar Muhammad ibn Musa al-Khwarizmi.)

Computer algorithms are usually expressed as programs. Since the term refers to the sequence of operations rather than the particular way they are described, it is possible to express the same algorithm in many different computer languages, or even to build it into hardware by connecting the appropriate registers and logic gates.

Usually, many algorithms can compute the same result. As in the sock example, different algorithms require different amounts of time to complete a given task. Certain algorithms may also offer other kinds of advantages: they may use only a small amount of a computer's memory, or they may require a particularly simple pattern of communication that is easy to wire into its hardware. The difference in speed and memory requirements between a good algorithm and a bad one is often a factor of thousands or even millions. Sometimes the discovery of a new algorithm allows you to solve previously intractable problems.

Because an algorithm can be implemented in many different ways and can be applied to problems of varying size, you can't judge how fast an algorithm is by measuring the time that elapses before a solution to your particular problem is reached. The time will vary with the method of implementation and the size of the problem. Instead, we usually describe the speed of an algorithm by how much the time required to complete the task grows along with the size of the problem. In the sock-pairing example, most of the time is spent in pulling the socks out of the basket, so we can compare the two sock algorithms by asking how the number of socks pulled out in each one compares to the total number of socks. Assume that there are n socks in the laundry basket. In the first algorithm, finding two that match requires pulling out and putting back an average of half the remaining socks, so the number of sock removals is proportional to the square of the number of socks. In analyzing algorithms, we usually don't bother to calculate the exact constant of proportionality; instead, we simply say that the algorithm is order n 2 , meaning that for large problems the time required for completion grows as the square of the problem size. This means that if there are ten times as many socks, the first algorithm will take a hundred times as long, so it is not a very good algorithm to use for pairing large numbers of socks. In the second algorithm, however, each of the n socks is pulled out only once, so the algorithm is order n. When you use the second algorithm to sort ten times as many socks, the task will take only ten times as long.

One of the greatest joys in computer programming is discovering a new, faster, more efficient algorithm for doing something — particularly if a lot of well-respected people have come up with worse solutions. Computer scientists can gain fame and admiration — at least among other computer scientists — by discovering a faster algorithm for a common problem. Since a bad algorithm can take weeks to solve a problem that a good algorithm can solve in minutes, the classical form of algorithmic one-upmanship is to write a new program and compute the right answer while your colleague's inferior program is still running.

Often the best algorithm is not obvious. Consider the problem of sorting a deck of sequentially numbered cards into ascending order. One way to do this is to start by looking through the entire deck for the lowest-numbered card. This card is removed and it becomes the first card of the sorted output pile. Next we look for the lowest card among those that remain. This in turn is removed and placed on top of the first card. The process is repeated until the unsorted cards are exhausted and the deck is arranged in ascending order. This procedure requires looking through the entire deck each time a card is extracted. Since there are n cards, each of which requires n comparisons, the run time of the algorithm is order n 2.

If we know that the cards are sequentially numbered from 1 to n, then we can sort them by a different method — one that uses a recursive definition, like the Logo procedure for drawing a tree described in chapter 3. To sort a deck of cards recursively, go through the deck once, moving cards with a value lower than the mean to the bottom half of the deck and leaving the cards with higher-than-average value in the top half. Then sort the two halves of the deck using the same algorithm. Applying the same algorithm recursively to each half of the deck will involve applying it recursively to each half of the half-decks, and so on. Each step of the recursion halves the number of cards to be sorted; the recursion ends when there is only one card — in which case, it is already sorted. Because this algorithm involves repeatedly dividing the cards until you are examining only one, it will require a time proportional to the number of times n cards can be divided — or the logarithm to the base 2 of the number of cards. So the order of this algorithm is n log n. (If you don't remember what logarithms are, never mind. They are all small numbers, so they can be safely ignored.)

There is an even more elegant recursive algorithm, which doesn't require the cards to be sequentially numbered; it would be useful for putting a large number of business cards into alphabetical order, for example. This algorithm, called merge sort , is harder to understand, but it's so beautiful that I cannot resist describing it. The merge-sort algorithm depends on the fact that it's easy to merge two already sorted stacks into a single sorted stack by successively pulling top-ranked cards off the top of one or the other of the stacks; this merge procedure is a subroutine of the algorithm, and the algorithm works like this: If your stack consists of only one card, then that card is already sorted. Otherwise divide the stack in half, and recursively use the merge-sort algorithm by sorting each half and then combining them using the merge procedure described above. That's all there is to it. (If this sounds too simple to work, you might want to try it with a few cards. Start with eight.) The merge-sort algorithm is a good example of the almost mysterious power and elegance of recursion.

A sorting algorithm that requires just n log n steps, like merge sort, is pretty fast. In fact, it is about the fastest algorithm possible. Proving that particular statement is beyond the scope of this book, but the reasoning that underlies the proof is interesting. It can be shown by counting the number of possible orderings of n cards. From this count, it is possible to compute that n log n bits of information must be known in order to put the cards in the correct order. Since each comparison of two cards produces only 1 bit of information (either the first card is greater than the second, or it is not), then to sort n numbers requires at least n log n comparisons, so in this case the merge-sort algorithm is about as good as any other. Books have been written on the topic of choosing the proper sorting algorithm. In many cases, where certain constraints are put on the sorting, or particular knowledge is available about the objects being sorted, the fastest possible sorting algorithm remains unknown. Still, on the scale of tasks for which we would like to design algorithms, sorting is considered relatively easy.

An example of a difficult task is called the traveling salesman problem. Imagine that a traveling salesman has to visit n cities. Given the traveling distance between each of the cities, in what order should the salesman visit the cities to minimize total distance traveled? No one knows an algorithm that is order n 2 , or order n 3 , or n to any power, which will accomplish this. The best algorithm known is order 2 n , meaning that the time required grows exponentially with the size of the problem. If we add ten more cities to the salesman's itinerary, the problem gets a thousand times harder (2 10 = 1,024). If we add thirty more cities, it gets about a billion times harder (2 30 is about 10 9 ). Exponential algorithms are not much use when problems get large, but for the traveling salesman problem they are the best algorithms we know. The fastest computer in the world, working for billions of years, would not have enough time to find the best route for just a few thousand cities.

The traveling salesman problem may seem unimportant, but it turns out to be equivalent to a lot of other problems — the so-called N-P complete problems (N-P stands for「nondeterministic polynomial」) — that it would be very useful to solve. A fast solution to the traveling salesman problem would lead immediately to a solution of these additional problems: for example, certain codes used for protecting secret information would become easy to break. Anyone who uses these codes is betting that no fast algorithm for solving the traveling salesman problem will ever be found. It's probably a safe bet.

No predictable technical breakthroughs in computers will help solve the traveling salesman problem, since even a computer a billion times faster will still be stumped by the addition of a few more cities. Exponential algorithms are just too slow to use for large problems. What could make a difference is the invention of a new algorithm: no one has ever proved that a fast algorithm for the traveling salesmen problem cannot exist. The study of algorithms has made significant progress in just the last few decades, and finding a fast one for the traveling salesman problem — or else proving that a fast one does not exist — remains one of computing's holy grails.

SETTLING FOR ALMOST ALWAYS

As hard as the traveling salesman problem is, it is not one of the most difficult problems to solve on a computer. Some problems are known to require even more than exponential time to solve. As discussed in the previous chapter, there are noncomputable problems that we know no algorithm can solve. Even when algorithms exist for certain problems, they are not necessarily the best approach. An algorithm, by definition, is guaranteed to get the job accomplished, but this guarantee of success often comes at too high a price. In many cases, it is more practical to use a procedure that only almost always gets the right answer. Often,「almost always」is good enough. A rule that tends to give the right answer, but is not guaranteed to, is called a heuristic. It is often more practical to use a heuristic than an algorithm: for instance, there are many effective heuristics for the traveling salesman problem — procedures that will provide an almost optimal route very quickly. In fact these heuristics usually do find the best route, although they are not absolutely guaranteed to do so. A real-life traveling salesman would presumably be happier with a good, fast heuristic than with a slow algorithm.

A simple example of the use of heuristics is the game of chess. A talented programmer who is only an average chess player can write a chess-playing program that will consistently beat the programmer. Such a program is not an algorithm, because it is not guaranteed to win. Heuristics make educated guesses; good heuristics usually make the right guess. Some of the most impressive behaviors of computers are the result of heuristics rather than of algorithms. (Philosophers have written a great deal of nonsense about「the limitations of computers」when what they are really talking about are the limitations of algorithms.)

A good chess-playing program can be written based on the following heuristics:

1.    Estimate the relative strength of each player's position by counting the number of pieces of each type remaining on the board.

2.    Move so as to put yourself in the strongest possible position a few moves in the future.

3.    Expect your opponent to adopt a strategy similar to your own.

Each of these rules is only an approximation of the ideal strategy, and it is possible to imagine situations in which each is actually wrong. The relative strength of a player's position, for example, depends not just on the number of pieces but also on their position. A good position can often be more advantageous than an extra piece. Regardless, the first heuristic is generally correct; in most cases, having more pieces is better. Even before computers, chess players developed a simple method of numerically scoring the relative strengths of two players' positions by assigning one point for a pawn, three for a bishop, five for a rook, and so on, and using the total score of each player's remaining pieces as a measure of strength.

Based on these heuristics, you can write a chess-playing program that will trace out all plausible lines of play for the next few moves. Of course, it would be preferable if the program considered all lines of play, plausible or not, all the way to the end of the game. This was easy in the game of tic-tac-toe, but where chess is concerned it is impractical even for the fastest computers. In a typical midgame chess position, a player has about thirty-six potential legal moves, each of which leads to thirty-six possible responses by the opponent. Since the average chess game lasts for more than eighty moves, the computer would have to search something on the order of 36 80 possibilities, or about 10 124 possibilities. Such a search could not be accomplished by the fastest modern computers in hundreds of years. The problem is that the possible lines of play grow exponentially with the number of moves; it is thus impractical to look more than about five to ten moves ahead — which is why computers use the heuristics I have just listed for evaluating their moves.

Let us for the moment accept the second heuristic as correct and agree that the best line of play is the one that optimizes a player's position a few moves into the future. Let us further specify that the chess-playing program will look six moves ahead. According to the first heuristic, the program will evaluate the strength of both players after the sixth move by counting the number of pieces on each side remaining on the board and scoring them using the point system I have described. The relative strengths of the two players in any position considered will be judged by the difference between those scores.

Given these assumptions, what is the best way for the program to choose its next move? It's not enough for the computer to choose a move leading to the most favorable sequence of six future moves, because every alternate move in that sequence will be determined by the opponent. Instead, we must assume that the opponent will always try to choose a line of play that will favor the opponent's relative position; this is the assumption embodied in the third heuristic. To predict the opponent's line of play, the computer must place itself in the position of the opponent. The computer chooses a move by evaluating each legal move that can be made by its own side — white, say. The procedure for evaluating a possible move to be made by white depends on invoking a procedure for evaluating a possible move to be made by black, and vice versa. In effect, the computer follows every possible line of play for six moves, alternately putting itself in the position of black and white. The program tries out the moves on an imaginary board inside the memory of the computer, in much the same way that a chess master imagines lines of play「inside his head.」The programs evaluating white's and black's positions call each other as subroutines, recursively. The recursion terminates after six levels, when the computer evaluates the score by counting the pieces.

Most chess-playing programs incorporate additional heuristics to abort searches of implausible lines of play and to search deeper in branches that involve the exchange of pieces. There are also more elaborate systems for evaluating positions without searching — for example, systems that award points for keeping control of the center or for protecting the king. Each of these heuristics is just an additional guess, and each one can improve the search in some situations at the cost of potentially making mistakes in others. With various refinements, this basic search procedure is at the heart of nearly every chess-playing program. It is effective because it takes advantage of the speed of the computer to consider many millions of alternate lines of play. Among these many millions of alternatives, there is often a variation that will surprise the programmer, or even an experienced human chess player. This ability to surprise is what allows the machine to play a better game of chess than the programmer.

Chess-playing machines have a long and sometimes dishonorable role in the history of computing. The eighteenth-century Hungarian inventor Wolfgang von Kempelen captured the world's imagination with a chess-playing automaton in the form of a mechanical turbaned Turk. As it turned out, the machine worked only because a chess-playing midget was hidden inside it. In 1914, the Spanish engineer Luis Torres y Quevedo built a mechanical device that played a simplified game of chess without the help of a concealed human being, and in the late 1940s Claude Shannon described how a computer could be programmed with a set of chess-playing heuristics similar to those listed here. Still, it was many years before computers were fast enough to play a decent game of chess, which comforted not a few philosophers who argued that chess playing was an example of the unique powers of the human mind. Modern computers, using the same heuristics, can now beat the best human chess players in the world (witness the victory in 1997 of IBM's Deep Blue over Garry Kasparov), so the philosophers have shifted the argument to other domains.

The simple search heuristics work because there are a relatively small number of responses to consider for each move. In checkers, where there are even fewer possible responses to each move, machines based on heuristics began beating the best human players in the 1960s. In the Chinese/Japanese game of Go, on the other hand, humans still reign, because the larger board (19 × 19) affords far more possible moves. (I prefer playing Go to chess, precisely because a search is less useful; it makes my impatience less of a disadvantage.)

FITNESS LANDSCAPES

The use of heuristics to search through a set of possibilities is ubiquitous in computer programming and has applications far more important than game playing. This is often the way computers find「creative」solutions to problems — usually problems whose solutions are known to be among a large but finite set of possibilities called a search space. The search space in chess is the set of all possible lines of play; the search space in the traveling salesman problem consists of all possible routes linking the cities on the salesman's list. Since these spaces are too large to search exhaustively, heuristics are used to reduce the area to be searched. In the case of small search spaces, such as in the game of tic-tac-toe, the exhaustive search is preferable, because it is guaranteed to find the right answer.

Generally, the reason that a search space is large is because the possibilities are produced by forming combinations of simpler elements — the individual moves in chess, the city-to-city hops in the traveling salesman problem. This combining of elements leads to a combinatorial explosion of possibilities — an explosion that grows exponentially with the number of elements being combined. Since the possibilities are built from combinations of elements, there is a sense of distance in the space; combinations that share common elements are「closer」than the combinations that do not. This is why it is called a「space」and not just a set of possibilities. To extend the analogy, we can imagine the possibilities as lying in a two-dimensional landscape sometimes known as a fitness landscape. The desirability, or score, of each possible solution is represented by the altitude of a point in the landscape. If similar possibilities have similar scores, then nearby points will have similar altitudes, so the landscape will have well-defined hills and valleys. In this analogy, finding the best solution is like finding the top of the highest hill. Taking the traveling salesman problem as an example, we can imagine each point in the landscape as representing a particular travel itinerary for the salesman. The height of each point represents the distance the salesman must travel, with points representing efficient travel itineraries at higher altitudes. The best itinerary will be at the top of the highest hill.

One of the simplest ways of searching such a space is to compare points at random and remember the best one found. The number of points that can be searched this way is generally limited only by the amount of time available, and the procedure can be applied to any type of space. It is the equivalent of parachuting scouts into various locations in the landscape and asking them to report back their altitude. It is not a very efficient way to find the top of a hill. If the space is large, then in any practical amount of time only a tiny portion of the possibilities will be investigated, and therefore the best point found is unlikely to be one of the highest.

In a search space like that of the traveling salesman problem, where nearby points are likely to have similar scores, it is usually better to use a procedure that searches a path through the space by traveling from point to nearby point. Just as the best method for finding a peak in a hilly landscape is to walk uphill, the equivalent heuristic is to choose the best of nearby solutions found in the search space. In the traveling salesman problem, for example, the computer might vary the best-known solution by exchanging the order of two of the cities in the itinerary. If this variation leads to a more efficient tour, then it is accepted as a superior solution (a step uphill); otherwise, it is rejected and a new variation is tried. This method of search will wander through the space, always traveling in an uphill direction, until it reaches the top of a hill. At this point, the solution cannot be improved by exchanging any pair of cities.

The weakness of this method, which is called hill climbing , is that although you thereby reach the top of a hill, it is not necessarily the highest hill in the landscape. Hill climbing is a heuristic, not an algorithm. There are other heuristics similar to hill climbing which are less likely to get you stuck on top of one of the foothills. For instance, you could repeat the hill-climbing process many times, starting from different random locations (that is, you might ask the parachutists to climb uphill). Or you could occasionally take a step downward to avoid getting stuck. There are many such variations, each with its own advantages and disadvantages.

Heuristics like hill climbing work well on the traveling salesman problem and produce good answers in a short amount of time. Even when thousands of cities are involved, it is usually possible to find at a good solution to the problem by starting out with a reasonable guess and improving it by hill climbing. So why is the traveling salesman problem considered so difficult? Using heuristics, we can almost always get almost the best itinerary. But a method that almost always works is not an algorithm. Periodically, a great deal of fuss is made by someone who has「solved」the traveling salesman problem; so far, all anyone has actually done is come up with a new heuristic. Fast heuristic solutions to the traveling salesman problem are not difficult to dream up; it is finding a fast algorithm that is the difficulty.

There are many problems for which we do not need exactly the right answer every time — problems for which we can accept a less-than-perfect solution. Even when we want a perfect answer, we may not be able to afford it. For such problems, computers can produce an educated and well-considered guess. Because the computer is able to consider an enormous number of combinations and possibilities, such a guess will often surprise the programmer. When a computer uses heuristics, it is capable both of surprises and mistakes — which makes it a little more like a person and a little less like a machine.