# 0301. A world of networks

网络世界

## 3.1 Networkomics

During the eighties and nineties of the last century everything was ‘genetic’ in some way. Newspapers published stories about ‘the gene for homosexuality’, ‘the gene for obesity’, ‘the gene for violence’, or the ‘gene for alcoholism’. This attitude responded to the expectation that the secret of human complexity was hidden in the genome. The DNA—the deoxyribonucleic acid molecule packed in the nucleus of the cell, that contains the genes—was dubbed the ‘software of life’, the program responsible for every single feature of a living being, the code whose dysfunction caused all the diseases. This vision set off a rush to sequence the genome, culminating in the publication of its map in February 2001. Results were quite surprising. Human beings do not have many more genes than a nematode worm, and fewer than some species of rice. It is reasonable that the human genome is almost identical to that of great apes, but the problem is that it is also rather similar to that of mice. The software metaphor did not stand in the face of this evidence: the DNA sequence alone does not explain the observed differences between species, let alone all the features and diseases of a single individual. In fact, there is a long series of steps from the genes to the macroscopic features of a living being. Variations in this path determine different outcomes.

The first layer of complexity above the gene level is given by gene regulation . Genes contained in the DNA are transcribed and translated to produce proteins. Proteins play a central role in almost every aspect of life: muscle movement, blood circulation, acting as enzymes, binding to hormones, etc. Moreover, proteins interact with each other: the production of a protein can be facilitated or hindered by the presence of other proteins in the cell. The delicate balance of these reciprocal influences is crucial for life. For example, the mutations of a single protein, the p53, are implied in a large number of different cancers. These interwoven patterns of activation and inhibition yield the gene regulatory network . In this net, nodes are genes and links are chains of reactions that connect the expression of a gene with that of others.

Protein interact, in all the forms in which they can happen, represent a second layer of complexity. For example, several proteins can bind together. These macromolecules behave as molecular machines, performing functions in the mach An engraving of Königsberg (top)" aid="tradinery of the cell. To do so, they must have the correct geometrical shape to fit with each other. When a protein is folded in the wrong way, several problems can arise. For example, the proteins responsible for the ‘mad cow syndrome’ (Creutzfeldt-Jacob disease) in humans, i.e. the prions , are supposed to be nothing else than misfolded proteins. All the possible physical connections between proteins can be represented as a network. In the protein interaction network the vertices are proteins and an edge is drawn between them if they physically interact in the cell.

Proteins are not enough for making a cell work. The cell interchanges matter, energy, and information with the environment, through many different molecules, involved in millions of reactions. Hunger, satiety, coldness, and in general all the states experienced by the organism, depend on this set of reactions, called metabolism . The chains of reactions that convert one molecule into another, passing through a series of intermediates steps, are called metabolic pathways . However, reactions in cells rarely follow the pattern of an ordered sequence. For example, the final molecule often interacts with the initial one in order to stop the reaction. This feedback process closes a loop in the chain of reactions. The ensemble of all such paths yields an intricate metabolic network .

An organism is therefore the outcome of several layered networks and not only the deterministic result of the simple sequence of genes. Genomics has been joined by epigenomics, transcriptomics, proteomics, metabolomics , etc., the disciplines that study these layers, in what is commonly called the omics revolution . Networks are at the heart of this revolution.

网络组学

上世纪 80 和 90 年代，人们倾向于认为在某种方式上一切都是由基因決定的。报纸上的报道都与「同性恋基因」「肥胖基因」「暴力基因」或者「酗酒基因」有关。这种态度呼应了人们对人类复杂性的秘密隐藏在基因组中的期望。DNA 一细胞核中包含基因的脱氧核糖核酸分子一又称「生命的软件」，该程序负责生命体的每一个特征正是其中代码功能的障碍导致了所有的疾病。这种图景引发了人们对基因组进行测序的风潮，而人类基因组图谱于 2001 年 2 月的发布将这个风潮推向了顶点。序的结果令人十分惊讶，人类的基因数并不比线虫多多少，而且比某些种类的水稻基因还少。类几乎与类人猿有着相同基因组的推断是合理的，但问题是人类基因组也与老鼠类似。软件的喻并不支持这一证据：DNA 序列本身并不能解释我们所能观察到的物种差异，更不用说单个个体的所有特征和疾病了。事实上，生物的基因与其相应的宏观特征之间还隔着一系列漫长的步骤。此间的变异决定了不同的结果。

基因之上的第一层复杂性由基因调控给出。包含在 DNA 中的基因被转录和翻译以产生蛋质。蛋白质几乎在生命的各个方面都起着核心作用：肌肉运动、血液循环、承担酶的作用、结合激素等等。此外，蛋白质还彼此相互作用：蛋白质的产生可能受到细胞內现有蛋白质的促进或阻碍。这些相互影响之间的微妙平衡对于生命而言至关重要。例如，p53 这一单个蛋白质的突就伴随着大量不同的癌症。这些交织的激活和抑制模式产生出了基因调控网络。在这个网络之中，节点为基因，连线则是关联某个基因与其他基因表达的反应链条。

蛋白质以所有可能发生的方式相互作用，这代表着另外一个层面的复杂性。例如，一些蛋质可以结合在一起。这些大分子像分子机器一样起作用，它们在细胞这种机器中发挥着自己的功能。为此，蛋白质必须具备正确的几何形状以彼此契合。当蛋白质以错误的方式折疊时，就可能出现一些问题。比如，人体中对应「疯牛综合征」（又称克雅二氏病）的蛋白质（即朊病毒）就被认为是错误折盛的。蛋白质之间所有可能的实体联系可表示为网络。在蛋白质相互作用网络中，顶点为蛋白质，而如果蛋白质在细胞中的确相互作用，则可在相应的点之间画出一条边。

蛋白质并不足以让细胞工作。细胞通过许多不同的分子与外界环境交换着物质、能量和信息，参与其中的反应数达百万级。饥饿、饱腹感、寒冷以及生物体大致上所经历的所有状态都赖于这种被称为新陈代谢反应的集合。而通过一系列中间步骤将一个分子转化为另一个分子的反应链则被称为代谢途径。然而，细胞中的反应很少遵循有序序列的模式。例如，反应终端的分子经常会与开端处的分子相互作用以终止反应。这种反馈过程就闭合了反应链中的一环。所有这般路径的集合就产生了复杂的代谢网络

因此，生物体是几层网络共同作用的结果，而不仅仅是简单基因序列的決定性结果。基因组学中已经加入了表观基因组学、转录组学、蛋白质组学、代谢组学等研究相关层级的学科，这通常被称作组学革命。而网络正是这场革命的核心。

## 3.2 Thinking webs

The idea that the ‘soul’ could be embodied in an organ sounded a weird supposition by the 18th century. But physicians were aware that a stroke or other brain injuries could compromise crucial cognitive functions: the link between mind and brain was then starting to become evident. At that time, the anatomist Franz Joseph Gall dared to propose that all mental functions must arise from the brain. He identified 27 ‘organs’ within the brain, each one responsible for colour, sound, memory, speech, as well as friendship, benevolence, pride, etc. The idea sounded so heretical that Gall had to flee Vienna and find shelter in revolutionary France.

Later on, several physiologists tried to verify Gall’s theory, for example by removing slices from pigeons’ brains. However, they could not find any evidence of the organs that Gall postulated. For this reason, they arrived at the conclusion that the brain was a homogeneous, undifferentiated unity that generated thought: ‘the brain secretes thought as the liver secretes bile’, as one of them put it. This conception dominated until the studies of Paul Broca in the 1860s. In autopsies of patients with expressive aphasia, Broca always found some damage to the frontal lobes of the left side of the brain. ‘We speak with the left hemisphere,’ he declared, after having identified what is now called Broca’s area . Since then, neurologists have found various centres responsible for different activities, but they have also found that they rarely work in isolation: the integration of different areas of the brain is crucial to its functioning.

Networks provide a bridge between the paradigms of a brain divided into specialized areas versus the model of the brain as a whole (not dissimilar to what happens in social sciences, where networks allow us to describe society at a level they did not know the recipient, scca between individuals and communities). The brain is full of networks where various web-like structures provide the integration between specialized areas. In the cerebellum, neurons form modules that are repeated again and again: the interaction between modules is restricted to neighbours, similarly to what happens in a lattice. In other areas of the brain, we find random connections, with a more or less equal probability of connecting local, intermediate, or distant neurons. Finally, the neocortex—the region involved in many of the higher functions of mammals—combines local structures with more random, long-range connections. Some scientists think that these wiring schemes may be responsible for subjective awareness: the emerging conscience may be the result of a sufficiently complex network structure.

Pinning down the actual structure of these neuronal networks is extremely hard, due to the enormous quantity of cells and the difficulty of probing them. Only for very simple organisms such as the nematode worm, Caenorabditis elegans , we have a detailed map. This one-millimetre long, transparent creature, with a three-week lifespan, has only about 300 neurons but it is a superstar in molecular biology. C. elegans is a model organism , an animal that is especially suitable for experiments, because scientists know its features well, and some aspects of it are comparable to those of the human organism. This translucent worm is often the first benchmark for the trial of new medicines and treatments.

Drawing a similar neuronal network for the human brain is impossible at the moment. However, another strategy can be applied. When humans perform an action, even one as simple as blinking, a storm of electrical signals from the neurons breaks out in several areas of the brain. These regions can be identified through techniques such as functional magnetic resonance . Through this technique, scientists have discovered that different areas emit correlated signals. That is, they show a special synchronization that suggests that they may influence each other. These areas can be taken as nodes and an edge is drawn between two of them if there is a sufficient level of correlation. Also at this level, the brain appears as a set of connected elements. Each action of a person lights up a network of connected areas in their brain.

## 3.3 The blood vessels of Gaia

In 1999, San Francisco Bay experienced massive algal blooms. Normally, such blooms are the result of an intensive agricultural use of land: when we drain fertilizers such as nitrogen and phosphorus into the sea, they become nutrients for algae. However, this was not the case in this instance, since a number of policies and controls had decreased the level of nutrient pollution entering the bay from its various rivers. Compiling data from three decades of observations, ecologists in California concluded that the blooms had a much more complicated explanation. In 1997 and 1998, one of the strongest El Niño events was recorded, followed by an equally strong La Niña in 1999. These phenomena induced changes in the California current system. Deep, cold, and nutrientladen waters emerged along the coast. Such nutrients attracted ocean dwellers—flatfish and crustacean—into the bay. These animals are predators of bivalves of the bay that, in turn, act as an obstacle to the spreading of algae. The collapse in the bivalve population due to the increase in its predator was the immediate cause of the algal blooms. The conditions that triggered this domino effect may be due to normal climatic fluctuations. Nevertheless, its consequences are a warning: climate change, and especially the increased frequency of extreme events, can have rather they did not know the recipient, sccaunexpected effects on ecosystems.

The central structure behind the San Francisco Bay algal bloom is a food chain— that is, a series of species in connection: flatfish and crustacean prey on bivalves, and bivalves consume algae. Through food chains, living organisms extract from each other the energy and matter they need to survive (this is not the only possible interaction between species in an ecosystem: organisms can also establish mutually beneficial interactions, such as those between flowering plants and their insect pollinators). Every food chain starts with basal species, such as plants and bacteria. These do not prey on any other species and take resources directly from the environment by transforming light, minerals, and water. These resources are transferred along the food chain by successive predations. Intermediate species are organisms that are both predators and prey. And top species (at the end of the chain) are those that are not predated by anything. Food chains help us understand why fisheries collapse, as the Peruvian anchovy fishery in the seventies. After periods of massive indiscriminate fishing, the result is a dramatic reduction of predators such as cod or tuna. After this phase, fishing tends to move towards more basal species, such as anchovies. But these rapidly collapse as well. The reason is that, when large predators are removed, they are replaced by other predators downstream in the foodweb. These are often non-edible fish: without population control, they deplete the other edible basal species.

The actual picture of an ecosystem is even more complicated: typically, food chains are not isolated, but interwoven in intricate patterns, where a species belongs to several chains at the same time. For example, a specialized species may predate on only one prey (or in some cases on only a few). If the prey becomes extinct, the population of the specialized species collapses, giving rise to a set of co-extinctions . An even more complicated case is where an omnivore species predates a certain herbivore, and both eat a certain plant. A decrease in the omnivore’s population does not imply that the plant thrives, because the herbivore would benefit from the decrease and consume even more plants.

As more species are taken into account, the population dynamics can become more and more complicated. This is why a more appropriate description than ‘foodchains’ for ecosystems is the term foodwebs ( Figure 5 ). These are networks in which nodes are species and links represent relations of predation. Links are usually directed (big fishes eat smaller ones, not the other way round). These networks provide the interchange of food, energy, and matter between species, and thus constitute the circulatory system of the biosphere. They are the blood vessels of the Earth.

5 A United Kingdom Grassland foodweb: nodes represent species of grassland plots in England and Wales, and links are drawn from predators (thicker end) to preys (thinner end)

## 3.4 Homo ‘retiarius’ (Net man)

Word of mouth is a common way to obtain information about white-collar job openings. So if we are looking for this kind of job, it is a good idea to spread the word between friends and relatives. Less obviously, it may be even better to inform distant acquaintances and people we do not see often. This is what Mark Granovetter suggested in 19 and now represents a wide variety of topics in history, philosophy, religion, science, and the humanities. The VSI such aca73. This sociologist interviewed a sample of professionals in a Boston suburb who had recently relied on personal contacts to obtain their jobs. He asked them how often they saw the person before obtaining the job. The majority reported ‘occasionally’ and a significant fraction answered ‘rarely’. Job offers are more likely to come from old college friends, past workmates, and previous employers, than from close friends. Chance or mutual friends were the channels by which these connections were rediscovered. Granovetter described this phenomenon as the strength of weak ties .

He explained this result by depicting the circle of acquaintances of a hypothetical individual called Ego. Ego lives every day with his family and some close friends. Probably all these persons are also in close contact with each other. As a result, information travels fast in the group. So Ego is likely aware of all the news available in the group. On the contrary, weak ties connect him to faraway people. These individuals are not bounded by Ego’s social surroundings. Therefore they open a whole set of new groups to him, each of them encapsulating information otherwise inaccessible. Missing the opportunity of weak ties causes difficulties in organizations, companies, or institutions. Information and skills become trapped in one group, without reaching those who need them. So these things have to be reinvented or paid for from outside consultants. A former CEO of HP is reported to have lamented: ‘If HP only knew what HP knows!’ Granovetter’s intuition was later developed into the theory of social capital . This idea implies that the contacts of one person (and the contacts of these contacts) enable him or her to access resources that ultimately provide such things as better jobs and faster promotions. More generally, the position of an individual in his or her social network is crucial to determine future opportunities, constraints, outcomes, etc.

Measuring acquaintance is not easy, since it is such a subjective issue. Usually, maps such as the flowchart of a company are not very useful, because they do not correspond to the actual relations between workers. For this reason they are useless in helping us understand the channels (and possible bottlenecks) of information within the company. Scientists have devised a large set of alternative strategies to draw social networks, ranging from questionnaires to snowball sampling , a system in which an interviewed subject suggests somebody in their circle for the next interview. These strategies have enabled the collection of data as sensitive as the map of sexual intercourse between groups of different individuals (from high-school students in the US Midwest to people living in a village of Burkina Faso): the knowledge of these networks allows for better understanding of the spread of sexually transmitted diseases.

Another kind of relation that is relatively easy to pin down is professional collaboration. Such networks exist in several fields, ranging from Hollywood (two actors become connected if they play in the same movie) to science (two scientists become linked if they write a paper together). Collaborations can be found in more exotic environments such as politics (US senators have been connected on the basis of the co-sponsorship of laws) or terrorism (activists are connected on the basis of intelligence reports and legal documents).

Information technology provides a new and powerful way to measure interaction between people. Frequent phone calls and emails between two individuals, or friendship in virtual social networks like Facebook or LinkedIn, indicate a stable relationship and therefore an edge. More and more companies exploit the social networks of their customers to find su steps away (friends of friendsttguch information. For example, telephone companies are reported to target ‘influential’ individuals with offers and other strategies: these are the customers who, when they change company, trigger similar changes in their close connections.

## 3.5 Webs of words, webs of ideas

‘What shall King Henry be a pupil still / Under the surly Gloucester’s governance?’ says Queen Margaret in Part II of Shakespeare’s King Henry VI trilogy (Act I, Scene III). The queen complains about the influence of the duke of Gloucester on her husband, the king. What does she mean by ‘pupil’? A thesaurus suggests that pupil can be rephrased as scholar, acolyte, adherent, convert, disciple, epigone, liege man, partisan, votarist, or votary. This list provides a full spectrum of words to denote one person subjected to another. We can enlarge the spectrum by exploring all the words related to ‘pupil’ that is, its semantic area . These include faithful, loyalist, advocate, backer, supporter, satellite, yes-man … What role does the queen desire for her husband? Antonyms of ‘pupil’ suggest non-student, coryphaeus, leader, apostate, defector, renegade, traitor, and turncoat. Naturally, she is asking King Henry to rebel against the authority of the duke of Gloucester.

This is a simple example of how words link to each other. Indeed, a rigorous analysis should take into account the historical differences in the use of a word, the specific occurrence of a term in Shakespeare’s work, the context in which it is used in the script, and many other aspects. In any case, it is fair to say that we can better understand the meaning of a word if we take into account its ‘neighbours’ in language. Synonimity, antonymity , and semantic connection are just a few of the possible relations. Others are meronymity and hypernimity (‘beer’ is a meronym of ‘drink’ and the latter is a hypernym of the former). ‘Pupil’ provides a crystalclear example of another kind of connection. This term has two completely different meanings: it indicates both a student and a part of the eye. It is a case of polysemy . Of course, the context of Shakespeare’s dramas immediately determines the correct meaning. In general, context provides the exact meaning of words: the co-occurrence of words in sentences defines their meaning. Such a co-occurrence provides yet another relation between words. For example, the words ‘king’ and ‘Henry’ are much more likely to appear together in English sentences than ‘king’ and relativity, for example.

We can now create our own maps of language. We use words as vertices and the edges connect synonyms, antonyms, and polysemic words (these relations can be drawn from a thesasurus or a dictionary, while patterns of co-occurrence can be drawn from large language databases, such as the British National Corpus) . Semantic connections are more difficult to pin down: their study forms a complete area of linguistics. Some languages have special dictionaries that associate one word with a set of related ones. An alternative approach is experimental word association . A word is provided to a sample of people, asking them to say the first word that comes into their mind after hearing it. The resulting words are then used to repeat the association experiment. Proceeding in this way, step by step we build our web of associations. Different instances of word networks display different results. These depend on the language, on the kind of text, on the education of the author of the text, or may be related to linguistic dysfunctions. Archaeology

Word networks contain a lot of information, but usually they are not particularly useful in studying the actual content of the texts and the relations between the ideas expressed in different texts. This is a crucial issue for web queries, for example. Usually, complicated algorithms have to be implemented to perform this task. However, in some bodies of texts, a very precise network can be drawn. This is the case with scientific literature. Producing knowledge is never a solitary endeavour. A scientist is always ‘a dwarf standing on the shoulders of a giant’, as philosopher Bernard of Chartres is said to have pointed out for the first time in the 12th century. Scientists’ work almost always builds on previous results. Researchers recognize this by citing several older publications at the end of their papers. Citations provide recognition of relevant results of the past, give credibility to new results and make reference to facts, technologies, and experiments that are accepted as valid, or criticized, within a work. Publications have been extensively standardized in recent years: articles are mostly in English, control methods have been homogenized (mainly through peer review) , measures of impact have been devised, etc. At the same time, large electronic databases of publications have been established, with thousands of new items being added every day: articles, books, patents, projects, etc. All this produces a large network of publications: two items are connected if one of them cites the other. We can also identify authorship from these databases and create networks of collaborations between scientists. These systems are increasingly used to map and visualize the development of knowledge and the most active areas of science.

## 3.6 Money by wire

In 2008 a number of large financial institutions in the United States suddenly went bankrupt. In a few months, the majority of the developed world was involved in one of the largest financial crises ever seen. Much has been written on the causes of this crisis. What is certain is that it showed that economies are very tightly interconnected at a global level.

Classical economic theories represented economic actors as independent, completely rational agents, focused on maximizing their income. However, facts show that individuals, companies, institutions, and countries are not independent: everyone influences each other in many ways. Their behaviour, far from being completely rational, is strongly dependent on subjectivity, emotions, and reciprocal influence.

Lending money is one way in which companies and institutions can become tightly interconnected. An interesting case is the money exchanged on a daily basis between private banks so that it can be available to meet the possible requests of bank clients (becoming therefore more liquid) . If customer requests should exceed the liquidity reserve of a bank, that bank can ask other banks to lend money. Central banks worldwide require other banks to place a part of their deposits and debts with them, to create a buffer against liquidity shortages. In this sense, central banks ensure the stability of the banking system, thus avoiding liquidity shocks. The freezing of the interbank lending network was one of the first signals of the 2008 financial crisis.

An even stronger relation than lending money is given by shareholding , i.e. the direct participation of a company in another company’s capital. This means that the first company holds a part of the second one, and can exert influence on its main decisions. Shareholding is converted into control when a company holds the majority of stock, or when it is able to determine the vote of the majority of the board. In this case they did not know the recipient, scca, legally independent companies are converted into a business group. Often, these groups display a pyramidal structure, where a holding company is at the top, and operating companies are at the bottom of the control hierarchy.

The existence of business groups is explicit and legally regulated in most countries; but softer and less regulated forms of influence can exist. The most common of these happens within boards. Managers often sit on many boards at the same time. Obviously, they act as channels of information, alliances, or interests between boards. Their simultaneous presence in different boards establishes an interlock between their companies. If the companies are explicit competitors, this situation is clearly incompatible with a free market. A shared director will either favour one of the companies against the other or establish a cartel between them (which is generally ruled out by law). In general, such a director will find it very difficult to operate in the interest of all the investors in the different companies.

Further evidence of interconnectedness between companies is given by stock price correlations . Finance practitioners know that the stocks of companies operating in the same sector (e.g. mining, transport, services, food, etc.) change their prices in a somehow similar or ‘synchronized’ fashion. For example, stock prices of all the companies within the electronic sector (or any other) tend to decrease or increase at the same time. Financial analysts are interested in knowing how much of the change in a stock price is influenced by the change of another stock (in short, they want to know the correlation between stock prices). If this connection is strong enough, it is likely that the two companies are somehow connected. Lending money, shareholdings, shared directors, or stock price correlations are the main criteria by which a network between companies can be built: edges are drawn when one of these situations occurs.

The interconnectedness goes far beyond companies within one specific market. As the financial crisis has shown, events rapidly spread from national markets into the global scenario. One obvious channel by which this can happen is the import/export trade relationships among countries. This world trade web is a network in which nodes are countries and their trade relations define the edges. Like the cell, economies depend on these multiple layers of networks.

## 3.7 Critical infrastructures

On the night of 28 September 2003, lights went out across the whole of Italy, with the single exception of the island of Sardinia. It took several hours, in some places even days, to reinstate normal supply. Investigation showed that the blackout was triggered by a tree flashover close to a high-tension line between Italy and Switzerland. The resulting shortage of electric supply caused a sharp increase in demand on the remaining lines. As a result those lines collapsed, generating a ripple effect through the entire system.

Large-scale power outages reveal the connectedness of power grids. These systems deliver electricity across large distances from central points to cities and industrial areas. Carefully planned in the beginning, they grow more and more intricate over time. Nowadays, generators, transformers, and substations, connected by high-voltage transmission lines, constitute a network that spans several regions and often several countries (as the 2003 example shows). It is clear that such networks require careful maintenance to prevent criticalities.

Similar instabilities appear in a variety of other infrastructures. Communication systems, such as the telephone network$ such aca, are one example. But probably the most sensitive is the transportation network: streets, highways, and railways connecting cities, the web of boats transporting fuel and other goods, and above all the airport web. Planes transport billions of passengers and tonnes of goods every year. A minimal malfunction in such an infrastructure has major consequences: Eurocontrol (the European organization for the safety of air navigation) has estimated that delays in flights cost European countries up to €200 billion in 1999 alone. In a globalized world, transportation networks are similar to circulatory systems in living beings.

## 3.8 A net as large as the world

In October 1969, a message travelled for the first time from one computer to another, through a telephone line. Two university labs in California were at the ends of the line. After a few letters, the message broke down, but the connection was established: Arpanet, the grandfather of the Internet, was born. The idea of a network of computers was around during the previous decade. At the end of the fifties, ARPA (the US Advanced Research Project Agency) asked engineer Paul Baran to design a communication structure able to resist an attack. In particular, the whole system had to continue working even under an attack destroying part of it. Baran duly designed a distributed system with such characteristics—but a change in strategy locked his pioneering studies into a drawer. However, in the sixties, some universities asked ARPA to finance a similar project for different purposes. The academic institutions were keen to interconnect their computers in order to aggregate their computational power.

The 1969 Arpanet connected UCLA (University of California Los Angeles) and the SRI (Stanford Research Institute). Two years later, the number of nodes was over forty, including some companies and other universities. This structure was so successful that in the seventies similar networks appeared in other parts of the world, created by particle physicists, astronomers, companies: Hepnet, Span, Telenet, etc. If at the beginning the problem was to connect the computers, this moved on how to connect networks. Internetworking became the motto of many computer scientists. At the end of the seventies, engineer Robert Kahn and mathematician Vinton Cerf developed the TCP/IP: whatever the internal structure of networks, this software allows them to talk to each other. This code was put in the public domain and based on the concept of open architecture . Finally, in the eighties, the TCP/IP transition was fully achieved, bringing to creation the Internet, the ‘network of networks’.

Such a structure is probably the human artefact that best embodies the idea of networks. A computer connected to the Internet becomes one of many hosts . If we want to deliver an email to a specific place, we do not need to be directly connected with that destination. From origin to our target, information travels along routers , devices responsible for transmitting packets of data. A large series of connections keeps the structure linked: optical fibres, telephone lines, satellite connections, etc. Since nobody plans where hosts and connections are added, the overall structure of the Internet is not recorded. Actually, mapping at host level is practically impossible. We can have a rough representation of it only at router level. In this case, the nodes of these networks are the routers, and the edges are their connections. We can coarse-grain the structure even more, grouping routers into autonomous systems . These groups are autonomously administrated domains that usually correspond to Internet Service Providers (ISPs) and other organizations.

The great success of the Internet is due to the exceptional experience it provides. Watching television is a one-direction, one-medium, passive experience. The Internet is not so. People can navigate an infinite series of documents, use different media, exchange information, and talk to each other. Unlike traditional communication technologies such as telephone, radio, or television, the Internet does not have a specific purpose. Rather, it is a mutant artefact able to host infinite applications. Actually, the Internet is only a physical infrastructure that supports services. One of the most successful of these is the World Wide Web (WWW). This is an enormous set of electronic documents recorded in the devices that make up the Internet and connected by hyperlinks that allow navigation between them. The pattern is somewhat similar to the body of scientific literature, made of articles, books, patents, etc. connected by citations.

The idea of the WWW was born at CERN (European Organization for Nuclear Research). Physicist Tim Berners-Lee (later joined by computer scientist Robert Cailliau) put forward the proposal for it in 1989. Berners-Lee designed a system that allowed scientists to access, through their own computers, the enormous amount of data produced by particle physics experiments. The software to make this system work was not patented but rather released in the public domain. This decision—as in the case of TCP/IP—proved to be very significant. Right from the beginning, thousands (and then even greater numbers) of users tried it, improved it, and created web pages and services. In just a few years, the Web became World Wide. Its magnitude is unknown, since none of the search engines that explore the web (such as Google or Yahoo!) is able to archive all web pages. After all, this would make little sense: several websites are capable of producing new pages upon request. A 2005 estimate put the content of the whole WWW (for static pages) as equivalent to 200 terabytes of information. At the time, this was about ten times the size of the US Congress Library. Undoubtedly today’s figure would be greater by orders of magnitude, since the growth of the WWW is exponential.

## 3.9 Cyberspaces

On 11 September 2001, the infrastructures of New York City experienced a ‘network catastrophe’, parallel and related to the human tragedy that was taking place that same day. Soon after two hijacked airliners crashed into the World Trade Center complex, a surge in phone calls was registered. People were trying to communicate with friends, and rescue personnel with colleagues. Cell networks were quickly overloaded and people lined up at payphones in Manhattan. The attack damaged Verizon’s central office, interrupting 200,000 lines. AT&T infrastructures, some of them housed in the basement of the World Trade Center were destroyed as well. When calls failed, many people turned to the Internet. But wireless service was also impacted. The impact on the economy extended well beyond the crash sites. It took six days before the New York Stock Exchange could return to work. Months passed before services were restored to near pre-disaster levels.

The terrorist attacks showed that there is almost no network that stands alone. Physical and virtual infrastructures are embedded in a common cyberspace , where energy, information, transport, communication, etc. are provided. Power grids support the Internet, that hosts the WWW, that in its turn enables email services, social networks, information websites, and file-sharing systems. Many activities, including flight control, bank programs, emer However, the





思维之网

直到 18 世纪，「灵魂」可以体现在某个器官中都是一个奇怪的设想。但是，医生已经意识到中风或者其他脑损伤可能会危及关键的认知功能 一一 心与脑之间的关联从那时开始変得明显起来。当时，解剖学家弗朗茨·约瑟夫·加尔便敢于提出所有心理官能必然起源于大脑这种想法。他确定了大脑中的 27「器官」，每个器官分别负责颜色、声音、记忆、言语，以及友谊、仁慈、骄做等等。这种想法听起来如此异类，以至于加尔不得不逃离维也纳，进而在激进的法国找寻避难所

后来，几位生理学家试图通过比如从鸽子的大脑中去除切片这样的方式验证加尔的理论。然而，他们并未找到加尔所设想的器官存在的任何证据。因此，他们得出结论说，大脑是产生思想的一个均匀、未经分化的统一体：如其中一位生理学家所说，「大脑分泌思想就像肝脏分泌胆汁一样」。这种观念在 1860 年代保罗·布罗卡的研究出来之前一直占据主导地位。在表达性失语症患者的尸体解剖中，布罗卡总能在他们大脑左的额叶区域发现一些损伤。在确定了人们现在称其为布罗卡区域的大脑部分之后，他便宣称，「我们用左脑说话」。从那时起，神经学家找到了负责不同活动的多个功能中心，但他门也发现这些中心区域绝少孤立运转：大脑不同区域的整合对其功能而言至关重要。

网络在被划分为专门领域的大脑模式和作为整体的大脑模式之间架起了桥梁（这与社会科学的情并无不同，在这个领域中，网络允许我们从个人和共同体之间的某个层面描述社会）。大脑中遍布网络，其中的各种网状结构在专门的区域之间提供了整合。在小脑中，神经元形成了一个个不断重复的

模块：它们的相互作用被限制在了相邻的模块之间，这与晶格中发生的事情类似。而在大脑的其他区域，我们发现了随机连接现象，即局部、居间或者通远神经元之间的连接概率大致相等。最后，新皮质一哺乳动物的许多高级功能所涉及的区域一则将局部结构与更加随机且遥远的连接相结合。一些科学家认为这些线路体系可能负责主体意识：涌现的良知便可能是某种足够复杂的网络结构作用的结果

确定这些神经网络的实际结构十分困难，因为细胞数量巨大，并且探測它们困难重重。我们仅掌握了那些十分简单的生物的详细神经网络图，比如一种名为秀丽隐杆线虫的寄生线虫。这种一毫米长的透明生物能存活三周，它仅有 300 个神经元，却是分子生物学界的超级明星。秀丽隐杆线虫是一种模式生物，即特别适于实验的生物，因为科学家对其特征了如指掌，且它在某些方面与人体类似。这种半透明的蠕虫通常是新药和新疗法实验的第一个基准

目前，人们还不可能为人类大脑绘制类似的神经网络。然而，我们可以使用另外一种策略。当人们执行一个动作，即便简单如眨眼，来自神经元的电信号风暴就会在大脑中的数个区域爆发。这些区域可以通过诸如功能性磁共振这样的技术加以确认。通过这种技术，科学家发现不同的区域会发出相互关联的信号。也就是说，它们显示出某种特殊的同步现象，这表明它们可能相互影响。可将这些区域视为节点，而如果它们之间存在足够的相关性，则它们两两之间便可画上ー条边。同样在这个层次上，大脑表现为相互连接的元素集合。人的每个动作都会点亮脑中的某个连接区域

盖亚的血管

1999 年，日金山湾区经历了大规模的藻类暴发。通常，藻类的这种暴发是农业密集用地的结果：我们将氮、磷等化肥排入海中后，它们就会成为藻类的营物。然而，本案例中的情況并非如此，因为ー些政策和限制已经少了从不同河流排入海中的营养物染水平。加利福尼亚州的生态学家们通过搜集三十年的观察数据得出结论说，藻类暴发有着复杂得多的原因。1997 年和 1998 年，人们记录到了最强的「厄尔尼诺」现象之ー，紧随其后的便是 1999 年同样强大的「拉尼娜」现象。这些现象导致了当时加利福尼亚生态系统的变化。深海处冰冷的富营养化海水涌至海岸。这些营养物质吸引了海洋中的生物 一一 鲽鱼和甲売类动物 一一 进入湾区。这些动物是湾区双売类动物的捕食者，而后者反而是藻类蔓延的障碍。双壳类动物由于捕食者的 27 增加而种群崩溃，这成为藻类暴发的直接原因。触发这种多米诺效应的条件可能来自正常的气候波动。然而，其后果对人类而言却是一种警告：气候变化，特别是极端气候的频率增加，可能对生态系统产生意想不到的影响。

日金山湾区海藻暴发背后的核心结构是食物链 一一 一系列物种的连接：鍱鱼和甲壳类动物捕食双売类动物，双売类动物消耗藻类。生物以食物链的方式从彼此身上提取他们生存所需的能量和物质（这并非生态系内物种之间唯一可能的相互作用：生物体也可以建立互利的相互作用，比如开花植物与其授粉昆虫之间的相互作用）。每个食物链都从基位物种开始，比如植物和细菌。这些物种不会捕食其他物种，它们通过转化阳光、矿物质和水而直接从环境中获取资源。这些资源以接连的捕食方式沿着食物链顺次转移。中位物种既是捕食者也是猎物。而顶位物种（处于食物链顶端）则不被任何别的物种捕食。食物链帮助我们理解为何渔业会崩溃，比如 70 年代秘鲁鲥鱼产业的境。在大规模的无差别捕鱼期之后，像鱼或金枪鱼等捕食者就会大幅少。在这个阶段之后，捕鱼业则朝着更加基位的物种进发，比如鲥鱼。但这些物种也会迅速崩溃。原因在于，当大型捕食者被移出食物链之后，食物网下游的其他捕食者便会取而代之。后者往往是不可食用的鱼类：它们的种群没了限制之后，便会耗尽其他可食用的基位物种

生态系的实际情況甚至更为复杂：通常，食物链并不孤立存在，而是以复杂的模式彼此交织，其中的某个物种会同时属于多个食物链。例如，一个特化物种可能只捕食一种猎物（或者在一些情下仅捕食少数物种）。如果猎物灭绝，这个特定物种的种群就会崩溃，并导致一系列的共同灭绝。更加复杂的情况是，杂食动物捕食某种食草动物，而两者都吃某种植物。杂食动物种群的减少并不意味着植物的繁茂，因为食草动物将从这种物种減少中受益，进而消耗更多的植物

최5 英国某草原食物网：节点代表英格兰和威尔士一些草地中的物种，连线则由捕食者（较粗的一端）指向猎物（细的一端）

将更多的物种纳入考虑范围，种群动力机制会变得越发复杂。这便是为何对生态系統而言，食物网（图 5）是比「食物链」更为恰当的描述。这些网络中的节点是物种，连线表示它们之间的捕食关系。连线通常是有向的（大鱼吃小鱼，而非相反）。这些网络提供了物种之间的食物、能量和物质交换并因此构成了生物圈的循环系統。它们构成了地球的血管。

人类「角斗士」（网络人）

口口相传（word of mouth）是获得有关白领职位空缺信息的惯常方式。所以，如果我们正在寻找这种工作，在亲友之间传递相关信息则不啻为一个好主意。不那么明显的是，我们将信息告知远方不常见面的熟人甚至会有更好的效果。这便是马克·格兰诺维特于 1973 年提出的观点。这位社会学家采访了波士顿郊区职业人士这一样本，他们当时都依靠个人联系获得了各自的工作。格兰诺维特问他们在获得工作之前与提供工作的人的联系频率。多数人的答复是「偶尔」，许多人的回答是「绝少」。与亲密的朋友相比，工作机会更可能来自旧时的校友、过去的同事和以前的雇主。运气或共同的朋友则是再现这些联系的管道。格兰诺维特将这种现象描述为弱连带优势

格兰诺维特通过描述一位假想中的名为埃戈的人的熟人来解释这种结果。埃戈每天都和家人及一些亲密的朋友生活在一起。所有这些人很可能也彼此联系紧密。其结果便是，信息会在这群人中快速传播。因此，埃龙可能知道这群人中的所有新鲜事。与此相反，较弱的人际联系也会将他与遥远的人联系起来。这些人并不会受到埃戈社交环境的限制。因此，他们向他开放了一组新的群体集合，每一群人都封装着别的群体无法获取的信息。弱联系的缺失会为组织、公司或机构带来各种困难。信息和技术被限制在一个群体之内，而没有抵达那些需要它们的人手中。因此，这些东西需被重新创造或从外部顾问处有偿获得。据报道，普的前首席执行官曾感叹道：「惠普不能闭目塞听！」格兰诺维特的直觉后来发展成为社会资本理论

这种想法意味着一个人的联系人（以及这些联系人的联系人）使他或她能够获取那些最终可以提供更好工作和更快升迁的资源。更普遍的是，个人在他或她的社交网络中的位置对于定其未来的机会、限制和成果而言至关重要

衡量交情并不容易，因为它是十分主观的事情。通常，像公司流程图之类的图谱并不是很有用，因为它们并不对应着员工之间的实际关系。正因为如此，流程图并不能帮助我们了解公司内部的信息渠道（以及可能的瓶颈）。科学家们设计了大量的替代策略来绘制社交网络，从问卷调查到雪球式抽样，即系统中的每个受访者都推荐自己圏子里的某人为下一个采访对象

这些策略使得数据的搜集就像不同个体（从美国中西部的高中生到非洲布基纳法索的村民）所组成的群体之间的性行为图那般敏感：有关这些关系网络的知识能让人们更好地理解性传擂疾病的蔓延。

另外一种相对容易定义的关系则是专业协作。这样的网络存在于多个领域，从好坞（如果两个演员出演同一部电影，他们便会产生联系）到科学领域（如果两位科学家共同撰写一篇论文，他们也会产生联系）。合作还能在更不寻常的环境中找到，比如政治（美国参议员会在支持共同法律的基础上生联系）或者恐怖主义活动（恐佈分子则基于情报和法律文件相互联系）中。

信息技术为衡量人际互动提供了一种强大的新手段。两人之间频繁的电话和邮件往来，或者在脸书、领英等虚拟社交网络中的友谊等，都表明了一种稳定的关系和网络图中的一条边。越来越多的公司利用他们客户的社交网络来找寻这样的信息。例如，据报道，电话公司会以提供工作机会或别的策略来瞄准「有影响力」的个人：当这些客户改换公司的时候，就会在他们的密切联系人中触发类似的变化

语词之网，思想之网

玛格莱特王后在莎翁的《亨利六世》三部曲的中篇（第一幕，第三场）里说道：「难道说，亨利王上老要在乖戾的葛罗斯特管辖之下当小学生吗？」1 王后抱怨葛罗斯特公爵对其国王丈夫的影响。她用「小学生」（pupil）表达的是什么意思？分类词典表明，「pupi 还可以表述为 scholar（学者） acolyte（助手）、adherent（信徒）、convert（皈依者）、disciple（】徒）、epigone（追随者）、liege man（臣下）、partisan（党羽）、votarist（拥护者）或者 votary（崇拜者）等等。这个清单为「ー个人从属于另外一个人」这项语义提供了一幅全景语词图谱。我们可以通过探索与「pupil 相关的语词即其语义区来扩展这一图谱。其他的语词包括 faithful（信徒）、loyalist（忠诚者）、advocate（倡导者）、backer（赞助者）、supporter（支持者）、satellite（随从）、yes-man（唯唯诺诺之人）那么，王后意欲用何种意义指谓其夫君呢？"pupi 的反义词表示 non- student（非学生） coryphaeus（领导者）、leader（首领）、apostate（变节者）、defector（背叛者）、renegade（叛徒）、traitor（背信弃义之人）以及 turncoat（叛贼）等。当然，她在要求亨利国王反对葛罗斯特公爵的权威。

这是语词之间如何相互联系的一个简单例子。事实上，严格的分析应该将语词使用的历史差异、莎士比亚作品中某个语词的特定出现、它在剧本中使用的语境，以及其他诸多方面都考虑进来。公平地讲，在任何情況下，我们都可以更好地理解语词的含义，若我们将其在语言中的「邻居」考虑进来的

话。同义、反义以及语义联系仅仅是语词间少数几种可能的联系。其他则包括整体部分关系和上下位关系等（「啤酒」是「料」的一部分，后者则是前者的上位词）。「pupi' 为语词间的另一种联系提供了清晰明了的例子。这个语词有着然不同的两种含义：它表示学生，也表示眼的一部分。。这便

是一词多义的情。自然，莎翁的戏剧语境当下就决定了其正确的含义。一般来说，上下文提供了语词的具体含义：句子中语词的共现定义了它们自身的含义。如比的共现提供了语词的另外一种关系。例如，语词「国王」和「亨利」在英语句子中就比「国王」和「相对论」一起出现的可能性要大得多

我们现在可以创建自己的语言地图。我们用语词作为顶点，同义词、反义词和多义词（这些语词关系可按照分类词典或一般词典绘制，而共现的模式则可从大型语言数据库中获取，比如英国国家语料库）则由边来连接。语义联系更加难以确定

对它们的研究构成了一个完整的语言学领域。一些语言具备将一个语词与一组相关语词联系起来的特殊词典。另外个替代方案便是词汇联想实验。一个语词被提供给样本中的一群人，要求他们说出听到这个语词之后想到的第一个语词。得出的语词接着又被用来重复这个联想实验。以这种方式，我们可以一步步建立自己的语词联系之网。语词网络的不同实例代表了不同的结果。这取決于语言本身、文本的类型、文本作者所受的教育，或许它与语言功能障碍也有关系

语词网络包含大量信息，但通常，这些信息在研究文本的具体内容和不同文本所表达的思想之间的关系时并不是特別有用。这是一个关键问题，比如对网络查询来说，通常，人们必须引入复杂的算法来执行该任务。然而，在一些文本中，人们可以绘制十分精确的网络。科学文献中即是如此。生产知识从来不是单个人的努力。如哲学家沙特尔的伯纳德在 12 世纪首次指出的那样，科学家总是「站在巨人肩膀上的矮子」。科学家的工作几乎总是建立在先前的结果之上。研究者们认识到了这一点，他们会在其论文未尾引用一些较早的出版物。引用提供了对过往相关成果的认可，赋予新的成果以可信度，并参考那些在某项研究中被接纳为有效或被批判过的事实、技术和实验。近年来，出版物在很大程度上实现了标准化：文章大多以英文写成，控制方法已经同质化（主要以同行评议的方式），文章影响力的衡量标准也已制定等。同时，出版物的大型电子数据库业已建立，其中每天都会增加上千个新项目文章、书籍、专利和工程等等。所有这些生成了个大型的出版网络：如果一个项目引用另外一个，则它们相互关联。我们还可从这些数据库中识别作者身份，并创建科学家之间的协作网络。人们越来越多地利用这些系统绘制知识发展和科学最活跃领域的图景，并将其可视化

互联的货币

2008 年，美国的一些大型金融机构突然破产。几个月的时间里，大多数发达国家都卷入了这场史上最严重的金融危机之ー。关于这场危机的原因已经有过很多分析了。可以肯定的是，它表明经济在全球层面的相互关联已十分紧密。

古典经济理论将经済参与者表示为独立、完全理性的行为者，他们专注于最大化自己的收入。然而，事实表明个人、公司、机构和国家并非相互独立：每一方都以多种方式彼此影响着。他们的行为远非完全理性，而是强烈地依赖于主观态度、情感和相互影响。

货款是公司和机构能够紧密互联的方式之ー。一个有趣的例子是私人银行间日常会进行货币交，以便能够满足银行客户的可能要求（因此变得更具流动性）。如果客户的要求超过了某银行的流动性储备，该银行可以向其他银行借款。世界各地的中央银行会要求其他银行将其存款和债务的一部分置于它们那里，以创造一个应对流动性不足的缓冲器。在这个意义上，中央银行确保了银行系统的稳定性，从而避免了流动性冲击。同业拆借网络的冻结是 2008 年金融危机的最初信号之ー。

で、与货款相比，持股，即某公司资本直接加入到另一个公司中，能够带来甚至更加紧密的联系。这意味着一家公司持有第二家公司的一部分，并能对其主要決策施加影响。当某公司持有大部分股票，或当它能够決定事会多数成员的投票时，持股就转变为控股。在这种情下，法律上独立的公司便转化为商业集团。通常，这些集团展现了某种金字塔结构，其中控股公司的权力在顶部，运作公司则处于控制层级的底部

在大多数国家，商业集团以具体形式存在，并在法律上受到监管；但是更软性和更少规制的影响形式也可能存在。这在董事会内部最为常见。管理者经常同时在多个公司的董事会任职。显然，他们扮演着董事会之间信息、联盟或者利益的交换渠道。他们在不同董事会中的同时任职为相关公司之间建立了连锁关系。如果这些公司是明确的竟争者关系，这种情况则明显与自由市场不兼容。共同的董事要么支持其中一个公司而打压另一个，要么在公司之间建立垄断联盟（这通常会被法律排除掉）。一般而言，这样的董事会发现自己身陷来自不同公司的投资者之间的利益纠缠之中而难以运作。

公司之间相互关联的进一步证据来自股票价格的相关性。财务人员知道在同一行业（例如采矿、运输、服务、食品等）经营的公司的股票会以某种类似或「同步」的方式改变价格。例如，电子行业（或任何其他行业）内所有公司的股票价格往往同时降低或升高。金融分析师则有兴趣知晓某只股票的价格变动在何种程度上受另ー只股票价格变动的影响（总之，他们想知道股票价格之间的相关性）。如果这种联系足够强，则很可能这两个公司以某种方式相互关联着。货款、持股、共享董事或股票价格的相关性是公司之间能够建立网络的主要标准：当出现这些情况之一时，则绘出网络图中的边

互联互通远远超出了某个特定市场中的公司。正如金融危机所展现的，事件会迅速地从国家市场范围扩展为全球局面。这种情况能够发生的一个明显途径是国家之间的进出口贸易关系。这种世界贸易网是一种以国家为节点，以贸易关系为边的网络。就像细胞一样，经济依赖于这些网络的多层结构。

关键的基础设施

2003 年 9 月 28 日晚，整个意大利的灯火都熄灭了，唯一的例外是撒丁岛。恢复正常供电耗费了数小时，有些地方甚至花费了数天时间。调查发现，这场停电由发生在意大利与瑞士之间高压线路邻近处的树木闪燃引发。由此造成的供电不足导致人们对剩余线路的供电需求猛增。结果，这些线路崩溃了，并在整个电力系统中产生了某种涟漪效应

大规模的停电掲示了电网的连通性。这些系统跨越很远的距离将电力从中心点传输至城市和工业区域。一开始的电网规划很周密，这些电网随着时间的推移而越发复杂。如今，由高压输电线路连接的发电机、变压器和变电站组成的电力网络跨越数个地区，通常是数个国家（正如 2003 年的例子所展现的那般）。很明显，这种网络需要仔细维护以防止危急情况。

类似的不稳定性出现在各种其他基础设施中。电话网络这样的通信系统便是一例。但可能最敏感的是交通网络：街道、高速公路和连接城市的铁路，运输燃料和其他货物的船只网络，最重要的则是机场网络。飞机每年运输数十亿乘客以及成吨的货物。这种基础设施中的一次微小故障都会产生重大后果：据欧洲空中航行安全组织估计，航班延误给欧洲国家造成的损失仅在 1999 年就高达 2000 亿欧元。在全球化的世界中，交通网络的作用类似于生物体内的循环系统。

如世界般巨大之网

1969 年 10 月，一条信息首次通过电话线从一台计算机传至另外一台。加利福尼亚州的两个大学实验室位于这条电话线的两端。几个字母的传之后，信息中断了，但连接业已建立：互联网的前身阿帕网（Arpanet）诞生了。关于计算机网络的设想在过去十年里一直都有。50 年代末，美国国防部高研究计划署（JS Advanced Research Project Agency, ARPA）要求工程师保罗·巴兰设计能够抵抗攻击的通信架构。尤其是即便在其部分正受破坏的情況下，整个系統还必须继续工作。巴兰恰当地设计了具备这种特征的分布式系统一但策略上的调整使得他的开创性研究被束之高阁。然而，在 60 年代，一些大学为了其他目的而要求 ARPA 资助一个类似的项目。学术机构渴望相互连接它们的计算机，以便汇聚其计算能力

1969 年，阿帕网连接了加州大学洛杉矶分校和斯坦福研究所。两年之后，阿帕网的节点数已超过 40 个，包括一些公司以及其他大学。这种通信架构是如此成功，以至于在 70 年代，由粒子物理学家、天文学家和一些企业创建的类似网络，如高能物理网、Span 网、远程网等纷纷出现在了世界其他地 方。如果说一开始的问题在于连接计算机，后来则转向了如何连接各种网络。网际互连成为许多计算机科学家的座右铭。70 年代末，工程师罗伯特·卡恩和数学家文顿·瑟夫开发了传输控制协议 / 互联网协议（TCP/IP）：无论何种网络内部架构，这个软件都允许它们彼此交换信息。这个代码基于开放体系 结构的概念，并被应用于公共领域。最终在 80 年代，TCP/IP 转换完全实现，互联网「众网之网」一由此证生

这一结很可能是最能体现网络思想的人工制品。一台连接到互联网的计算机即成为众多主机之一。如果要向特定地点发送电子邮件，我们并不需要直接与该目的地相互关联。从原点到我们的目标，信息沿着路由器这种负责传送数据包的设备传播。大量的连接使结构内部相互关联：光纤、电话线卫星连接等。因为没人筹划过哪里应该增加主机和连接，人们并未记录互联网的大致结构。实际上，绘制主机层面的图景是不可能的，我们只能在路由器层面对其进行大致的呈现。在这种情况下，这些网络的节点便是路由器，它们的连接就是边。我们甚至可将结构更加粗粒度化，将路由器编组至自治系统中。这些组便是自主管理的域，通常对应于互联网服务提供商和其他组织

互联网的巨大成功在于它提供的卓越体验。观看电视乃单向、单媒体的被动体验。互联网并非如此。人们可以浏览无数的文档，使用不同的媒体，交换信息，并相互交谈。与传统的通信技术，比如电话、无线电或电视不同，互联网并没有特定的目的。相反，它是一个能够容纳无数设备的异形人工制品。实际上，互联网仅仅是一个支持各种服务的物理基础设施。其中最成功的乃是万维网（WW）。这是一组巨大的电子文档，被记录在组成互联网的设备之中，并通过那些为它们提供导航的超链接相互关联。这种模式有些类似于由文章、书籍、专利等组成，且经引用而相互关联的科学文献整体

万维网的想法诞生于欧洲核子研究组织。物理学家蒂姆·伯纳斯一李（计算机科学家罗伯特·卡约后来也加入进来）于 1989 年提出了这一想法。伯纳斯一李设计了ー个允许科学家们通过自己的计算机访问粒子物理实验所得出的大量数据的系统。让这一系统得以运转的软件并未申请专利，而是被公开发 行。这一決定 一一 就像 TCP/IP 的例子一样一被证明意义重大。从一开始，成千上万（之后甚至更多）的用户便对其进行了试用和改进，进而创建了各种网页和服务。短短几年之内，网络覆盖了整个世界。它的量级无人知晓，因为任何探索网络的搜索引擎（比如谷歌或雅虎）都无法归档所有网页。毕竟，这也没什么意义：几个网站一经请求就能生成新的页面。一项 2005 年的评估认为，整个万维网（对于静态页面而言）的内容相当于 200 太字节的信息。当时，这个数据量大约相当于 10 个美国国会图书馆。亳无疑问，如今这一数字会比之前多出若干数量级，因为万维网的信息量增长呈指数级

赛博空间

2001 年 9 月 11 日，约市的基础设施经历了次「网络灾难」，这一灾难与当天发生的人类悲剧有关且类似。在两架被劫持的飞机撞向世贸中心大度之后不久，记录显示通话数量激增。入们试图与朋友取得联系，并与同事ー道救援相关人员。手机网络很快超载，人们纷纷在曼哈顿的付费电话旁排队等

欠袭击破坏了威瑞森的总部，切断了 20 万条线路。美国电话电报公司的基础设施，包括那些设置在世贸中心地下室的也遭到损毁。当电话呼叫失败时，许多人便求助于互联网。但无线服务也受到影响。而袭击对经济的影向则远远超出事故地之外。纽约证券交易所耗时六天才重新恢复运转各种服务直到数月之后才恢复至灾难前的水平

这场恐怖袭击表明，几乎没有任何网络能够独立存在。物理和虚拟的基础设施已嵌入公共赛博空间（cyberspace），并在其中提供能量、信息、传输和通信等服务。电网支撑着互联网，互联网存储万维网，万维网又让邮件服务、社交网络、信息网站和文件共享系统运转起来。许多活动，包括飞行管控、银行项目、应急系统和商业服务等也依赖万维网。赛博空间中某个层面的崩溃通常会以相当不可预知的方式影响到其他层面。

多个网络的相互连接在许多其他情况下也很常见。例如，影响 2008 年经济的流动性冲击迅速蔓延至其他许多经济网络之中。类似地，社交网络也在许多方面显示出这种特征。一个有趣的例子是真实世界的友谊与虚拟社交网络的联系相比较而显示的特征：这两个网络之间有着重要的反馈机制。细胞则是微型赛博空间：基因调控网络、蛋白质相互作用网络和代谢网络之间彼此嵌套。因此，一些科学家提出将基因组、蛋白质组、代谢组等相关概念融合为相互作用组这一综合概念。最后，生态系统可被看作是相互作用的网络组。例如，对抗和共生网络都在决定物种如何繁盛方面发挥着自己的作用。在所有这些情况下，网络为解开相互交织的复杂系统提供了有用的图景。