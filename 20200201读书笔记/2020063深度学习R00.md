## 记忆时间

## 卡片

### 0101. 主题卡——

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

### 0201. 术语卡——

根据反常识，再补充三个证据——就产生三张术语卡。

例子。

### 0202. 术语卡——

### 0203. 术语卡——

### 0301. 人名卡——

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

维基百科链接：有的话。

#### 01. 基本信息

用一句话描述你对这个大牛的印象。

#### 02. 贡献及著作

### 0401. 金句卡——

最后根据他写的非常震撼的话语——产生一张金句卡。

### 0501. 行动卡——

行动卡是能够指导自己的行动的卡。

### 0601. 任意卡——

最后还有一张任意卡，记录个人阅读感想。

《深度学习》由全球知名的三位专家 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 撰写，是深度学习领域奠基性的经典教材。全书的内容包括 3 个部分：第 1 部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识；第 2 部分系统深入地讲解现今已成熟的深度学习方法和技术；第 3 部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。《深度学习》适合各类读者阅读，包括相关专业的大学生或研究生，以及不具有机器学习或统计背景、但是想要快速补充深度学习知识，以便在实际产品或平台中应用的软件工程师。

## 作者简介

Ian Goodfellow，谷歌公司（Google）的研究科学家，2014 年蒙特利尔大学机器学习博士。他的研究兴趣涵盖大多数深度学习主题，特别是生成模型以及机器学习的安全和隐私。Ian Goodfellow 在研究对抗样本方面是一位有影响力的早期研究者，他发明了生成式对抗网络，在深度学习领域贡献卓越。

Yoshua Bengio，蒙特利尔大学计算机科学与运筹学系（DIRO）的教授，蒙特利尔学习算法研究所（MILA）的负责人，CIFAR 项目的共同负责人，加拿大统计学习算法研究主席。Yoshua Bengio 的主要研究目标是了解产生智力的学习原则。他还教授「机器学习」研究生课程（IFT6266），并培养了一大批研究生和博士后。

Aaron Courville，蒙特利尔大学计算机科学与运筹学系的助理教授，也是 LISA 实验室的成员。目前他的研究兴趣集中在发展深度学习模型和方法，特别是开发概率模型和新颖的推断方法。Aaron Courville 主要专注于计算机视觉应用，在其他领域，如自然语言处理、音频信号处理、语音理解和其他 AI 相关任务方面也有所研究。

## 译者序 —— 青山遮不住，毕竟东流去

深度学习这个术语自 2006 年被正式提出后，在最近 10 年得到了巨大发展。它使人工智能（AI）产生了革命性的突破，让我们切实地领略到人工智能给人类生活带来改变的潜力。2016 年 12 月，MIT 出版社出版了 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville 三位学者撰写的《Deep Learning》一书。三位作者一直耕耘于机器学习领域的前沿，引领了深度学习的发展潮流，是深度学习众多方法的主要贡献者。该书正应其时，一经出版就风靡全球。

该书包括 3 个部分，第 1 部分介绍基本的数学工具和机器学习的概念，它们是深度学习的预备知识。第 2 部分系统深入地讲解现今已成熟的深度学习方法和技术。第 3 部分讨论某些具有前瞻性的方向和想法，它们被公认为是深度学习未来的研究重点。因此，该书适用于不同层次的读者。我本人在阅读该书时受到启发良多，大有裨益，并采用该书作为教材在北京大学讲授深度学习课程。

这是一本涵盖深度学习技术细节的教科书，它告诉我们深度学习集技术、科学与艺术于一体，牵涉统计、优化、矩阵、算法、编程、分布式计算等多个领域。书中同时也蕴含了作者对深度学习的理解和思考，处处闪烁着深刻的思想，耐人回味。第 1 章关于深度学习的思想、历史发展等论述尤为透彻而精辟。

作者在书中写到：「人工智能的真正挑战在于解决那些对人来说很容易执行、但很难形式化描述的任务，比如识别人们所说的话或图像中的脸。对于这些问题，我们人类往往可以凭直觉轻易地解决」。为了应对这些挑战，他们提出让计算机从经验中学习，并根据层次化的概念体系来理解世界，而每个概念通过与某些相对简单的概念之间的关系来定义。由此，作者给出了深度学习的定义：「层次化的概念让计算机构建较简单的概念来学习复杂概念。如果绘制出表示这些概念如何建立在彼此之上的一幅图，我们将得到一张‘深’（层次很多）的图。由此，我们称这种方法为 AI 深度学习（deep learning）」。

作者指出：「一般认为，到目前为止深度学习已经经历了三次发展浪潮：20 世纪 40 年代到 60 年代深度学习的雏形出现在控制论（cybernetics）中，20 世纪 80 年代到 90 年代深度学习以联结主义（connectionism）为代表，而从 2006 年开始，以深度学习之名复兴」。

谈到深度学习与脑科学或者神经科学的关系，作者强调：「如今神经科学在深度学习研究中的作用被削弱，主要原因是我们根本没有足够的关于大脑的信息作为指导去使用它。要获得对被大脑实际使用算法的深刻理解，我们需要有能力同时监测（至少是）数千相连神经元的活动。我们不能够做到这一点，所以我们甚至连大脑最简单、最深入研究的部分都还远远没有理解」。值得注意的是，我国有些专家热衷倡导人工智能与脑科学或认知学科的交叉研究，推动国家在所谓的「类脑智能」等领域投入大量资源。且不论我国是否真有同时精通人工智能和脑科学或认知心理学的学者，至少对交叉领域，我们都应该怀着务实、理性的求是态度。唯有如此，我们才有可能在这一波人工智能发展浪潮中有所作为，而不是又成为一群观潮人。

作者进一步指出：「媒体报道经常强调深度学习与大脑的相似性。的确，深度学习研究者比其他机器学习领域（如核方法或贝叶斯统计）的研究者更可能地引用大脑作为参考，但大家不应该认为深度学习在尝试模拟大脑。现代深度学习从许多领域获取灵感，特别是应用数学的基本内容如线性代数、概率论、信息论和数值优化。尽管一些深度学习的研究人员引用神经科学作为重要的灵感来源，然而其他学者完全不关心神经科学」。的确，对于广大青年学者和一线的工程师来说，我们是可以完全不用因为不懂神经（或脑）科学而对深度学习、人工智能踯躅不前。数学模型、计算方法和应用驱动才是我们研究人工智能的可行之道。深度学习和人工智能不是飘悬在我们头顶的框架，而是立足于我们脚下的技术。我们诚然可以从哲学层面或角度来欣赏科学与技术，但过度地从哲学层面来研究科学问题只会导致一些空洞的名词。

关于人工神经网络在 20 世纪 90 年代中期的衰落，作者分析到：「基于神经网络和其他 AI 技术的创业公司开始寻求投资，其做法野心勃勃但不切实际。当 AI 研究不能实现这些不合理的期望时，投资者感到失望。同时，机器学习的其他领域取得了进步。比如，核方法和图模型都在很多重要任务上实现了很好的效果。这两个因素导致了神经网络热潮的第二次衰退，并一直持续到 2007 年」。「其兴也悖焉，其亡也忽焉」。这个教训也同样值得当今基于深度学习的创业界、工业界和学术界等警醒。

我非常荣幸获得人民邮电出版社王峰松先生的邀请来负责该书的中文翻译。我是 2016 年 7 月收到王先生的邀请，但那时我正忙于找工作，无暇顾及。然而，当我和我的学生讨论翻译事宜时，他们一致认为这是一件非常有意义的事情，表达愿意来承担。译稿是由我的四位学生赵申剑、黎彧君、符天凡和李凯独立完成的。申剑和天凡是二年级的硕士生，而李凯和彧君则分别是二年级和三年级的直博生。虽然他们在机器学习领域都还是新人，其知识结构还不全面，但是他们热情高涨、勤于学习、工作专注、执行力极强。他们通过重现书中的算法代码和阅读相关文献来加强理解，在不到三个月的时间就拿出了译著的初稿，之后又经过自校对、交叉校对等环节力图使译著保持正确性和一致性。他们自我协调、主动揽责、相互谦让，他们的责任心和独立工作能力让我倍感欣慰，因而得以从容。

由于我们无论是中文还是英文能力都深感有限，译文恐怕还是有些生硬，我们特别担心未能完整地传达出原作者的真实思想和观点。因此，我们强烈地建议有条件的读者去阅读英文原著，也非常期待大家继续指正译著，以便今后进一步修订完善。我恳请大家多给予 4 位译者以鼓励。请把你们对译著的批评留给我，这是我作为他们的导师必须要承担的，也是我对王峰松先生的信任做出的承诺。

当初译稿基本完成时，我们决定把它公开在 GitHub 上，希望通过广大读者的参与来完善译稿。令人惊喜的是，有上百位热心读者给予了大量富有建设性的修改意见，其中有 20 多位热心读者直接帮助润色校对（详见中文版致谢名单）。可以说，这本译著是大家共同努力的结晶。这些读者来自一线的工程师和在校的学生，从中我领略到了他们对深度学习和机器学习领域的挚爱。更重要的是，我感受到了他们开放、合作和奉献的精神，而这也是推动人工智能发展不可或缺的。因此，我更加坚定地认为中国人工智能发展的希望在于年青学者，唯有他们才能让我国人工智能学科在世界有竞争力和影响力。

江山代有人才出，各领风骚数十年！

张志华代笔

2017 年 5 月 12 日于北大静园六院

