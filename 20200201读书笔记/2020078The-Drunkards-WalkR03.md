# 2020078The-Drunkards-WalkR03

## 记忆时间

## 目录

0501 The Dueling Laws of Large and Small Numbers

0601 False Positives and Positive Fallacies

## 0501. The Dueling Laws of Large and Small Numbers

IN THEIR WORK, Cardano, Galileo, and Pascal assumed that the probabilities relevant to the problems they tackled were known. Galileo, for example, assumed that a die has an equal chance of landing on any of its six faces. But how solid is such「knowledge」? The grand duke's dice were probably designed not to favor any face, but that doesn't mean fairness was actually achieved. Galileo could have tested his assumption by observing a number of tosses and recording how often each face came up. If he had repeated the test several times, however, he would probably have found a slightly different distribution each time, and even small deviations might have mattered, given the tiny differential he was asked to explain. In order to make the early work on randomness applicable to the real world, that issue had to be addressed: What is the connection between underlying probabilities and observed results? What does it mean, from a practical point of view, when we say the chances are 1 in 6 a die will land on 2? If it doesn't mean that in any series of tosses the die will land on the 2 exactly 1 time in 6, then on what do we base our belief that the chances of throwing a 2 really are 1 in 6? And what does it mean when a doctor says that a drug is 70 percent effective or has serious side effects in 1 percent of the cases or when a poll finds that a candidate has support of 36 percent of voters? These are deep questions, related to the very meaning of the concept of randomness, a concept mathematicians still like to debate.

I recently engaged in such a discussion one warm spring day with a statistician visiting from Hebrew University, Moshe, who sat across the lunch table from me at Caltech. Between spoonfuls of nonfat yogurt, Moshe espoused the opinion that truly random numbers do not exist.「There is no such thing,」he said.「Oh, they publish charts and write computer programs, but they are just fooling themselves. No one has ever found a method of producing randomness that's any better than throwing a die, and throwing a die just won't do it.」

Moshe waved his white plastic spoon at me. He was agitated now. I felt a connection between his feelings about randomness and his religious convictions. Moshe is an Orthodox Jew, and I know that many religious people have problems thinking God can allow randomness to exist.「Suppose you want a string of N random numbers between 1 and 6,」he told me.「You throw a die N times and record the string of N numbers that comes up. Is that a random string?」

No, he claimed, because no one can make a perfect die. There will always be some faces that are favored and some that are disfavored. It might take 1,000 throws to notice the difference, or 1 billion, but eventually you will notice it. You'll see more 4s than 6s or maybe fewer. Any artificial device is bound to suffer from that flaw, he said, because human beings do not have access to perfection. That may be, but Nature does, and truly random events do occur on the atomic level. In fact, that is the very basis of quantum theory, and so we spent the rest of our lunch in a discussion of quantum optics.

Today cutting-edge quantum generators produce truly random numbers from the toss of Nature's perfect quantum dice. In the past the perfection necessary for randomness was indeed an elusive goal. One of the most creative approaches came from New York City's Harlem crime syndicates around 1920.1 Needing a daily supply of five-digit random numbers for an illegal lottery, the racketeers thumbed their noses at the authorities by employing the last five digits of the U.S. Treasury balance. (At this writing the U.S. government is in debt by `$`8,995,800,515,946.50, or `$`29,679.02 per person, so today the racketeers could have obtained their five digits from the per capita debt!) Their so-called Treasury lottery ran afoul of not only criminal law, however, but also scientific law, for according to a rule called Benford's law, numbers arising in this cumulative fashion are not random but rather are biased in favor of the lower digits.

Benford's law was discovered not by a fellow named Benford but by the American astronomer Simon Newcomb. Around 1881, Newcomb noticed that the pages of books of logarithms that dealt with numbers beginning with the numeral 1 were dirtier and more frayed than the pages corresponding to numbers beginning with the numeral 2, and so on, down to the numeral 9, whose pages, in comparison, looked clean and new. Assuming that in the long run, wear was proportional to amount of use, Newcomb concluded from his observations that the scientists with whom he shared the book were working with data that reflected that distribution of digits. The law's current name arose after Frank Benford noticed the same thing, in 1938, when scrutinizing the log tables at the General Electric Research Laboratory in Schenectady, New York. But neither man proved the law. That didn't happen until 1995, in work by Ted Hill, a mathematician at the Georgia Institute of Technology.

According to Benford's law, rather than all nine digits' appearing with equal frequency, the number 1 should appear as the first digit in data about 30 percent of the time; the digit 2, about 18 percent of the time; and so on, down to the digit 9, which should appear as the first digit about 5 percent of the time. A similar law, though less pronounced, applies to later digits. Many types of data obey Benford's law, in particular, financial data. In fact, the law seems tailor-made for mining large amounts of financial data in search of fraud.

One famous application involved a young entrepreneur named Kevin Lawrence, who raised `$`91 million to create a chain of high-tech health clubs.2 Engorged with cash, Lawrence raced into action, hiring a bevy of executives and spending his investors' money as quickly as he had raised it. That would have been fine except for one detail: he and his cohorts were spending most of the money not on the business but on personal items. And since several homes, twenty personal watercraft, forty-seven cars (including five Hummers, four Ferraris, three Dodge Vipers, two DeTomaso Panteras, and a Lamborghini Diablo), two Rolex watches, a twenty-one-carat diamond bracelet, a `$`200,000 samurai sword, and a commercial-grade cotton candy machine would have been difficult to explain as necessary business expenditures, Lawrence and his pals tried to cover their tracks by moving investors' money through a complex web of bank accounts and shell companies to give the appearance of a bustling and growing business. Unfortunately for them, a suspicious forensic accountant named Darrell Dorrell compiled a list of over 70,000 numbers representing their various checks and wire transfers and compared the distribution of digits with Benford's law. The numbers failed the test.3 That, of course, was only the beginning of the investigation, but from there the saga unfolded predictably, ending the day before Thanksgiving 2003, when, flanked by his attorneys and clad in light blue prison garb, Kevin Lawrence was sentenced to twenty years without possibility of parole. The IRS has also studied Benford's law as a way to identify tax cheats. One researcher even applied the law to thirteen years of Bill Clinton's tax returns. They passed the test.4

Presumably neither the Harlem syndicate nor its customers noticed these regularities in their lottery numbers. But had people like Newcomb, Benford, or Hill played their lottery, in principle they could have used Benford's law to make favorable bets, earning a nice supplement to their scholar's salary.

In 1947, scientists at the Rand Corporation needed a large table of random digits for a more admirable purpose: to help find approximate solutions to certain mathematical equations employing a technique aptly named the Monte Carlo method. To generate the digits, they employed electronically generated noise, a kind of electronic roulette wheel. Is electronic noise random? That is a question as subtle as the definition of randomness itself.

In 1896 the American philosopher Charles Sanders Peirce wrote that a random sample is one「taken according to a precept or method which, being applied over and over again indefinitely, would in the long run result in the drawing of any one of a set of instances as often as any other set of the same number.」5 That is called the frequency interpretation of randomness. The main alternative to it is called the subjective interpretation. Whereas in the frequency interpretation you judge a sample by the way it turned out, in the subjective interpretation you judge a sample by the way it is produced. According to the subjective interpretation, a number or set of numbers is considered random if we either don't know or cannot predict how the process that produces it will turn out.

The difference between the two interpretations is more nuanced than it may seem. For example, in a perfect world a throw of a die would be random by the first definition but not by the second, since all faces would be equally probable but we could (in a perfect world) employ our exact knowledge of the physical conditions and the laws of physics to determine before each throw exactly how the die will land. In the imperfect real world, however, a throw of a die is random according to the second definition but not the first. That's because, as Moshe pointed out, owing to its imperfections, a die will not land on each face with equal frequency; nevertheless, because of our limitations we have no prior knowledge about any face being favored over any other.

In order to decide whether their table was random, the Rand scientists subjected it to various tests. Upon closer inspection, their system was shown to have biases, just like Moshe's archetypally imperfect dice.6 The Rand scientists made some refinements to their system but never managed to completely banish the regularities. As Moshe said, complete chaos is ironically a kind of perfection. Still, the Rand numbers proved random enough to be useful, and the company published them in 1955 under the catchy title A Million Random Digits.

In their research the Rand scientists ran into a roulette-wheel problem that had been discovered, in some abstract way, almost a century earlier by an Englishman named Joseph Jagger.7 Jagger was an engineer and a mechanic in a cotton factory in Yorkshire, and so he had an intuitive feel for the capabilities — and the shortcomings — of machinery and one day in 1873 turned his intuition and fertile mind from cotton to cash. How perfectly, he wondered, can the roulette wheels in Monte Carlo really work?

The roulette wheel — invented, at least according to legend, by Blaise Pascal as he was tinkering with an idea for a perpetual-motion machine — is basically a large bowl with partitions (called frets) that are shaped like thin slices of pie. When the wheel is spun, a marble first bounces along the rim of the bowl but eventually comes to rest in one of the compartments, which are numbered 1 through 36, plus 0 (and 00 on American roulette wheels). The bettor's job is simple: to guess in which compartment the marble will land. The existence of roulette wheels is pretty good evidence that legitimate psychics don't exist, for in Monte Carlo if you bet `$`1 on a compartment and the marble lands there, the house pays you `$`35 (plus your initial dollar). If psychics really existed, you'd see them in places like that, hooting and dancing and pushing wheelbarrows of cash down the street, and not on Web sites calling themselves Zelda Who Knows All and Sees All and offering twenty-four-hour free online love advice in competition with about 1.2 million other Web psychics (according to Google). For me both the future and, increasingly, the past unfortunately appear obscured by a thick fog. But I do know one thing: my chances of losing at European roulette are 36 out of 37; my chances of winning, 1 out of 37. That means that for every `$`1 I bet, the casino stands to win (36/37 × `$`1) – (1/37 × `$`35). That comes to 1/37 of a dollar, or about 2.7¢. Depending on my state of mind, it's either the price I pay for the enjoyment of watching a little marble bounce around a big shiny wheel or else the price I pay for the opportunity of having lightning strike me (in a good way). At least that is how it is supposed to work.

But does it? Only if the roulette wheels are perfectly balanced, thought Jagger, and he had worked with enough machines to share Moshe's point of view. He was willing to bet they weren't. So he gathered his savings, traveled to Monte Carlo, and hired six assistants, one for each of the casino's six roulette wheels. Every day his assistants observed the wheels, writing down every number that came up in the twelve hours the casino was open. Every night, back in his hotel room, Jagger analyzed the numbers. After six days, he had not detected any bias in five of the wheels, but on the sixth wheel nine numbers came up noticeably more often than the others. And so on the seventh day he headed to the casino and started to bet heavily on the nine favored numbers: 7, 8, 9, 17, 18, 19, 22, 28, and 29.

When the casino shut that night, Jagger was up `$`70,000. His winnings did not go without notice. Other patrons swarmed his table, tossing down their own cash to get in on a good thing. And casino inspectors were all over him, trying to decipher his system or, better, catch him cheating. By the fourth day of betting, Jagger had amassed `$`300,000, and the casino's managers were desperate to get rid of the mystery guy, or at least thwart his scheme. One imagines this being accomplished by a burly fellow from Brooklyn. Actually the casino employees did something far more clever.

On the fifth day, Jagger began to lose. His losing, like his winning, was not something you could spot immediately. Both before and after the casino's trick, he would win some and lose some, only now he lost more often than he won instead of the other way around. With the casino's small margin, it would take some pretty diligent betting to drain Jagger's funds, but after four days of sucking in casino money, he wasn't about to let up on the straw. By the time his change of luck deterred him, Jagger had lost half his fortune. One may imagine that by then his mood — not to mention the mood of his hangers-on — was sour. How could his scheme have suddenly failed?

Jagger at last made an astute observation. In the dozens of hours he had spent winning, he had come to notice a tiny scratch on the roulette wheel. This scratch was now absent. Had the casino kindly touched it up so that he could drive them to bankruptcy in style? Jagger guessed not and checked the other roulette wheels. One of them had a scratch. The casino managers had correctly guessed that Jagger's days of success were somehow related to the wheel he was playing, and so overnight they had switched wheels. Jagger relocated and again began to win. Soon he had pumped his winnings past where they had been, to almost half a million.

Unfortunately for Jagger, the casino's managers, finally zeroing in on his scheme, found a new way to thwart him. They decided to move the frets each night after closing, turning them along the wheel so that each day the wheel's imbalance would favor different numbers, numbers unknown to Jagger. Jagger started losing again and finally quit. His gambling career over, he left Monte Carlo with `$`325,000 in hand, about `$`5 million in today's dollars. Back home, he left his job at the mill and invested his money in real estate.

It may appear that Jagger's scheme had been a sure thing, but it wasn't. For even a perfectly balanced wheel will not come up on 0, 1, 2, 3, and so on, with exactly equal frequencies, as if the numbers in the lead would politely wait for the laggards to catch up. Instead, some numbers are bound to come up more often than average and others less often. And so even after six days of observations, there remained a chance that Jagger was wrong. The higher frequencies he observed for certain numbers may have arisen by chance and may not have reflected higher probabilities. That means that Jagger, too, had to face the question we raised at the start of this chapter: given a set of underlying probabilities, how closely can you expect your observations of a system to conform to those probabilities? Just as Pascal's work was done in the new climate of (the scientific) revolution, so this question would be answered in the midst of a revolution, this one in mathematics — the invention of calculus.

IN 1680 a great comet sailed through our neighborhood of the solar system, close enough that the tiny fraction of sunlight it reflected was sufficient to make it prominent in the night sky of our own planet. It was in that part of earth's orbit called November that the comet was first spotted, and for months afterward it remained an object of intense scrutiny, its path recorded in great detail. In 1687, Isaac Newton would use these data as an example of his inverse square law of gravity at work. And on one clear night in that parcel of land called Basel, Switzerland, another man destined for greatness was also paying attention. He was a young theologian who, gazing at the bright, hazy light of the comet, realized that it was mathematics, not the church, with which he wanted to occupy his life.8 With that realization sprouted not just Jakob Bernoulli's own career change but also what would become the greatest family tree in the history of mathematics: in the century and a half between Jakob's birth and 1800 the Bernoulli family produced a great many offspring, about half of whom were gifted, including eight noted mathematicians, and three (Jakob, his younger brother Johann, and Johann's son Daniel) who are today counted as among the greatest mathematicians of all times.

Comets at the time were considered by theologians and the general public alike as a sign of divine anger, and God must have seemed pretty pissed off to create this one — it occupied more than half the visible sky. One preacher called it a「heavenly warning of the Allpowerful and Holy God written and placed before the powerless and unholy children of men.」It portended, he wrote,「a noteworthy change in spirit or in worldly matters」for their country or town.9 Jakob Bernoulli had another point of view. In 1681 he published a pamphlet titled Newly Discovered Method of How the Path of a Comet or Tailed Star Can Be Reduced to Certain Fundamental Laws, and Its Appearance Predicted.

Bernoulli had scooped Newton on the comet by six years. At least he would have scooped him had his theory been correct. It wasn't, but claiming publicly that comets follow natural law and not God's whim was a gutsy thing to do, especially given that the prior year — almost fifty years after Galileo's condemnation — the professor of mathematics at the University of Basel, Peter Megerlin, had been roundly attacked by theologians for accepting the Copernican system and had been banned from teaching it at the university. A forbidding schism lay between the mathematician-scientists and the theologians in Basel, and Bernoulli was parking himself squarely on the side of the scientists.

Bernoulli's talent soon brought the embrace of the mathematics community, and when Megerlin died, in late 1686, Bernoulli succeeded him as professor of mathematics. By then Bernoulli was working on problems connected with games of chance. One of his major influences was a Dutch mathematician and scientist, Christiaan Huygens, who in addition to improving the telescope, being the first to understand Saturn's rings, creating the first pendulum clock (based on Galileo's ideas), and helping to develop the wave theory of light, had written a mathematical primer on probability inspired by the ideas of Pascal and Fermat.

For Bernoulli, Huygens's book was an inspiration. And yet he saw in the theory Huygens presented severe limitations. It might be sufficient for games of chance, but what about aspects of life that are more subjective? How can you assign a definite probability to the credibility of legal testimony? Or to who was the better golfer, Charles I of England or Mary, Queen of Scots? (Both were keen golfers.) Bernoulli believed that for rational decision making to be possible, there must be a reliable and mathematical way to determine probabilities. His view reflected the culture of the times, in which to conduct one's affairs in a manner that was consistent with probabilistic expectation was considered the mark of a reasonable person. But it was not just subjectivity that, in Bernoulli's opinion, limited the old theory of randomness. He also recognized that the theory was not designed for situations of ignorance, in which the probabilities of various outcomes could be defined in principle but in practice were not known. It is the issue I discussed with Moshe and that Jagger had to address: What are the odds that an imperfect die will come up with a 6? What are your chances of contracting the plague? What is the probability that your breastplate can withstand a thrust from your opponent's long sword? In both subjective and uncertain situations, Bernoulli believed it would be「insanity」to expect to have the sort of prior, or a priori, knowledge of probabilities envisioned in Huygens's book.10

Bernoulli saw the answer in the same terms that Jagger later would: instead of depending on probabilities being handed to us, we should discern them through observation. Being a mathematician, he sought to make the idea precise. Given that you view a certain number of roulette spins, how closely can you nail down the underlying probabilities, and with what level of confidence? We'll return to those questions in the next chapter, but they are not quite the questions Bernoulli was able to answer. Instead, he answered a closely related question: how well are underlying probabilities reflected in actual results? Bernoulli considered it obvious that we are justified in expecting that as we increase the number of trials, the observed frequencies will reflect — more and more accurately — their underlying probabilities. He certainly wasn't the first to believe that. But he was the first to give the issue a formal treatment, to turn the idea into a proof, and to quantify it, asking how many trials are necessary, and how sure can we be. He was also among the first to appreciate the importance of the new subject of calculus in addressing these issues.

THE YEAR Bernoulli was named professor in Basel proved to be a milestone year in the history of mathematics: it was the year in which Gottfried Leibniz published his revolutionary paper laying out the principles of integral calculus, the complement to his 1684 paper on differential calculus. Newton would publish his own version of the subject in 1687, in his Philosophiae Naturalis Principia Mathematica, or Mathematical Principles of Natural Philosophy, often referred to simply as Principia. These advances would hold the key to Bernoulli's work on randomness.

By the time they published, both Leibniz and Newton had worked on the subject for years, but their almost simultaneous publications begged for controversy over who should be credited for the idea. The great mathematician Karl Pearson (whom we shall encounter again in chapter 8) said that the reputation of mathematicians「stands for posterity largely not on what they did, but on what their contemporaries attributed to them.」11 Perhaps Newton and Leibniz would have agreed with that. In any case neither was above a good fight, and the one that ensued was famously bitter. At the time the outcome was mixed. The Germans and Swiss learned their calculus from Leibniz's work, and the English and many of the French from Newton's. From the modern standpoint there is very little difference between the two, but in the long run Newton's contribution is often emphasized because he appears to have truly had the idea earlier and because in Principia he employed his invention in the creation of modern physics, making Principia probably the greatest scientific book ever written. Leibniz, though, had developed a better notation, and it is his symbols that are often used in calculus today.

Neither man's publications were easy to follow. In addition to being the greatest book on science, Newton's Principia has also been called「one of the most inaccessible books ever written.」12 And Leibniz's work, according to one of Jakob Bernoulli's biographers, was「understood by no one」it was not only unclear but also full of misprints. Jakob's brother Johann called it「an enigma rather than an explanation.」13 In fact, so incomprehensible were both works that scholars have speculated that both authors might have intentionally made their works difficult to understand to keep amateurs from dabbling. This enigmatic quality was an advantage for Jakob Bernoulli, though, for it did separate the wheat from the chaff, and his intellect fell into the former category. Hence once he had deciphered Leibniz's ideas, he possessed a weapon shared by only a handful of others in the entire world, and with it he could easily solve problems that were exceedingly difficult for others to attempt.

The set of concepts central to both calculus and Bernoulli's work is that of sequence, series, and limit. The term sequence means much the same thing to a mathematician as it does to anybody else: an ordered succession of elements, such as points or numbers. A series is simply the sum of a sequence of numbers. And loosely speaking, if the elements of a sequence seem to be heading somewhere — toward a particular endpoint or a particular number — then that is called the limit of the sequence.

Though calculus represents a new sophistication in the understanding of sequences, that idea, like so many others, had already been familiar to the Greeks. In the fifth century B.C., in fact, the Greek philosopher Zeno employed a curious sequence to formulate a paradox that is still debated among college philosophy students today, especially after a few beers. Zeno's paradox goes like this: Suppose a student wishes to step to the door, which is 1 meter away. (We choose a meter here for convenience, but the same argument holds for a mile or any other measure.) Before she arrives there, she first must arrive at the halfway point. But in order to reach the halfway point, she must first arrive halfway to the halfway point — that is, at the one-quarter-way point. And so on, ad infinitum. In other words, in order to reach her destination, she must travel this sequence of distances: 1/2 meter, 1/4 meter, 1/8 meter, 1/16 meter, and so on. Zeno argued that because the sequence goes on forever, she has to traverse an infinite number of finite distances. That, Zeno said, must take an infinite amount of time. Zeno's conclusion: you can never get anywhere.

Over the centuries, philosophers from Aristotle to Kant have debated this quandary. Diogenes the Cynic took the empirical approach: he simply walked a few steps, then pointed out that things in fact do move. To those of us who aren't students of philosophy, that probably sounds like a pretty good answer. But it wouldn't have impressed Zeno. Zeno was aware of the clash between his logical proof and the evidence of his senses; it's just that, unlike Diogenes, what Zeno trusted was logic. And Zeno wasn't just spinning his wheels. Even Diogenes would have had to admit that his response leaves us facing a puzzling (and, it turns out, deep) question: if our sensory evidence is correct, then what is wrong with Zeno's logic?

Consider the sequence of distances in Zeno's paradox: 1/2 meter, 1/4 meter, 1/8 meter, 1/16 meter, and so on (the increments growing ever smaller). This sequence has an infinite number of terms, so we cannot compute its sum by simply adding them all up. But we can notice that although the number of terms is infinite, those terms get successively smaller. Might there be a finite balance between the endless stream of terms and their endlessly diminishing size? That is precisely the kind of question we can address by employing the concepts of sequence, series, and limit. To see how it works, instead of trying to calculate how far the student went after the entire infinity of Zeno's intervals, let's take one interval at a time. Here are the student's distances after the first few intervals:

After the first interval: 1/2 meter

After the second interval: 1/2 meter + 1/4 meter = 3/4 meter

After the third interval: 1/2 meter + 1/4 meter + 1/8 meter = 7/8 meter

After the fourth interval: 1/2 meter + 1/4 meter + 1/8 meter + 1/16 meter = 15/16 meter

There is a pattern in these numbers: 1/2 meter, 3/4 meter, 7/8 meter, 15/16 meter…The denominator is a power of two, and the numerator is one less than the denominator. We might guess from this pattern that after 10 intervals the student would have traveled 1,023/1,024 meter; after 20 intervals, 1,048,575/1,048,576 meter; and so on. The pattern makes it clear that Zeno is correct that the more intervals we include, the greater the sum of distances we obtain. But Zeno is not correct when he says that the sum is headed for infinity. Instead, the numbers seem to be approaching 1; or as a mathematician would say, 1 meter is the limit of this sequence of distances. That makes sense, because although Zeno chopped her trip into an infinite number of intervals, she had, after all, set out to travel just 1 meter.

Zeno's paradox concerns the amount of time it takes to make the journey, not the distance covered. If the student were forced to take individual steps to cover each of Zeno's intervals, she would indeed be in some time trouble (not to mention her having to overcome the difficulty of taking submillimeter steps)! But if she is allowed to move at constant speed without pausing at Zeno's imaginary checkpoints — and why not? — then the time it takes to travel each of Zeno's intervals is proportional to the distance covered in that interval, and so since the total distance is finite, as is the total time — and fortunately for all of us — motion is possible after all.

Though the modern concept of limits wasn't worked out until long after Zeno's life, and even Bernoulli's — it came in the nineteenth century14 — it is this concept that informs the spirit of calculus, and it is in this spirit that Jakob Bernoulli attacked the relationship between probabilities and observation. In particular, Bernoulli investigated what happens in the limit of an arbitrarily large number of repeated observations. Toss a (balanced) coin 10 times and you might observe 7 heads, but toss it 1 zillion times and you'll most likely get very near 50 percent. In the 1940s a South African mathematician named John Kerrich decided to test this out in a practical experiment, tossing a coin what must have seemed like 1 zillion times — actually it was 10,000 — and recording the results of each toss.15 You might think Kerrich would have had better things to do, but he was a war prisoner at the time, having had the bad luck of being a visitor in Copenhagen when the Germans invaded Denmark in April 1940. According to Kerrich's data, after 100 throws he had only 44 percent heads, but by the time he reached 10,000, the number was much closer to half: 50.67 percent. How do you quantify this phenomenon? The answer to that question was Bernoulli's accomplishment.

According to the historian and philosopher of science Ian Hacking, Bernoulli's work「came before the public with a brilliant portent of all the things we know about it now; its mathematical profundity, its unbounded practical applications, its squirming duality and its constant invitation for philosophizing. Probability had fully emerged.」In Bernoulli's more modest words, his study proved to be one of「novelty, as well as…high utility.」It was also an effort, Bernoulli wrote, of「grave difficulty.」16 He worked on it for twenty years.

JAKOB BERNOULLI called the high point of his twenty-year effort his「golden theorem.」Modern versions of it that differ in their technical nuance go by various names: Bernoulli's theorem, the law of large numbers, and the weak law of large numbers. The phrase law of large numbers is employed because, as we've said, Bernoulli's theorem concerns the way results reflect underlying probabilities when we make a large number of observations. But we'll stick with Bernoulli's terminology and call his theorem the golden theorem because we will be discussing it in its original form.17

Although Bernoulli's interest lay in real-world applications, some of his favorite examples involved an item not found in most households: an urn filled with colored pebbles. In one scenario, he envisioned the urn holding 3,000 white pebbles and 2,000 black ones, a ratio of 60 percent white to 40 percent black. In this example you conduct a series of blind drawings from the urn「with replacement」 — that is, replacing each pebble before drawing the next in order not to alter the 3:2 ratio. The a priori chances of drawing a white pebble are then 3 out of 5, or 60 percent, and so in this example Bernoulli's central question becomes, how strictly should you expect the proportion of white pebbles drawn to hew to the 60 percent ratio, and with what probability?

The urn example is a good one because the same mathematics that describes drawing pebbles from an urn can be employed to describe any series of trials in which each trial has two possible outcomes, as long as those outcomes are random and the trials are independent of each other. Today such trials are called Bernoulli trials, and a series of Bernoulli trials is a Bernoulli process. When a random trial has two possible outcomes, one is often arbitrarily labeled「success」and the other「failure.」The labeling is not meant to be literal and sometimes has nothing to do with the everyday meaning of the words — say, in the sense that if you can't wait to read on, this book is a success, and if you are using this book to keep yourself and your sweetheart warm after the logs burned down, it is a failure. Flipping a coin, deciding to vote for candidate A or candidate B, giving birth to a boy or girl, buying or not buying a product, being cured or not being cured, even dying or living are examples of Bernoulli trials. Actions that have multiple outcomes can also be modeled as Bernoulli trials if the question you are asking can be phrased in a way that has a yes or no answer, such as「Did the die land on the number 4?」or「Is there any ice left on the North Pole?」And so, although Bernoulli wrote about pebbles and urns, all his examples apply equally to these and many other analogous situations.

With that understanding we return to the urn, 60 percent of whose pebbles are white. If you draw 100 pebbles from the urn (with replacement), you might find that exactly 60 of them are white, but you might also draw just 50 white pebbles or 59. What are the chances that you will draw between 58 percent and 62 percent white pebbles? What are the chances you'll draw between 59 percent and 61 percent? How much more confident can you be if instead of 100, you draw 1,000 pebbles or 1 million? You can never be 100 percent certain, but can you draw enough pebbles to make the chances 99.9999 percent certain that you will draw, say, between 59.9 percent and 60.1 percent white pebbles? Bernoulli's golden theorem addresses questions such as these.

In order to apply the golden theorem, you must make two choices. First, you must specify your tolerance of error. How near to the underlying proportion of 60 percent are you demanding that your series of trials come? You must choose an interval, such as plus or minus 1 percent or 2 percent or 0.00001 percent. Second, you must specify your tolerance of uncertainty. You can never be 100 percent sure a trial will yield the result you are aiming for, but you can ensure that you will get a satisfactory result 99 times out of 100 or 999 out of 1,000.

The golden theorem tells you that it is always possible to draw enough pebbles to be almost certain that the percentage of white pebbles you draw will be near 60 percent no matter how demanding you want to be in your personal definition of almost certain and near. It also gives a numerical formula for calculating the number of trials that are「enough,」given those definitions.

The first part of the law was a conceptual triumph, and it is the only part that survives in modern versions of the theorem. Concerning the second part — Bernoulli's formula — it is important to understand that although the golden theorem specifies a number of trials that is sufficient to meet your goals of confidence and accuracy, it does not say you can't accomplish those goals with fewer trials. That doesn't affect the first part of the theorem, for which it is enough to know simply that the number of trials specified is finite. But Bernoulli also intended the number given by his formula to be of practical use. Unfortunately, in most practical applications it isn't. For instance, here is a numerical example Bernoulli worked out himself, although I have changed the context: Suppose 60 percent of the voters in Basel support the mayor. How many people must you poll for the chances to be 99.9 percent that you will find the mayor's support to be between 58 percent and 62 percent — that is, for the result to be accurate within plus or minus 2 percent? (Assume, in order to be consistent with Bernoulli, that the people polled are chosen at random, but with replacement. In other words, it is possible that you poll a person more than once.) The answer is 25,550, which in Bernoulli's time was roughly the entire population of Basel. That this number was impractical wasn't lost on Bernoulli. He also knew that accomplished gamblers can intuitively guess their chances of success at a new game based on a sample of far fewer than thousands of trial games.

One reason Bernoulli's numerical estimate was so far from optimal was that his proof was based on many approximations. Another reason was that he chose 99.9 percent as his standard of certainty — that is, he required that he get the wrong answer (an answer that differed more than 2 percent from the true one) less than 1 time in 1,000. That is a very demanding standard. Bernoulli called it moral certainty, meaning the degree of certainty he thought a reasonable person would require in order to make a rational decision. It is perhaps a measure of how much the times have changed that today we've abandoned the notion of moral certainty in favor of the one we encountered in the last chapter, statistical significance, meaning that your answer will be wrong less than 1 time in 20.

With today's mathematical methods, statisticians have shown that in a poll like the one I described, you can achieve a statistically significant result with an accuracy of plus or minus 5 percent by polling only 370 subjects. And if you poll 1,000, you can achieve a 90 percent chance of coming within 2 percent of the true result (60 percent approval of Basel's mayor). But despite its limitations, Bernoulli's golden theorem was a milestone because it showed, at least in principle, that a large enough sample will almost certainly reflect the underlying makeup of the population being sampled.

IN REAL LIFE we don't often get to observe anyone's or anything's performance over thousands of trials. And so if Bernoulli required an overly strict standard of certainty, in real-life situations we often make the opposite error: we assume that a sample or a series of trials is representative of the underlying situation when it is actually far too small to be reliable. For instance, if you polled exactly 5 residents of Basel in Bernoulli's day, a calculation like the ones we discussed in chapter 4 shows that the chances are only about 1 in 3 that you will find that 60 percent of the sample (3 people) supported the mayor.

Only 1 in 3? Shouldn't the true percentage of the mayor's supporters be the most probable outcome when you poll a sample of voters? In fact, 1 in 3 is the most probable outcome: the odds of finding 0, 1, 2, 4, or 5 supporters are lower than the odds of finding 3. Nevertheless, finding 3 supporters is not likely: because there are so many of those nonrepresentative possibilities, their combined odds add up to twice the odds that your poll accurately reflects the population. And so in a poll of 5 voters, 2 times out of 3 you will observe the「wrong」percentage. In fact, about 1 in 10 times you'll find that all the voters you polled agree on whether they like or dislike the mayor. And so if you paid any attention to a sample of 5, you'd probably severely over- or underestimate the mayor's true popularity.

The misconception — or the mistaken intuition — that a small sample accurately reflects underlying probabilities is so widespread that Kahneman and Tversky gave it a name: the law of small numbers.18 The law of small numbers is not really a law. It is a sarcastic name describing the misguided attempt to apply the law of large numbers when the numbers aren't large.

If people applied the (untrue) law of small numbers only to urns, there wouldn't be much impact, but as we've said, many events in life are Bernoulli processes, and so our intuition often leads us to misinterpret what we observe. That is why, as I described in chapter 1, when people observe the handful of more successful or less successful years achieved by the Sherry Lansings and Mark Cantons of the world, they assume that their past performance accurately predicts their future performance.

Let's apply these ideas to an example I mentioned briefly in chapter 4: the situation in which two companies compete head-to-head or two employees within a company compete. Think now of the CEOs of the Fortune 500 companies. Let's assume that, based on their knowledge and abilities, each CEO has a certain probability of success each year (however his or her company may define that). And to make things simple, let's assume that for these CEOs successful years occur with the same frequency as the white pebbles or the mayor's supporters: 60 percent. (Whether the true number is a little higher or a little lower doesn't affect the thrust of this argument.) Does that mean we should expect, in a given five-year period, that a CEO will have precisely three good years?

No. As the earlier analysis showed, even if the CEOs all have a nice cut-and-dried 60 percent success rate, the chances that in a given five-year period a particular CEO's performance will reflect that underlying rate are only 1 in 3! Translated to the Fortune 500, that means that over the past five years about 333 of the CEOs would have exhibited performance that did not reflect their true ability. Moreover, we should expect, by chance alone, about 1 in 10 of the CEOs to have five winning or losing years in a row. What does this tell us? It is more reliable to judge people by analyzing their abilities than by glancing at the scoreboard. Or as Bernoulli put it,「One should not appraise human action on the basis of its results.」19

Going against the law of small numbers requires character. For while anyone can sit back and point to the bottom line as justification, assessing instead a person's actual knowledge and actual ability takes confidence, thought, good judgment, and, well, guts. You can't just stand up in a meeting with your colleagues and yell,「Don't fire her. She was just on the wrong end of a Bernoulli series.」Nor is it likely to win you friends if you stand up and say of the gloating fellow who just sold more Toyota Camrys than anyone else in the history of the dealership,「It was just a random fluctuation.」And so it rarely happens. Executives' winning years are attributed to their brilliance, explained retroactively through incisive hindsight. And when people don't succeed, we often assume the failure accurately reflects the proportion with which their talents and their abilities fill the urn.

Another mistaken notion connected with the law of large numbers is the idea that an event is more or less likely to occur because it has or has not happened recently. The idea that the odds of an event with a fixed probability increase or decrease depending on recent occurrences of the event is called the gambler's fallacy. For example, if Kerrich landed, say, 44 heads in the first 100 tosses, the coin would not develop a bias toward tails in order to catch up! That's what is at the root of such ideas as「her luck has run out」and「He is due.」That does not happen. For what it's worth, a good streak doesn't jinx you, and a bad one, unfortunately, does not mean better luck is in store. Still, the gambler's fallacy affects more people than you might think, if not on a conscious level then on an unconscious one. People expect good luck to follow bad luck, or they worry that bad will follow good.

I remember, on a cruise a few years back, watching an intense pudgy man sweating as he frantically fed dollars into a slot machine as fast as it would take them. His companion, seeing me eye them, remarked simply,「He is due.」Although tempted to point out that, no, he isn't due, I instead walked on. After several steps I halted my progress owing to a sudden flashing of lights, ringing of bells, not a little hooting on the couple's part, and the sound of, for what seemed like minutes, a fast stream of dollar coins flying out of the machine's chute. Now I know that a modern slot machine is computerized, its payoffs driven by a random-number generator, which by both law and regulation must truly generate, as advertised, random numbers, making each pull of the handle completely independent of the history of previous pulls. And yet…Well, let's just say the gambler's fallacy is a powerful illusion.

THE MANUSCRIPT in which Bernoulli presented his golden theorem ends abruptly even though he promises earlier in the work that he will provide applications to various issues in civic affairs and economics. It is as if「Bernoulli literally quit when he saw the number 25,550,」wrote the historian of statistics Stephen Stigler.20 In fact, Bernoulli was in the process of publishing his manuscript when he died「of a slow fever」in August 1705, at the age of fifty. His publishers asked Johann Bernoulli to complete it, but Johann refused, saying he was too busy. That may appear odd, but the Bernoullis were an odd family. If you were asked to choose the most unpleasant mathematician who ever lived, you wouldn't be too far off if you fingered Johann Bernoulli. He has been variously described in historical texts as jealous, vain, thin-skinned, stubborn, bilious, boastful, dishonest, and a consummate liar. He accomplished much in mathematics, but he is also known for having his son Daniel tossed out of the Académie des Sciences after Daniel won a prize for which Johann himself had competed, for attempting to steal both his brother's and Leibniz's ideas, and for plagiarizing Daniel's book on hydrodynamics and then faking the publication date so that his book would appear to have been published first.

When he was asked to complete his late brother's manuscript, he had recently relocated to Basel from the University of Groningen, in the Netherlands, obtaining a post not in mathematics but as a professor of Greek. Jakob had found this career change suspicious, especially since in his estimation Johann did not know Greek. What Jakob suspected, he wrote Leibniz, was that Johann had come to Basel to usurp Jakob's position. And, indeed, upon Jakob's death, Johann did obtain it.

Johann and Jakob had not gotten along for most of their adult lives. They would regularly trade insults in mathematics publications and in letters that, one mathematician wrote,「bristle with strong language that is usually reserved for horse thieves.」21 And so when the need arose to edit Jakob's posthumous manuscript, the task fell further down the food chain, to Jakob's nephew Nikolaus, the son of one of Jakob's other brothers, also named Nikolaus. The younger Nikolaus was only eighteen at the time, but he had been one of Jakob's pupils. Unfortunately he didn't feel up to the task, possibly in part because he was aware of Leibniz's opposition to his uncle's ideas about applications of the theory. And so the manuscript lay dormant for eight years. The book was finally published in 1713 under the title Ars conjectandi, or The Art of Conjecture. Like Pascal's Pensées, it is still in print.

Jakob Bernoulli had shown that through mathematical analysis one could learn how the inner hidden probabilities that underlie natural systems are reflected in the data those systems produce. As for the question that Bernoulli did not answer — the question of how to infer, from the data produced, the underlying probability of events — the answer would not come for several decades more.

## Notes

1 Tijms, Understanding Probability, p. 53.

2 Scott Kinney,「Judge Sentences Kevin L. Lawrence to 20 Years Prison in Znetix/HMC Stock Scam,」Washington State Department of Financial Institutions, press release, November 25, 2003; http://www.dfi.wa.gov/sd/kevin_laurence_sentence.htm.

3 Interview with Darrell Dorrell, August 1, 2005.

4 Lee Berton,「He's Got Their Number: Scholar Uses Math to Foil Financial Fraud,」Wall Street Journal, July 10, 1995.

5 Charles Sanders Peirce, Max Harold Fisch, and Christian J. W. Kloesel, Writings of Charles S. Peirce: A Chronological Edition (Bloomington: Indiana University Press, 1982), p. 427.

6 Rand Corporation, A Million Random Digits with 100,000 Normal Deviates (1955; repr., Santa Monica, Calif.: Rand, 2001), pp. ix–x. See also Lola L. Lopes,「Doing the Impossible: A Note on Induction and the Experience of Randomness,」Journal of Experimental Psychology: Learning, Memory, and Cognition 8, no. 6 (November 1982): 626–36.

7 The account of Joseph Jagger (sometimes spelled Jaggers) is from John Grochowski,「House Has a Built-in Edge When Roulette Wheel Spins,」Chicago Sun-Times, February 21, 1997.

8 For details about the Bernoulli family and Jakob's life, see E. S. Pearson, ed., The History of Statistics in the 17th and 18th Centuries against the Changing Background of Intellectual, Scientific and Religious Thought: Lectures by Karl Pearson Given at University College, London, during the Academic Sessions 1921–1933 (New York: Macmillan, 1978), pp. 221–37; J. O. Fleckenstein,「Johann und Jakob Bernoulli,」in Elemente der Mathematik, Beihefte zur Zeitschrift, no. 6 (Basel, 1949); and Stephen Stigler,「The Bernoullis of Basel,」Journal of Econometrics 75, no. 1 (1996): 7–13.

9 Quoted in Pearson, The History of Statistics in the 17th and 18th Centuries, p. 224.

10 Stephen Stigler, The History of Statistics: The Measurement of Uncertainty before 1900 (Cambridge, Mass.: Harvard University Press, 1986), p. 65.

11 Pearson, The History of Statistics in the 17th and 18th Centuries, p. 226.

12 William H. Cropper, The Great Physicists: The Life and Times of Leading Physicists from Galileo to Hawking (London: Oxford University Press, 2001), p. 31.

13 Johann Bernoulli, quoted in Pearson, The History of Statistics in the 17th and 18th Centuries, p. 232.

14 This depends, of course, on what you identify as「the modern concept.」I am using the definition employed by Hankel's 1871 history of the topic, described in great detail in Gert Schubring, Conflicts between Generalization, Rigor, and Intuition: Number Concepts Underlying the Development of Analysis in 17th–19th Century France and Germany (New York: Springer, 2005), pp. 22–32.

15 David Freedman, Robert Pisani, and Roger Purves, Statistics, 3rd ed. (New York: W. W. Norton, 1998), pp. 274–75.

16 The Hacking quote is from Ian Hacking, The Emergence of Probability (Cambridge: Cambridge University Press, 1975), p. 143. The Bernoulli quote is from David, Gods, Games and Gambling, p. 136.

17 For a discussion of what Bernoulli actually proved, see Stigler, The History of Statistics, pp. 63–78, and Ian Hacking, The Emergence of Probability, pp. 155–65.

18 Amos Tversky and Daniel Kahneman,「Belief in the Law of Small Numbers,」Psychological Bulletin 76, no. 2 (1971): 105–10.

19 Jakob Bernoulli, quoted in L. E. Maistrov, Probability Theory: A Historical Sketch, trans. Samuel Kotz (New York: Academic Press, 1974), p. 68.

20 Stigler, The History of Statistics, p. 77.

21 E. T. Bell, Men of Mathematics (New York: Simon & Schuster, 1937), p. 134.

0501针锋相对的大数定律与小数定律

卡尔达诺、伽利略和帕斯卡都做了一个假设，那就是问题中的概率是已知的。伽利略就假设骰子的 6 个面出现的可能性都相等。但这种「知识」有多可靠呢？大公的骰子很可能是按各面平等的原则设计的，但这并不意味着这个期望中的公平就能成为现实。也许伽利略观察了若干次投掷的结果，并记下各面出现的频度来检验他的假设。但是，如果把这个检验重复几次，那么他很可能会发现，频率分布每次都会稍有出入。对于他需要解释的那个 8% 的微小差异，分布中的任何出入都可能对结论造成显著的影响。要想把随机性的早期研究成果真正应用于真实情况，就必须面对如下的问题：那些隐藏着的概率和观测结果之间的联系究竟是怎样的？在实际应用的时候，如果我们说骰子扔出 2 点的可能性是 1/6，这个说法到底是要表达什么意思？如果这句话并不是指在任一系列的投掷中，每 6 次就会严格地出现一次 2 点，那么我们对于扔出 2 点的概率为 1/6 的这种信念，到底从何而来？如果医生说一种药的有效率是 70%，但还有 1% 的可能性会出现严重的副作用，那么他又是什么意思？或者一次民意调查发现某候选人的选民支持率为 36%，这句话到底有什么含义？这些问题都十分深刻，而且与随机性的定义本身有关，而这也是一个时至今日数学家仍然乐此不疲地为之争辩的概念。

最近，我就在一个温暖的春日里，与一名来我校访问的希伯来大学统计学家进行了一次这样的讨论。莫希，这位统计学家当时就坐在加州理工学院我餐桌的对面。趁着吞下一口脱脂酸奶的空当，莫希表明了一个观点，即并不存在所谓真正的随机数。「根本没这种事儿。」他说，「对，他们出版了很多随机数表，写了很多计算机程序，但都只是在自己骗自己。从来就没有人找到过比扔骰子更好的产生随机性的方法，而扔骰子同样做不到真正的随机。」

莫希朝我挥舞着他的白色塑料勺子。他的情绪有些激动。我察觉到他对随机性的信念和他的宗教信仰之间有某种联系。莫希是一名犹太东正教徒，而就我所知，许多有宗教信仰的人，会比较难以想象上帝竟然能够允许随机性的存在。「假设你想得到 N 个由 1 到 6 的数字构成的一串随机数，」他告诉我，「那么把骰子扔上 N 次，再记录下所得的点数。不过这是一个随机数串吗？」

然后他说，不是的，因为没人能做出一个完美的骰子。总会有某些点数出现得比其他点数更频繁。也许要扔上 1000 次或 10 亿次这一点才会显示出来，但你迟早总会注意到这样的偏向。他说，只要是由人制造出来的东西，就注定会受到这类缺陷的影响，因为人类无法做到完美。这句话也许没错。不过大自然却可以做到完美，真正随机的事件确确实实在原子层面上发生着。实际上，这正是量子理论的基础。因此，我们就把剩下的午餐时间都用来讨论量子光学了。

现在，我们通过投掷大自然完美的量子骰子，可以用最尖端的量子发生器产生真正的随机数。不过在以前，产生随机性所必需的完美性，的确是一个不容易达到的目标。1920 年前后，纽约哈莱姆区的犯罪集团在这个问题上，倒是想出一种非常有创造性的方法。他们每天都需要找到 5 位数字构成的随机数，好用来进行非法彩票活动。这些骗子对当局嗤之以鼻，他们以美国国债余额的最后 5 位数字作为他们需要的随机数。（在撰写本书时，美国政府已负债 8995800515946.50 美元，或者平均每人负债 29679.02 美元。因此，如果是在今天，骗子们就可以直接利用人均负债来获得他们要的 5 个数字！）不过骗子们组织的所谓「财富」彩票，不但违反了刑法，还违反了科学规律。根据一条被称为本福特定律的规则，像国债那样的累积方式所产生的数字并不是随机的，实际上，这些数字更倾向于出现较小的值。

2『本福特定律，做一张术语卡片。（2021-02-20）』——已完成

本福特定律并不是哪个叫本福特的家伙发现的。它的发现者是美国天文学家西蒙·纽科姆。纽科姆在 1881 年前后注意到一种现象：那些对数表书中，用来处理 1 开头的数字的那几页，相比于处理 2 开头一直到 9 开头的数字的那些书页，看起来更脏一些，磨损得也更厉害。特别是 9 开头的数字对应的那几页，看上去干净崭新。纽科姆假定对数表书在长期的使用过程中，其磨损度与使用次数成正比。根据这个假设，他得出一个结论，就是跟他共用这本对数表的那些科学家，他们日常所处理的数据的分布，决定了这些书页的新旧分布。在纽约州斯克内克塔迪的通用电气研究实验室工作的弗兰克·本福特，1938 年也在对数表书中发现了同样的情况。之后，这条规律就获得了它今天的那个名字。不过这两人都未能给出证明。这个证明要到 1995 年才由佐治亚理工学院的数学家特德·希尔完成。

根据本福特定律，1 到 9 这 9 个数字的出现频率并不相等。相反，数位最高位为 1 的情况约占 30%，为 2 的情况约占 18%，如此一直到数字 9，它出现在最高位的情况大概是 5%。另外还有一个类似但人们较少提到的定律，里面考察的则是数位最低位的数字。许多类型的数据都遵循本福特定律，特别是财务数据。实际上，这条定律简直就是为在大量财务数据中发现欺诈行径而量身定做的。

本福特定律的一个著名应用，跟凯文·劳伦斯这位年轻企业家有关。劳伦斯集资 9100 万美元，说要办一个高科技保健连锁俱乐部。大把钞票到手后，劳伦斯迅速行动起来。他雇了一帮人坐办公室，很快就花光了投资人的钱，花钱的速度跟他筹钱的速度一样快。如果不在意一些小细节的话，这本来也没什么。不过几栋私人住宅，20 艘私人游艇，47 辆汽车（包括 5 辆悍马、4 辆法拉利、2 辆道奇蝰蛇、2 辆德托马索 Pantera 跑车以及 1 辆兰博基尼迪亚波罗），2 块劳力士表，1 个 21 克拉的钻石手镯，1 把 20 万美元的日本武士刀，以及 1 台商用棉花糖机，这些小细节可很难被说成是业务方面的必要开支。为了掩饰这些贪污公款的痕迹，劳伦斯和同伙们想用一个复杂的银行账户与皮包公司网络，来制造业务欣欣向荣的假象。不幸的是，他们碰到一位名叫达雷尔·多雷尔的生性多疑的法务会计师。多雷尔把他们的支票与转账单编成了一张有着 7 万个数据的表，然后把表中数字的分布情况与本福特定律进行了对比。这些数据没能通过定律的检验。这当然只是调查的开始，不过后来这个商业传奇的真相大白也就没有什么出乎意料的地方了。2003 年感恩节的前一天，穿着浅蓝色囚服、被律师簇拥着的劳伦斯被判 20 年徒刑，不得假释，这个故事就此画上了句号。美国国家税务局（IRS）也研究了本福特定律，以便用它来识别纳税中的骗局。甚至还有研究者把该定律用到了克林顿 13 年的退税款上。不过这些款项通过了定律的检验。

可想而知，哈莱姆区的犯罪集团和它的彩票顾客都没有注意到中奖号码中存在的这种规律性，但如果纽科姆、本福特或希尔这类人也来玩这个彩票，原则上他们就可以利用本福特定律，对赢面更大的数字投注，这样他们就能在学者职位的薪水之外，赚上一笔颇为不错的外快。

1947 年，兰德公司的科学家迫切需要一个巨大的随机数表。当然，他们的目的要高尚得多：用这些随机数，以一种被很恰当地称为蒙特卡罗方法的数学方法，求取某些方程的近似解。他们用电子噪声产生这些随机数。实际上，我们可以把电子噪声看成一种电子轮盘赌。那么，电子噪声是随机的吗？这个问题就如随机性的定义本身一样微妙。

美国哲学家查尔斯·桑德斯·皮尔斯在 1896 年写道，随机采样是「根据某种规则或方法进行的抽样方法，当这种规则或方法被重复无限次，那么从长远来看，它从某组实例中抽取任一元素的次数，跟它从其他任何一个元素数目相同的集合中抽取任一元素的次数，频率相同」。这被称为随机数的频率解释。另一个主流解释叫作主观解释。频率解释根据采样结果进行判断，而主观解释根据采样值的产生方式进行判断。根据主观解释，如果我们既不知道也无法预测产生某个或某些数字的过程会给出怎样的结果，那么这个或这些数字就被认为是随机的。

这两种解释之间的差别要比看上去的更大。打个比方，在一个完美的世界中，根据第一种定义，扔骰子是随机的，但按照第二种定义就不是那样了，因为尽管扔出各个点数的机会都相等，但我们可以（在一个完美的世界中）根据所掌握的精确的物理条件，在每次投出骰子前就确定将得到的点数。但在我们不完美的真实世界中，扔骰子在第二种定义下是随机的，而在第一种定义下又不是了，原因就是莫希指出的那一点，即骰子本身并非完美，它的各个点数不会以相同的频率出现。能力所限，我们没有任何先验知识知道某个点数会比另一个点数出现得更频繁。

兰德公司的科学家们为了搞清楚他们的随机数表是不是真的随机，进行了许多不同的检验。更细致的分析显示，正如莫希那个从原则上来说不完美的骰子一样，这个随机数生成系统似乎是有偏差的。兰德公司的科学家对系统进行了一些改进，但还是没有办法完全消除这种规律性。正如莫希所言，颇具讽刺意味的是，彻底的混沌本身其实也是一种完美。不过兰德公司的这些随机数已经被证明具有足够的随机性，因此可以满足使用要求。1955 年，兰德公司用一个挺好记的名字出版了这些随机数表：《百万乱数表》（ A Million Random Digits ）。

其实在差不多一个世纪之前，兰德公司的科学家在研究中碰到的这个问题，已经有一名英国人约瑟夫·贾格尔以某种形式遭遇到了。他所碰到的问题叫轮盘赌问题。贾格尔是约克郡一个棉花厂的工程师和机修师，因此，他对于机械的能力及缺陷有一种直觉。在 1873 年的某一天，他把自己对机械的直觉和创造性思维从棉纺车间转向了金钱。他考虑的问题是，蒙特卡洛赌场的轮盘赌到底有多完美？

根据传说，轮盘赌是帕斯卡在瞎想着永动机时发明出来的。基本上，轮盘赌就是把一个很大的碗，隔成许多形如从馅饼上切下的窄窄的扇形部分（称为槽）；当轮子转动时，一颗石弹珠先在碗沿上跳来跳去，并最终落入这些以数字 1 到 36 再加一个 0（美国的轮盘上还有一个 00）作为标记的槽中的某一个。轮盘赌存在的本身，就是所谓靠谱的灵媒根本不存在的一个极好的证据，因为在蒙特卡洛，你如果把 1 美元押在某个编号的槽上，而弹珠恰好掉到了这个槽里，那么赌场会付你 35 美元（再加上你下注的那 1 美元）。如果我们认为的那种灵媒确实存在，那么我们本该在赌场这类地方，看着他们一个个吵吵嚷嚷、手舞足蹈地推走一车又一车的钞票。但实际上，我们碰到的灵媒大都出没于网络，给自己起个「啥都知道也啥都看到的泽尔塔」之类的名字，一边提供 24 小时免费在线情感咨询，一边和大概 120 万（据谷歌）名其他网络灵媒激烈竞争。对我来说，未来有如身处浓雾之中，模糊不清，实际上，甚至连以前的事情也一天天都变成这样。但我起码知道这么一件事：如果赌欧式轮盘赌，我输钱的机会将是 36/37，而赢钱的机会只有 1/37。这就意味着我们每下 1 美元赌注，赌场就会赚（36/37×1 美元）-（1/37×35 美元）= 1/37 美元，大约 2.7 美分。当然，我可以把这 2.7 美分当成欣赏石弹珠在闪亮锃亮的大轮子上弹来蹦去的门票钱，也可以把它当成购买一次试图（以一种好的方式）被闪电击中的机会所付的价钱。至于到底是哪种看法，就取决于我当时的精神状态了。上面这种方式，就是我们所期望的轮盘赌机的行为方式。

但轮盘赌机真的就是如此行事的吗？贾格尔认为，只有当轮盘的各个部分都处于一种完美的平衡状态时，机器才能做到这一点。不过贾格尔跟机器厮混的时间太长了，因此他的观点跟莫希一致：他很愿意去赌一赌，这些轮盘赌机其实并不完美。于是他带着全部积蓄来到蒙特卡洛，雇了 6 名助手，赌场里面有 6 台轮盘赌机，这些助手每人负责盯一台。助手们每天都要观察所负责的机器，并记录下赌场开门后 12 个小时内，每次轮盘赌中获胜的数字。晚上回到旅馆后，贾格尔就对这些数字进行分析。经过 6 天的观察，有 5 台机器并没有表现出任何不均匀的数字分布，但在第 6 台机器上，有 9 个数字明显比其他数字出现得更频繁。第 7 天，他开赴赌场，并在这 9 个出现得更频繁的数字 ——7、8、9、17、18、19、22、28 和 29—— 上投以重注。

当晚赌场关门时，贾格尔赢了 7 万美元。这个胜利没有逃脱其他人的眼睛。别的赌徒围到他的桌旁，扔下钞票一同分享好运。赌场所有的巡查都紧盯着贾格尔，想要找出他如此走运的原因，当然，如果能在他出老千的时候抓个现行就更棒了。大赌 4 天之后，贾格尔堆起了 30 万美元，而赌场经理能做的只是绝望地祈求摆脱这个神秘的家伙，或者至少能够阻止他继续推进他的计划。也许你会以为赌场经理是请某个布鲁克林的壮汉来帮助达到这个目的的，不过赌场的人的做法可要聪明得多。

在第五天，贾格尔开始输钱了。他现在的失败一如之前的成功，并不是马上就能察觉到的。在赌场搞小动作的之前或之后，贾格尔一直都有输有赢，只不过现在他输多赢少，而之前输少赢多。照着赌场在每一注上赚到的那点儿小钱，如果贾格尔想把他的钱都输光，就得加倍勤勉地在赌桌上大干很多天；但 4 天中鲸吞了赌场金钱的贾格尔，可不想因为一点儿风声鹤唳就收手不干了。从开始转霉运到他终于收手，贾格尔输掉了一半的家产。我们不难想象他 —— 更不用说他的跟随者们 —— 是多么失落和难过。好好的一个计划怎么突然就不行了呢？

贾格尔终于精明地发现，他赢钱的时候曾经瞥到机器上有一条细微的划痕，但现在划痕不见了。难道赌场会好心地给机器补个漆，好让贾格尔把它搞破产的过程看起来更加有范儿？贾格尔可不觉得赌场会有这份好心。因此，他仔细地检查了其他几台机器。划痕在其中一台上。赌场经理没有猜错，贾格尔的成功，肯定跟他赌的那台机器存在某种联系。因此他们连夜调换了机器。发现这一点之后，贾格尔换到这台有划痕的机器上，钱再次流向他的钱包。没多久，他就赚到比之前更多的钱，这次有将近 50 万美元。

后来的事情对贾格尔来说就很不幸了。赌场经理终于忍无可忍，于是集中全力来对付他。为了阻止贾格尔，赌场想出一个新方法：每晚赌场关门后，他们就把轮盘槽全部转离原先的位置。这样一来，机器的不平衡性每一天都会偏爱不同的数字，而贾格尔现在可没法知道到底哪些数字才能赢钱了。于是钱又开始溜出贾格尔的钱包，而这一轮输钱，最终让贾格尔离开了赌场。贾格尔带着 32.5 万美元离开了蒙特卡洛，就此结束了他的赌徒生涯。以现值计算，这笔钱大约有 500 万美元。回到家乡后，他辞去厂里的工作，开始投资房地产。

贾格尔的方法看似稳妥可靠，实际上却并不那么简单。哪怕一个轮盘赌机达到了所谓完美的平衡性，0、1、2、3 等这些点数也不会以绝对相等的频率出现。那些出现频率较高的数字可不会出于礼貌而留步，以便让掉队的家伙们赶上来。实际上，肯定会有某些数字出现得比平均水平更频繁，而另一些则达不到平均水平。所以，即使进行了 6 天的观察，贾格尔仍然有可能出错。他发现的某些数字的更高出现频率，其实也有可能还是一个随机的结果，而并非说明这些数字的出现概率确实更高。换言之，贾格尔也需要面对本章开头的问题：对于一系列未知概率，如果我们通过由此产生的结果进行观察，那么这个观测结果与未知概率的吻合程度到底有多高呢？我们已经看到，帕斯卡的工作是在（科学）革命的新氛围中才得以完成的。同样，现在这个问题也是在一次新的革命期间才获得答案的，不过这回是一次数学革命，而这个革命就是微积分的发明。

1680 年，一颗巨大的彗星掠过我们附近的太空。它离地球非常近，因此哪怕仅凭它反射的那微不足道的阳光，就足以让它成为夜空中引人注目的主角。人们第一次发现这颗彗星时，它正处在被我们称为 11 月的那一段地球轨道中。在之后的几个月中，它成为人们充满热情、细致入微的调查对象，人们对它的运行轨迹不厌其烦地做着记录。1687 年，牛顿用这些数据作为他平方反比定律的例子。在瑞士巴塞尔这片土地上，另一个注定要成就伟大功业的人，同样在一个晴朗的夜晚注视着这颗彗星。这名年轻的神学家凝视着彗星那明亮而弥漫的光芒，突然意识到他希望为之奉献一生的，不是教会，而是数学。这个意识不仅带来了雅各布·伯努利个人职业生涯的改变，也诞生了数学史上最伟大的一棵家族树：从雅各布出生到 1800 年的一个半世纪里，伯努利家族产生了许多后人，其中约半数都颇具天分，贡献了 8 位知名的数学家，而其中 3 位（雅各布，他的弟弟约翰，以及约翰的儿子丹尼尔）更是成为历史上最伟大的数学家这一群体的成员。

当时的神学家跟普罗大众一样，都认为彗星是神愤怒的标志。按照这个说法，1680 年这颗彗星出现时，上帝肯定快被气疯了，因为它竟然占据了大半个肉眼可见的天空。一个牧师称它为「由全能而神圣之上帝书写并呈现于无力而不洁的凡人之子眼前的天国之警告」。他还写道，这颗彗星预示着国家或城市在「精神或俗事中将出现值得关注的变化」。雅各布·伯努利对此却另有看法。1681 年，他出版了一本小册子，书名是冗长的《一种新发现的方法：如何将彗星或扫帚星的路径简化为某些基本定律，并预测它的出现》。

在预测这颗彗星轨道的问题上，伯努利可比牛顿早了整整 6 年。或者我们应该说，如果他的理论没错的话，可就确确实实抢在了牛顿的前面。不过他的理论不正确。尽管如此，这个理论仍然成了一份公开的宣告，即彗星所遵循的是自然规律，而非上帝的什么奇思怪想。做这件事需要极大的勇气，特别是在一年前，也就是伽利略被宣判有罪之后差不多 50 年，巴塞尔大学的数学教授彼得·梅格林刚刚因为接受了哥白尼的科学体系，而遭到神学家的全面攻击。他因此被禁止在这所大学任教。一道无法跨越的鸿沟横亘在巴塞尔的数学家、科学家与神学家之间，而伯努利坚定地站在科学家的一方。

由于伯努利的出众天分，他很快被数学家团体接纳。当梅格林在 1686 年晚些时候去世之后，伯努利继承了他的数学教授职位。伯努利当时正在研究随机博弈的问题。在那些对他影响最大的人中，就有荷兰数学家与科学家克里斯蒂安·惠更斯。惠更斯改进了望远镜，成为了解土星光环的第一人，（基于伽利略的思路）创造了第一台摆钟，并对光的波动学说做出贡献。除此之外，他还受到帕斯卡与费马观点的启发，写了一本关于概率的初级数学读本。

惠更斯的书确实为伯努利带来了灵感，但他同样在惠更斯的理论中看到了严重的局限性。对于随机博弈而言，这个理论也许够用了，但是对于那些更具主观性的生活中的方方面面来说，这个理论的适用性又如何呢？我们应当怎样做，才能给法庭证言的可信度赋予一个确定的合理概率呢？而英格兰的查理一世和苏格兰女王玛丽，哪个才是更棒的高尔夫球手（这两个人都热衷于打高尔夫球）？伯努利相信，如果想要让理性的决策成为可能，就必须有一个可靠的数学方法来确定概率。他的这种观点实际上反映了他所处时代的文化氛围。在当时的氛围中，一个人被大家认为具备理性的一个标志，就是他能按照符合概率期望的方式行事。但在伯努利看来，主观性并非禁锢旧的随机理论的唯一因素。他也认识到，这个理论不是为无知的情况设计的，在这种情况下，虽然我们原则上能够定义每种可能结果的发生概率，但这些概率的值实际上是未知的。这就是我与莫希谈论的问题，也是贾格尔需要解决的问题：一个不完美的骰子扔出 6 点的机会有多大？你感染上瘟疫的可能性有多大？你的胸甲能挡住对手长剑一刺的可能性又有多大？在主观和不确定的情况下指望我们能掌握惠更斯书中所预设的那些先验概率，这种念头在伯努利看来，简直就是一种「精神错乱」。

正如贾格尔所做的，伯努利认识到这个问题的答案就是：我们不应该依靠那些硬塞到我们手中的概率，而应该通过观测找出这些概率。作为一名数学家，他努力将这个思路精确化。假定我们对一台轮盘赌机进行了若干次观察，那么我们由此估计得到的每个槽获胜的概率，跟隐含的真实获胜概率相比，两者有多接近呢？对于这样估计得到的概率，我们对其正确性又该抱有多强的信念呢？我们将在下一章回顾这些问题，因为它们并不是伯努利能解决的问题。伯努利回答的实际上是与之紧密相关的另外一个问题：我们的观测结果能以多高的准确度，来体现造成这些结果的隐含概率？伯努利认为，随着实验次数的增加，我们显然有理由期望，实际观测到的各种结果的出现频率，应该能越来越精确地体现真实的概率。他肯定不是最早有这种念头人，不过他是把问题进行形式化处理，将思路转化为证明并利用量化的方式进行处理的第一人。他提出的问题具体一点儿说，是这样的：要通过观测结果估计概率，我们至少需要做多少次实验？对于这样得到的结果，我们对它的正确性又有多大把握？在解决这些问题的过程中，他同时认识到微积分这个新学科的重要性，并成为最早认识到这一点的人群中的一员。

2『伯努利回答的问题：想到要通过观测结果估计概率，我们至少需要做多少次实验？对于这样得到的结果，我们对它的正确性又有多大的把握？这就是大数定理解决的问题。做一张主题卡片。（2021-02-20）』

事后看来，伯努利在巴塞尔被提名为教授的那一年，在数学史上具有里程碑式的意义：正是在那一年，戈特弗里德·莱布尼兹发表了一篇革命性的论文。作为 1684 年发表的关于微积分的论文的补充，在新论文中，他阐述了微积分运算的原理。而在 1687 年，牛顿在常被简称为《原理》的《自然哲学的数学原理》一书中，对同样的问题给出他自己的处理方法。这些进展将是伯努利解决之前那个随机性问题的关键。

在莱布尼兹和牛顿各自发表他们的论文时，他们都已经在微积分问题上研究了很多年。但是，由于他们的成果几乎是同时发表的，这就引起了一番争论：到底是谁最早提出这个想法的？伟大的数学家卡尔·皮尔逊（我们将在第 8 章提到他）认为，数学家「流传后世（的声望），很大程度上并不在于他们做了什么，而在于同时代的人认为他们做了什么」。牛顿和莱布尼兹应该会赞同这种观点。无论如何，这两个人都免不了一场激烈的争论，而随后发生的那场争论非常激烈，最终的结果好坏参半。德国人和瑞士人学习微积分时，用的是莱布尼兹的著作，而英国人与许多法国人读的是牛顿的书。从现代观点来看，这两种微积分之间的差别十分微小，但长期以来，人们往往更强调牛顿的贡献，因为看起来确实是他更早一点儿提出这个想法的。当牛顿在《原理》一书中建立起现代物理学的时候，他应用了这一想法。正是现代物理学的建立，使《原理》成为或许是有史以来最伟大的科学著作。不过莱布尼兹建立了一套更好的表示方法，而我们经常使用的，就是这套表示方法。

两位的著作都不容易读懂。《原理》一书除了被认为是最伟大的科学著作，同时获得了「有史以来最难理解的图书之一」的称号。而按照雅各布·伯努利的一位传记作者的话来说，「根本没有人能看懂」莱布尼兹的著作，因为这本书不仅言语晦涩难懂，而且满是印刷错误。雅各布的弟弟约翰则称它为「谜题而非解答」。实际上，两部著作都相当晦涩难懂，因此有学者猜测这两位是不是有意而为之，以便劝退各路业余爱好者。不过这谜题一般的风格确实能够把天分的高低区分得清清楚楚，对雅各布·伯努利而言，这种风格倒不失为一个优点，因为他的智力明显高于常人。当他参透了莱布尼兹的思想时，他就拥有了一件有力的武器，而这件武器的拥有者的人数，在全世界来说是屈指可数的。有了这件武器，伯努利就能轻而易举地解决足以令他人望而却步的难题。

跟伯努利的工作一样，微积分的核心概念就是序列、级数和极限。对数学家或其他人来说，序列这个词表达的意思几乎是一样的：按顺序排列的若干元素（如点或数字）。级数则是一系列数字的和。而极限，不那么严密地说，如果某序列的组成元素似乎指向某个地方，比如某个特定的端点或数字，那么该处就被称为该序列的极限。

尽管微积分把对序列的理解提升到一个新高度，但与许多其他概念一样，古希腊人其实早已熟知。实际上，公元前 5 世纪的古希腊哲学家芝诺，就通过一个令人惊讶的序列，创造出一个至今仍然让哲学专业的大学生们争论不休的悖论，特别是当他们在几杯啤酒下肚之后。芝诺悖论的描述大体如下：设想有一个学生想朝 1 米外的门口走去（1 米只不过是为了叙述方便，但下面的说法对于 1 英里或其他任何距离而言都是一样的）。在这名学生到达门口之前，她首先必须到达这段距离的中点；而为了到达这个中点，她必须到达这一半距离的中点，也就是 1/4 距离点；如此下去，直至无穷。换句话说，为了到达目的地，她必须走过下面这个序列中的这些距离：1/2 米、1/4 米、1/8 米、1/16 米等等。芝诺因此说，由于这个序列无穷无尽，所以这个学生必须越过无穷多的有限距离，而这将耗费无穷多的时间。芝诺由此得出结论：她其实根本动弹不得。

千百年来，从亚里士多德到康德的哲学家们，都在这个困境上争来辩去。犬儒学派的创始人第欧根尼用一种经验主义的方式来解决这个问题：他不过就是起身走了几步，然后说明物体确实是在运动的。对于我们这些并非哲学专业的人而言，这个答案听起来挺不错。可是这个回答打动不了芝诺。芝诺当然清楚他的逻辑与我们感受的运动之间的矛盾，只不过跟第欧根尼不同，芝诺更相信逻辑。而且他的努力也并非毫无效果。即使第欧根尼本人大概也不得不承认，他的那个回答把我们带入另一个令人困惑（而且最终被证明是十分深刻）的问题中：如果我们的感觉是正确的，那么芝诺的逻辑错在何处？

让我们看看芝诺悖论中的这个距离序列：1/2 米、1/4 米、1/8 米、1/16 米……（距离越来越短。）这个序列有无穷多项，因此，我们无法通过直接相加得到整个序列的总和。但我们注意到，尽管这些距离的项数有无穷多，每项的值却一个比一个小。在这个序列中，无穷无尽的项数，和无休无止缩短的每项距离，这两者会不会相互抵消而给出一个有限的总和呢？序列、级数和极限等概念所解释的正是这类问题。现在我们看看具体是怎么做的。我们不再试图去实际计算芝诺那无穷多的间隔累加起来后，所给出的学生行走过的距离，而是考虑每次多加一个间隔，那么得到的结果是怎样的？下面就是经过最初几个间隔后学生走过的距离：

第一个间隔后：1/2 米

第二个间隔后：1/2 米 + 1/4 米 = 3/4 米

第三个间隔后：1/2 米 + 1/4 米 + 1/8 米 = 7/8 米

第四个间隔后：1/2 米 + 1/4 米 + 1/8 米 + 1/16 米 = 15/16 米

1/2 米，3/4 米，7/8 米，15/16 米…… 我们可以在这些数字中发现一种模式：它们的分母是 2 的幂，而分子总比分母小 1。根据这个模式，我们可以猜出，在经过头 10 个间隔后，这名学生将走过 1023/1024 米的距离；而在头 20 个间隔后走过的距离是 1048575/1048576 米；等等。从这个模式可以看出，间隔越多，走过的距离越长，在这一点上，芝诺越对。不过他说因此总距离就是无穷大 —— 错了。从上面这些数字来看，它们好像越来越接近 1，或者用数学家的话来说，1 米就是这个距离序列的极限。这么一来，一切都说得通了：尽管芝诺把学生到门之间的这段旅程剪成了无穷多个间隔，但学生终归还是只需要越过 1 米的距离。

芝诺悖论说的倒不是这段旅程的长度，而是走完这段旅程需要的时间。如果我们的学生得一步一个间隔地走，那么时间确实会成为一个问题（我们就不说她得怎样才能迈出那些比 1 毫米还要小得多的小碎步了）！但如果她可以按正常速度行走，而不必在每个芝诺想象出来的检查站停顿一下（为什么要停呢？），那么跨过每个芝诺间隔的时间，就跟间隔长度成正比了。既然现在总的距离是有限的，那么需要的总时间自然也有限。我们确实挺走运的，毕竟运动对我们而言还是可能的。

虽然现代的极限概念要到芝诺甚至伯努利过世很久之后的 19 世纪才会出现，但正是这个概念，蕴涵了微积分的核心思想。雅各布·伯努利也正是用这个思想，来处理概率与观察结果之间的关系的。更具体点儿说，伯努利研究的是任意大数量的重复实验所给出的极限情况。将一枚（均匀的）硬币扔上 10 次，也许有 7 次是正面朝上；但如果这个扔硬币的次数是一个无限大的数目，那么最可能得到的正面朝上的比例将非常接近 50%。20 世纪 40 年代，南非数学家约翰·克里奇决定用实验来验证一下这个结论。他把一枚硬币扔了又扔，扔的次数肯定赶得上恒河里沙子的数量了（好吧，其实是扔了 1 万次），然后记录下每次扔出的结果。你肯定会奇怪，这位克里奇老兄就没啥别的更紧要的事情好做了？不过还真没有，他当时是一名战囚，德国人在 1940 年 4 月侵入丹麦时，不走运的他正好在哥本哈根访问。根据克里奇得到的数据，在前 100 次中，得到正面朝上的比例只有 44%；但到了 1 万次的时候，得到的结果就很接近对半开了：正面的比例为 50.67%。但我们应该用什么样的定量公式来描述这个结果呢？这正是伯努利取得的成就。

按科学史学家和哲学家伊恩·哈金的话来说，伯努利的工作被「公之于众时，就夺目地预示着我们如今所知的这个理论的所有成就；它的数学深度，它无限的实际应用，它不断转换的二元视角，让我们不断从哲学层面上去思考。概率论至此完全显现出来」。伯努利自己倒是更谦虚一些，他称自己的研究被证明具有「创新性，以及…… 高度实用性」。他还写道，这个研究过程充满了「令人殚精竭虑的困难」。他在这项研究上投入了整整 20 年。

这个耗费了 20 年努力才达到的巅峰，被雅各布·伯努利称为「黄金定理」。不过这个定理的各个（相互间仅有些微技术性差别的）现代版本有好几个名字：伯努利定理，大数定律，以及弱大数定律。正如我们已经看到的，使用大数定律这个术语，是因为伯努利定理所说明的，就是大量观测的结果是如何体现隐含概率的。不过我们在这里还是继续沿用伯努利「黄金定理」的叫法，因为我们下面的讨论，将在这条定理最原始的形式上展开。

尽管伯努利对定理在实际中的应用很感兴趣，但他在举例的时候，却最喜欢用一样恐怕我们大多数人家里都找不到的东西：一个装满了各色鹅卵石的瓮。在一个例子中，他这个瓮里装了 3000 颗白鹅卵石和 2000 颗黑鹅卵石，也就是 60∶40 的白黑比例。然后我们蒙上眼睛，从这个瓮里「返还式地」摸出一系列鹅卵石。这里的「返还式」的含义，是指我们在取出下一枚鹅卵石之前，要把上次取出的石子放回瓮里，以保证 3∶2 的白黑比不会发生改变。这样一来，我们每次摸到白色石子的先验概率就是 3/5，或者 60%。在这个例子里，伯努利所关心的问题是：按照这种方式摸出一系列石子后，其中白色石子的数量跟这个 60% 的比例吻合的程度有多好？而发生这种吻合程度的概率又是多少？

这个瓮是个好例子，因为用来描述从瓮里摸取鹅卵石的那些数学内容，也能用来描述任何一系列具有两种可能结果的试验，只要这些结果的出现是随机的，且各次试验结果相互独立。我们现在称此类试验为伯努利试验，而一系列伯努利试验就构成了一个伯努利过程。如果一个随机试验有两种可能的结果，我们常常认为其中一个结果表示「成功」，另一个自然就表示「失败」了。当然，这样的记号并不严格表示它们的字面意义，实际上，这两种记号有时根本与这两个词的日常含义无关。以我们平时说的成功或失败为例，如果这本书让你迫不及待地想往下读，它就是成功的；如果它唯一的用处，是你在壁炉里的木柴都被烧完之后，用它来给自己和心上人取暖，这本书就失败了。不过更多地，我们扔硬币得到正面或反面朝上，投票给候选人 A 或 B，生男或生女，买或不买某件商品，病愈或未愈，甚至是死亡或生存，这些也都是伯努利试验用到的例子，我们也用「成功」和「失败」来描述这些可能的结果。哪怕一些行为有超过两种的可能结果，但如果我们针对结果提出的问题可以用「是」或「不是」来回答，那么这样的问题同样可以用伯努利试验来描述，比如「骰子是不是扔出了 4 点？」或「北极还有没有冰？」之类的问题。因此，伯努利写的虽然是石子和瓮，但他所有的例子都能原封不动地用于许多其他类似的场合。

理解了这一点之后，让我们再回到那个 60% 的鹅卵石是白色的瓮上。如果你从瓮里（返还式地）取出 100 颗鹅卵石，你也许会发现其中恰好有 60% 是白色的。不过你同样有可能只抽到 50 颗或 59 颗白色石子。那么，你取出的石子中，58% 到 62% 的石子是白色的机会有多大？如果是 59% 到 61% 呢？如果你不是取 100 颗，而是取 1000 颗或 100 万颗鹅卵石，那么这时我们对结果的信任又能增加多少？我们当然永远没办法百分之百地确信这样做得到的结果，但是我们能不能抽取足够多的鹅卵石，从而有 99.9999% 的把握，保证取到白色石子的比例在 59.9% 到 60.1% 之间？伯努利的黄金定理要解决的，就是诸如此类的问题。

在应用黄金定理之前，你需要首先进行两个选择。首先，你要给定一个可容忍的误差范围。大量试验的结果与真实的 60% 的比例，两者之间应该有多接近呢？你必须就此指定一个接近的范围，比如 60%±1% 或 60%±2% 或 60%±0.00001%。其次，你必须明确你对不确定性的容忍度。你永远无法 100% 地确定试验会给出你想要的结果，但你能够有把握做到比如在 100 次试验中获得 99 次满意的结果，或者在 1000 次试验中有 999 次是满意的。

黄金定理指出，你总能通过取出足够多的鹅卵石，保证你能几乎确定所得的白色鹅卵石比例很接近 60%，而不论几乎确定和接近的定义是何等严苛。而且，在给定了这个几乎确定和接近的具体数值后，定理还给出用来计算这个「足够」次数的数学公式。

定理的第一部分是一次理念上的胜利，也是定理中唯一能幸存到各个现代版本中的部分。而关于伯努利公式，这个定理的第二部分，重要的是我们要知道，尽管黄金定理给出一个足以满足你要求的置信度与准确度的试验次数，但这并不意味着我们不能通过更少的试验来达到同样的目标。但这并不影响定理的第一部分，因为第一部分只是说这个特定的试验次数总是有限的。伯努利希望他的公式能给出实际可行的答案，但不幸的是，在大多数实际应用中，这个公式很难实现这一点。这里有一个伯努利自己解出的数值例子，我稍微改动一下文字的先后顺序：假设巴塞尔市长在选民中的实际支持率为 60%；现在我们希望对选民进行民意调查，要使调查显示对市长的支持率在 58% 到 62% 之间（即在真实支持率的正负 2 个百分点区间内）的概率为 99.9%，那么至少需要调查多少位选民？（为了与伯努利的问题保持一致，我们假定采用返还式的采样方式随机选取被调查者。换句话说，同一名被调查者有可能被询问不止一次。）这个问题的答案是 25550 人。这也差不多就是伯努利那个年代巴塞尔城的人口。伯努利并没有将这个不实用的结果扔到一边，因为他知道，老练的赌徒根本用不着几千次试验，就能凭直觉猜出一种新的赌博方式中获胜的概率。

伯努利的公式给出的估计值如此不理想的一个原因，是他的证明基于许多近似值。还有一个原因是，他选择的置信度标准是 99.9%，也就是说结果出错（与真实概率偏差超过 2 个百分点）的概率小于 1/1000。这实在是一个非常苛刻的标准。伯努利称它为道德确定性，是指他认为一个理性的人在进行理性的决策时所应具有的确定性程度。我们现在已经抛弃了道德确定性这种提法，更多地使用在上一章中提到的统计显著性，这意味着你的答案在 20 次中只有不到一次出错的可能。这也许是一种衡量时代变化的方式。

统计学家利用现在的数学方法已经证明，对上面那个民意调查，我们只需要抽查区区 370 名被调查者，就能得到一个具有统计显著性的结果，其准确度在正负 5% 之间。如果调查人数上升到 1000 人，那么调查结果落在真实答案（巴赛尔市长 60% 的真实支持度）2 个百分点的误差范围内的可能性是 90%。尽管伯努利的黄金定理存在各种局限，但是它仍然是数学史上的一座里程碑，因为它至少从原则上证明了，足够大的样本几乎能肯定地反映出被采样群体的真实构成。

在现实生活中，我们通常不会靠几千次的试验来观察人或事物的表现。因此，如果说伯努利错在把确定性标准定得过于严格了，那么在实际生活中，我们常常又会犯下相反的错误：我们假设一个样本或一系列试验的结果体现了潜在情况，但实际上它太小了，并不可靠。举例来说，如果在伯努利那个年代，我们恰好调查了 5 位巴塞尔居民，根据第 4 章中的计算，这个调查能够得到正确的结果，也就是被调查者中的 60%（或 3 人）支持市长，这种情况出现的可能性仅为 1/3。

仅仅 1/3？在对某选民样本进行调查时，市长支持者在人群中的真实比例，难道不应该是最可能的结果吗？事实上，1/3 的确是最可能的结果：调查中碰到 0 个、1 个、2 个、4 个或 5 个支持者的可能性，都比碰到 3 个支持者的可能性小。即使是这个最大的碰到 3 个支持者的可能性，也不太可能：因为有太多非代表性的可能性存在，它们的总和比得到正确结果的可能性大了两倍。所以，对 5 名选民进行调查，每 3 次中就会有 2 次得到「错误」的支持率。事实上，每 10 次这样的调查中，就差不多有 1 次会得出 5 名选民都支持或都不支持市长的结果。如果我们只关注 5 个样本，那么市长真实的支持率很可能被严重高估或低估。

小样本准确反映潜在概率的错误观念（或错误直觉）如此普遍，以至卡尼曼和特沃斯基给它专门起了个名字：小数定律。小数定律并不是一条正儿八经的定律，它只是一个带有讽刺性的名字，用来描述在数字不大的情况下，试图应用大数定律的错误做法。

如果人们只把这个（不正确的）小数定律用在那些鸡毛蒜皮的事情上，倒也没什么大不了的后果。不过我们之前已经提到过，我们生活中的许多事情都可以被看成伯努利过程，因此这个小数定律的直觉，经常让我们对我们看到的事物做出错误的解释。这也就是为什么在第一章中，当人们看到兰辛或坎顿们那屈指可数的几个成功或不够成功的年头时，会认为他们的这些表现能准确预测他们将来的表现。

现在，我们把上面的解决思路用到第 4 章提到过的一个例子上，就是两个公司之间或公司内部两个员工之间的竞争。现在让我们考察一下《财富》500 强公司的首席执行官们。我们假设，这些首席执行官每人都因其学识和能力有一定的概率获得成功（不管他 / 她的公司是如何定义成功的）。同时，为了简化问题，我们假设年终总结时这些首席执行官的成功概率，就跟瓮里的白鹅卵石或市长支持者的比例一样，也是 60%（具体的值高一点儿或低一点儿，都不影响我们论证的核心）。这是不是意味着，我们应该预期，在某个给定的 5 年内，一位首席执行官恰好会有 3 年的好时光？

并非如此。之前的分析表明，即使这些首席执行官都有一个还算过得去的 60% 的先验成功率，但在某个给定的 5 年期间，某特定的首席执行官的职场表现准确符合这一成功率的可能性，仅仅是 1/3！套用到《财富》500 强的例子里，这就意味着在过去的 5 年中，大约有 333 名首席执行官的实际表现并没有反映出他们真正的能力。我们还可以进一步指出，很可能有约 1/10 的首席执行官在这 5 年中会连赢或连输，而造成这种结果的不过是偶然因素。这个事实告诉了我们怎样的道理？它告诉我们，评价一个人更可靠的方法，应该是具体分析他具备的能力，而不是仅仅看业绩表上的分数。或者用伯努利的话来说：「我们不应该以成败论英雄。」

要摆脱小数定律的控制，我们需要一些特殊的能力。躺在沙发里，看着业绩表的最下一行，然后指点一番，这是任何人都能做到的。但评判一个人的真才实学，需要信心、思考、良好的判断以及勇气。开会的时候，你可不能就这么不管不顾地跳出来，对着同事一通大吼：「不要解雇她！她只不过是碰巧处于伯努利序列错误的一端！」当然，如果你跳出来冲着那个志得意满、刚成为销售史上卖出最多丰田凯美瑞的家伙说「你不过就是碰到个随机波动而已」，那么这种做法也不太可能让你赢得朋友。但用后一种方式去评价他人的事情很少发生。高管们的成功总会被归功于他们的聪明才智，而且这些才智是通过深刻的后见之明得来的。而当他们失败时，我们又常常认为这些失败准确地反映了他们的天分与能力的高低。

另一个与大数定律有关的错误的思维方式，就是仅根据事情在最近的发生情况，认定它更可能或更不可能发生。认为某一事件的概率的增加或减少取决于该事件最近一段时间内的出现情况，这种错误叫作赌徒谬论。拿克里奇扔硬币的事儿来说，哪怕他在最开始的 100 次中只扔出 44 次正面朝上，这枚硬币也不会变得更偏向正面朝上，好让正面朝上的次数赶上反面朝上的次数。这个赌徒谬论，就是诸如「她的运气用光了」或「轮也该轮到他了」之类想法的根本所在，而这种事情其实根本不会发生。不管你信不信，好运连连本身并不会给你带来霉运；而一个接一个的坏消息，也并不代表转运的曙光就在前方等着你。不过被赌徒谬论有意无意影响的人，可比你想象的多得多。人们总是期待着倒霉后面会有好运紧随，或者担心顺风顺水的下一刻就是狂风巨浪。

我还记得几年前，我曾在一艘游轮上看到过一个矮胖男人，他满头大汗，充满激情，疯狂地把手中的硬币接二连三地塞到老虎机里，老虎机吞得有多快，他就塞得有多快。他的同伴发现我正盯着他们看，就简单地跟我解释了一句：「他走运的时候就快到了。」尽管我很想对他说：「不，他走运的时候可还没到。」但终于我还是没说出口就走开了。结果刚走出没几步，突然闪动的灯光，响个不停的铃声，这对儿好友发出的不小的喊叫声，以及那哗啦啦肯定响了好几分钟的硬币从老虎机流泻而出的声音，让我停下了脚步。现代的老虎机是由计算机控制的，它的输赢是由随机数生成器驱动的，而且根据法律和法规，这个随机数生成器产生的必须是名副其实真正的随机数，以保证每次搬下手柄时的结果都完全独立于之前的输出。然而…… 好吧，我们还能说什么呢？赌徒谬论实在是一种强大的错觉。

伯努利提出黄金定理的手稿结束得十分突兀，而在手稿的开头，他还许诺会给出定理在公众事务及经济问题等若干不同方面的应用。统计史学家斯蒂芬·施蒂格勒写道，大概是「伯努利在看到 25550 这个数字后，就死心塌地地放弃了」。事实上，当 1705 年 8 月时年 50 岁的伯努利死于「慢性发热」时，他正在准备手稿的出版。出版商请求约翰·伯努利续完手稿，但他以事情太多为由拒绝了。这听起来可能很奇怪，不过这本来就是个奇怪的家族。如果要评选史上最不开心的数学家，你就选约翰·伯努利吧，估计不会错。许多历史文献将他描述成一个嫉妒、虚荣、敏感、固执、脾气糟糕、自卖自夸、毫无诚信的登峰造极的骗子。他在数学方面颇有成就，但下面这件事为人熟知的程度，并不亚于他的数学成就。当时他跟儿子丹尼尔都参加了一场竞赛，丹尼尔在竞赛中胜出。约翰试图窃取他的哥哥和莱布尼茨的观点，并抄袭丹尼尔《流体动力学》一书，篡改了出版日期，让他的书看起来出版时间更早，最终把丹尼尔踢出了法国科学院。

在收到续写过世兄长的手稿这个请求时，约翰刚好从荷兰的格罗宁根大学来到巴塞尔大学，获得了一个希腊语教授而非数学教授的职位。雅各布本人也觉得这个职业变动颇为可疑，特别是他觉得约翰并不懂希腊语。在写给莱布尼兹的信中，雅各布怀疑约翰来到巴塞尔大学是为了篡夺自己数学教授的位子。的确，雅各布一去世，约翰就获得了这个职位。

约翰和雅各布两人在成人之后的大部分岁月中，相处得都不算融洽。在数学著作和书信中，他们颇为常态化地相互羞辱对方，一位数学家就此事曾经写道：「他们那些愤怒又激烈的言辞，在别人那儿通常是为偷马贼保留的。」因此，编辑雅各布遗稿这个任务，就落到了更下一层雅各布的侄子尼古拉 —— 雅各布另一位同样名叫尼古拉的兄弟的儿子 —— 的身上。小尼古拉当时只有 18 岁，不过他也曾是雅各布的学生之一。不幸的是，他感到自己不能胜任这项任务，另外也可能有部分原因是，他清楚地知道，莱布尼兹并不赞同他伯父应用这个理论的那些想法。手稿因此又沉睡了 8 年。最终，手稿以《猜度术》为名于 1713 年出版。和帕斯卡的《思想录》一样，该书至今仍在不断被印刷出版。

1-2『猜度术的电子版目前没找到，已下载书籍「2021072思想录」。（2021-02-20）』

雅各布·伯努利已经表明，我们可以通过数学分析，了解自然系统内部的隐含概率是如何在这些系统产生的数据中被反映出来的。至于伯努利没有回答的那个如何根据观测数据推断事件的隐含概率的问题，它的答案在几十年后才会被揭晓。