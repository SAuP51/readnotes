## 记忆时间

## 卡片

### 0101. 反常识卡——

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

### 0201. 术语卡——

根据反常识，再补充三个证据——就产生三张术语卡。

### 0202. 术语卡——

### 0203. 术语卡——

### 0301. 人名卡——

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

### 0401. 金句卡——

最后根据他写的非常震撼的话语——产生一张金句卡。

### 0501. 任意卡——

最后还有一张任意卡，记录个人阅读感想。

## 模板

### 1. 逻辑脉络

用自己的话总结主题，梳理逻辑脉络，也就是这本书整个地图里这一章所在的节点。

### 2. 摘录及评论

1『自己的观点』

2『行动指南』

3『与其他知识的连接』

## 2020018周志华的机器学习0101.md

### 1. 逻辑脉络

用自己的话总结主题，梳理逻辑脉络，也就是这本书整个地图里这一章所在的节点。

### 2. 摘录及评论

回头看第一段话，我们会发现这里涉及很多基于经验做出的预判。例如，为什么看到微湿路面、感到和风、看到晚霞，就认为明天是好天呢？这是因为在我们的生活经验中已经遇见过很多类似情况，头一天观察到上述特征后，第二天天气通常会很好。为什么色泽青绿、根蒂蜷缩、敲声浊响，就能判断出是正熟的好瓜？因为我们吃过、看过很多西瓜，所以基于色泽、根蒂、敲声这几个特征我们就可以做出相当好的判断。类似的，我们从以往的学习经验知道，下足了工夫、弄清了概念、做好了作业，自然会取得好成绩。可以看出，我们能做出有效的预判，是因为我们已经积累了许多经验，而通过对经验的利用，就能对新情况做出有效的决策。

上面对经验的利用是靠我们人类自身完成的。计算机能帮忙吗？

机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。在计算机系统中，「经验」通常以「数据」形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生「模型」（model）的算法，即「学习算法」（learning algorithm）。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时（例如看到一个没剖开的西瓜），模型会给我们提供相应的判断（例如好瓜）。如果说计算机科学是研究关于「算法」的学问，那么类似的，可以说机器学习是研究关于「学习算法」的学问。本书用「模型」泛指从数据中学得的结果。有文献用「模型」指全局性结果（例如一棵决策树）而用「模式」指局部性结果（例如一条规则）。

『Mitchell 给出了一个更形式化的定义：假设用 P 来评估计算机程序在某任务类 T 上的性能，若一个程序通过利用经验 E 在 T 中任务上获得了性能改善，则我们就说关于 T 和 P，该程序对 E 进行了学习。』

要进行机器学习，先要有数据。假定我们收集了一批关于西瓜的数据，例如（色泽 = 青绿；根蒂 = 蜷缩；敲声 = 浊响）,（色泽 = 鸟黑；根蒂 = 稍蜷；敲声 = 沉闷）,（色泽 = 浅白；根蒂 = 硬挺；敲声 = 清脆）, ……，每对括号内是一条记录，「=」意思是「取值为」。

这组记录的集合称为一个「数据集」（data set），其中每条记录是关于个事件或对象（这里是一个西瓜）的描述，称为一个「示例」（(instance）或「样本」（sample）。反映事件或对象在某方面的表现或性质的事项，例如「色泽」「根蒂」「敲声」，称为「属性」（attribute）或「特征」（eature）；属性上的取值，例如「青绿」「乌黑」，称为「属性值」（attribute value）。属性张成的空间称为「属性空间」（attribute space）、「样本空间」（sample space）或「输入空间」。例如我们把「色泽」「根蒂」「敲声」作为三个坐标轴，则它们张成个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位置。由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个「特征向量」（feature vector）。

『有时整个数据集亦称一个「样本」，因为它可看作对样本空间的一个采样；通过上下文可判断出「样本」是指单个示例还是数据集。』

一般地，令 D={x1, x2,, xm} 表示包含 m 个示例的数据集，每个示例由 d 个属性描述（例如上面的西瓜数据使用了 3 个属性），则每个示例 xi= (x; xi2; …xid）是 d 维样本空间 X 中的一个向量，xi ∈ X，其中 xij 是 xi 在第 j 个属性上的取值（例如上述第 3 个西瓜在第 2 个属性上的值是「硬挺」），d 称为样本 x1 的「维数」（dimensionality）。

从数据中学得模型的过程称为「学习」（earning）或「训练」（training），这个过程通过执行某个学习算法来完成。训练过程中使用的数据称为「训练数据」（training data），其中每个样本称为一个「训练样本」（training sample），训练样本组成的集合称为「训练集」（training set）。学得模型对应了关于数据的某种潜在的规律，因此亦称「假设」（hypothesis）；这种潜在规律自身，则称为「真相」或「真实」（ground-truth），学习过程就是为了找出或逼近真相。本书有时将模型称为「学习器」（learner），可看作学习算法在给定数据和参数空间上的实例化。

『训练样本亦称「训练示例」（training Instance）或「训练例」。学习算法通常有参数需设置，使用不同的参数值和积（或）训练数据，将产生不同的结果。将「label」译为「标记」而非「标签」，是考虑到英文中「label」既可用作名词、也可用作动词。』

如果希望学得一个能帮助我们判断没剖开的是不是「好瓜」的模型，仅有前面的示例数据显然是不够的。要建立这样的关于「预测」（prediction）的模型，我们需获得训练样本的「结果」信息，例如「（色泽 = 青绿；根蒂 = 蜷缩；敲声 = 浊响），好瓜）」。这里关于示例结果的信息，例如「好瓜」，称为「标记」（label）；拥有了标记信息的示例，则称为「样例」（example）。一般地，用 (xi, yi）表示第个 i 个样例，其中 yi∈Y是示例 xi 的标记，Y 是所有标记的集合，亦称「标记空间」（abel space）或「输出空间」。

『若将标记看作对象本身的一部分，则「样例」有时也称为「样本」。』

若我们欲预测的是离散值，例如「好瓜」「坏瓜」，此类学习任务称为「分类」（classification）；若欲预测的是连续值，例如西瓜成熟度 0.95、0.37, 此类学习任务称为「回归」（regression）。对只涉及两个类别的「二分类」（binary classification）任务，通常称其中一个类为「正类」（positive class），另一个类为「反类」（negative class）；涉及多个类别时，则称为「多分类」（multi-class classification）任务。一般地，预测任务是希望通过对训练集 {(x1, y1), (x2, y2),, (xm, ym)} 进行学习，建立一个从输入空间 X 到输出空间 Y 的映射 f：X→Y。对二分类任务，通常令 y={-1, +1} 或 {0,1｝；对多分类任务，|y| > 2；对回归任务，y=R，R 为实数集。

『若将标记看作对象本身的一部分，则「样例」有时也称为「样本」。「反类」亦称「负类」。』

学得模型后，使用其进行预测的过程称为「测试」（(testing），被预测的样本称为「测试样本」（testing sample）。例如在学得 f 后，对测试例 x，可得到其预测标记 y=f (x)。

『亦称「测试示例」（testing Instance）或「测试例」。』

我们还可以对西瓜做「聚类」（clustering），即将训练集中的西瓜分成若干组，每组称为一个「簇」（cluster）；这些自动形成的簇可能对应一些潜在的概念划分，例如「浅色瓜」「深色瓜」，甚至「本地瓜」「外地瓜」。这样的学习过程有助于我们了解数据内在的规律，能为更深入地分析数椐建立基础。需说明的是，在聚类学习中，「浅色瓜」「本地瓜」这样的概念我们事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息。

『否则标记信息直接形成了簇划分；但也有例外情况，参见 13.6 节。』

根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：「监督学习」（supervised learning）和「无监督学习」（unsupervised learning），分类和回归是前者的代表，而聚类则是后者的代表。

1『亦称「有导师学习」和「无导师学习」』

需注意的是，机器学习的目标是使学得的模型能很好地适用于「新样本」而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能适用于没在训练集中出现的样本。学得模型适用于新样本的能力，称为「泛化」（generalization）能力。具有强泛化能力的模型能很好地适用于整个样本空间。于是，尽管训练集通常只是样本空间的一个很小的采样，我们仍希望它能很好地反映出样本空间的特性，否则就很难期望在训练集上学得的模型能在整个样本空间上都工作得很好。通常假设样本空间中全体样本服从一个未知「分布」（distribution）D，我们获得的每个样本都是独立地从这个分布上采样获得的，即「独立同分布」（independent and identically distributed，简称 i.i.d.) 一般而言，训练样本越多，我们得到的关于 D 的信息越多，这样就越有可能通过学习获得具有强泛化能力的模型。

1『「新样本」更确切地说，是「未见示例」  (unseen Instance）。现实任务中样本空间的规模通常很大（例如 20 个属性，每个属性有 10 个可能取值，则样本空间的规模已达 10^20）。』




