## 0801. Reframing Techniques

Students of the intelligence profession have long recognized that failure to challenge a consensus judgment or a well-established mental model has caused most major intelligence failures. The postmortem analysis of virtually every major U.S. intelligence failure since Pearl Harbor has identified an analytic mental model or outdated mindset as a key factor contributing to the failure. Appropriate use of the techniques in this chapter can, however, help mitigate a variety of common cognitive limitations and improve the analyst's odds of getting the analysis right.

This record of analytic failures has generated discussion about the "paradox of expertise." 1 Experts can be the last to recognize the occurrence and significance of change. For example, few specialists on the Middle East foresaw the events of the Arab Spring, few experts on the Soviet Union foresaw its collapse, and almost every economist was surprised by the depth of the financial crisis in 2008. Political analysts in 2016 also failed to forecast the United Kingdom vote to leave the European Union or Donald Trump's election to the presidency of the United States.

As we noted in chapter 2 , an analyst's mental model is everything the analyst knows about how things normally work in a certain environment or a specific scientific field. It tells the analyst, sometimes subconsciously, what to look for, what is important, and how to interpret what he or she sees. A mental model formed through education and experience serves an essential function: it is what enables the analyst to provide routinely reasonably good intuitive assessments or estimates about what is happening or likely to happen.

What gets us into trouble is not what we don't know, it's what we know for sure that just ain't so.

—Mark Twain, American author and humorist

The problem is that a mental model that has previously provided accurate assessments and estimates for many years can be slow to change. New information received incrementally over time is easily assimilated into one's existing mental model, so the significance of gradual change over time is easily missed. It is human nature to see the future as a continuation of the past. Generally, major trends and events evolve slowly, and the future is often foreseen by skilled intelligence analysts. However, life does not always work this way. The most significant intelligence failures have been failures to foresee historical discontinuities, when history pivots and changes direction.

In the wake of Al-Qaeda's attack on the United States on September 11, 2001, and the erroneous 2002 National Intelligence Estimate on Iraq's weapons of mass destruction, the U.S. Intelligence Community came under justified criticism. This prompted demands to improve its analytic methods to mitigate the potential for future such failures. For the most part, critics, especially in the U.S. Congress, focused on the need for "alternative analysis" or techniques that challenged conventional wisdom by identifying potential alternative outcomes. Such techniques carried many labels, including challenge analysis, contrarian analysis, and Red Cell/Red Team/Red Hat analysis.

U.S. intelligence agencies responded by developing and propagating techniques such as Devil's Advocacy, Team A/Team B Analysis, Red Team Analysis, and Team A/Team B Debate. Use of such techniques had both plusses and minuses. The techniques forced analysts to consider alternative explanations and explore how their key conclusions could be undermined, but the proposed techniques have several drawbacks.

In a study evaluating the efficacy of Structured Analytic Techniques, Coulthart notes that techniques such as Devil's Advocacy, Team A/Team B Analysis, and Red Teaming are not quantitative and are more susceptible to the biasing found in System 1 Thinking. 2 This observation reinforces our view that this book should give more weight to techniques, such as Analysis of Competing Hypotheses or Structured Self-Critique, that are based on the more formalized and deliberative rule processes consistent with System 2 Thinking.

Another concern is the techniques carry with them an emotional component. No one wants to be told they did something wrong, and it is hard not to take such criticism personally. Moreover, when analysts feel obligated to defend their positions, their key judgments and mindsets tend to become even more ingrained.

One promising solution to this dilemma has been to develop and propagate Reframing Techniques that hopefully accomplish the same objective while neutralizing the emotional component. The goal is to find ways to look at a problem from multiple perspectives while avoiding the emotional pitfalls of an us-versus-them approach.

A frame is any cognitive structure that guides the perception and interpretation of what one sees. A mental model of how things normally work can be thought of as a frame through which an analyst sees and interprets evidence. An individual or a group of people can change their frame of reference, and thus challenge their own thinking about a problem, simply by changing the questions they ask or changing the perspective from which they ask the questions. Analysts can use a Reframing Technique when they need to generate new ideas, when they want to see old ideas from a new perspective, or when they want to challenge a line of analysis. 3 Reframing helps analysts break out of a mental rut by activating a different set of synapses in their brain.

To understand the power of reframing and why it works, it is necessary to know a little about how the human brain works. Scientists believe the brain has roughly 100 billion neurons, each analogous to a computer chip capable of storing information. Each neuron has octopus-like arms called axons and dendrites. Electrical impulses flow through these arms and are ferried by neurotransmitting chemicals across the synaptic gap between neurons. Whenever two neurons are activated, the connections, or synapses, between them are strengthened. The more frequently those same neurons are activated, the stronger the path between them.

Once a person has started thinking about a problem one way, the same mental circuits or pathways are activated and strengthened each time the person thinks about it. The benefit of this is that it facilitates the retrieval of information one wants to remember. The downside is that these pathways become mental ruts that make it difficult to see the information from a different perspective. When an analyst reaches a judgment or decision, this thought process is embedded in the brain. Each time the analyst thinks about it, the same synapses are triggered, and the analyst's thoughts tend to take the same well-worn pathway through the brain. Because the analyst keeps getting the same answer every time, she or he will gain confidence, and often overconfidence, in that answer.

Another way of understanding this process is to compare these mental ruts to the route a skier will cut looking for the best path down from a mountain top (see Figure 8.0 ). After several runs, the skier has identified the ideal path and most likely will remain stuck in the selected rut unless other stimuli or barriers force him or her to break out and explore new opportunities.

Fortunately, it is easy to open the mind to think in different ways. The techniques described in this chapter are designed to serve that function. The trick is to restate the question, task, or problem from a different perspective to activate a different set of synapses in the brain. Each of the applications of reframing described in this chapter does this in a different way. Premortem Analysis, for example, asks analysts to imagine themselves at some future point in time, after having just learned that a previous analysis turned out to be completely wrong. The task then is to figure out how and why it might have gone wrong. What If? Analysis asks the analyst to imagine that some unlikely event has occurred, and then to explain how it could have happened along with the implications of the event.

These techniques are generally more effective in a small group than with a single analyst. Their effectiveness depends in large measure on how fully and enthusiastically participants in the group embrace the imaginative or alternative role they are playing. Just going through the motions is of limited value. Practice in using Reframing Techniques—especially Outside-In Thinking, Premortem Analysis, and Structured Self-Critique—will help analysts become proficient in the fifth habit of the Five Habits of the Master Thinker: understanding the overarching context within which the analysis is being done.

Description Figure 8.0 Mount Brain: Creating Mental Ruts

In addition, appropriate use of Reframing Techniques can help mitigate a variety of common cognitive limitations and improve the analyst's odds of getting the analysis right. They are particularly useful in minimizing Mirror Imaging or the tendency to assume others will act in the same way we would, given similar circumstances. They guard against the Anchoring Effect, which is accepting a given value of something unknown as a proper starting point for generating an assessment. Reframing Techniques are especially helpful in countering the intuitive traps of focusing on a narrow range of alternatives representing only modest change (Expecting Marginal Change) and continuing to hold to a judgment when confronted with a mounting list of contradictory evidence (Rejecting Evidence).

This chapter discusses three families of Reframing Techniques:

Three techniques for assessing cause and effect: Outside-In Thinking, Structured Analogies, and Red Hat Analysis Six techniques for challenging conventional wisdom or the group consensus: Quadrant Crunching™, Premortem Analysis, Structured Self-Critique, What If? Analysis, High Impact/Low Probability Analysis, and the Delphi Method Two techniques for managing conflict: Adversarial Collaboration and Structured Debate

Overview of Techniques

Outside-In Thinking broadens an analyst's thinking about the forces that can influence an issue of concern. The technique prompts the analyst to reach beyond his or her specialty area to consider broader social, organizational, economic, environmental, political, legal, military, technological, and global forces or trends that can affect the topic under study.

Structured Analogies applies analytic rigor to reasoning by analogy. This technique requires that the analyst systematically compare the topic at hand with multiple potential analogies before selecting the one for which the circumstances are most similar. Most analysts are comfortable using analogies to organize their thinking or make forecasts as, by definition, they contain information about what has happened in similar situations in the past. People often recognize patterns and then consciously take actions that were successful in a previous experience or avoid actions that previously were unsuccessful. However, analysts need to avoid the strong tendency to fasten onto the first analogy that comes to mind—particularly one that supports their prior view about an issue.

Red Hat Analysis is a useful technique for trying to perceive threats and opportunities as others see them. Intelligence analysts frequently endeavor to forecast the behavior of a foreign leader, group, organization, or country. In doing so, they need to avoid the common error of Mirror Imaging, which is the natural tendency of analysts to assume that others think and perceive the world in the same way they do. Business analysts can fall into the same trap when projecting the actions of their competitors. Red Hat Analysis is of limited value without significant understanding of the culture of the target company or country and the decision-making styles of the people involved.

Quadrant Crunching™ uses key assumptions and their opposites as a starting point for systematically generating multiple alternative outcomes. The technique forces analysts to rethink an issue from a broad range of perspectives and systematically question all the assumptions that underlie their lead hypothesis. It is most useful for ambiguous situations for which little information is available. Two versions of the technique have been developed: Classic Quadrant Crunching™ to avoid surprise and Foresight Quadrant Crunching™ to develop a comprehensive set of potential alternative futures. For example, analysts might use Classic Quadrant Crunching™ to identify the many ways terrorists might attack a water supply. They would use Foresight Quadrant Crunching™ to generate multiple scenarios of how the conflict in Syria might evolve over the next five years.

Premortem Analysis reduces the risk of analytic failure by identifying and analyzing a potential failure before it occurs. Imagine that several months or years have passed, and the just-completed analysis has turned out to be spectacularly wrong. Then imagine what could have caused it to be wrong. Looking back from the future to explain something that has happened is much easier than looking into the future to forecast what will happen. This approach to analysis helps identify problems one has not foreseen.

Structured Self-Critique is a procedure that a small team or group uses to identify weaknesses in its own analysis. All team or group members don a hypothetical black hat and become critics rather than supporters of their own analysis. From this opposite perspective, they respond to a list of questions about sources of uncertainty, the analytic processes used, critical assumptions, diagnosticity of evidence, anomalous evidence, and information gaps. They also consider changes in the broad environment in which events are happening, alternative decision models, current cultural expertise, and indicators of possible deception. Looking at the responses to these questions, the team strengthens its analysis by addressing uncovered faults and reassesses its confidence in its overall judgment.

What If? Analysis is an important technique for alerting decision makers to an event that could happen, or is already happening, even if it may seem unlikely at the time. It is a tactful way of suggesting to decision makers the possibility that their understanding of an issue may be wrong. What If? Analysis serves a function like Foresight analysis—it creates an awareness that prepares the mind to recognize early signs of a significant change, and it may enable a decision maker to plan for that contingency. The analyst imagines that an event has occurred and then considers how the event could have unfolded.

High Impact/Low Probability Analysis is used to sensitize analysts and decision makers to the possibility that a low-probability event might happen. It should also stimulate them to think about measures that could deal with the danger or to exploit the opportunity if the event occurs. The analyst assumes the event has occurred, and then figures out how it could have happened and what the consequences might be.

Delphi Method is a procedure for obtaining ideas, judgments, or forecasts electronically from a geographically dispersed panel of experts. It is a time-tested, extremely flexible procedure that can be used on any topic to which expert judgment applies. The technique can identify divergent opinions that challenge conventional wisdom and double-check research findings. If two analyses from different analysts who are using different techniques arrive at the same conclusion, confidence in the conclusion is increased or at least warranted. If the two conclusions disagree, this is also valuable information that may open new avenues of research.

Adversarial Collaboration is an agreement between opposing parties on how they will work together to resolve their differences, gain a better understanding of why they differ, or collaborate on a joint paper to explain the differences. Six approaches to implementing Adversarial Collaboration are presented in this chapter, including variations of three techniques described elsewhere in this book—Key Assumptions Check, Analysis of Competing Hypotheses, and Argument Mapping—and three new techniques—Mutual Understanding, Joint Escalation, and the Nosenko Approach.

Structured Debate is a planned debate of opposing points of view on a specific issue in front of a "jury of peers," senior analysts, or managers. As a first step, each side writes up the best possible argument for its position and passes this summation to the opposing side. The next step is an oral debate that focuses on refuting the other side's arguments rather than further supporting one's own arguments. The goal is to elucidate and compare the arguments against each side's argument. If neither argument can be refuted, perhaps both merit some consideration in the analytic report.

8.1 Cause and Effect Techniques

Attempts to explain the past and forecast the future are based on an understanding of cause and effect. Such understanding is difficult, because the kinds of variables and relationships studied by the intelligence analyst are, in most cases, not amenable to the kinds of empirical analysis and theory development common in academic research. The best the analyst can do is to make an informed judgment, but such judgments depend upon the analyst's subject-matter expertise and reasoning ability and are vulnerable to various cognitive pitfalls and fallacies of reasoning.

One of the most common causes of intelligence failures is the unconscious assumption that other countries and their leaders will act as we would in similar circumstances, a form of Mirror Imaging. Two related pitfalls are the tendency to assume that the results of an opponent's actions are what the opponent intended and an analyst's reluctance to accept the reality that simple mistakes, accidents, unintended consequences, coincidences, or small causes can have large effects. Perceptions of causality are partly determined by where one's attention is directed; as a result, information that is readily available, salient, or vivid is more likely to be perceived as causal than information that is not. Cognitive limitations and common errors in the perception of cause and effect are discussed in greater detail in Richards J. Heuer Jr.'s Psychology of Intelligence Analysis (Reston, VA: Pherson Associates, LLC, 2007).

I think we ought always to entertain our opinions with some measure of doubt. I shouldn't wish people dogmatically to believe any philosophy, not even mine.

—Bertrand Russell, English philosopher

There is no single, easy technique for mitigating the pitfalls involved in making causal judgments because analysts usually lack the information they need to be certain of a causal relationship. Moreover, the complex events that are the focus of intelligence analysis often have multiple causes that interact with one another.

Psychology of Intelligence Analysis describes three principal strategies that intelligence analysts use to make judgments to explain the cause of current events or forecast what might happen in the future:

Applying theory. Basing judgments on the systematic study of many examples of the same phenomenon. Theories or models often based on empirical academic research are used to explain how and when certain types of events normally occur. Many academic models are too generalized to be applicable to the unique characteristics of most intelligence problems. Many others involve quantitative analysis that is beyond the domain of Structured Analytic Techniques as defined in this book. However, a conceptual model that simply identifies relevant variables and the diverse ways they might combine to cause specific outcomes can be a useful template for guiding collection and analysis of some common types of problems. Outside-In Thinking can be used to explain current events or forecast the future in this way. Comparison with historical analogies. Combining an understanding of the facts of a specific situation with knowledge of what happened in similar situations either in one's personal experience or historical events. The Structured Analogies technique adds rigor to this process for understanding what has occurred and Analysis by Contrasting Narratives in chapter 9 provides insight into understanding how the future might evolve. Situational logic. Making expert judgments based on the known facts and an understanding of the underlying forces at work at a given time and place. When an analyst is working with incomplete, ambiguous, and possibly deceptive information, these expert judgments usually depend upon assumptions about capabilities, intent, or the normal workings of things in the country of concern. Red Hat Analysis has proven highly effective when seasoned analysts use it to anticipate the actions of dictators or autocratic regimes.

8.1.1 Outside-In Thinking

Outside-In Thinking identifies the broad range of global, political, environmental, technological, economic, or social forces and trends that are outside the analyst's area of expertise but that may profoundly affect the issue of concern. Many analysts tend to think from the inside out, focused on factors they are familiar with in their specific area of responsibility. Outside-In Thinking reverses this process as illustrated in Figure 8.1.1a . Whereas an analyst usually works from the data at hand outward to explain what is happening, Outside-In Thinking spurs the analyst to first consider how external factors such as an adversary's intent or new advances in artificial intelligence (AI) could have an impact on the situation, thereby enriching the analysis.

When to Use It

This technique is most useful in the early stages of an analytic process when analysts need to identify all the critical factors that might explain an event or could influence how a situation will develop. It should be part of the standard process for any project that analyzes potential future outcomes, for this approach covers the broader environmental context from which surprises and unintended consequences often come.

Description Figure 8.1.1A An Example of Outside-In Thinking Source: Pherson Associates, LLC, 2019.

Outside-In Thinking also is useful when assembling a large database, and analysts want to ensure they have not forgotten important fields in the database architecture. For most analysts, important categories of information (or database fields) are easily identifiable early in a research effort, but invariably one or two additional fields emerge after an analyst or group of analysts is well into a project. This forces the analyst or group to go back and review all previous reporting and input the additional data. Typically, the overlooked fields are in the broader environment over which the analysts have little control. By applying Outside-In Thinking, analysts can better visualize the entire set of data fields early in the research effort.

Value Added

Most analysts focus on familiar factors within their field of specialty, but we live in a complex, interrelated world where events in our little niche of that world are often affected by forces in the broader environment over which we have no control. The goal of Outside-In Thinking is to help analysts see the entire picture, not just the part of the picture with which they are already familiar.

Outside-In Thinking reduces the risk of missing important variables early in the analytic process because of the tendency to focus on a narrow range of alternatives representing only incremental or marginal change in the current situation. It encourages analysts to rethink a problem or an issue while employing a broader conceptual framework. The technique is illustrated in Figure 8.1.1b . By casting their net broadly at the beginning, analysts are more likely to see an important dynamic or to include a relevant alternative hypothesis. The process can provide new insights and uncover relationships that were not evident from the intelligence reporting. In doing so, the technique helps analysts think in terms that extend beyond day-to-day reporting. It stimulates them to address the absence of information and identify more fundamental forces and factors that should be considered.

The Method

Generate a generic description of the problem or phenomenon under study.

Figure 8.1.1B Inside-Out Analysis versus Outside-In Thinking Source: Pherson Associates, LLC, 2019. Form a group to brainstorm all the key forces and factors that could affect the topic but over which decision makers or other individuals can exert little or no influence, such as globalization, the emergence of new technologies, historical precedent, and the growing role of social media. Employ the mnemonic STEMPLES + to trigger new ideas ( S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity, plus other factors such as Demographic, Religious, or Psychological) and structure the discussion. Determine whether sufficient expertise is available for each factor or category. Assess specifically how each of these forces and factors might affect the problem. Ascertain whether these forces and factors have an impact on the issue at hand, basing your conclusion on the available evidence. Generate new intelligence collection tasking or research priorities to fill in information gaps.

Relationship to Other Techniques

Outside-In Thinking is essentially the same as a business analysis technique that goes by different acronyms such as STEEP, STEEPLED, PEST, or PESTLE. For example, PEST is an acronym for P olitical, E conomic, S ocial, and T echnological; STEEPLED also includes L egal, E thical, and D emographic. Military intelligence organizations often use the mnemonic PMESII, which stands for P olitical, M ilitary, E conomic, S ocial, I nformation, and I nfrastructure. 4 All require the analysis of external factors that may have either a favorable or unfavorable influence on an organization or the phenomenon under study.

Origins of This Technique

This technique has been used in planning and management environments to ensure identification of outside factors that might affect an outcome. The Outside-In Thinking approach described here is from Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019).

8.1.2 Structured Analogies

Analogies compare two situations to elicit and provoke ideas, help solve problems, and suggest history-tested indicators. An analogy can capture shared attributes or it can be based on similar relationships or functions being performed (see Figure 8.1.2 ). The Structured Analogies technique applies increased rigor to analogical reasoning by requiring that the issue of concern be compared systematically with multiple analogies.

Description Figure 8.1.2 Two Types of Structured Analogies Source: Pherson Associates, LLC, 2019.

When to Use It

In daily life, people recognize patterns of events or similar situations, then consciously take actions that were successful in a previous experience or avoid actions that were previously unsuccessful. Similarly, analysts infer courses of action from past, similar situations, often turning to analogical reasoning in unfamiliar or uncertain situations where the available information is inadequate for any other approach. However, analysts should consider the time required for this structured approach and may choose to use it only when the cost of being wrong is high.

Structured Analogies also is one of many structured techniques analysts can use to generate a robust set of indicators. If history reveals sets of events or actions that foretold what was about to occur in the past, they could prove to be valuable lead indicators for anticipating whether a similar event is likely to unfold in the future.

One of the most widely used tools in intelligence analysis is the analogy. Analogies serve as the basis for constructing many predictive models, are the basis for most hypotheses, and rightly or wrongly, underlie many generalizations about what the other side will do and how they will go about doing it.

—Jerome K. Clauser and Sandra M. Weir, Intelligence Research Methodology , Defense Intelligence School (1975)

Value Added

Reasoning by analogy helps achieve understanding by reducing the unfamiliar to the familiar. In the absence of data required for a full understanding of the current situation, analogical reasoning may be the only forecasting option. Using the Structured Analogies technique helps analysts avoid the tendency to fasten quickly on a single analogy and then focus only on evidence that supports the similarity of that analogy.

Structured Analogies is one technique for which there has been an empirical study of its effectiveness. A series of experiments compared Structured Analogies with unaided judgments in predicting the decisions made in eight conflict situations. These were difficult forecasting problems, and the 32 percent accuracy of unaided experts was only slightly better than chance. In contrast, 46 percent of the forecasts made by using the Structured Analogies process described here were accurate. Among the experts who were independently able to think of two or more analogies and who had direct experience with their closest analogy, 60 percent of the forecasts were accurate. 5

Structured Analogies help analysts avoid the mistake of focusing attention on one vivid scenario while ignoring other possibilities (Vividness Bias), seeing patterns in random events as systematic (Desire for Coherence and Uncertainty Reduction), and selecting the first answer that appears "good enough" (Satisficing). It also helps protect analysts from assuming the same dynamic is in play when, at first glance, something seems to accord with their past experiences (Projecting Past Experiences), assuming an event was more certain to occur than actually was the case (Assuming Inevitability), and believing that actions are the result of centralized patterns or direction and finding patterns where they do not exist (Presuming Patterns).

The Method

We recommend training in this technique before using it. Such a training course is available at http://www.academia.edu/1070109/Structured_Analogies_for_Forecasting .

Describe the issue and the judgment or decision that needs to be made. Identify experts who are familiar with the problem and have a broad background that enables them to identify analogous situations. Aim for at least five experts with varied backgrounds. Brainstorm as many analogies as possible without focusing too strongly on how similar they are to the current situation. Various universities and international organizations maintain databases to facilitate this type of research. For example, the Massachusetts Institute of Technology (MIT) maintains its Cascon System for Analyzing International Conflict, a database of 85 post–World War II conflicts that are categorized and coded to facilitate their comparison with current conflicts of interest. The University of Maryland maintains the International Crisis Behavior Project database covering 452 international crises between 1918 and 2006. Each case is coded for eighty-one descriptive variables. Review the list of potential analogies and agree on which ones should be examined further. Develop a tentative list of categories for comparing the analogies to determine which analogy is closest to the issue in question. For example, the MIT conflict database codes each case according to the following broad categories as well as finer subcategories: previous or general relations, military-strategic, international organization (United Nations, legal, public opinion), ethnic, economic/resources, internal politics of the sides, communication and information, and actions in disputed area. Write an account of each selected analogy, with equal focus on those aspects of the analogy that are similar and those that are different from the situation in play. A sophisticated approach to analogical reasoning examines the nature of the similarities and traces these critical aspects back to root causes. A good analogy goes beyond superficial similarity to examine deep structure. Each write-up, distributed among the experts, can be posted electronically so each member of the group can read and comment on it. Evaluate the analogies by asking each expert to rate the similarity of each to the issue of concern on a scale of 0 to 10, where 0 = not at all similar and 10 = very similar. Relate the highest-ranked analogies to the issue of concern by discussing the results of the evaluation and making a forecast for the current issue. The forecast may be the same as the outcome of the most-similar analogy. Alternatively, identify several other possible outcomes based on the diverse outcomes of analogous situations. When appropriate, use the analogous cases to identify drivers or policy actions that might influence the outcome of the current situation.

If using Structured Analogies to generate indicators, consider the highest-ranking analogies and ask if the previous actions and events are happening now or have happened. Also ask what actions have not happened or are not happening and assess the implications.

Potential Pitfalls

Noticing shared characteristics leads most people to an analogy, but logical reasoning necessitates considering conditions, qualities, or circumstances that are dissimilar between the two phenomena. A sophisticated approach examines the nature of the similarities and traces these critical aspects back to root causes. This should be standard practice in all reasoning by analogy and especially in those cases when one cannot afford to be wrong.

When resorting to an analogy, [people] tend to seize upon the first that comes to mind. They do not research more widely. Nor do they pause to analyze the case, test its fitness, or even ask in what ways it might be misleading.

—Ernest R. May, " Lessons" of the Past: The Use and Misuse of History in American Foreign Policy (1975)

Additionally, many analogies are used loosely and have a broad impact on the thinking of both decision makers and the public at large—for better or worse. One role for analysis is to take analogies that are already being used by others and subject these analogies to rigorous examination to prevent assumption-based decision making.

Origins of This Technique

Structured Analogies is described in greater detail in Kesten C. Green and J. Scott Armstrong, "Structured Analogies for Forecasting," in International Journal of Forecasting (2007), and www.forecastingprinciples.com/paperpdf/Structured_Analogies.pdf .

We recommend that analysts considering the use of this technique read Richard D. Neustadt and Ernest R. May, "Unreasoning from Analogies," chapter 4 in Thinking in Time: The Uses of History for Decision Makers (New York: Free Press, 1986). We also suggest Giovanni Gavetti and Jan W. Rivkin, "How Strategists Really Think: Tapping the Power of Analogy," Harvard Business Review (April 2005).

8.1.3 Red Hat Analysis

Red Hat Analysis is anticipating the behavior of another individual or group by trying to replicate how they think. Intelligence analysts frequently endeavor to forecast the actions of an adversary or a competitor. In doing so, they must take care to avoid the common error of Mirror Imaging, the natural tendency to assume that others think and perceive the world in the same way as the analyst does. Red Hat Analysis 6 is a useful technique for trying to perceive threats and opportunities as others see them. This technique alone, however, is of limited value without significant understanding of the culture of the other country or company and the decision-making style of the people involved.

To see the options faced by foreign leaders as these leaders see them, one must understand their values and assumptions and even their misperceptions and misunderstandings. Without such insight, interpreting foreign leaders' decisions or forecasting future decisions is often little more than partially informed speculation. Too frequently, behavior of foreign leaders appears "irrational" or "not in their own best interest." Such conclusions often indicate analysts have projected American values and conceptual frameworks onto the foreign leaders and societies, rather than understanding the logic of the situation as it appears to them.

—Richards J. Heuer Jr., Psychology of Intelligence Analysis (2007)

When to Use It

The chances of a Red Hat Analysis being accurate are better when one is trying to foresee the behavior of a specific person who has the authority to make decisions. Authoritarian leaders as well as small, cohesive groups, such as terrorist cells, are obvious candidates for this type of analysis. In contrast, the chances of making an accurate forecast about an adversary's or a competitor's decision is appreciably lower when the decision is constrained by a legislature or influenced by conflicting interest groups. In law enforcement, Red Hat Analysis is useful in simulating the likely behavior of a criminal or a drug lord.

Value Added

There is a great deal of truth in the maxim, "Where you stand depends on where you sit." Red Hat Analysis requires the analyst to adopt—and make decisions consonant with—the culture of a foreign leader, cohesive group, criminal, or competitor. This conscious effort to imagine the situation as the target perceives it helps the analyst gain a different and usually more accurate perspective on a problem or issue. Reframing the problem in this way typically changes the analyst's perspective from that of an analyst observing and forecasting an adversary's behavior to that of a leader who must make a difficult decision within that operational culture. This reframing process often introduces new and different stimuli that might not have been factored into a traditional analysis, such as a target's familial ties.

The technique introduces more human factors into the analysis such as, "Who can I count on (e.g., do I have relatives, friends, or business associates) to help me out?" "Is that operation within my capabilities?" "What are my supporters expecting from me?" "Do I really need to make this decision now?" and "What are the consequences of making a wrong decision?"

In addition to protecting the analyst against the bias of Mirror Imaging, Red Hat Analysis has proved to be effective in combating the influence of accepting the given value of things unknown as proper starting points for predicting someone's future course of action (Anchoring Effect) and predicting rare events based on weak evidence or evidence that easily comes to mind (Associative Memory).

Red Hat Analysis helps analysts guard against the common pitfall of Overrating Behavioral Factors (also referred to as Fundamental Attribution Error) by dampening the tendency to attribute the behavior of other people, organizations, or governments to the nature of the actor and underestimate the influence of situational factors. Conversely, people tend to see their own behavior as conditioned almost entirely by the situation in which they find themselves. We seldom see ourselves as a bad person, but we often see malevolent intent in others. 7

Red Hat Analysis also protects analysts from falling prey to the practitioners' traps of not addressing the impact of the absence of information on analytic conclusions (Ignoring the Absence of Information) and continuing to hold to a judgment when confronted with a mounting list of contradictory evidence (Rejecting Evidence).

The Method

Gather a group of experts with in-depth knowledge of the operating environment and target's personality, motives, and style of thinking. If possible, try to include people who are well-grounded in the target's culture, speak the same language, share the same ethnic background, or have lived in the target's country. Establish a baseline by presenting the experts with a situation or a stimulus and ask them what they would do in this situation. For example, you might ask for a response to this situation: "The United States has just imposed sanctions on your country. How would you react?" Or, "We are about to launch a new product. How would you react if you were a competitor?" The reason for first asking the experts how they would react is to assess whether the adversary is likely to react differently than the analyst would. 8 After the experts have articulated how they would have responded or acted, ask them to explain why they think they would behave that way. Ask the experts to list what core values or core assumptions were motivating their behavior or actions. Again, this step establishes a baseline for assessing why the adversary is likely to react differently than the analyst would. Once they can explain in a convincing way why they chose to act the way they did, ask the experts to put themselves in the shoes of the target, adversary, or competitor and simulate how the target would respond. At this point, the experts should ask themselves, "Does our target share our values or motives or methods of operation?" If not, then how would those differences lead the target to act in ways the analysts might not have anticipated before engaging in this exercise? To gain cultural expertise that might otherwise be lacking, consider using the Delphi Method to elicit the expertise of geographically distributed experts. In presenting the results, describe the considered alternatives and the rationale for selecting the path the assembled participants think the person or group is most likely to take. Consider other less conventional means of presenting the results of your analysis, such as the following:

Describing a hypothetical conversation in which the leader and other players talk in first person. Drafting a document (a set of instructions, military orders, policy paper, or directives) that the target, adversary, or competitor would likely generate.

Figure 8.1.3 shows how one might use Red Hat Analysis to catch bank robbers.

Potential Pitfalls

Forecasting human decisions or the outcome of a complex organizational process is difficult in the best of circumstances. For example, how successful would you expect to be in forecasting the difficult decisions to be made by the U.S. president or even your local mayor? It is even more difficult when dealing with a foreign culture with sizeable gaps in the available information. Mirror Imaging is hard to avoid because, in the absence of a thorough understanding of the foreign situation and culture, your own perceptions appear to be the only reasonable way to look at the problem.

A key first step in avoiding Mirror Imaging is to establish how you would behave and the reasons why. After establishing this baseline, the analyst then asks if the adversary would act differently and why. Is the adversary motivated by different stimuli, or does the adversary hold different core values? The task of Red Hat Analysis then becomes illustrating how these differences would result in different policies or behaviors.

A common error in our perceptions of the behavior of other people, organizations, or governments is to fall prey to the heuristic of Overrating Behavior Factors, which is likely to be even more common when assessing the behavior of foreign leaders or groups. This error is especially easy to make when one assumes that the target has malevolent intentions, but our understanding of the pressures on that actor is limited.

Figure 8.1.3 Using Red Hat Analysis to Catch Bank Robbers Source: Eric Hess, Senior Biometric Product Manager, MorphoTrak, Inc. From an unpublished paper, "Facial Recognition for Criminal Investigations," delivered at the International Association of Law Enforcement Intelligence Analysts, Las Vegas, NV, 2009. Reproduced with permission.

Analysts should always try to see the situation from the other side's perspective, but if a sophisticated grounding in the culture and operating environment of their subject is lacking, they will often be wrong. Recognition of this pitfall should prompt analysts to consider using words such as "possibly" and "could happen" rather than "likely" or "probably" when reporting the results of Red Hat Analysis.

Relationship to Other Techniques

Red Hat Analysis differs from Red Team Analysis in that it can be done or organized by any analyst—or more often a team of analysts—who needs to understand or forecast an adversary's behavior and who has, or can gain access to, the required cultural expertise. Red Cell and Red Team Analysis are challenge techniques usually conducted by a permanent organizational unit staffed by individuals well qualified to think like or play the role of an adversary. The goal of Red Hat Analysis is to exploit available resources to develop the best possible analysis of an adversary's or competitor's behavior. The goal of Red Cell or Red Team Analysis is usually to challenge the conventional wisdom of established analysts or an opposing team.

Origins of This Technique

Red Hat, Red Cell, and Red Team Analysis became popular during the Cold War when "red" symbolized the Soviet Union, but they continue to have broad applicability. This description of Red Hat Analysis is a modified version of that in Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, 2019).

8.2 Challenge Analysis Techniques

Challenge analysis encompasses a set of analytic techniques that are also called contrarian analysis, alternative analysis, red teaming, and competitive analysis. What all of these have in common is the goal of challenging an established mental model or analytic consensus to broaden the range of possible explanations or estimates that should be seriously considered. That this same activity has been called by so many different names suggests there has been some conceptual diversity about how and why these techniques are used and what they might help accomplish. All of them apply some form of reframing to better understand past patterns or foresee future events.

These techniques enable the analyst, and eventually the intelligence or business client, to evaluate events from a different or contrary perspective—in other words, with a different mental model. A surprising event is not likely to be anticipated if it has not been imagined, which requires examining the world from a different perspective. 9

Former Central Intelligence Agency director Michael Hayden makes a compelling logical case for consistently challenging conventional wisdom. He has stated that "our profession deals with subjects that are inherently ambiguous, and often deliberately hidden. Even when we're at the top of our game, we can offer policymakers insight, we can provide context, and we can give them a clearer picture of the issue at hand, but we cannot claim certainty for our judgments." The director went on to suggest that getting it right seven times out of ten might be a realistic expectation. 10

Hayden's estimate of seven times out of ten is supported by a quick look at verbal expressions of probability used in intelligence reports. "Probable" seems to be the most common verbal expression of the likelihood of an assessment or estimate. Unfortunately, there is no consensus within the Intelligence Community on what "probable" and other verbal expressions of likelihood mean when they are converted to numerical percentages. For discussion here, we accept Sherman Kent's definition of "probable" as meaning "75% plus or minus 12%." 11 This means that analytic judgments described as "probable" are expected to be correct roughly 75 percent of the time—and, therefore, incorrect or off target about 25 percent of the time.

Logically, one might then expect that one of every four judgments that intelligence analysts describe as "probable" will turn out to be wrong. This perspective broadens the scope of what challenge analysis might accomplish. It should not be limited to questioning the dominant view to be sure it's right. Even if the challenge analysis confirms the initial probability judgment, it should go further to seek a better understanding of the other 25 percent. In what circumstances might there be a different assessment or outcome, what would that be, what would constitute evidence of events moving in that alternative direction, how likely is it, and what would be the consequences?

As we will discuss in the next section on conflict management, an understanding of these probabilities should reduce the frequency of unproductive conflict between opposing views. Analysts who recognize a one-in-four chance of being wrong should at least be open to consideration of alternative assessments or estimates to account for the other 25 percent.

This chapter describes three categories of challenge analysis techniques: self-critique, critique of others, and solicitation of critique by others:

Self-critique. Three techniques that help analysts challenge their own thinking are Classic Quadrant Crunching™, Premortem Analysis, and Structured Self-Critique. These techniques spur analysts to reframe and challenge their analysis in multiple ways. They can counteract the pressures for conformity or consensus that often suppress the expression of dissenting opinions in an analytic team or group. We adapted Premortem Analysis from the business world and applied it to the analytic process more broadly. Critique of others. Analysts can use What If? Analysis or High Impact/Low Probability Analysis to tactfully question the conventional wisdom by making the best case for an alternative explanation or outcome. Critique by others. The Delphi Method is a structured process for eliciting usually anonymous opinions from a panel of outside experts. The authors have decided to drop from this edition of the book two other techniques for seeking critique by others—Devil's Advocacy and Red Team Analysis. They can be counterproductive because they add an emotional component to the analytic process that further ingrains mindsets.

8.2.1 Quadrant Crunching™

Quadrant Crunching™ is a systematic procedure for identifying all the potentially feasible combinations among several sets of variables. It combines the methodology of a Key Assumptions Check ( chapter 7 ) with Multiple Scenarios Generation ( chapter 9 ).

There are two versions of the technique: Classic Quadrant Crunching™ helps analysts avoid surprise, and Foresight Quadrant Crunching™ is used to develop a comprehensive set of potential alternative futures. Both techniques spur analysts to rethink an issue from a broad range of perspectives and systematically question all the assumptions that underlie their lead hypothesis.

Classic Quadrant Crunching™ helps analysts avoid surprise by examining multiple possible combinations of selected key variables. Pherson Associates, LLC, initially developed the technique in 2006 to help counterterrorism analysts and decision makers discover all the ways international terrorists or domestic radical extremists might mount an attack. Foresight Quadrant Crunching™ was developed in 2013 by Globalytica, LLC. It adopts the same initial approach of Reversing Assumptions as Classic Quadrant Crunching™. It then applies Multiple Scenarios Generation to generate a wide range of comprehensive and mutually exclusive future scenarios or outcomes of any type—many of which analysts had not previously contemplated.

When to Use It

Both techniques are useful for dealing with highly complex and ambiguous situations for which little data is available and the chances for surprise are great. Analysts need training and practice before using either technique, and we highly recommend engaging an experienced facilitator, especially when this technique is used for the first time.

Analysts can use Classic Quadrant Crunching™ to identify and systematically challenge assumptions, explore the implications of contrary assumptions, and discover "unknown unknowns." By generating multiple possible alternative outcomes for any situation, Classic Quadrant Crunching™ reduces the chance that events could play out in a way that analysts have not previously imagined or considered. Analysts, for example, would use Classic Quadrant Crunching™ to identify the different ways terrorists might conduct an attack on the homeland or how business competitors might react to a new product launch.

Analysts who use Foresight Quadrant Crunching™ can be more confident that they have considered a broad range of possible situations that could develop and have spotted indicators that signal a specific scenario is starting to unfold. For example, an analyst could use Foresight Quadrant Crunching™ to generate multiple scenarios of how the conflict in Syria or Venezuela might evolve over the next five years and gain a better understanding of the interplay of key drivers in that region.

Value Added

Both techniques reduce the potential for surprise by providing a structured framework with which the analyst can generate an array of alternative options or mini-stories. Classic Quadrant Crunching™ requires analysts to identify and systematically challenge all their key assumptions about how a terrorist attack might be launched or how any other specific situation might evolve. By critically examining each assumption and how a contrary assumption might play out, analysts can better assess their level of confidence in their predictions and the strength of their lead hypothesis. Foresight Quadrant Crunching™ belongs to the family of Foresight Techniques; it is most effective when there is a strong consensus that only a single future outcome is likely.

Both techniques provide a useful platform for developing indicator lists and for generating collection requirements. They also help decision makers focus on what actions need to be undertaken today to best prepare for events that could transpire in the future. By reviewing an extensive list of potential alternatives, decision makers are in a better position to select those that deserve the most attention. They can then take the necessary actions to avoid or mitigate the impact of unwanted or bad alternatives and help foster more desirable ones. The techniques also are helpful in sensitizing decision makers to potential "wild cards" (High Impact/Low Probability developments) or "nightmare scenarios," both of which could have significant policy or resource implications.

The Method

8.2.1.1 The Method: Classic Quadrant Crunching™

Classic Quadrant Crunching™ is sometimes described as a Key Assumptions Check on steroids. It is most useful when there is a well-established lead hypothesis that can be articulated clearly. Classic Quadrant Crunching™ calls on the analyst to break down the lead hypothesis into its component parts, identifying the key assumptions that underlie the lead hypothesis, or the dimensions that focus on Who, What, How, When, Where, and Why. After the key dimensions of the lead hypothesis are articulated, the analyst generates two or four examples of contrary dimensions.

For example, two contrary dimensions for a single attack would be simultaneous attacks and cascading attacks. The various contrary dimensions are then arrayed in sets of 2-×-2 matrices. If four dimensions are identified for a topic, the technique would generate six different 2-×-2 combinations of these four dimensions (AB, AC, AD, BC, BD, and CD). Each of these pairs would be presented as a 2-×-2 matrix with four quadrants. Participants then generate different stories or alternatives for each quadrant in each matrix. If analysts create two stories for each quadrant in each of these 2-×-2 matrices, there will be a total of forty-eight different ways the situation could evolve. Similarly, if six drivers are identified, the technique will generate as many as 120 different stories to consider (see Figure 8.2.1.1a ).

The best way to have a good idea is to have a lot of ideas.

—Linus Pauling, American chemist

After a rich array of potential alternatives is generated, the analyst's task is to identify which of the various alternative stories are the most deserving of attention. The last step in the process is to develop lists of indicators for each story and track them to determine which story is beginning to emerge.

The question, "How might terrorists attack a nation's water system?" is useful for illustrating the Classic Quadrant Crunching™ technique. State the conventional wisdom for the most likely way terrorists might launch such an attack. For example, "Al-Qaeda or its affiliates will contaminate the water supply for a large metropolitan area, causing mass casualties."

Break down this statement into its component parts or key assumptions. For example, the statement makes its key assumptions: (1) a single attack, (2) involving the contamination of drinking water, (3) conducted by an outside attacker, (4) against a major metropolitan area, causing large numbers of casualties. Posit a contrary assumption for each key assumption. For example, what if there are multiple attacks instead of a single attack?

Figure 8.2.1.1A Classic Quadrant Crunching™: Creating a Set of Stories Source: Pherson Associates, LLC, 2019. Identify two or four dimensions of that contrary assumption. For example, what are different ways a terrorist group could launch a multiple attack? Two possibilities would be simultaneous attacks (as in the September 2001 attacks on the World Trade Center and the Pentagon or the London bombings in 2005) or cascading attacks (as in the sniper killings in the Washington, D.C., area in October 2002).

Figure 8.2.1.1B Terrorist Attacks on Water Systems: Reversing Assumptions Source: Pherson Associates, LLC, 2019.

Description Figure 8.2.1.1C Terrorist Attacks on Water Systems: Sample Matrices Source: Pherson Associates, LLC, 2019. Repeat this process for each of the key assumptions. Develop two or four contrary dimensions for each contrary assumption. (See Figure 8.2.1.1b .) Array pairs of contrary dimensions into sets of 2-×-2 matrices. In this case, ten different 2-×-2 matrices are the result. Two of the ten matrices are shown in Figure 8.2.1.1c . For each cell in each matrix, generate one to three examples of how terrorists might launch an attack. In some cases, such an attack might already have been imagined. In other quadrants, there may be no credible attack concept. But several of the quadrants will usually stretch the analysts' thinking, pushing them to consider the dynamic in new and different ways.

Description Figure 8.2.1.1D Selecting Attack Plans Source: Pherson Associates, LLC, 2019. Review all the attack plans generated; using a preestablished set of criteria, select those most deserving of attention. In this example, possible criteria might be plans that are most likely to do the following:

Cause the most damage; have the most impact. Be the hardest to detect or prevent. Pose the greatest challenge for consequence management. This process is illustrated in Figure 8.2.1.1d . In this case, three attack plans were deemed the most likely. Attack plan 1 became Story A, attack plans 4 and 7 were combined to form Story B, and attack plan 16 became Story C. It may also be desirable to select one or two additional attack plans that might be described as "wild cards" or "nightmare scenarios." These are attack plans that have a low probability of being tried but are worthy of attention because their impact would be substantial if they did occur. The figure shows attack plan 11 as a "nightmare scenario." Consider what decision makers might do to prevent bad stories from happening, mitigate their impact, and deal with their consequences. Generate a list of key indicators to help assess which, if any, of these attack plans is beginning to emerge.

8.2.1.2 The Method: Foresight Quadrant Crunching™

Foresight Quadrant Crunching™ adopts much the same method as Classic Quadrant Crunching™, with two major differences. In the first step, state the scenario that most analysts believe has the greatest probability of emerging. When later developing the list of alternative dimensions, include the dimensions contained in the lead scenario. By including the lead scenario, the final set of alternative scenarios or futures should be comprehensive and mutually exclusive. The specific steps for Foresight Quadrant Crunching™ are the following:

State what most analysts believe is the most likely future scenario. Break down this statement into its component parts or key assumptions. Posit a contrary assumption for each key assumption. Identify one or three contrary dimensions of that contrary assumption. Repeat this process for each of the contrary assumptions—a process like that shown in Figure 8.2.1.1b . Add the key assumption to the list of contrary dimensions, creating either one or two pairs. Repeat this process for each row, creating one or two pairs, including a key assumption and one or three contrary dimensions. Array these pairs into sets of 2-×-2 matrices, a process shown in Figure 8.2.1.1c . For each cell in each matrix, generate one to three credible scenarios. In some cases, such a scenario may already have been imagined. In other quadrants, there may be no scenario that makes sense. But several of the quadrants will usually stretch the analysts' thinking, often generating counterintuitive scenarios. Review all the scenarios generated—a process outlined in Figure 8.2.1.1d ; using a preestablished set of criteria, select those scenarios most deserving of attention. The difference is that with Classic Quadrant Crunching™, analysts are seeking to develop a set of credible alternative attack plans to avoid surprise. In Foresight Quadrant Crunching™, analysts are engaging in a new version of Multiple Scenarios Generation analysis.

Relationship to Other Techniques

Both Quadrant Crunching™ techniques are specific applications of a generic method called Morphological Analysis (described in chapter 9 ). They draw on the results of the Key Assumptions Check and can contribute to Multiple Scenarios Generation. They are also useful in identifying indicators.

Origins of This Technique

Classic Quadrant Crunching™ was developed by Randolph Pherson and Alan Schwartz to meet a specific analytic need in the counterterrorism arena. It was first published in Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 4th ed. (Reston, VA: Pherson Associates, LLC, 2008). Foresight Quadrant Crunching™ was developed by Globalytica, LLC, in 2013 as a new method for conducting Foresight analysis.

8.2.2 Premortem Analysis

Premortem Analysis is conducted prior to finalizing an analysis or a decision to assess how a key analytic judgment, decision, or plan of action could go spectacularly wrong. The goal is to reduce the risk of surprise and the subsequent need for a postmortem investigation of what went wrong. It is an easy-to-use technique that enables a group of analysts who have been working together on any type of future-oriented analysis or project to challenge effectively the accuracy of their own conclusions. It is a specific application of the reframing method, in which restating the question, task, or problem from a different perspective enables one to see the situation differently and come up with different ideas.

When to Use It

Premortem Analysis should be used by analysts who can devote a few hours to challenging their own analytic conclusions about the future to see where they might be wrong. It is much easier to influence people's decisions before they make up their mind than afterward when they have a personal investment in that decision. For this reason, analysts should use Premortem Analysis and its companion technique, Structured Self-Critique, just before finalizing their key analytic judgments.

A single analyst may use the two techniques, but, like all Structured Analytic Techniques, they are most effective when used by a small group. If a team assessment, the process should be initiated as soon as the group starts to coalesce on a common position.

The concept of a premortem as an analytic aid was first used in the context of decision analysis by Gary Klein in his 1998 book, Sources of Power: How People Make Decisions . He reported using it in training programs to show decision makers that they typically are overconfident that their decisions and plans will work. After the trainees formulated a plan of action, they were asked to imagine that it is several months or years in the future, and their plan has been implemented but has failed. They were then asked to describe how it might have failed, despite their original confidence in the plan. The trainees could easily come up with multiple explanations for the failure, but none of these reasons were articulated when the plan was first proposed and developed.

This assignment provided the trainees with evidence of their overconfidence, and it demonstrated that the premortem strategy can be used to expand the number of interpretations and explanations that decision makers consider. Klein explains: "We devised an exercise to take them out of the perspective of defending their plan and shielding themselves from flaws. We tried to give them a perspective where they would be actively searching for flaws in their own plan." 12 Klein reported his trainees showed a "much higher level of candor" when evaluating their own plans after exposure to the premortem exercise, as compared with other, more passive attempts at getting them to critique their initial drafts. 13

Value Added

The primary goal of Premortem Analysis is to reduce the risk of surprise and the subsequent need for a postmortem investigation. The technique—and its companion, Structured Self-Critique—helps analysts identify potential causes of error that they had overlooked. Two creative processes are at work here:

The questions are reframed. This exercise typically elicits responses that are different from the original ones. Asking questions about the same topic, but from a different perspective, opens new pathways in the brain. The method legitimizes dissent. For various reasons, individual egos and group dynamics can suppress dissenting opinions, leading to premature consensus. In Premortem Analysis, all the participants make a positive contribution to the group goal by identifying weaknesses in the previous analysis.

An important cause of poor group decisions is the desire for consensus. This desire can lead to Groupthink or agreement with majority views regardless of whether participants perceive them as right or wrong. Attempts to improve group creativity and decision making often focus on ensuring that the group considers a wide range of information and opinions. 14

Group members tend to go along with the group leader, with the first group member to stake out a position, or with an emerging majority viewpoint for many reasons. Most benign is the common rule of thumb that when we have no firm opinion, we take our cues from the opinions of others. We follow others because we believe (often rightly) that they know what they are doing. Analysts may also be concerned that others will critically evaluate their views, or that dissent will come across as disloyalty or as an obstacle to progress that will just prolong the meeting.

In a candid newspaper column written long before he became CIA director, Leon Panetta wrote that "an unofficial rule in the bureaucracy says that to ‘get along, go along.' In other words, even when it is obvious that mistakes are being made, there is a hesitancy to report the failings for fear of retribution or embarrassment. That is true at every level, including advisers to the president. The result is a ‘don't make waves' mentality that . . . is just another fact of life you tolerate in big organizations." 15

It is not bigotry to be certain we are right; but it is bigotry to be unable to imagine how we might possibly have gone wrong.

—G. K. Chesterton, English writer

A major benefit of Premortem Analysis is that it legitimizes dissent. The technique empowers team members who may have unspoken reservations or doubts because they lacked confidence to participate in a way that is consistent with perceived group goals. If this change in perspective is handled well, each team member will know that they add value to the exercise by being critical of the previous judgment, not for supporting it. By employing both companion techniques analysts can explore all the ways analysis could turn out to be wrong—one is a totally unbounded approach and the other is a highly structured mechanism. The first technique is a right-brained process called Premortem Analysis; the second is a left-brained technique, the Structured Self-Critique, which is discussed later in this chapter.

The Method

The best time to conduct a Premortem Analysis is shortly after a group has reached a conclusion on an action plan but before any serious drafting of the report. If the group members are not already familiar with the Premortem Analysis technique, the group leader, another group member, or a facilitator steps up and makes a statement along the lines of the following: "Okay, we now think we know the right answer, but we need to double-check this. To free up our minds to consider other possibilities, let's imagine that we have made this judgment, our report has gone forward and been accepted, and now, x months or x years later, we learn that our analysis was wrong. Things have turned out much differently than we expected. Now, working from that perspective in the future, let's put our imaginations to work and brainstorm what could have possibly happened to cause our analysis to be spectacularly wrong."

Ideally, the actual brainstorming session should be a separate meeting to give the participants time to think about what might have happened to cause the analytic judgment to be wrong. They should bring to the meeting a list of what might have gone differently than expected. To set the tone for the brainstorming session, analysts should be advised not to focus only on the hypotheses, assumptions, and key evidence already discussed during their group meetings. Rather, they should be encouraged to look at the situation from the perspective of their own life experiences. They should think about how fast the world is changing, how many of their organization's programs are unsuccessful or have unintended consequences, or how difficult it is to see things from the perspective of a foreign culture or a competitor. This type of thinking may bring a different part of analysts' brains into play as they are mulling over what could have gone wrong with their analysis. Outside-In Thinking can also be helpful for this purpose.

In the Premortem Analysis meeting, the group leader or a facilitator writes the ideas presented on a whiteboard or flip chart. To ensure that no single person dominates the presentation of ideas, the Nominal Group Technique version of brainstorming is a good option. With that technique, the facilitator goes around the room in round-robin fashion, taking one idea from each participant until all have presented every idea on their lists (see chapter 6 ). After all ideas are posted on the board and made visible to all, the group discusses what it has learned from this exercise, and what action, if any, the group should take. This generation and initial discussion of ideas can often occur in a single two-hour meeting, which is a small investment of time to undertake a systematic challenge to the group's thinking.

One expected result is an increased appreciation of the uncertainties inherent in any assessment of the future. Another outcome might be identification of indicators that, if observed, would provide early warning that events are not proceeding as expected. Such findings may lead to modification of the existing analytic framework.

If the Premortem Analysis leads the group to reconsider and revise its analytic judgment, the questions shown in Figure 8.2.2 are a good starting point. For a more thorough set of self-critique questions, see the discussion of Structured Self-Critique, which involves changing one's role from advocate to critic of one's previous analysis.

Premortem Analysis may identify problems, conditions, or alternatives that require rethinking the group's original position. In such a case, Premortem Analysis has done its job by alerting the group to the fact that it has a problem, but it does not necessarily tell the group exactly what the problem is or how to fix it. That is beyond the scope of Premortem Analysis. The technique alerts the group to the fact that it has a problem, but it does not systematically assess the likelihood of these things happening. It also has not evaluated multiple sources of analytic error or made a comprehensive assessment of alternative courses of action. These tasks are better accomplished with the Structured Self-Critique.

Relationship to Other Techniques

If the Premortem Analysis identifies a significant problem, the natural follow-up technique for addressing this problem is Structured Self-Critique, described in the next section.

Origins of This Technique

Gary Klein originally developed the premortem concept to train managers to recognize their habitual overconfidence in the success of their plans and decisions. The authors adapted the technique and redefined it as an intelligence analysis technique called Premortem Analysis. For original references on this subject, see Gary Klein, Sources of Power: How People Make Decisions (Cambridge, MA: MIT Press, 1998); Klein, Intuition at Work: Why Developing Your Gut Instinct Will Make You Better at What You Do (New York: Doubleday, 2002); and Klein, "Performing a Project Pre Mortem," Harvard Business Review (September 2007). An interactive group activity can be planned at https://www.atlassian.com/team-playbook/plays/pre-mortem .

Description Figure 8.2.2 Premortem Analysis: Some Initial Questions Source: Pherson Associates, LLC, 2019.

8.2.3 Structured Self-Critique

Structured Self-Critique is a systematic procedure that a small team or group can use to identify weaknesses in its own analysis. All team or group members don a hypothetical black hat and become critics rather than supporters of their own analysis. From this opposite perspective, they respond to a list of questions about sources of uncertainty, the analytic processes used, critical assumptions, diagnosticity of evidence, anomalous evidence, information gaps, changes in the broad environment in which events are happening, alternative decision models, availability of cultural expertise, and indicators of possible deception. As it reviews responses to these questions, the team reassesses its overall confidence in its own judgment.

Begin challenging your own assumptions. Your assumptions are your windows on the world. Scrub them off every once in a while, or the light won't come in.

—Alan Alda, American actor

When to Use It

You can use Structured Self-Critique productively to look for weaknesses in any analytic explanation of events or estimate of the future. We specifically recommend using it in the following ways:

As the next step if the Premortem Analysis raises unresolved questions about any estimated future outcome or event. As a double-check prior to the publication of any major product such as a National Intelligence Estimate or a corporate strategic plan. As one approach to resolving conflicting opinions (as discussed in the next section on Adversarial Collaboration).

The amount of time required to work through the Structured Self-Critique will vary greatly depending upon how carefully the previous analysis was done. The questions listed in the method later in this section are just a prescription for careful analysis. To the extent that analysts have already explored these same questions during the initial analysis, the time required for the Structured Self-Critique is reduced. If these questions are asked for the first time, the process will take longer. As analysts gain experience with Structured Self-Critique, they may have less need for certain parts of it, as they will have internalized the method and used its questions during the initial analysis (as they should have).

Value Added

When people are asked questions about the same topic but from a different perspective, they often give different answers than the ones they gave before. For example, if someone asks a team member if he or she supports the team's conclusions, the answer will usually be "yes." However, if all team members are asked to look for weaknesses in the team's argument, that member may give a different response.

This change in the frame of reference is intended to change the group dynamics. The critical perspective should always generate more critical ideas. Team members who previously may have suppressed questions or doubts because they lacked confidence or wanted to be good team players are now able to express those divergent thoughts. If the change in perspective is handled well, all team members will know that they win points with their colleagues for being critical of the previous judgment, not for supporting it.

The Method

Start by reemphasizing that all analysts in the group are now wearing a black hat. They have become critics, not advocates, and their job is to find weaknesses in the previous analysis, not support the previous analysis. The group then works its way through the following topics or questions:

Sources of uncertainty. Identify the sources and types of uncertainty to set reasonable expectations for what the team might expect to achieve. Should one expect to find (1) a single correct or most likely answer, (2) a most likely answer together with one or more alternatives that must also be considered, or (3) many possible explanations or scenarios for future development? To judge the uncertainty, answer these questions:

Is the question being analyzed a puzzle or a mystery? Puzzles have answers, and correct answers are attainable if enough pieces of the puzzle surface. A mystery has no single definitive answer; it depends upon the future interaction of many factors, some known and others unknown. Analysts can frame the boundaries of a mystery only "by identifying the critical factors and making an intuitive judgment about how they have interacted in the past and might interact in the future." 16 How does the team rate the quality and timeliness of its evidence? Are there a greater than usual number of assumptions because of insufficient evidence or the complexity of the situation? Is the team dealing with a relatively stable situation or with a situation that is undergoing, or potentially about to undergo, significant change? Analytic process. In the initial analysis, see if the team did the following: Did it identify alternative hypotheses and seek out information on these hypotheses? Did it identify key assumptions? Did it seek a broad range of diverse opinions by including analysts from other offices and agencies, academia, or the private sector in the deliberations? If the team did not take these steps, the odds of the team having a faulty or incomplete analysis increased. Either consider doing some of these things now or lower the team's level of confidence in its judgment. Critical assumptions. Presuming that the team has already identified key assumptions, the next step is to identify the one or two assumptions that would have the greatest impact on the analytic judgment if they turned out to be wrong. In other words, if the assumption is wrong, the judgment will be wrong. How recent and well documented is the evidence that supports each such assumption? Brainstorm circumstances that could cause each of these assumptions to be wrong and assess the impact on the team's analytic judgment if the assumption is wrong. Would the reversal of any of these assumptions support any alternative hypothesis? If the team has not previously identified key assumptions, it should do a Key Assumptions Check. Diagnostic evidence. Identify alternative hypotheses and the most diagnostic items of evidence that enable the team to reject alternative hypotheses. For each item, brainstorm reasonable alternative interpretations of this evidence that could make it consistent with an alternative hypothesis. See Diagnostic Reasoning in chapter 7 . Information gaps. Are there gaps in the available information, or is some of the information so dated that it may no longer be valid? Is the absence of information readily explainable? How should absence of information affect the team's confidence in its conclusions? Missing evidence. Is there evidence that one would expect to see in the regular flow of intelligence or open-source reporting if the analytic judgment is correct, but is not there? Anomalous evidence. Is there any anomalous item of evidence that would have been important if it had been believed or if it could have been related to the issue of concern, but was rejected because it was not deemed important at the time or its significance was not known? If so, try to imagine how this item might be a key clue to an emerging alternative hypothesis. Changes in the broad environment. Driven by technology and globalization, the world seems to be experiencing social, technical, economic, environmental, and political changes at a faster rate than ever before in history. Might any of these changes play a role in what is happening or will happen? More broadly, what key forces, factors, or events could occur independently of the issue under study that could have a significant impact on whether the analysis proves to be right or wrong? Alternative decision models. If the analysis deals with decision making by a foreign government or nongovernmental organization (NGO), was the group's judgment about foreign behavior based on a rational actor assumption? If so, consider the potential applicability of other decision models, specifically that the action was or will be the result of bargaining between political or bureaucratic forces, the result of standard organizational processes, or the whim of an authoritarian leader. 17 If information for a more thorough analysis is lacking, consider the implications of that for confidence in the team's judgment. Cultural expertise. If the topic being analyzed involves a foreign or otherwise unfamiliar culture or subculture, does the team have or has it obtained cultural expertise on thought processes in that culture? 18 Deception. Does another country, NGO, or commercial competitor about which the team is making judgments have a motive, opportunity, or means for engaging in deception to influence U.S. policy or to change your organization's behavior? Does this country, NGO, or competitor have a history of engaging in denial, deception, or influence operations?

After responding to these questions, the analysts take off their black hats and reconsider the appropriate level of confidence in the team's previous judgment. Should the initial judgment be reaffirmed or modified?

Potential Pitfalls

The success of this technique depends in large measure on the team members' willingness and ability to make the transition from supporters to critics of their own ideas. Some individuals lack the intellectual flexibility to do this well. It must be clear to all members that they are no longer performing the same function as before. They should view their task as an opportunity to critique an analytic position taken by some other group (themselves, but with a different hat on).

To emphasize the different role analysts are playing, Structured Self-Critique meetings should be scheduled exclusively for this purpose. The meetings should be led by a different person from the usual leader, and, preferably, held at a different location. It will be helpful if an experienced facilitator is available to lead the meeting(s). This formal reframing of the analysts' role from advocate to critic is an important part of helping analysts see an issue from a different perspective.

Relationship to Other Techniques

Structured Self-Critique was developed in large part as an alternative to Devil's Advocacy and Team A/Team B Analysis. The techniques share the same objective, but Structured Self-Critique engages all the members of the group in a team effort to find flaws in the analysis as opposed to asking one person or group to criticize another. When someone is designated to play the role of Devil's Advocate, that member will take one of the team's critical judgments or assumptions, reverse it, and then argue from that perspective against the team's conclusions. We believe it is more effective for the entire team to don the hypothetical black hat and play the role of critic. When only one team member—or a competing team—dons the black hat and tries to persuade the authors of the analysis that they are wrong, the authors almost always become defensive and resist the need to make changes. Sometimes, Devil's Advocates will find themselves acting out a role that they do not actually agree with, but their actions will still stir frictions within the group.

Origins of This Technique

Richards J. Heuer Jr. and Randolph Pherson developed Structured Self-Critique. A simpler version of this technique appears in Randolph H. Pherson, "Premortem Analysis and Structured Self-Critique," in Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019).

8.2.4 What If? Analysis

What If? Analysis posits that an event has occurred with the potential for a major positive or negative impact and then, with the benefit of "hindsight," explains how this event could have come about and what the consequences might be.

When to Use It

This technique should be in every analyst's toolkit. It is an important technique for alerting decision makers to an event that could happen, even if it may seem unlikely at the present time. What If? Analysis serves a function like Foresight analysis—it creates an awareness that prepares the mind to recognize early signs of a significant change, and it may enable the decision maker to plan for that contingency. It is most appropriate when any of the following conditions are present:

A mental model is well ingrained within the analytic or the client community that a certain event will not happen. The issue is highly contentious, either within the analytic community or among decision makers, and no one is focusing on what actions need to be considered to deal with or prevent an untoward event. Analysts perceive a need for others to focus on the possibility this event could happen and to consider the consequences if it does occur.

When analysts are too cautious in estimative judgments on threats, they brook blame for failure to warn. When too aggressive in issuing warnings, they brook criticism for "crying wolf."

—Jack Davis, "Improving CIA Analytic Performance: Strategic Warning," Sherman Kent School for Intelligence Analysis (September 2002)

What If? Analysis is a logical follow-up after any Key Assumptions Check that identifies an assumption critical to an important estimate but about which there is some doubt. In that case, the What If? Analysis would imagine that the opposite of this assumption is true. Analysis would then focus on ways this outcome could occur and what the consequences would be.

Value Added

Shifting the focus from asking whether an event will occur to imagining that it has occurred and then explaining how it might have happened opens the mind to think in different ways. What If? Analysis shifts the discussion from "How likely is it?" to these questions:

How could it possibly come about? Could it come about in more than one way? What would be the impact? Has the possibility of the event happening increased?

The technique also gives decision makers

a better sense of what they might be able to do today to prevent an untoward development from occurring or leverage an opportunity to advance their interests and a list of specific indicators to monitor and determine if a development may soon occur.

What If? Analysis is a useful tool for exploring unanticipated or unlikely scenarios that are within the realm of possibility and that would have significant consequences should they come to pass. Figure 8.2.4 is an example of this. It posits a dramatic development—the emergence of India as a new international hub for finance—and then explores how this scenario could occur. In this example, the technique spurs the analyst to challenge traditional analysis and rethink the underlying dynamics of the situation.

The Method

A What If? Analysis can be done by an individual or as a team project. The time required is about the same as that for drafting a short paper. It usually helps to initiate the process with a brainstorming session. Additional brainstorming sessions can be interposed at various stages of the process.

Figure 8.2.4 What If? Scenario: India Makes Surprising Gains from the Global Financial Crisis Source: This example was developed by Ray Converse and Elizabeth Manak, Pherson Associates, LLC. Begin by assuming that what could happen has occurred. Often it is best to pose the issue in the following way: "The New York Times reported yesterday that . . ." Be precise in defining both the event and its impact. Sometimes it is useful to posit the new contingency as the outcome of a specific triggering event, such as a natural disaster, an economic crisis, a major political miscalculation, or an unexpected new opportunity that vividly reveals a key analytic assumption is no longer valid. Develop at least one chain of argumentation—based on both evidence and logic—to explain how this outcome could have come about. In developing the scenario or scenarios, focus on what must occur at each stage of the process. Work backwards from the event to the present day. This is called "backwards thinking." Try to envision more than one scenario or chain of argument. Generate and validate a list of indicators or "observables" for each scenario that would help analysts detect whether events are starting to play out in a way envisioned by that scenario. Identify which scenarios deserve the most attention by taking into consideration the difficulty of implementation and the potential significance of the impact. Assess the level of damage or disruption that would result from a negative scenario and estimate how difficult it would be to overcome or mitigate the damage incurred. For new opportunities, assess how well developments could turn out and what can be done to ensure that such a positive scenario might occur. Monitor the indicators on a periodic basis. Report periodically on whether any of the proposed scenarios are beginning to emerge and why.

Relationship to Other Techniques

What If? Analysis is sometimes confused with the High Impact/Low Probability Analysis technique, as each considers low-probability events. However, only What If? Analysis uses the reframing technique of positing that a future event has happened and then works backwards in time to imagine how it could have happened. High Impact/Low Probability Analysis requires new or anomalous information as a trigger and then projects forward to what might occur and the consequences if it does.

Origins of This Technique

Analysts and practitioners have applied the term "What If? Analysis" to a variety of techniques for a long time. The version described here is based on Randolph H. Pherson, "What If? Analysis," in Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019) and training materials from the Department of Homeland Security, Office of Intelligence and Analysis.

A Cautionary Note

Scenarios developed using both the What If? Analysis and the High Impact/Low Probability Analysis techniques can often contain highly sensitive data requiring a very limited distribution of the final product. Examples are the following: How might a terrorist group launch a debilitating attack on a vital segment of the U.S. infrastructure? How could a coup be launched successfully against a friendly government? What could be done to undermine or disrupt global financial networks? Obviously, if an analyst identifies a major vulnerability that could be exploited by an adversary, extreme care must prevent that detailed description from falling into the hands of the adversary. An additional concern is that the more "brilliant" and provocative the scenario, the more likely it will attract attention, be shared with others, and possibly leak and be read by an adversary or competitor.

8.2.5 High Impact/Low Probability Analysis

High Impact/Low Probability Analysis provides decision makers with early warning that a seemingly unlikely event with major policy and resource repercussions might occur.

When to Use It

Analysts should use High Impact/Low Probability Analysis when they want to alert decision makers to the possibility that a seemingly long-shot development with a major policy or resource impact may be more likely than previously anticipated. Events that would have merited such treatment before they occurred include the devastation caused by Hurricane Katrina to New Orleans in August 2005 or Hurricane Maria, which struck Puerto Rico in September 2017—two of the costliest natural disasters in the history of the United States. In addition, the world would have benefited greatly if financial and political analysts respectively had used structured techniques to anticipate the global economic crisis in 2008 and the rapid rise of the Islamic State (ISIS). A variation of this technique, High Impact/Uncertain Probability Analysis, might be used to address the potential impact of an outbreak of H5N1 (avian influenza) or applied to a terrorist attack when intent is well established but there are multiple variations on how it might occur.

A High Impact/Low Probability study most often is initiated when some new and often fragmentary information suggests that an unanticipated event might be more likely to occur than thought previously. For example, analysts should pass decision makers a tip-off warning of a major information warfare attack or a serious terrorist attack on a national holiday even though solid evidence is lacking. The technique is also helpful in sensitizing analysts and decision makers to the possible effects of low-probability events and to stimulate them to think early on about measures that could avoid the danger or exploit the opportunity.

A thoughtful senior policy official has opined that most potentially devastating threats to U.S. interests start out being evaluated as unlikely. The key to effective intelligence-policy relations in strategic warning is for analysts to help policy officials in determining which seemingly unlikely threats are worthy of serious consideration.

—Jack Davis, "Improving CIA Analytic Performance: Strategic Warning," Sherman Kent School for Intelligence Analysis, September 2002

Value Added

The High Impact/Low Probability Analysis format allows analysts to explore the consequences of an event—particularly one not deemed likely by conventional wisdom—without having to challenge the mainline judgment or to argue with others about the likelihood of an event. In other words, this technique provides a tactful way of communicating a viewpoint that some recipients might prefer not to hear.

The analytic focus is not on whether something will happen but to take it as a given that an event, which would have a major and unanticipated impact, could happen. The objective is to explore whether an increasingly credible case can be made for an unlikely event occurring that could pose a major danger—or offer great opportunities. The more nuanced and concrete the analyst's depiction of the plausible paths to danger, the easier it is for a decision maker to develop a package of policies to protect or advance the vital interests of his or her country or business.

High Impact/Low Probability Analysis helps protect analysts against some of the most common cognitive biases and misapplied heuristics, including assuming that others would act in the same way we would in similar circumstances (Mirror Imaging), accepting a given value of something unknown as a proper starting point for generating an assessment (Anchoring Effect), and ignoring conflicts within a group due to a desire for consensus (Groupthink). Use of the technique also helps counter the impact of several intuitive traps, including not addressing the impact of the absence of information on analytic conclusions (Ignoring the Absence of Information), failing to factor something into the analysis because the analyst lacks an appropriate category or "bin" for that item of information (Lacking Sufficient Bins), and focusing on a narrow range of alternatives representing marginal, not radical, change (Expecting Marginal Change).

The Method

An effective High Impact/Low Probability Analysis involves these steps:

Clearly describe the unlikely event. Define the high-impact outcome precisely if this event occurs. Consider both the actual event and the secondary effects of the event. Identify recent information or reporting that suggests the possibility of the unlikely event occurring may be increasing. Postulate additional triggers that would propel events in this unlikely direction or factors that would greatly accelerate timetables, such as a botched government response, the rise of an energetic political challenger, a major terrorist attack, or a surprise electoral outcome. Develop one or more plausible pathways to explain how this seemingly unlikely event could unfold. Focus on the specifics of what must happen at each stage of the process for the train of events to play out. Generate and validate a list of indicators to help analysts and decision makers anticipate whether the scenarios were beginning to unfold. Identify factors that would deflect a bad outcome or encourage a positive outcome. Periodically review the indicators and report on whether the proposed scenarios may be emerging and why. Be alert to events so unlikely that they did not merit serious attention but are beginning to emerge.

The last step in the process is extremely important. Periodic reviews of indicators provide analysts with useful signals that alert them to the possibility that prevailing mental models are no longer correct and an event previously considered unlikely now merits careful attention.

Potential Pitfalls

Analysts need to be careful when communicating the likelihood of unlikely events. The meaning of the word "unlikely" can be interpreted as meaning anywhere from 1 percent to 25 percent probability; "highly unlikely" may mean from 1 percent to 10 percent. 19 Clients receiving an intelligence report that uses words of estimative probability such as "very unlikely" will typically interpret the report as consistent with their own prior thinking. If the report says a terrorist attack against a specific foreign embassy within the next year is highly unlikely, it is possible that the analyst may be thinking of about a 10 percent possibility. A decision maker, however, may see that as consistent with his or her own thinking and assume the likelihood is less than 1 percent. Such a difference in likelihood can make the difference in deciding whether to order expensive contingency plans or enact proactive preventive countermeasures. When an analyst is describing the likelihood of an unlikely event, it is desirable to express the likelihood in numeric terms, either as a range (such as less than 5 percent or 10 to 20 percent) or as bettor's odds (such as one chance in ten).

Figure 8.2.5 shows an example of an unlikely event—the outbreak of conflict in the Arctic Ocean—that could have major geopolitical consequences. Analysts can employ the technique to sensitize decision makers to the possible effects of the melting of Arctic ice and stimulate them to think about measures that could deal with the danger.

Relationship to Other Techniques

High Impact/Low Probability Analysis is sometimes confused with What If? Analysis. Both deal with low-probability or unlikely events.

What If? Analysis does not require new or anomalous information to serve as a trigger. It reframes the question by positing that a surprise event has happened. It then looks backwards from that surprise event to map several ways it could have happened. It also tries to identify actions that, if taken in a timely manner, might have prevented it. High Impact/Low Probability Analysis is primarily a vehicle for warning decision makers that recent, unanticipated developments suggest that an event previously deemed highly unlikely may occur. Extrapolating on recent evidence or information, it projects forward to discuss what could occur and the consequences if the event does occur. It challenges the conventional wisdom.

Figure 8.2.5 High Impact/Low Probability Scenario: Conflict in the Arctic 20 Source: This example was developed by Pherson Associates, LLC.

Origins of This Technique

The description here is based on Randolph H. Pherson, "High Impact/Low Probability Analysis," in Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019); Globalytica, LLC, training materials; and Department of Homeland Security, Office of Intelligence and Analysis training materials. Tools needed to create your own chart can be found at https://www.mindtools.com/pages/article/newPPM_78.htm .

8.2.6 Delphi Method

Delphi is a method for eliciting ideas, judgments, or forecasts from a group of experts who may be geographically dispersed. It is different from a survey in that there are two or more rounds of questioning. After the first round of questions, a moderator distributes all the answers and explanations of the answers to all participants, often anonymously. The expert participants are then given an opportunity to modify or clarify their previous responses, if so desired, based on what they have seen in the responses of the other participants. A second round of questions builds on the results of the first round, drills down into greater detail, or moves to a related topic. The technique allows flexibility by increasing the number of rounds of questions.

When to Use It

The RAND Corporation developed the Delphi Method at the beginning of the Cold War in the 1950s to forecast the impact of new technology on warfare. It was also used to assess the probability, intensity, or frequency of future enemy attacks. In the 1960s and 1970s, Delphi became widely known and used as a method for futures research, especially forecasting long-range trends in science and technology. Futures research is like intelligence analysis in that the uncertainties and complexities one must deal with often preclude the use of traditional statistical methods, so explanations and forecasts must be based on the experience and informed judgments of experts.

Over the years, Delphi has been used in a wide variety of ways, and for an equally wide variety of purposes. Although many Delphi projects have focused on developing a consensus of expert judgment, a variant called Policy Delphi is based on the premise that the decision maker is not interested in having a group make a consensus decision, but rather in having the experts identify alternative policy options and present all the supporting evidence for and against each option. That is the rationale for describing Delphi as a reframing technique. It can be used to identify a set of divergent opinions, many of which may be worth exploring.

One group of Delphi scholars advises that the Delphi technique "can be used for nearly any problem involving forecasting, estimation, or decision making"—if the problem is not so complex or so new as to preclude the use of expert judgment. These Delphi advocates report using it for diverse purposes that range from "choosing between options for regional development, to predicting election outcomes, to deciding which applicants should be hired for academic positions, to predicting how many meals to order for a conference luncheon." 21

Value Added

We believe the development of Delphi panels of experts on areas of critical concern should be standard procedure for outreach to experts outside an analyst's organization, particularly in the intelligence community because of its more insular work environment. In the United States, the Office of the Director of National Intelligence (ODNI) encourages intelligence analysts to consult with relevant experts in academia, business, and NGOs in Intelligence Community Directive No. 205, on Analytic Outreach, dated July 2008.

As an effective process for eliciting information from outside experts, Delphi has several advantages:

Outside experts can participate remotely, thus reducing time and travel costs. Delphi can provide analytic judgments on any topic for which outside experts are available. That means it can be an independent cross-check of conclusions reached in-house. If the same conclusion is reached in two analyses using different analysts and different methods, confidence in the conclusion is increased. If the conclusions disagree, this is also valuable information that may open a new avenue of research. Delphi identifies any outliers who hold an unusual position. Recognizing that the majority is not always correct, researchers can then focus on gaining a better understanding of the grounds for any views that diverge significantly from the consensus. In fact, identification of experts who have an alternative perspective and are qualified to defend it might be the objective of a Delphi project. The process by which panel members are provided feedback from other experts and are given an opportunity to modify their responses makes it easy for participants to adjust their previous judgments in response to new evidence. In many Delphi projects, the experts remain anonymous to other panel members so that no one can use his or her position of authority, reputation, or personality to influence others. Anonymity also facilitates the expression of opinions that go against the conventional wisdom and may not otherwise be expressed. The anonymous features of the Delphi Method substantially reduce the potential for Groupthink. They also make it more difficult for any participant with strong views based on his or her past experiences and worldview to impose such views on the rest of the group (Projecting Past Experiences). The requirement that the group of experts engage in several rounds of information sharing also helps mitigate the potential for Satisficing.

The Delphi Method can help protect analysts from falling victim to several intuitive traps, including giving too much weight to first impressions or initial data, especially if they attract our attention and seem important at the time (Relying on First Impressions). It also protects against the tendency to continue holding to an analytic judgment when confronted with a mounting list of evidence that contradicts the initial conclusion (Rejecting Evidence).

The Method

In a Delphi project, a moderator or analyst sends a questionnaire to a panel of experts usually in different locations. The experts respond to these questions and are asked to provide short explanations for their responses. The moderator collates the results from the first questionnaire and sends the collated responses back to all panel members, asking them to reconsider their responses based on what they see and learn from the other experts' responses and explanations. Panel members may also be asked to answer another set of questions. This cycle of question, response, and feedback continues through several rounds using the same or a related set of questions. It is often desirable for panel members to remain anonymous so that they are not unduly influenced by the responses of senior members. This method is illustrated in Figure 8.2.6 .

Examples

Description Figure 8.2.6 Delphi Technique

To show how Delphi can be used for intelligence analysis, we have developed three illustrative applications:

Evaluation of another country's policy options. The Delphi project manager or moderator identifies several policy options that a foreign country might choose. The moderator then asks a panel of experts on the country to rate the desirability and feasibility of each option, from the other country's point of view, on a five-point scale ranging from "Very Desirable" or "Feasible" to "Very Undesirable" or "Definitely Infeasible." Panel members also identify and assess any other policy options that should be considered and identify the top two or three arguments or items of evidence that guided their judgments. A collation of all responses is sent back to the panel with a request for members to do one of the following: reconsider their position in view of others' responses, provide further explanation of their judgments, or reaffirm their previous response. In a second round of questioning, it may be desirable to list key arguments and items of evidence and ask the panel to rate them on their validity and their importance, again from the other country's perspective. Analysis of alternative hypotheses. A panel of outside experts is asked to estimate the probability of each hypothesis in a set of mutually exclusive hypotheses where the probabilities must add up to 100 percent. This could be done as a stand-alone project or to double-check an already completed Analysis of Competing Hypotheses ( chapter 7 ). If two analyses using different analysts and different methods arrive at the same conclusion, confidence in the conclusion can increase. If the analyses disagree, that may also be useful to know, as one can then seek to understand the rationale for the different judgments. Warning analysis or monitoring a situation over time. The facilitator asks a panel of experts to estimate the probability of a future event. This might be either a single event for which the analyst is monitoring early warning indicators or a set of scenarios for which the analyst is monitoring milestones to determine the direction in which events seem to be moving. A Delphi project that monitors change over time can be managed in two ways. One is to have a new round of questions and responses at specific intervals to assess the extent of any change. The other is what is called either Dynamic Delphi or Real-Time Delphi, where participants can modify their responses at any time as new events occur or as a participant submits new information. 22 The probability estimates provided by the Delphi panel can be aggregated to furnish a measure of the significance of change over time. They can also be used to identify differences of opinion among the experts that warrant further examination.

Potential Pitfalls

A Delphi project involves administrative work to identify the experts, communicate with panel members, and collate and tabulate their responses through several rounds of questioning. The use of Delphi by intelligence organizations can pose additional obstacles, such as ensuring that the experts have appropriate security clearances or requiring them to meet with the analysts in approved office spaces. Another potential pitfall is that overenthusiastic use of the technique can force consensus when it might be better to present two competing hypotheses and the evidence supporting each position.

Origins of This Technique

The origin of Delphi as an analytic method was described above under "When to Use It." The following references were useful in researching this topic: Murray Turoff and Starr Roxanne Hiltz, "Computer Based Delphi Processes," 1996, http://web.njit.edu/~turoff/Papers/delphi3.html ; and Harold A. Linstone and Murray Turoff, The Delphi Method: Techniques and Applications (Reading, MA: Addison-Wesley, 1975). A 2002 digital version of Linstone and Turoff's book is available online at http://is.njit.edu/pubs/delphibook ; see in particular the chapter by Turoff on "The Policy Delphi" ( http://is.njit.edu/pubs/delphibook/ch3b1.pdf ).

For more recent information on validity and optimal techniques for implementing a Delphi project, see Gene Rowe and George Wright, "Expert Opinions in Forecasting: The Role of the Delphi Technique," in Principles of Forecasting, ed. J. Scott Armstrong (New York: Springer Science+Business Media, 2001).

Several software programs are available for using the Delphi Method; for example, one can be found at http://armstrong.wharton.upenn.edu/delphi2 . Distributed decision support systems now publicly available to support virtual teams include some functions necessary for Delphi as part of a larger package of analytic tools.

8.3 Conflict Management Techniques

Challenge techniques support the identification and confrontation of opposing views. That is, after all, their purpose. This raises two important questions, however. First, how can confrontation be managed so that it becomes a learning experience rather than a battle between determined adversaries? Second, in an analysis of any topic with a high degree of uncertainty, how can one decide if one view is wrong or if both views have merit and need to be discussed in an analytic report? This section offers a conceptual framework and seven useful techniques for dealing with analytic conflicts.

A widely distributed article in the Harvard Business Review stresses that improved collaboration among organizations or organizational units with different interests can be achieved only by accepting and actively managing the inevitable—and desirable—conflicts between these units:

The disagreements sparked by differences in perspective, competencies, access to information, and strategic focus . . . actually generate much of the value that can come from collaboration across organizational boundaries. Clashes between parties are the crucibles in which creative solutions are developed. . . . So instead of trying simply to reduce disagreements, senior executives need to embrace conflict and, just as important, institutionalize mechanisms for managing it. 23

The most common procedures for dealing with differences of opinion have been to force a consensus, minimize the differences, or—in the U.S. Intelligence Community—add a dissenting footnote to an estimate. We believe these practices are suboptimal, at best. We hope they will become increasingly rare as our analytic communities embrace greater collaboration early in the analytic process, rather than endure mandated coordination at the end of the process after all parties are locked into their positions. One of the principal benefits of using Structured Analytic Techniques for intraoffice and interagency collaboration is that these techniques identify differences of opinion at the start of the analytic process. This gives time for the differences to be at least understood, if not resolved, at the working level before management becomes involved.

How one deals with conflicting analytic assessments or estimates depends, in part, upon one's expectations about what is achievable. Mark Lowenthal has written persuasively of the need to recalibrate expectations of what intelligence analysis can accomplish. 24 More than in any other discipline, intelligence analysts typically work with incomplete, ambiguous, and potentially deceptive evidence. Combine this with the fact that intelligence analysts are seeking to understand human behavior, which is difficult to predict even in our own culture. It should not be surprising that intelligence analysis sometimes turns out to be "wrong."

Acceptance of the basic principle that it is okay for analysts to be uncertain, because they are dealing with uncertain matters, helps to set the stage for appropriate management of conflicting views. In some cases, one position will be refuted and rejected. In other cases, two or more positions may be reasonable assessments or estimates, usually with one more likely than the others. In such cases, conflict is mitigated when it is recognized that each position has some value in covering the full range of options.

Earlier in this chapter, we noted that an assessment or estimate that is properly described as "probable" has about a one-in-four chance of being wrong. This has clear implications for appropriate action when analysts hold conflicting views. If an analysis meets rigorous standards yet conflicting views remain, decision makers are best served by an analytic product that deals directly with the uncertainty rather than minimizing or suppressing it. The greater the uncertainty, the more appropriate it is to go forward with a product that discusses the most likely assessment or estimate and gives one or more alternative possibilities. Some intelligence services have even required that an analysis or assessment cannot go forward unless the analyst can demonstrate that he or she has considered alternative explanations or scenarios.

Factors to be considered when assessing the amount of uncertainty include the following:

An estimate of the future generally has more uncertainty than an assessment of a past or current event. Mysteries, for which there are no knowable answers, are far more uncertain than puzzles, for which an answer does exist if one could only find it. 25 The more assumptions that are made, the greater the uncertainty. Assumptions about intent or capability, and whether they have changed, are especially critical. Analysis of human behavior or decision making is far more uncertain than analysis of technical data. The behavior of a complex dynamic system is more uncertain than that of a simple system. The more variables and stakeholders involved in a system, the more difficult it is to foresee what might happen.

If the decision is to go forward with a discussion of alternative assessments, the next step might be to produce any of the following:

A comparative analysis of opposing views in a single report. This calls for analysts to identify the sources and reasons for the uncertainty (e.g., assumptions, ambiguities, knowledge gaps), consider the implications of alternative assessments or estimates, determine what it would take to resolve the uncertainty, and suggest indicators for future monitoring that might provide early warning of a given alternative emerging. An analysis of alternative scenarios, as described in chapter 9 . A What If? Analysis or High Impact/Low Probability Analysis, as described in this chapter. A report that is clearly identified as a "second opinion" or "alternative perspective."

8.3.1 Adversarial Collaboration

Adversarial Collaboration is an agreement between opposing parties about how they will work together to resolve or at least gain a better understanding of their differences. Adversarial Collaboration is a relatively new concept championed by Daniel Kahneman, the psychologist who along with Amos Tversky initiated much of the research on cognitive biases described in Heuer's Psychology of Intelligence Analysis . Kahneman received a Nobel Prize in 2002 for his research on behavioral economics, and he wrote an intellectual autobiography in connection with this work in which he commented as follows on Adversarial Collaboration:

One line of work that I hope may become influential is the development of a procedure of adversarial collaboration , which I have championed as a substitute for the format of critique-reply-rejoinder in which debates are currently conducted in the social sciences. Both as a participant and as a reader, I have been appalled by the absurdly adversarial nature of these exchanges, in which hardly anyone ever admits an error or acknowledges learning anything from the other. Adversarial collaboration involves a good-faith effort to conduct debates by carrying out joint research—in some cases there may be a need for an agreed arbiter to lead the project and collect the data. Because there is no expectation of the contestants reaching complete agreement at the end of the exercise, adversarial collaboration will usually lead to an unusual type of joint publication, in which disagreements are laid out as part of a jointly authored paper. 26

Kahneman's approach to Adversarial Collaboration involves agreement on empirical tests for resolving a dispute and conducting those tests with the help of an impartial arbiter. A joint report describes the tests, states what both sides agree has been learned, and provides interpretations of the test results on which they disagree. 27

Truth springs from argument amongst friends.

—David Hume, Scottish philosopher

Although differences of opinion on intelligence judgments can seldom be resolved through empirical research, the Adversarial Collaboration concept can, nevertheless, be adapted to apply to the work of analysts. Analysts—and their managers—can agree to use a variety of techniques to reduce, resolve, more clearly define, or explain their differences. These are grouped together here under the overall heading of Adversarial Collaboration.

When to Use It

Adversarial Collaboration should be used only if both sides are open to discussion of an issue. If one side is fully locked into its position and has repeatedly rejected the other side's arguments, this technique is unlikely to be successful. Structured Debate is more appropriate to use in these situations because it includes an independent arbiter who listens to both sides and then decides.

Value Added

Adversarial Collaboration can help opposing analysts see the merit of another group's perspective. If successful, it will help both parties gain a better understanding of what assumptions or evidence are behind their opposing opinions on an issue and to explore the best way of dealing with these differences. Can one side be shown to be wrong, or should both positions be reflected in any report on the subject? Can there be agreement on indicators to show the direction in which events seem to be moving?

A key advantage of Adversarial Collaboration techniques is that they bring to the surface critical items of evidence, logic, and assumptions that the other side had not factored into its own analysis. This is especially true for evidence that is inconsistent with or unhelpful in supporting either side's lead hypothesis.

The Method

Six approaches to Adversarial Collaboration are described here. What all have in common is the requirement to understand and address the other side's position rather than simply dismiss it. Mutual understanding of the other side's position is the bridge to productive collaboration. These six techniques are not mutually exclusive; in other words, one might use several of them for any specific project.

8.3.1.1 The Method: Key Assumptions Check

The first step in understanding what underlies conflicting judgments is a Key Assumptions Check, as described in chapter 7 . Evidence is always interpreted in the context of a mental model about how events normally transpire in a given country or situation, and a Key Assumptions Check is one way to make a mental model explicit. If a Key Assumptions Check has not already been done, each side can apply this technique and then share the results with the other side.

Discussion should then focus on the rationale for each assumption and suggestions for how the assumption might be either confirmed or refuted. If the discussion focuses on the probability of Assumption A versus Assumption B, it is often helpful to express probability as a numerical range—for example, 65 percent to 85 percent for probable. When analysts go through these steps, they sometimes discover they are not as far apart as they thought. The discussion should focus on refuting the other side's assumptions rather than supporting one's own.

8.3.1.2 The Method: Analysis of Competing Hypotheses

When opposing sides are dealing with a collegial difference of opinion, with neither side firmly locked into its position, Analysis of Competing Hypotheses (ACH), described in chapter 7 , may be a good structured format for helping to identify and discuss differences. One important benefit of ACH is that it pinpoints the exact sources of disagreement. Both parties agree on a set of hypotheses and then rate each item of evidence or relevant information as consistent or inconsistent with each hypothesis. When analysts disagree on these consistency ratings, the differences are often quickly resolved. When not resolved, the differences often point to previously unrecognized assumptions or to some interesting rationale for a different interpretation of the evidence. One can also use ACH to trace the significance of each item of relevant information in supporting the overall conclusion.

The use of ACH may not result in the elimination of all the differences of opinion, but it can be a big step toward understanding these differences and determining what might be reconcilable through further intelligence collection or research. The analysts can then make a judgment about the potential productivity of further efforts to resolve the differences. ACH may not be helpful, however, if two sides are already locked into their positions. It is all too easy in ACH for one side to interpret the evidence and enter assumptions in a way that deliberately supports its preconceived position. To challenge a well-established mental model, other challenge or conflict management techniques may be more appropriate.

8.3.1.3 The Method: Argument Mapping

Argument Mapping, which was described in chapter 7 , maps the logical relationship between each element of an argument. Two sides might agree to work together to create a single Argument Map with the rationales both for and against a given conclusion. Such an Argument Map will show where the two sides agree, where they diverge, and why. The visual representation of the argument makes it easier to recognize weaknesses in opposing arguments. This technique pinpoints the location of any disagreement and could serve as an objective basis for mediating a disagreement. An alternative approach might be to create, compare, and discuss the merits of alternative, contrasting Argument Maps.

8.3.1.4 The Method: Mutual Understanding

When analysts in different offices or agencies disagree, the disagreement is often exacerbated by the fact that they have a limited understanding of the other side's position and logical reasoning. The Mutual Understanding approach addresses this problem directly.

There are two ways to measure the health of a debate: the kinds of questions being asked and the level of listening.

—David A. Garvin and Michael A. Roberto, "What You Don't Know about Making Decisions," Harvard Business Review (September 2001)

After an exchange of information on their positions, the two sides meet with a facilitator, moderator, or decision maker. Side 1 is required to explain to Side 2 its understanding of Side 2's position. Side 1 must do this in a manner that satisfies Side 2 that its position is appropriately represented. Then the roles are reversed, and Side 2 explains its understanding of Side 1's position. This mutual exchange is often difficult to do without carefully listening to and understanding the opposing view and what it is based upon. Once each side accurately understands and represents the other side's position, both sides can more collegially discuss their differences rationally and with less emotion. Experience shows that this technique normally prompts some movement of the opposing parties toward common ground. 28

8.3.1.5 The Method: Joint Escalation

When disagreement occurs within an analytic team, the disagreement is often referred to a higher authority. This escalation often makes matters worse. What typically happens is that a frustrated analyst takes the problem up to his or her boss, briefly explaining the conflict in a manner that is clearly supportive of the analyst's own position. The analyst then returns to the group armed with the boss's support. However, the opposing analyst(s) have also gone to their bosses and come back with support for their solution. Each analyst is then locked into what has become "my manager's view" of the issue. An already thorny problem has become even more intractable. If the managers engage each other directly, both will quickly realize they lack a full understanding of the problem and must factor in what their counterparts know before trying to resolve the issue.

This situation can be avoided by an agreement among team members, or preferably an established organization policy, that requires joint escalation. 29 The analysts should be required to prepare a joint statement describing the disagreement and to present it jointly to their superiors. This requires each analyst to understand and address, rather than simply dismiss, the other side's position. It also ensures that managers have access to multiple perspectives on the conflict, its causes, and various paths for resolution.

Just the need to prepare such a joint statement discourages escalation and often leads to an agreement. The proponents of this approach report their experience that "companies that require people to share responsibility for the escalation of a conflict often see a decrease in the number of problems that are pushed up the management chain. Joint escalation helps create the kind of accountability that is lacking when people know they can provide their side of an issue to their own manager and blame others when things don't work out." 30

8.3.1.6 The Method: The Nosenko Approach

Yuri Nosenko was a Soviet intelligence officer who defected to the United States in 1964. Whether he was a true defector or a Soviet plant was a subject of intense and emotional controversy within the CIA for more than a decade. In the minds of some, this historic case is still controversial.

At a critical decision point in 1968, the leadership of the CIA's Soviet Bloc Division set up a three-man team to review all the evidence and make a recommendation for the division's action in this case. The amount of evidence is illustrated by the fact that just one single report arguing that Nosenko was still under Soviet control was 1,000 pages long. The team consisted of one leader who was of the view that Nosenko was a Soviet plant, one leader who believed that he was a bona fide defector, and an experienced officer who had not previously been involved but was inclined to think Nosenko might be a plant.

The interesting point here is the ground rule that the team was instructed to follow. After reviewing the evidence, each officer identified those items of evidence thought to be of critical importance in making a judgment on Nosenko's bona fides. Any item that one officer stipulated as critically important then had to be addressed by the other two members.

It turned out that fourteen items were stipulated by at least one of the team members and had to be addressed by the others. Each officer prepared his own analysis, but they all had to address the same fourteen issues. Their report became known as the "Wise Men" report.

The team did not come to a unanimous conclusion. However, it was significant that the thinking of all three moved in the same direction. When the important evidence was viewed from the perspective of searching for the truth, rather than proving Nosenko's guilt or innocence, the case that Nosenko was a plant began to unravel. The officer who had always believed that Nosenko was bona fide felt he could now prove the case. The officer who was relatively new to the case changed his mind in favor of Nosenko's bona fides. The officer who had been one of the principal analysts and advocates for the position that Nosenko was a plant became substantially less confident in that conclusion. There were now adequate grounds for management to make the decision.

The ground rules used in the Nosenko case can be applied in any effort to abate a long-standing analytic controversy. The key point that makes these rules work is the requirement that each side must directly address the issues important to the other side and thereby come to understand the other's perspective. This process guards against the common propensity of analysts to make their own arguments and then simply dismiss those of the other side as unworthy of consideration. 31

8.3.2 Structured Debate

Structured Debate is a planned debate between analysts or analytic teams that hold opposing points of view on a specific issue. The debate is conducted according to set rules and before an audience, which may be a "jury of peers" or one or more senior analysts or managers.

When to Use It

Structured Debate is called for when a significant difference of opinion exists within or between analytic units or within the decision-making community. It can also be used effectively when Adversarial Collaboration has been unsuccessful or is impractical, and a choice must be made between two opposing opinions or a decision to go forward with a comparative analysis of both. Structured Debate requires a significant commitment of analytic time and resources. A long-standing policy issue, a critical decision that has far-reaching implications, or a dispute within the analytic community that is obstructing effective interagency collaboration would be grounds for making this type of investment in time and resources.

Value Added

In the method proposed here, each side presents its case in writing to the opposing side; then, both cases are combined in a single paper presented to the audience prior to the debate. The oral debate then focuses on refuting the other side's position. Glib and personable speakers can always make arguments for their own position sound persuasive. Effectively refuting the other side's position is a different ball game, however. The requirement to refute the other side's position brings to the debate an important feature of the scientific method: that the most likely hypothesis is the one with the least evidence against it as well as good evidence for it. (The concept of refuting hypotheses is discussed in chapter 7 .)

He who knows only his own side of the case, knows little of that. His reasons may be good, and no one may have been able to refute them. But if he is equally unable to refute the reasons on the opposite side, if he does not so much as know what they are, he has no ground for preferring either opinion.

—John Stuart Mill, On Liberty (1859)

The goal of the debate is to decide what to tell the client. If neither side can effectively refute the other, then arguments for and against both sides should be in the report. Customers of intelligence analysis gain more benefit by weighing well-argued conflicting views than from reading an assessment that masks substantive differences among analysts or drives the analysis toward the lowest common denominator. If participants routinely interrupt one another or pile on rebuttals before digesting the preceding comment, the objective of Structured Debate is defeated. The teams are engaged in emotional conflict rather than constructive debate.

The Method

Start by defining the conflict to be debated. If possible, frame the conflict in terms of competing and mutually exclusive hypotheses. Ensure that all sides agree with the definition. Then follow these steps:

An individual is selected, or a group identified, who can develop the best case for each hypothesis. Each side writes up the best case from its point of view. This written argument must be structured with an explicit presentation of key assumptions, key pieces of evidence, and careful articulation of the logic behind the argument. Each side presents the opposing side with its arguments, and the two sides are given time to develop counterarguments to refute the opposing side's position.

Next, conduct the debate phase in the presence of a jury of peers, senior analysts, or managers who will provide guidance after listening to the debate. If desired, an audience of interested observers might also watch the debate.

The debate starts with each side presenting a brief (maximum five minutes) summary of the argument for its position. The jury and the audience are expected to have read each side's full argument. Each side then presents to the audience its rebuttal of the other side's written position. The purpose here is to proceed in the oral arguments by systematically refuting alternative hypotheses rather than by presenting more evidence to support one's own argument. This is the best way to evaluate the strengths of the opposing arguments. After each side has presented its rebuttal argument, the other side is given an opportunity to refute the rebuttal. The jury asks questions to clarify the debaters' positions or gain additional insight needed to pass judgment on the debaters' positions. The jury discusses the issue and passes judgment. The winner is the side that makes the best argument refuting the other side's position, not the side that makes the best argument supporting its own position. The jury may also recommend possible next steps for further research or intelligence collection efforts. If neither side can refute the other's arguments, it may be because both sides have a valid argument; if that is the case, both positions should appear in any subsequent analytic report.

Relationship to Other Techniques

Structured Debate is like the Team A/Team B technique that has been taught and practiced throughout the intelligence community. Structured Debate differs from Team A/Team B Analysis in its focus on refuting the other side's argument. Use of the technique also reduces the chances that emotions overshadow the process of conflict resolution. The authors have dropped Team A/Team B Analysis and Devil's Advocacy from the third edition of this book because they believe neither is an appropriate model for how analysis should be conducted. 32

Origins of This Technique

The history of debate goes back to the Socratic dialogues in ancient Greece, and even earlier. Many different forms of debate have evolved since then. Richards J. Heuer Jr. formulated the idea of focusing the debate on refuting the other side's argument rather than supporting one's own.

Notes

1. Rob Johnston, Analytic Culture in the U.S. Intelligence Community (Washington, DC: CIA Center for the Study of Intelligence, 2005), 64.

2. Stephen J. Coulthart, "Improving the Analysis of Foreign Affairs: Evaluating Structured Analytic Techniques" (PhD diss., University of Pittsburgh, 2015), http://d-scholarship.pitt.edu/26055/1/CoulthartSJ_ETD2015.pdf

3. Reframing is like the Problem Restatement technique Morgan Jones described in his book The Thinker's Toolkit (New York: Three Rivers Press, 1995). Jones observed that "the moment we define a problem our thinking about it quickly narrows considerably." We create a frame through which we view the problem and that tends to obscure other interpretations of the problem. A group can change that frame of reference, and challenge its own thinking, simply by redefining the problem.

4. For more information about this application, see the Applied Critical Thinking Handbook, 7.0 (Fort Leavenworth, KS: University of Foreign Military and Cultural Studies, 2015), https://fas.org/irp/doddir/army/critthink.pdf .

5. Kesten Green and J. Scott Armstrong, "Structured Analogies for Forecasting," in International Journal of Forecasting , Vol. 23, Issue 3, July–September 2007, pp. 365–376, and www.forecastingprinciples.com/paperpdf/Structured_Analogies.pdf

6. This technique should not be confused with Edward de Bono's Six Thinking Hats technique.

7. Richards J. Heuer Jr., Psychology of Intelligence Analysis (Washington, DC: CIA Center for the Study of Intelligence, 1999; reprinted by Pherson Associates, LLC, 2007), 134–138.

8. The description of how to conduct a Red Hat Analysis has been updated since publication of the first edition to capture insights provided by Todd Sears, a former Defense Intelligence Agency analyst, who noted that Mirror Imaging is unlikely to be overcome simply by sensitizing analysts to the problem. The value of a structured technique like Red Hat Analysis is that it requires analysts to think first about what would motivate them to act before articulating why a foreign adversary would act differently.

9. Peter Schwartz, The Art of the Long View (New York: Doubleday, 1991).

10. Paul Bedard, "CIA Chief Claims Progress with Intelligence Reforms," U.S. News and World Report , May 16, 2008.

11. Donald P. Steury, ed., Sherman Kent and the Board of National Estimates: Collected Essays (Washington, DC: CIA Center for the Study of Intelligence, 1994), 133.

12. Gary Klein, Sources of Power: How People Make Decisions (Cambridge, MA: MIT Press, 1998), 71.

13. Gary Klein, Intuition at Work: Why Developing Your Gut Instinct Will Make You Better at What You Do (New York: Doubleday, 2002), 91.

14. Charlan J. Nemeth and Brendan Nemeth-Brown, "Better Than Individuals? The Potential Benefits of Dissent and Diversity for Group Creativity," in Group Creativity: Innovation through Collaboration , eds. Paul B. Paulus and Bernard A. Nijstad (New York: Oxford University Press, 2003), 63.

15. Leon Panetta, "Government: A Plague of Incompetence," Monterey County Herald , March 11, 2007, F1.

16. Gregory F. Treverton, "Risks and Riddles," Smithsonian Magazine , June 2007.

17. For information about these three decision-making models, see Graham T. Allison and Philip Zelikov, Essence of Decision , 2nd ed. (New York: Longman, 1999).

18. For information on fundamental differences in how people think in different cultures, see Richard Nisbett, The Geography of Thought: How Asians and Westerners Think Differently and Why (New York: Free Press, 2003).

19. Richards J. Heuer Jr., Psychology of Intelligence Analysis (Washington, DC: CIA Center for the Study of Intelligence, 1999; reprinted by Pherson Associates, LLC, 2007), 155.

20. A more robust discussion of how conflict could erupt in the Arctic can be found in "Uncharted Territory: Conflict, Competition, or Collaboration in the Arctic?" accessible at shop.globalytica.com.

21. Kesten C. Green, J. Scott Armstrong, and Andreas Graefe, "Methods to Elicit Forecasts from Groups: Delphi and Prediction Markets Compared," Foresight: The International Journal of Applied Forecasting (Fall 2007), www.forecastingprinciples.com/paperpdf/Delphi-WPlatestV.pdf

22. See Real-Time Delphi, www.realtimedelphi.org

23. Jeff Weiss and Jonathan Hughes, "Want Collaboration? Accept—and Actively Manage—Conflict," Harvard Business Review , March 2005.

24. Mark M. Lowenthal, "Towards a Reasonable Standard for Analysis: How Right, How Often on Which Issues?" Intelligence and National Security 23, no. 3 (June 2008): 303–15. https://doi.org/10.1080/02684520802121190.

25. Treverton, "Risks and Riddles."

26. Daniel Kahneman, Autobiography , 2002, available on the Nobel Prize website: https://www.nobelprize.org/prizes/economic-sciences/2002/kahneman/biographical/ . For a pioneering example of a report on an Adversarial Collaboration, see Barbara Mellers, Ralph Hertwig, and Daniel Kahneman, "Do Frequency Representations Eliminate Conjunction Effects? An Exercise in Adversarial Collaboration," Psychological Science 12 (July 2001).

27. Richards J. Heuer Jr. is grateful to Steven Rieber of the Office of the Director of National Intelligence, Office of Analytic Integrity and Standards, for referring him to Kahneman's work on Adversarial Collaboration.

28. Richards J. Heuer Jr. is grateful to Jay Hillmer of the Defense Intelligence Agency for sharing his experience in using this technique to resolve coordination disputes.

29. Weiss and Hughes, "Want Collaboration?"

30. Ibid.

31. This discussion is based on Richards J. Heuer Jr., "Nosenko: Five Paths to Judgment," in Inside CIA's Private World: Declassified Articles from the Agency's Internal Journal, 1955–1992 , ed. H. Bradford Westerfield (New Haven, CT: Yale University Press, 1995).

32. The term Team A/Team B is taken from a historic analytic experiment conducted in 1976. A team of CIA Soviet analysts (Team A) and a team of outside critics (Team B) prepared competing assessments of the Soviet Union's strategic military objectives. This exercise was characterized by entrenched and public warfare between long-term adversaries. In other words, the historic legacy of Team A/Team B is exactly the type of trench warfare between opposing sides that we need to avoid. The 1976 experiment did not achieve its goals, and it is not a model that most analysts familiar with it would want to follow. We recognize that some Team A/Team B exercises can be fruitful if carefully managed but believe the Reframing Techniques described in this chapter are better ways to proceed.

Descriptions of Images and Figures

Back to Figure

New information is acquired while going up a cable car in a mountain. When a person skis down a gentle slope, twisting and turning along the way, they grind a new set of lenses, and outcome is more imaginative thinking. When a person goes straight down a steep slope, with same old cognitive destination, the outcome is speedy but predictable thinking.

Back to Figure

Your office has high influence in the thinking process. Your profession, and key factors, such as size, growth, clients, adversaries, suppliers, products, and technology have some influence. The world, and key forces such as globalization, identity, social stress, social media, big data, and artificial intelligence have little or no influence.

Back to Figure

Analogy based on shared attributes. The illustration shows a pentagon and a hexagon with two stars in each of them. An accompanying text reads, "Canadians and Americans speak English and eat pizza."

Analogy based on function or relation. The illustration shows a small square, labeled A, a larger square, labeled B, a small triangle, labeled C, and a larger triangle, labeled D. Text reads, "A is to B as C is to D. A driver is to a car as a pilot is to an airplane."

Back to Figure

The first coordinate system is titled, multiple attacks or insider. Data in each quadrant are as follows. Quadrant 1: Simultaneous. Contractor or visitor. Quadrant 2: Simultaneous. Staff employee. Quadrant 3: Cascading. Staff employee. Quadrant 4: Cascading. Contractor or visitor. The second coordinate system is titled, multiple attacks or minor casualties. Data in each quadrant are as follows. Quadrant 1: Simultaneous. Disrupt Economy. Quadrant 2: Simultaneous. Spark terror. Quadrant 3: Cascading. Spark terror. Quadrant 4: Simultaneous. Spark terror.

Back to Figure

The first system is titled, multiple attacks or insider. Data in each quadrant are as follows. Quadrant 1: Attack plan 2. Quadrant 2: Story A. Simultaneous. Staff employee. Quadrant 3: Attack Plan 3. Quadrant 4: Story B. Cascading. Staff employee.

The second system is titled, multiple attacks or minor casualties. Data in the quadrant are as follows. Quadrant 1: Attack Plan 6. Quadrant 2: Attack Plan 5. Quadrant 3: Story B. Cascading. Spark terror. Quadrant 4: Attack Plan 8.

The third system is titled, multiple attacks or other strategies. Data in the quadrant are as follows. Quadrant 1: Attack Plan 14. Quadrant 2: Attack Plan 13. Quadrant 3: Attack Plan 15. Quadrant 4: Story B. Cascading. Water as weapon.

The fourth system is titled, multiple attacks or wastewater. Quadrant 1: Attack Plan 10. Quadrant 2: Attack Plan 9. Quadrant 3: Nightmare Attack Plan. Cascading. Treatment plants. Quadrant 4: Attack Plan 12.

Back to Figure

What caused our analysis to be so wrong? Did we consider alternative hypotheses? Did external influences affect the outcome? Did deception go undetected? Were our sources or key evidence unreliable? Was any contradictory evidence ignored? Did the absence of information mislead us? Were our key assumptions valid?

Back to Figure

There are seven steps. Steps 1, 3, and 5 are from the facilitator to the experts. Steps 2, 4, and 6 are from the experts to the facilitator. The facilitator prepares the final report in step 7. The technique flows as follows. Facilitator seeks individual assessments from a pool of experts. Experts respond to the request, receive feedback from the facilitator, and revise their responses. Facilitator compiles the responses and sends a revised set of questions to each expert. Several feedback cycles may be needed. Facilitator prepares report on experts' responses, noting key outliers.

Chapter 9 Foresight Techniques

9.1 Key Drivers Generation™ [ 260 ] 9.2 Key Uncertainties Finder™ [ 262 ] 9.3 Reversing Assumption [ 264 ] 9.4 Simple Scenarios [ 265 ] 9.5 Cone of Plausibility [ 267 ] 9.6 Alternative Futures Analysis [ 270 ] 9.7 Multiple Scenarios Generation [ 272 ] 9.8 Morphological Analysis [ 276 ] 9.9 Counterfactual Reasoning [ 279 ] 9.10 Analysis by Contrasting Narratives [ 285 ] 9.11 Indicators Generation, Validation, and Evaluation [ 289 ]

9.11.1 The Method: Indicators Generation [ 292 ] 9.11.2 The Method: Indicators Validation [ 295 ] 9.11.3 The Method: Indicators Evaluation [ 295 ]

I n the complex, evolving, uncertain situations that analysts and decision makers must deal with every day, the future is not easily predictable. Some events are intrinsically of low predictability. The best the analyst can do is to identify the driving forces that are likely to determine future outcomes and monitor those forces as they interact to become the future. Scenarios are a principal vehicle for doing this. Scenarios are plausible and provocative stories about how the future might unfold. When alternative futures are clearly outlined, decision makers can mentally rehearse these futures and ask themselves, "What should I be doing now to prepare for these futures?"

Anticipating future developments and implementing future-oriented policies is particularly challenging because of the increasing complexity of problems, the expanding number of stakeholders, and the growing interdependence among various actors, institutions, and events. Senior officials in the government and private sector expect analysts to alert them to emerging trends and unanticipated developments such as the rapid rise of the Islamic State (ISIS), the migration crisis in Europe, the Brexit vote in the United Kingdom, and the results of the 2016 presidential election in the United States.

Analysts can best perform this function by using Foresight Techniques—a family of imaginative structured techniques that infuse creativity into the analytic process. The techniques help decision makers better structure a problem and anticipate the unanticipated. Figure 9.0 lists eleven techniques described in this and other chapters, suggesting the best circumstances for using each technique. When the Foresight Techniques are matched with Indicators, they can help warn of coming dangers or expose new ways of responding to opportunities.

Description Figure 9.0 Taxonomy of Foresight Techniques Source: Pherson Associates, LLC, 2019.

The process of developing key drivers—and using them in combinations to generate a wide array of alternative trajectories—forces analysts to think about the future in ways they never would have contemplated if they relied only on intuition and their own expert knowledge. Generating a comprehensive list of key drivers requires organizing a diverse team that is knowledgeable in a wide variety of disciplines. A good guide for ensuring diversity is to engage a set of experts who can address all the elements of STEMPLES+, that is, the S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity dimensions of a problem plus possible additional factors such as Demographics, Religion, or Psychology.

We begin this chapter with a discussion of two techniques for developing a list of key drivers. Key Drivers Generation™ uses the Cluster Brainstorming technique to identify potential key drivers. The Key Uncertainties Finder™ is an extension of the Key Assumptions Check. We recommend using both techniques and melding their findings to generate a robust set of drivers. The authors' decades of experience in developing key drivers suggest that the number of mutually exclusive key drivers rarely exceeds four or five. Practice in using these two techniques will help analysts become proficient in the fourth of the Five Habits of the Master Thinker: identifying key drivers.

Scenarios provide a framework for considering multiple plausible futures by constructing alternative trajectories or stories about how a situation could unfold. As Peter Schwartz, author of The Art of the Long View , has argued, "The future is plural." 1 Trying to divine or predict a single outcome typically is a disservice to senior policy officials, decision makers, and other clients. Generating several scenarios (for example, those that are most likely, unanticipated, or most dangerous) can be more helpful because it helps focus attention on the underlying forces and factors—or key drivers—that are most likely to determine how the future will unfold. When High Impact/Low Probability scenarios are included, analysts can use scenarios to examine assumptions, identify emerging trends, and deliver useful warning messages. Foresight Techniques help analysts manage complexity and uncertainty by adding rigor to the foresight process. They are based on the premise that generating numerous stories about how the future will evolve will increase the practitioner's sensitivity to outlier scenarios, reveal new opportunities, and reduce the chances of surprise. By postulating different scenarios, analysts can identify the multiple ways in which a situation might evolve. This process can help decision makers develop plans to take advantage of whatever opportunities the future may hold—or, conversely, to avoid or mitigate risks.

It is vitally important that we think deeply and creatively about the future, or else we run the risk of being surprised and unprepared. At the same time, the future is uncertain, so we must prepare for multiple plausible futures, not just the one we expect to happen. Scenarios contain the stories of these multiple futures, from the expected to the wildcard, in forms that are analytically coherent and imaginatively engaging. A good scenario grabs us by the collar and says, "Take a good look at this future. This could be your future. Are you going to be ready?"

— Peter Bishop, Andy Hines, and Terry Collins,"The Current State of Scenario Development," Foresight (March 2007)

Foresight Techniques are most useful when a situation is complex or when the outcomes are too uncertain to trust a single prediction. When decision makers and analysts first come to grips with a new situation or challenge, a degree of uncertainty always exists about how events will unfold. At the point when national policies or long-term corporate strategies are in the initial stages of formulation, Foresight Techniques can have a strong impact on decision makers' thinking.

One benefit of Foresight Techniques is that it provides an efficient mechanism for communicating complex ideas, typically described in a scenario with a short and "catchy" label. These labels provide a lexicon for thinking and communicating with other analysts and decision makers about how a situation or a country is evolving. Examples of effective labels include "Red Ice," which describes Russia's takeover of a melting Arctic Ocean, or "Glueless in Havana," which describes the collapse of the Cuban government and its replacement by the Russian mafia.

Scenarios do not predict the future, but a good set of scenarios bounds the range of possible futures for which a decision maker may need to be prepared. Scenarios can be used as a strategic planning tool that brings decision makers and stakeholders together with experts to envisage the alternative futures for which they must plan. 2

When analysts are thinking about scenarios, they are rehearsing the future so that decision makers can be prepared for whatever direction that future takes. Instead of trying to estimate the most likely outcome and being wrong quite often, scenarios provide a framework for considering multiple plausible futures. Trying to divine or predict a single outcome is usually a fool's errand. By generating several scenarios, the decision makers' attention is shifted to the key drivers that are most likely to influence how a situation will develop.

Analysts have learned from experience that involving decision makers in a scenarios workshop is an effective way to communicate the results of this technique and to sensitize them to important uncertainties. Most participants find the process of developing scenarios much more useful than any written report or formal briefing. Those involved in the process often benefit in several ways. Experience has shown that scenarios can do the following:

Suggest indicators to monitor for signs that a specified future is becoming more or less likely. Help analysts and decision makers anticipate what would otherwise be surprising developments by forcing them to challenge assumptions and consider plausible "wild-card" scenarios or discontinuous events. Produce an analytic framework for calculating the costs, risks, and opportunities represented by different outcomes. Provide a means for weighing multiple unknown or unknowable factors and presenting a set of plausible outcomes. Stimulate thinking about opportunities that can be leveraged or exploited. Bound a problem by identifying plausible combinations of uncertain factors.

When decision makers or analysts from different disciplines or organizational cultures are included on the team, new insights invariably emerge as new relevant information and competing perspectives are introduced. Analysts from outside the organizational culture of an analytic unit are likely to see a problem in different ways. They are likely to challenge key working assumptions and established mental models of the analytic unit and avoid the trap of expecting only incremental change. Involving decision makers, or at least a few individuals who work in the office of the ultimate client or decision maker, can bring invaluable perspective and practical insights to the process.

When analysts look well into the future, they usually find it extremely difficult to do a simple, straight-line projection, given the high number of variables they need to consider. By changing the "analytic lens" through which the future is viewed, analysts are also forced to reevaluate their assumptions about the priority order of key factors driving the issue. By pairing the key drivers to create sets of mutually exclusive scenarios, scenario techniques help analysts think about the situation from sometimes counterintuitive perspectives, often generating several unexpected and dramatically different potential future worlds.

By engaging in a multifaceted and systematic examination of an issue, analysts create a more comprehensive set of alternative futures. This enables them to maintain records about each alternative and track the potential for change, thus gaining greater confidence in their overall assessment.

The amount of time and effort required depends upon the specific technique used. A single analyst can use Reversing Assumptions, Simple Scenarios, What If? Analysis, and Cone of Plausibility without any technical or methodological support, although a group effort typically yields more diverse and creative results. Various forms of Brainstorming, Key Drivers Generation™, and Key Uncertainties Finder™ require a group and a facilitator but can be done in an hour or two. The time required for Foresight Quadrant Crunching™, Alternative Futures Analysis, Multiple Scenarios Generation, Morphological Analysis, and Counterfactual Reasoning varies, but these techniques usually require a team of experts to spend several days working together on the project. Analysis by Contrasting Narratives and often Multiple Scenarios Generation involve engaging decision makers directly in the process. How the technique is applied will also vary depending on the topic and the target client. For this reason, we strongly recommend engaging a facilitator who is knowledgeable about Foresight Techniques to save time and ensure a high-quality product.

Criteria should be established for choosing which scenarios are the most important to bring to the attention of the decision maker or ultimate client. The list should be tailored to the client's needs and should fully answer the focal question asked at the beginning of the exercise. Five criteria often used in selecting scenarios follow:

Downside Risk. This criterion addresses the question most often asked: "How bad can it get?" The response should be a credible scenario that has a reasonable chance of occurring and should require the development of a contingency plan for avoiding, mitigating, or recovering if the selected scenario comes to pass. A "nightmare scenario," also described as a High Impact/Low Probability scenario, is usually best portrayed in a tone box or text box in the paper and not as its own stand-alone scenario. Mainline Assessment. Most clients will usually ask, "What is most likely to happen?" The honest answer is usually, "We do not really know; it depends on how the various key drivers play out in influencing future developments." Although the purpose of Foresight analysis is to show that several scenarios are possible, scenarios can usually be ranked in order from most to least likely to occur based on current trends and reasonable key assumptions. Providing a mainline scenario also establishes a convenient baseline for conducting further analysis and deciding what actions are critical. New Opportunity. Every Foresight workshop should include pathways that show decision makers how they can fashion a future or futures more to their liking. This can be accomplished by including one or more scenario that showcases new opportunities or by including a section describing how a bad outcome can be mitigated or remedied. Every adversity comes with an opportunity, and the Foresight processes discussed in this chapter can be just as effective in developing positive, opportunities-based scenarios as in describing all the bad things that can happen. Emerging Trend. Often when conducting a Foresight workshop, new factors will appear or new trends will be identified that analysts or decision makers had previously ignored. These new trends, relationships, or dynamics often are integral to or reflected in several of the scenarios and can be collapsed into a single scenario that best illustrates the significance of—and opportunities presented by—the new trend. Recognizable Anchor. If the client does not believe any of the scenarios of the Foresight analysis exercise are credible or consistent with the client's experience or convictions, then the recipient will likely disregard the entire process and ignore key findings or discoveries made. On the other hand, recipients who find a scenario that resonates with their current worldview will anchor their understanding of the exercise on that scenario and more easily understand the alternatives.

One of the greatest challenges in applying Foresight Techniques is to generate attention-deserving scenarios that are comprehensive, mutually exclusive, and optimally support the needs of the primary client. A frequent question is, "How many scenarios should we create?" Past practice suggests that the optimal number is four, because any other number has built-in drawbacks:

One scenario is a prediction that invariably will not come true. Two scenarios suggest an artificial binary process. Three scenarios introduce the Goldilocks effect, often implying that the "middle" scenario is an appropriate compromise. Five or more scenarios are usually too many for a decision maker to process cognitively.

Scenarios workshops will most likely fail if the group conducting the exercise is not highly diverse, with representatives from a variety of disciplines, organizations, and even cultures to avoid the trap of Groupthink. Foresight analysis can be a powerful instrument for overcoming well-known cognitive biases and heuristics such as the Anchoring Effect, Groupthink, and Premature Closure. Scenarios techniques also mitigate the intuitive traps of thinking of only one likely (and predictable) outcome instead of acknowledging that several outcomes are possible (Assuming a Single Solution), focusing on a narrow range of alternatives representing marginal—and not radical—change (Expecting Marginal Change), and failing to factor something into the analysis because the analyst lacks an appropriate category or "bin" for that item of information (Lacking Sufficient Bins).

Users of Foresight Techniques often find that members of the "futures group or study group" have difficulty thinking outside of their comfort zone, resisting instructions to look far into the future, or to explore or suggest concepts that do not fall within their area of expertise. Techniques that have worked well to pry participants out of such analytic pitfalls are to (1) define a time period for the estimate (such as five or ten years) that one cannot easily extrapolate from current events, or (2) post a list of concepts or categories (such as the STEMPLES+ list of S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity, plus other factors such as Demographic, Religious, or Psychological) to stimulate thinking about an issue from different perspectives. Analysts involved in the process should have a thorough understanding of the subject matter and possess the conceptual skills necessary to identify the key drivers and assumptions that are likely to remain valid throughout the period of the assessment.

Identification and monitoring of indicators or signposts can provide early warning of the direction in which the future is heading, but these early signs are not obvious. 3 Indicators take on meaning only in the context of a specific scenario with which they are associated. The prior identification of a scenario and related indicators can create an awareness that prepares the mind to recognize early signs of significant change. Change sometimes happens so gradually that analysts do not notice it, or they rationalize it as not being of fundamental importance until it is too obvious to ignore. After analysts take a position on an issue, they typically are slow to change their minds in response to new evidence. By going on the record in advance to specify what actions or events would be significant and might change their minds, analysts can avert this type of rationalization.

The time required to use Foresight Techniques (such as Multiple Scenarios Generation, Foresight Quadrant Crunching™, or Counterfactual Reasoning) ranges from a few days to several months, depending on the complexity of the problem, scheduling logistics, and the number of participants involved in the process. 4 Most of the techniques involve several stages of analysis and employ different techniques to (1) identify key drivers, (2) generate permutations to reframe how the topic could evolve, (3) convert them into scenarios, (4) establish indicators for assessing the potential for each proposed alternative trajectory, and (5) use Decision Support Techniques to help policymakers and decision makers shape an action agenda.

This chapter addresses the first three stages. Decision Support Techniques such as the Opportunities Incubator™ and the Impact Matrix that can be used to implement stage 5 are described in the next chapter . In a robust Foresight exercise, several weeks may pass between each of these stages to provide time to effectively capture, reflect on, and refine the results of each session.

Overview of Techniques

Key Drivers Generation™ should be used at the start of a Foresight exercise to assist in the creation of key drivers. These key drivers should be mutually exclusive, fundamental to the issue or problem under study, and usually not obvious to the uninformed.

Key Uncertainties Finder™ should also be used at the start of a Foresight analysis exercise to assist in the creation of a list of key drivers. When possible, the results of the Key Uncertainties Finder™ process should be melded with the drivers generated by Key Drivers Generation™ to create a more robust and cross-checked list of key drivers.

Reversing Assumptions is a simple technique. The process is to assume that a key assumption is no longer valid and then explore the implications of this change by generating a new, alternative scenario.

Simple Scenarios is a quick and easy way for an individual analyst or a small group of analysts to generate multiple scenarios or trajectories. It starts with the current analytic line and then explores other alternatives, often employing the Cluster Brainstorming technique.

Cone of Plausibility works well with a small group of experts who define a set of assumptions and key drivers, establish a baseline scenario, and then modify the assumptions and drivers to create plausible alternative scenarios and wild cards.

Alternative Futures Analysis is a systematic and imaginative procedure that engages a group of experts in using a 2-×-2 matrix defined by two key drivers to generate a set of mutually exclusive scenarios. The technique often includes academics and decision makers and requires the support of a trained facilitator.

Multiple Scenarios Generation can handle a much larger number of scenarios than Alternative Futures Analysis. It also requires a facilitator, but the use of this technique can greatly reduce the chance that events could play out in a way that was not foreseen as a possibility.

Morphological Analysis is useful for dealing with complex, nonquantifiable problems for which little data are available and the chances for surprise are significant. It is a generic method for systematically identifying and considering all possible relationships in a multidimensional, highly complex, usually nonquantifiable problem space. Users need training and practice in this method, and a facilitator experienced in Morphological Analysis may be necessary.

Counterfactual Reasoning considers what might happen if an alternative possibility were to occur rather than attempting to determine if the lead scenario itself is probable. It is designed to answer the question "How could things have been different in the past and what does that tell us about what to expect in the future?" Use of an experienced facilitator is also highly recommended.

Analysis by Contrasting Narratives is a method for analyzing complex problems by identifying a set of narratives associated with entities involved in the problem. 5 This includes the strategic narrative of the primary client of the analysis, the adversary, and a third party. The process involves having analysts and working-level decision makers collaborate to further their understanding of a problem.

Several techniques that can be used to generate scenarios also perform other functions. They are listed below and are described in other chapters:

Simple Brainstorming is a simple and well-established mechanism described in chapter 6 to stimulate creative thinking about alternative ways the future might unfold. The brainstorming session should be a structured process that follows specific rules. 6 A downside risk for using brainstorming to generate scenarios is that there is no guarantee that the scenarios generated are mutually exclusive. The tendency is to draw heavily from past experiences and similar situations, thus falling victim to the Availability Heuristic. Cluster Brainstorming is a silent brainstorming technique described in chapter 6 that can be used to generate scenarios. Participants generate ideas using self-stick notes that are arrayed in clusters, with each cluster suggesting a different scenario. What If? Analysis (also referred to as Backwards Thinking) is scenarios analysis in reverse. Participants posit an outcome and then develop scenarios to explain what had to occur for that outcome to have happened. It has also been categorized as a Reframing Technique and is described in chapter 8 . Foresight Quadrant Crunching™ was developed in 2013 by Randolph Pherson as a variation on Multiple Scenarios Generation and the Key Assumptions Check. It adopts a different approach to generating scenarios by Reversing Assumptions, and it is described along with its companion technique, Classic Quadrant Crunching™, in chapter 8 .

Indicators are used in Foresight analysis to provide early warning of some future event. They are often paired with scenarios to identify which of several possible scenarios is developing. They also are useful in measuring change toward an undesirable condition, such as political instability, or a desirable condition, such as economic reform. Analysts can use a variety of structured techniques to generate indicators, which should be validated using the five characteristics of a good indicator. Indicators Evaluation is a process that helps analysts assess the diagnostic power of an indicator.

9.1 Key Drivers Generation™

Key Drivers Generation™ uses the Cluster Brainstorming technique to generate a list of candidate key drivers needed to conduct a Foresight exercise.

When to Use It

Key Drivers Generation™ should be used at the start of a Foresight exercise to assist in the creation of key drivers. A key driver is defined as a basic force or factor, such as economic growth, popular support, conflict versus cooperation, or globalization, that affects behavior, performance, or strategy now or in the future. Items on the list of key drivers should be M utually E xclusive and C omprehensively E xhaustive (MECE). A robust set of key drivers should be fundamental to the issue or problem; the list often is not obvious to the uninformed.

Value Added

Key Drivers Generation™ is one of two techniques that have proved helpful in developing rigorous lists of key drivers. The other technique is the Key Uncertainties Finder™, which adapts elements of the Key Assumptions Check. Both techniques are particularly effective in countering the impact of the Anchoring Effect, Availability Heuristic, and Hindsight Bias. They also help mitigate the influence of intuitive traps such as Assuming Inevitability, overrating the role of internal determinants of behavior and underestimating the importance of situational factors (Overrating Behavioral Factors), and failing to accurately assess the likelihood of an event when faced with statistical facts and ignoring prior probabilities or base rates (Ignoring Base Rate Probabilities).

The Method

Key Drivers Generation™ follows specific rules and procedures to stimulate new ideas and concepts, emphasizing the use of silence and "kinetic brainstorming" with self-stick notes.

Stage I: Cluster Brainstorming Exercise (see more detailed instructions in chapter 6 )

Gather a small group of individuals who are working the issue along with a few "outsiders" who bring an independent perspective. Pass out self-stick notes and marker pens. Formulate the question and write it on a whiteboard or easel. A Key Drivers Generation™ focal question usually begins with "What are all the (things/forces and factors/circumstances) that would help explain . . .?" Ask the participants to write down their responses on self-stick notes. The facilitator collects them and reads the responses out loud. Only the facilitator speaks during this initial information-gathering stage of the exercise. The facilitator sticks the notes on the wall or whiteboard. As the facilitator calls out the responses, participants are urged to build on one another's ideas. After several pauses in idea generation, facilitators ask three to five participants to arrange the self-stick notes into affinity groups (basically grouping the ideas by like concept). Group members do not talk while doing this. If the topic is sufficiently complex, ask a second small group to rearrange the notes into a more coherent pattern. They cannot speak. This group—or a third group—then picks a word that best describes each grouping. This group can discuss how the self-stick notes were arranged and what would constitute the best label to assign to each affinity group. Participants then discuss which affinity groups are the best candidates for conversion to key drivers. Create a list of four to six candidate drivers.

Stage II: Find the Key Drivers

Identify which affinity groups represent or suggest a critical variable—something that is certain to influence how the situation under consideration would evolve over time. Make a list of four to six critical variables that would best serve as key drivers to use in conducting a Foresight analysis. If the group has also conducted a Key Uncertainties Finder™ exercise, examine both sets of key drivers and meld them into a single list of four or five drivers. Determine if the final list of key drivers meets the following requirements:

Mutually exclusive—items do not overlap or are not variants of the same issue. Cover most, if not all, of the STEMPLES+ criteria ( S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity, plus other factors such as Demographic, Religious, or Psychological). Revise the list as appropriate and add a new driver if a major dimension of the problem is not covered by the list of drivers.

9.2 Key Uncertainties Finder™

The Key Uncertainties Finder™ transforms the results of a Key Assumptions Check exercise into a list of candidate key drivers needed to conduct a Foresight exercise.

When to Use It

The Key Uncertainties Finder™ should be used at the start of a Foresight exercise to assist in the creation of a list of key drivers. In the business world, a key driver is defined as a basic force or factor affecting performance. The definition used in intelligence analysis is broader: basic forces and factors (economic growth, popular support, conflict versus cooperation, globalization) that affect behavior, performance, or strategy now or in the future. Key drivers are not nations, regions, or labels, such as "Russia," "cyber," or "increased military spending." When compiling a list of key drivers, the list should reflect the following characteristics:

Mutually Exclusive. Each key driver does not share the same basic dynamic as another driver. Fundamental. Each key driver affects performance or behavior or strategy. Nonobvious. At least one listed key driver illustrates a dynamic that is not immediately obvious.

Value Added

The Key Uncertainties Finder™ adapts elements of the Key Assumptions Check to generate a list of key drivers needed in a Foresight analysis. It is one of two techniques that have proved helpful in developing rigorous lists of key drivers for generating alternative scenarios. The other technique is Key Drivers Generation™, which builds on Cluster Brainstorming.

When conducting a Key Assumptions Check, some of the unsupported assumptions often turn out to be key uncertainties—things we initially thought to be true but were not when critically examined. In most cases, these key uncertainties can also be described as critical variables in determining how a situation might evolve or what trajectory evolves over time.

The Method

Stage I: Conduct a Key Assumptions Check Exercise (see more detailed instructions in chapter 7 )

Gather a small group of individuals who are working the issue along with a small number of "outsiders" who can come to the table with an independent perspective. Review the definition of a key assumption: a supposition of something as true for another condition or development to be true. It can also be a fact or statement that analysts tend to take for granted. On a whiteboard or an easel, list all the key assumptions that participants can generate about the topic. After developing a complete list, go back and critically examine each assumption.

Stage II: Find the Key Uncertainties

Identify the unsupported assumptions on the list; ask if they can be characterized as key uncertainties. Review the key uncertainties and ask if they could also be described as critical variables. A critical variable should have specific end points that bound the phenomenon along a continuous spectrum.

Stage III: Convert the Key Uncertainties into Key Drivers

Make a list of the four to six key uncertainties that would best serve as key drivers used in a Foresight exercise. If the group has also conducted a Key Drivers Generation™ exercise, compare both sets of key drivers and meld them into a single list of four to five drivers. Determine if the final list of key drivers meets the following requirements:

Mutually exclusive Cover most, if not all, of the STEMPLES+ criteria ( S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity, plus other factors such as Demographic, Religious, or Psychological) Revise the list as appropriate and add a new driver if a major dimension of the problem is not covered by the list of drivers.

9.3 Reversing Assumptions

Reversing Assumptions challenges established mindsets by reframing key elements of the problem. The technique involves identifying a key assumption, assuming the reverse is true, and assessing how the overall assessment would change if the key assumption were not true.

When to Use It

Reversing Assumptions is a simple but highly effective technique analysts and decision makers can use to explore the significance of key assumptions and generate alternative scenarios. Individuals or a group can use the technique without a facilitator. The technique usually is employed at the start of a project but can prove just as useful for testing working hypotheses and analytic judgments throughout the production process.

The Method

The method is straightforward:

Make a list of key assumptions. Identify one or more solid assumptions that underpin the analysis. Assume that—for whatever reason—the assumption is incorrect, and the contrary assumption has turned out to be true. Ask how reversing that key assumption would change the expected outcome. If the impact would be significant, ask if a credible case—no matter how unlikely—could be made that the selected key assumption could turn out to be untrue. Articulate the circumstances under which this could happen. Convert the case into an alternative scenario.

The process can be repeated for several key assumptions, generating a set of plausible alternative scenarios.

9.4 Simple Scenarios

The Simple Scenarios technique is a brainstorming process designed to generate multiple scenarios by manipulating the strengths of a set of key drivers.

When to Use It

Simple Scenarios is a relatively straightforward technique. An analyst working alone can use this technique as well as a group or a team. There is no need for a coach or a facilitator to conduct the process or exercise but having one available enriches the outcome. The lack of structure in the brainstorming process does not guarantee that all the scenarios generated are mutually exclusive, so the results may not be optimal. Participants also may fall into the trap of drawing too heavily from past experiences and similar situations.

The Method

Here are the steps for using this technique:

Clearly define the focal issue and the specific goals of the futures exercise. Make a list of forces, factors, and events that are likely to influence the future using Simple Brainstorming or Cluster Brainstorming techniques. Organize the forces, factors, and events related to one another into five to ten affinity groups that are the likely driving forces in determining how the focal issue will evolve. Label each of these drivers and write a brief description of each. For example, analysts used the technique to forecast the future of the fictional country of Caldonia, which was facing a chronic insurgency and a growing threat from narcotics traffickers. Six drivers were identified using Cluster Brainstorming. Generate a matrix, as shown in Figure 9.4 , with a list of drivers down the left side. The columns of the matrix are used to describe scenarios. Each scenario is assigned a value for each driver. The values are strong or positive (+), weak or negative (–), and blank if neutral or no change. In Figure 9.4 , participants identified the following six key drivers and then rated them.

Government effectiveness. To what extent does the government exert control over all populated regions of the country and effectively deliver services? Economy. Does the economy sustain positive growth? Civil society. Can nongovernmental and local institutions provide appropriate services and security to the population? Insurgency. Does the insurgency pose a viable threat to the government? Is it able to extend its dominion over greater portions of the country? Drug trade. Is there a robust drug-trafficking economy? Foreign influence. Do foreign governments, international financial organizations, or nongovernmental organizations provide military or economic assistance to the government?

Figure 9.4 Simple Scenarios Source: Pherson Associates, LLC, 2019. Generate at least four different scenarios—a best case, worst case, mainline, and at least one other by assigning different values (+, 0, –) to each driver. In this case, four scenarios were created by varying the impact of six drivers: "Fragmentation" represents the downside scenario, "Descent into Order" the mainline assessment, "An Imperfect Peace" a new opportunity, and "Pockets of Civility" focuses on the strength of civil society. Reconsider the list of drivers. Is there a better way to conceptualize and describe the drivers? Are there important forces that have not been included? Look across the matrix to see the extent to which each driver discriminates among the scenarios. If a driver has the same value across all scenarios, it is not discriminating and should be deleted. Ask if the set of selected scenarios is complete. To stimulate thinking about other possible scenarios, consider the key assumptions made in deciding on the most likely scenario. What if some of these assumptions turn out to be invalid? If they are invalid, how might that affect the outcome, and are such outcomes included in the available set of scenarios? For each scenario, write a one-page story to describe what that future looks like and/or how it might come about. The story should illustrate the interplay of the drivers. For each scenario, describe the implications for the decision maker. Generate and validate a list of indicators, or "observables," for each scenario that would aid in discovering that events are starting to play out in a way envisioned by that scenario. Monitor the list of indicators on a regular basis. Report periodically on which scenario appears to be emerging and why.

Origins of This Technique

Pherson Associates, LLC, developed the model of Simple Scenarios in the late 1990s to support scenarios work done for the U.S. State Department and the U.S. Intelligence Community.

9.5 Cone of Plausibility

Cone of Plausibility is a structured process using key drivers and assumptions to generate a range of plausible alternative scenarios that help analysts and decision makers imagine various futures and their effects. The value of Cone of Plausibility lies in showcasing the drivers that are shaping current and future events.

When to Use It

The Cone of Plausibility can be used to explore how well or how poorly events might unfold, thereby bounding the range of possibilities for the decision maker. 7 It helps the decision maker focus on scenarios that are plausible—and fall inside the cone—and implausible—and fall outside the cone. Dramatic, but unlikely, or "possible" scenarios that fall outside the cone can be displayed separately in text boxes alongside the narrative. The technique also is highly effective for strategic warning.

The Method

The steps in the technique are as follows (see Figure 9.5 ):

Convene a small group of experts with some diversity of background. Define the issue at hand and set the time frame of the assessment. A common question to ask is, "What will X (e.g., a country, regime, issue) look like in Y (e.g., two months, five years, twenty years)?" Identify the drivers that are key factors or forces and thus most useful in defining the issue and shaping the current environment. Analysts in various fields have created mnemonics to guide their analysis of key drivers. One of the most common is PEST, which signifies P olitical, E conomic, S ocial, and T echnological variables. Other analysts have combined PEST with legal, military, environmental, psychological, or demographic factors to form abbreviations such as STEEP, STEEPLE, or PESTLE. 8 We recommend using STEMPLES+ ( S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity, plus other factors such as Demographic, Religious, or Psychological). Write the drivers as neutral statements that should be valid throughout the period of the assessment. For example, write "the economy," not "declining economic growth." Be sure you are listing true drivers and not just describing important players or factors relevant to the situation. The technique works best when four to six drivers are generated. Make assumptions about how the drivers are most likely to play out over the time frame of the assessment. Be as specific as possible; for example, say, "The economy will grow 2–4 percent annually over the next five years," not simply that "The economy will improve." Generate only one assumption per driver.

Description Figure 9.5 Cone of Plausibility Generate a baseline scenario from the list of key drivers and key assumptions. This is often a projection from the current situation forward, adjusted by the assumptions you are making about future behavior. The scenario assumes that the drivers and their descriptions will remain valid throughout the period. Write the scenario as a future that has come to pass and describe how it came about. Construct one to three alternative scenarios by changing an assumption or several of the assumptions that you included in your initial list. Often it is best to start by looking at those assumptions that appear least likely to remain true. Consider the impact that change is likely to have on the baseline scenario and describe this new end point and how it came about. Also consider what impact changing one assumption would have on the other assumptions on the list. We recommend making at least one of these alternative scenarios an opportunities scenario, illustrating how a positive outcome that is significantly better than the current situation could plausibly be achieved. Often it is also desirable to develop a scenario that captures the full extent of the downside risk. Generate a possible wild-card scenario by radically changing the assumption that you judge as the least likely to change. This should produce a High Impact/Low Probability scenario (see chapter 8 ) that may not have been considered otherwise.

Origins of This Technique

Cone of Plausibility is a well-established technique used by intelligence analysts in several countries. It is a favorite of analysts working in Canada and the United Kingdom. For additional insight and visuals on the Cone of Plausibility, visit https://prescient2050.com/the-cone-of-plausibility-can-assist-your-strategic-planning-process/ .

9.6 Alternative Futures Analysis

Alternative Futures Analysis is a systematic method for identifying alternative trajectories by developing plausible but mind-stretching "stories" based on critical uncertainties to inform and illuminate decisions, plans, and actions today.

When to Use It

Alternative Futures Analysis and Multiple Scenarios Generation (the next technique to be described) differ from the previously described techniques in that they are usually larger projects that rely on a group of experts, often including decision makers, academics, and other outside experts. They use a more systematic process and usually require the assistance of a knowledgeable facilitator.

Alternative Futures Analysis is limited in that participants define a future world based on only two driving forces. Each driving force is a spectrum with two extremes, and these drivers combine to make four possible scenarios. Multiple Scenarios Generation has no such limitation other than the practical limitations of time and complexity.

A team of experts can spend hours or days using the technique to organize, brainstorm, and develop multiple futures. A large, multi-day effort often demands the special skills of trained facilitators knowledgeable in the mechanics of Alternative Futures Analysis. The technique has proven highly effective in helping decision makers and policymakers contemplate multiple futures, challenge their assumptions, and anticipate surprise developments by identifying "unknown unknowns." "Unknown unknowns" are best defined as those factors, forces, or players that one did not realize were important or influential before commencing the exercise.

The Method

The steps in the Alternative Futures Analysis process are as follows:

Clearly define the focal issue and the specific goals of the futures exercise. Brainstorm to identify the key forces, factors, or events most likely to influence how the issue will develop over a specified time period. If possible, group these various forces, factors, or events to form two critical drivers that are expected to determine the future outcome. In the example on the future of Cuba ( Figure 9.6 ), the two key drivers are "Effectiveness of Government" and "Strength of Civil Society." If there are more than two critical drivers, do not use this technique—use the Multiple Scenarios Generation technique, which can handle a larger number of drivers. As shown in the Cuba example, define the two ends of the spectrum for each driver. Draw a 2-×-2 matrix. Label the two ends of the spectrum for each driver. Note that the square is now divided into four quadrants. Each quadrant represents a scenario generated by a combination of the two drivers. Now give a name to each scenario and write it in the relevant quadrant. Generate a narrative story of how each hypothetical scenario might come to pass. Include a hypothetical chronology of key dates and events for each scenario. Describe the implications of each scenario, should it develop.

Description Figure 9.6 Alternative Futures Analysis: Cuba Source: Pherson Associates, LLC, 2019. Generate and validate a list of indicators, or "observables," for each scenario that would help determine whether events are starting to play out in a way envisioned by that scenario. Monitor the list of indicators on a regular basis. Report periodically on which scenario appears to be emerging and why.

Origins of the Technique

A team at the Royal Dutch Shell Company developed a robust alternative futures methodology in the 1980s. In The Art of the Long View , Peter Schwartz provides a detailed description of the process and the power of the technique. Use of the technique usually requires the assistance of a team of knowledgeable facilitators.

9.7 Multiple Scenarios Generation

Multiple Scenarios Generation is a systematic method for brainstorming multiple explanations of how a situation may develop when considerable uncertainty and several underlying key drivers are present.

When to Use It

Multiple Scenarios Generation is a useful technique for exploring the many ways a situation might evolve, anticipating surprise developments, and generating field requirements when dealing with little concrete information and/or a highly ambiguous or uncertain threat. In counterterrorism, analysts can use it to identify new vulnerabilities, and to assess, anticipate, and prioritize possible attacks and attack methods. It also can be an investigative tool, providing an ideal framework for developing indicators and formulating requirements for field collectors and researchers.

Value Added

The Multiple Scenarios Generation process helps analysts and decision makers expand their imagination and avoid surprise by generating large numbers of potential scenarios. This sensitizes them to possible new outcomes and makes them more likely to consider outlying data that suggest events are unfolding in a way not previously imagined. The challenge for the analyst is to identify just three or four major themes that emerge from the process. Thus, the true value of the technique is to provide a palette of ideas from which analysts can develop attention-deserving themes.

The Method

Multiple Scenarios Generation applies the collective knowledge and imagination of a group of experts to identify a set of key drivers (forces, factors, or events) that are likely to shape an issue and arrays them in different paired combinations to generate robust sets of potential scenarios.

Multiple Scenarios Generation is like Alternative Futures Analysis (described above) except that with this technique, you are not limited to two critical drivers that generate four scenarios. By using multiple 2-×-2 matrices pairing every possible combination of multiple drivers, you can create many possible scenarios. Doing so helps ensure nothing has been overlooked. Once generated, the scenarios can be screened quickly without detailed analysis of each one. After becoming aware of the variety of possible scenarios, analysts are more likely to pay attention to outlying data that would suggest that events are playing out in a way not previously imagined.

Training and an experienced team of facilitators are needed to use this technique. Here are the basic steps:

Clearly define the focal issue and the specific goals of the futures exercise. Brainstorm to identify the key forces, factors, or events most likely to influence how the issue will develop over a specified time period—often five or ten years. Define the two ends of the spectrum for each driver. Pair the drivers in a series of 2-×-2 matrices. Develop a story or two for each quadrant of each 2-×-2 matrix. From all the scenarios generated, select those most deserving of attention because they illustrate compelling and challenging futures not yet under consideration. Develop and validate indicators for each scenario that could be tracked to determine which scenario is starting to develop. Report periodically on which scenario appears to be emerging and why.

The technique is illustrated by exploring the focal question, "What is the future of the insurgency in Iraq?" (See Figure 9.7a .) Here are the steps:

Convene a group of experts (including some creative thinkers who can challenge the group's mental model) to brainstorm the forces and factors that are likely to determine the future of the insurgency in Iraq. Select those factors or drivers whose outcome is the hardest to predict or for which analysts cannot confidently assess how the driver will influence future events. In the Iraq example, three drivers meet these criteria:

The role of neighboring states (e.g., Syria, Iran) The capability of Iraq's security services (military and police) The political environment in Iraq Define the ends of the spectrum for each driver. For example, the neighboring state could be stable and supportive at one end and unstable and disruptive at the other end of the spectrum. Pair the drivers in a series of 2-×-2 matrices, as shown in Figure 9.7a . Develop a story or a couple of stories describing how events might unfold for each quadrant of each 2-×-2 matrix. For example, in the 2-×-2 matrix defined by the role of neighboring states and the capability of Iraq's security forces, analysts would describe how the insurgency would function in each quadrant on the basis of the criteria defined at the far end of each spectrum. In the upper-left quadrant, the criteria would be stable and supportive neighboring states but ineffective internal security capabilities (see Figure 9.7b ). In this "world," one might imagine a regional defense umbrella that would help to secure the borders. Another possibility is that the neighboring states would have the Shiites and Kurds under control, with Sunnis, who continue to harass the Shia-led central government, as the only remaining insurgents.

Description Figure 9.7A Multiple Scenarios Generation: Future of the Iraq Insurgency

Description Figure 9.7B Future of the Iraq Insurgency: Using Spectrums to Define Potential Outcomes Review all the stories generated and select those most deserving of attention. For example, which scenario

presents the greatest challenges to Iraqi and U.S. decision makers? raises concerns that have not been anticipated? surfaces new dynamics that should be addressed? suggests new collection needs? Select a few scenarios that might be described as "wild cards" (High Impact/Low Probability developments) or "nightmare scenarios" (see Figure 9.7c ). Consider what decision makers might do to prevent bad scenarios from occurring or enable good scenarios to develop. Generate and validate a list of key indicators to help monitor which scenario story best describes how events are beginning to play out. Report periodically on which scenario appears to be emerging and why.

Origins of This Technique

Multiple Scenarios Generation is described in Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019). For information on other approaches to scenarios analysis, see Randolph H. Pherson, "Leveraging the Future with Foresight Analysis," The International Journal of Intelligence, Security, and Public Affairs (Fall 2018), and Andy Hines, "The Current State of Scenario Development: An Overview of Techniques," Foresight 9, no. 1 (March 2007). The Multiple Scenarios Generation illustrations are drawn from a report prepared by Alan Schwartz (PolicyFutures, LLC), "Scenarios for the Insurgency in Iraq," Special Report 174 (Washington, DC: United States Institute of Peace, October 2006).

Description Figure 9.7C Selecting Attention-Deserving and Nightmare Scenarios

9.8 Morphological Analysis

Morphological Analysis is a method for systematically structuring and examining all the possible relationships in a multidimensional, highly complex, usually nonquantifiable problem space. The basic idea is to identify a set of variables and then examine all possible combinations of these variables.

Morphological Analysis is a generic method used in a variety of disciplines. For intelligence analysis, it helps prevent surprise by generating many feasible outcomes for any complex situation. This exercise reduces the chance that events will play out in a way that the analyst has not previously imagined and considered. Specific applications of this method are Quadrant Crunching™ (described in chapter 8 ), Multiple Scenarios Generation (in this chapter), and Quadrant Hypothesis Generation ( chapter 7 ). This technique needs training and practice for its successful application, and a facilitator with experience in Morphological Analysis is highly desirable.

When to Use It

Morphological Analysis is most useful for dealing with complex, nonquantifiable problems for which little information is available and the chances for surprise are great. It can be used, for example, to identify possible variations of a threat, possible ways a crisis might occur between two countries, possible ways a set of driving forces might interact, or the full range of potential outcomes in any ambiguous situation. Morphological Analysis is generally used early in an analytic project, as it aims to identify all the possibilities, not to drill deeply into any specific possibility.

Morphological Analysis is typically used for looking ahead; it can also be used in an investigative context to identify the full set of possible explanations for some event.

Value Added

By generating a comprehensive list of possible outcomes, analysts are in a better position to identify and select those outcomes that seem most credible or that most deserve attention. This list helps analysts and decision makers focus on what actions need to be undertaken today to prepare for events that could occur in the future. Decision makers can then take the actions necessary to prevent or mitigate the effect of bad outcomes and help foster better outcomes. The technique can also sensitize analysts to High Impact/Low Probability developments, or "nightmare scenarios," which could have significant adverse implications for influencing policy or allocation of resources.

The product of Morphological Analysis is often a set of potential noteworthy scenarios, with indicators of each, plus the intelligence collection requirements or research directions for each scenario. Another benefit is that Morphological Analysis leaves a clear audit trail about how the judgments were reached.

The Method

Morphological Analysis works by applying two common principles of creativity techniques: decomposition and forced association. Start by defining a set of key parameters or dimensions of the problem; then break down each of those dimensions further into relevant forms or states or values that the dimension can assume—as in the example described later in this section. Two dimensions can form a matrix and three dimensions a cube. In more complicated cases, multiple linked matrices or cubes may be needed to break the problem down into all its parts.

The principle of forced association then requires that every element be paired with and considered in connection with every other element in the morphological space. How that is done depends upon the complexity of the case. In a simple case, each combination may be viewed as a potential scenario or problem solution and examined from the point of view of its possibility, practicability, effectiveness, or other criteria. In complex cases, there may be thousands of possible combinations; computer assistance is required to handle large numbers of combinations. With or without computer assistance, it is often possible to quickly eliminate a large proportion of the combinations as not physically possible, impracticable, or undeserving of attention. This narrowing-down process allows the analyst to concentrate only on those combinations that are within the realm of the possible and most worthy of attention.

Example

Decision makers ask analysts to assess how a terrorist attack on the water supply might unfold. In the absence of direct information about specific terrorist planning for such an attack, a group of analysts uses Cluster Brainstorming or Mind Mapping to identify the following key dimensions of the problem: attacker, type of attack, target, and intended impact. For each dimension, the analysts identify as many elements as possible. For example, the group could be an outsider, an insider, or a visitor to a facility; the location could be an attack on drinking water, wastewater, or storm sewer runoff. The analysts then array this data into a matrix, illustrated in Figure 9.8 , and begin to create as many permutations as possible using different combinations of the matrix boxes. These permutations allow the analysts to identify and consider multiple combinations for further exploration. One possible scenario is an outsider who carries out multiple attacks on a treatment plant to cause economic disruption. Another possible scenario is an insider who carries out a single attack on drinking water to terrorize the population.

Analysts interested in using a computerized version of Morphological Analysis should consult information produced by the Swedish Morphology Society ( www.swemorph.com ). Their website has detailed guidance and examples of the use of Morphological Analysis for futures research, disaster risk management, complex socio-technical problems, policy research, and other problems comparable to those faced by intelligence analysts.

Origins of This Technique

The current form of Morphology Analysis was developed by astronomer Fritz Zwicky and described in his book Discovery, Invention, Research through the Morphological Approach (Toronto: Macmillan, 1969). Basic information about this method is available from two well-known websites that provide information on creativity tools: http://creatingminds.org and www.mindtools.com . For more advanced information, see General Morphological Analysis: A General Method for Non-Quantified Modeling (1998); Wicked Problems: Structuring Social Messes with Morphological Analysis (2008); and Futures Studies Using Morphological Analysis (2009), all downloadable from the Swedish Morphology Society's website: http://www.swemorph.com . For further instruction on how to use Morphological Analysis, go to https://www.ideaconnection.com/thinking-methods/morphological-analysis-00026.html .

Description Figure 9.8 Morphological Analysis: Terrorist Attack Options Source: Pherson Associates, LLC, 2019.

9.9 Counterfactual Reasoning

Counterfactual Reasoning is the process of evaluating conditional claims about possible changes and their consequences. 9 The changes can be either alternative past possibilities that did not happen (but could have) or alternative future possibilities that are not expected to happen (but could). The technique considers what would or might happen if such changes (counter to the facts of what happened or counter to what is expected to happen) were to occur. But, it does not attempt to determine the extent to which the alternative possibility itself is probable.

When to Use It

Counterfactual Reasoning should be used when conducting a strategic assessment or supporting a strategic decision-making process. The purpose of the method is to help analysts recognize that any strategic analysis is grounded in a series of underlying claims about alternative possibilities, their consequences, and the relationships among them. The technique should be used when analysts need to answer basic questions such as

How could things have been different in the past and what does this tell us about what to do today? How could things be different (than they are expected to be) in the future and what can be done to facilitate good outcomes and mitigate the impact of bad outcomes?

The method also provides a robust and systematic framework for using other structured techniques such as What If? Analysis, High Impact/Low Probability Analysis, Red Hat Analysis, and many Foresight Techniques.

Value Added

The primary purpose of Counterfactual Reasoning is to ground the analytic foundation of a strategic assessment by considering alternative possibilities, their consequences, and the relationships among them. Counterfactual Reasoning is essential to analysis and strategy because all strategic assessment and/or decision making presupposes counterfactual claims. Every strategic question has embedded assumptions about the consequences of possible challenges the decision maker might face. These assumptions can be conceived of as counterfactuals of the form "If X were to occur, then Y would (or might) follow."

Counterfactual Reasoning provides analysts with a rigorous process:

Develop a detailed account of the causes, context, and consequences of a specific possible change or alternative. Integrate creative thinking into the analytic process while simultaneously guarding against speculation by employing a series of precise techniques. Open the analyst and decision maker up to a range of new possibilities to overcome deterministic biases such as Hindsight Bias and the practitioners' intuitive trap of Assuming Inevitability.

The Method

Counterfactual Reasoning explores a specific possible change in three progressive stages that ask the following:

Stage 1: "When and where might this change plausibly come about? " Stage 2: "When and where might this change cause broader uncertainties (and unexpected consequences)? " Stage 3: "When and where might this have long-term impact? "

If one conceives of the possible change as a narrative or story, then the stages correspond to developing the beginning, middle, and end of the story (see Figure 9.9 ). The first two stages can sometimes be counterintuitive and, as a result, they are often overlooked by analysts.

Description Figure 9.9 Three Stages of Counterfactual Reasoning

Stage One: "Convergent Scenario Development"— The Beginning and Causes of the Change

There is rarely just one way that a possible change can happen. Instead, typically many paths could lead to the change. Whenever analysts consider an "if . . . then" statement, they should avoid assuming that they already know how the possibility (i.e., the "if") would come to be. Instead, they should develop and assess multiple possible scenarios that start differently, but all "converge" on that possibility. The most plausible of these scenarios will be the analyst's chosen "back story" for the possibility: the most reasonable way that it could happen. It is what happens prior to the "if" in a standard statement: "If X were to occur, then Y would (or might) follow." It constitutes the first part of a counterfactual conditional.

For an alternative possible future change, this scenario begins at the present and charts a precise, postulated future sequence of events that ends when the change happens or "If X were to occur." For an alternative possible past change, the scenario begins at the first place at which history is imagined to be different than it was and then charts a precise sequence of events (which also change history) that ends at the moment when the possibility (X) fully comes to be.

Obviously, the ideal scenario back story for the possible change would be the most plausible one. To develop a plausible account, analysts should first identify the reasons why the change itself is (or was) unlikely. Then, they should identify the reasons why the change is (or was) still possible nonetheless. Using these reasons, analysts should develop possible "triggering events" that could weaken the reasons why the change is unlikely and/or strengthen the reasons why the change is still possible. The resulting scenarios can be a single such event, or a series of distinct events that lead stepwise or converge to produce the change. Usually, the less time covered by the scenario the better. The more recent the history is to a scenario coming to be, the more likely it would merit consideration by the decision maker.

Three key characteristics of good convergent scenarios are that they (1) are shorter in temporal length, (2) have triggering events that are themselves as plausible as possible, and (3) require a fewer number of triggering events. Once constructed, the convergent scenarios should be assessed relative to each other and rated in terms of plausibility by applying the three criteria. The chosen scenario represents the official assessed "back story" of the possible change as the analysts consider it further.

Stage Two: "Ripple Effect Analysis"— The Middle and (Broader) Context of the Change

When analysts imagine a possible change to what happened in the past or to what is expected to happen in the future, it is easy for them to assume that its effects will be narrow. But, change often extends well beyond the reach of what is anticipated, especially when other actors start to respond to the initial change and thereby create a broader "ripple effect" of unintended consequences. In many narratives, it is in the "middle" of the story that everything gets more complicated as the actors begin to experience the broader and deeper consequences of what happened at the beginning. Analysts have to explore these possible consequences before they can develop a viable account of the longer-term impact of their imagined change. This is what happens between the "if" and the "then" in a standard statement: "If X were to occur, then Y would (or might) follow."

To search for possible "ripple effects," analysts should first locate several major actors, causal forces, or trends that are not major players or factors in the scenario they developed for Stage 1 but are likely to interact with the change after it begins to have impact. Second, the analysts should identify what is currently expected of those major actors (or what they actually did in the past). Third, the analysts should consider how those actors might act differently assuming all the changes imagined in Stage 1:

How do the events of that scenario create a "new world" for these actors? How might these actors respond in ways that are different from what analysts currently expect them to do (or what they did in the past)? In what ways can the analysts no longer assume these actors will maintain the "status quo" given the imagined changes?

The most significant possible alternative ways these actors might respond represent "new uncertainties" or possible "unintended consequences" that should be taken seriously. Note that analysts are not (at this point) projecting what these actors would do but are only identifying the significant ways in which they might plausibly act differently. They are locating possible "ripple effects"—what analysts can no longer assume will still happen.

Stage Three: "Divergent Scenario Development"—The End and Consequences of the Change

The task for the analyst in Stage 3 is to examine all possible consequences of the change's back story (Stage 1) and the further changes that might follow it (Stage 2). A key tenet of the methodology is that the evaluation of the longer-term consequences of a change (what happens after the "then") should be done only after considering both how the change would come to be (what happens before the "if"), and how it might generate new uncertainties (what happens between the "if" and the "then").

To identify the range of outcomes that follow (or "diverge") from a possible change, analysts should look for possible interactions between the events of the convergent scenario (Stage 1) and the possible new uncertainties generated by it (Stage 2). Divergent scenarios are selected based on what would be useful for a decision maker to consider when conducting a full-fledged strategic assessment.

To this end, it is important to know what sorts of consequences the decision maker believes are worth thinking about, what decisions the outcomes are related to, and the nature of the connection between the decision and the consequences. The analyst should distinguish between outcomes that occur in one possible scenario from those that occur across a wide range of possible scenarios. The former are consequences that "might plausibly follow" and the latter are consequences that "would probably follow." Note that it is important for analysts to always put the conclusions of Counterfactual Reasoning in the form of a conditional claim such as "If X were to occur, then Y would (or might) follow," and never simply as "Y would (or might) follow."

Relationship to Other Techniques

Counterfactual Reasoning is implicit in most strategic assessments because any proposed scenario or response to a situation presumes that certain things would or might have to occur for that scenario to play out. Several Structured Analytic Techniques mirror some of the basic processes of Counterfactual Reasoning. The Key Assumptions Check, for example, employs some of the principles of Counterfactual Reasoning in that it prompts analysts to challenge their underlying assumptions about what might have caused something to occur in the past or would make it occur in the future.

What If? Analysis focuses its attention mostly on the same subject as the first stage of Counterfactual Reasoning, emphasizing the need to develop a "back story" to explain how a posited outcome emerged. An analyst could (theoretically) use What If? Analysis to do the first stage of Counterfactual Reasoning, or vice versa. Red Hat Analysis also generates a specific back story by simulating how an adversary would deal with a particular situation. Counterfactual Reasoning, however, goes further by exploring the implications or consequences of that scenario for the decision maker.

High Impact/Low Probability Analysis relates more to the third stage of Counterfactual Reasoning by focusing on the consequences of a specific—but low-probability—scenario. Similarly, the function of most Foresight Techniques, such as Multiple Scenarios Generation and the Cone of Plausibility, is to identify a set of plausible futures and their consequences by applying a systematic process to generate a set of comprehensive and mutually exclusive alternative scenarios. An analyst could (theoretically) use one of these methods to do the third stage of Counterfactual Reasoning (as long as they integrate the outcomes of Stages 1 and 2), or vice versa.

Origins of This Technique

The origin of counterfactual thinking has philosophical roots and can be traced back to early philosophers such as Aristotle and Plato. In the seventeenth century, the German philosopher Gottfried Wilhelm Leibniz argued that there could be an infinite number of alternate worlds, so long as they were not in conflict with laws of logic. 10 More recently, counterfactual thinking has gained interest from a psychological perspective. Daniel Kahneman and Amos Tversky pioneered the study of counterfactual thought, showing that people tend to think "if only" more often about exceptional events than about normal events. 11 Noel Hendrickson has pioneered the application of counterfactual thinking to intelligence analysis and teaches the technique as one of his four core courses in advanced reasoning methods for intelligence analysts at James Madison University. 12

9.10 Analysis by Contrasting Narratives

Analysis by Contrasting Narratives is a recently developed methodology for analyzing complex problems by identifying the narratives associated with entities involved in the problem. 13 This includes the strategic narrative associated with the primary client of the analysis, be it an intelligence consumer or a corporate executive. The process involves having analysts and decision makers work collaboratively to further their understanding of a problem. This melding of the expertise of both analysts and decision makers is also an effective practice in Multiple Scenarios Generation workshops and other Foresight exercises.

When to Use It

Analysis by Contrasting Narratives seeks to answer strategic-level questions such as, "Who has what power, on what level, in what setting, over what audience, to attribute what meaning of security, in what form of discourse, which supports what interests, and motivates what action, by whom?" The technique helps analysts understand how a decision maker's perception of a threat differs from that of an adversary or from that of other geopolitical state or non-state actors. It also focuses attention on the identities of an adversary, whether they may be changing over time, and to what extent the decision makers' own statements and actions could have undercut their own policy objectives.

The technique is most typically used on complex intelligence problems characterized by sets of interacting events, themes, or entities that are evolving in a dynamic social context. It is useful in analyzing trends in international terrorism, weapons proliferation, and cyber security, and complex counterintelligence, political instability, and Digital Disinformation issues. The narratives can be considered as separate case studies focused on distinct entities, often at different levels (individual, group, or institution).

Value Added

Analysis by Contrasting Narratives engages analysts, working-level policymakers and decision makers, and trusted external subject matter experts in a joint effort to study a topic and develop working narratives relating to a common issue. The narratives reflect the perspectives of the key decision maker(s), the adversary or competitor, and other stakeholders or entities associated with the issue.

The method requires the development and interpretation of distinct narratives by those who can remain critically distant and objective while being sufficiently informed on the topic. It can broaden the analytic spectrum at an initial stage to prompt further analysis and drive additional collection efforts.

A key benefit of the technique is that it increases the diversity of perspectives an analyst can bring to understanding the root causes of an event and the circumstances surrounding it. By highlighting the significance of differing narratives, analysts can consider multiple interpretations as they reframe the intelligence issue or analytic problem. As the developer of the methodology explains, "Rather than telling truth to power, this thesis ‘Analysis by Contrasting Narratives' argues that intelligence analysis should strive to consider the most relevant truths to serve power." 14

The method recognizes that the world has become much more complex. As analysis expands beyond traditional military, political, and economic issues to environmental, social, technical, and cyber domains, there is growing need for analytic techniques that involve more adaptive sense making, flexible organizational structures, direct engagement with the decision maker, and liaising with nontraditional intelligence and academic partners.

Analysis by Contrasting Narratives differs from many traditional forms of intelligence analysis in that it seeks to integrate the perceptions of the policymaker or decision maker into the analysis of the behavior of adversaries and other hostile entities. By engaging the decision maker in the analytic process, the method can also reflect and interactively assess the impact of a decision maker's actions on the problem at hand.

The Method

The methodology consists of two phases: (1) basic analytic narratives are identified, and (2) the narratives are analyzed to assess their development, looking for effects of statements and actions across multiple social domains. A central focus lies with articulations of difference, expressing (or critiquing) an "us-against-them" logic to enable or legitimize particular security policies or decisions.

Phase I: Developing Contrasting Narratives

Create a basic timeline that defines key events to be studied in all the narratives. Develop at least three narratives reflecting the perspective of (1) those who have power or influence over how the issue plays out—a macro narrative—and (2) entities that can reflect critically on actions taken by key players but who lack power to act to influence the situation—a micro narrative. Primary candidates for macro narratives are the adversary or competitor in the scenario and the decision maker and his or her coterie who are the clients for the study. For each narrative,

Construct a timeline, based on key words, of all significant events. Select texts (articles, public statements) produced by the central actors that are related to the major events in the timeline. For institutional actors, the texts usually are generated by the leadership. In a personal narrative, the texts would be produced by that person. It is possible for new key events to be added to the basic timeline as the analysis progresses. Analyze the meaning constructed in texts regarding threats and security through the type of grammar (e.g., declaring), lexicon (e.g., metaphors, synonyms, stereotypes), and visual aspects of signs and images used. Examine the settings, involving ways of communicating (to various audiences), social roles, identities, and power relations. Consider the background context, including cultural, religious, and socio-political factors. For macro narratives, focus on threat articulations in and through statements and actions. For micro narratives, identify commentary on these threat articulations to reveal internal tensions and inconsistencies.

Phase II: Comparing and Contrasting the Narratives

Analyze and link the macro narratives. Ask, "To what extent are statements and actions in one narrative reflected in another narrative?" Use the micro narratives to enhance, contrast, or highlight additional events and factors of influence. Explore:

What facilitating conditions and drivers, or factors and events, account for the overall transformation of narratives from beginning to end? How do these elements relate? How do the beginning points of the analysis for each narrative differ? How do the analytic end states for each narrative differ? How do statements and actions resonate with various audiences? Is an audience formal (granting executive powers) or moral (legitimizing statements and actions)? Are the audiences institutionalized, or forming in and through the narrative? Is their response hostile or supportive, sympathetic, and understanding? Is the impact on the audience fluctuating or gradual? What key factors and events, such as material and ideational circumstances, intentions, statements, and actions, add or diminish momentum of threat articulations? Overall, explain how courses of action are shaped and produce multiple effects within and across social domains. For example, ask,

Does ideology fuel the process of identification of others and the self? Are conflicts between entities a reflection of inherent structural factors or perceptions of a physical threat to self? Are people being portrayed in negative ways to suit ideological, political, religious, or economic norms?

Analysis by Contrasting Narratives can be graphically displayed with diagrams, creating one for each macro narrative. Key events for a narrative are listed vertically in chronological order. On the left, factors are depicted that add momentum to these events and the overall security dynamic in the narrative. Factors removing momentum are listed on the right. Each narrative has its own color that is also used to highlight related factors in other narratives, visualizing the extent to which narratives influence each other.

Relationship to Other Techniques

Analysis by Contrasting Narratives incorporates elements of Reframing Techniques such as Red Hat Analysis, Premortem Analysis, and Structured Self-Critique and several challenge approaches including Team A/Team B Analysis and Devil's Advocacy.

The method is like Red Hat Analysis in that both techniques aim to widen cultural empathy and understanding of a problem. Red Hat Analysis differs from Analysis by Contrasting Narratives, however, in that it is more likely to assume that the opposing sides view the conflict in much the same way. Devil's Advocacy involves having someone who did not participate in the analysis challenge the analytic judgments and the process that produced them whereas Analysis by Contrasting Narratives is a more collaborative process. Rather than posing a narrative and a counter-narrative, Analysis by Contrasting Narratives seeks to understand narratives associated with a multitude of actors. The method differs from challenge techniques in that it engages the decision maker as a participant in the analytic process rather than presenting the decision maker with several options from which to choose.

Origins of This Technique

The Analysis by Contrasting Narratives methodology was developed by Peter de Werd, an assistant professor in intelligence and security at the Netherlands Defence Academy. His PhD dissertation, "Critical Intelligence: Analysis by Contrasting Narratives, Identifying and Analyzing the Most Relevant Truths," provides a detailed description of both the theory underlying this new approach to analysis and the method itself. 15

9.11 Indicators Generation, Validation, and Evaluation

Indicators are a preestablished set of observable phenomena that are periodically reviewed to track events, spot emerging trends, validate a hypothesis, and warn of unanticipated change. An indicator list is a preestablished set of observable or potentially observable actions, conditions, facts, or events whose simultaneous occurrence would argue strongly that a phenomenon is present or is highly likely to occur. Indicators can be monitored to obtain tactical, operational, or strategic warnings of some future development that, if it were to occur, would have a major impact.

The central mission of intelligence analysis is to warn U.S. officials about dangers to national security interests and to alert them to perceived openings to advance U.S. policy objectives. Thus the bulk of analysts' written and oral deliverables points directly or indirectly to the existence, characteristics, and implications of threats to and opportunities for U.S. national security.

—Jack Davis, "Strategic Warning: If Surprise Is Inevitable, What Role for Analysis?" (January 2003)

The identification and monitoring of indicators are fundamental tasks of analysis, as they are the principal means of avoiding surprise. When used in intelligence analysis, they usually are forward looking and are often described as estimative, anticipatory, or foresight indicators. In the law enforcement community, indicators are more often used to assess whether a target's activities or behavior are consistent with an established pattern. These indicators look backward and are often described as descriptive or diagnostic indicators.

When to Use It

Indicators provide an objective baseline for tracking events, instilling rigor into the analytic process, and enhancing the credibility of the final product. The indicator list can become the basis for investigating a situation or directing collection efforts and routing relevant information to all interested parties. In the private sector, indicators can track whether a new business strategy is working or whether a low-probability scenario is developing that offers new commercial opportunities.

Indicator lists can serve as a baseline for generating collection requirements or establishing research priorities. They can also be the basis for the analyst's filing system to track developing events.

Descriptive or diagnostic indicators are best used to help the analyst assess whether there are grounds to believe that a specific action is taking place. They provide a systematic way to validate a hypothesis or help substantiate an emerging viewpoint. Figure 9.11 is an example of a list of descriptive indicators, in this case pointing to a clandestine drug laboratory.

A classic application of anticipatory indicators is to seek early warning of some undesirable event, such as a military attack or a nuclear test by a foreign country. Today, indicators are often paired with scenarios to identify which of several possible scenarios is developing. Analysts also use indicators to measure change that points toward an undesirable condition, such as political instability or an economic slowdown, or toward a desirable condition, such as economic reform or the potential for market growth. Analysts can use this technique whenever they need to track a specific situation to monitor, detect, or evaluate change over time.

Value Added

The human mind sometimes sees what it expects to see and can overlook the unexpected. Identification of indicators prepares the mind to recognize early signs of significant change. Change often happens so gradually that analysts do not see it, or they rationalize signs of change as not important until they are too obvious to ignore. Once analysts take a position on an issue, they can be reluctant to change their minds in response to new evidence. Analysts can avoid this type of rationalization by specifying beforehand the threshold for what actions or events would be significant and might cause them to change their minds.

Figure 9.11 Descriptive Indicators of a Clandestine Drug Laboratory Source: Pamphlet from ALERT Unit, New Jersey State Police, 1990; republished in The Community Model , Counterdrug Intelligence Coordinating Group, 2003.

Defining explicit criteria for tracking and judging the course of events makes the analytic process more visible and available to scrutiny by others, thus enhancing the credibility of analytic judgments. Including an indicator list in the finished product helps decision makers track future developments and builds a more concrete case for the analytic conclusions.

Preparation of a detailed indicator list by a group of knowledgeable analysts is usually a good learning experience for all participants. It can be a useful medium for an exchange of knowledge between analysts from different organizations or those with different types of expertise—for example, analysts who specialize in a country and those who are knowledgeable in a given field, such as military mobilization, political instability, or economic development.

When analysts or decision makers are sharply divided over (1) the interpretation of events (for example, political dynamics in Saudi Arabia or how the conflict in Syria is progressing), (2) the guilt or innocence of a "person of interest," or (3) the culpability of a counterintelligence suspect, indicators can help depersonalize the debate by shifting attention away from personal viewpoints to more objective criteria. Strong emotions are often diffused and substantive disagreements clarified if both sides can agree on a set of criteria before the fact that show developments are—or are not—moving in a particular direction or a person's behavior suggests guilt or innocence.

The process of developing indicators forces the analyst to reflect and explore all that might be required for a specific event to occur. The process can also ensure greater objectivity if two sets of indicators are developed: one pointing to a likelihood that the scenario will emerge and another showing that it is not emerging.

Indicators help counteract Hindsight Bias because they provide a written record that more accurately reflects what the analyst was thinking at the time rather than relying on that person's memory. Indicators can help analysts overcome the tendency to judge the frequency of an event by the ease with which instances come to mind (Availability Heuristic) and the tendency to predict rare events based on weak evidence or evidence that easily comes to mind (Associative Memory). Indicators also help analysts avoid the intuitive traps of ignoring information that is inconsistent with what one wants to see (Ignoring Inconsistent Evidence), continuing to hold to a judgment when confronted with a mounting list of contradictory evidence (Rejecting Evidence), and assuming something is inevitable, for example, if the indicators an analyst had expected to emerge are not actually realized (Assuming Inevitability).

9.11.1 The Method: Indicators Generation

Analysts can develop indicators in a variety of ways. The method can range from a simple process to a sophisticated team effort. For example, with minimum effort, analysts can jot down a list of things they would expect to see if a given situation were to develop as feared or foreseen. Or analysts could work together to define multiple variables that would influence a situation and then rank the value of each variable based on incoming information about relevant events, activities, or official statements.

When developing indicators, clearly define the issue, question, outcome, or hypothesis and then generate a list of activities, events, or other observables that you would expect to see if that issue or outcome emerged. Think in multiple dimensions using STEMPLES+ ( S ocial, T echnical, E conomic, M ilitary, P olitical, L egal, E nvironmental, and S ecurity, plus Demographic, Religious, Psychological, or other factors) to stimulate new ways of thinking about the problem. Also consider analogous sets of indicators from similar or parallel circumstances.

Indicators can be derived by applying a variety of Structured Analytic Techniques, depending on the issue at hand and the frame of analysis. 16 For example, analysts can use

Cluster Brainstorming or Mind Mapping to generate signposts. A signpost could be a new development, a specific event, or the announcement of a new policy or decision that would be likely to emerge as a scenario unfolds. Circleboarding™ to identify all the dimensions of a problem. It prompts the analyst to explore the Who, What, How, When, Where, Why, and So What of an issue. Key Assumptions Check to surface key variables or key uncertainties that could determine how a situation unfolds. Gantt Charts or Critical Path Analysis to identify markers. Markers are the various stages in a process (planning, recruitment, acquiring materials, surveillance, travel, etc.) that note how much progress the group has made toward accomplishing the task. Analysts can identify one or more markers for each step of the process and then aggregate them to create a chronologically ordered list of indicators. Decision Trees to reveal critical nodes. The critical nodes displayed on a Decision Tree diagram can often prove to be useful indicators. Models to describe emerging phenomena. Analysts can identify indicators that correspond to the various components or stages of a model that capture the essence of dynamics such as political instability, civil-military actions presaging a possible coup, or ethnic conflict. The more indicators observed, the more likely that the phenomenon represented by the model is present. Structured Analogies to flag what caused similar situations to develop. When historical or generic examples of the topic under study exist, analysis of what created these analogous situations can be the basis for powerful indicators of how the future might evolve.

When developing indicators, analysts should take time to carefully define each indicator. It is also important to establish what is "normal" for that indicator.

Consider the indicators as a set. Are any redundant? Have you generated enough? The set should be comprehensive, consistent, and complementary. Avoid the temptation of creating too many indicators; collectors, decision makers, and other analysts usually ignore long lists.

After completing your list, review and refine it, discarding indicators that are duplicative and combining those that are similar. See Figure 9.11.1 for a sample list of anticipatory or foresight indicators.

Figure 9.11.1 Using Indicators to Track Emerging Scenarios in Zambria Source: Pherson Associates, LLC, 2019.

9.11.2 The Method: Indicators Validation

Good indicators possess five key characteristics: they should be observable and collectible, valid, reliable, stable, and unique. 17 Discard those that are found wanting. The first two characteristics are required for every indicator. The third and fourth characteristics are extremely important but cannot always be satisfied. The fifth characteristic is key to achieving a high degree of diagnosticity for a set of indicators but is the most difficult goal to achieve.

Observable and collectible. The analyst should have good reason to expect that the indicator can be observed and reported by a reliable source. To monitor change over time, an indicator needs to be collectible over time. It must be legal and not too costly to collect. Valid. An indicator must be clearly relevant to the end state the analyst is trying to predict or assess. It must accurately measure the concept or phenomenon at issue. Reliable. Data collection must be consistent when comparable methods are used. Those observing and collecting the information must observe the same thing. This requires precise definition of each indicator. Stable. An indicator must be useful over time to allow comparisons and to track events. Ideally, the indicator should be observable early in the evolution of a development so that analysts and decision makers have time to react accordingly. Unique. An indicator should measure only one thing and, in combination with other indicators, point only to the phenomenon being studied. Valuable indicators are those that are consistent with a specified scenario or hypothesis and inconsistent with alternative scenarios or hypotheses. Indicators Evaluation, described next, can be used to check the diagnosticity of indicators.

Remember that indicators must be tangibly defined to be objective and reliable. For example, "growing nervousness" or "intent to do harm" would fail the test, but "number of demonstrators" or "purchase of weapons" would pass.

9.11.3 The Method: Indicators Evaluation

The best way to assess the diagnosticity of indicators used to distinguish among different scenarios is to employ the Indicators Evaluation methodology. Indicators Evaluation helps ensure the credibility of the analysis by identifying and dismissing non-diagnostic indicators or those defined as indicators that would be present for multiple scenarios or hypotheses.

The ideal indicator is highly likely or consistent for the scenario or hypothesis to which it is assigned and highly unlikely or inconsistent for all other alternatives. A non-diagnostic indicator would be observed in every scenario or hypothesis, suggesting that it may not be particularly useful in determining whether a specific scenario or a particular hypothesis is true. Most indicators fall somewhere in between.

Application of the Indicators Evaluation method helps identify the most-diagnostic indicators for each scenario or hypothesis—which are most deserving of monitoring and collection (see Figure 9.11.3a ).

Figure 9.11.3A Indicators Evaluation Source: Pherson Associates, LLC, 2019.

Employing Indicators Evaluation to identify and dismiss non-diagnostic indicators can increase the credibility of an analysis. By applying the method, analysts can rank order their indicators from most to least diagnostic and decide how far up the list they want to draw the line in selecting the indicators used in the analysis. In some circumstances, analysts might discover that most or all the indicators for a given scenario are also consistent with other scenarios, forcing them to brainstorm a new and better set of indicators for that scenario. If analysts find it difficult to generate independent lists of diagnostic indicators for two scenarios, it may be that the scenarios are not sufficiently dissimilar, suggesting the two scenarios should be combined.

Indicators Evaluation can help overcome mindsets by showing analysts how a set of indicators that point to one scenario may also point to others. It can also show how some indicators, initially perceived to be useful or diagnostic, may not be. By placing an indicator in a broader context against multiple scenarios, the technique helps analysts focus on which one(s) are useful and diagnostic instead of simply supporting a given scenario.

The Method

The first step is to fill out a matrix like that used for Analysis of Competing Hypotheses.

List the alternative scenarios along the top of the matrix (as is done for hypotheses in Analysis of Competing Hypotheses). List indicators generated for all the scenarios down the left side of the matrix (as is done with relevant information in Analysis of Competing Hypotheses). In each cell of the matrix, assess the status of that indicator against the noted scenario. Would you rate the indicator as

Highly Likely to appear? Likely to appear? Could appear? Unlikely to appear? Highly Unlikely to appear?

Indicators developed for the home scenario should be either "Highly Likely" or "Likely."

After assessing the likelihood of all indicators against all scenarios, assign a score to each cell. If the indicator is "Highly Likely" in the home scenario as we would expect it to be, then other cells for that indicator should be scored as follows for the other scenarios:

Highly Likely is 0 points Likely is 1 point Could is 2 points Unlikely is 4 points Highly Unlikely is 6 points If the indicator is deemed "Likely" in the home scenario, then the cells for the other scenarios for that indicator should be scored as follows:

Highly Likely is 0 points Likely is 0 points Could is 1 point Unlikely is 3 points Highly Unlikely is 5 points Tally up the scores across each row; the indicators with the highest scores are the most diagnostic or discriminating. Once this process is complete, re-sort the indicators for each scenario so that the most discriminating indicators are displayed at the top and the least discriminating indicators at the bottom.

The most discriminating indicator is "Highly Likely" to emerge in its scenario and "Highly Unlikely" to emerge in all other scenarios. The least discriminating indicator is "Highly Likely" to appear in all scenarios. Most indicators will fall somewhere in between. The indicators with the most "Highly Unlikely" and "Unlikely" ratings are the most discriminating. Review where analysts differ in their assessments and decide if adjustments are needed in their ratings. Often, differences in how an analyst rates an indicator can be traced back to different assumptions about the scenario when the analysts were doing the ratings. Decide whether to retain or discard indicators that have no "Unlikely" or "Highly Unlikely" ratings. In some cases, an indicator may be worth keeping if it is useful when viewed in combination with a cluster of indicators. Develop additional—and more diagnostic indicators—if a large number of initial indicators for a given scenario have been eliminated. Recheck the diagnostic value of any new indicators by applying the Indicators Evaluation technique to them as well.

Analysts should think seriously before discarding indicators determined to be non-diagnostic. For example, an indicator might not have diagnostic value on its own but be helpful when viewed as part of a cluster of indicators. An indicator that a terrorist group "purchased guns" would not be diagnostic in determining which of the following scenarios were likely to happen: armed attack, hostage taking, or kidnapping; knowing that guns had been purchased could be critical in pointing to an intent to commit an act of violence or even to warn of the imminence of the event. Figure 9.11.3b explores another reason for not discarding a non-diagnostic indicator. It is called the INUS (Insufficient but Nonredundant/Unnecessary but Sufficient) Condition.

A final argument for not discarding non-diagnostic indicators is that maintaining and publishing the list of non-diagnostic indicators could prove valuable to collectors. If analysts initially believed the indicators would be helpful in determining whether a specific scenario was emerging, then collectors and other analysts working the issue, or a similar issue, might come to the same conclusion. For these reasons, facilitators of the Indicators Validation and Evaluation techniques believe that the list of non-diagnostic indicators should also be published to alert other analysts and collectors to the possibility that they might also assume an indicator was diagnostic when it turned out on further inspection not to be.

If you take the time to develop a robust set or sets of anticipatory or foresight indicators (see Figure 9.11.3c ), you must establish a regimen for monitoring and reviewing the indicators on a regular basis. Analysts should evaluate indicators on a set schedule—every week or every month or every quarter—and use preestablished criteria when doing so. When many or most of the indicators assigned to a given scenario begin to "light up," this should prompt the analyst to alert the broader analytic community and key decision makers interested in the topic. A good set of indicators will give you advance warning of which scenario is about to emerge and where to concentrate your attention. It can also alert you to unlikely or unanticipated developments in time for decision makers to take appropriate action.

Figure 9.11.3B The INUS Condition 18

Any indicator list used to monitor whether something has happened, is happening, or will happen implies at least one alternative scenario or hypothesis—that it has not happened, is not happening, or will not happen. Many indicators that a scenario or hypothesis is happening are just the opposite of indicators that it is not happening; some are not. Some are consistent with two or more scenarios or hypotheses. Therefore, an analyst should prepare separate lists of indicators for each scenario or hypothesis. For example, consider indicators of an opponent's preparations for a military attack where there may be three hypotheses—no attack, attack, and feigned intent to attack with the goal of forcing a favorable negotiated solution. Almost all indicators of an imminent attack are also consistent with the hypothesis of a feigned attack. The analyst must identify indicators capable of diagnosing the difference between true intent to attack and feigned intent to attack. The mobilization of reserves is such a diagnostic indicator. It is so costly that it is not usually undertaken unless there is a strong presumption that the reserves will be needed.

After creating the indicator list or lists, the analyst or analytic team should regularly review incoming reporting and note any changes in the indicators. To the extent possible, the analyst or the team should decide well in advance which critical indicators, if observed, will serve as early-warning decision points. In other words, if a certain indicator or set of indicators is observed, it will trigger a report advising of some modification in the analysts' appraisal of the situation.

Techniques for increasing the sophistication and credibility of an indicator list include the following:

Establishing a scale for rating each indicator. Providing specific definitions of each indicator. Rating the indicators on a scheduled basis (e.g., monthly, quarterly, annually). Assigning a level of confidence to each rating. Providing a narrative description for each point on the rating scale, describing what one would expect to observe at that level. Listing the sources of information used in generating the rating.

Figure 9.11.3c is an example of a complex indicators chart that incorporates the first three techniques listed above.

Description Figure 9.11.3C Zambria Political Instability Indicators

Potential Pitfalls

The quality of indicators is critical, as poor indicators lead to analytic failure. For these reasons, analysts must periodically review the validity and relevance of an indicator list. Narrowly conceived or outdated indicators can reinforce analytic bias, encourage analysts to discard new evidence, and lull consumers of information inappropriately. Indicators can also prove to be invalid over time, or they may turn out to be poor "pointers" to what they were supposed to show. By regularly checking the validity of the indicators, analysts may also discover that their original assumptions were flawed. Finally, if an opponent learns what indicators are on your list, the opponent may make operational changes to conceal what you are looking for or arrange for you to see contrary indicators.

Relationship to Other Techniques

Indicators are closely related to many other techniques. Some form of brainstorming is commonly used to draw upon the expertise of various analysts to create indicators reflecting different perspectives and different specialties. The development of alternative scenarios should always involve the development and monitoring of indicators that point toward a given scenario unfolding or evolving. What If? Analysis and High Impact/Low Probability Analysis depend upon the development and use of indicators. Indicators are often entered as items of relevant information in Analysis of Competing Hypotheses, as discussed in chapter 7 .

Origins of These Techniques

The identification and monitoring of indicators of military attack is one of the oldest forms of intelligence analysis. The discussion here is based on Randolph H. Pherson and John Pyrik, Analyst's Guide to Indicators (Tysons, VA: Pherson Associates, LLC, 2018), and Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019). Cynthia M. Grabo's book Anticipating Surprise: Analysis for Strategic Warning (Lanham, MD: University Press of America, 2004) is a classic text on the development and use of indicators. A useful compendium of violent extremist mobilization indicators published by the U.S. Director of National Intelligence (DNI) describes indicators in terms of four criteria: diagnosticity, category of behavior, observability, and time sensitivity. See Homegrown Violent Extremist Mobilization Indicators , 2019 edition, accessible at https://www.dni.gov/index.php/nctc-newsroom/nctc-resources/item/1945-homegrown-violent-extremist-mobilization-indicators-2019 .

The Indicators Evaluation methodology was developed by Randolph Pherson, Grace Scarborough, Alan Schwartz, and Sarah Beebe, Pherson Associates, LLC. It was first published as the Indicators Validator ® in Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 3rd ed. (Reston, VA: Pherson Associates, LLC, 2008).

Notes

1. Peter Schwartz, The Art of the Long View: Planning for the Future in an Uncertain World (New York: Doubleday, 1991).

2. See, for example, Brian Nichiporuk, Alternative Futures and Army Force Planning: Implications for the Future Force Era (Santa Monica, CA: RAND Corporation, 2005).

3. A comprehensive review of how to generate, validate, and evaluate the diagnosticity of indicators can be found in Randolph H. Pherson and John Pyrik, Analyst's Guide to Indicators (Tysons, VA: Pherson Associates LLC, 2018).

4. Randolph H. Pherson, "Leveraging the Future with Foresight Analysis," The International Journal of Intelligence, Security, and Public Affairs 20, no. 2 (Fall 2018).

5. Peter Gijsbert de Werd, "Critical Intelligence: Analysis by Contrasting Narratives, Identifying and Analyzing the Most Relevant Truths" (PhD diss., Utrecht University, 2018), https://dspace.library.uu.nl/bitstream/handle/1874/373430/deWerd.pdf?sequence=1&isAllowed=y .

6. A fuller description of individual and group brainstorming techniques can be found in Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates LLC, 2019), 10–11.

7. The description of the Cone of Plausibility is taken from two government publications: (1) Quick Wins for Busy Analysts, DI Futures and Analytic Methods (DI FAM) , Professional Head of Defence Intelligence Analysis, United Kingdom Ministry of Defence, and (2) Gudmund Thompson, Aide Memoire on Intelligence Analysis Tradecraft, Version 4.02, Chief of Defence Intelligence, Director General of Intelligence Production, Canada. These sources are used with the permission of the UK and Canadian governments, respectively.

8. STEEP stands for S ocial, T echnological, E conomic, E nvironmental, and P olitical; STEEP + 2 adds Psychological and Military; STEEPLE adds L egal and E thics to the original STEEP list; STEEPLED further adds D emographics; and PESTLE stands for P olitical, E conomic, S ocial, T echnological, L egal, and E nvironmental.

9. This description of Counterfactual Reasoning is drawn largely from Noel Hendrickson, Reasoning for Intelligence Analysis (Lanham, MD: Rowman & Littlefield, 2018), as well as his earlier "Counterfactual Reasoning: A Basic Guide for Analysts, Strategists, and Decision Makers," The Proteus Monograph Series 2, no. 5 (October 2008).

10. N. J. Roese and J. M. Olson, eds., What Might Have Been: The Social Psychology of Counterfactual Thinking (Hillsdale, NJ: Lawrence Erlbaum Associates, 1995).

11. D. Kahneman and A. Tversky, "The Simulation Heuristic," in Judgment under Uncertainty: Heuristics and Biases , eds. D. Kahneman, P. Slovic, and A. Tversky (New York: Cambridge University Press, 1982).

12. Noel Hendrickson, "Critical Thinking in Intelligence Analysis," International Journal for Intelligence and Counterintelligence 21, no. 4 (September 2008).

13. This discussion of Analysis by Contrasting Narratives is taken from de Werd's "Critical Intelligence."

14. Ibid, 15.

15. Ibid.

16. A robust discussion of the processes analysts use to generate, validate, and evaluate the diagnosticity of indicators can be found in Pherson and Pyrik, Analyst's Guide to Indicators .

17. A shorter description of Indicators Generation, Validation, and Evaluation can be found in Pherson, Handbook of Analytic Tools and Techniques , 5th ed., 48–50.

18. See J. L. Mackie, "Causes and Conditions," American Philosophical Quarterly 2, no. 4 (October 1965), 245–264.

Descriptions of Images and Figures

Back to Figure

1 to 4 years. Simple situation: Brainstorming, reversing, and assumptions. Complex situation: Simple scenarios, cone of plausibility, and morphological analysis. Primary objective: Avoiding surprises. Anticipating the unanticipated.

5 to 10 years. Simple situation: Alternative futures analysis, and what if analysis. Complex situation: Multiple scenarios, generation, foresight quadrant, crunching trademarked, and analysis by contrasting narratives and counterfactual reasoning. Primary objective: Mapping the future. Finding opportunities.

Back to Figure

The present drivers and assumptions lead to the multiple scenarios after a period of stable regime. The drivers and their corresponding assumptions are as follows. Economy: Growth likely 2 to 5 percent. Popular support: Slowly eroding. Civil-Military relations: Growing tensions. Regional relations: Peaceful and stable. Foreign relations: Substantial. The scenarios are as follows. Plausible Scenario 1: More inclusive policies and sound economic decisions bring stability. Baseline scenario. President under fire and struggling to retain control. Plausible scenario 2: Junior military officers stage successful coup. Wild-card scenario: War breaks out with neighbor as regime collapses.

Back to Figure

The effectiveness of the government is fully operational and marginalized. The strength of the civil society is nonexistent and robust. Fully operational and nonexistent: Keeping it all together. Fully operational and robust: Competing power centers. Marginalized and nonexistent: Glueless in Havana. Marginalized and robust: Drifting toward democracy.

Back to Figure

A. The role of neighboring states, example, Syria, Iran. B. The capability of Iraq's security forces, such as military and police. C. The political environment in Iraq. In the first scenario, the key drivers are A and B. In the second scenario, the key drivers are A and C. In the third scenario, the key drivers are B and C.

Back to Figure

The key definers are Iraqi security capability, which are ineffective and effective, and the helpfulness of neighbors, which are stable and supportive, and unstable or disruptive. Neighboring states are stable and supportive and ineffective security capability: Regional defensive umbrella secures borders. Insurgency is pure Sunni, internal political solution? Neighboring states are stable and supportive and effective security capability: Militias integrated into new Iraqi Army. Jordan brokers deal; economic aid to Sunnis. Neighboring states are unstable or disruptive and ineffective security capability: Syria collapses, influx of new fighters. Civil wars. Neighboring states are unstable or disruptive and effective security capability: Insurgency fragments. Refugees flow into Iraq seeking safe haven.

Back to Figure

A. The role of neighboring states, example, Syria, Iran. B. The capability of Iraq's security forces, such as military and police. C. The political environment in Iraq. In the first scenario, the key drivers are A and B. The Civil War is the nightmare scenario in the third quadrant. In the second scenario, the key drivers are A and C. Sunni politics in the second quadrant deserve the most attention. In the third scenario, the key drivers are B and C. New fighters in the third column deserve the most attention.

Back to Figure

The dimensions are group, type of attack, target, and impact. The first option is an outside group planning multiple attacks on the treatment plant for disrupting economy. The second option is an insider group planning a single type of attack on the drinking water for terrorizing the population. The third option is a visitor group planning a threatening type of attack on wastewater to cause major casualties.

Back to Figure

Convergent scenario for X changes to divergent scenario for Y due to ripple effects, or possible change X, if, is the consequence Y, then. Convergent scenario is the break with prior history. Divergent scenario is he continuation to failure. Counterfactual: If X were to occur, then Y would or might occur. Stage 1. Convergent scenario development. Ask, "When and where might this change plausibly come about?" Assess the causes of the change and develop the story's beginning. Stage 2. Ripple Effect Analysis. Ask, "When and where might this change cause broader uncertainties and unintended consequences? Asses the context of the change or new uncertainties and develop the story's middle. Stage 3. Divergent Scenario Development. Ask, "When and where might this change have long-term impact?" Assess the consequences of the change and develop the story's end.

Back to Figure

A tabular representation of Zambria Political Instability Indicators lists the five main indicators, with sub-indicators, and their corresponding concerns for the first, second, third, and fourth quarters of 2008 and 2009 and the first and second quarters of 2010.

2008

2009

2010

First Quarter

Second Quarter

Third Quarter

Fourth Quarter

First Quarter

Second Quarter

Third Quarter

Fourth Quarter

First Quarter

Second Quarter

Social change or conflict

Ethnic or religious discontent

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Demonstrations, riots, strikes

Negligible

Negligible

Low

Low

Low

Moderate

Strong

Strong

Strong

Substantial

Economic factors

General deterioration

Low

Low

Moderate

Moderate

Moderate

Low

Moderate

Moderate

Moderate

Moderate

Decreased access to foreign funds

Low

Moderate

Low

Low

Low

Low

Low

Low

Low

Low

Capital flight

Low

Low

Low

Moderate

Moderate

Low

Strong

Strong

Strong

Strong

Unpopular changes in economic policies

Low

Low

Low

Low

Strong

Strong

Strong

Strong

Strong

Strong

Food or energy shortages

Low

Low

Low

Low

Moderate

Substantial

Strong

Strong

Strong

Strong

Inflation

Low

Low

Moderate

Low

Low

Moderate

Strong

Strong

Strong

Strong

Opposition activities

Organizational capabilities

Low

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Low

Low

Low

Opposition or conspiracy planning

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

Terrorism and sabotage

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

Insurgent armed attacks

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

Public support

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Military attitude or activities

Threat to corporate military interests or dignity

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Low

Low

Low

Discontent over career loss, pay, or benefits

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Low

Low

Low

Discontent over government action or policies

Low

Low

Low

Low

Low

Low

Low

Moderate

Moderate

Moderate

Reports or rumors of coup plotting

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

External support for government

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

External support for opposition

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

Threat of military conflict

Low

Low

Low

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Negligible

Regime actions or capabilities

Repression or brutality

Moderate

Low

Moderate

Moderate

Moderate

Moderate

Moderate

Moderate

Moderate

Moderate

Security capabilities

Negligible

Negligible

Negligible

Negligible

Low

Low

Low

Low

Low

Low

Political disunity or loss of confidence

Low

Low

Low

Low

Low

Low

Low

Low

Low

Low

Loss of legitimacy

Substantial

Moderate

Moderate

Moderate

Moderate

Moderate

Low

Moderate

Moderate

Moderate

Chapter 10 Decision Support Techniques

10.1 Opportunities Incubator™ [ 311 ] 10.2 Bowtie Analysis [ 314 ] 10.3 Impact Matrix [ 318 ] 10.4 SWOT Analysis [ 321 ] 10.5 Critical Path Analysis [ 323 ] 10.6 Decision Trees [ 326 ] 10.7 Decision Matrix [ 329 ] 10.8 Force Field Analysis [ 332 ] 10.9 Pros-Cons-Faults-and-Fixes [ 336 ] 10.10 Complexity Manager [ 339 ]

M anagers, commanders, planners, and other decision makers all make choices or trade-offs among competing goals, values, or preferences. Because of limitations in human short-term memory, we usually cannot keep all the pros and cons of multiple options in mind at the same time. That causes us to focus first on one set of problems or opportunities and then another. This often leads to vacillation or procrastination in making a firm decision. Some Decision Support Techniques help overcome this cognitive limitation by laying out all the options and interrelationships in graphic form so that analysts can test the results of alternative options while keeping the problem as a whole in view. Other techniques help decision makers untangle the complexity of a situation or define the opportunities and constraints in the environment in which the choice needs to be made.

The role of the analyst in the policymaking process is similar to that of the scout in relation to the football coach. The job of the scout is not to predict in advance the final score of the game, but to assess the strengths and weaknesses of the opponent so that the coach can devise a winning game plan. Then the scout sits in a booth with powerful binoculars, to report on specific vulnerabilities the coach can exploit.

—Douglas MacEachin, CIA Deputy Director for Intelligence, 1993–1995

It is usually not the analyst's job to make the choices or decide on the trade-offs, but analysts can and should use Decision Support Techniques to provide timely support to managers and decision makers who must make these choices. To engage in this type of client support, analysts must be aware of the operating environment of decision makers and anticipate how they are likely to approach an issue. Analysts also need to understand the dynamics of the decision-making process to recognize when and how they can be most useful. Most of the decision support techniques described here are used in both government and industry.

By using such techniques, analysts can see a problem from the decision maker's perspective. They can use these techniques without overstepping the limits of their role as analysts because the technique does not make the decision; it just structures all the relevant information in a format that makes it easier for the decision maker to make a choice.

The decision aids described in this chapter provide a framework for analyzing why or how a leader, group, organization, company, or country has made, or is likely to make, a decision. If analysts can describe an adversary's or a competitor's goals and preferences, it will be easier to anticipate their actions. Similarly, when the decisions are known, the technique makes it easier to infer the adversary's or competitor's goals and preferences. Analysts can use these Decision Support Techniques to help the decision maker frame a problem instead of trying to predict the decision of a foreign government or competitor. Often, the best support an analyst can provide is to describe the forces that are most likely to shape a decision or an outcome. Knowledge of these key drivers then gives the decision maker a "head start" in trying to leverage the eventual outcome. (See chapter 9 for a discussion of Foresight Techniques.)

Caution is in order, however, whenever one attempts to predict or explain another person's decision, even if the person is of similar background. People do not always act rationally or in their own best interests. Their decisions are influenced by emotions and habits as well as by what others might think and values of which others may not be aware.

The same is true of organizations, companies, and governments. One of the most common analytic errors is to assume that an organization, company, or government will act rationally or in its own best interests. All intelligence analysts seeking to understand the behavior of another country should be familiar with Graham Allison's analysis of U.S. and Soviet decision making during the Cuban missile crisis. 1 It documents three different models for how governments make decisions—bureaucratic bargaining processes, standard organizational procedures, and the rational actor model.

Even if an organization, company, or government is making a rational decision, analysts may get their analysis wrong. Foreign entities typically view their own best interests quite differently from the way analysts from different cultures, countries, or backgrounds would see them. Also, organizations, companies, and governments do not always have a clear understanding of their own best interests, and often must manage a variety of conflicting interests.

Decision making and decision analysis are large and diverse fields of study and research. The decision support techniques described in this chapter are only a small sample of what is available, but they do meet many of the basic requirements for intelligence and competitive analysis.

By providing structure to the decision-making process, the Decision Support Techniques discussed in this chapter help analysts as well as decision makers avoid the common cognitive limitations of Premature Closure and Groupthink. Application of the techniques will often surface new options or demonstrate that a previously favored option is less optimal than originally thought. The natural tendency toward Mirror Imaging is more likely to be kept in check when using these techniques because they provide multiple perspectives for viewing a problem and envisioning the interplay of complex factors.

Decision Support Techniques help analysts overcome several practitioner's mental mistakes including the intuitive trap of Overrating Behavioral Factors when the role of internal determinants of behavior (personality, attitudes, beliefs) are given more weight than external or situational factors (constraints, forces, incentives). They also help counter the traps of overestimating the probability of multiple independent events occurring for an event or attack to take place (Overestimating Probability) and failing to factor something into the analysis because an appropriate category or "bin" is lacking (Lacking Sufficient Bins).

Techniques such as the Opportunities Incubator™, Bowtie Analysis, and Impact Matrix help decision makers decide how to implement the key findings of a Foresight analysis to either mitigate the impact of a bad scenario or increase the chances of a good scenario occurring. SWOT Analysis (Strengths, Weaknesses, Opportunities, and Threats) and Critical Path Analysis are basic tools of the competitive analysis profession. Decision Trees and the Decision Matrix use simple math to help analysts and decision makers calculate the most probable or preferred outcomes. Force Field Analysis, Pros-Cons-Faults-and-Fixes, and the Complexity Manager can help decision makers understand the overarching context of a problem and identify the key forces and factors at play.

Overview of Techniques

Opportunities Incubator™. A systematic method for identifying actions that can facilitate the emergence of positive scenarios and thwart or mitigate less desirable outcomes.

Bowtie Analysis. A technique for mapping causes and consequences of a disruptive event. It is particularly effective in identifying opportunities for decision makers to avoid undesirable developments and promote positive outcomes.

Impact Matrix. A management tool for assessing the impact of a decision on the organization by evaluating what impact a decision is likely to have on all key actors or participants in that decision. It gives the analyst or decision maker a better sense of how the issue is most likely to play out or be resolved in the future.

SWOT Analysis (Strengths, Weaknesses, Opportunities, and Threats). A 2-×-2 matrix used to develop a plan or strategy to accomplish a specific goal. In using this technique, the analyst first lists the Strengths and Weaknesses in the organization's ability to achieve a goal, and then balances them against lists of Opportunities and Threats in the external environment that would either help or hinder the organization from reaching the goal.

Critical Path Analysis. A modeling technique for identifying the critical stages required to move from a beginning to an end. It also is used for scheduling a set of project activities commonly used in conjunction with Program Evaluation and Review Technique (PERT) charts.

Decision Trees. A simple way to chart the range of options available to a decision maker, estimate the probability of each option, and show possible outcomes. The technique provides a useful landscape to organize a discussion and weigh alternatives but can also oversimplify a problem.

Decision Matrix. A simple but powerful device for making trade-offs between conflicting goals or preferences. An analyst lists the decision options or possible choices, the criteria for judging the options, the weights assigned to each of these criteria, and an evaluation of the extent to which each option satisfies each of the criteria. This process will show the best choice—based on the values the analyst or a decision maker puts into the matrix. By studying the matrix, one can also analyze how the best choice would change if the values assigned to the selection criteria were changed or if the ability of an option to satisfy a specific criterion were changed. It is almost impossible for an analyst to keep track of these factors effectively without such a matrix, as one cannot keep all the pros and cons in working memory at the same time. A Decision Matrix helps the analyst see the whole picture.

Force Field Analysis. A technique that analysts can use to help the decision maker identify the most effective ways to solve a problem or achieve a goal—and whether it is possible to do so. The analyst identifies and assigns weights to the relative importance of all the factors or forces that either help or hinder a solution to the problem or achievement of the goal. After organizing all these factors in two lists, pro and con, with a weighted value for each factor, the analyst or decision maker is in a better position to recommend strategies that would be most effective in either strengthening the impact of the driving forces or reducing the impact of the restraining forces.

Pros-Cons-Faults-and-Fixes. A strategy for critiquing new policy ideas. It is intended to offset the human tendency of analysts and decision makers to jump to conclusions before conducting a full analysis of a problem, as often happens in group meetings. The first step is for the analyst or the project team to make lists of Pros and Cons. If the analyst or team is concerned that people are being unduly negative about an idea, he or she looks for ways to "Fix" the Cons—that is, to explain why the Cons are unimportant or even to transform them into Pros. If concerned that people are jumping on the bandwagon too quickly, the analyst tries to "Fault" the Pros by exploring how they could go wrong. Usually, the analyst will either "Fix" the Cons or "Fault" the Pros, but will not do both. Of the various techniques described in this chapter, this is one of the easiest and quickest to use.

Complexity Manager . A simplified approach to understanding complex systems—the kind of systems in which many variables are related to each other and may be changing over time. Government policy decisions are often aimed at changing a dynamically complex system. It is because of this dynamic complexity that many policies fail to meet their goals or have unforeseen and unintended consequences. Use the Complexity Manager to assess the chances for success or failure of a new or proposed policy, identify opportunities for influencing the outcome of any situation, determine what would need to change in order to achieve a specified goal, or recognize the potential for unintended consequences from the pursuit of a policy goal.

10.1 Opportunities Incubator™

The Opportunities Incubator™ is a systematic method for identifying actions that can facilitate positive outcomes and thwart or mitigate less desirable outcomes.

When to Use It

The technique is most useful for assisting decision makers when they are preparing for change or they want to shape how change will occur.

Value Added

The Opportunities Incubator™ helps senior officials and decision makers identify what actions would be most effective in preventing a negative scenario from occurring or fostering the emergence of a good scenario. The tool focuses attention on who is most affected by a given scenario and who has the capability and intent to influence an outcome.

The technique is helpful in mitigating the deleterious impact of cognitive biases such as Mirror Imaging, providing quick and easy answers to complex challenges (Mental Shotgun), and judging the desirability of a potential course of action by the ease with which the policy option comes to mind (Availability Heuristic). It also helps analysts avoid the pitfalls of failing to incorporate a policy option into an action plan because the analyst lacks a category or "bin" for such an option (Lacking Sufficient Bins), overestimating the probable impact of multiple independent actions occurring (Overestimating Probability), and giving too much credit to the role of behavioral factors (personality, attitudes, beliefs) and underestimating the impact of situational factors (constraints, time, incentives) on accomplishing a stated objective (Overrating Behavioral Factors).

The Method

After developing a set of scenarios, assess each scenario separately using the following steps (see Figure 10.1 ):

Describe the scenario, projected trajectory, or anticipated outcome in one sentence. Determine your client's perception of the scenario, projected trajectory, or anticipated outcome. Use the following scale: Strongly Positive, Positive, Neutral, Negative, Strongly Negative. Identify the primary actors in the scenario who have a stake in the projected trajectory or anticipated outcome. Assess how much each actor might care about the scenario's projected outcome because of its positive or negative (perceived or real) impact on the actor's livelihood, status, prospects, and so forth. This assessment considers how motivated the actor may be to act, not whether the actor is likely to act or not. Use the scale: Very Desirable (DD), Desirable (D), Neutral (N), Undesirable (U), Very Undesirable (UU). Assess each actor's capability or resources to respond to the scenario using a High, Medium, or Low scale. Assess each actor's likely intent to respond to the scenario using a High, Medium, or Low scale. Identify the actors who should receive the most attention based on the following tiers:

1st: DD or UU Level of Interest rating plus High ratings in both Capability and Intent 2nd: High ratings in Capability and Intent 3rd: DD or UU Level of Interest rating plus a High rating in either Capability or Intent 4th: High rating in either Capability or Intent 5th: All other actors Reorder the rows in the matrix so that the actors are listed from first to fifth tiers. Record the two to three key drivers that would most likely influence or affect each actor or the actor's response. Consider your client's perception and determine how and when he or she might act to influence favorably, counteract, or deter an actor's response. From this discussion, develop a list of possible actions the client can take.

Figure 10.1 Opportunities Incubator™ Source: Globalytica, LLC, 2019.

Origins of This Technique

The Opportunities Incubator™ was developed by Globalytica, LLC, to provide a structured process decision makers can use to implement the key findings of a Foresight exercise. This technique and the Impact Matrix are the most common decision support tools used to conclude a Foresight exercise.

10.2 Bowtie Analysis

Bowtie Analysis is a technique for mapping causes and consequences of a disruptive event to facilitate the management of both risks and opportunities.

The technique was first developed for the oil and gas industry but has evolved into a generic method for assisting decision makers in proactively managing potential hazards and anticipated opportunities. Analysts can use the method to enhance their understanding of causal relationships through mapping both anticipatory and reactive responses to a disruptive event.

The Bowtie's logical flow can make the analysis of risks and opportunities more rapid and efficient. The graphical "bowtie" display also makes it easier for analysts to communicate the interaction and relative significance of causes and consequences of a disruptive event, whether it presents a hazard or an opportunity.

When to Use It

Bowtie Analysis is used when an organization needs to thoroughly examine its responses to a potential or anticipated disruptive event. Traditionally, industry has used it to establish more control over a potential hazard and improve industrial safety, but it is also useful in identifying a potential opportunity. Bowtie Analysis helps analysts and decision makers understand the causal relationships among seemingly independent events. Decision makers can use the technique to do the following:

Evaluate their ability to control the occurrence of a risk event by identifying both measures to prevent the event from happening and responses for mitigating the harm it would do. Explore ways to ensure good things happen and accelerate the timing and benefits of a positive event.

In both cases, the process helps analysts and decision makers recognize weaknesses and strengths in the risk prevention structures and strategic planning processes of an adversary or their organization. It can also be a part of a lessons-learned process to assess why something happened in the past and identify opportunities that can be leveraged in the future.

Value Added

Bowtie Analysis forces a thorough assessment of causes and consequences of a disruptive event. It is adaptable to almost any organization and scalable for any level of risk or opportunity. The technique can be used either to evaluate possible causes and consequences of a risk or opportunity event or to investigate an organization's overall risk and profitability management system. It can also pinpoint elements of an organization's risk management system that need further development.

The method first evaluates the ability of an organization to prevent or control the occurrence of a risk event—or anticipate the emergence of an opportunity. If there is the potential for control, then the technique identifies the steps that can be taken to exercise that control. If there is little ability to control, then the method evaluates the potential impact of the event and describes what steps should be taken to mitigate the resulting damage. Similarly, Bowtie Analysis can help develop strategies for taking advantage of an upcoming event to optimize positive benefits for the organization.

Bowtie graphics are an effective mechanism for conveying a risk or opportunity landscape because of their visual and logically flowing presentation. They are quickly understood and conducive to manipulation by decision makers as they consider options and construct strategies to either mitigate harm or capitalize on the potential for gain.

As with opportunities analysis, the technique is helpful in mitigating the impact of Mental Shotgun, the Availability Heuristic, and Satisficing, which is selecting the first answer that appears "good enough." The technique also helps counter the intuitive traps of Lacking Sufficient Bins, Overrating Behavioral Factors, and Assuming a Single Solution.

The Method

A Bowtie Analysis is conducted using the following steps (see Figure 10.2 ):

Risk or Opportunity Event. Identify a hazard (something in or around the organization of a decision maker that has the potential to cause damage) or an opportunity (something that has the potential to bring positive benefits to the organization). If no specific hazard or opportunity comes readily to mind, begin by brainstorming ideas, then choose the one with the greatest potential for good or ill. Determine a possible event caused by the hazard or opportunity. This event is the Risk or Opportunity Event. It represents either a loss of control of the hazard or a favorable outcome of an opportunity. The event may be unprecedented, or it may have already occurred, in which case the organization can look to the past for root causes.

Description Figure 10.2 Bowtie Analysis Causes. Make a list of threats or trends, placing them on the left and drawing connecting lines from each to the centered Risk/Opportunity Event. Threats/trends are potential causes of the Risk/Opportunity Event. Be specific (i.e., "weather conditions" can be specified as "slippery road conditions") so that actionable preventive barriers in the case of threats, or accelerators for positive trends, can be created in a later step. Consequences. Make a similar list of consequences, placing them on the right and drawing connecting lines from each to the centered Risk/Opportunity Event. Consequences are results from the event. Continue to be specific. This will aid in identifying relevant recovery barriers or distributors to the consequences in a later step. Preventive Barriers or Accelerators. Focus on the causes on the left of the Bowtie. If the causes are threats, brainstorm barriers that would stop the threats from leading to the Risk Event. If the causes are trends, brainstorm accelerators that would quicken the occurrence of the Opportunity Event. Recovery Barriers or Amplifiers. Similarly, focus on the consequences on the right of the Bowtie. If the consequences are undesired, brainstorm barriers that would stop the Risk Event from leading to the worst-case consequences. If the consequences are desired, brainstorm amplifiers that would capitalize on the effects of the Opportunity Event. Escalation Factor. Brainstorm escalation factors and connect each to a barrier, accelerator, or amplifier. An escalation factor (EF) is anything that may cause a barrier to fail (e.g., "forgetting to wear a seatbelt" is an escalation factor for a Risk Event because it impairs the effectiveness of the "wearing a seatbelt" recovery barrier) or enhances the positive effects of an accelerator or distributor (e.g., "getting all green lights" is an escalation factor for an Opportunity Event because it increases the effectiveness of the amplifier "going the maximum speed limit"). An escalation factor barrier stops or mitigates the impact of the escalation factor and its effects, while an escalation factor accelerator or amplifier intensifies the escalation factor and its effects.

Potential Pitfalls

Specificity is necessary to create actionable barriers, accelerators, and amplifiers in a Bowtie Analysis. However, a detailed Bowtie Analysis can present the impression that the authors have thought of all options or outcomes when they actually have not, as unanticipated options are often available to decision makers and unintended consequences result.

Relationship to Other Techniques

The Bowtie method is like Decision Tree analysis because both methods analyze chains of events to illustrate possible future actions. Bowtie Analysis also evaluates controls, or barriers, that an organization has in place. The Opportunities Incubator™ is another technique that can be used to facilitate positive outcomes and thwart or mitigate less desirable outcomes. It structures the process decision makers can use to develop strategies for leveraging or mitigating the impact of key drivers that influence primary actors, who are associated with differing levels of intent and capability.

Origins of This Technique

The University of Queensland, Australia, is credited with disseminating the first Bowtie diagrams at a lecture on hazard analysis in 1979. After the Piper Alpha offshore oil and gas platform explosion in 1988, the oil and gas industry adopted the technique to develop a systematic way of understanding the causal relationships among seemingly independent events and asserting control over the potentially lethal hazards in the industry. The versatile Bowtie Analysis technique is now in widespread use throughout a variety of industries, including chemicals, aviation, and health care. It is also used by several intelligence services. Additional resources on Bowtie Analysis can be found at https://www.cgerisk.com/knowledgebase/The_bowtie_method .

10.3 Impact Matrix

The Impact Matrix identifies the key actors involved in a decision, their level of interest in the issue, and the impact of the decision on them. It is a technique managers use to gain a better sense of how well or how poorly a decision may be received, how it is most likely to play out, and what would be the most effective strategies to resolve a problem. Analysts can also use it to anticipate how decisions will be made in another organization or by a foreign leader.

When to Use It

The best time for a manager to use this technique is when a major new policy initiative is being contemplated or a mandated change is about to be announced. The technique helps managers identify where they are most likely to encounter both resistance and support. Intelligence analysts can also use the technique to assess how the public might react to a new policy pronouncement by a foreign government or a new doctrine posted on the internet by a political movement. Invariably, the technique will uncover new insights by focusing in a systematic way on all possible dimensions of the issue.

The matrix template makes the technique easy to use. Most often, an individual manager will apply the technique to develop a strategy for how he or she plans to implement a new policy or respond to a newly decreed mandate from superiors. Managers can also use the technique proactively before they announce a new policy or procedure. The technique can expose unanticipated pockets of resistance or support, as well as individuals to consult before the policy or procedure becomes public knowledge. A single intelligence analyst or manager can also use the technique, although it is usually more effective if done as a group process.

Value Added

The technique provides the user with a comprehensive framework for assessing whether a new policy or procedure will be met with resistance or support. A key concern is to identify any actor who will be heavily affected in a negative way. Those actors should be engaged early on or ideally before the policy is announced, in case they have ideas on how to make the new policy more digestible. At a minimum, they will appreciate that their views—either positive or negative—were sought out and considered. Support can be enlisted from those who will be strongly impacted in a positive way.

The Impact Matrix usually is most effective when used by a manager as he or she is developing a new policy. The matrix helps the manager identify who will be most affected, and he or she can consider whether this argues for either modifying the plan or modifying the strategy for announcing the plan.

The technique is helpful in reducing the impact of several of the most common cognitive biases and heuristics: Mirror Imaging, Mental Shotgun, and Groupthink. It also helps analysts avoid several common mental mindsets or intuitive traps, including Overrating Behavioral Factors, Lacking Sufficient Bins, and Overestimating Probability.

The Method

The Impact Matrix process involves the following steps (a template for using the Impact Matrix is provided in Figure 10.3 ):

Identify all the individuals or groups involved in the decision or issue. The list should include me (usually the manager); my supervisor; my employees or subordinates; my client(s), colleagues, or counterparts in my office or agency; and counterparts in other agencies. If analyzing the decision-making process in another organization, the "me" becomes the decision maker. Rate how important this issue is to each actor or how much each actor is likely to care about it. Use a three-point scale: Low, Moderate, or High. The level of interest should reflect how great an impact the decision would have on such issues as each actor's time, quality of work life, and prospects for success.

Figure 10.3 Impact Matrix: Identifying Key Actors, Interests, and Impact Categorize the impact of the decision on each actor as Mostly Positive (P), Neutral or Mixed (O), or Mostly Negative (N). If a decision has the potential to be negative, mark it as negative. If in some cases the impact on a person or group is mixed, then either mark it as neutral or split the group into subgroups if specific subgroups can be identified. Review the matrix after completion and assess the likely overall reaction to the policy or decision. Develop an initial action plan. Identify where the decision is likely to have a major negative impact and consider the utility of prior consultations. Identify where the decision is likely to have a major positive impact and consider enlisting the support of key actors in helping make the decision or procedure work. Finalize the action plan reflecting input gained from consultations. Announce the decision and monitor reactions. Reassess the action plan based on feedback received on a periodic basis.

Origins of This Technique

The Impact Matrix was developed by Mary O'Sullivan and Randolph Pherson, Pherson Associates, LLC, and is taught in courses for mid-level managers in the government, law enforcement, and business.

10.4 SWOT Analysis

SWOT Analysis is commonly used by all types of organizations to evaluate the S trengths, W eaknesses, O pportunities, and T hreats involved in any project or plan of action. The Strengths and Weaknesses are internal to the organization; Opportunities and Threats are characteristics of the external environment. It is a frequently used tool in competitive analysis.

When to Use It

After setting a goal or objective, use SWOT as a framework for collecting and organizing information in support of strategic planning and decision making to achieve the goal or objective. Information is collected to analyze the plan's Strengths and Weaknesses and the Opportunities and Threats present in the external environment that might affect attainment of the goal.

SWOT is easy to use. It is usually a group process, but a single analyst can also use it effectively. It is particularly effective as a cross-functional team-building exercise at the start of a new project. Businesses and organizations of all types use SWOT so frequently that a Google search on "SWOT Analysis" turns up more than one million hits.

Value Added

SWOT can generate useful information with relatively little effort. It brings information together in a framework that provides a good base for further analysis. It often points to specific actions that can or should be taken. Because the technique matches an organization's or plan's Strengths and Weaknesses against the Opportunities and Threats in the environment in which it operates, the plans or action recommendations that develop from the use of this technique are often highly practical.

SWOT helps analysts overcome, or at least reduce, the impact of seeking only the information that is consistent with the lead hypothesis, policy option, or business strategy (Confirmation Bias), accepting a given value of something as a proper starting point (Anchoring Effect), and Groupthink. It also helps analysts avoid the intuitive traps of Lacking Sufficient Bins, Overrating Behavioral Factors, and Overestimating Probability.

The Method

Define the objective. Fill in the SWOT table by listing Strengths, Weaknesses, Opportunities, and Threats that are expected to facilitate or hinder achievement of the objective (see Figure 10.4 ). The significance of the attributes' and conditions' impact on achievement of the objective is far more important than the length of the list. It is often desirable to list the items in each quadrant in order of their significance or to assign them values on a scale of 1 to 5. Identify possible strategies for achieving the objective. This is done by asking the following questions:

How can we use each Strength? How can we improve each Weakness? How can we exploit each Opportunity? How can we mitigate each Threat?

Figure 10.4 SWOT Analysis

An alternative approach is to apply "matching and converting" techniques. Matching refers to matching Strengths with Opportunities to make the Strengths even stronger. Converting refers to matching Opportunities with Weaknesses to convert the Weaknesses into Strengths.

Potential Pitfalls

SWOT is simple, easy, and widely used, but it has limitations. It focuses on a single goal without weighing the costs and benefits of alternative means of achieving the same goal. In other words, SWOT is a useful technique if the analyst or group recognizes that it does not necessarily tell the full story of what decision should or will be made. There may be other equally good or better courses of action.

Another strategic planning technique, the TOWS Matrix, remedies one of the limitations of SWOT. The factors listed under T hreats, O pportunities, W eaknesses, and S trengths are combined to identify multiple alternative strategies that an organization might pursue. 2

Relationship to Other Techniques

The factors listed in the Opportunities and Threats quadrants of a SWOT Analysis are the same as the outside or external factors the analyst seeks to identify during Outside-In Thinking ( chapter 8 ). In that sense, there is some overlap between the two techniques.

Origins of This Technique

The SWOT technique was developed in the late 1960s at Stanford Research Institute as part of a decade-long research project on why corporate planning fails. It is the first part of a more comprehensive strategic planning program. It has been so heavily used over such a long period of time that several versions have evolved. Richards J. Heuer Jr. selected the version he believed the most appropriate for intelligence analysis. It comes from multiple internet sites, including the following: http://www.businessballs.com/swotanalysisfreetemplate.htm , http://en.wikipedia.org/wiki/SWOT_analysis , http://www.mindtools.com , http://www.valuebasedmanagement.net , and http://www.mycoted.com . Pros and cons for using this technique, along with interactive templates, can be found at https://www.mindtools.com/pages/article/newTMC_05.htm .

10.5 Critical Path Analysis

Critical Path Analysis is a modeling technique for identifying the critical stages required to move from a beginning to an end point.

When to Use It

Critical Path Analysis is used for scheduling a set of project activities often in conjunction with P rogram E valuation and R eview T echnique (PERT) charts.

Value Added

Critical Path Analysis uses a model to show the logical progression of events, the key nodes (or intersections) in the process, and the routes taken in getting from one state to others. Figure 10.5 provides an example of Critical Path Analysis used to describe how a country could move from a relatively stable state to different forms of political instability.

Critical Path Analysis can assist analysts in reducing the influence of several cognitive biases and heuristics, including Satisficing, the Availability Heuristic, and Premature Closure. It also helps analysts resist the intuitive traps of Overinterpreting Small Samples, Relying on First Impressions, and Projecting Past Experiences.

More detailed project models show the various paths of critical activities required to achieve a planned end point of a project. These models can be used to calculate the earliest, most feasible time each step of the process can commence and the latest time it needs to be concluded to avoid making the project longer. The process allows the analyst to determine which activities are critical to achieving the outcome in the minimal amount of time possible and which can be delayed without causing the time frame to be extended. A project can have several parallel critical or near critical paths.

The Method

Define the task. Define the end point of the project. Define the activities involved. List all the components or activities required to bring the project to completion. Calculate the time to do each task. Indicate the amount of time (duration) it will take to perform the activity. This can be a set amount of time or a range from shortest to longest expected time. Identify dependencies. Determine which activities are dependent on other activities and the sequences that must be followed. Identify pathways. Identify various ways or combinations of activities that would enable accomplishment of the project. Estimate time to complete. Calculate how much time would be required for each path taken. This could be a set amount of time or a range.

Description Figure 10.5 Political Instability Critical Path Analysis Identify the optimal pathway. Rank order the various pathways in terms of time required and select the pathway that requires the least amount of time. Identify which activities are critical to achieving this goal. Identify key indicators. Formulate expectations (theories) about potential indicators at each stage that could either expedite or impede progress toward achieving the end point of the project. Generate a final product. Capture all the data in a final chart and distribute it to all participants for comment.

Given the complexity of many projects, software is often used for project management and tracking. Microsoft Project is purposely built for this task. There are also free charting tools like yEd that are serviceable alternatives. Using this process, analysts can better recognize important nodes and associated key indicators.

10.6 Decision Trees

Decision Trees establish chains of decisions and/or events that illustrate a comprehensive range of possible future decision points. They paint a landscape for the decision maker showing the range of options available, the estimated value or probability of each option, and the likely implications or outcomes of choosing each option.

When to Use It

Decision Trees can be used to do the following:

Aid decision making by explicitly comparing options. Create a heuristic model of the decision-making process of the subject or adversary. Map multiple competing hypotheses about an array of possible actions.

A Decision Tree can help a decision maker resolve a difficult problem, or assess what options an adversary or competitor might choose to implement. In constructing a Decision Tree, analysts need to have a rich understanding of the operating environment in which the decision is being made. This can include knowledge of motives, capabilities, sensitivities to risk, current doctrine, and cultural norms and values.

Value Added

Decision Trees are simple to create and easy to use and interpret. A single analyst can create a Decision Tree but a group using brainstorming techniques as discussed in chapter 6 typically yields better results. Once the tree has been built, it can be posted on a wall or website and adjusted over time as new information becomes available. When significant new data are received that add new branches to the tree or substantially alter the probabilities of the options, these changes can be inserted into the tree and highlighted with color to show the decision maker what has changed and how it may have changed the previous line of analysis.

Both this technique and the Decision Matrix are useful for countering the impact of cognitive biases and heuristics such as the Anchoring Effect, Satisficing, and Premature Closure. They also help analysts avoid falling into the intuitive traps of Relying on First Impressions, Assuming a Single Solution, and Overrating Behavioral Factors.

The Method

Using a Decision Tree is a fairly simple process involving two steps: (1) building the tree and (2) calculating the value or probability of each outcome represented on the tree (see Figure 10.6 ). Follow these steps:

Draw a square on a piece of paper or whiteboard to represent a decision point. Draw lines from the square representing a range of options that can be taken. At the end of the line for each option indicate whether further options are available (by drawing an oval followed by more lines) or by designating an outcome (by drawing a circle followed by one or more lines describing the range of possibilities). Continue this process along each branch of the tree until all options and outcomes are specified. Once the tree has been constructed, do the following:

Establish a set of percentages (adding to 100) for each set of lines emanating from each oval. Multiply the percentages shown along each critical path or branch of the tree and record these percentages at the far right of the tree. Check to make sure all the percentages in this column add to 100.

Description Figure 10.6 Counterterrorism Attack Decision Tree

The most valuable or most probable outcome will have the highest percentage assigned to it, and the least valuable or least probable outcome will have the lowest percentage assigned to it.

Potential Pitfalls

A Decision Tree is only as good as the reliability of the data, completeness of the range of options, and validity of the qualitative probabilities or values assigned to each option. A detailed Decision Tree can present the misleading impression that the authors have thought of all possible options or outcomes. For example, options may be available that the authors of the analysis did not imagine, just as there might be unintended consequences that the authors did not anticipate.

Relationship to Other Techniques

A Decision Tree is similar structurally to Critical Path Analysis and P rogram E valuation and R eview T echnique (PERT) charts. Both of these techniques, however, only show the activities and connections that need to be undertaken to complete a complex task. A timeline analysis (as is often done in support of a criminal investigation) is essentially a Decision Tree drawn after the fact, showing only the paths of actual events.

Origins of This Technique

This description of Decision Trees was taken from the Canadian government's Structured Analytic Techniques for Senior Analysts course. The Intelligence Analyst Learning Program developed the course, and the materials are used here with the permission of the Canadian government. More detailed discussions of how to build and use Decision Trees are readily available on the internet, for example, at the MindTools website and at https://medium.com/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb .

10.7 Decision Matrix

A Decision Matrix helps analysts identify the course of action that best achieves specified goals or preferences.

When to Use It

The Decision Matrix technique should be used when a decision maker has multiple options from which to choose, has multiple criteria for judging the desirability of each option, and/or needs to find the decision that maximizes a specific set of goals or preferences. For example, a Decision Matrix can help choose among various plans or strategies for improving intelligence analysis, select one of several IT systems one is considering buying, determine which of several job applicants is the right choice, or consider any personal decision, such as what to do after retiring.

A Decision Matrix is not applicable to most intelligence analysis, which typically deals with evidence and judgments rather than goals and preferences. It can be used, however, for supporting a decision maker's consideration of alternative courses of action. Analysts can use the tool in a Red Hat Analysis to demonstrate the possible choices a leader might make when faced with a given situation or to help decision makers or clients see the potential effect of a policy choice or business decision. It can also be used at the conclusion of a Foresight workshop to identify optimal strategies for making good scenarios happen or mitigate the impact of bad scenarios.

Value Added

By deconstructing a decision into its component parts, the Decision Matrix technique makes it easier to identify areas of disagreement or hidden assumptions and determine their impact on the decision. Listing all the options or possible choices, the criteria for judging the options, the weights assigned to each of these criteria, and an evaluation of the extent to which each option satisfies each of these criteria makes the analytic process transparent. All the judgments are available for anyone to see—and challenge—by looking at the matrix.

Because it is so explicit, the matrix can play an important role in facilitating communication among those who are involved in, or affected by, the decision process. It can be easy to identify areas of disagreement and to determine whether such disagreements have any material impact on the decision. One can also see how sensitive a decision is to changes that might be made to the values assigned to the selection criteria or to the ability of an option to satisfy the criteria. If circumstances or preferences change, it is easy to go back to the matrix, make changes, and calculate the impact of the changes on the proposed decision.

The matrix helps decision makers and analysts avoid the cognitive traps of Premature Closure, Satisficing, and the Anchoring Effect. It also helps analysts avoid falling prey to intuitive traps such as Relying on First Impressions, Assuming a Single Solution, and Overrating Behavioral Factors.

The Method

Create a Decision Matrix table. To do this, break down the decision problem into two main components by making two lists—a list of options or alternatives for making a choice and a list of criteria to be used when judging the desirability of the options. Then follow these steps:

Create a matrix with one column for each option. Write the name of each option at the head of one of the columns. Add two more blank columns on the left side of the table. Count the number of selection criteria, and then adjust the table so that it has that many rows plus two more: one at the top to list the options and one at the bottom to show the scores for each option. Try to avoid generating a large number of criteria: usually four to six will suffice. In the first column on the left side, starting with the second row, write in the selection criteria down the left side of the table, one per row. Listing them roughly in order of importance can sometimes add value but doing so is not critical. Leave the bottom row blank. ( Note : Whether you enter the options across the top row and the criteria down the far-left column, or vice versa, depends on what fits best on the page. If one of the lists is significantly longer than the other, it usually works best to put the longer list in the left-side column.) Assign weights based on the importance of each of the selection criteria. This can be done in several ways, but the preferred way is to take 100 percent and divide these percentage points among the selection criteria. Be sure that the weights for all the selection criteria combined add to 100 percent. Also, be sure that all the criteria are phrased in such a way that a higher weight is more desirable. (Note: If this technique is being used by an intelligence analyst to support decision making, this step should not be done by the analyst. The assignment of relative weights is up to the decision maker.) Work across the matrix one row at a time to evaluate the relative ability of each of the options to satisfy each of the selection criteria. For example, assign ten points to each row and divide these points according to an assessment of the degree to which each of the options satisfies each of the selection criteria. Then multiply this number by the weight for that criterion. Figure 10.7 is an example of a Decision Matrix with three options and six criteria. Add the numbers calculated in the columns for each of the options. If you accept the judgments and preferences expressed in the matrix, the option with the highest number will be the best choice.

When using this technique, many analysts will discover relationships or opportunities not previously recognized. A sensitivity analysis may find that plausible changes in some values would lead to a different choice. For example, the analyst might think of a way to modify an option in a way that makes it more desirable or might rethink the selection criteria in a way that changes the preferred outcome. The numbers calculated in the matrix do not make the decision. The matrix is just an aid to help the analyst and the decision maker understand the trade-offs between multiple competing preferences.

Figure 10.7 Decision Matrix

Origins of This Technique

This is one of the most commonly used techniques for decision analysis. Many variations of this basic technique have been called by many different names, including decision grid, Multiple Attribute Utility Analysis (MAUA), Multiple Criteria Decision Analysis (MCDA), Multiple Criteria Decision Making (MCDM), Pugh Matrix, and Utility Matrix. For a comparison of various approaches to this type of analysis, see Panos M. Parlos and Evangelos Triantaphyllou, eds., Multi-Criteria Decision Making Methods: A Comparative Study (Dordrecht, Netherlands: Kluwer Academic Publishers, 2000).

10.8 Force Field Analysis

Force Field Analysis is a simple technique for listing and assessing all the forces for and against a change, problem, or goal.

Kurt Lewin, one of the fathers of modern social psychology, believed that all organizations are systems in which the present situation is a dynamic balance between forces driving for change and forces restraining change. For any change to occur, the driving forces must exceed the restraining forces, and the relative strength of these forces is what this technique measures. This technique is based on Lewin's theory. 3

When to Use It

Force Field Analysis is useful in the early stages of a project or research effort when the analyst is defining the issue, gathering data, or developing recommendations for action. It requires that the analyst clearly define the problem in all its aspects. The technique aids in structuring the data and assessing the relative importance of each of the forces affecting the issue. It can also help the analyst overcome the natural human tendency to dwell on the aspects of the data that are most comfortable. An individual analyst or a small team can use this technique.

In the world of business and politics, the technique can help develop and refine strategies to promote a particular policy or ensure that a desired outcome actually occurs. In such instances, it is often useful to define the various forces in terms of key individuals who need to be persuaded. For example, instead of listing budgetary restrictions as a key factor, one would write down the name of the person who controls the budget. Similarly, Force Field Analysis can help diagnose what forces and individuals need to be constrained or marginalized to prevent a policy from being adopted or an outcome from happening.

Value Added

The primary benefit of Force Field Analysis is that it requires an analyst to consider the forces and factors (and, in some cases, individuals) that influence a situation. It helps analysts think through the ways various forces affect the issue and fosters recognition that such forces can be divided into two categories: driving forces and restraining forces. By sorting the evidence into two categories, the analyst can delve deeply into the issue and consider less obvious factors.

By weighing all the forces for and against an issue, analysts can better recommend strategies that would be most effective in reducing the impact of the restraining forces and strengthening the effect of the driving forces.

Force Field Analysis offers a powerful way to visualize the key elements of the problem by providing a simple tally sheet for displaying the different levels of intensity of the forces individually and together. With the data sorted into two lists, decision makers can more easily identify which forces deserve the most attention and develop strategies to overcome the negative elements while promoting the positive elements. Figure 10.8 is an example of a Force Field diagram.

An issue is held in balance by the interaction of two opposing sets of forces—those seeking to promote change (driving forces) and those attempting to maintain the status quo (restraining forces).

—Kurt Lewin, Resolving Social Conflicts (1948)

Description Figure 10.8 Force Field Analysis: Removing Abandoned Cars from City Streets Source: Pherson Associates, LLC, 2019.

Force Field Analysis is a powerful tool for reducing the impact of several of the most common cognitive biases and heuristics: Premature Closure, Groupthink, and the Availability Heuristic. It also is a useful weapon against the intuitive traps of Relying on First Impressions, Expecting Marginal Change, and Assuming a Single Solution.

The Method

Define the problem, goal, trend, or change clearly and concisely. Brainstorm to identify the forces that will most influence the issue. Consider such topics as needs, resources, costs, benefits, organizations, relationships, attitudes, traditions, and interests. Other forces and factors to consider are social and cultural trends, rules and regulations, policies, values, popular desires, and leadership to develop the full range of forces promoting and restraining the factors involved. Make one list showing the forces or personalities "driving" change and a second list showing the forces or personalities "restraining" change. Assign a value (the intensity score) to each driving or restraining force to indicate its strength. Give the weakest intensity scores a value of 1 (weak) and the strongest a value of 5 (strong). The same intensity score can be assigned to more than one force if the analyst considers the factors equal in strength. List the intensity scores in parentheses beside each item. Examine the two lists to determine if any of the driving forces balance out or neutralize the restraining forces. Devise a manageable course of action to strengthen the forces that lead to the preferred outcome and weaken the forces that would hinder the desired outcome.

Analysts should keep in mind that the preferred outcome may be either promoting a change or restraining a change. For example, if the problem is increased drug use or criminal activity, the analysis would focus on the factors that would have the most impact on restraining criminal activity or drug use. On the other hand, if the preferred outcome is improved border security, the analyst would highlight the drivers that would be most likely to promote border security if strengthened.

Potential Pitfalls

When assessing the balance between driving and restraining forces, the authors recommend caution not to add up the scores on each side and concluding that the side with the most points will win. Any numerical calculation can be easily manipulated by simply adding more forces or factors to either list to increase its overall score.

Origins of This Technique

Force Field Analysis is widely used in social science and business research. (A Google search on the term brings up more than seventy-one million hits.) This version of the technique is found in Randolph H. Pherson, Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019). To learn more about the Decision Matrix techniques, visit https://asq.org/quality-resources/decision-matrix .

10.9 Pros-Cons-Faults-and-Fixes

Pros-Cons-Faults-and-Fixes is a strategy for critiquing new policy ideas. It is intended to offset the human tendency of a group of analysts and decision makers to jump to a conclusion before completing a full analysis of the problem.

When to Use It

Making lists of pros and cons for any action is a common approach to decision making. Finding "Faults" and "Fixes" distinguishes this technique from a simple "Pros and Cons" approach. Use this technique to make a quick appraisal of a new idea or a more systematic analysis of a choice between two options.

One advantage of Pros-Cons-Faults-and-Fixes is its applicability to virtually all types of decisions. Of the various structured techniques for decision making, it is one of the easiest and quickest to use. It requires only a certain procedure for making the lists and discussing them with others to solicit divergent input.

In the business world, the technique can help discover potential vulnerabilities in a proposed strategy to introduce a new product or acquire a new company. By assessing how Pros can be "Faulted," one can anticipate how competitors might react to a new corporate initiative; by assessing how Cons can be "Fixed," potential vulnerabilities can be addressed, and major mistakes avoided early in the planning process.

Value Added

It is unusual for a new idea to meet with instant approval. What often happens in meetings is that a new idea is brought up, one or two people immediately explain why they don't like it or believe it won't work, and the idea is then dropped. On the other hand, there are occasions when just the opposite happens. A new idea is immediately welcomed, and a commitment to support it is made before the idea is critically evaluated. The Pros-Cons-Faults-and-Fixes technique helps to offset this human tendency to jump to conclusions.

The technique first requires a list of Pros and Cons about the new idea or the choice between two alternatives. If there seems to be excessive enthusiasm for an idea and a risk of acceptance without critical evaluation, the next step is to look for "Faults." A Fault is any argument that a Pro is unrealistic, won't work, or will have unacceptable side effects. On the other hand, if there seems to be a bias toward negativity or a risk of the idea being dropped too quickly without careful consideration, the next step is to look for "Fixes." A Fix is any argument or plan that would neutralize or minimize a Con, or even change it into a Pro. In some cases, it may be appropriate to look for both Faults and Fixes before comparing the two lists and finalizing a decision.

The Pros-Cons-Faults-and-Fixes technique does not tell an analyst whether the decision or strategy is "good" or not, nor does it help decide whether the Pros or the Cons have the strongest argument. That answer is still based on an analyst's professional judgment. The purpose of the technique is to offset any tendency to rush to judgment. It organizes the elements of the problem logically and helps ensure that the analyst considers both sides of a problem or issue systematically. Documenting the elements of a problem and taking the time to reflect whether all parties would view each element the same way helps the analyst and decision maker see things more clearly and become more objective and emotionally detached from the decision (see Figure 10.9 ).

The technique militates against classic biases and misapplied heuristics including Groupthink, Satisficing, and the Anchoring Effect. It also protects against Projecting Past Experiences, Overrating Behavioral Factors, and Overinterpreting Small Samples.

The Method

Start by clearly defining the proposed action or choice. Then follow these steps:

List the Pros in favor of the decision or choice. Think broadly and creatively, and list as many benefits, advantages, or other positives as possible. List the Cons, or arguments against what is proposed. The Cons usually will outnumber the Pros, as most humans are naturally critical. It is often difficult to get a careful consideration of a new idea because it is easier to think of arguments against something new than to imagine how the new idea might work.

Figure 10.9 Pros-Cons-Faults-and-Fixes Analysis Review each list and consolidate similar ideas. If two Pros are similar or overlapping, consider merging them to eliminate any redundancy. Do the same for any overlapping Cons.

If the choice is between two clearly defined options, go through the previous steps for the second option. If there are more than two options, a technique such as the Decision Matrix may be more appropriate than Pros-Cons-Faults-and-Fixes.

Decide whether the goal is to demonstrate that an idea will not work or show how best to make it succeed. If the goal is to challenge an initial judgment that an idea will not work, take the Cons and see if they can be "Fixed." How can their influence be neutralized? Can you even convert them to Pros? Four possible strategies are to

Propose a modification of the Con that would significantly lower the risk of the Con being a problem. Identify a preventive measure that would significantly reduce the chances of the Con being a problem. Create a contingency plan that includes a change of course if certain indicators are observed. Identify a need for further research to confirm the assumption that the Con is a problem. If the goal is to challenge an initial optimistic assumption that the idea will work and should be pursued, take the Pros, one at a time, and see if they can be "Faulted." That means to try to figure out how the Pro might fail to materialize or have undesirable consequences. This exercise is intended to counter any wishful thinking or unjustified optimism about the idea. A Pro might be Faulted in at least three ways:

Identify a reason why the Pro would not work or why the benefit would not be received. Identify an undesirable side effect that might accompany the benefit. Identify a need for further research or information gathering to confirm or refute the assumption that the Pro will work or be beneficial. A third option is to combine both approaches: to Fault the Pros and Fix the Cons. Compare the Pros, including any Faults, against the Cons, including the Fixes. Weigh one against the other and make the choice. The choice is based on your professional judgment, not on any numerical calculation of the number or value of Pros versus Cons.

Potential Pitfalls

Often when listing the Pros and Cons, analysts will assign weights to each Pro and Con on the list and then re-sort the lists, with the Pros or Cons receiving the most points at the top of the list and those receiving the fewest points at the bottom. This can be a useful exercise, helping the analyst weigh the balance of one against the other, but the authors strongly recommend against mechanically adding up the scores on each side and deciding that the list with the most points is the right choice. Any numerical calculation can be easily manipulated by simply adding more Pros or more Cons to either list to increase its overall score. The best protection against this practice is simply not to add up the points in either column.

Origins of This Technique

Pros-Cons-Faults-and-Fixes is Richards J. Heuer Jr.'s adaptation of the Pros-Cons-and-Fixes technique described by Morgan D. Jones in The Thinker's Toolkit: Fourteen Powerful Techniques for Problem Solving (New York: Three Rivers Press, 1998), 72–79. Jones assumed that humans are "compulsively negative" and that "negative thoughts defeat creative objective thinking." Thus, his technique focused only on Fixes for the Cons. The technique described here recognizes that analysts and decision makers can also be biased by overconfidence, in which case Faulting the Pros may be more important than Fixing the Cons.

10.10 Complexity Manager

Complexity Manager helps analysts and decision makers understand and anticipate changes in complex systems. As used here, the word "complexity" encompasses any distinctive set of interactions that are more complicated than even experienced analysts can think through solely in their heads. 4

When to Use It

As a policy support tool, Complexity Manager can help assess the chances for success or failure of a new or proposed program or policy and identify opportunities for influencing the outcome of any situation. It is also useful in identifying what would have to change to achieve a specified goal as well as the unintended consequences from the pursuit of a policy goal.

When trying to foresee future events, both the intelligence and business communities have typically dealt with complexity by doing the following:

Assuming that the future is unpredictable and generating alternative future scenarios and indicators that can be tracked to obtain early warning of which future is emerging. Developing or contracting for complex computer models and simulations of how the future might play out. This practice is costly in time and money and often of limited practical value to the working analysts. Making multiple assumptions and relying on the analyst's intuition or expert judgment to generate a best guess of how things will work out.

The use of Complexity Manager is a fourth approach that may be preferable in some circumstances, especially in cases of what one might call "manageable complexity." It can help decision makers ask better questions and anticipate problems.

Complexity Manager is different from other methods for dealing with complexity, because we believe the average analyst who lacks advanced quantitative skills can use it. There is no need for programs such as Causal Loop Diagramming or Block-Flow Diagramming commonly used in System Dynamics Analysis.

Value Added

We all know that we live in a complex world of interdependent political, economic, social, and technological systems in which each event or change has multiple effects. These effects then affect other elements of the system. Although we understand this, we usually do not analyze the world in this way, because the multitude of potential interactions is too difficult for the human brain to track simultaneously. As a result, analysts often fail to foresee future problems or opportunities that may be generated by current trends and developments. Or they fail to foresee the undesirable side effects of well-intentioned policies. 5

Complexity Manager can often improve an analyst's understanding of a complex situation without the time delay and cost required to build a computer model and simulation. The steps in the Complexity Manager technique are the same as the initial steps required to build a computer model and simulation. These are identification of the relevant variables or actors, analysis of all the interactions between them, and assignment of rough weights or other values to each variable or interaction.

Scientists who specialize in the modeling and simulation of complex social systems report that "the earliest—and sometimes most significant—insights occur while reducing a problem to its most fundamental players, interactions, and basic rules of behavior," and that "the frequency and importance of additional insights diminishes exponentially as a model is made increasingly complex." 6 In many cases the Complexity Manager is likely to provide much, although not all, of the benefit one could gain from computer modeling and simulation, but without the time lag and contract costs. However, if key variables are quantifiable with changes that are trackable over time, it would be more appropriate to use a quantitative modeling technique such as System Dynamics.

Complexity Manager, like most Structured Analytic Techniques, does not itself provide analysts with answers. It enables analysts to find a best possible answer by organizing in a systematic manner the jumble of information about many relevant variables. It helps analysts comprehend the whole problem, not just one part of the problem at a time. Analysts can then apply their expertise to make an informed judgment about the problem. This structuring of the analyst's thought process also provides the foundation for a well-organized report that clearly presents the rationale for each conclusion. This may also lead to some form of visual presentation, such as a Concept Map or Mind Map, or a causal or influence diagram.

It takes time to work through the Complexity Manager process, but it may save time in the long run. This structured approach helps analysts work efficiently without getting mired down in the complexity of the problem. Because it produces a better and more carefully reasoned product, it also saves time during the editing and coordination processes.

The Complexity Manager is helpful in reducing the influence of many cognitive biases and misapplied heuristics, among them, Premature Closure, Mental Shotgun, and the Availability Heuristic. It also helps mitigate the impact of several intuitive traps including Relying on First Impressions, Overinterpreting Small Samples, and Overestimating Probability.

The Method

Complexity Manager requires the analyst to proceed through eight specific steps:

Define the problem. State the problem (plan, goal, outcome) to be analyzed, including the time period covered by the analysis. Identify and list relevant variables. Use one of the brainstorming techniques described in chapter 6 to identify the significant variables (factors, conditions, people, etc.) that may affect the situation of interest during the designated time period. Think broadly to include organizational or environmental constraints that are beyond anyone's ability to control. If the goal is to estimate the status of one or more variables several years in the future, those variables should be at the top of the list. Group the other variables in some logical manner with the most important variables at the top of the list. Create a Cross-Impact Matrix. Create a matrix in which the number of rows and columns are each equal to the number of variables plus one header row (see chapter 7 ). Leaving the cell at the top-left corner of the matrix blank, enter all the variables in the cells in the row across the top of the matrix and the same variables in the column down the left side. The matrix then has a cell for recording the nature of the relationship between all pairs of variables. This is called a Cross-Impact Matrix—a tool for assessing the two-way interaction between each pair of variables. Depending on the number of variables and the length of their names, it may be convenient to use the variables' letter designations across the top of the matrix rather than the full names.

When deciding whether to include a variable, or to combine two variables into one, keep in mind that the number of variables has a significant impact on the complexity and the time required for an analysis. If an analytic problem has five variables, there are 20 possible two-way interactions between those variables. That number increases rapidly as the number of variables increases. With 10 variables, as in Figure 10.10 , there are 90 possible interactions. With 15 variables, there are 210. Complexity Manager may be impractical with more than 15 variables. Assess the interaction between each pair of variables. Use a diverse team of experts on the relevant topic to analyze the strength and direction of the interaction between each pair of variables. Enter the results in the relevant cells of the matrix. For each pair of variables, ask the question: Does this variable affect the paired variable in a manner that will increase or decrease the impact or influence of that variable?

When entering ratings in the matrix, it is best to take one variable at a time, first going down the column and then working across the row. Note that the matrix requires each pair of variables to be evaluated twice—for example, the impact of variable A on variable B and the impact of variable B on variable A. To record what variables impact variable A, work down column A and ask yourself whether each variable listed on the left side of the matrix has a positive or negative influence, or no influence at all, on variable A. To record the reverse impact of variable A on the other variables, work across row A to analyze how variable A impacts the variables listed across the top of the matrix.

Analysts can record the nature and strength of impact that one variable has on another in two different ways. Figure 10.10 uses plus and minus signs to show whether the variable being analyzed has a positive or negative impact on the paired variable. The size of the plus or minus sign signifies the strength of the impact on a three-point scale. The small plus or minus sign shows a weak impact; the medium size a medium impact; and the large size a strong impact. If the variable being analyzed has no impact on the paired variable, the cell is left empty. If a variable might change in a way that could reverse the direction of its impact, from positive to negative or vice versa, this is shown by using both a plus and a minus sign.

The completed matrix shown in Figure 10.10 is the same matrix you will see in chapter 11 , when the Complexity Manager technique is used to forecast the future of Structured Analytic Techniques. The plus and minus signs work well for the finished matrix. When first populating the matrix, however, it may be easier to use letters ( P and M for plus and minus) to show whether each variable has a positive or negative impact on the other variable with which it is paired. Each P or M is then followed by a number to show the strength of that impact. A three-point scale is used, with 3 indicating a Strong Impact, 2 Medium, and 1 Weak.

After rating each pair of variables, and before doing further analysis, consider pruning the matrix to eliminate variables that are unlikely to have a significant effect on the outcome. It is possible to measure the relative significance of each variable by adding up the weighted values in each row and column. The sum of the weights in each row is a measure of each variable's impact on the entire system. The sum of the weights in each column is a measure of how much each variable is affected by all the other variables. Those variables most impacted by the other variables should be monitored as potential indicators of the direction in which events are moving or as potential sources of unintended consequences. Analyze direct impacts. Document the impact of each variable, starting with variable A. For each variable, provide further clarification of the description, if necessary. Identify all the variables that have an impact on that variable with a rating of 2 or 3, and briefly explain the nature, direction, and, if appropriate, the timing of this impact. How strong is it and how certain is it? When might these effects be observed? Will the effects be felt only in certain conditions? Next, identify and discuss all variables on which this variable has an effect with a rating of 2 or 3 (Medium or Strong Impact), including the strength of the impact and how certain it is to occur. Identify and discuss the potentially good or bad side effects of these impacts.

Analyze loops and indirect impacts. The matrix shows only the direct effect of one variable on another. When you are analyzing the direct impacts variable by variable, there are several things to look for and make note of. One is feedback loops. For example, if variable A has a positive impact on variable B, and variable B also has a positive impact on variable A, this is a positive feedback loop. Or there may be a three-variable loop, from A to B to C and back to A. The variables in a loop gain strength from one another, and this boost may enhance their ability to influence other variables. Another thing to look for is circumstances where the causal relationship between variables A and B is necessary but not sufficient for something to happen. For example, variable A has the potential to influence variable B, and may even be trying to influence variable B, but it can do so effectively only if variable C is also present. In that case, variable C is an enabling variable and takes on greater significance than it ordinarily would have.

Description Figure 10.10 Variables Affecting the Future Use of Structured Analysis

All variables are either static or dynamic. Static variables are expected to remain unchanged during the period covered by the analysis. Dynamic variables are changing or have the potential to change. The analysis should focus on the dynamic variables, as these are the sources of surprise in any complex system. Determining how these dynamic variables interact with other variables and with each other is critical to any forecast of future developments. Dynamic variables can be either predictable or unpredictable. Predictable change includes established trends or established policies that are in the process of being implemented. Unpredictable change may be a change in leadership or an unexpected change in policy or available resources. Draw conclusions. Using data about the individual variables assembled in steps 5 and 6, draw conclusions about the entire system. What is the most likely outcome, or what changes might be anticipated during the specified time period? What are the driving forces behind that outcome? What things could happen to cause a different outcome? What desirable or undesirable side effects should be anticipated? If you need help to sort out all the relationships, it may be useful to sketch out by hand a diagram showing all the causal relationships. A Concept Map ( chapter 6 ) may be useful for this purpose. If a diagram is helpful during the analysis, it may also be helpful to the reader or customer to include such a diagram in the report. Conduct an opportunity analysis. When appropriate, analyze what actions could be taken to influence this system in a manner favorable to the primary customer of the analysis.

Relationship to Other Techniques

The same procedures for creating a matrix and coding data can be applied in using a Cross-Impact Matrix ( chapter 7 ). The difference is that the Cross-Impact Matrix technique is used only to identify and share information about the cross-impacts in a group or team exercise. The goal of Complexity Manager is to build on the Cross-Impact Matrix to analyze the working of a complex system.

If the goal is to identify alternative scenarios and early warning of future directions of change, especially in a highly uncertain environment, a form of Foresight analysis rather than Complexity Manager would be more appropriate. Use a computerized modeling system such as System Dynamics rather than Complexity Manager when changes over time in key variables can be quantified or when there are more than fifteen variables to be considered. 7

Origins of This Technique

Richards J. Heuer Jr. developed Complexity Manager to fill an important gap in structured techniques available to the average analyst. It is a simplified version of older quantitative modeling techniques, such as System Dynamics.

Notes

1. See Graham T. Allison and Philip Zelikow, Essence of Decision: Explaining the Cuban Missile Crisis, 2nd ed. (New York: Addison-Wesley, 1999).

2. Heinz Weihrich, "The TOWS Matrix—A Tool for Situational Analysis," Long Range Planning 15, no. 2 (April 1982): 54–66.

3. Kurt Lewin, Resolving Social Conflicts: Selected Papers on Group Dynamics (New York: Harper & Row, 1948).

4. Seth Lloyd, a specialist in complex systems, has listed thirty-two definitions of complexity . See Seth Lloyd, Programming the Universe (New York: Knopf, 2006).

5. Dietrich Dorner, The Logic of Failure (New York: Basic Books, 1996).

6. David S. Dixon and William N. Reynolds, "The BASP Agent-Based Modeling Framework: Applications, Scenarios, and Lessons Learned," Proceedings of the 36th Annual Hawaii International Conference on System Sciences (February 2003), https://www.academia.edu/797988/The_BASP_Agent-Based_Modeling_Framework_Applications_Scenarios_and_Lessons_Learned_with_William_N._Reynolds . Also see Donnella H. Meadows and J. M. Robinson, The Electronic Oracle: Computer Models and Social Decisions (New York: Wiley, 1985).

7. John Sterman, Business Dynamics: Systems Thinking and Modeling for a Complex World (New York: McGraw-Hill, 2000).

Descriptions of Images and Figures

Back to Figure

Hazard or opportunity, cause or trend consisting of preventive barrier or accelerator, escalation factor consisting of EF barrier or accelerator for their recovery, and consequences with recovery barrier or amplifier leads to risk event or opportunity event. Causes are anticipatory and consequences are reactive.

Back to Figure

Stimulus leads to response, which leads to different forms of instability. The sources of grievances and conflict are domestic or international, intellectual, social, political, economic, and military. This is the stimulus. Opposition's ability to articulate grievance or mobilize discontent leads to government or society's capacity to respond. This is the response. Responses include legitimacy or leadership, resource availability or responsiveness, institutional strength, and monopoly of coersive force. The response leads to grievance and conflict, and different forms of instability. All and legitimate instability is peaceful political change. Elite and illegitimate instability are conspiracy or coups d'etat, internal war or insurgencies, and group-on-group violence. Mass and illegitimate stability are turmoil, internal war or insurgencies, and group-on-group violence.

Back to Figure

A suspected terrorist is either arrested or not arrested. If arrested, they are either interrogated or released. If interrogated, the plot to attack is described, or there is no evidence of plot. If the terrorist is not arrested, they are either under no surveillance or under surveillance. If they are under surveillance, there is no evidence of plotting or they meet with known terrorist. If there is meeting, then place covert agent, who either discovers plans to attack or gets killed, or arrest all suspects to be detained in jail or released on bail.

Back to Figure

Note: The number value and size of the type indicate the significance of each argument. With increase in the number value, the size of the type increases. The arguments corresponding to each number value are as follows. 1: The definition of "abandoned cars" is unclear to the public. 2: The public climate favors cleaning up the city. It is difficult to locate abandoned cars. Health Department has cited old and abandoned vehicles as potential health hazards. 3: A procedure is needed to verify a car's status and notify owners. Advocacy groups have expressed interest. The owners of old cars feel threatened. Locating and disposing of cars will be expensive. 4: The City Council supports the plan. A location is needed to put the abandoned cars once identified. 5: Local auto salvage yards will remove cars for free. The public service director supports the plan.

Back to Figure

Reading the matrix: The cells in each row show the impact of the variable represented by that row on each of the variables listed across the top of the matrix. The cells in each column show the impact of each variable listed down the left side of the matrix on the variable represented by the column. Combination of positive and negative means impact could go either direction. Empty cell equals no impact.

A

B

C

D

E

F

G

H

I

J

A Increased use of Structured Analytic Techniques

Nil

Strong positive

Positive

Nil

Strong positive and strong negative

Weak positive and weak negative

Medium positive

Strong positive and strong negative

Medium positive and medium negative

Medium negative

B Executive support for collaboration and Structured Analytic Techniques

Strong positive

Nil

Strong positive

Medium positive

Medium positive

Medium positive and medium negative

Medium positive

Strong positive and strong negative

Weak positive and weak negative

Medium negative

Availability of virtual technologies

Strong positive

Medium positive

Nil

Medium positive

Medium positive

Nil

Strong positive

Nil

Weak positive and weak negative

Nil

D Generational change

Strong positive

Medium positive

Medium positive

Nil

Weak positive

Nil

Nil

Weak positive and weak negative

Weak negative

Weak positive

E Availability of analytic tradecraft support

Strong positive and strong negative

Strong positive and strong negative

Medium positive and medium negative

Nil

Nil

Nil

Weak positive and weak negative

Weak positive and weak negative

Medium positive and medium negative

Weak positive

F

Change in budget for analysis

Strong negative

Medium negative

Medium negative

Medium negative

Strong negative

Nil

Nil

Strong positive and strong negative

Nil

Nil

G

Charge in client preferences for collaborative, digital products

Medium positive

Weak positive

Medium positive

Nil

Medium positive and medium negative

Medium positive and medium negative

Nil

Weak positive

Medium negative

Nil

H Research on effectiveness of Structured Analytic Techniques

Strong positive and strong negative

Medium positive and medium negative

Nil

Nil

Medium positive and medium negative

Weak positive and weak negative

Weak positive and weak negative

Nil

Medium positive and medium negative

Strong positive and strong negative

I

Analysts' perception of time pressure

Medium positive and medium negative

Medium positive and medium negative

Nil

Nil

Weak positive

Nil

Nil

Nil

Nil

Medium positive

J

Lack of openness to change among senior analysts or managers

Medium negative

Medium negative

Nil

Nil

Medium negative

Nil

Nil

Nil

Medium positive and medium negative

Nil

Chapter 11 The Future of Structured Analytic Techniques

11.1 Limits of Empirical Analysis [ 349 ] 11.2 Purpose of Structured Techniques [ 351 ] 11.3 Projecting the Trajectory of Structured Techniques [ 353 ]

11.3.1 Structuring the Data [ 354 ] 11.3.2 Identifying Key Drivers [ 356 ] 11.4 Role of Structured Techniques in 2030 [ 358 ]

S ince the term Structured Analytic Techniques was first introduced in 2005, a persistent and unresolved debate has centered on the question of their effectiveness in generating higher-quality analysis. Testing the value of these techniques in the U.S. Intelligence Community has been done largely through the process of using them. That experience has certainly been successful, but it has not been enough to convince skeptics reluctant to change their long-ingrained habits. Nor has it persuaded academics accustomed to looking for hard, empirical evidence. Similar questions have arisen regarding the use of Structured Analytic Techniques in business, medicine, and other fields that consistently deal with probabilities and uncertainties rather than hard data.

11.1 Limits of Empirical Analysis

A few notable studies have evaluated the efficacy of structured techniques. A RAND study in 2016, for example, found that intelligence publications using the techniques generally addressed a broader range of potential outcomes and implications than did other analyses, but that more controlled experiments were needed to provide a complete picture of their contribution to intelligence analysis. 1

Coulthart in his 2015 doctoral dissertation, "Improving the Analysis of Foreign Affairs: Evaluating Structured Analytic Techniques," evaluates the use of twelve core techniques in the U.S. Intelligence Community. 2 His study found moderate to strong evidence affirming the efficacy of using Analysis of Competing Hypotheses, Brainstorming, and Devil's Advocacy. Other findings were that face-to-face collaboration decreases creativity, weighting evidence appears to be more valuable than seeking disconfirming evidence, and conflict improves the quality of analysis.

Chang et al., in a 2018 article, "Restructuring Structured Analytic Techniques in Intelligence," identify two potential problems that could undercut the effectiveness of structured techniques. 3 First, Structured Analytic Techniques treat all biases as unipolar when, in fact, many are bipolar. For example, analysts using structured techniques to mitigate the impact of Confirmation Bias, which would make them too confident in the soundness of their key judgments, could trigger the opposing problem of under-confidence. Second, many structured techniques involve the process of decomposing a problem into its constituent parts. No one has tested, however, whether the process of decomposition is adding or subtracting noise from the analytic process. They suspect that, on balance, decomposition is most likely to degrade the reliability of analytic judgments. As they conclude—and the authors agree—more sustained scientific research is needed to determine whether these and other shortcomings pose problems when evaluating the utility of structured techniques in improving analytic reasoning.

Efforts to conduct such qualitative studies, however, confront several obstacles not usually encountered in other fields of study. Findings from empirical experiments can be generalized to apply to intelligence analysis or any other specific field only if the test conditions match the conditions in which the analysis is conducted. Because so many variables can affect the research results, it is extremely difficult to control for all, or even most, of them. These variables include the purpose for which a technique is used, implementation procedures, context of the experiment, nature of the analytic task, differences in analytic experience and skill, and whether the analysis is done by a single analyst or as a group process. All of these variables affect the outcome of any experiment that ostensibly tests the utility of a Structured Analytic Technique. Many of these same challenges are present, and should be factored into, efforts by intelligence organizations to formalize processes for evaluating the quality of papers produced by their analysts.

Two specific factors raise questions about the practical feasibility of valid empirical testing of Structured Analytic Techniques as used in intelligence analysis. First, these techniques are commonly used as a group process. That would require testing with groups of analysts rather than individual analysts. Second, intelligence deals with issues of high uncertainty. Former Central Intelligence Agency director Michael Hayden wrote that because of the inherent uncertainties in intelligence analysis, a record of 70 percent accuracy is a good performance. 4 If this is true, a single experiment testing the use of a structured technique that leads to a wrong answer does not prove the lack of effectiveness of the technique. Multiple repetitions of the same experiment would be needed to evaluate how often the analytic judgments were accurate.

Many problems could largely be resolved if experiments were conducted with intelligence analysts using techniques as they are used every day to analyze typical intelligence issues. 5 But even if such conditions were met, major obstacles to meaningful conclusions would remain. Since many Structured Analytic Techniques can be used for several purposes, research findings on the effectiveness of these techniques can be generalized and applied to the intelligence community only if the techniques are used in the same way and for the same purpose as actually used by intelligence analysts.

Philip Tetlock, for example, in his pathbreaking book, Expert Political Judgment , describes two experiments that show scenario development may not be an effective analytic technique. The experiments compared judgments on a political issue before and after the test subjects prepared scenarios to try to gain a better understanding of the issues. 6 The experiments showed that the predictions by both experts and nonexperts were more accurate before generating the scenarios; in other words, the generation of scenarios actually reduced the accuracy of their predictions. Several experienced analysts have separately cited this finding as evidence that scenario development may not be a useful method for intelligence analysis. 7

However, Tetlock's conclusions should not be generalized to apply to intelligence analysis, as his experiments tested scenarios as a predictive tool. The intelligence community does not use scenarios for prediction. Scenario development is best used to describe several outcomes or futures that a decision maker should consider because intelligence is unable to predict a single outcome with reasonable certainty. For most decision makers, the most important product generated by Foresight analysis is the identification of a set of key drivers that will likely determine how the future will evolve. These drivers then can be leveraged by the decision maker to mitigate harmful scenarios and facilitate the emergence of beneficial scenarios. Two other often-cited benefits are the discovery of emerging trends and the identification of indicators and milestones for each scenario. The indicators and milestones can then be monitored to gain early warning of the direction in which events seem to be heading. Tetlock's experiments did not use scenarios in this way.

11.2 Purpose of Structured Techniques

We believe the easiest way to assess the value of Structured Analytic Techniques is to look at the purpose for which a technique is used. Once that is established, the next step is to determine whether it achieves that purpose, or some better way exists to achieve that same purpose.

A key distinction in this debate is that Structured Analytic Techniques are designed primarily to help analysts think, not to predict what will occur in the future. The authors often describe structured techniques as "thinking tools" analysts can use to instill more rigor, structure, and imagination in the analysis. Most analysts report that the techniques help them avoid—or at least mitigate—the impact of cognitive bias, misapplied heuristics, and intuitive traps, thereby reducing error rates. Structured Analytic Techniques also spur analysts to reframe issues and discover "unknown unknowns" that they otherwise would have missed.

For these reasons, basing an analysis of the value of structured techniques on how accurately they can be used to predict the future would be applying an incomplete and misleading standard for the evaluation. The better questions to test would be, Did the analysts correctly frame the issue? Was the analysis done with rigor and transparency? Were incorrect mental mindsets identified and corrected? Did the analysis explore both challenges and opportunities for the decision maker? and Did use of the techniques save the analysts time over time? Moreover, applying a standard of predictive accuracy could be highly misleading if the analyst accurately identified an emerging problem and policymakers took action to prevent it from occurring. The function of a good warning analyst is to alert decision makers to a developing problem in time for them to prevent a prediction from becoming true.

This book has six chapters of techniques. Each Structured Analytic Technique has what is called face validity, which means there is reason to expect that it will help to mitigate or avoid a type of problem that sometimes occurs when one is engaged in doing analysis. The following paragraphs provide examples of face validity or how structured techniques help analysts do a better job.

A great deal of research in human cognition during the past sixty years shows the limits of working memory and suggests that one can manage a complex problem most effectively by breaking it down into smaller pieces. That is, in fact, the dictionary definition of "analysis," 8 and that is what techniques that make lists, trees, matrices, diagrams, maps, and models do. It is reasonable to expect, therefore, that an analyst who uses such tools for organization or visualization of information will do a more thorough job than an analyst who does not.

Similarly, much empirical evidence suggests that the human mind tends to see what it is looking for and often misses what it is not looking for (i.e., Confirmation Bias and Ignoring Inconsistent Evidence). Given this cognitive limitation, it seems useful to develop scenarios and indicators of possible future events for which intelligence needs to provide early warning. These techniques can help collectors target needed information. For analysts, they prepare the mind to recognize the early signs of significant change.

"Satisficing" is the term Herbert Simon invented to describe the act of selecting the first identified alternative that appears "good enough" rather than evaluating all the likely alternatives and identifying the best one (see the introduction to chapter 6 ). Satisficing is a common analytic shortcut that people use in making everyday decisions when there are multiple possible answers. It saves a lot of time when making judgments or decisions of little consequence, but it is ill-advised when making judgments or decisions with significant consequence for national security. It seems self-evident that an analyst who deliberately identifies and analyzes alternative hypotheses before reaching a conclusion is more likely to find a better answer than an analyst who does not.

Given the necessary role that assumptions play when making intelligence judgments based on incomplete and ambiguous information, an analyst who uses the Key Assumptions Check is likely to do a better job than an analyst who makes no effort to identify and validate assumptions. Extensive empirical evidence suggests that reframing a question helps to unblock the mind. It helps one to see other perspectives.

The empirical research on small-group performance is virtually unanimous in emphasizing that groups make better decisions when their members bring to the table a diverse set of ideas, experiences, opinions, and perspectives. 9 Looking at these research findings, one may conclude that the use of any structured technique in a group process is likely to improve the quality of analysis, as compared with analysis by a single individual using that technique or by a group that does not use a structured process for eliciting divergent ideas or opinions.

The experience of U.S. Intelligence Community analysts using the Analysis of Competing Hypotheses (ACH) software and similar computer-aided analytic tools provides anecdotal evidence to support this conclusion. One of the goals in using ACH is to gain a better understanding of the differences of opinion with other analysts or between analytic offices. 10 The creation of an ACH matrix requires step-by-step discussion of evidence and arguments being used and deliberation about how these are interpreted as either consistent or inconsistent with each of the hypotheses. This process takes time, but many analysts believe it is time well spent; they say it saves them time in the long run once they have learned the technique.

Our experience teaching ACH to intelligence analysts illustrates how structured techniques can elicit significantly more divergent information when used as a group process. Intelligence and law enforcement analysts consider this group discussion the most valuable part of the ACH process. Use of structured techniques does not guarantee a correct judgment, but this anecdotal evidence suggests that these techniques make a significant contribution to higher-quality analysis.

11.3 Projecting the Trajectory of Structured Techniques

Intelligence analysts and managers are continuously looking for ways to improve the quality of their analysis. One of these paths is the increased use of Structured Analytic Techniques. This book is intended to encourage and support that effort.

This final chapter employs a new technique called Complexity Manager ( chapter 10 ) to instill rigor in addressing a complex problem—the future of Structured Analytic Techniques. Richards J. Heuer Jr. developed the Complexity Manager as a simplified combination of two long-established futures analysis methods, Cross-Impact Matrix and System Dynamics. It is designed for analysts who have not been trained in the use of advanced, quantitative techniques.

We apply the Complexity Manager technique specifically to address the following questions:

What is the prognosis for the use of Structured Analytic Techniques in 2030? Will the use of Structured Analytic Techniques gain traction and be used with greater frequency by intelligence agencies, law enforcement, the business sector, and other professions? Or will its use remain at current levels? Or will it atrophy? What forces are spurring the increased use of structured analysis, and what opportunities are available to support these forces? What obstacles are hindering the increased use of structured analysis, and how might these obstacles be overcome?

In this chapter, we suppose that it is now the year 2030 and the use of Structured Analytic Techniques is widespread. We present our vision of what has happened to make this a reality and how the use of structured techniques has transformed the way analysis is done—not only in intelligence but across a broad range of professional disciplines.

11.3.1 Structuring the Data

The analysis for this future of Structured Analytic Techniques case study starts with a brainstormed list of variables that will influence—or be impacted by—the use of Structured Analytic Techniques in the coming years. The first variable listed is the target variable, followed by nine other variables related to it.

Increased use of Structured Analytic Techniques Executive support for collaboration and Structured Analytic Techniques Availability of virtual collaborative technology platforms Generational change of analysts Availability of analytic tradecraft support and mentoring Change in budget for analysis Change in client preferences for collaborative, digital products Research on effectiveness of Structured Analytic Techniques Analysts' perception of time pressure Lack of openness to change among senior analysts and mid-level managers

The next step in Complexity Manager is to put these ten variables into a Cross-Impact Matrix. This is a tool for the systematic description of the two-way interaction between each pair of variables. Each pair is assessed using the following question: Does this variable affect the paired variable in a manner that will contribute to increased or decreased use of Structured Analytic Techniques in 2030? The completed matrix is shown in Figure 11.3.1 . This is the same matrix that appears in chapter 10 .

Description Figure 11.3.1 Variables Affecting the Future Use of Structured Analysis

The goal of this analysis is to assess the likelihood of a substantial increase in the use of Structured Analytic Techniques by 2030, while identifying any side effects that might be associated with such an increase. That is why increased use of structured techniques is the lead variable, variable A, which forms the first column and top row of the matrix. The letters across the top of the matrix are abbreviations of the same variables listed down the left side.

To fill in the matrix, the authors started with column A to assess the impact of each of the variables listed down the left side of the matrix on the frequency of use of structured analysis. This exercise provides an overview of what likely are the most important variables that will impact positively or negatively on the use of structured analysis. Next, the authors completed row A across the top of the matrix. This shows the reverse impact—the impact of increased use of structured analysis on the other variables listed across the top of the matrix. Here one identifies the second-tier effects. Does the growing use of structured techniques affect any of these other variables in ways that one needs to be aware of? 11

The remainder of the matrix was then completed one variable at a time, while identifying and making notes on potentially significant secondary effects. A secondary effect occurs when one variable strengthens or weakens another variable, which in turn has an effect on or is affected by Structured Analytic Techniques.

11.3.2 Identifying Key Drivers

A rigorous analysis of the interaction of all the variables suggests several conclusions about the future of structured analysis. The analysis focuses on those variables that (1) are changing or that have the potential to change and (2) have the greatest impact on other significant variables.

The principal potential positive drivers of the system are the extent to which (1) senior executives support a culture of collaboration and (2) the work environment supports the development of virtual collaborative communities and technologies. These two variables provide strong support to structured analysis through their endorsement of and support for collaboration. Structured analysis reinforces them in turn by providing an optimal process through which collaboration occurs.

A third variable, the new generation of analysts accustomed to social networking, is strongly supportive of information sharing and collaboration and therefore indirectly supportive of growth in the use of Structured Analytic Techniques. The impact of the new generation of analysts is important because it means time is not neutral. In other words, with the new generation, time is now on the side of change. The interaction of these three variables, all reinforcing one another and moving in the same direction, signals that the future of structured techniques is most likely to be positive.

Two other variables are likely to play a major role because they have the most cross-impact on other variables as shown in the matrix. These two variables represent opportunities either to facilitate the change or obstacles that need to be managed. The two variables are (1) the level of support for analytic tradecraft cells, on-the-job mentoring, and facilitators to assist analysts and analytic teams in using structured techniques 12 and (2) the results of ongoing research on the effectiveness of structured techniques.

The speed and ease of the change in integrating structured techniques into the analytic process will be significantly influenced by the availability of senior mentors and facilitators who can identify which techniques to use and explain how to use them correctly. Ongoing research into the viability of structured techniques and best ways to harness their potential could provide strong validation for their use or undercut the prima facia case for their use. Research that discusses some of the obstacles identified earlier in this chapter could be helpful in optimizing their use and counter the opposition from those who are hesitant using the techniques.

The odds seem to favor continuing, fundamental change in how analysis is done. However, any change is far from guaranteed, because the outcome depends on two assumptions, either of which, if wrong, could preclude the desired outcome.

One assumption is that funding for analysis during the next decade will be adequate to provide an environment conducive to the expanded use of Structured Analytic Techniques. Increased training of managers as well as analysts in the proper use of structured techniques is important, but the provision of online programs and informal "brown bag" sessions to reinforce what was taught as well as the availability of knowledgeable mentors and facilitators is even more important. In addition, funding is needed to establish and sustain analytic tradecraft and collaboration support cells, facilitation support, mentoring programs, and research on the effectiveness of Structured Analytic Techniques. A second assumption is that senior executives will have the wisdom to allocate the necessary personnel and resources to create robust collaboration communities within and external to their organizational units. A critical requirement is the introduction and institutionalization of inventive and effective incentives to foster the broader use of structured techniques in support of their analysis.

11.4 Role of Structured Techniques in 2030

Imagine it is now 2030. Our assumptions have turned out to be accurate, and collaboration in the use of Structured Analytic Techniques is widespread. What has happened to make this outcome possible? How has it transformed the way analysis is done in 2030? This is our vision of what could be happening by that date.

The use of analytic teams and virtual collaborative platforms has been growing rapidly over the past decade. Analysts working in small groups, often from different locations, have increasingly embraced digital collaborative systems as user-friendly vehicles to produce joint papers with colleagues working on related topics in other offices. Analysts in different geographic locations arrange to meet from time to time, but most of the ongoing interaction is accomplished using asynchronous and synchronous computer applications and systems.

Analysts, with a click of the mouse or a simple voice command, can find themselves participating in a virtual meeting conferring with experts from multiple geographic locations. They can post their papers—or more likely a digital product—for others to review and edit in their virtual world, call up an internet site that merits examination, or project what they see on their own computer screens so that others can view their presentation or how they are using a specific software tool. Analysts or small teams can use virtual, collaborative platforms to be mentored "on demand" by a senior analyst on the use of a particular technique or by an instructor who can teach a structured techniques workshop without requiring anyone to leave his or her cubicle.

Structured Analytic Techniques have become a primary vehicle by which information is shared as analysts work together to deliver a high-quality product. Analysts readily employ a basic set of techniques and critical thinking skills at the beginning of most projects to establish a shared foundation for their communication and work together. They routinely use structured brainstorming techniques to identify key drivers and relevant variables to be tracked and considered, a Cross-Impact Matrix as a basis for discussion and learning from one another about the relationships between key variables, and a Key Assumptions Check to review and critically assess the assumptions that will provide the foundation for the analysis. They usually incorporate the results of these exercises as dropdowns in their tablet presentations.

The techniques provide a common base of knowledge and understanding about a topic of interest. They also help reveal, at an early stage of the production process, potential differences of opinion, gaps in the available information, what graphics to use, and where best to find the data and tap the expertise of people most knowledgeable about various aspects of the project.

By 2030, most social media service providers have established large analytic units to vet what is posted on their sites and combat the proliferation of Digital Disinformation or "Fake News." Many of these units have started to employ structured techniques to instill more rigor into their analytic processes and anticipate new ways perpetrators of Digital Disinformation could thwart their curation processes.

By 2030, all the principal elements of the U.S. Intelligence Community, many foreign intelligence services, and a growing number of business analysis units have created analytic tradecraft or collaboration support cells—or support mechanisms—in their analytic components. Academic institutions now routinely teach courses on critical thinking, cognitive bias, Structured Analytic Techniques, combating Digital Disinformation, and using structured techniques to better exploit Big Data. Analysts with experience in using structured techniques routinely help other analysts overcome their uncertainty when using a technique for the first time. They help others decide which techniques are most appropriate for their particular needs, provide oversight when needed to ensure that a technique is being used appropriately, and teach other analysts through example and on-the-job training how to effectively facilitate team or group meetings.

In 2030, the process for coordinating analytic papers and assessments is dramatically different. Formal coordination prior to publication is now a formality. Collaboration among interested parties takes place from the start as papers are initially conceptualized and relevant information is collected and shared. Basic critical thinking techniques such as the use of AIMS ( A udience, I ssue, M essage, and S toryline) to describe the key components of an analyst's project and the Getting Started Checklist are used regularly. Differences of opinion are surfaced and explored early in the preparation of an analytic product. Analytic techniques, such as Premortem Analysis and Structured Self-Critique, have become a requirement to bulletproof analytic products. Several Adversarial Collaboration techniques have become ingrained into the culture as the most effective mechanisms to resolve disagreements before final coordination and delivery of an analytic product.

Exploitation of outside knowledge—especially cultural, environmental, and technical expertise—has increased significantly. Outside-In Thinking, Structured Analogies, and the Delphi Method are used extensively to obtain ideas, judgments, or forecasts electronically from geographically dispersed panels of experts. Almost all analytic units have a dedicated unit for conducting Foresight analysis that (1) identifies key drivers to help frame basic lines of analysis and (2) generates a set of alternative scenarios that can be tracked using validated indicators to anticipate new challenges and exploit new opportunities.

By 2030, the use of Structured Analytic Techniques has expanded across the globe. All U.S. intelligence agencies, all intelligence services in Europe, and many services in other parts of the world have incorporated structured techniques into their analytic process. Over one hundred Fortune 500 companies with competitive intelligence units routinely employ structured techniques, including Foresight, Indicators, and Decision Support tools. A growing number of hospitals have incorporated selected structured techniques, including the Key Assumptions Check, Differential Diagnosis (their version of Analysis of Competing Hypotheses), Indicators, and Premortem Analysis into their analytic processes. Many businesses have concluded that they can no longer afford multimillion-dollar mistakes that would have been avoided by embracing competitive intelligence processes in their business practices.

One no longer hears the old claim that there is no proof that the use of Structured Analytic Techniques improves analysis. The widespread use of structured techniques in 2030 is partially attributable to the debunking of that claim. Several European Union and other foreign studies involving a sample of reports prepared with the assistance of several structured techniques and a comparable sample of reports where structured techniques had not been used showed that the use of structured techniques had distinct value. Researchers interviewed the authors of the reports, their managers, and the clients who received these reports. The studies confirmed that reports prepared with the assistance of the selected structured techniques were more thorough, provided better accounts of how the conclusions were reached, and generated greater confidence in the conclusions than did reports for which such techniques were not used. The findings were replicated by several government intelligence services that use the techniques, and the results were sufficiently convincing to quiet most of the doubters.

The collective result of all these developments is an analytic climate in 2030 that produces more rigorous, constructive, and informative analysis—a development that decision makers have noted and are making use of as they face increasingly complex and interrelated policy challenges. As a result, policymakers are increasingly demanding analytic products that identify key drivers, consider multiple scenarios, and challenge key assumptions and the conventional wisdom. The key conclusions generated by techniques such as Quadrant Crunching™ and What If? Analysis are commonly discussed among analysts and decision makers alike. In some cases, decision makers or their aides observe or participate in Foresight workshops using structured techniques. These interactions help both clients and analysts understand the benefits and limitations of using collaborative processes to produce analysis that informs and augments policy deliberations.

This vision of a robust and policy-relevant analytic climate in 2030 is achievable. But it is predicated on the willingness and ability of senior managers in the intelligence, law enforcement, and business communities to foster a collaborative environment that encourages the use of Structured Analytic Techniques. Achieving this goal will require a relatively modest infusion of resources for analytic tradecraft centers, facilitators, mentors, and methodology development and testing. It will also require patience and a willingness to tolerate some mistakes as analysts become familiar with the techniques, collaborative software, and working in a virtual, digital landscape. We believe the outcome will be worth the risk involved in charting a new analytic frontier.

Notes

1. Stephen Artner, Richard S. Girven, and James B. Bruce, Assessing the Value of Structured Analytic Techniques in the U.S. Intelligence Community (Santa Monica, CA: RAND Corporation, 2016), https://www.rand.org/pubs/research_reports/RR1408.html

2. Stephen Coulthart, "Improving the Analysis of Foreign Affairs: Evaluating Structured Analytic Techniques" (PhD diss., University of Pittsburgh, 2015), http://d-scholarship.pitt.edu/26055/

3. Welton Chang et al., "Restructuring Structured Analytic Techniques in Intelligence," Intelligence and National Security 33, no. 3 (2018): 337–56, https://doi.org/10.1080/02684527.2017.1400230

4. Paul Bedard, "CIA Chief Claims Progress with Intelligence Reforms," U.S. News and World Report, May 16, 2008, www.usnews.com/articles/news/2008/05/16/cia-chief-claims-progress-with-intelligence-reforms.html

5. One of the best examples of research that does meet this comparability standard is Robert D. Folker, Jr., Intelligence Analysis in Theater Joint Intelligence Centers: An Experiment in Applying Structured Methods (Washington, DC: Joint Military Intelligence College, 2000).

6. Philip Tetlock, Expert Political Judgment (Princeton, NJ: Princeton University Press, 2005), 190–202.

7. These judgments have been made in public statements and in personal communications to the authors.

8. Merriam-Webster Online, www.m-w.com/dictionary/analysis

9. Charlan J. Nemeth and Brendan Nemeth-Brown, "Better Than Individuals? The Potential Benefits of Dissent and Diversity for Group Creativity," in Group Creativity: Innovation through Collaboration, eds. Paul B. Paulus and Bernard A. Nijstad (New York: Oxford University Press, 2003), 63–64.

10. This information was provided by a senior U.S. Intelligence Community educator in December 2006 and has been validated subsequently on many occasions in projects done by government analysts.

11. For a more detailed explanation of how each variable was rated in the Complexity Analysis matrix, send an email requesting the data to think@globalytica.com.

12. The concept of analytic tradecraft support cells is explored more fully in Randolph H. Pherson, "Transformation Cells: An Innovative Way to Institutionalize Collaboration," in Collaboration in the National Security Arena: Myths and Reality—What Science and Experience Can Contribute to Its Success , June 2009. It is part of a collection published by the Topical Strategic Multilayer Assessment (SMA), Multi-Agency/Multi-Disciplinary White Papers in Support of Counter-Terrorism and Counter-WMD, Office of Secretary of Defense/DDR&E/RTTO, http://www.hsdl.org/?view&did=712792 .

Structured Analytic Techniques: Families and Linkages

The sixty-six Structured Analytic Techniques presented in this book can be used independently or in concert with other techniques. The art and science of analysis is dynamic, however, and we expect this list of techniques to continue to change over time.

For ease of presentation, we have sorted the techniques into six groups, or families, mirroring when they most often are used in the analytic production process. See chapter 3 for guidance on how to select the proper technique(s).

The graphic on the opposing page illustrates the relationships among the techniques. Mapping the techniques in this manner highlights the mutually reinforcing nature of many of the techniques.

Many of these techniques have value for more than one family. These "core" techniques relate to three or more families and are highlighted in a light color. These techniques are often cited by analysts in the intelligence and business communities as tools they are most likely to use in their analysis.

Structured Analytic Techniques that make use of indicators are designated by stars.

Descriptions of Images and Figures

Back to Figure

Reading the matrix: The cells in each row show the impact of the variable represented by that row on each of the variables listed across the top of the matrix. The cells in each column show the impact of each variable listed down the left side of the matrix on the variable represented by the column. Combination of positive and negative means impact could go either direction.

Empty cell equals no impact.