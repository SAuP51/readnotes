第 3 章　字典和集合

字典这个数据结构活跃在所有 Python 程序的背后，即便你的源码里并没有直接用到它。

——A. M. Kuchling

《代码之美》第 18 章「Python 的字典类：如何打造全能战士」

dict 类型不但在各种程序里广泛使用，它也是 Python 语言的基石。模块的命名空间、实例的属性和函数的关键字参数中都可以看到字典的身影。跟它有关的内置函数都在 __builtins__.__dict__模块中。

正是因为字典至关重要，Python 对它的实现做了高度优化，而散列表则是字典类型性能出众的根本原因。

集合（set）的实现其实也依赖于散列表，因此本章也会讲到它。反过来说，想要进一步理解集合和字典，就得先理解散列表的原理。

本章内容的大纲如下：

常见的字典方法

如何处理查找不到的键

标准库中 dict 类型的变种

set 和 frozenset 类型

散列表的工作原理

散列表带来的潜在影响（什么样的数据类型可作为键、不可预知的顺序，等等）

3.1　泛映射类型

collections.abc 模块中有 Mapping 和 MutableMapping 这两个抽象基类，它们的作用是为 dict 和其他类似的类型定义形式接口（在 Python 2.6 到 Python 3.2 的版本中，这些类还不属于 collections.abc 模块，而是隶属于 collections 模块）。详见图 3-1。

图 3-1：collections.abc 中的 MutableMapping 和它的超类的 UML 类图（箭头从子类指向超类，抽象类和抽象方法的名称以斜体显示）

然而，非抽象映射类型一般不会直接继承这些抽象基类，它们会直接对 dict 或是 collections.UserDict 进行扩展。这些抽象基类的主要作用是作为形式化的文档，它们定义了构建一个映射类型所需要的最基本的接口。然后它们还可以跟 isinstance 一起被用来判定某个数据是不是广义上的映射类型 1 ：

1 在运行这两行代码前，读者需要先执行一下 from collections import abc。—— 译者注

>>> my_dict = {} >>> isinstance(my_dict, abc.Mapping) True

这里用 isinstance 而不是 type 来检查某个参数是否为 dict 类型，因为这个参数有可能不是 dict，而是一个比较另类的映射类型。

标准库里的所有映射类型都是利用 dict 来实现的，因此它们有个共同的限制，即只有可散列的数据类型才能用作这些映射里的键（只有键有这个要求，值并不需要是可散列的数据类型）。

什么是可散列的数据类型

在 Python 词汇表中，关于可散列类型的定义有这样一段话：

如果一个对象是可散列的，那么在这个对象的生命周期中，它的散列值是不变的，而且这个对象需要实现 __hash__() 方法。另外可散列对象还要有 __qe__() 方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的……

原子不可变数据类型（str、bytes 和数值类型）都是可散列类型，frozenset 也是可散列的，因为根据其定义，frozenset 里只能容纳可散列类型。元组的话，只有当一个元组包含的所有元素都是可散列类型的情况下，它才是可散列的。来看下面的元组 tt、tl 和 tf：

>>> tt = (1, 2, (30, 40)) >>> hash(tt) 8027212646858338501 >>> tl = (1, 2, [30, 40]) >>> hash(tl) Traceback (most recent call last): File "<stdin>", line 1, in <module> TypeError: unhashable type: 'list' >>> tf = (1, 2, frozenset([30, 40])) >>> hash(tf) -4118419923444501110

直到我写这本书的时候，Python 词汇表里还在说「Python 里所有的不可变类型都是可散列的」。这个说法其实是不准确的，比如虽然元组本身是不可变序列，它里面的元素可能是其他可变类型的引用。

一般来讲用户自定义的类型的对象都是可散列的，散列值就是它们的 id () 函数的返回值，所以所有这些对象在比较的时候都是不相等的。如果一个对象实现了 __eq__ 方法，并且在方法中用到了这个对象的内部状态的话，那么只有当所有这些内部状态都是不可变的情况下，这个对象才是可散列的。

根据这些定义，字典提供了很多种构造方法，「Built-in Types」这个页面上有个例子来说明创建字典的不同方式：

>>> a = dict(one=1, two=2, three=3) >>> b = {'one': 1, 'two': 2, 'three': 3} >>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3])) >>> d = dict([('two', 2), ('one', 1), ('three', 3)]) >>> e = dict({'three': 3, 'one': 1, 'two': 2}) >>> a == b == c == d == e True

除了这些字面句法和灵活的构造方法之外，字典推导（dict comprehension）也可以用来建造新 dict，详见下一节。

3.2　字典推导

自 Python 2.7 以来，列表推导和生成器表达式的概念就移植到了字典上，从而有了字典推导（后面还会看到集合推导）。字典推导（dictcomp）可以从任何以键值对作为元素的可迭代对象中构建出字典。示例 3-1 就展示了利用字典推导可以把一个装满元组的列表变成两个不同的字典。

示例 3-1　字典推导的应用

>>> DIAL_CODES = [ ➊ ... (86, 'China'), ... (91, 'India'), ... (1, 'United States'), ... (62, 'Indonesia'), ... (55, 'Brazil'), ... (92, 'Pakistan'), ... (880, 'Bangladesh'), ... (234, 'Nigeria'), ... (7, 'Russia'), ... (81, 'Japan'), ... ] >>> country_code = {country: code for code, country in DIAL_CODES} ➋ >>> country_code {'China': 86, 'India': 91, 'Bangladesh': 880, 'United States': 1, 'Pakistan': 92, 'Japan': 81, 'Russia': 7, 'Brazil': 55, 'Nigeria': 234, 'Indonesia': 62} >>> {code: country.upper() for country, code in country_code.items() ➌ ... if code < 66} {1: 'UNITED STATES', 55: 'BRAZIL', 62: 'INDONESIA', 7: 'RUSSIA'}

❶ 一个承载成对数据的列表，它可以直接用在字典的构造方法中。

❷ 这里把配好对的数据左右换了下，国家名是键，区域码是值。

❸ 跟上面相反，用区域码作为键，国家名称转换为大写，并且过滤掉区域码大于或等于 66 的地区。

如果列表推导的概念已经为你所熟知，接受字典推导应该不难。如果你对列表推导还不熟，那么是时候来掌握它了，因为字典推导的表达形式会蔓延到其他数据类型中。

下面来看看映射类型提供的 API 的全景图。

3.3　常见的映射方法

映射类型的方法其实很丰富。表 3-1 为我们展示了 dict、defaultdict 和 OrderedDict 的常见方法，后面两个数据类型是 dict 的变种，位于 collections 模块内。

表 3-1：dict、collections.defaultdict 和 collections.OrderedDict 这三种映射类型的方法列表（依然省略了继承自 object 的常见方法）；可选参数以 [...] 表示

dict

defaultdict

OrderedDict

d.clear()

•

•

•

移除所有元素

d.__contains__(k)

•

•

•

检查 k 是否在 d 中

d.copy()

•

•

•

浅复制

d.__copy__()

•

用于支持 copy.copy

d.default_factory

•

在 __missing__ 函数中被调用的函数，用以给未找到的元素设置值 *

d.__delitem__(k)

•

•

•

del d [k]，移除键为 k 的元素

d.fromkeys(it, [initial])

•

•

•

将迭代器 it 里的元素设置为映射里的键，如果有 initial 参数，就把它作为这些键对应的值（默认是 None）

d.get(k, [default])

•

•

•

返回键 k 对应的值，如果字典里没有键 k，则返回 None 或者 default

d.__getitem__(k)

•

•

•

让字典 d 能用 d [k] 的形式返回键 k 对应的值

d.items()

•

•

•

返回 d 里所有的键值对

d.__iter__()

•

•

•

获取键的迭代器

d.keys()

•

•

•

获取所有的键

d.__len__()

•

•

•

可以用 len (d) 的形式得到字典里键值对的数量

d.__missing__(k)

•

当 __getitem__ 找不到对应键的时候，这个方法会被调用

d.move_to_end(k, [last])

•

把键为 k 的元素移动到最靠前或者最靠后的位置（last 的默认值是 True）

d.pop(k, [defaul]

•

•

•

返回键 k 所对应的值，然后移除这个键值对。如果没有这个键，返回 None 或者 defaul

d.popitem()

•

•

•

随机返回一个键值对并从字典里移除它 #

d.__reversed__()

•

返回倒序的键的迭代器

d.setdefault(k, [default])

•

•

•

若字典里有键 k，则直接返回 k 所对应的值；若无，则让 d [k] = default，然后返回 default

d.__setitem__(k, v)

•

•

•

实现 d [k] = v 操作，把 k 对应的值设为 v

d.update(m, [**kargs])

•

•

•

m 可以是映射或者键值对迭代器，用来更新 d 里对应的条目

d.values()

•

•

•

返回字典里的所有值

* default_factory 并不是一个方法，而是一个可调用对象（callable），它的值在 defaultdict 初始化的时候由用户设定。

# OrderedDict.popitem () 会移除字典里最先插入的元素（先进先出）；同时这个方法还有一个可选的 last 参数，若为真，则会移除最后插入的元素（后进先出）。

上面的表格中，update 方法处理参数 m 的方式，是典型的「鸭子类型」。函数首先检查 m 是否有 keys 方法，如果有，那么 update 函数就把它当作映射对象来处理。否则，函数会退一步，转而把 m 当作包含了键值对 (key, value) 元素的迭代器。Python 里大多数映射类型的构造方法都采用了类似的逻辑，因此你既可以用一个映射对象来新建一个映射对象，也可以用包含 (key, value) 元素的可迭代对象来初始化一个映射对象。

在映射对象的方法里，setdefault 可能是比较微妙的一个。我们虽然并不会每次都用它，但是一旦它发挥作用，就可以节省不少次键查询，从而让程序更高效。如果你对它还不熟悉，下面我会通过一个实例来讲解它的用法。

用 setdefault 处理找不到的键

当字典 d [k] 不能找到正确的键的时候，Python 会抛出异常，这个行为符合 Python 所信奉的「快速失败」哲学。也许每个 Python 程序员都知道可以用 d.get (k, default) 来代替 d [k]，给找不到的键一个默认的返回值（这比处理 KeyError 要方便不少）。但是要更新某个键对应的值的时候，不管使用 __getitem__ 还是 get 都会不自然，而且效率低。就像示例 3-2 中的还没有经过优化的代码所显示的那样，dict.get 并不是处理找不到的键的最好方法。

示例 3-2 是由 Alex Martelli 举的一个例子 2 变化而来，例子生成的索引跟示例 3-3 显示的一样。

2 示例代码出现在 Martelli 的演讲「Re-learning python」中（第 41 张幻灯片），他的代码被我放在了示例 3-4 中，代码很好地展示了 dict.setdefault 的用法。

示例 3-2　index0.py 这段程序从索引中获取单词出现的频率信息，并把它们写进对应的列表里（更好的解决方案在示例 3-4 中）

"""创建一个从单词到其出现情况的映射""" import sys import re WORD_RE = re.compile (r'\w+') index = {} with open (sys.argv [1], encoding='utf-8') as fp: for line_no, line in enumerate (fp, 1): for match in WORD_RE.finditer (line): word = match.group () column_no = match.start ()+1 location = (line_no, column_no) # 这其实是一种很不好的实现，这样写只是为了证明论点 occurrences = index.get (word, []) ➊ occurrences.append (location) ➋ index [word] = occurrences ➌ # 以字母顺序打印出结果 for word in sorted (index, key=str.upper): ➍ print (word, index [word])

❶ 提取 word 出现的情况，如果还没有它的记录，返回 []。

❷ 把单词新出现的位置添加到列表的后面。

❸ 把新的列表放回字典中，这又牵扯到一次查询操作。

❹ sorted 函数的 key= 参数没有调用 str.upper，而是把这个方法的引用传递给 sorted 函数，这样在排序的时候，单词会被规范成统一格式。3

3 这是将方法用作一等函数的一个示例，第 5 章会谈到这一点。

示例 3-3　这里是示例 3-2 的不完全输出，每一行的列表都代表一个单词的出现情况，列表中的元素是一对值，第一个值表示出现的行，第二个表示出现的列

$ python3 index0.py ../../data/zen.txt a [(19, 48), (20, 53)] Although [(11, 1), (16, 1), (18, 1)] ambiguity [(14, 16)] and [(15, 23)] are [(21, 12)] aren [(10, 15)] at [(16, 38)] bad [(19, 50)] be [(15, 14), (16, 27), (20, 50)] beats [(11, 23)] Beautiful [(3, 1)] better [(3, 14), (4, 13), (5, 11), (6, 12), (7, 9), (8, 11), (17, 8), (18, 25)] ...

示例 3-2 里处理单词出现情况的三行，通过 dict.setdefault 可以只用一行解决。示例 3-4 更接近 Alex Martelli 自己举的例子。

示例 3-4　index.py 用一行就解决了获取和更新单词的出现情况列表，当然跟示例 3-2 不一样的是，这里用到了 dict.setdefault

"""创建从一个单词到其出现情况的映射""" import sys import re WORD_RE = re.compile (r'\w+') index = {} with open (sys.argv [1], encoding='utf-8') as fp: for line_no, line in enumerate (fp, 1): for match in WORD_RE.finditer (line): word = match.group () column_no = match.start ()+1 location = (line_no, column_no) index.setdefault (word, []).append (location) ➊ # 以字母顺序打印出结果 for word in sorted (index, key=str.upper): print (word, index [word])

➊ 获取单词的出现情况列表，如果单词不存在，把单词和一个空列表放进映射，然后返回这个空列表，这样就能在不进行第二次查找的情况下更新列表了。

也就是说，这样写：

my_dict.setdefault(key, []).append(new_value)

跟这样写：

if key not in my_dict: my_dict[key] = [] my_dict[key].append(new_value)

二者的效果是一样的，只不过后者至少要进行两次键查询 —— 如果键不存在的话，就是三次，用 setdefault 只需要一次就可以完成整个操作。

那么，在单纯地查找取值（而不是通过查找来插入新值）的时候，该怎么处理找不到的键呢？

3.4　映射的弹性键查询

有时候为了方便起见，就算某个键在映射里不存在，我们也希望在通过这个键读取值的时候能得到一个默认值。有两个途径能帮我们达到这个目的，一个是通过 defaultdict 这个类型而不是普通的 dict，另一个是给自己定义一个 dict 的子类，然后在子类中实现 __missing__ 方法。下面将介绍这两种方法。

3.4.1　defaultdict：处理找不到的键的一个选择

示例 3-5 在 collections.defaultdict 的帮助下优雅地解决了示例 3-4 里的问题。在用户创建 defaultdict 对象的时候，就需要给它配置一个为找不到的键创造默认值的方法。

具体而言，在实例化一个 defaultdict 的时候，需要给构造方法提供一个可调用对象，这个可调用对象会在 __getitem__ 碰到找不到的键的时候被调用，让 __getitem__ 返回某种默认值。

比如，我们新建了这样一个字典：dd = defaultdict (list)，如果键 'new-key' 在 dd 中还不存在的话，表达式 dd ['new-key'] 会按照以下的步骤来行事。

(1) 调用 list () 来建立一个新列表。

(2) 把这个新列表作为值，'new-key' 作为它的键，放到 dd 中。

(3) 返回这个列表的引用。

而这个用来生成默认值的可调用对象存放在名为 default_factory 的实例属性里。

示例 3-5　index_default.py：利用 defaultdict 实例而不是 setdefault 方法

"""创建一个从单词到其出现情况的映射""" import sys import re import collections WORD_RE = re.compile (r'\w+') index = collections.defaultdict (list) ➊ with open (sys.argv [1], encoding='utf-8') as fp: for line_no, line in enumerate (fp, 1): for match in WORD_RE.finditer (line): word = match.group () column_no = match.start ()+1 location = (line_no, column_no) index [word].append (location) ➋ # 以字母顺序打印出结果 for word in sorted (index, key=str.upper): print (word, index [word])

➊ 把 list 构造方法作为 default_factory 来创建一个 defaultdict。

➋ 如果 index 并没有 word 的记录，那么 default_factory 会被调用，为查询不到的键创造一个值。这个值在这里是一个空的列表，然后这个空列表被赋值给 index [word]，继而被当作返回值返回，因此 .append (location) 操作总能成功。

如果在创建 defaultdict 的时候没有指定 default_factory，查询不存在的键会触发 KeyError。

defaultdict 里的 default_factory 只会在 __getitem__ 里被调用，在其他的方法里完全不会发挥作用。比如，dd 是个 defaultdict，k 是个找不到的键，dd [k] 这个表达式会调用 default_factory 创造某个默认值，而 dd.get (k) 则会返回 None。

所有这一切背后的功臣其实是特殊方法 __missing__。它会在 defaultdict 遇到找不到的键的时候调用 default_factory，而实际上这个特性是所有映射类型都可以选择去支持的。

3.4.2　特殊方法 __missing__

所有的映射类型在处理找不到的键的时候，都会牵扯到 __missing__ 方法。这也是这个方法称作「missing」的原因。虽然基类 dict 并没有定义这个方法，但是 dict 是知道有这么个东西存在的。也就是说，如果有一个类继承了 dict，然后这个继承类提供了 __missing__ 方法，那么在 __getitem__ 碰到找不到的键的时候，Python 就会自动调用它，而不是抛出一个 KeyError 异常。

__missing__ 方法只会被 __getitem__ 调用（比如在表达式 d [k] 中）。提供 __missing__ 方法对 get 或者 __contains__（in 运算符会用到这个方法）这些方法的使用没有影响。这也是我在上一节最后的警告中提到，defaultdict 中的 default_factory 只对 __getitem__ 有作用的原因。

有时候，你会希望在查询的时候，映射类型里的键统统转换成 str。为可编程电路板（像 Raspberry Pi 或 Arduino4）准备的 Pingo.io 项目里就有具体的例子。在 Pingo.io 里，电路板上的 GPIO 针脚 5 以 board.pins 为名，封装在名为 board 的对象里。board.pins 是一个映射类型，其中键是针脚的物理位置，它可能只是一个数字或字符串，比如 "A0" 或 "P9_12"；值则是针脚连接的东西。为了保持一致性，我们希望 board.pins 的键只能是字符串，但是为了方便查询，my_arduino.pins [13] 也是可行的，这样可以帮 Arduino 的初级玩家快速找到第 13 个针脚上的 LED 灯。示例 3-6 展示了这样的一个映射是怎么运行的。

4Raspberry Pi 是一个集成到巴掌大小的板子上的电脑。Arduino 则是一种可以在烧录程序的同时，连接上各种传感器，用以跟物理世界交互的电路板。更多的相关信息可以在 https://www.raspberrypi.org/ 和 https://www.arduino.cc/ 上找到。—— 译者注

5 通用输入输出针脚，用来跟传感器或其他设备用数据互动。—— 译者注

示例 3-6　当有非字符串的键被查找的时候，StrKeyDict0 是如何在该键不存在的情况下，把它转换为字符串的

Tests for item retrieval using `d[key]` notation:: >>> d = StrKeyDict0([('2', 'two'), ('4', 'four')]) >>> d['2'] 'two' >>> d[4] 'four' >>> d[1] Traceback (most recent call last): ... KeyError: '1' Tests for item retrieval using `d.get(key)` notation:: >>> d.get('2') 'two' >>> d.get(4) 'four' >>> d.get(1, 'N/A') 'N/A' Tests for the `in` operator:: >>> 2 in d True >>> 1 in d False

示例 3-7 则实现了上面例子里的 StrKeyDict0 类。

如果要自定义一个映射类型，更合适的策略其实是继承 collections.UserDict 类（示例 3-8 就是如此）。这里我们从 dict 继承，只是为了演示 __missing__ 是如何被 dict.__getitem__ 调用的。

示例 3-7　StrKeyDict0 在查询的时候把非字符串的键转换为字符串

class StrKeyDict0(dict): ➊ def __missing__(self, key): if isinstance(key, str): ➋ raise KeyError(key) return self[str(key)] ➌ def get(self, key, default=None): try: return self[key] ➍ except KeyError: return default ➎ def __contains__(self, key): return key in self.keys() or str(key) in self.keys() ➏

❶ StrKeyDict0 继承了 dict。

❷ 如果找不到的键本身就是字符串，那就抛出 KeyError 异常。

❸ 如果找不到的键不是字符串，那么把它转换成字符串再进行查找。

❹ get 方法把查找工作用 self [key] 的形式委托给 __getitem__，这样在宣布查找失败之前，还能通过 __missing__ 再给某个键一个机会。

❺ 如果抛出 KeyError，那么说明 __missing__ 也失败了，于是返回 default。

❻ 先按照传入键的原本的值来查找（我们的映射类型中可能含有非字符串的键），如果没找到，再用 str () 方法把键转换成字符串再查找一次。

下面来看看为什么 isinstance (key, str) 测试在上面的 __missing__ 中是必需的。

如果没有这个测试，只要 str (k) 返回的是一个存在的键，那么 __missing__ 方法是没问题的，不管是字符串键还是非字符串键，它都能正常运行。但是如果 str (k) 不是一个存在的键，代码就会陷入无限递归。这是因为 __missing__ 的最后一行中的 self [str (key)] 会调用 __getitem__，而这个 str (key) 又不存在，于是 __missing__ 又会被调用。

为了保持一致性，__contains__ 方法在这里也是必需的。这是因为 k in d 这个操作会调用它，但是我们从 dict 继承到的 __contains__ 方法不会在找不到键的时候调用 __missing__ 方法。__contains__ 里还有个细节，就是我们这里没有用更具 Python 风格的方式 ——k in my_dict—— 来检查键是否存在，因为那也会导致 __contains__ 被递归调用。为了避免这一情况，这里采取了更显式的方法，直接在这个 self.keys () 里查询。

像 k in my_dict.keys () 这种操作在 Python 3 中是很快的，而且即便映射类型对象很庞大也没关系。这是因为 dict.keys () 的返回值是一个「视图」。视图就像一个集合，而且跟字典类似的是，在视图里查找一个元素的速度很快。在「Dictionary view objects」里可以找到关于这个细节的文档。Python 2 的 dict.keys () 返回的是个列表，因此虽然上面的方法仍然是正确的，它在处理体积大的对象的时候效率不会太高，因为 k in my_list 操作需要扫描整个列表。

出于对准确度的考虑，我们也需要这个按照键的原本的值来查找的操作（也就是 key in self.keys ()），因为在创建 StrKeyDict0 和为它添加新值的时候，我们并没有强制要求传入的键必须是字符串。因为这个操作没有规定死键的类型，所以让查找操作变得更加友好。

好了，我们已经见识过 dict 和 defaultdict 了。但是标准库里面还有很多其他的映射类型，下面就来看看。

3.5　字典的变种

这一节总结了标准库里 collections 模块中，除了 defaultdict 之外的不同映射类型。

collections.OrderedDict

这个类型在添加键的时候会保持顺序，因此键的迭代次序总是一致的。OrderedDict 的 popitem 方法默认删除并返回的是字典里的最后一个元素，但是如果像 my_odict.popitem (last=False) 这样调用它，那么它删除并返回第一个被添加进去的元素。

collections.ChainMap

该类型可以容纳数个不同的映射对象，然后在进行键查找操作的时候，这些对象会被当作一个整体被逐个查找，直到键被找到为止。这个功能在给有嵌套作用域的语言做解释器的时候很有用，可以用一个映射对象来代表一个作用域的上下文。在 collections 文档介绍 ChainMap 对象的那一部分里有一些具体的使用示例，其中包含了下面这个 Python 变量查询规则的代码片段：

import builtins pylookup = ChainMap(locals(), globals(), vars(builtins))

collections.Counter

这个映射类型会给键准备一个整数计数器。每次更新一个键的时候都会增加这个计数器。所以这个类型可以用来给可散列表对象计数，或者是当成多重集来用 —— 多重集合就是集合里的元素可以出现不止一次。Counter 实现了 + 和 - 运算符用来合并记录，还有像 most_common ([n]) 这类很有用的方法。most_common ([n]) 会按照次序返回映射里最常见的 n 个键和它们的计数，详情参阅文档。下面的小例子利用 Counter 来计算单词中各个字母出现的次数：

>>> ct = collections.Counter('abracadabra') >>> ct Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) >>> ct.update('aaaaazzz') >>> ct Counter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) >>> ct.most_common(2) [('a', 10), ('z', 3)]

colllections.UserDict

这个类其实就是把标准 dict 用纯 Python 又实现了一遍。

跟 OrderedDict、ChainMap 和 Counter 这些开箱即用的类型不同，UserDict 是让用户继承写子类的。下面就来试试。

3.6　子类化 UserDict

就创造自定义映射类型来说，以 UserDict 为基类，总比以普通的 dict 为基类要来得方便。

这体现在，我们能够改进示例 3-7 中定义的 StrKeyDict0 类，使得所有的键都存储为字符串类型。

而更倾向于从 UserDict 而不是从 dict 继承的主要原因是，后者有时会在某些方法的实现上走一些捷径，导致我们不得不在它的子类中重写这些方法，但是 UserDict 就不会带来这些问题。6

6 关于从 dict 或者其他内置类继承到底有什么不好，详见 12.1 节。

另外一个值得注意的地方是，UserDict 并不是 dict 的子类，但是 UserDict 有一个叫作 data 的属性，是 dict 的实例，这个属性实际上是 UserDict 最终存储数据的地方。这样做的好处是，比起示例 3-7，UserDict 的子类就能在实现 __setitem__ 的时候避免不必要的递归，也可以让 __contains__ 里的代码更简洁。

多亏了 UserDict，示例 3-8 里的 StrKeyDict 的代码比示例 3-7 里的 StrKeyDict0 要短一些，功能却更完善：它不但把所有的键都以字符串的形式存储，还能处理一些创建或者更新实例时包含非字符串类型的键这类意外情况。

示例 3-8　无论是添加、更新还是查询操作，StrKeyDict 都会把非字符串的键转换为字符串

import collections class StrKeyDict(collections.UserDict): ➊ def __missing__(self, key): ➋ if isinstance(key, str): raise KeyError(key) return self[str(key)] def __contains__(self, key): return str(key) in self.data ➌ def __setitem__(self, key, item): self.data[str(key)] = item ➍

❶ StrKeyDict 是对 UserDict 的扩展。

❷ __missing__ 跟示例 3-7 里的一模一样。

❸ __contains__ 则更简洁些。这里可以放心假设所有已经存储的键都是字符串。因此，只要在 self.data 上查询就好了，并不需要像 StrKeyDict0 那样去麻烦 self.keys ()。

❹ __setitem__ 会把所有的键都转换成字符串。由于把具体的实现委托给了 self.data 属性，这个方法写起来也不难。

因为 UserDict 继承的是 MutableMapping，所以 StrKeyDict 里剩下的那些映射类型的方法都是从 UserDict、MutableMapping 和 Mapping 这些超类继承而来的。特别是最后的 Mapping 类，它虽然是一个抽象基类（ABC），但它却提供了好几个实用的方法。以下两个方法值得关注。

MutableMapping.update

这个方法不但可以为我们所直接利用，它还用在 __init__ 里，让构造方法可以利用传入的各种参数（其他映射类型、元素是 (key, value) 对的可迭代对象和键值参数）来新建实例。因为这个方法在背后是用 self [key] = value 来添加新值的，所以它其实是在使用我们的 __setitem__ 方法。

Mapping.get

在 StrKeyDict0（示例 3-7）中，我们不得不改写 get 方法，好让它的表现跟 __getitem__ 一致。而在示例 3-8 中就没这个必要了，因为它继承了 Mapping.get 方法，而 Python 的源码显示，这个方法的实现方式跟 StrKeyDict0.get 是一模一样的。

在写完 StrKeyDict 这个类之后，我读到了 Antonie Pitrou 写的「PEP 455 — Adding a key-transforming dictionary to collections」。文章附带的补丁里包含了一个叫作 TransformDict 的新类型。这个补丁通过 issue 18986 被吸收进了 Python 3.5。7 为了试试这个类，我把它提取出来放进了一个单独的模块（在本书代码仓库中：03-dict-set/transformdict.py）。比起 StrKeyDict，TransformDict 的通用性更强，也更复杂，因为它把键存成字符串的同时，还要按照它原来的样子存一份。

7 译者浏览 http://bugs.python.org/issue18986 后发现这个 PEP 最终被关闭，相应的补丁也没有被吸收进 Python 3.5。有兴趣的读者可以通过这个链接看看它被拒绝的原因：http://bugs.python.org/issue18986#msg243370 。—— 译者注

之前我们见识过了不可变的序列类型，那有没有不可变的字典类型呢？这么说吧，在标准库里是没有这样的类型的，但是可以用替身来代替。

3.7　不可变映射类型

标准库里所有的映射类型都是可变的，但有时候你会有这样的需求，比如不能让用户错误地修改某个映射。3.4.2 节提到过 Pingo.io，它里面就有个现成的例子。Pingo.io 里有个映射的名字叫作 board.pins，里面的数据是 GPIO 物理针脚的信息，我们当然不希望用户一个疏忽就把这些信息给改了。因为硬件方面的东西是不会受软件影响的，所以如果把这个映射里的信息改了，就跟物理上的元件对不上号了。

从 Python 3.3 开始，types 模块中引入了一个封装类名叫 MappingProxyType。如果给这个类一个映射，它会返回一个只读的映射视图。虽然是个只读视图，但是它是动态的。这意味着如果对原映射做出了改动，我们通过这个视图可以观察到，但是无法通过这个视图对原映射做出修改。示例 3-9 简短地对这个类的用法做了个演示。

示例 3-9　用 MappingProxyType 来获取字典的只读实例 mappingproxy

>>> from types import MappingProxyType >>> d = {1:'A'} >>> d_proxy = MappingProxyType(d) >>> d_proxy mappingproxy({1: 'A'}) >>> d_proxy[1] ➊ 'A' >>> d_proxy[2] = 'x' ➋ Traceback (most recent call last): File "<stdin>", line 1, in <module> TypeError: 'mappingproxy' object does not support item assignment >>> d[2] = 'B' >>> d_proxy ➌ mappingproxy({1: 'A', 2: 'B'}) >>> d_proxy[2] 'B' >>>

➊ d 中的内容可以通过 d_proxy 看到。

➋ 但是通过 d_proxy 并不能做任何修改。

➌ d_proxy 是动态的，也就是说对 d 所做的任何改动都会反馈到它上面。

因此在 Pingo.io 中我们是这样用它的：Board 的具体子类会提供一个包含针脚信息的私有映射成员，然后通过公开属性 .pins 把这个映射暴露给 API 的客户，而 .pins 属性其实就是用 mappingproxy 实现的。一旦这样写好了，客户就不能对这个映射进行任何意外的添加、移除或者修改操作。8

8 为了照顾 Python 2.7，现实中的 Pingo.io 没有借用 MappingProxyType 来实现这个功能，因为它只在 Python 3.3 里才有。

到了这里，我们对标准库中的大多数映射类型都有了一些了解，下面让我们移步到集合类型。

3.8　集合论

「集」这个概念在 Python 中算是比较年轻的，同时它的使用率也比较低。set 和它的不可变的姊妹类型 frozenset 直到 Python 2.3 才首次以模块的形式出现，然后在 Python 2.6 中它们升级成为内置类型。

本书中「集」或者「集合」既指 set，也指 frozenset。当「集」仅指代 set 类时，我会用等宽字体表示 9。

9「集」在英文中就是 set，因此原书中需要用等宽字体来区分特指和泛指。—— 编者注

集合的本质是许多唯一对象的聚集。因此，集合可以用于去重：

>>> l = ['spam', 'spam', 'eggs', 'spam'] >>> set(l) {'eggs', 'spam'} >>> list(set(l)) ['eggs', 'spam']

集合中的元素必须是可散列的，set 类型本身是不可散列的，但是 frozenset 可以。因此可以创建一个包含不同 frozenset 的 set。

除了保证唯一性，集合还实现了很多基础的中缀运算符。给定两个集合 a 和 b，a | b 返回的是它们的合集，a & b 得到的是交集，而 a - b 得到的是差集。合理地利用这些操作，不仅能够让代码的行数变少，还能减少 Python 程序的运行时间。这样做同时也是为了让代码更易读，从而更容易判断程序的正确性，因为利用这些运算符可以省去不必要的循环和逻辑操作。

例如，我们有一个电子邮件地址的集合（haystack），还要维护一个较小的电子邮件地址集合（needles），然后求出 needles 中有多少地址同时也出现在了 heystack 里。借助集合操作，我们只需要一行代码就可以了（见示例 3-10）。

示例 3-10　needles 的元素在 haystack 里出现的次数，两个变量都是 set 类型

found = len(needles & haystack)

如果不使用交集操作的话，代码可能就变成了示例 3-11 里那样。

示例 3-11　needles 的元素在 haystack 里出现的次数（作用和示例 3-10 中的相同）

found = 0 for n in needles: if n in haystack: found += 1

示例 3-10 比示例 3-11 的速度要快一些；另一方面，示例 3-11 可以用在任何可迭代对象 needles 和 haystack 上，而示例 3-10 则要求两个对象都是集合。话再说回来，就算手头没有集合，我们也可以随时建立集合，如示例 3-12 所示。

示例 3-12　needles 的元素在 haystack 里出现的次数，这次的代码可以用在任何可迭代对象上

found = len (set (needles) & set (haystack)) # 另一种写法： found = len (set (needles).intersection (haystack))

示例 3-12 里的这种写法会牵扯到把对象转化为集合的成本，不过如果 needles 或者是 haystack 中任意一个对象已经是集合，那么示例 3-12 的方案可能就比示例 3-11 里的要更高效。

以上的所有例子的运行时间都能在 3 毫秒左右，在含有 10 000 000 个元素的 haystack 里搜索 1000 个值，算下来大概是每个元素 3 微秒。

除了速度极快的查找功能（这也得归功于它背后的散列表），内置的 set 和 frozenset 提供了丰富的功能和操作，不但让创建集合的方式丰富多彩，而且对于 set 来讲，我们还可以对集合里已有的元素进行修改。在讨论这些操作之前，先来看一下相关的句法。

3.8.1　集合字面量

除空集之外，集合的字面量 ——{1}、{1, 2}，等等 —— 看起来跟它的数学形式一模一样。如果是空集，那么必须写成 set () 的形式。

句法的陷阱

不要忘了，如果要创建一个空集，你必须用不带任何参数的构造方法 set ()。如果只是写成 {} 的形式，跟以前一样，你创建的其实是个空字典。

在 Python 3 里面，除了空集，集合的字符串表示形式总是以 {...} 的形式出现。

>>> s = {1} >>> type(s) <class 'set'> >>> s {1} >>> s.pop() 1 >>> s set()

像 {1, 2, 3} 这种字面量句法相比于构造方法（set ([1, 2, 3])）要更快且更易读。后者的速度要慢一些，因为 Python 必须先从 set 这个名字来查询构造方法，然后新建一个列表，最后再把这个列表传入到构造方法里。但是如果是像 {1, 2, 3} 这样的字面量，Python 会利用一个专门的叫作 BUILD_SET 的字节码来创建集合。

用 dis.dis（反汇编函数）来看看两个方法的字节码的不同：

>>> from dis import dis >>> dis('{1}') ➊ 1 0 LOAD_CONST 0 (1) 3 BUILD_SET 1 ➋ 6 RETURN_VALUE >>> dis('set([1])') ➌ 1 0 LOAD_NAME 0 (set) ➍ 3 LOAD_CONST 0 (1) 6 BUILD_LIST 1 9 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 12 RETURN_VALUE

➊ 检查 {1} 字面量背后的字节码。

➋ 特殊的字节码 BUILD_SET 几乎完成了所有的工作。

➌ set ([1]) 的字节码。

➍ 3 种不同的操作代替了上面的 BUILD_SET：LOAD_NAME、BUILD_LIST 和 CALL_FUNCTION。

由于 Python 里没有针对 frozenset 的特殊字面量句法，我们只能采用构造方法。Python 3 里 frozenset 的标准字符串表示形式看起来就像构造方法调用一样。来看这段控制台对话：

>>> frozenset(range(10)) frozenset({0, 1, 2, 3, 4, 5, 6, 7, 8, 9})

既然提到了句法，就不得不提一下我们已经熟悉的列表推导，因为也有类似的方式来新建集合。

3.8.2　集合推导

Python 2.7 带来了集合推导（setcomps）和之前在 3.2 节里讲到过的字典推导。示例 3-13 是个简单的例子。

示例 3-13　新建一个 Latin-1 字符集合，该集合里的每个字符的 Unicode 名字里都有「SIGN」这个单词

>>> from unicodedata import name ➊ >>> {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')} ➋ {'§', '=', '¢', '#', '¤', '<', '¥', 'μ', '×', '$', '¶', '£', '©', '°', '+', '÷', '±', '>', '¬', '®', '%'}

➊ 从 unicodedata 模块里导入 name 函数，用以获取字符的名字。

➋ 把编码在 32~255 之间的字符的名字里有「SIGN」单词的挑出来，放到一个集合里。

跟句法相关的内容就讲到这里，下面看看用于集合类型的丰富操作。

3.8.3　集合的操作

图 3-2 列出了可变和不可变集合所拥有的方法的概况，其中不少是运算符重载的特殊方法。表 3-2 则包含了数学里集合的各种操作在 Python 中所对应的运算符和方法。其中有些运算符和方法会对集合做就地修改（像 &=、difference_update，等等），这类操作在纯粹的数学世界里是没有意义的，另外 frozenset 也不会实现这些操作。

图 3-2：collections.abc 中，MutableSet 和它的超类的 UML 类图（箭头从子类指向超类，抽象类和抽象方法的名称以斜体显示，其中省略了反向运算符方法）

表 3-2 中的中缀运算符需要两侧的被操作对象都是集合类型，但是其他的所有方法则只要求所传入的参数是可迭代对象。例如，想求 4 个聚合类型 a、b、c 和 d 的合集，可以用 a.union (b, c, d)，这里 a 必须是个 set，但是 b、c 和 d 则可以是任何类型的可迭代对象。

表 3-2：集合的数学运算：这些方法或者会生成新集合，或者会在条件允许的情况下就地修改集合

数学符号 Python 运算符 方法 描述

S ∩ Z s & z s.\_\_and\_\_(z) s 和 z 的交集

z & s s.\_\_rand\_\_(z) 反向 & 操作

s.intersection (it, ...) 把可迭代的 it 和其他所有参数转化为集合，然后求它们与 s 的交集

s &= z s.\_\_iand\_\_(z) 把 s 更新为 s 和 z 的交集

s.intersection\_update (it, ...) 把可迭代的 it 和其他所有参数转化为集合，然后求得它们与 s 的交集，然后把 s 更新成这个交集

S ∪ Z s | z s.\_\_or\_\_(z) s 和 z 的并集

z | s s.\_\_ror\_\_(z) | 的反向操作

s.union (it, ...) 把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的并集

s |= z s.\_\_ior\_\_(z) 把 s 更新为 s 和 z 的并集

s.update (it, ...) 把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的并集，并把 s 更新成这个并集

S \ Z s - z s.\_\_sub\_\_(z) s 和 z 的差集，或者叫作相对补集

z - s s.\_\_rsub\_\_(z) - 的反向操作

s.difference (it, ...) 把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的差集

s -= z s.\_\_isub\_\_(z) 把 s 更新为它与 z 的差集

s.difference\_update (it, ...) 把可迭代的 it 和其他所有参数转化为集合，求它们和 s 的差集，然后把 s 更新成这个差集

s.symmetric\_difference (it) 求 s 和 set (it) 的对称差集

S △ Z s ^ z s.\_\_xor\_\_(z) 求 s 和 z 的对称差集

z ^ s s.\_\_rxor\_\_(z) ^ 的反向操作

s.symmetric\_difference\_update (it, ...) 把可迭代的 it 和其他所有参数转化为集合，然后求它们和 s 的对称差集，最后把 s 更新成该结果

s ^= z s.\_\_ixor\_\_(z) 把 s 更新成它与 z 的对称差集

在写这本书的时候，Python 有个缺陷（issue 8743），里面说到 set () 的运算符（or、and、sub、xor 和它们相对应的就地修改运算符）要求参数必须是 set () 的实例，这就导致这些运算符不能被用在 collections.abc.Set 这个子类上面。这个缺陷已经在 Python 2.7 和 Python 3.4 里修复了，在你看到这本书的时候，它已经成了历史。

表 3-3 里列出了返回值是 True 和 False 的方法和运算符。

表 3-3：集合的比较运算符，返回值是布尔类型

数学符号 Python 运算符 方法 描述

s.isdisjoint (z) 查看 s 和 z 是否不相交（没有共同元素）

e ∈ S e in s s.\_\_contains\_\_(e) 元素 e 是否属于 s

S ⊆ Z s <= z s.\_\_le\_\_(z) s 是否为 z 的子集

s.issubset (it) 把可迭代的 it 转化为集合，然后查看 s 是否为它的子集

S ⊂ Z s <z s.\_\_lt\_\_(z) s 是否为 z 的真子集

S ⊇ Z s >= z s.\_\_ge\_\_(z) s 是否为 z 的父集

s.issuperset (it) 把可迭代的 it 转化为集合，然后查看 s 是否为它的父集

S ⊃ Z s > z s.\_\_gt\_\_(z) s 是否为 z 的真父集

除了跟数学上的集合计算有关的方法和运算符，集合类型还有一些为了实用性而添加的方法，其汇总见于表 3-4。

表 3-4：集合类型的其他方法

set

frozenset

s.add(e)

•

把元素 e 添加到 s 中

s.clear()

•

移除掉 s 中的所有元素

s.copy()

•

•

对 s 浅复制

s.discard(e)

•

如果 s 里有 e 这个元素的话，把它移除

s.__iter__()

•

•

返回 s 的迭代器

s.__len__()

•

•

len(s)

s.pop()

•

从 s 中移除一个元素并返回它的值，若 s 为空，则抛出 KeyError 异常

s.remove(e)

•

从 s 中移除 e 元素，若 e 元素不存在，则抛出 KeyError 异常

到这里，我们差不多把集合类型的特性总结完了。

下面会继续探讨字典和集合类型背后的实现，看看它们是如何借助散列表来实现这些功能的。读完这章余下的内容后，就算再遇到 dict、set 或是其他这一类型的一些莫名其妙的表现，你也不会手足无措。

3.9　dict 和 set 的背后

想要理解 Python 里字典和集合类型的长处和弱点，它们背后的散列表是绕不开的一环。

这一节将会回答以下几个问题。

Python 里的 dict 和 set 的效率有多高？

为什么它们是无序的？

为什么并不是所有的 Python 对象都可以当作 dict 的键或 set 里的元素？

为什么 dict 的键和 set 元素的顺序是跟据它们被添加的次序而定的，以及为什么在映射对象的生命周期中，这个顺序并不是一成不变的？

为什么不应该在迭代循环 dict 或是 set 的同时往里添加元素？

为了让你有动力研究散列表，下面先来看一个关于 dict 和 set 效率的实验，实验对象里大概有上百万个元素，而实验结果可能会出乎你的意料。

3.9.1　一个关于效率的实验

所有的 Python 程序员都从经验中得出结论，认为字典和集合的速度是非常快的。接下来我们要通过可控的实验来证实这一点。

为了对比容器的大小对 dict、set 或 list 的 in 运算符效率的影响，我创建了一个有 1000 万个双精度浮点数的数组，名叫 haystack。另外还有一个包含了 1000 个浮点数的 needles 数组，其中 500 个数字是从 haystack 里挑出来的，另外 500 个肯定不在 haystack 里。

作为 dict 测试的基准，我用 dict.fromkeys () 来建立了一个含有 1000 个浮点数的名叫 haystack 的字典，并用 timeit 模块测试示例 3-14（与示例 3-11 相同）里这段代码运行所需要的时间。

示例 3-14　在 haystack 里查找 needles 的元素，并计算找到的元素的个数

found = 0 for n in needles: if n in haystack: found += 1

然后这段基准测试重复了 4 次，每次都把 haystack 的大小变成了上一次的 10 倍，直到里面有 1000 万个元素。最后这些测试的结果列在了表 3-5 中。

表 3-5：用 in 运算符在 5 个不同大小的 haystack 字典里搜索 1000 个元素所需要的时间。代码运行在一个 Core i7 笔记本上，Python 版本是 3.4.0（测试计算的是示例 3-14 里循环的运行时间）

haystack 的长度

增长系数

dict 花费时间

增长系数

1000

1×

0.000202s

1.00×

10 000

10×

0.000140s

0.69×

100 000

100×

0.000228s

1.13×

1 000 000

1000×

0.000290s

1.44×

10 000 000

10 000×

0.000337s

1.67×

也就是说，在我的笔记本上从 1000 个字典键里搜索 1000 个浮点数所需的时间是 0.000202 秒，把同样的搜索在含有 10 000 000 个元素的字典里进行一遍，只需要 0.000337 秒。换句话说，在一个有 1000 万个键的字典里查找 1000 个数，花在每个数上的时间不过是 0.337 微秒 —— 没错，相当于平均每个数差不多三分之一微秒。

作为对比，我把 haystack 换成了 set 和 list 类型，重复了同样的增长大小的实验。对于 set，除了上面的那个循环的运行时间，我还测量了示例 3-15 那行代码，这段代码也计算了 needles 中出现在 haystack 中的元素的个数。

示例 3-15　利用交集来计算 needles 中出现在 haystack 中的元素的个数

found = len(needles & haystack)

表 3-6 列出了所有测试的结果。最快的时间来自「集合交集花费时间」这一列，这一列的结果是示例 3-15 中利用集合 & 操作的代码的效果。不出所料的是，最糟糕的表现来自「列表花费时间」这一列。由于列表的背后没有散列表来支持 in 运算符，每次搜索都需要扫描一次完整的列表，导致所需的时间跟据 haystack 的大小呈线性增长。

表 3-6：在 5 个不同大小的 haystack 里搜索 1000 个元素所需的时间，haystack 分别以字典、集合和列表的形式出现。测试环境是一个有 Core i7 处理器的笔记本，Python 版本是 3.4.0（测试所测量的代码是示例 3-14 中的循环和示例 3-15 的集合 & 操作）

haystack 的长度

增长系数

dict 花费时间

增长系数

集合花费时间

增长系数

集合交集花费时间

增长系数

列表花费时间

增长系数

1000

1×

0.000202s

1.00×

0.000143s

1.00×

0.000087s

1.00×

0.010556s

1.00×

10 000

10×

0.000140s

0.69×

0.000147s

1.03×

0.000092s

1.06×

0.086586s

8.20×

100 000

100×

0.000228s

1.13×

0.000241s

1.69×

0.000163s

1.87×

0.871560s

82.57×

1 000 000

1000×

0.000290s

1.44×

0.000332s

2.32×

0.000250s

2.87×

9.189616s

870.56×

10 000 000

10 000×

0.000337s

1.67×

0.000387s

2.71×

0.000314s

3.61×

97.948056s

9278.90×

如果在你的程序里有任何的磁盘输入 / 输出，那么不管查询有多少个元素的字典或集合，所耗费的时间都能忽略不计（前提是字典或者集合不超过内存大小）。可以仔细看看跟表 3-6 有关的代码，另外在附录 A 的示例 A-1 中还有相关的讨论。

把字典和集合的运行速度之快的事实抓在手里之后，让我们来看看它背后的原因。对散列表内部结构的讨论，能解释诸如为什么键是无序且不稳定的。

3.9.2　字典中的散列表

这一节笼统地描述了 Python 如何用散列表来实现 dict 类型，有些细节只是一笔带过，像 CPython 里的一些优化技巧 10 就没有提到。但是总体来说描述是准确的。

10Python 源码 dictobject.c 模块里有丰富的注释，另外延伸阅读中有对《代码之美》一书的引用。

为了简单起见，这里先集中讨论 dict 的内部结构，然后再延伸到集合上面。

散列表其实是一个稀疏数组（总是有空白元素的数组称为稀疏数组）。在一般的数据结构教材中，散列表里的单元通常叫作表元（bucket）。在 dict 的散列表当中，每个键值对都占用一个表元，每个表元都有两个部分，一个是对键的引用，另一个是对值的引用。因为所有表元的大小一致，所以可以通过偏移量来读取某个表元。

因为 Python 会设法保证大概还有三分之一的表元是空的，所以在快要达到这个阈值的时候，原有的散列表会被复制到一个更大的空间里面。

如果要把一个对象放入散列表，那么首先要计算这个元素键的散列值。Python 中可以用 hash () 方法来做这件事情，接下来会介绍这一点。

散列值和相等性

内置的 hash () 方法可以用于所有的内置类型对象。如果是自定义对象调用 hash () 的话，实际上运行的是自定义的 __hash__。如果两个对象在比较的时候是相等的，那它们的散列值必须相等，否则散列表就不能正常运行了。例如，如果 1 == 1.0 为真，那么 hash (1) == hash (1.0) 也必须为真，但其实这两个数字（整型和浮点）的内部结构是完全不一样的。11

为了让散列值能够胜任散列表索引这一角色，它们必须在索引空间中尽量分散开来。这意味着在最理想的状况下，越是相似但不相等的对象，它们散列值的差别应该越大。示例 3-16 是一段代码输出，这段代码被用来比较散列值的二进制表达的不同。注意其中 1 和 1.0 的散列值是相同的，而 1.0001、1.0002 和 1.0003 的散列值则非常不同。

示例 3-16　在 32 位的 Python 中，1、1.0001、1.0002 和 1.0003 这几个数的散列值的二进制表达对比（上下两个二进制间不同的位被！高亮出来，表格的最右列显示了有多少位不相同）

32-bit Python build 1 00000000000000000000000000000001 != 0 1.0 00000000000000000000000000000001 ------------------------------------------------ 1.0 00000000000000000000000000000001 ! !!! ! !! ! ! ! ! !! !!! != 16 1.0001 00101110101101010000101011011101 ------------------------------------------------ 1.0001 00101110101101010000101011011101 !!! !!!! !!!!! !!!!! !! ! != 20 1.0002 01011101011010100001010110111001 ------------------------------------------------ 1.0002 01011101011010100001010110111001 ! ! ! !!! ! ! !! ! ! ! !!!! != 17 1.0003 00001100000111110010000010010110 ------------------------------------------------

用来计算示例 3-16 的程序见于附录 A。尽管程序里大部分代码都是用来整理输出格式的，考虑到完整性，我还是把全部的代码放在示例 A-3 中了。

从 Python 3.3 开始，str、bytes 和 datetime 对象的散列值计算过程中多了随机的「加盐」这一步。所加盐值是 Python 进程内的一个常量，但是每次启动 Python 解释器都会生成一个不同的盐值。随机盐值的加入是为了防止 DOS 攻击而采取的一种安全措施。在 __hash__ 特殊方法的文档里有相关的详细信息。

了解对象散列值相关的基本概念之后，我们可以深入到散列表工作原理背后的算法了。

散列表算法

为了获取 my_dict [search_key] 背后的值，Python 首先会调用 hash (search_key) 来计算 search_key 的散列值，把这个值最低的几位数字当作偏移量，在散列表里查找表元（具体取几位，得看当前散列表的大小）。若找到的表元是空的，则抛出 KeyError 异常。若不是空的，则表元里会有一对 found_key:found_value。这时候 Python 会检验 search_key == found_key 是否为真，如果它们相等的话，就会返回 found_value。

如果 search_key 和 found_key 不匹配的话，这种情况称为散列冲突。发生这种情况是因为，散列表所做的其实是把随机的元素映射到只有几位的数字上，而散列表本身的索引又只依赖于这个数字的一部分。为了解决散列冲突，算法会在散列值中另外再取几位，然后用特殊的方法处理一下，把新得到的数字再当作索引来寻找表元。12 若这次找到的表元是空的，则同样抛出 KeyError；若非空，或者键匹配，则返回这个值；或者又发现了散列冲突，则重复以上的步骤。图 3-3 展示了这个算法的示意图。

图 3-3：从字典中取值的算法流程图；给定一个键，这个算法要么返回一个值，要么抛出 KeyError 异常

添加新元素和更新现有键值的操作几乎跟上面一样。只不过对于前者，在发现空表元的时候会放入一个新元素；对于后者，在找到相对应的表元后，原表里的值对象会被替换成新值。

另外在插入新值时，Python 可能会按照散列表的拥挤程度来决定是否要重新分配内存为它扩容。如果增加了散列表的大小，那散列值所占的位数和用作索引的位数都会随之增加，这样做的目的是为了减少发生散列冲突的概率。

表面上看，这个算法似乎很费事，而实际上就算 dict 里有数百万个元素，多数的搜索过程中并不会有冲突发生，平均下来每次搜索可能会有一到两次冲突。在正常情况下，就算是最不走运的键所遇到的冲突的次数用一只手也能数过来。

了解 dict 的工作原理能让我们知道它的所长和所短，以及从它衍生而来的数据类型的优缺点。下面就来看看 dict 这些特点背后的原因。

11 既然提到了整型，CPython 的实现细节里有一条是：如果有一个整型对象，而且它能被存进一个机器字中，那么它的散列值就是它本身的值。

12 在散列冲突的情况下，用 C 语言写的用来打乱散列值位的算法的名字很有意思，叫 perturb。详见 CPython 源码里的 dictobject.c（https://hg.python.org/cpython/file/tip/Objects/dictobject.c）。

3.9.3　dict 的实现及其导致的结果

下面的内容会讨论使用散列表给 dict 带来的优势和限制都有哪些。

键必须是可散列的

一个可散列的对象必须满足以下要求。

(1) 支持 hash () 函数，并且通过 __hash__() 方法所得到的散列值是不变的。

(2) 支持通过 __eq__() 方法来检测相等性。

(3) 若 a == b 为真，则 hash (a) == hash (b) 也为真。

所有由用户自定义的对象默认都是可散列的，因为它们的散列值由 id () 来获取，而且它们都是不相等的。

如果你实现了一个类的 __eq__ 方法，并且希望它是可散列的，那么它一定要有个恰当的 __hash__ 方法，保证在 a == b 为真的情况下 hash (a) == hash (b) 也必定为真。否则就会破坏恒定的散列表算法，导致由这些对象所组成的字典和集合完全失去可靠性，这个后果是非常可怕的。另一方面，如果一个含有自定义的 __eq__ 依赖的类处于可变的状态，那就不要在这个类中实现 __hash__ 方法，因为它的实例是不可散列的。

字典在内存上的开销巨大

由于字典使用了散列表，而散列表又必须是稀疏的，这导致它在空间上的效率低下。举例而言，如果你需要存放数量巨大的记录，那么放在由元组或是具名元组构成的列表中会是比较好的选择；最好不要根据 JSON 的风格，用由字典组成的列表来存放这些记录。用元组取代字典就能节省空间的原因有两个：其一是避免了散列表所耗费的空间，其二是无需把记录中字段的名字在每个元素里都存一遍。

在用户自定义的类型中，__slots__ 属性可以改变实例属性的存储方式，由 dict 变成 tuple，相关细节在 9.8 节会谈到。

记住我们现在讨论的是空间优化。如果你手头有几百万个对象，而你的机器有几个 GB 的内存，那么空间的优化工作可以等到真正需要的时候再开始计划，因为优化往往是可维护性的对立面。

键查询很快

dict 的实现是典型的空间换时间：字典类型有着巨大的内存开销，但它们提供了无视数据量大小的快速访问 —— 只要字典能被装在内存里。正如表 3-5 所示，如果把字典的大小从 1000 个元素增加到 10 000 000 个，查询时间也不过是原来的 2.8 倍，从 0.000163 秒增加到了 0.00456 秒。这意味着在一个有 1000 万个元素的字典里，每秒能进行 200 万个键查询。

键的次序取决于添加顺序

当往 dict 里添加新键而又发生散列冲突的时候，新键可能会被安排存放到另一个位置。于是下面这种情况就会发生：由 dict ([key1, value1), (key2, value2)] 和 dict ([key2, value2], [key1, value1]) 得到的两个字典，在进行比较的时候，它们是相等的；但是如果在 key1 和 key2 被添加到字典里的过程中有冲突发生的话，这两个键出现在字典里的顺序是不一样的。

示例 3-17 展示了这个现象。这个示例用同样的数据创建了 3 个字典，唯一的区别就是数据出现的顺序不一样。可以看到，虽然键的次序是乱的，这 3 个字典仍然被视作相等的。

示例 3-17　dialcodes.py 将同样的数据以不同的顺序添加到 3 个字典里

# 世界人口数量前 10 位国家的电话区号 DIAL_CODES = [(86, 'China'), (91, 'India'), (1, 'United States'), (62, 'Indonesia'), (55, 'Brazil'), (92, 'Pakistan'), (880, 'Bangladesh'), (234, 'Nigeria'), (7, 'Russia'), (81, 'Japan'), ] d1 = dict (DIAL_CODES) ➊ print ('d1:', d1.keys ()) d2 = dict (sorted (DIAL_CODES)) ➋ print ('d2:', d2.keys ()) d3 = dict (sorted (DIAL_CODES, key=lambda x:x [1])) ➌ print ('d3:', d3.keys ()) assert d1 == d2 and d2 == d3 ➍

➊ 创建 d1 的时候，数据元组的顺序是按照国家的人口排名来决定的。

➋ 创建 d2 的时候，数据元组的顺序是按照国家的电话区号来决定的。

➌ 创建 d3 的时候，数据元组的顺序是按照国家名字的英文拼写来决定的。

➍ 这些字典是相等的，因为它们所包含的数据是一样的。示例 3-18 里是上面例子的输出。

示例 3-18　dialcodes.py 的输出中，3 个字典的键的顺序是不一样的

d1: dict_keys([880, 1, 86, 55, 7, 234, 91, 92, 62, 81]) d2: dict_keys([880, 1, 91, 86, 81, 55, 234, 7, 92, 62]) d3: dict_keys([880, 81, 1, 86, 55, 7, 234, 91, 92, 62])

往字典里添加新键可能会改变已有键的顺序

无论何时往字典里添加新的键，Python 解释器都可能做出为字典扩容的决定。扩容导致的结果就是要新建一个更大的散列表，并把字典里已有的元素添加到新表里。这个过程中可能会发生新的散列冲突，导致新散列表中键的次序变化。要注意的是，上面提到的这些变化是否会发生以及如何发生，都依赖于字典背后的具体实现，因此你不能很自信地说自己知道背后发生了什么。如果你在迭代一个字典的所有键的过程中同时对字典进行修改，那么这个循环很有可能会跳过一些键 —— 甚至是跳过那些字典中已经有的键。

由此可知，不要对字典同时进行迭代和修改。如果想扫描并修改一个字典，最好分成两步来进行：首先对字典迭代，以得出需要添加的内容，把这些内容放在一个新字典里；迭代结束之后再对原有字典进行更新。

在 Python 3 中，.keys ()、.items () 和 .values () 方法返回的都是字典视图。也就是说，这些方法返回的值更像集合，而不是像 Python 2 那样返回列表。视图还有动态的特性，它们可以实时反馈字典的变化。

现在已经可以把学到的有关散列表的知识应用在集合上面了。

3.9.4　set 的实现以及导致的结果

set 和 frozenset 的实现也依赖散列表，但在它们的散列表里存放的只有元素的引用（就像在字典里只存放键而没有相应的值）。在 set 加入到 Python 之前，我们都是把字典加上无意义的值当作集合来用的。

在 3.9.3 节中所提到的字典和散列表的几个特点，对集合来说几乎都是适用的。为了避免太多重复的内容，这些特点总结如下。

集合里的元素必须是可散列的。

集合很消耗内存。

可以很高效地判断元素是否存在于某个集合。

元素的次序取决于被添加到集合里的次序。

往集合里添加元素，可能会改变集合里已有元素的次序。

3.10　本章小结

字典算得上是 Python 的基石。除了基本的 dict 之外，标准库还提供现成且好用的特殊映射类型，比如 defaultdict、OrderedDict、ChainMap 和 Counter。这些映射类型都属于 collections 模块，这个模块还提供了便于扩展的 UserDict 类。

大多数映射类型都提供了两个很强大的方法：setdefault 和 update。setdefault 方法可以用来更新字典里存放的可变值（比如列表），从而避免了重复的键搜索。update 方法则让批量更新成为可能，它可以用来插入新值或者更新已有键值对，它的参数可以是包含 (key, value) 这种键值对的可迭代对象，或者关键字参数。映射类型的构造方法也会利用 update 方法来让用户可以使用别的映射对象、可迭代对象或者关键字参数来创建新对象。

在映射类型的 API 中，有个很好用的方法是 __missing__，当对象找不到某个键的时候，可以通过这个方法自定义会发生什么。

collections.abc 模块提供了 Mapping 和 MutableMapping 这两个抽象基类，利用它们，我们可以进行类型查询或者引用。不太为人所知的 MappingProxyType 可以用来创建不可变映射对象，它被封装在 types 模块中。另外还有 Set 和 MutableSet 这两个抽象基类。

dict 和 set 背后的散列表效率很高，对它的了解越深入，就越能理解为什么被保存的元素会呈现出不同的顺序，以及已有的元素顺序会发生变化的原因。同时，速度是以牺牲空间为代价而换来的。

3.11　延伸阅读

Python 标准库中的「8.3. collections—Container datatypes」一节提到了关于一些映射类型的例子和使用技巧。如果想要创建新的映射类型，或者是体会一下现有的映射类型的实现方式，Python 模块 Lib/collections/__init__.py 的源码是一个很好的参考。

《Python Cookbook（第 3 版）中文版》（David Beazley 和 Brian K. Jones 著）的第 1 章中有 20 个关于数据结构的使用技巧，大多数都在讲 dict 的巧妙用法。

「Python 的字典类：如何打造全能战士」是《代码之美》第 18 章的标题，这一章集中解释了 Python 字典背后的工作原理。A.M. Kuchling 是这一章的作者，同时他还是 Python 的核心开发者，并撰写了很多 Python 的官方文档和指南。同时 CPython 模块里的 dictobject.c 源文件还提供了大量的注释。Brandon Craig Rhodes 的讲座「The Mighty Dictionary」对散列表做了很精彩的讲解，有趣的是他的幻灯片里也包含了大量的表格。

关于为什么要在语言里加入集合这种数据类型，当初也是有一番考量的。具体情况在「PEP 218 — Adding a Built-In Set Object Type」中有所记录。在 PEP 128 刚刚通过的时候，还没有针对 set 的特殊字面量句法。后来 Python 3 里加入了对 set 字面量句法的支持，然后这个实现又被向后兼容到了 Python 2.7 里，同时被移植的还有 dict 和 set 推导。「PEP 274 — Dict Comprehensions」就是字典推导的出生证；然而我找不到任何关于集合推导的 PEP，当然很有可能是因为这两个功能太接近了。

杂谈

我的朋友 Geraldo Cohen 曾经说过，Python 的特点是「简单而正确」。

dict 类型正是这一特点的完美体现 —— 对它的优化只为一个目标：更好地实现对随机键的读取。而优化的结果非常好，由于速度快而且够健壮，它大量地应用于 Python 的解释器当中。如果对排序有要求，那么还可以选择 OrderedDict。然而对于映射类型来说，保持元素的顺序并不是一个常用需求，因此会把它排除在核心功能之外，而以标准库的形式提供其他衍生的类型。

与之形成鲜明对比的是 PHP。在 PHP 手册中，数组的描述如下：

PHP 中的数组实际上是一个有序的映射 —— 映射类型存放的是键值对。这个映射类型被优化为可充当不同的角色。它可以当作数组、列表（向量）、散列表（映射类型的一种实现）、字典、集合类型、栈、队列或其他可能的数据类型。

单凭这段话，我无法想象 PHP 把 list 和 OrderedDict 混合实现的成本有多大。

本书前两章的目的是展示 Python 中的集合类型为特定的使用场景做了怎样的优化。我特意强调了在 list 和 dict 的常规用法之外还有那些特殊的使用情景。

在遇到 Python 之前，我主要使用 Perl、PHP 和 JavaScript 做网站开发。我很喜欢这些语言中跟映射类型相关的字面量句法特性。某些时候我不得不使用 Java 和 C，然后我就会疯狂地想念这些特性。好用的映射类型的字面量句法可以帮助开发者轻松实现配置和表格相关的开发，也能让我们很方便地为原型开发或者测试准备好数据容器。Java 由于没有这个特性，不得不用复杂且冗长的 XML 来替代。

JSON 被当作「瘦身版 XML」。在很多情景下，JSON 都成功取代了 XML。由于拥有紧凑的列表和字典表达，JSON 格式可以完美地用于数据交换。

PHP 和 Ruby 的散列语法借鉴了 Perl，它们都用 => 作为键和值的连接。JavaScript 则从 Python 那儿偷师，使用了 :。而 JSON 又从 JavaScript 发展而来，它的语法正好是 Python 句法的子集。因此，除了在 true、false 和 null 这几个值的拼写上有出入之外，JSON 和 Python 是完全兼容的。于是，现在大家用来交换数据的格式全是 Python 的 dict 和 list。

简单而正确。

