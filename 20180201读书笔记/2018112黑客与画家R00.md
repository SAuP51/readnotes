## 记忆时间

## 卡片

### 0101. 主题卡——

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

#### 01. 常识

#### 02. 反常识

#### 03. 知识来源

比如提出者，如何演化成型的；书或专栏具体出现的地方。

#### 04. 例子

### 0201. 术语卡——编程语言的演化主干

编程语言如同生物物种一般演化，关心一百年后的编程语言等同于选择演化的主干。

任何一种编程语言都可以分成两大组成部分：基本运算符的集合（扮演公理的角色）以及除运算符以外的其他部分（原则上，这个部分可以用基本运算符表达出来）。我认为，基本运算符是一种语言能否长期存在的最重要因素。其他因素都不是决定性的。这有点像买房子的时候你应该先考虑地理位置。别的地方将来出问题都有办法弥补，但是地理位置是没法变的。慎重选择公理还不够，还必须控制它的规模。数学家总是觉得公理越少越好，我觉得他们说到了点子上。

你仔细审视一种语言的内核，考虑哪些部分可以被摒弃，这至少也是一种很有用的训练。在长期的职业生涯中，我发现冗余的代码会导致更多冗余的代码，不仅软件如此，而且像我这样性格懒散的人，我发现在床底下和房间的角落里这个命题也成立，一件垃圾会产生更多的垃圾。我的判断是，那些内核最小、最干净的编程语言才会存在于进化的主干上。一种语言的内核设计得越小、越干净，它的生命力就越顽强。

### 0202. 术语卡——

根据反常识，再补充三个证据——就产生三张术语卡。

### 0203. 术语卡——

### 0301. 人名卡——Paul Graham

[保罗·格雷厄姆 - 维基百科，自由的百科全书](https://zh.wikipedia.org/zh-cn/%E4%BF%9D%E7%BD%97%C2%B7%E6%A0%BC%E9%9B%B7%E5%8E%84%E5%A7%86)

[Paul Graham (@paulg) / Twitter](https://twitter.com/paulg)

保罗·格雷厄姆（英语：Paul Graham，1964－）

印象：黑客、风投，有硅谷创业之父之称，《黑客与画家》的作者。

美国著名程序员、风险投资家、博客和技术作家。他以 Lisp 方面的工作而知名，也是最早的 Web 应用 Viaweb 的创办者之一，后来以近 5 千万美元价格被雅虎收购，成为 Yahoo! Store。他的著作包括《On Lisp》（1993），《ANSI Common Lisp》（1995）和《Hackers & Painters》（2004）。

### 0302. 人名卡——

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

### 0401. 金句卡——

最后根据他写的非常震撼的话语——产生一张金句卡。

### 0501. 行动卡——

行动卡是能够指导自己的行动的卡。

### 0601. 任意卡——

最后还有一张任意卡，记录个人阅读感想。

## 模板

### 1. 逻辑脉络

用自己的话总结主题，梳理逻辑脉络，也就是这本书整个地图里这一章所在的节点。

### 2. 摘录及评论

## 前言

本书是硅谷创业之父 Paul Graham 的文集，主要介绍黑客即优秀程序员的爱好和动机，讨论黑客成长、黑客对世界的贡献以及编程语言和黑客工作方法等所有对计算机时代感兴趣的人的一些话题。书中的内容不但有助于了解计算机编程的本质、互联网行业的规则，还会帮助读者了解我们这个时代，迫使读者独立思考。

软件带来财富，仅仅代表了大趋势的一面而已。这种大趋势就是本书的主题。我们的时代是计算机时代。以前，人们曾经认定这个时代应该是太空时代或者原子时代。但是事实证明，它们只是公关公司发明的概念。计算机对人类生活的影响远远超过了太空航行或者原子技术的影响。

本书后面几章谈的是大多数非计算机行业的人士没有想过的问题 —— 编程语言。为什么普通人要去关心编程语言？因为如果你想了解黑客，就必须懂一点编程语言。这就好比回到 1880 年，如果你想理解技术发展，就必须懂一点蒸汽机。

计算机程序只是文本而已。你选择什么语言，决定了你能说什么话。编程语言就是程序员的思维方式。

1968 年至 1972 年期间，美国出版过一本叫做《地球商品目录》（Whole Earth Catalog）的杂志，内容从植物种子到电子仪器，无所不包，出版目的据说是要帮助读者「理解整个系统」。多年后，苹果公司的总裁乔布斯盛赞它「有点像印刷版的谷歌」。从某种意义上说，本书也是如此，作者试图从许许多多不同的方面解释这个时代的内在脉络，揭示它的发展轨迹，帮助你看清我们现在的位置和将来的方向。

想要把握这个时代，就必须理解计算机。理解计算机的关键，则是要理解计算机背后的人。表面上这是一个机器的时代，但是实际上机器的设计者决定了我们的时代。程序员的审美决定了你看到的软件界面，程序员的爱好决定了你有什么样的软件可以使用。我们的时代是程序员主导的时代，而伟大的程序员就是黑客。本书就是帮助你了解黑客、从而理解这个时代的一把钥匙。

为了把这个问题说清楚，有必要从源头上讲起。1946 年，第一台电子计算机 ENIAC 在美国诞生，从此世界上一些最聪明、最有创造力的人开始进入这个行业，在他们身上逐渐地形成了一种独特的技术文化。在这种文化的发展过程中，涌现了很多「行话」（jargon）。20 世纪 60 年代初，麻省理工学院有一个学生团体叫做「铁路模型技术俱乐部」（Tech Model Railroad Club，简称 TMRC），他们把难题的解决方法称为 hack。

在这里，hack 作为名词有两个意思，既可以指很巧妙或很便捷的解决方法，也可以指比较笨拙、不那么优雅的解决方法。两者都能称为 hack，不同的是，前者是漂亮的解决方法（cool hack 或 neat hack），后者是丑陋的解决方法（ugly hack 或 quick hack）。hack 的字典解释是砍（木头），在这些学生看来，解决一个计算机难题就好像砍倒一棵大树。那么相应地，完成这种 hack 的过程就被称为 hacking，而从事 hacking 的人就是 hacker，也就是黑客。

从这个意思出发，hack 还有一个引申义，指对某个程序或设备进行修改，使其完成原来不可用的功能（或者禁止外部使用者接触到的功能）。在这种意义上，hacking 可以与盗窃信息、信用卡欺诈或其他计算机犯罪联系在一起，这也是后来「黑客」被当作计算机入侵者的称呼的原因。

但是，在 20 世纪 60 年代这个词被发明的时候，「黑客」完全是正面意义上的称呼。TMRC 使用这个词是带有敬意的，因为在他们看来，如果要完成一个 hack，就必然包含着高度的革新、独树一帜的风格、精湛的技艺。最能干的人会自豪地称自己为黑客。

这时，「黑客」这个词不仅是第一流能力的象征，还包含着求解问题过程中产生的精神愉悦或享受。也就是说，从一开始，黑客就是有精神追求的。自由软件基金会创始人理查德·斯托尔曼说：「出于兴趣而解决某个难题，不管它有没有用，这就是黑客。」[1]

根据理查德·斯托尔曼的说法，黑客行为必须包含三个特点：好玩、高智商、探索精神。只有其行为同时满足这三个标准，才能被称为「黑客」。另一方面，它们也构成了黑客的价值观，黑客追求的就是这三种价值，而不是实用性或金钱。

1984 年，《新闻周刊》的记者史蒂文·利维出版了历史上第一本介绍黑客的著作 ——《黑客：计算机革命的英雄》（Hackers: Heroes of the Computer Revolution）。在该书中，他进一步将黑客的价值观总结为六条「黑客伦理」（hacker ethic），直到今天这几条伦理都被视为这方面的最佳论述。

1. 使用计算机以及所有有助于了解这个世界本质的事物都不应受到任何限制。任何事情都应该亲手尝试。

    Access to computers—and anything that might teach you something about the way the world works—should be unlimited and total. Always yield to the Hands-On Imperative!

2. 信息应该全部免费。

    All information should be free.

3. 不信任权威，提倡去中心化。

    Mistrust Authority—Promote Decentralization.

4. 判断一名黑客的水平应该看他的技术能力，而不是看他的学历、年龄或地位等其他标准。

    Hackers should be judged by their hacking, not bogus criteria such as degrees, age, race, or position.

5. 你可以用计算机创造美和艺术。

    You can create art and beauty on a computer.

6. 计算机使生活更美好。

    Computers can change your life for the better.）

根据这六条「黑客伦理」，黑客价值观的核心原则可以概括成这样几点：分享、开放、民主、计算机的自由使用、进步。所以，「黑客」这个词的原始含义就是指那些信奉「黑客伦理」而且能力高超的程序员。历史上一些最优秀的程序员都是「黑客」。除了上文提到的理查德·斯托尔曼，还包括 Unix 操作系统创始人丹尼斯·里奇和肯·汤普森，经典巨著《计算机程序设计艺术》的作者、斯坦福大学计算机教授高德纳，Linux 操作系统创始人莱纳斯·托沃兹，「开源运动」创始人埃里克·雷蒙德，微软公司创始人比尔·盖茨等。正是黑客把计算机工业推向了更高的高度。

「黑客伦理」的一个必然推论就是，黑客不服从管教，具有叛逆精神。

黑客通常对管理者强加的、限制他们行为的愚蠢规定不屑一顾，会找出规避的方法。一部分原因是为了自由使用计算机，另一部分原因是为了展现自己的聪明。比如，计算机设备的各种安全措施就是最常被黑客破解的东西。史蒂文·利维对这一点有过一段生动的描述：

「对于黑客来说，关着的门就是一种挑衅，而锁着的门则是一种侮辱。…… 黑客相信，只要有助于改进现状、探索未知，人们就应该被允许自由地使用各种工具和信息。当一个黑客需要一样东西来帮助自己创造、探索或者改正某种设备时，他不会自找麻烦，不会接受那些财产专有权的荒谬概念。」

这就是黑客有时会入侵计算机系统的原因，他们的主要目的并不是侵犯别人的利益，这与那些计算机罪犯是不同的。但是，20 世纪 80 年代初，事情发生了变化。

全书 15 章可以大致分成三个部分。第一部分从第 1 章到第 4 章，解释了黑客是如何成长的以及他们看待世界的一些观点；第二部分从第 5 章到第 9 章，解释了黑客怎样做出自己的成果，这些成果又是怎样对全世界产生了影响；第三部分从第 10 章到第 15 章，解释了黑客的工具（编程语言）和工作方法，这是黑客文化的基础和核心。

结果令人鼓舞，格雷厄姆觉得可以把这件事情做下去，将扶植创业公司作为一项事业。于是，他和莫里斯再加上特雷弗·布莱克韦尔和杰西卡·立弗斯通 [2]，合伙在硅谷成立了 Y Combinator [3]（Y 运算子，简称 YC）。根据格雷厄姆的设想，它既是一个创业公司的孵化器，也是一个教导员，还是一个与投资人联系的中介。

1『原来 YC 是格雷厄姆（Paul Graham）创建的。』

保罗·格雷厄姆有一套完整的创业哲学，他的创业公式是：

1. 搭建原型

2. 上线运营（别管 bug）

3. 收集反馈

4. 调整产品

5. 成长壮大

首先，他鼓励创业公司快速发布产品，因为这样可以尽早知道一个创意是否可行。其次，他认为一定要特别关注用户需要什么，这样才有办法将一个坏项目转变成好项目。他说：「许多伟大的公司，一开始的时候做的都是与后来业务完全不同的事情。乔布斯创建苹果公司后的第一个计划是出售计算机零件，然后让用户自己组装，后来才变成开发苹果电脑。你需要倾听用户的声音，琢磨他们需要什么，然后就去做。」所有学员刚刚来到 YC 的时候，每人都会拿到一件白色 T 恤衫，上面写着「Make something people want」（制造用户需要的东西），等到他们的项目得到风险投资以后，又会收到一件黑色 T 恤衫，上面写着「I made something people want」（我制造了用户需要的东西）。

比起那些令人叫好的创意，格雷厄姆更看重创始人的素质。他说：「我们从一开始就认识到，创始人本身比他的创意更重要。」他还认为，小团队更容易成功，创始成员总数最好不要超过三个人。其中一个原因是，创始人越多，股权越不容易平等分配，容易造成内耗。

格雷厄姆认为，我们正在进入一个创业时代。未来的社会，创业可能成为一种常态，而替别人打工反而成了少见的事情。一方面，创业是最有效的创造财富的方法，对创始人、对投资者、对社会都是如此。「如果拉里·佩奇（Larry Page）和谢尔盖·布林（Sergey Brin）没有创立谷歌，那么他们可能还在某个研究部门工作，写一些不会有多少人使用的代码。但是，他们选择了创业，想一想这样做为全世界增加了多少价值？」另一方面，创业越来越简单了，成本也越来越低。「以前创业很昂贵，你不得不找到投资人才能创业。而现在，唯一的门槛就是勇气。」

## 10. 编程语言解析

### 1. 逻辑脉络

机器语言是计算机的操作命令清单。编译器的存在，可以将以某种简便方式书写的程序转变为计算器可以理解的语言，而这种简便方式书写的语言即为高级语言。

### 2. 摘录及评论

所有机器都有一张操作命令清单，让你可以控制它。有时这个清单非常简短。电水壶就只允许两种操作：打开和关闭。CD 播放器稍微复杂点，除了打开和关闭以外，还能调节音量、播放、暂停、快进、快退、随机播放等。计算机和其他机器一样，也有一张操作命令清单。比如，可以命令计算机把两个数相加。这种操作命令的总和就是计算机的机器语言（machine language）。

计算机刚发明的时候，所有程序就是一条条机器语言的命令。没过多久，程序就改成使用汇编语言了，它要比机器语言写起来稍微方便一点。命令清单还是一样的，就是每个命令换了一个更人性化的名字。机器语言的加法命令是 11001101，这可能就是计算机内部的加法表达方式，但是在汇编语言中，这条命令就改成了 add。机器语言和汇编语言的共同问题就是，只能让大多数计算机做一些很简单的事情。比如，假定你想让计算机的蜂鸣器响 10 次，但是不存在一条直接的机器语言命令让电脑重复进行 n 次操作，所以只能用机器语言写出下面这样的程序：

如果只是为了让蜂鸣器响 10 次就不得不写这么多代码，不难想象写出一个文字处理器或电子表格将是一项多么浩大的工程。顺便说一句，请再看一下上面的程序。蜂鸣器真的会响 10 次吗？不，响了 11 次。我不应该在第一行使用 10，而应该使用 9。我故意在这个例子中留了一个 bug，证明编程语言的一个重要特点：一个操作所需的代码越多，就越难避免 bug，也越难发现它们。

1『编程里很多很多地方，计数是从 0 开始的。』

接下来，你的助手会用汇编语言来实现这条命令（假定他不会产生 bug）。事实上大多数程序员就是这样工作的，不同之处就是，程序员的助手不是一个人，而是编译器。所谓「编译器」，本身就是一个程序，作用是将简便方式书写的程序（就像上面这一行命令）转变为硬件可以理解的语言。这种简便方式书写的程序所使用的语言就叫做高级语言。它让你能够使用更强大的命令开发程序，比如现在你就有了「重复 n 次操作」的命令，不再仅限于只能做简单的「两个数相加」。

写程序时有了方便的命令，就可以把程序写得更简短。在上面假想的例子中，高级语言写出来的程序的长度只有机器语言的五分之一。所以，要是你犯错了，现在也更容易发现。高级语言还有一个优点，它使得程序更具有可移植性。不同计算机的机器语言都不是完全相同的。所以，你无法将为某一种机型写的机器语言程序放到另一种机型上运行，只有彻底重写才能实现。但是，如果你的程序是用高级语言写的，你只需要重写编译器就可以了。

编译器不是高级语言唯一的实现方法，另一种方法是使用解释器，它的作用是实时地将代码解释为相应的机器语言，然后一行行运行。相比之下，编译器则是先将整个程序全部翻译成机器语言，然后再运行。

1『典型如 Python 解释器。』

编译器处理的高级语言代码又叫做源码。它经过翻译以后产生的机器码就叫做目标码。顾客购买市场上的商业软件时得到的往往只是目标码。（目标码很难读懂，所以相当于被加密了，可以保护公司的商业秘密。）但是，后来出现另一种潮流：开放源码的软件。你可以得到源码，并且可以不受限制地修改它。

这两种方式的真正区别在于，开放源码使你对软件有更大的控制权，如果你想理解开源软件如何运行，只要阅读源码就行了。如果愿意，你甚至可以修改软件、重新编译。你之所以需要这样做，一个原因可能是为了修正 bug。比如，你自己不可能修正 Windows 的 bug，因为你没有源码。（理论上你也许可以破解目标码，但是实际上这是非常难的。另一方面，软件的授权协议一般也不允许你这样做。）这会导致很大的问题。一旦 Windows 出现新的安全漏洞，只能等待微软公司发布解决方法，这还算是快的。如果 bug 的危害性不严重，只是偶尔会让你的机器死机，那么可能不得不等到下一次全面升级后问题才会得到解决。

开放源码的优势还不仅局限于可以自己动手解决 bug。这里的关键是所有人都可以参与。所以，开源软件就像一篇经受同行评议的论文。许许多多的聪明人仔细阅读了 Linux 和 FreeBSD 这样的开源操作系统的源码，发现并且解决了大量的 bug。相比之下，Windows 的可靠性只能依赖于大公司自己的质量保证部门了。

开放源码的拥护者常常被看作反对知识产权的怪人。其中有些人确实如此，但是我本人肯定不反对知识产权。只是如果你要我安装没有源码的软件，我会非常犹豫。普通的消费者也许不需要看到他们使用的文字处理器的源码，但是在非常强调软件可靠性的情况下，出于强烈的工程需求的考虑，会要求开放源码。

绝大多数程序员在绝大多数时候都使用高级语言编程。现在很少有人使用汇编语言。程序员的时间要比计算机的时间昂贵得多，后者已经变得很便宜了，所以几乎不值得非常麻烦地用汇编语言开发软件。只有少数最关键的部分可能还会用到汇编语言，比如开发某个计算机游戏时，你需要在微观水平控制硬件，使得游戏速度得到最大限度的终极提高。Fortran、Lisp、Cobol、Basic、C、Pascal、Smalltalk、C++、Java、Perl 和 Python，全都是高级语言。它们只是比较出名的几种而已。现在的高级语言大概有几百种之多。不同机器语言的指令集基本相同，但是高级语言就不一样，它们开发程序的模式差别相当大。

那么，应该使用哪一种语言？嗯，关于这个问题，现在有很多争论。部分原因是，如果你长期使用某种语言，你就会慢慢按照这种语言的思维模式进行思考。所以，后来当你遇到其他任何一种有重大差异的语言，即使那种语言本身并没有任何不对的地方，你也会觉得它极其难用。缺乏经验的程序员对于各种语言优缺点的判断经常被这种心态误导。

可能因为想炫耀自己见多识广，某些黑客会告诉你所有高级语言基本相似。「所有编程语言我都用过。」某个看上去饱经风霜又酷的黑客往酒吧里一坐，「你用什么语言并不重要，重要的是你对问题是否有正确的理解。代码以外的东西才是关键。」这当然是一派胡言。各种语言简直是天差地别，比如 Fortran I 和最新版的 Perl 就是两种完全不同的语言，而早期版的 Perl 和最新版的 Perl 之间的差别也大得惊人。但是，那个夸夸其谈的黑客可能真的相信自己的这番话，的确有可能使用所有不同的语言写出了与用原始的 Pascal 语言写的差不多的程序。如果你吃过麦当劳，就会知道全世界各地的麦当劳的味道都几乎一样。

高级语言比汇编语言更接近人类语言，而某些高级语言又比其他语言更进一步。举例来说，C 语言是一种低层次语言，很接近硬件，几乎堪称可移植的汇编语言，而 Lisp 语言的层次则是相当高。如果高层级语言比汇编语言更有利于编程，你也许会认为语言的层次越高越好。一般情况下确实如此，但不是绝对的。编程语言可以变得很抽象，完全脱离硬件，但也有可能走错了方向。比如，我觉得 Prolog 语言就有这个问题。它的抽象能力强得不可思议，但是只能用来解决 2％ 的问题，其余时间你苦思冥想、运用这些抽象能力写出来的程序实际上就是 Pascal 语言的程序。

另一个你会用到低层次语言的原因就是效率问题。如果你非常关注运行速度，那么最好使用接近机器的语言。大多数操作系统都是用 C 语言写的，这并非偶然。不过，硬件的运行速度越来越快了，所以使用 C 这样的低层次语言开发应用程序的必要性正在不断减少，但是大家似乎还是要求操作系统越快越好。（另一种可能是，人们还是希望「缓存区溢出攻击」继续存在下去，以便让大家时时保持警惕。［2］）

语言设计者之间的最大分歧也许就在于，有些人认为编程语言应该防止程序员干蠢事，另一些人则认为程序员应该可以用编程语言干一切他们想干的事。Java 语言是前一个阵营的代表，Perl 语言则是后一个阵营的代表。（美国国防部很看中 Java 也就不足为奇了。）

由于防止程序员做蠢事有好几种方法，所以上面的争论逐渐分化成几个较小的议题。目前最活跃的议题之一就是静态类型语言与动态类型语言之争。在静态类型语言中，写代码时必须知道每个变量的类型。而在动态类型语言中，随便什么时候，你都可以把变量设为任意类型的值。

静态类型语言的拥护者认为这样可以防止 bug，并且帮助编译器生成更快的代码（这两点理由都成立）。动态类型语言的拥护者认为静态类型对程序构成了限制（这点理由也成立）。我本人更喜欢动态类型，痛恨那些限制我的自由的语言。但是，确实有一些很聪明的人看来喜欢用静态类型语言。所以，这个问题依然值得讨论，并没有固定答案。

眼下另一个争论的热点则是面向对象编程。它是一种不同的组织程序的方法。假定你要写一个程序，计算二维图形的面积。首先，你必须知道到底是圆形还是正方形。一种解决方法是用一整块的代码判断遇到的是什么图形，然后再用相应的公式计算面积。面向对象编程不是这样，它的方法是写出两个类，一个是圆形类，另一个是正方形类，然后每个类里面用一小块代码（叫做方法）计算该类图形的面积。求面积的时候，你就问要用哪一个类，然后再使用相应的方法得出最后答案。

这两种不同的计算方法可能听上去很相似，事实上，运行代码后，实际计算面积的运算过程也很相似。（这不奇怪，因为你本来就在解决同一个问题。）但是，代码的形式却是大相径庭。在面向对象编程的方式中，计算圆面积和正方形面积的代码可能分散在不同的文件中。与圆形有关的代码都放在一个文件中，与正方形有关的代码则放在另一个文件中。

面向对象编程的优点在于，如果你需要修改程序，计算另一种图形的面积，比如三角形，你只需要再另外增加一块相应的代码就可以了，甚至可以不修改程序的其他部分。但是，批评者会反驳说，这种方法的缺点是，由于增加代码不用考虑其他部分，结果往往导致写出性能不佳甚至有副作用的代码，就好比造房子不考虑已经完成的部分一样。

关于面向对象编程优劣的争论并不像静态类型与动态类型之争那样壁垒分明，因为编程的时候你只能在静态类型和动态类型之中选一种。但是，面向对象编程只是程度不同的问题。事实上有两种程度的面向对象编程：某些语言允许你以这种风格编程，另一些语言则强迫你一定要这样编程。我觉得后一类语言不可取。允许你做某事的语言肯定不差于强迫你做某事的语言。所以，至少在这方面我们可以得到明确的结论：你应该使用允许你面向对象编程的语言。至于你最后到底用不用则是另外一个问题了。

结果就是产生了一些也许可以称为「头重脚轻」的语言：它们的内核设计得并非很好，但是却有着无数强大的函数库，可以用来解决特定的问题。（你可以想象一辆本身性能很差的小汽车，车顶却绑着一个飞机发动机。）有一些很琐碎、很普遍的问题，程序员本来要花大量时间来解决，但是有了这些函数库以后，解决起来就变得很容易，所以这些库本身可能比核心的语言还要重要。所以，这些奇特组合的语言还是蛮有用的，一时间变得相当流行。车顶上绑着飞机发动机的小车也许真能开，只要你不尝试拐弯，可能就不会出问题。［4］另一个结果就是语言的多样化。编程语言之间总是存在很大区别。Fortran、Lisp、APL 都是 1970 年以前开发出来的，它们之间的区别大得就像海星、熊、蜻蜓之间的区别。新兴的开源编程语言肯定将继承这种传统。

实际上，很多历史学家相信战争是文艺复兴的一个副产品。［5］当时，欧洲活力旺盛可能就是因为它分成许多互相竞争的小国。它们互相毗邻，所以新思想能够从一个国家传播到另一个国家，但是它们又互相独立，使得单个的统治者无法遏制创新的发展。相比之下，中国古代的封建皇朝禁止民间建造大型的远洋船只，阻止了经济的正常发展。所以，程序员活在这个文艺复兴时代可能是一件好事。如果我们所有人都使用同一种编程语言，反而有可能是坏事。

## 11. 一百年后的编程语言

### 1. 逻辑脉络

编程语言如同生物物种一般演化，关心一百年后的编程语言等同于选择演化的主干。那些内核最小、最干净的编程语言才会存在于进化的主干上。一种语言的内核设计得越小、越干净，它的生命力就越顽强。

### 2. 摘录及评论

我认为，编程语言就像生物物种一样，存在一个进化的脉络，许许多多分支最终都会成为进化的死胡同。这种现象已经发生了。Cobol 语言曾经流行一时，但是现在看来没有任何后续语言继承它的思想。它就像尼安德特人［1］一样，进化之路已经走到了尽头。

我预言 Java 也会如此。有人写信说：「你怎么能说 Java 不会成功呢？它已经成功了。」我觉得这要看你的成功标准是什么。如果标准是相关书籍的出版量，或者是相信学会 Java 就能找到工作的大学生数量，那么 Java 确实已经成功了。当我说 Java 不会成功时，我的意思是它和 Cobol 一样，进化之路已经走到了尽头。这只是我的猜测，未必正确。这里的重点不是看衰 Java，而是提出编程语言存在一个进化的脉络，从而引导读者思考，在整个进化过程中，某一种语言的位置到底在哪里？之所以要问这个问题，不是为了一百年后让后人感叹我们曾经如此英明，而是为了找到进化的主干。它会启发我们去选择那些靠近主干的语言，这样对当前的编程最有利。

编程语言的进化与生物学进化还是有区别的，因为不同分支的语言会发生聚合。比如，Fortran 分支看来正在与 Algol［2］的继承者聚合。理论上，不同的生物物种也可能发生聚合，但是可能性很低，所以大概从来没有真正出现过。编程语言之所以可能出现聚合，一个原因是它的概率空间［3］比较小，另一个原因是它的突变不是随机的。语言的设计者们总是有意识地借鉴其他语言的设计思想。

对于语言设计者来说，认清编程语言的进化路径特别有用，因为这样就可以照着样子设计语言了。这时，认清进化的主干就不仅有助于识别现存的优秀语言，还可以把它当作设计语言的指南。

任何一种编程语言都可以分成两大组成部分：基本运算符的集合（扮演公理的角色）以及除运算符以外的其他部分（原则上，这个部分可以用基本运算符表达出来）。我认为，基本运算符是一种语言能否长期存在的最重要因素。其他因素都不是决定性的。这有点像买房子的时候你应该先考虑地理位置。别的地方将来出问题都有办法弥补，但是地理位置是没法变的。慎重选择公理还不够，还必须控制它的规模。数学家总是觉得公理越少越好，我觉得他们说到了点子上。

1『编程语言的两大部分：基本运算符以及除此之外的。』

你仔细审视一种语言的内核，考虑哪些部分可以被摒弃，这至少也是一种很有用的训练。在长期的职业生涯中，我发现冗余的代码会导致更多冗余的代码，不仅软件如此，而且像我这样性格懒散的人，我发现在床底下和房间的角落里这个命题也成立，一件垃圾会产生更多的垃圾。我的判断是，那些内核最小、最干净的编程语言才会存在于进化的主干上。一种语言的内核设计得越小、越干净，它的生命力就越顽强。

2『以上即为核心观点了，做一张论点卡片。』

你可能认为只有那些自以为是的人才会去预言一百年后的技术。但是，请不要忘记，软件发展的历史已经走过了 50 年。在这 50 年中，编程语言的进化其实是非常缓慢的，因此展望一百年后的语言并不是虚无缥缈的想法。编程语言进化缓慢的原因在于它们并不是真正的技术。语言只是一种书写法，而程序则是一种严格符合规则的描述，以书面形式记录计算机应该如何解决你的问题。所以，编程语言的进化速度更像数学符号的进化速度，而不像真正的技术（比如交通或通信技术）的进化速度。数学符号的进化是缓慢的渐变式变化，而不是真正技术的那种跳跃式发展。

那时，依然会有对运行速度要求很高的应用程序。我们希望计算机解决的有些问题其实是计算机本身引起的。比如，计算机处理视频的速度取决于生成这些视频的另一台计算机。此外，还有一些问题本身就要求无限快的处理能力，比如图像渲染、加密 / 解密、模拟运算等。

既然在现实中一些应用程序本身的效率较低，而另一些应用程序会耗尽硬件提供的所有运算能力，那么有了更快速的计算机就意味着编程语言不得不应付更多的极端情况，涵盖更大范围的效率要求。我们已经看到这种情况发生了。要是以几十年前的标准衡量，有一些使用新语言开发的热门应用程序对硬件资源的浪费非常惊人。

不仅编程语言有这种现象，这实际上是一种普遍的历史趋势。随着技术的发展，每一代人都在做上一代人觉得很浪费的事情。30 年前的人要是看到我们今天如此随意地使用长途电话，一定会感到震惊。100 年前的人要是看到一个普通的包裹竟然也能享受一天内从波士顿发件、途经孟菲斯、抵达纽约的待遇，恐怕就要更震惊了。

我已经预测了，一旦未来硬件的性能大幅提高将会发生什么事。新增加的运算能力都会被糟蹋掉。在我学习编程的年代，计算机还是稀罕玩意。我记得当时使用的微机型号是 TRS-80，它的内存只有 4K，为了把 BASIC 程序装入内存，我不得不把源码中的空格全部删除。我一想到那些极其低效率的软件，不断重复某些愚蠢的运算，把硬件的计算能力全部占用，就感到无法忍受。但是，我的这种反应是错的，我就像某个出身贫寒的穷孩子，一听到要花钱就舍不得，即使把钱用在重要场合（比如去医院看病）都觉得很难接受。

浪费可以分成好的浪费和坏的浪费。我感兴趣的是好的浪费，即用更多的钱得到更简单的设计。所以，问题就变成了如何才能充分利用新硬件更强大的性能最有利地「浪费」它们？对速度的追求是人类内心深处根深蒂固的欲望。当你看着计算机这个小玩意，就会不由自主地希望程序运行得越快越好，真的要下一番功夫才能把这种欲望克制住。设计编程语言的时候，我们应该有意识地问自己，什么时候可以放弃一些性能，换来一点点便利性的提高。

很多数据结构存在的原因都与计算机的速度有关。比如，今天的许多语言都同时有字符串和列表。从语义上看，字符串或多或少可以理解成列表的一个子集，其中的每一个元素都是字符。那么，为什么还需要把字符串单列为一种数据类型呢？完全可以不这么做。只是为了提高效率，所以字符串才会存在。但是，这种以加快运行速度为目的、却使得编程语言的语义大大复杂的行为，很不可取。编程语言设置字符串似乎就是一个过早优化的例子。

如果我们把一种语言的内核设想为一些基本公理的集合，那么仅仅为了提高效率就往内核添加多余的公理，却没有带来表达能力的提升，这肯定是一件很糟的事。没错，效率是很重要，但是我认为修改语言设计并不是提高效率的正确方法。正确做法应该是将语言的语义与语言的实现予以分离。在语义上不需要同时存在列表和字符串，单单列表就够了。而在实现上做好编译器优化，使它在必要时把字符串作为连续字节的形式处理。［4］

1『语言的语义和语言的实现应该分隔开来。』

对于大多数程序，速度不是最关键的因素，所以你通常不需要费心考虑这种硬件层面上的微观管理。随着计算机速度越来越快，这一点已经越发明显了。

语言设计时，对实现方式少作限制还会使得程序具备更大的灵活性。语言的规格发生变化不仅是无法避免的，也是合理的。通过编译器的处理，按照以前规格开发的软件就会照常运行，这就提供了灵活性。essay（论文）这个词来自法语的动词 essayer，意思是「试试看」。从这个原始意义来说，论文就是你写一篇文章，试着搞清楚某件事。软件也是如此。我觉得一些最好的软件就像论文一样，也就是说，当作者真正开始动手写这些软件的时候，他们其实不知道最后会写出什么结果。

Lisp 语言的黑客早就明白数据结构灵活性的价值。我们写程序的第一版时，往往会把所有事情都用列表的形式处理。所以，这些最初版本可能效率低下得惊人，你必须努力克制自己才能忍住不动手优化它们，这就好像吃牛排的时候必须努力克制自己才能不去想牛排是从哪里来的一样，至少对我来说是这样的。

一百年后的程序员最需要的编程语言就是可以让你毫不费力地写出程序第一版的编程语言，哪怕它的效率低下得惊人（至少按我们今天的眼光来看是如此）。他们会说，他们想要的就是很容易上手的编程语言。效率低下的软件并不等于很烂的软件。一种让程序员做无用功的语言才真正称得上很烂。浪费程序员的时间而不是浪费机器的时间才是真正的无效率。随着计算机速度越来越快，这会变得越来越明显。

1『在浪费人的时间和浪费机器的时间之间选择，无疑是选择后者。』

我觉得，放弃字符串类型已经是大家可以接受的想法了。Arc 语言已经这样做了，看上去效果不错。以前用正则表达式很难描述的一些操作，现在用回归函数可以表达得很简单。这种数据结构的扁平化趋势会怎么发展？我极其努力地设想各种可能，得到的结果甚至令我自己都吓了一跳。比如，数组会不会消失？毕竟数组只是散列表的一个子集，其特点就是数组的键全部都是整数向量。进一步说，散列表本身会不会被列表取代呢？

还有比这更惊人的预言。在逻辑上其实不需要对整数设置单独的表示法，因为可以把它们也看作列表，整数 n 可以用一个 n 元素的列表表示。这一样能完成数学运算，只是效率低得让人无法忍受。

编程语言会发展到放弃基本数据类型之一的整数这一步吗？我这样问并不是真的要你严肃思考这个问题，更多的是希望打开你对未来的思路。我只是提出一种假想的情况：如果一股不可抗拒的力量遇到了一个不可移动的物体，会发生什么事。具体就本文而言：一种效率低得不可想象的语言遇到了性能强大得不可想象的硬件，会发生什么事。我看不出放弃整数类型有什么不妥。未来相当漫长。如果我们想要减少语言内核中基本公理的数目，不妨把眼光放得远一点，想一想如果时间变量 t 趋向无限会怎么样。一百年是一个很好的参考指标，如果你觉得某个想法在一百年后仍然可能是难以令人接受，那么也许一千年后它也依然难以令人接受。我的意思不是说所有的整数运算都用列表来实现，而是说语言的内核（不涉及任何编译器的实现）可以这样定义。在现实中，任何进行数学运算的程序可能都是以二进制形式表示数字，但是这属于编译器的优化，而不属于语言内核语义的一部分。

另一种消耗硬件性能的方法就是，在应用软件与硬件之间设置很多的软件层。这也是我们已经看到的一种趋势，许多新兴的语言就被编译成字节码［5］。比尔·伍兹曾经对我说，根据经验判断，每增加一个解释层，软件的运行速度就会慢一个数量级。但是，多余的软件层可以让编程灵活起来。Arc 语言［6］最初的版本就是一个极端的例子，它的层很多，运行速度非常慢，但是确实带来了相应的好处。Arc 是一个典型的「元循环」（metacircular）解释器，在 Common Lisp 的基础上开发，很像约翰·麦卡锡在他经典的 Lisp 论文中定义的 eval 函数。Arc 解释器一共只有几百行代码，所以很便于理解和修改。我们采用的 Common Lisp 版本是 CLisp，它本身是在另一个字节码解释器的基础上开发的。所以，我们一共有两层解释器，最上面那层效率低下得惊人，但是语言本身是能用的。我承认只是勉强可用，但是确实能用。

即使是应用程序，使用多层形式开发也是一种很强大的技巧。自下而上的编程方法意味着要把软件分成好几层，每一层都可以充当它上面那一层的开发语言。这种方法往往会产生更小、更灵活的程序。它也是通往软件圣杯 —— 可重用性（reusability）—— 的最佳路线。从定义上看，语言就是可以重用的。在编程语言的帮助下，你的应用程序越是采用这种多层形式开发，它的可重用性就越好。

可重用性这个概念多多少少与 20 世纪 80 年代兴起的面向对象编程有些关联。不管怎样寻找证据，也不可能把这两件事完全分开。某些使用面向对象编程开发出来的软件确实具有可重用性，但是这不是因为它使用了面向对象编程，而是因为它的开发方法是自下而上的。以函数库为例，它们具有可重用性，是因为它们属于语言的一部分，而不是因为它们采用面向对象或者其他编程方法。顺便说一句，我不认为面向对象编程将来会消亡。我觉得，除了某些特定的领域，这种编程方法其实没有为优秀程序员带来很多好处，但是它对大公司有不可抗拒的吸引力。面向对象编程使得你有办法对一团乱码似的代码进行可持续性开发。通过不断地打补丁，它让你将软件一步步做大。大公司总是倾向于采用这样的方式开发软件。我预计一百年后也是如此。

1『作者不看好面向对象。』

既然是谈论未来，最好谈谈并行计算（parallel computation），因为看上去并行计算好像就是为未来而存在的。无论怎么想，并行计算似乎都是未来生活的一部分。它会在未来实现吗？过去二十年，人们都在说并行计算马上就会来临。但是，到目前为止，它对编程实践并没有太大影响。这是真的吗？芯片设计师已经不得不把它考虑在内，为多 CPU 计算机开发系统软件的程序员也是如此。但是，真正的问题在于，并行计算到底能达到哪个抽象层次？一百年后它就会影响到开发应用软件的程序员吗？或者，它还只是编译器作者需要考虑的事情，在应用软件的代码中根本就无处寻觅？

一种可能是，大多数可以用到并行计算的场合，人们都会放弃使用并行计算。虽然我总的预测是未来的软件会挥霍掉大部分新增的硬件性能，但是并行计算是一个特例。我估计随着硬件性能得到惊人的提升，如果你明确地说想要并行计算，那么肯定可以得到它，但是通常情况下你不会用到它。这意味着，除了一些特殊的应用程序，一百年后的并行计算不会是那种大规模的并行计算（massive parallelism）。我预料，对于普通程序员来说，一切更像对进程进行分叉，然后让多个进程在后台并行运行。这是编程进行到很后期才要做的事情，属于对程序的优化，类似于你想开发一种特定的数据结构来取代现有的数据结构。程序的第一个版本通常会忽略并行计算提供的各种好处，就好像编程开始时会忽略某种特定的数据结构给你带来的好处一样。除了某些特定的应用软件，一百年后，并行计算不会很流行。如果应用软件真的大量使用并行计算，这就属于过早优化了。

一百年后会有多少种编程语言？从最近来看，出现了大量的新语言。硬件性能提高是一个原因，这就允许程序员根据使用目的在运行速度和编程便利性之间做出不同的取舍。如果这就是未来的趋势，那么一百年后强大的硬件只会使得语言数目变得更多。但是，另一方面，一百年后的常用语言可能只有很少几种。部分原因是基于我的乐观主义，我相信在未来，如果你的作品确实很出色，你可能选择的是一种开发起来很方便的语言。使用这种语言写出来的软件第一版的运行速度很慢，只有对编译器进行优化设置后运行速度才会提升。既然我抱有这种乐观主义，那么我还要做一个预言。有些语言可以达到机器的最高效率，另一些语言的效率则慢到刚刚可以运行而已，两者之间存在巨大的差距。我预言一百年后，这段差距之间的各个点上都会有对应的编程语言存在。

因为这段差距正在变得越来越大，所以性能分析器（profiler）将变得越来越重要。目前，性能分析并没有受到重视。许多人好像仍然相信，程序运行速度提升的关键在于开发出能够生成更快速代码的编译器。代码效率与机器性能的差距正在不断加大，我们将会越来越清楚地看到，应用软件运行速度提升的关键在于有一个好的性能分析器帮助指导程序开发。

我说将来可能只有很少几种常用语言，但没有把用于特定领域的「小众语言」（little language）算进去。我觉得，这些嵌入式语言的想法很不错，一定会蓬勃发展。但是我判断这些「小众语言」会被设计成相当薄的一层，使得用户可以一眼看出在底下作为基础的通用型语言，这样就减少了学习时间，降低了使用成本。

谁来设计这些未来的语言？过去 10 年最激动人心的趋势之一就是开源语言的崛起，比如 Perl、Python 和 Ruby。语言设计已经被黑客接管。到目前为止这样到底是好是坏还看不清楚，但是发展势头令人鼓舞。比如，Perl 就有一些绝妙的创新。不过，它也包含了一些很糟糕的想法。对于一种充满进取心、大胆探索的语言来说，这也是很正常的事。以它现在这种变化的速率，大概只有上帝才知道一百年后 Perl 会变成什么样。

有一句俗话说，如果你自己做不到，那就去当老师。这在语言设计领域不成立，我认识的一些最出色的黑客就在当教授。但是，当老师的人确实有很多事情不能做。研究性职位给黑客带来了一些限制。在任何学术领域，都有一些题目是可以做的，另一些题目是不可以做的。不幸的是，这两类题目的区别通常取决于它们写成论文后看上去是不是很高深，而不是取决于它们对软件业的发展是否重要。最极端的例子可能就是文学，文学研究者的任何成果几乎对文学创作者都毫无影响。虽然科学领域的状况要稍好一点，但是研究者可以做的题目与能够对设计优秀语言有所帮助的题目之间的交集小得令人沮丧。（奥林·希弗斯曾经对这一点表达不满，而且说得头头是道。）比如，研究变量类型的论文好像多得无穷无尽，尽管事实上静态类型语言看来无法真正支持宏（在我看来，一种语言不支持宏，那就不值得使用了）。

新语言更多地以开源项目的形式出现，而不是以研究性项目的形式出现。这是语言的一种发展趋势。另一种发展趋势是，新语言的设计者更多的是本身就需要使用它们的应用软件作者，而不是编译器作者。这似乎是好的趋势，我期待它继续保持下去。

一百年后的物理学基本上不可能预测。但是计算机语言不一样，现在就动手设计一种一百年后可以吸引使用者的新语言，这在理论上似乎是可能的。设计新语言的方法之一就是直接写下你想写的程序，不管编译器是否存在，也不管有没有支持它的硬件。这就是假设存在无限的资源供你支配。不管是今天还是一百年后，这样的假设好像都是有道理的。

你应该写什么程序？随便什么，只要能让你最省力地写出来就行。但是要注意，这必须是在你的思维没有被当前使用的编程语言影响的情况下。这种影响无处不在，必须很努力才能克服。你也许觉得，对于人类这样懒惰的生物，喜欢用最省力的方式写程序是再自然不过的事情。但是事实上，我们的思想可能往往会受限于某种现存的语言，只采用在这种语言看来更简单的形式，它对我们思想的束缚作用会大得令人震惊。新语言必须靠你自己去发现，不能依靠那些让你自然而然就沉下去的思维定势。

1『语言不是思维的外衣，语言是思维本身。』

采用程序的长度作为它耗费工作量的近似指标是个很有用的技巧。这里的程序长度当然不是指字符的数量，而是指各种句法元素的总长度，基本上就是整个解析树的大小。也许不能说最短的程序就是写起来最省力的程序，但是当你一心想把程序写得简洁而不是松松垮垮时，你就更接近省力这个目标，你的日子也会变得好过得多。所以，设计语言的正确做法就变成了，看着一段程序，然后问自己是不是能把它写得更短一点？

实际上，用想象出来的一种一百年后的语言来写程序，这件事情的可靠程度，取决于你对语言内核的估计是否足够正确。常规的排序，你现在就可以写出来。但是，想要预测一百年后的语言使用什么函数库就很难了。很可能许多函数库针对的领域现在还根本不存在。比如，如果 SETI@home［7］计划成功，我们就需要与外星人联系的函数库了。当然，如果外星人的文明高度发达，已经到了用 XML 格式交换信息的地步，那就不需要新的函数库了。

另一个极端是，我觉得今天你就能设计出一百年后的语言内核。事实上，在有些人看来，大部分语言内核在 1958 年就已经设计出来了。［8］如果今天就能使用一百年后的编程语言，我们会用它编程吗？观古而知今。如果 1960 年就能使用今天的编程语言，那时的人们会用它们吗？

在某些方面，回答是否定的。今天的编程语言依赖的硬件在 1960 年并不存在。比如，Python 这样的语言，正确的缩进（indentation）在编写时很重要，但是 1960 年的计算机没有显示器，只有打印机终端，所以编写起来就不会很顺利。但是，如果把这些因素排除在外（你可以假设，我们只在纸上编程），20 世纪 60 年代的程序员会喜欢用现在的语言编程吗？我想他们会的。某些缺乏想象力、深受早期编程语言思想影响的人可能会觉得不可能。（没有指针运算，如何复制数据？没有 goto 语句，如何实现流程图？）但是我想，那时最聪明的程序员一定能轻松地使用今天的大多数语言，假定他们能得到的话。

如果我们现在就能拥有一百年后的编程语言，那就至少能用来写出优秀的伪码［9］。我们会用它开发软件吗？因为一百年后的编程语言需要为某些应用程序生成快速代码，所以很可能它生成的代码能够在我们的硬件上运行，速度也还可以接受。相比一百年后的用户，我们也许不得不对这种语言做更多的优化，但是总的来看，它应该仍然会为我们带来净收益。

现在，我们的两个观点就是：（1）一百年后的编程语言在理论上今天就能设计出来；（2）如果今天真能设计出这样一种语言，很可能现在就适合编程，并且能够产生更好的结果。如果我们把这两个观点联系起来，那就得出了一些有趣的可能性。为什么不现在就动手尝试写出一百年后的编程语言呢？当你设计语言的时候，心里牢牢记住这个目标是有好处的。学习开车的时候，一个需要记住的原则就是要把车开直，不是通过将车身对齐画在地上的分隔线，而是通过瞄准远处的某个点。即使你的目标只在几米开外，这样做也是正确的。我认为，设计编程语言时，我们也应该这样做。

## 12. 拒绝平庸

### 1. 逻辑脉络



### 2. 摘录及评论

埃里克·雷蒙德写过一篇文章《如何变成一个黑客》（How to Become a Hacker）。文中有一部分专门谈到，在他看来，如果你想当一个黑客，应该学习哪些语言。他建议从 Python 和 Java 入手，因为它们比较容易学。想当高级一点的黑客，还应该学习 C 和 Perl。前者用来对付 Unix 系统，后者用来系统管理和开发 CGI 脚本。最后，真正非常严肃地把黑客作为人生目标的人，应该考虑学习 Lisp。






















