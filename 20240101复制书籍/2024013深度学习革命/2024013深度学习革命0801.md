凯德·梅茨.(2023.2021).2024013深度学习革命.(桂曙光译).中信出版社 => 0101 感知机：最早的神经网络之一

Cade Metz.(2007).2024013Genius-Makers => Preface

## 0801. 炒作

成功是有保证的。

2012 年，阿兰·尤斯塔斯在一次跨国飞行中读着飞机座椅背后的一份免费杂志，他偶然看到了奥地利冒险家菲利克斯·鲍姆加特纳（Felix Baumgartner）的介绍。鲍姆加特纳和他的团队正在计划依靠一种新型太空舱让这个奥地利人像宇航员一样进入平流层，然后从那里来一次单人跳伞挑战。但是，尤斯塔斯认为，他们的方法是完全错误的。他认为，如果他们不是把鲍姆加特纳当作宇航员，而是当作一名戴着水下呼吸器的潜水员，那么结果会更好：他确信，使用配备了水下呼吸器的潜水服是一种更为灵活的方式，可以提供人类在稀薄空气中生存所需的一切。菲利克斯·鲍姆加特纳从距离地球 24 英里的太空舱中跳下，很快创造了高空跳伞的世界纪录。1 但是，尤斯塔斯已经打算打破这项纪录。在接下来的两年里，他把大部分业余时间都用于与一家私人工程公司合作，制作一套高空「潜水服」以及其他一切所需的东西，以超越鲍姆加特纳。他计划在 2014 年秋天从新墨西哥州罗斯韦尔的一条废弃跑道上空几英里的地方进行飞跃。但在此之前，他与谷歌进行了最后一次「飞跃」。

在谷歌以 4 400 万美元收购了克里哲夫斯基、萨特斯基弗和辛顿的公司，并以 6.5 亿美元收购了 DeepMind 之后，尤斯塔斯几乎彻底垄断了深度学习研究人员的市场。来自多伦多大学的三人组很快发现，谷歌仍然欠缺的是加速这些研究人员工作所需的硬件设施，这些设施才能匹配他们的天赋和野心。克里哲夫斯基用为 GPU 芯片编写的代码赢得了 ImageNet 竞赛，但当抵达硅谷的山景城时，他们发现谷歌的版本是由一位名叫沃伊切赫·扎伦巴（Wojciech Zaremba）的研究人员开发的，使用的是标准芯片，就像其他所有为 DistBelief 开发的东西一样（DistBelief 是谷歌为运行其神经网络而定制的硬件和软件系统）。它被称为 WojNet，是以扎伦巴的名字命名的，辛顿反对这个项目的名字，后来辛顿开始称之为 AlexNet，全球人工智能研究人员的圈子也纷纷效仿。克里哲夫斯基反对谷歌的技术，公司花了几个月的时间来打造运行神经网络的系统，但他没有兴趣使用。

在这家公司上班的第一天，他就在当地的一家电子商店买了一台 GPU 机器，把它放在走廊尽头的壁橱里，接入网络，并开始在这个单独的硬件上训练他的神经网络，而其他研究人员把 GPU 机器随手放在自己的桌子下面。虽然电费由谷歌来支付，但与克里哲夫斯基在多伦多大学时在卧室里的工作方式相比，现在没有太大的区别。谷歌的其他人在公司庞大的数据中心网络上开发和运行其软件，利用的可能是世界上最大的私人计算机集群，但克里哲夫斯基不得不接受一些小得多的东西。管理公司数据中心的人认为，没有理由在数据中心里铺满 GPU 机器。

这些思想更传统的谷歌人没有意识到的是，深度学习是未来，而 GPU 可以加速这一新兴技术的发展，其速度是普通计算机芯片无法企及的。这种情况经常发生在大型科技公司或小公司内部：大多数人看不到自己正在做的事情之外的东西。阿兰·尤斯塔斯认为，诀窍在于让自己处在一些特定人群周围，这些人能够将新的专业知识应用到旧技术似乎无法解决的问题上。「大多数人是以特定的方式、特定的视角和特定的历史来看待特定问题的，」他说，「他们无法看到那些能改变格局的专业知识的交会点。」这也是他在高空跳伞时秉持的哲学。当他计划飞跃时，他的妻子不想让他参加。她坚持要他自拍一段视频，解释自己为什么要去冒险，这样如果他活不下来，她就可以拿给他们的孩子看。他拍了，但告诉她风险很小，几乎不存在风险。他和他的团队找到了一种新的飞跃方式，尽管其他人可能不理解，但他知道这是可行的。「人们经常问我：‘你不怕死吗？' 但我与不怕死的人相反，」他说，「我招募了我能找到的最棒的人，我们一起努力，基本上消除了每一项可能的风险，并对每一项风险进行测试，试图达到一种看似非常危险、实则非常安全的效果。」

杰夫·迪恩的办公室离克里哲夫斯基的办公室不远，迪恩知道谷歌的硬件需要调整。除非基于 GPU 重建 DistBelief，否则公司无法进一步推动深度学习的发展。因此，在 2014 年春天，他约见了谷歌的人工智能主管约翰·詹南德雷亚（John Giannandrea），公司的每个人都称他为「J.G.」，他负责管理多年来协助创建的「谷歌大脑」和人工智能专家这两个姐妹团队。当克里哲夫斯基这样的研究人员的桌子底下或走廊尽头壁橱里需要更多的 GPU 时，他们就会去找他。J.G. 和杰夫·迪恩坐下来讨论，他们应该在一个巨大的数据中心里安装多少个图形芯片，才能满足研究人员的需求。

最初的建议数量是 2 万个，但他们认为这个数量太少了，应该要 4 万个。不过，当他们向谷歌谨慎的决策层提交申请时，他们立即遭到拒绝。4 万个 GPU 构成的网络要花费公司大约 1.3 亿美元，尽管谷歌经常在数据中心硬件上投入巨额资金，但他们从未投资过这样的硬件。所以，迪恩和詹南德雷亚把他们的申请提交给了阿兰·尤斯塔斯，而他即将从平流层飞跃。尤斯塔斯理解这件事，他又将申请提交给了拉里·佩奇，就在他穿着「潜水服」打破鲍姆加特纳的高空跳伞纪录之前，1.3 亿美元的图形芯片申请获得了批准。2 芯片安装之后不到一个月，所有 4 万个芯片都夜以继日地运行起来，开始训练一个又一个的神经网络。

### 01

那时，亚历克斯·克里哲夫斯基正在为谷歌一个完全不同的部门工作。当年 12 月，在假期回多伦多看望父母时，他收到了一位女士的电子邮件，这位女士是阿妮莉亚·安杰洛娃（Anelia Angelova），她想参与谷歌的自动驾驶汽车项目。她实际上并没有在这个领域工作过，而是曾在「谷歌大脑」与克里哲夫斯基共事。但她知道实验室正在进行的计算机视觉研究 —— 这是克里哲夫斯基在多伦多大学工作的延伸 —— 将重塑谷歌制造自动驾驶汽车的方式。谷歌的自动驾驶汽车项目已经启动了将近 5 年时间，该项目在公司内部被称为「司机」。这意味着，在没有深度学习帮助的情况下，谷歌花了近 5 年的时间尝试打造自动驾驶汽车。

在 20 世纪 80 年代末的卡内基 —— 梅隆大学，迪安·波默洛曾经在神经网络的帮助下设计过一辆自动驾驶汽车，但当谷歌在将近 20 年后开始从事自动驾驶汽车研究时，研究领域的核心人员，包括卡内基 —— 梅隆大学为谷歌项目招募的很多研究人员，早已放弃了这个想法。神经网络可以帮助打造一辆能够独自行驶在空旷街道上的汽车，但仅此而已。这是一种好奇的尝试，而不是打造可以像人类司机那样在繁忙的交通环境中行驶的车辆。然而，安杰洛娃并不信服。在谷歌的一栋空荡荡的大楼里，在其他人都回家享受假期时，她开始研究深度学习，将它作为汽车在行人过马路或在人行道上漫步时对他们进行监测的一种方法。因为一切对她来说都是全新的，她向那个被她称为「深度网络大师」的男人伸出了手。他同意帮忙，因此，在度假期间，她和克里哲夫斯基创建了一个系统，通过分析数千张街道照片，系统学会了如何识别行人。当大家新年假期之后回来工作时，他们与汽车项目的负责人分享了他们的新原型。这个原型非常有效，他们都被邀请去参与「司机」项目。后来这个项目被分拆成独立的公司，并改名为 Waymo。「谷歌大脑」最终把克里哲夫斯基的办公桌给了一名实习生，因为克里哲夫斯基几乎从来没有用过这张桌子，他总是在「司机」那边。

「司机」项目的工程师称他为「人工智能密语者」3 ，他的方法很快在整个项目中传播开来。深度学习成为谷歌汽车识别道路上的各种物体 —— 停车标志、街道标记、其他车辆等 —— 的一种方式。克里哲夫斯基称这些为「容易摘到的果子」。在接下来的几年里，他和同事们将这项技术推广到汽车导航系统的其他部分。经过合适的数据的训练，深度学习可以帮助汽车规划前进路线，甚至预测未来事件。在过去的 5 年里，汽车团队一直以手工的方式对汽车的行为进行编程。而现在，他们可以打造自主学习的系统，不再试图一次一行代码地去定义行人是什么样的了，他们可以使用成千上万张街道照片，在几天之内训练一个系统。理论上，如果谷歌能够收集足够的数据 —— 显示汽车在道路上可能遇到的各种情况的图像，然后将其输入一个巨大的神经网络，这个单一的系统就可以完成所有的驾驶行为。在最顺利的情况下，这种未来的情形还需要很多年才能实现，但在 2014 年，这就是谷歌调整之后的方向。

这一时刻是谷歌内部更大规模调整的一部分。至此，神经网络这个单独的想法改变了谷歌在其不断扩张的帝国版图中构建技术的方式，无论是在物理世界，还是在数字世界。在这 4 万个 GPU 芯片以及更多芯片 —— 一个名为「麦克卡车项目」的数据中心 —— 的帮助下，深度学习已经渗透了一切领域，从谷歌照片应用程序（可以在海量的图像中迅速找到目标）到 Gmail（可以预测你将要键入的单词）。它还可以让 AdWords 的运行更为高效，公司 560 亿美元年收入的绝大部分是由这个在线广告系统实现的。4 通过分析用户曾点击过哪些广告的数据，深度学习可以帮助系统预测他们以后会点击什么，更多的点击意味着更多的收入。谷歌花费了数亿美元购买 GPU 芯片，还花了数百万美元招募研究人员，但它已经将这些钱赚回来了。

很快，谷歌搜索的主管阿密特·辛格哈尔承认，互联网技术正在发生变化。2011 年，当吴恩达和巴斯蒂安·特隆与他接触时，他曾强烈抵制深度学习。现在，他和他的工程师们别无选择，只能放弃对搜索引擎构建方式的严格控制。2015 年，他们推出了一个名为 RankBrain 的系统，5 该系统使用神经网络来辅助选择搜索结果，这一举措推动增加了公司约 15% 的搜索查询。6 总的来说，在预测用户点击行为时，它比资深搜索工程师更为准确。几个月之后，辛格哈尔被指控性骚扰并离开了公司，7 人工智能主管约翰·詹南德雷亚取而代之，成为谷歌搜索的新主管。8

在伦敦，戴密斯·哈萨比斯很快透露，DeepMind 已经开发了一个系统，它可以降低谷歌数据中心的网络功耗，并借鉴了该实验室用来破解《越狱》游戏的相同技术。9 该系统决定何时打开、何时关闭单个计算机服务器中的冷却风扇，何时打开、何时关闭数据中心进行额外冷却的窗口，何时使用冷却器和冷却塔，以及服务器何时可以不使用这些设施。10 哈萨比斯说，谷歌的数据中心如此之大，DeepMind 的技术如此有效，它已经为公司节省了数亿美元。11 换句话说，这补偿了收购 DeepMind 的成本。

谷歌 GPU 集群的强大之处在于，它允许该公司对大量的技术进行大规模试验。打造神经网络是一项反复试验的工作，有了成千上万的 GPU 芯片可供使用，研究人员就可以在更短的时间内探索更多的可能性。同样的现象很快刺激了其他公司。在出售 1.3 亿美元的图形芯片给谷歌的刺激下，英伟达围绕深度学习的思路进行了重组，很快就不再满足于仅仅出售用于人工智能研究的芯片，而是自己也参与了研究，探索图像识别和自动驾驶汽车的边界，希望进一步拓展市场。在吴恩达的带领下，百度也在各个方面进行了探索，从新的广告系统到能够预测其数据中心内硬盘何时发生故障的技术。但最大的变化是可对话式数字助理的兴起，这些服务不仅接收从网络浏览器中输入的关键词，还能像搜索引擎一样通过一些互联网链接进行响应。它们可以倾听你的问题和命令，并以语音的方式回答，就像一个真人一样。谷歌在安卓手机上重构了语音识别，在它超越了苹果 Siri 的效果之后，同样的技术在整个行业普及开来。2014 年，亚马逊推出了 Alexa（个人语音助手），并将这项技术从手机端转移到了客厅的茶几上，其他市场也迅速跟进。现在被称为「谷歌助手」的谷歌技术，既可以在手机上运行，也可以在茶几设备上运行。百度、微软甚至 Facebook 都打造了自己的助手。

随着所有这些产品、服务和想法的激增，再加上这些公司和很多其他科技公司的营销部门通常以夸张的方式宣传它们，「人工智能」成了这 10 年的流行词，无休止地在新闻稿、网站、博客和新闻报道中重复出现。一如既往，这是一个让人感到充满压力的术语。对普通大众来说，「人工智能」重振了科幻小说的比喻 —— 可对话的计算机、有感知能力的机器、拟人化的机器人，它们可以做人类能做的任何事情，但最终可能会毁灭它们的创造者。我们更不用说媒体在头条新闻、照片和报道中提到像《2001：太空漫游》和《终结者》这样的电影，试图描述新的技术浪潮了。这就像是弗兰克·罗森布拉特和感知机的历史重现。随着深度学习的兴起，自动驾驶汽车的概念也随之兴起。就在同一时期，牛津大学的一个学术团队发布了一项研究，预测自动化技术将很快在就业市场上崭露头角。12 在某种程度上，这一切都混合成了一锅快要溢出的大杂烩，其中包含非常真实的技术进步、毫无根据的炒作、疯狂的预测，以及对未来的担忧。「人工智能」则是描述这一切的术语。

媒体在人工智能上的叙事需要英雄，于是它们选择了辛顿、杨立昆、本吉奥，有时还会包括吴恩达，这在很大程度上归功于谷歌和 Facebook 在推广上的努力。但媒体宣传并没有延伸到于尔根·施米德胡贝这里，生活在德国卢加诺湖畔的这名研究人员在 20 世纪 90 年代和 21 世纪初在欧洲点燃了神经网络的火炬。有些人对施米德胡贝被排除在外表示异议，包括他自己。2005 年，他和后来加入 DeepMind 的研究员亚历克斯·格雷夫斯发表了一篇论文，描述了一个基于长短期记忆的语音识别系统 —— 具有短期记忆的神经网络。「这是疯狂的施米德胡贝的成果，」辛顿告诉自己，「但它确实有效。」现在，这项技术正在为谷歌和微软等公司的语音服务提供支持，施米德胡贝想要得到他应得的。在辛顿、杨立昆和本吉奥在《自然》杂志上发表了一篇关于深度学习兴起的论文后，施米德胡贝写了一篇评论文章，认为这些「加拿大人」并不像他们看起来那样具有影响力，因为他们的工作是建立在欧洲和日本其他人的想法之上的。大约在同一时期，当伊恩·古德费洛介绍他关于 GAN（生成对抗网络）的论文时 —— 这项技术很快就在整个行业产生了反响 —— 施米德胡贝从观众席中站了起来，指责他没有引用瑞士 20 世纪 90 年代的相关论文。他经常做这种事情，以至于他的名字变成了一个动词，比如：「你一直都在施米德胡贝。」13 但他并不是唯一一个为正在发生的事情邀功的人。多年来，很多深度学习研究人员的想法在这个圈子一直被忽视，他们感到迫切需要宣扬自己在一场真正的技术变革中的个人贡献。「每个人的内心都有对荣誉的一点儿虚荣，」辛顿说，「你也可以在自己身上看到这一点，意识到这一点很好。」

亚历克斯·克里哲夫斯基是一个例外。正如辛顿所说：「他内心没有那么在意名声。」坐在「司机」项目的办公桌前，克里哲夫斯基是这场人工智能热潮的核心人物，但他不认为自己的角色有那么重要，也不认为自己的角色在于人工智能。他的角色在于深度学习，深度学习只是数学、模式识别，或者正如他所说的 ——「非线性回归」。这些技术已经存在了几十年，只是像他这样的人在正确的时间出现了，当时有足够的数据和足够的处理能力来让这一切发挥作用。他打造的技术一点儿也不智能，这些技术只在非常特殊的情况下有效。「深度学习不应该被称为人工智能，」克里哲夫斯基说，「我读研究生是为了研究曲线设置，而不是人工智能。」他的工作，先是在「谷歌大脑」，然后在自动驾驶汽车项目，都是将数学应用于新场景。这与任何重建大脑的尝试都相去甚远，更谈不上需要担心有一天机器会超出我们的控制范围。这是计算机科学，其他人都认同，但这并不能成为头条新闻的观点。更响亮的声音来自他在多伦多大学实验室的老同学伊利亚·萨特斯基弗。

### 02

2011 年，还在多伦多大学的时候，萨特斯基弗飞到伦敦参加 DeepMind 的面试。他在拉塞尔广场附近跟戴密斯·哈萨比斯和沙恩·莱格碰面，在三个人交流时，哈萨比斯和莱格解释了他们正在做什么。他们在打造通用人工智能，而起点是会玩游戏的系统。萨特斯基弗一边听，一边觉得他们已经脱离了现实，他觉得通用人工智能不是严肃的研究人员谈论的话题。所以，他拒绝了这家初创公司提供的工作，回到了大学，最终加入了谷歌。但是一进入谷歌，他就意识到人工智能研究的本质正在发生变化，它不再是一两个人在学术实验室里摆弄神经网络了，参与的都是大团队，所有人都朝着共同的大目标努力，背后有大量的计算能力做支撑。他一直喜欢大的想法，当他进入「谷歌大脑」时，他的想法变得更大了。作为伦敦实验室和「谷歌大脑」跨大西洋合作的一部分，他在 DeepMind 办公室待了两个月，之后他开始相信，取得真正进展的唯一途径是触达看似遥不可及的东西。他的想法与杰夫·迪恩（他更关心对市场产生即时影响）的目标不同，也与杨立昆（他一心用自己的研究展望未来，但从未走得太远）的目标不同，而是更接近于 DeepMind 创始人的观点。他说的好像遥远的未来就在眼前 —— 可以超越人类思维的机器，可以创建其他计算机数据中心的计算机数据中心。他和他的同事们需要的只是更多的数据和处理能力。然后，他们就可以训练一个系统去做任何事情了 —— 不仅仅是开车，还包括阅读、交谈和思考。「他是一个不惧怕相信的人，」谢尔盖·莱文（Sergey Levine）说，莱文是一位机器人研究员，这些年来在谷歌一直与萨特斯基弗共事，「不怕的人有很多，但他尤其不怕。」

当萨特斯基弗加入谷歌时，深度学习已经重构了语音和图像识别。下一个重大步骤是「机器翻译」，这项技术可以即时将任何一种语言翻译成其他语言。这是一个更加困难的问题。它涉及的不是识别单一的东西，比如照片中的小狗。它是将「一系列的东西」（比如组成一个句子的单词）转换成另一个系列（那个句子的翻译）。这需要一种完全不同的神经网络，但萨特斯基弗相信解决方案并不遥远，他并不孤单。「谷歌大脑」的两位同事的目标跟他一样，在百度和蒙特利尔大学等地方，还有其他人也在尝试同样的道路。

「谷歌大脑」已经探索出了一种被称作「词嵌入」的技术，这涉及通过大量的文本分析（新闻文章、维基百科文章、自出版书籍等），使用神经网络来构建英语的数学地图，以显示该语言中每个单词和其他单词之间的关系。14 这不是一张你可以想象的地图。它不是像路线图那样的二维，也不是像电子游戏那样的三维，它有成千上万个维度，类似的东西你从未见过，也永远看不到。在这张地图上，「哈佛」这个词与「大学」、「常春藤」和「波士顿」很接近，尽管这些词在语言上并不相关。地图给每个单词一个数学值，这个值定义了它与语言中其他部分的关系，这被称为「向量」。「哈佛」的向量看起来很像「耶鲁」的向量，但它们并不完全相同。与「耶鲁」接近的是「大学」和「常春藤」，但不是「波士顿」。

萨特斯基弗的翻译系统是这一想法的延伸。15 运用瑞士的于尔根·施米德胡贝和亚历克斯·格雷夫斯开发的长短期记忆方法，萨特斯基弗将大量的英语文本和它们的法语译文一起输入神经网络。通过分析原文和译文，这个神经网络学会了为一个英语句子建立一个向量，然后将其映射到一个具有相似向量的法语句子。即使你不懂法语，你也能看到其中数学的力量。「玛丽崇拜约翰」的向量与「玛丽爱上了约翰」和「玛丽尊重约翰」的向量非常相似，而与「约翰崇拜玛丽」的向量完全不同。「她在花园里给了我一张卡片」的向量与「我在花园里收了她给的一张卡片」和「在花园里，她给了我一张卡片」的向量相匹配。到了年底，萨特斯基弗和他的合作者们打造的系统的性能超过了其他所有翻译技术，至少在他们测试的少量英语和法语翻译中是这样的。

2014 年 12 月，当年的 NIPS 会议在加拿大蒙特利尔举行，萨特斯基弗向来自全球的研究人员展示了一篇描述他们工作的论文。16 他告诉与会的观众们，这个系统的优势在于其简洁性。「我们用最小的创新，获得了最大的结果。」他说，观众掌声雷动，甚至让他大吃一惊。他解释说，神经网络的力量在于，你可以向它输入数据，它会自行学习。虽然训练这些数学系统有时就像黑魔法，但这个项目并非如此。「它想工作。」他说。在接收数据并进行一段时间的训练之后，它就会给出结果，不需要反复试验。但萨特斯基弗并不认为这仅仅是在翻译上的突破，他认为这是在任何涉及序列的人工智能问题上的突破，从自动为照片生成标题，到用一两句话对一篇新闻文章做即时总结。他说，人类在几分之一秒内能做的任何事情，神经网络也能做，它只需要正确的数据。他告诉观众：「真正的结论是，如果你有一个非常大的数据集和非常大的神经网络，那么成功是有保证的。」

杰夫·辛顿在会场的后面观看他的演讲。正如萨特斯基弗所说的「成功是有保证的」，他认为：「只有萨特斯基弗才不受到质疑。」有些研究人员对这种大胆的说法感到愤怒，但其他人被吸引住了。萨特斯基弗可以这样说，而不会引起太多的怨恨。他就是这样的人，虽然从别人口中说出来有些可笑，但从他口中说出来的就是真实的。他也是对的，至少在翻译方面是这样的。在接下来的 18 个月里，「谷歌大脑」将这个原型转变成了一个被数百万人使用的商业系统，这与该实验室三年前对纳夫迪普·贾特利的语音原型所做的工作如出一辙。但在这里，该实验室改变了等式，这在整个领域引发了另一波涟漪，并最终放大了伊利亚·萨特斯基弗和其他很多人的野心。

### 03

「我们需要另一个谷歌。」杰夫·迪恩告诉乌尔斯·霍尔泽（Urs Holzle），后者是一位出生于瑞士的计算机科学家，谷歌数据中心的负责人。这是真的。谷歌在部分安卓手机上发布新的语音识别服务几个月之后，迪恩意识到一个问题：如果谷歌继续扩展这项服务，那么这项服务最终就能覆盖全球 10 多亿部安卓手机，而这 10 多亿部手机每天只分别使用这项服务 3 分钟，公司却将需要两倍的数据中心来处理所有额外的流量。这是一个巨大的问题。谷歌的数据中心已经超过 15 个 —— 从美国加州到芬兰，再到新加坡 —— 每个数据中心的建设成本都高达数亿美元。17 但是，在与霍尔泽及其他几位专门研究数据中心基础设施的同事召开的常务会议上，迪恩提出了一个替代方案：他们可以开发一种新的计算机芯片，仅用于提供神经网络。

谷歌在开发自主的数据中心硬件方面有着较长的历史。18 它的数据中心如此庞大，消耗了巨量的电力，为了以更便宜、更高效的方式提供谷歌服务，霍尔泽和他的团队花了数年时间设计计算机服务器、网络设备和其他设备。这项鲜有讨论的业务与惠普、戴尔和思科这些商业硬件制造商形成竞争，并最终从它们的核心业务中抢走了大量资金。由于谷歌开发了自己的硬件，它不需要在公开市场上采购，随着 Facebook、亚马逊和其他公司开始效仿，这些互联网巨头创造了一个计算机硬件的影子行业。19 但是，谷歌从来没有开发过自己的计算机芯片，它的竞争对手们也没有。因为这需要更高水平的专业知识和更大的投资，在经济上不划算。英特尔和英伟达等公司以如此庞大的规模生产芯片，其成本优势是谷歌无法匹敌的，并且它们生产的芯片能够完成谷歌需要完成的工作。英伟达的 GPU 芯片推动了深度学习的兴起，帮助训练了像安卓语音服务这样的系统。但是，现在迪恩正在处理一个新问题。在训练了这项服务后，他需要一种更有效的方式来运行它 —— 通过互联网提供服务，并将其传递给全世界。迪恩可以用 GPU 或标准处理器来实现，但这两者都没有他所需要的高效性能。因此，他和他的团队开发了一种新的芯片，专门用于运行神经网络。他们在周围各种不同的部门筹集资金，包括搜索团队。此时，所有人都已经看到了深度学习能够做什么。

多年来，谷歌一直在威斯康星州麦迪逊的一个半秘密实验室里设计数据中心硬件。霍尔泽是一位前计算机科学教授，戴着钻石耳钉，留着一头蓬松的斑白短发，他将这项工作视为公司真正的竞争优势，小心翼翼地保护其设计免受 Facebook 和亚马逊等竞争对手的关注。麦迪逊是一个偏僻的地方，但还是依靠威斯康星大学工程学院吸引了源源不断的人才。现在，迪恩和霍尔泽在新的芯片项目中利用了这些人才资源，同时还从惠普等硅谷公司聘请了经验丰富的芯片工程师。他们的成果就是张量处理器，即 TPU，它是设计用来处理支撑神经网络的张量的，而张量就是数学对象。其中的诀窍在于它的计算不像典型的处理器那样精确。20 神经网络进行的计算量如此之大，但每次计算都不必精确，它处理的是整数而不是浮点数。TPU 不是将 13.646 乘以 45.828，而是砍掉了小数点，将 13 和 45 相乘。这意味着它每秒钟可以执行数万亿次额外的计算，而这正是迪恩和他的团队需要的，不仅是为了语音服务，也是为了语言翻译。

萨特斯基弗的工作是研究，而不是开发大规模的消费级产品。他的系统可以很好地处理普通词汇，但不能处理更大体量的词汇，也不能真正与谷歌 10 多年来通过互联网提供的翻译服务竞争 —— 现有的服务是建立在完善的老式规则和统计数据之上的。但多亏了他搜集的所有数据，公司才去搜集了大量的翻译，使用萨特斯基弗和他的同事们所展示的方法，这些翻译有助于训练一个更大的神经网络。他们的数据集比萨特斯基弗过去训练系统所用的数据集大 100 到 1 000 倍。21 因此，在 2015 年，迪恩挑选了三名工程师来打造一个可以从这些数据中学习的系统。22

谷歌现有的翻译服务是将句子分解成片段，再将它们转换成另一种语言的片段，然后努力将这些片段连接成一个连贯的整体，因此，深夜电视节目主持人吉米·法伦（Jimmy Fallon）开玩笑说谷歌翻译的句子杂乱无章、略显混乱、不够连贯。对英语和法语来说，其 BLEU 评分（衡量翻译质量的标准方法）不足 30 分，这意味着效果不太好，而且在 4 年的时间里只提高了 3 分多。23 经过短短几个月的工作，迪恩的团队打造了一个神经网络，其评分比现有系统高 7 分。24 与所有深度学习方法一样，该方法的强大之处在于这是一个单一的学习任务，没有必要把句子分解成几个部分。「突然之间，事情从不可理解变成了可以理解，」麦克达夫·休斯（Macduff Hughes）说，他是开发旧系统的团队负责人，「就像有人把灯打开了。」

但是，有一个问题。翻译一个由 10 个单词组成的句子需要 10 秒钟，这在开放的互联网上永远都行不通。25 用户是不会使用的。休斯认为，公司需要三年时间来完善该系统，使其能够毫不拖延地提交翻译。26 但是，迪恩不这么认为。27 在旧金山一家酒店里召开的公司会议上，他告诉休斯：「我们如果下定决心，就可以在年底前完成。」28 休斯对此表示怀疑，但他告诉他的团队要在年底前为新的服务做好准备。29 他说：「我不会是那个说杰夫·迪恩无法实现这一速度的人。」30

他们在和百度赛跑。几个月前，这家中国互联网巨头发表了一篇描述类似研究成果的论文，31 同年夏天，它又发表了一篇论文，展示了与「谷歌大脑」内部打造的系统相当的性能。随着杰夫·迪恩和他的团队打造出新版本的谷歌翻译，他们决定在中英文翻译上首次推出该服务。由于这两种语言之间的巨大差异，这是为深度学习提供最大改进的配对。从长远来看，这也是翻译能够提供最大好处的配对。毕竟，这是世界上最大的两个经济体。最终，谷歌工程师比迪恩的最后期限还提前了三个月，原因就在于 TPU。在谷歌新芯片的帮助下，2 月，在普通硬件上需要翻译 10 秒的句子可以在几毫秒内被翻译出来。32 他们在美国劳动节之后发布了这项服务的第一个版本，远远早于百度。33「我很惊讶它能如此有效。我想每个人都会感到惊讶的，」辛顿说，「没人能想到，这么快就能这么有效。」

### 04

当杰夫·辛顿来到谷歌时，他和杰夫·迪恩参与了一个他们称之为「蒸馏」（Distillation）的项目。34 这是一种采用他们在公司内部训练的巨型神经网络的方式，他们将它所学的一切缩小到合适的规模，使得谷歌可以在实时网络服务中实际使用，迅速将其技能传递给全球网民。这是辛顿漫长的职业生涯（神经网络）与迪恩的职业生涯（全球计算）的结合。然后，辛顿超越了神经网络，转向一种全新的、更复杂的模仿大脑的工作。那是他在 20 世纪 70 年代末首先提出的一个想法，他称之为「胶囊网络」。在谷歌收购 DeepMind 后的那个夏天，辛顿计划在伦敦实验室待上三个月，并决定用这三个月的时间来研究这个「新的旧想法」。

他买了两张从纽约到英国南安普敦的「玛丽女王 2 号」的船票 —— 一张是他自己的，一张是给他的妻子杰基·福特的，她是一位艺术史学家。在第一任妻子罗莎琳德因卵巢癌去世后，辛顿在 20 世纪 90 年代末与杰基结婚。他们计划在一个星期天从纽约启航。在他们离开多伦多之前的一个星期四，杰基被诊断为患有晚期胰腺癌。医生预计她还有大约一年的生存期，并建议她立即开始化疗。在知道没有治愈的机会后，她决定去英国旅行，然后在秋天时回到多伦多开始治疗。她的家人和很多朋友还在英国，这将是她最后一次见到他们。因此，她和辛顿去了纽约，并于周日起航前往南安普敦。辛顿确实花了整个夏天围绕着「胶囊网络」的想法工作，但没有取得太大进展。