凯德·梅茨.(2023.2021).2024013深度学习革命.(桂曙光译).中信出版社 => 0101 感知机：最早的神经网络之一

Cade Metz.(2007).2024013Genius-Makers => Preface

第四部分被低估的人类　PART FOUR　HUMANS ARE UNDERRATED

## 1801. 一场马库斯与杨立昆的辩论

无论快速发展能持续多久，盖瑞都认为它即将结束。

谷歌每年会举办一场名为「谷歌 I/O」的重要会议，这场会议的名称源于代表「输入 / 输出」的计算机名词缩写。每年 5 月，成千上万人会前往山景城参加这一企业盛会，这些来自硅谷及其他地方的科技行业从业人员，可以在为期三天的会议中了解谷歌的最新产品和服务。谷歌年度会议的主题演讲在海岸线露天剧场举行，这是一个拥有 22 000 个座位的音乐会场地，马戏团帐篷般的尖顶耸立在公司总部对面绿草如茵的山丘上。几十年来，从「感恩而死」到「U2」，再到「后街男孩」，这些知名的乐队都来露天剧场表演过。现在，桑达尔·皮查伊上台向成千上万的软件开发人员介绍这家日益多元化的公司的无数技术。2018 年春，在大会开幕的当天，皮查伊外面穿着一件森林绿色的羊毛拉链衫，里面穿着一件亮白色 T 恤，他告诉所有与会者，该公司开发的会说话的数字助理可以自己打电话。1

得益于杰夫·辛顿和他的学生在多伦多大学首创的方法，「谷歌助手」几乎可以像人类一样识别口语单词。也得益于 DeepMind 开发的语音生成技术 WaveNet，它的声音听起来也更为人性化了。然后，站在海岸线露天剧场的舞台上，皮查伊展示了一项新的改进。他告诉与会的听众，谷歌助手现在可以打电话给一家餐厅并进行预订，后台的谷歌计算机网络能够帮它做到这一点。在你做一些完全无关的事情的时候，比如倒垃圾或给草坪浇水时，你可以让助手为你预订晚餐的座位，这位助手会从谷歌数据中心的某个地方自动给餐厅打电话。皮查伊播放了其中一段电话录音，这是谷歌助手跟一家不知名餐厅接电话的女人之间的对话。

「嗨，需要帮忙吗？」这位女人问道，她带着浓重的中国口音。

「嗨，我想预订一张 7 号星期三的桌子。」谷歌助手说。

「7 个人？」女人问道。（笑声在露天剧场里荡漾。）

「嗯，4 个人的桌子。」谷歌助手说。

「4 个人。什么时候？今天？今晚？」餐厅的女人说。（笑声越来越大。）

「嗯，下周三下午 6 点。」

「实际上，我们预约要 5 个人以上。4 个人的话，你们可以直接来。」

「通常要等多久才能入座？」

「什么时候？明天？还是周末？」

「下周三，呃，7 号。」

「哦，那时候不是太繁忙。你们可以 4 个人来，好吧？」

「哦，我明白了。谢谢你。」

「好的。再见。」这位女士说。（皮查伊的观众们爆发出了欢呼声和惊叹声。）

正如皮查伊解释的那样，这项新技术被命名为 Duplex，它是多项人工智能技术多年发展的结果，包括语音识别、语音生成以及自然语言理解。它不仅能够识别和生成口语单词，而且能够真正理解语言的使用方式。对观众来说，皮查伊的演示非常强大。然后，他又给观众播放了第二段演示，让系统在当地一家发廊预约理发。当接电话的女士说「稍等」、Duplex 回应「嗯嗯」时，现场掌声响起。Duplex 不仅可以用正确的词语来回应，还可以用正确的声音 —— 正确的语言暗示来回应。此后，很多权威人士抱怨，谷歌的 Duplex 如此强大，这是不道德的。它在主动欺骗大家，让别人以为它是人类。谷歌同意对系统进行调整，2 使其始终透露自己是一个机器人，谷歌很快在美国各地发布了这款工具。3

但是对盖瑞·马库斯来说，这项技术并不像看上去的那样完美。

皮查伊在海岸线露天剧场演示几天后，纽约大学心理学教授马库斯在《纽约时报》上发表了一篇社论，对谷歌的 Duplex 泼了点儿冷水。4「假设演示是真实的，这是一个令人印象深刻（有点儿令人毛骨悚然）的成就，但是谷歌 Duplex 并不是很多人认为的、有意义的人工智能的进步。」他说。5 奥妙在于这个系统演示的是一个非常细分的场景：餐厅预订和发廊预约。通过缩小范围 —— 限制对话双方可能回应的内容 —— 谷歌可以欺骗人们，让他们相信机器是人。这与一个可以超越这些界限的系统截然不同。「安排发廊预约？人工智能的梦想应该比这个更加宏伟，比如辅助医疗革命或者为家庭制造值得信赖的机器人助手，」他写道，「谷歌 Duplex 之所以范围如此狭窄，并不是因为它代表了朝着这些目标迈出的微小而重要的第一步，而是因为人工智能领域还不知道如何做得更好。」6

### 01

盖瑞·马库斯是众多这样的思想家之一，他们相信先天遗传的重要性，而不仅仅是后天培养的重要性。他们被称为先天论者，他们认为，所有人类知识的很大一部分，是传输进大脑的，而不是从经验中学到的。这是一场跨越了几个世纪的哲学和心理学争论，从柏拉图到康德，再到诺姆·乔姆斯基，再到史蒂芬·平克（Steven Pinker）。先天论者反对经验主义者，后者认为人类的知识主要来自学习。盖瑞·马库斯曾在心理学家、语言学家和科普作家平克的指导下学习，之后围绕同样的基本态度创立了自己的事业。现在，他在人工智能领域施展他的先天论主义。他是全球针对神经网络的主要批评者，是「深度学习时代的马文·明斯基」。

正如他相信知识会传输进人脑一样，他也相信研究人员和工程师别无选择，只能将知识传输进人工智能。他确信，机器无法学会一切。早在 20 世纪 90 年代初，他和平克就发表了一篇论文，表明神经网络甚至无法学会非常年幼的孩子已经掌握的语言技能，比如识别常用动词的过去式。过了 20 年，在 AlexNet 之后，当《纽约时报》在头版刊登了一篇关于深度学习兴起的报道时，他给《纽约客》写了一篇专栏文章作为回应，他认为这种变化并没有看起来那么大。7 他说，杰夫·辛顿支持的技术并不够强大，不足以理解自然语言的基础，更不用说复制人类思维了。他写道：「套用一个古老的寓言，辛顿制作了一个更好的梯子，但更好的梯子无法让你登上月球。」8

具有讽刺意味的是，不久之后，马库斯就在深度学习的热潮中大赚了一笔。在 2014 年初，听说 DeepMind 以 6.5 亿美元的价格出售给了谷歌，他想，「我也能做到」。于是他给一位名叫祖宾·盖拉马尼（Zoubin Ghahramani）的老朋友打了电话。他们相识于 20 多年前，当时他们都是麻省理工学院的研究生。马库斯在那里学习认知科学，而盖拉马尼在参与弥合计算机科学和神经科学之间差距的一个项目。他们之所以成为朋友，是因为他们曾在剑桥杂志街马库斯的公寓里庆祝他们共同的 21 岁生日。在获得博士学位后，盖拉马尼跟现在很多人工智能研究人员一样，走上了一条为谷歌、Facebook 和 DeepMind 工作的道路。他在多伦多大学杰夫·辛顿手下做过博士后研究，然后跟随辛顿去了伦敦大学学院的盖茨比中心。但盖拉马尼最终远离了神经网络研究，他接受了他认为更优雅、更强大、更有用的想法。所以，在 DeepMind 出售给谷歌之后，马库斯说服盖拉马尼相信，他们应该围绕一个理念创建自己的初创公司，这个理念就是，世界需要的不仅仅是深度学习。他们称之为「几何智能」。

他们从美国各地的大学招募了十几位人工智能研究人员，其中一些人专门从事深度学习，包括盖拉马尼在内的其他人则从事其他技术。马库斯并非不知道这项技术的力量，但他当然了解围绕它的炒作。在 2015 年夏天创立他们的初创公司后，他和盖拉马尼将他们的学术团队安置在曼哈顿市中心的一间小办公室里，那里是纽约大学孵化初创公司的地方。马库斯跟他们在一起，而盖拉马尼留在英国。仅仅过了一年，在跟苹果、亚马逊等很多最大的科技公司交流后，他们将自己的初创公司出售给了 Uber，这家迅速发展的叫车公司立志打造自动驾驶汽车。9 这家初创公司的十几名研究人员迅速搬到了旧金山，成立了 Uber 人工智能实验室。马库斯搬去了实验室，而盖拉马尼仍留在了英国。然后，在没有太多解释的情况下，马库斯 4 个月之后离开了公司，回到了纽约，恢复了他作为全球深度学习主要批评家的角色。他不是人工智能研究员，他是一个醉心于自己思想的人，一位同事称他为「可爱的自恋者」。回到纽约之后，他开始写一本书，再次主张机器靠自己只能学习这么多，他开始基于同样的前提创立第二家公司。他还向辛顿这样的人提出挑战，要求对方就人工智能的未来展开公开辩论。辛顿没有接受。

但在 2017 年秋天，马库斯在纽约大学与杨立昆进行了一场辩论。10 这场辩论由纽约大学的精神、大脑和意识中心组织，该中心是一个结合了心理学、语言学、神经科学、计算机科学等多种学科的项目。这场辩论的主题是自然对抗后天、先天论对抗经验主义、「先天机器」对抗「机器学习」。马库斯是第一个发言的人，他认为深度学习的能力并不比简单的感知强多少，比如识别图像中的物体或识别口语单词。「如果说神经网络教会了我们什么，那就是纯粹的经验主义有其局限性。」他说。11 他解释说，在通往人工智能的漫长道路上，深度学习只迈出了很小的几步。除了感知（像图像识别和语音识别）和媒体生成（像 GAN）之外，它最大的成就是解决了围棋问题，围棋只是一个游戏，是规则被严格定义的一个封闭的「宇宙」。现实世界几乎无限复杂。马库斯常常说，一个经过训练、可以下围棋的系统在任何其他情况下都毫无用处。它不够智能，因为它不能适应全新的情况，它当然也无法处理人类智能的关键产品之一：语言。「纯粹的自下而上的统计数据并没有让我们在一系列重要的问题上走得太远 —— 语言、推理、规划和常识 —— 虽然经过了 60 年的神经网络研究，虽然我们有了更好的计算、更多的记忆和更好的数据，但情况依然如此。」他告诉观众。12

他解释说，问题在于神经网络并不像人脑那样学习。即使在掌握神经网络无法掌握的任务时，大脑也不需要深度学习所需要的大量数据。儿童，包括新生婴儿，可以从少量的信息中进行学习，有时信息只是一两个好的例子。在家庭中长大的孩子，即使父母对他们的发展和教育不感兴趣，他们自己也可以通过倾听周围的声音来学习口语的细微差别。他认为，神经网络不仅需要成千上万个例子，还需要有人仔细对所有的例子进行标记。这表明，如果没有更多先天论者所谓的「先天机器」，人工智能就不会发生，他们认为大量的知识已经融入人脑。马库斯说：「学习之所以成为可能，只是因为我们的祖先进化出了代表空间、时间和持久物体等事物的‘机器 '。我的预测 —— 这只是一个预测，我无法证明 —— 当我们学会将类似的信息整合到人工智能中时，人工智能的效果会更好。」13 换句话说，他相信，有很多东西是人工智能无法独立学习的，必须由工程师手工编码。

作为一个坚定的先天论者，马库斯有一个意识形态的议程。围绕「先天机器」的理念，在打造一家新的人工智能初创公司时，他也有一个经济方面的议程。在纽约大学与杨立昆的辩论是一场协同运动的开始，旨在向全球人工智能研究人员的圈子、科技行业和普通公众展示，深度学习的局限性远比看起来的要大。在 2018 年刚开始的几个月，他发表了他所谓的「论文三部曲」来批评深度学习，尤其针对 AlphaGo 的壮举。14 然后，他在大众媒体上发表评论，其中一篇报道出现在《连线》杂志的封面上。所有这些最终促成了一本他命名为《重启人工智能》的书 15 ，以及一家新的初创公司，这家公司旨在利用他所认为的全球人工智能探索中的一个漏洞。

杨立昆被这一切弄得不知所措。正如他在纽约大学告诉观众的那样，他认同单靠深度学习无法获得真正的智能，他也从未做过肯定的表述。16 他认同人工智能需要「先天机器」。毕竟，神经网络就是「先天机器」。但有些东西必须学习。他在辩论中很有分寸，甚至很有礼貌，但他的语气在网上变味了。当马库斯发表他的第一篇质疑深度学习未来的论文时，杨立昆在 Twitter 上回应道：「准确来说，盖瑞·马库斯提出过的有价值的建议的数量是零。」

马库斯并不孤单。很多人正在抵制来自行业和媒体围绕着「人工智能」这几个词无休止的炒作浪潮。Facebook 站在深度学习革命的前沿，把这项技术作为解决最紧迫问题的答案。但是，越来越明显的是，这充其量只是部分解决方案。多年来，像谷歌和 Uber 这样的公司承诺自动驾驶汽车将很快上路，并每天穿梭于美国和国外的城市。但即使大众媒体也开始意识到，这些说法被严重夸大了。尽管深度学习显著提高了它们识别道路上的行人、物体和标志的能力，并加速了它们预测事件和规划路线的能力，但与人类敏捷地应对日常通勤中的混乱状况相比，自动驾驶汽车还有很长的路要走。谷歌承诺在 2018 年底之前在亚利桑那州凤凰城提供叫车服务，但这件事并没有实现。至于将深度学习用于新药研发，在乔治·达尔和他的多伦多合作者赢得默克公司主办的竞赛之后，这个领域似乎充满了希望，但事实证明，这是一个比看起来要复杂得多的命题。来到谷歌之后没多久，达尔就放弃了这个想法。他说：「问题是，在新药研发的通道中，我们最能提供帮助的部分并不是最重要的部分，并不是这部分的工作导致将一种分子推向市场需要 20 亿美元的成本。」主管艾伦人工智能研究所的华盛顿大学前研究员奥伦·埃齐奥尼经常说，尽管围绕深度学习进行了各种炒作，但人工智能甚至无法通过八年级的科学测试。

2015 年 6 月，杨立昆公开了 Facebook 在巴黎的新实验室，他说：「深度学习的下一个重大步骤是自然语言理解，其目的是让机器不仅能够理解单个单词，还能理解整个句子和段落。」这是更广泛的研究人员圈子的目标 —— 在图像和语音识别之外的下一大步。自 20 世纪 50 年代以来，打造一台能够理解人类以自然方式书写和说话（甚至进行对话）的机器，一直是人工智能研究的最终目标。但到了 2018 年底，很多人开始觉得这种信心是错误的。

辩论接近尾声的时候，马库斯和杨立昆接受观众提问，一位穿着黄色上衣的女士站了起来，她问杨立昆为什么自然语言的进步停滞不前。

「没有什么比物体识别更具革命性的东西出现了。」她说。17

「我不完全同意你的前提，」杨立昆说，「还有 ——」

然后，她打断了他，说：「你的例子是什么？」

「翻译。」他说。

「机器翻译不一定代表着语言理解。」她说。

### 02

就在进行这场辩论的同时，艾伦人工智能研究所的研究人员公布了针对计算机系统的一种新的英语测试，18 它要测试机器能否完成下面这样的句子：

舞台上，一位女士坐在钢琴前。她 ——

a．坐在长椅上，她姐姐在玩洋娃娃。

b．随着音乐响起，跟某人一起微笑。

c．在人群中，看着舞者。

d．紧张地将手指放在琴键上。

机器做得不太好。而人类回答测试问题的正确率超过了 88%，艾伦人工智能研究所打造的系统的正确率达到了 60% 左右，其他机器的表现要差得多。然后，过了大约两个月，由一位名叫雅各布·德夫林（Jacob Devlin）的人领导的谷歌研究团队公布了一个他们称之为 BERT 的系统。19 BERT 参加测试时，可以正确回答的问题和人类一样多，并且它也不是为了参加测试而设计的。

BERT 被研究人员称为「通用语言模型」。其他几个实验室，包括艾伦人工智能研究所和 OpenAI，也在研究类似的系统。通用语言模型是巨大的神经网络，通过分析人类书写的数百万个句子，来学习变幻莫测的语言。OpenAI 构建的系统分析了成千上万本自助出版的书籍，包括爱情小说、科幻小说和推理小说。BERT 分析了同样庞大的图书馆以及维基百科上的每一篇文章，在数百个 GPU 芯片的帮助下，花了几天时间仔细阅读了所有的文本。

每个系统都通过分析所有这些文本学会了一项非常具体的技能。OpenAI 的系统学会了猜测句子的下一个单词，BERT 学会了猜测句子中任何地方缺失的单词（比如，「这个人____这辆车，因为它很便宜」）。但是，在掌握这些具体任务的过程中，每个系统也了解了语言拼凑的一般方式，以及数千个英语单词之间的基本关系。然后，研究人员可以很容易地将这些知识应用到其他广泛的任务之中。如果他们把成千上万个问题和答案输入 BERT，它就能自行学会回答其他问题；如果他们把大量的对话输入 OpenAI 的系统，它就能学会对话；如果他们给它提供成千上万个负面标题，它就能学会识别负面标题。

BERT 证明了这个伟大的想法是可行的。它可以应对艾伦人工智能研究所的「常识」测试，还可以处理阅读理解测试，在其中回答有关百科全书文章的问题。什么是碳？吉米·霍法是谁？在另一项测试中，它可以判断电影评论的情绪是积极的还是消极的。在这些情况下，它其实并不完美，但它立即改变了自然语言研究的进程，以一种前所未有的方式加速了该领域的进展。杰夫·迪恩和谷歌开源了 BERT 的代码，并很快用 100 多种语言对其进行了培训。有些人建立了更大的模型，用更大的数据量训练模型。作为研究人员之间的一种内部玩笑，这些系统通常以《芝麻街》中的角色命名：ELMO、ERNIE、BERT。但这掩盖了它们的重要性。几个月后，利用 BERT，奥伦·埃齐奥尼和艾伦人工智能研究所开发了一个人工智能系统，它可以通过八年级的科学测试，也可以通过十二年级的测试。

在 BERT 公开之后，《纽约时报》发表了一篇关于通用语言模型兴起的报道，解释了这些系统如何改进广泛的产品和服务，包括从 Alexa 和谷歌助手这样的数字助理，到自动分析律师事务所、医院、银行和其他企业内部文档的软件。这解释了为什么人们担心这些语言模型会导致更强大版本的谷歌 Duplex 出现，这是一种旨在让世界相信它们是人类的机器人。这篇报道还援引了盖瑞·马库斯的话，说公众应该怀疑这些技术是否会继续如此迅速地改进，因为研究人员往往专注于他们可以取得进展的工作，而回避那些他们无法取得进展的工作。「这些系统离真正理解散文还有很长的路要走。」马库斯说。20 杰夫·辛顿读到这里时，他很开心。他说，盖瑞·马库斯的这句话将被证明是有用的，因为它可以在未来几年里用于任何关于人工智能和自然语言的报道之中。「它没有技术含量，所以永远不会过时，」辛顿说，「无论快速发展能持续多久，马库斯都会认为它即将结束。」