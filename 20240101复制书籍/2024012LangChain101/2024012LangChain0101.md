方军.(2024).2024012LangChain101.未出版 => 0101 LangChain 简介：为何需要

## 0101. LangChain 简介：为何需要

AI 能够回答问题、写文章、编写程序、生成图片、生成视频，自 2022 年底 OpenAI 推出 ChatGPT 依赖，大模型激发起学界、产业界和公众对人工智能的巨大热情。所谓大模型，通常指的是生成式 AI（Generative AI）这一类别的预训练深度学习模型。

生成式 AI 主要包括两大类：一类是基于文本训练的大语言模型（LLM），一类是图像生成模型如稳定扩散模型（Stable Diffussion）。在这里，我们使用的主要是大语言模型。值得注意的是，它们背后采用的是同一种人工智能神经网络架构，即 2017 年由谷歌八名研究员提出的 Transformer 架构。

现在，众多公司或研究机构纷纷推出开源或闭源大语言模型，它们可用于问答、写作、翻译、客服等众多场景，能够大幅度提升管理学家彼得·德鲁克所说的知识工作者的工作效能。

但是，仅有大语言模型是不够的，普通人要能运用它的能力，还需要应用开发者依托模型的能力开发易用的应用。聊天机器人 ChatGPT 即是 OpenAI 依托自己的 GPT 模型（GPT-3.5、GPT-4 等）开发的应用。

我们把这些应用称为「AI 应用」。AI 应用的开发者们在尝试用各种途径，其中一个重要的现象是使用 LangChain 等 「AI 应用开发框架」。在这个系列教程中，我们将介绍 LangChain 的核心设计，讨论如何使用它，如何用它更高效地开发应用。

在这一系列的第一篇教程中，我们将先暂不讨论具体的开发实现，而是从宏观出发讨论如下两方面：

1、什么是大语言模型、提示语、AI 应用。

2、LangChain 是什么？为什么需要它？

AI 应用与调用链：

在本教程中，AI 应用主要指的包括一次或多次的对大语言模型的调用的工作流（Workflow），其能协助用户利用模型完成特定的生成型任务，比如文档问答、文章修改、生成代码等。这个工作流也就是 AI 应用的业务逻辑。

在 LangChain 中，这个工作流被称作 Chain（预设的工作流）或 Agent（AI 参与执行步骤的选择）。我们在这里把 AI 应用的业务逻辑或工作流的中文统称为「调用链」。

与判别型模型及应用任务主要产生数据预测不同，这个工作流的最终目标通常是生成新的内容。

接下来，我们将主要使用 AI 模型或 AI 大语言模型（或简单地说模型）来表示各个生成式 AI 的大语言模型等。

### 0101. AI 大语言模型与 AI 应用简介

普通人对 AI 大语言模型的第一反应是：它很神奇，当我们向它提问时，它能够以通顺的语言、正确的信息进行回答。它拥有至少普通人水准的语言水平，也至少拥有普通人水准的知识水平。当然，它所给出的回应可能有错，这通常被称为幻觉。

我们可从如下五个方面逐步深入去理解 AI 大语言模型和 AI 应用：

1、AI 大语言模型的训练与推理。

2、AI 大语言模型的使用原理。

3、AI 应用：ChatGPT 聊天机器人。

4、AI 应用开发框架：如 LangChain。

5、RAG，Chain 与 Agent。

#### 1.1 AI 大语言模型的训练与推理

图：大模型包括训练与推理两个阶段

我们使用的 AI 大模型是预训练后的人工神经网络模型。如图所示，大模型的生命周期包括两大阶段：

第一阶段：预训练（pre-train）。通过海量文本数据对人工神经网络模型进行训练，直到获得理想的模型参数（权重）。通常，只有大型机构才有实力从头开始进行模型的预训练。

第二阶段：推理（inference）。在服务器上运行模型，针对用户的查询，模型给出回应。我们既可以通过 API （比如 OpenAI 的 API）访问别人运行的模型，也可以用开源模型的权重自行搭建推理服务。

#### 1.2 AI 大语言模型的使用原理

当我们作为用户使用 AI 大语言模型时，使用过程由两步组成：

第一步：我们向模型发起查询。通俗地说，我们向模型「提问」。

第二步：模型用文本补全或对话补全处理查询，然后给出回应。这是模型在「回答」。

现在的大语言模型通常有多种处理模式，其中常见的是这里提到的两种：

文本补全。你给出一段文本，模型按你的叙述补全后续的文本。

对话补全。你和 AI 进行对话。你提出问题或要求，AI 给出回答。

现在，越来越多的 AI 应用是基于对话补全开发的。

#### 1.3 AI 应用：ChatGPT 聊天机器人

普通人能直接使用的 AI 应用多是类似 ChatGPT 这样的聊天机器人，如图左图所示，右图则是 Poe 聊天机器人平台，支持多种模型。

聊天机器人用户界面加上它背后的应用逻辑，就构成了一个典型的 AI 应用，如下图所示包括三个部分：「模型-业务逻辑-应用界面」。它做的是，用界面接受用户的请求，将之处理成向 AI 大模型的查询。在模型回应后，它再将回应在界面上呈现出来。

以 ChatGPT 、文心一言等聊天机器人为例。当我们向它提问时，它将我们的提问和系统提示语组合起来，提交给模型去生成回应，然后将回应作为机器人的回复呈现在对话界面中。我们与它继续对话下去时，它会处理我们的对话历史，将系统提示语、对话历史以及新提问组合起来给模型。

要组织一个 AI 应用的业务逻辑，开发者需要处理包括提示语、模型调用与返回、知识库查询及其他第三方工具如搜索、代码运行等多个环节。以 ChatGPT 的高级数据分析功能（原名为代码解析器）为例，它将用户的请求转变 Python 代码生成任务，模型生成代码后，它在建立一个系统环境去运行代码，最终将结果给到用户。也就是说，它调用了代码运行这个第三方工具。

#### 1.4 AI 应用开发框架：以 LangChain 为例

由以上讨论可以看到，一个 AI 应用要处理复杂的业务逻辑，因此，类似 LangChain 这样的「AI 应用开发框架」（也称编排 orchestration）就出现了，这些 AI 应用开发框架能协助开发者快速地构建包括 AI 模型调用在内的业务逻辑。

现在的 AI 应用开发框架主要有三类：

第一类是云服务平台（如微软 Azure、百度千帆）提供的从模型微调、模型推理在内的全方位服务。

第二类是 LangChain、LlamaIndex、PromptFlow 等开源库。

第三类是 AI 应用 SaaS 平台。Dify、Coze 等平台甚至能非程序员也可以通过网页界面快速搭建复杂的 AI 应用。

总的来说，这些 AI 应用开发框架对 AI 的应用逻辑进行封装，从而让开发者能够快速地开发应用。它们通常为应用开发者提供如下功能：

连接多种 AI 模型，

更方便地处理提示语，

使用知识库进行检索增强生成（RAG），

将应用、模型和其他工具（如搜索）连接起来，

及 AI 应用的效果评估等开发者急需的功能。

如上提到的三种常见 AI 应用开发框架，它们各自的特点是：

LangChain，主要用于应用的编排，同时提供 Python 和 Javascript 版本。

LlamaIndex，主要为引入资料库提供了多种便捷的索引与检索组件。

Dify.ai、Coze，提供简洁的界面，让非程序员也能处理提示语、知识库等功能。

在 2023 年底，OpenAI 为自己的模型推出了 Assistant 接口，这一接口现已经成为行业的事实标准。这实际上也是在提供一个易用的 AI 应用开发框架，让开发者可以方便地处理上传文档进行检索增强生成（RAG）、调用第三方工具（通过 Action 功能）。面向普通用户的 GPTs、GPT Store，则是为 Assitant 接口加上界面，让普通人也能方便地创建 AI 应用。

#### 1.5 RAG，Chain 与 Agent

如果关注 AI 应用，你听到频率最高的两个词可能是 RAG（检索增强生成）和 Agent（智能代理）。其实，最值得关注的反而是 LangChain 名字中的 Chain。

当我们向 AI 模型提问时，一种让是直接运用已经通过预训练纳入到模型中的知识，另一种是我们额外提供资料，要求模型按提供的资料来生成。所谓检索，指的是当用户提问时，用在外部知识库中进行检索，匹配出相应的资料后，交由 AI 模型去进行生成。这就是所谓的 RAG （检索增强生成）。

Agent（智能代理）所代表的设想是，将 AI 大模型看成是有智能的：我们给它一个任务和目标，它自行选择相应的工具、路径去达成目标。Agent 是当前的热门探索方向，主要的思路是用大语言模型来作为 Agent 的「大脑」。当然这些探索离实际应用仍较远。

如前所说，当前的主要 AI 应用实际更多是 Chain（调用链）或 Workflow（工作流）。比如，一个简单的 AI 应用实际上都是由一系列流程组成的工作流：

1、通过用户界面，用户发起提问请求；

2、AI 应用将用户提问和系统提示语结合，形成向模型的提问；

3、AI 应用接收模型的回应，将它转换成便于用户查阅的形式呈现在界面上。

在 LangChain 的语境中，Agent 则比上述智能代理要简单得多：它能够自行选择工具。在 LangChain 中，Agent 与 Chain 的区别是，Chain 是预先设定并编程固定下来的流程；而 Agent 中，我们调用 AI 大模型来决定选择何种工具。比如，一个简单的能够让 AI 模型按需选择工具与路径的 Agent 如下：

1、通过用户界面，用户发起提问；

2、AI 应用将用户提问和系统提示语结合，形成向模型的提问；

3、AI 模型来回答时，自行判断是否需要调用搜索工具：

3.1 需要，则 AI 应用调用搜索工具，用搜索结果作为上下文再次向模型提问；

3.2 不需要，AI 模型直接给出回应。

4、AI 应用接收到模型的回应，将它转换成便于用户查阅的形式呈现在界面上。

此外，在开发 AI 应用时，我们还可以针对特定任务去对 AI 大模型进行精调（fine-tune），即采用一组数据集去微调它的参数，让它能够比原模型更好地适应这一特定任务。在这一组教程中，我们将不涉及精调的话题。

到此，我们从五个方面完成一个简单的 AI 大语言模型和 AI 应用的介绍，相信你对 AI 大模型、AI 应用已经有了基础的认识。接下来，我们将开始介绍 LangChain 的基本原理，并讨论一个重要的问题：我们为什么需要 LangChain？

### 0201. LangChain 是什么？为什么需要它？

简言之，LangChain 是一个 AI 应用开发框架。它同时提供 Python 和 Javascript 版本的开源库，让开发者能够：

方便地连接多种 AI 大语言模型，

组织自己的提示语模板，

连接其他组件如加载文档或搜索、连接向量库，

最终编排形成自己的 AI 应用逻辑。

#### 2.1 LangChain 的整体架构

在 2023 年生成式 AI 的快速发展中，LangChain 也迅速扩张。在 2024 年初，它的整体架构如下图所示，其中深色部分是狭义的 LangChain 开源库。它现在包括三大部分：

[Introduction | 🦜️🔗 Langchain](https://python.langchain.com/docs/get_started/introduction)

LangChain 库，包括：LangChain-Core, LangChain-Community, LangChain。

LangServe 与 Template 模板。其社区现在提供一系列易复用的 AI 应用模板，这些知识之前主要用 Jupyter Notebook 形式的 Cookbook 形式提供。开发者可以用 LangServe 来运行一个 AI 应用业务逻辑的 API 服务，供前台界面调用。

LangSmith，其公司提供的商业服务，让开发者可以记录 AI 应用的运行情况，包括测试、评估、监控等。现在，它的角色相当于机器学习领域的另一个监测服务 Weights & Biases。

LangSmith 提供了运行 AI 应用需要的多种重要监测功能：

1、可视化查看每次 LLM 调用，比如提示语、回应及其他参数；

2、可视化查看包括模型调用在内的调用链（Chain）的具体调用情况；

3、管理 AI 应用的评测，包括数据集、运行记录及人工进行结果标注；

4、提示语模板的多版本管理及运行，它提供了便捷的测试运行网页界面（即 Playground）。

（图片获取于 2024.1，LangChain Docs）

早期，开发者使用 LangChain 的原因是，用它能够快速地构建 AI 应用原型，方便地连接多种模型，快速上线产品。在其 Javascript 版本推出后，这更成为一个重要的理由。比如，你要让自己的应用能够方便地支持多模型，比起自行完成适配，LangChain 是更好的选择。

现在，LangSmith 提供的服务开始成为很多开发者选择 LangChain 的重要理由之一。这是因为，AI 应用的开发从早期的多模型支持到了注重自身业务运行质量的阶段。通过它，我们可以观测自己创建的业务逻辑的实际运行情况。

#### 2.2 LangChain 库介绍：以 Python 版本为例

在 2023 年，LangChain 以小版本号快速迭代，几乎每天都有新更新版推出。在 2023 年底，它正式升级到 0.1.0 版，其中一个重要变化是确保内核的相对稳定，这是通过将 LangChain 库一拆为三达成的。它现在包括三个库：

langchain-core，这个核心库主要是定义和编排 AI 应用工作流的 LangChain Expression Language (LCEL)。

langchain-community，提供与 LLM、检索、向量库、工具等的集成组件。

langchain，包括 Chain、Agent、检索等 AI 应用工作流所需的组件。

另外，其还为少数主流的 LLM 服务商提供了独立的库，比如 langchain-openai。

LangChain 也把 AI 应用的业务逻辑称为应用的「认知架构」（cognitive architecture）。在本教程中，我们则通常称调用链或工作流。

以开发一个 AI 应用为例，LangChain 库提供了全流程的支持：

1、Model I/O 部分：连接某个或几个模型；

2、Model I/O 部分：按需组织自己的提示语 (prompt)；

3、Retrieval 部分：加载文档、进行文本嵌入、存入向量库；

4、Retrieval 部分：根据用户的提问，匹配文档片段，交由 AI 模型去处理；

5、Model I/O 部分：对模型的输出进行分析，形成 AI 应用的输出。

LangChain 提供的 LangChain Expression Language (LCEL) 让开发可以很方便地将多个组件连接成 AI 工作流。如下是一个简单的工作流：

```py
chain = prompt | chatmodel | outputparser
chain.invoke("What's your name?")
```

其中，通过如上表达式，我们方便地将三个组件 prompt chatmodel outparser 按顺序连接起来，这就形成了一个 AI 工作流。运行 invoke ()，我们可以运行这个工作流。

又比如，我们可以组织如下较为复杂的 AI 工作流，其中进行两次模型调用，示例中用的两个不同的模型。将任务拆解分步后，我们能更好地利用模型的能力，

```py
chain = (
        prompt | chatmodel | outputparser |
        second_prompt | model2 | finalparser
        )
chain.invoke("waht's AI?")
```

#### 2.3 为什么使用 LangChain？

为什么用 LangChain？为什么不用 LangChain？

无论是从开发项目的选型，还是开发者的个人偏好，都有很多不用 LangChain 的理由：

1、它逻辑复杂、代码复杂、过度封装。比如，你调用一个 Chain 时，它隐含了一系列缺省参数、预设的提示语模板。相比之下，直接调用如 OpenAI 的 API 接口要透明得多。

2、它代码变化过快、缺少文档。它在快速跟上 LLM 领域的发展，但一个附带的效应是，它的版本迭代过快，几乎每天都有新版本推出。缺少文档让我们经常需要直接去查看源码，以了解某个组件的工作原理、调用方法。

3、它规模庞大、模块化不足。将这样的大型库引入项目工程，可能带来不必要的复杂性。在出现问题时，难以快速定位，更难以调试。

另一方面，又有很多 AI 应用开发者选择 LangChain，理由也有很多：

1、LangChain 已被证明能够快速跟进模型与 API 的变化。比如，在 2023 年，OpenAI 推出 Chat Model、Function Calling、Assistant API 等现在已经成为行业事实标准的 API 接口，而 LangChain 均快速、高质量地提供了相应的功能。

2、LangChain 能够快速跟进 AI 研究领域、AI 模型领域、AI 开源领域的变化。当前，大量论文被发表出来，很多研究结论可以用于改进 AI 应用的效果。LangChain 社区能够有效地识别这些研究成果，并将之纳入框架之中。新模型、开源领域的新变化也是如此，均被快速纳入。

3、LangChain 在活跃的社区方面有着领先优势。身处这一社区，开发者可以借鉴和学习其他人的最佳实践。实际上，LangChain 的「大而全」的全面性让它的社区非常活跃。因此，要提升 LangChain 的可用性，出路不是改变它的大而全定位，而是加强其模块化，这也正是它正在做的。

4、LangChain 公司提供了 LangSmith（观测）、LangServe（API 服务）、LangGraph（Agent 框架）等，在 LangChain 库之外为 AI 应用开发者提供更多的支撑与服务。

### 0301. 小结

总而言之，当你关注 AI 应用开发时，LangChain 既是一个强大的 AI 应用快速搭建框架，又是一个高质量的的学习资源。AI 应用开发者持续跟踪它总能有所收获。

参考链接：

LangChain: https://www.langchain.com

LangChain Python docs: https://python.langchain.com

LangChain.js: https://js.langchain.com/

LangChain Github: https://github.com/langchain-ai/langchain

LangChain Cookbook: https://github.com/langchain-ai/langchain/blob/master/cookbook/README.md

附录：LangChain 于2024.2展示于其首页的产品架构