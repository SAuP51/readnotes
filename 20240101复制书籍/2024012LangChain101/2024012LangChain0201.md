方军.(2024).2024012LangChain101. 未出版 => 0201 快速启动：用 LangChain 调用 OpenAI

## 0201. 快速启动：用 LangChain 调用 OpenAI

开发者使用 LangChain 进行 AI 应用开发的第一步通常是，用它调用 OpenAI 的 GPT-3.5 或 GPT-4 等大语言模型。LangChain 的特点是，它集成了对多种模型的支持，但其中使用 OpenAI 的模型尤为简便，我们这里先以它为例来尝试使用 LangChain。

这一快速入门教程最后更新日期是 2024.2，采用的 LangChain 版本是 0.1.1。

这里会涉及到 LangChain 及大语言模型调用的一些概念，为便于你快速启动，我们不多做介绍，而把这些内容留到后续教程。

本教程由两个部分组成，一部分是本文，另一部分是配套的 Notebook（Google Colab）。

[langchain-quickstart.ipynb - Colab](https://colab.research.google.com/drive/1PUiPg0t8sdqZJomNOXs7a9CRLU2KmnkH)

### 01. LangChain 使用简介

#### 1.1 直接调用模型 SDK 与使用 LangChain

ChatGPT 聊天机器人背后调用是大语言模型 GPT-3.5 或 GPT-4。大语言模型的工作机制是：我们向它提交一个提问，它给出回应。

OpenAI 的大语言模型都提供了 API 供调用，其目前主要被采用的是聊天完成接口（Chat Completions API, link），具体参见 OpenAI 大语言模型的相关 API 文档 。

要编程调用大语言模型时，我们有两种方式（如图所示）：

1、直接使用 API 提供方如 OpenAI 的 SDK，在账户的鉴权后，向模型提交提问，获得回应。

2、为了更方便地编写应用，比如兼容多种模型、对调用逻辑进行复杂设计、接入附加知识库，采用 LangChain 框架来编排 AI 应用逻辑的。LangChain 背后实际也是调用相应的 SDK。

图：使用 LLM 模型的两种方式：（a）直接使用 SDK，（b）使用 LangChain（图中以 OpenAI SDK 为例）

#### 1.2 安装 LangChain 时，你安装的是什么？

先介绍一点必要的背景知识。在 LangChain 0.1.0 之后，它由三个包组成，分别是（以下版本号获取时间是：2024/01/18）：

LangChain：langchain 0.1.1

LangChain Core：langchain-core 0.1.12

LangChain Community：langchain-community 0.0.13

其中 LangChain Core 是框架中相对稳定的部分，近期被单独拆分出来。当你安装 LangChain 时，它包含了 LangChain Core，但不包含集成各种模型的 LangChain Community。

但是，当我们要在 LangChain 中使用 OpenAI 时，最方便的方式是安装一个专门的包：

LangChain-OpenAI：langchain-openai 0.0.2.post1

安装它时，OpenAI 的 SDK 会作为依赖项被安装：

OpenAI SDK：openai 1.8.0

之前，LangChain 对 OpenAI 的支持也放在 Community 中，但当前代码及注释已经明确提示，建议使用 langchain-openai。

如下是 LangChain 的架构图，其中包括了以上介绍的，同时也包括了其公司的商业产品服务如 LangServe、LangSmith。

图：LangChain 架构图，获取时间：2024.1, link

有了以上背景知识，我们可以使用 LangChain 来调用 OpenAI 的 AI 模型。

注意：OpenAI API Key

为了运行 OpenAI 及其他公司的模型，你需要准备相应的 API Key。你在对应的网站注册并设置账户付费信息。

#### 1.3 注册 OpenAI 开发平台账户

在使用 OpenAI 的 API 之前，我们需要获得 OpenAI API Key。你可以在 OpenAI 开发者平台注册，并按需充值。

OpenAI 开发者平台：https://platform.openai.com/

1. 注册账户

2. 设置付费信息

3. 创建与获取 OPENAI API Key

你将使用一个类似于如下格式的 OPENAI API Key： sk-11111111111111111111111。请注意，不要将它存在代码中，更不要上传到 github 代码库，泄露后别人也可以用你的账户。

接下来，让我们进入到初次使用 LangChain 调用 OpenAI 的大语言模型的实际过程。

代码笔记本 Notebook

为便于快速入手，以下 Python 代码为运行于 Google Colab 的 Notebook。

本文所附的 Notebook 地址：

https://colab.research.google.com/drive/1PUiPg0t8sdqZJomNOXs7a9CRLU2KmnkH

### 02. 实例：使用 LangChain 调用大模型

2.1 安装 LangChain-openai

如上所述，我们安装 langchain-openai，它会同时安装 OpenAI sdk：

bash

!pip install -U langchain-openai --quiet

1

我们可以用 pip show 查看版本号：

Name: langchain-openai

Version: 0.0.2.post1

Name: openai

Version: 1.8.0

1

2

3

4

5

小贴士

在安装 langchain 库时，有一个无关大雅的关于 llmx 的警告。你可以用先安装它，以避免这个警告。如下：

python

!pip install -U llmx --quiet

!pip install -U langchain-openai --quiet

1

2

2.2 设置 OpenAI API KEY

在这里简化起见，我们要求你在运行时手工输入 OpenAI API KEY，然后将之设为环境变量。

代码如下：

python

import getpass

import os

# 获取 OpenAI API Key

openai_api_key = getpass.getpass("Enter your OpenAI API Key: ")

# 将 API Key 保存为环境变量

os.environ["OPENAI_API_KEY"] = openai_api_key

1

2

3

4

5

6

7

8

OpenAI SDK 将会使用此环境变量。除了这种方式之外，你也可在创建模型实例时，直接提供 API KEY 作为参数。如果你使用 Google Colab，你也可以将 API KEY 存放在它的 Secret 中然后进行调用。

2.3 创建与调用聊天模型

调用 AI 模型获取回答的过程很直接。我们创建一个聊天模型实例，调用模型提问，如下：

python

from langchain_openai import ChatOpenAI

llm = ChatOpenAI（)  # 创建模型实例

llm.invoke（"what's generative ai?") # 调用模型提问

1

2

3

4

5

我们用英文提问：

what's generative ai? （什么是生成式 AI？）

返回的结果是，请注意这是一个 LangChain AIMessage，其中 content 是模型返回的内容：

AIMessage(content='Generative AI refers to a type of artificial intelligence system that is designed to generate new content, such as images, text, music, or videos, that is similar to or indistinguishable from content created by humans. These systems use machine learning techniques, particularly deep learning models like generative adversarial networks（GANs) or variational autoencoders（VAEs), to learn patterns from large datasets and generate new data samples. Generative AI has applications in various fields, including art, music, gaming, storytelling, and even scientific research.')

在采用上述代码调用模型时，我们使用的是缺省模型： model_name="gpt-3.5-turbo"。另外，温度（temperature）的缺省值是：temperature = 0.7。

如果仅需要这样简单的调用，我们可以直接使用 OpenAI SDK。而使用 LangChain 是因为，它提供了强大的 AI 应用业务逻辑的编排功能。其中最关键的是它的名字中 Chain 这个词所揭示的，我们可以将包括大模型调用在内的一组操作组成「链条」，即所谓「调用链」。

在如下示例中，我们将展示了 LangChain 如何让我们方便地创建 AI 应用业务逻辑：

2.4. 提示语模板

2.5. 输出处理

2.6. 两次调用模型

2.4 使用提示语模板

LangChain 对于聊天模型进行了封装，并提供了方便的提示语构建方法。在如下示例代码中：

采用 ChatPromptTemplate 构建一个聊天模型的提示语模板，分别包括了系统提示语与用户提示语，即 system 与 user。其中，input 是提示语模板的输入参数。

用 LangChain 的 LangChain Expression Language（LCEL) 组成一个调用链。

用 invoke（) 实际调用这个调用链。

python

from langchain_openai import ChatOpenAI

from langchain_core.prompts import ChatPromptTemplate

llm = ChatOpenAI()

prompt = ChatPromptTemplate.from_messages([

("system", "You are world class technical documentation writer."),

("user", "{input}")

])

chain = prompt | llm

chain.invoke({"input": "what's generative ai?"})

1

2

3

4

5

6

7

8

9

10

11

12

13

2.5 解析输出结果

我们还可以进一步优化以上调用链。比如，在上述两个例子中，调用链返回的是 AIMessage 类型，而我们希望获得是其中的文本信息。我们可以调整调用链，在最后增加 StrOutputParser，它可将输出解析为易读的文本格式。

聊天模型的输出通常是 Markdown 格式，为了在 Jupyter Notebook 中更好地显示，这里使用了 IPython.display 的 Markdown（) 将它显示出来。

示例代码如下：

python

from langchain_openai import ChatOpenAI

from langchain_core.prompts import ChatPromptTemplate

from langchain_core.output_parsers import StrOutputParser

from IPython.display import Markdown

llm = ChatOpenAI()

prompt = ChatPromptTemplate.from_messages([

("system", "You are world class technical documentation writer."),

("user", "{input}")

])

output_parser = StrOutputParser()

chain = prompt | llm | output_parser

output = chain.invoke({"input": "what's generative ai?"})

display(Markdown(output))


输出结果如下：

聊天模型返回的结果

Generative AI, short for Generative Artificial Intelligence, refers to a subset of artificial intelligence that focuses on generating new and original content, such as images, text, music, and even videos. Unlike traditional AI systems that are designed to recognize patterns or make predictions based on existing data, generative AI systems are capable of creating new content that did not previously exist.

Generative AI uses deep learning techniques, specifically generative models, to analyze and learn patterns from a large dataset. These models then generate new content by extrapolating from the learned patterns. One popular type of generative model is the Generative Adversarial Network（GAN), which consists of two neural networks: a generator network that creates new content, and a discriminator network that evaluates and provides feedback on the generated content.

Generative AI has been used in various fields, including art, design, music, and even storytelling. For example, it can create realistic images, compose original pieces of music, or generate natural language text. However, it's important to note that while generative AI can produce impressive results, it still requires human supervision and guidance to ensure the quality and ethical considerations of the generated content.

2.6 多次调用模型

使用 LangChain 的一个基本技巧是，我们可以多次调用模型，分步来进行操作，从而利用模型的能力得到更符合期待的结果。

在如上示例中，我们采用英文向模型提问，得到英文的回答。在这个示例中，我们再进行第二次模型调用，要求模型将之前的回复翻译为简体中文。

这一调用链的具体步骤如下：

创建聊天模型示例。这里采用 gpt-4-1106-preview 模型。

创建第一次模型调用的提示语模板。其中系统提示语是「You are world class technical documentation writer.」（你是一个世界级的技术文档编写者。）

创建第二次模型调用的提示语模板。其中系统提示语是「Translate to simplified Chinese.」（翻译为简体中文。）

建立调用链。其中用 RunnablePassthrough（) 将第一次模型的输出作为第二次的输入。

用 StrOutputParser（) 对输出进行解析。

用 Markdown 形式将结果在 Notebook 中显示出来。

其中调用链是：

python

chain = prompt | llm | output_parser \

| {"input": RunnablePassthrough()} \

| translate_prompt | llm | output_parser

1

2

3

完整代码及调用结果如下：

python

from langchain_openai import ChatOpenAI

from langchain_core.prompts import ChatPromptTemplate

from langchain_core.output_parsers import StrOutputParser

from langchain_core.runnables import RunnablePassthrough

from IPython.display import Markdown

llm = ChatOpenAI(

model_name="gpt-4-1106-preview"

)

prompt = ChatPromptTemplate.from_messages([

("system", "You are world class technical documentation writer."),

("user", "{input}")

])

translate_prompt = ChatPromptTemplate.from_messages([

("system", "Translate to simplified Chinese."),

("user", "{input}")

])

output_parser = StrOutputParser()

chain = prompt | llm | output_parser \

| {"input": RunnablePassthrough()} \

| translate_prompt | llm | output_parser

output = chain.invoke({"input": "what's generative ai?"})

display(Markdown(output))

聊天模型返回的结果如下：

生成式 AI 指的是人工智能技术中的一个子集，它能够生成新的内容，如文本、图像、音频和视频，这些内容与人类创造的内容相似。这些系统通常从大量现有示例数据中学习，然后生成新的、以前未见过的输出，这些输出往往与人类创造的内容无法区分。

术语「生成式」表明 AI 能够生产某些东西，而不仅仅是分析或分类数据。生成式 AI 包括各种模型和技术，包括：

生成对抗网络（GANs）：它们包括两个神经网络，生成器和鉴别器，这两个网络同时进行训练。生成器创造新的数据实例，而鉴别器将其与真实数据进行评估。这两个网络基本上相互竞争，随着时间的推移，提高了生成输出的质量。

变分自编码器（VAEs）：VAEs 是另一种神经网络，它学习将数据编码成压缩表示，然后再解码回原始形式。它们特别擅长生成与其训练数据相似的新数据。

变压器模型：像 GPT（生成预训练变压器）和 BERT（双向编码器表示变压器）这样的大型变压器模型旨在理解和预测人类语言，并能够生成高度连贯且与上下文相关的文本。

神经风格迁移：这种技术使用深度神经网络将一个图像的艺术风格应用到另一个图像的内容上，有效地创建新的、风格改变的图像。

生成式 AI 有许多应用，包括：

创建逼真的图像和艺术作品

作曲和生成音效

写故事、诗歌，并为游戏或聊天机器人生成基于文本的内容

增强和恢复旧照片或视频

为 3D 打印设计新的物体或结构

通过生成分子结构来进行药物发现

生成式 AI 技术的快速发展带来了重要的伦理考虑，特别是关于在制作深度伪造、传播错误信息或侵犯知识产权方面的潜在滥用。因此，围绕生成式 AI 的使用和部署需要制定规章和保障措施，这一讨论仍在进行中。

### 03. 小结

通过如上示例我们可以看到，LangChain 让创建 AI 应用的业务逻辑变得更为便利。

参考文档：

LangChain Quickstart: https://python.langchain.com/docs/get_started/quickstart

LangChain OpenAI Integration: https://python.langchain.com/docs/integrations/platforms/openai

OpenAI API Docs: https://platform.openai.com/docs/guides/text-generation

Last updated: 2024/2/17 10:01
