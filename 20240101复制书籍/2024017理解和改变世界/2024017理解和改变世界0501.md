约瑟夫·希发基思.(2023.2022).2024017理解和改变世界.(唐杰译).中信出版社 => 0501. 人类智能与人工智能

## 0501. 人类智能与人工智能

人类智能和人工智能的关系是一个非常热门的话题。特别由于近些年，人们在机器学习研究以及智能服务和系统开发中取得了惊人的成就，让这个话题越发充满争议。

### 5.1 人类智能的特征

#### 思维的快与慢

众所周知，我们的思维包含两种思维方式。[1]

第一种是较慢却有意识加工的思维，这是程序性的并且需要运用推理规则。我们使用慢速思维去有意识地解决问题，例如分析问题、做计划或制造东西。第二种则是快速却自动（无意识）完成的思维。快速思维是自动完成的，却可以让我们解决复杂度极高的问题，例如说话、走路、弹钢琴等。当我们走路时，我们的「高速计算机」所解决的问题如果用算法进行实时处理将变得极其复杂。试想如果有一位钢琴家在演奏一首钢琴曲时，他要先想清楚自己在某一时刻应该做什么动作，以及使出多大的力，那显然会失去节奏感。

自动思维是人类智能中最重要的部分。如果我们对快速思维和慢速思维两个系统处理信息的能力进行比较，会发现前者处理的信息要远多于后者。当然，这种比较是从量上来说的，并没有考虑信息的重要性权重。

两种思维方式之间有着显著的协作和互补。人出生后，有意识的、慢速的思维系统逐渐创造出一些流程，随后由快速系统进行自动化执行。例如当婴儿有意识地不断重复说出「妈妈」时，大脑的快速思维系统会逐渐学习，直到它掌握了这个词语，再之后说「妈妈」这个词的时候便能够自动完成了，而不需要再去想发声器官如何配合。当我们学习如何骑自行车时也会发生同样的情况。首先，我们有意识地去尝试在两个轮子上保持平衡，这是一个「试错」的过程。最终，我们的「快速计算机」学会了如何自动平衡，而不需要我们了解力学定律。

这两种思维模式也对应两种不同的计算模式。慢速思维，是基于我们理解事物的心智模式，这种模式与我们对计算机进行编程的计算模式类似。而快速思维是有意识学习的结果，通过反复地训练，内化成一种自动的模式，这与人工神经网络的计算模型一样。如果我们想制造一个双足机器人或一个能骑自行车的机器人，我们可以采取两种不同的方法：一种是考虑好所有可能的物理情况，然后将机器人的动作编写为相应的程序；另一种则是对人工神经网络进行反复训练，让它在同样的物理条件下做出相似的动作。在第一种情况中，我们必须借助力学理论，编写能实时控制的程序。而在第二种情况中，我们并不知道关于力学的任何知识，但我们可以训练人工神经网络来学习如何平衡。

数学和逻辑是慢速思维的产物，它们在一定程度上也能反映这种思维的工作原理。事实上，计算机执行的算法和程序只是把这种思维方式形式化表示了出来。

顺便说一下，我们通常所说的「因果关系」，并不一定是物理现象的属性。它反映了我们理解现象的一种方式，因为慢速思维是一个连续的思考序列，于是推理规则就将这种前后相继发生的关系视作因果关系。如上文所说，计算过程只是慢速思维的形式化表示，因此计算过程的操作也就具备了因果关系的属性，当一个操作完成时，其结果会触发后续的操作。但在数学中，我们可以定义一些具有动态相关性的关系，简单来说，就是操作 A 的结果会影响别的操作（B、C……），反过来，其他操作的结果也会在一定程度上影响操作 A，它们之间处于相互影响的状态。这些关系显然不是因果关系，因此也不能作为单个的计算过程（一个操作的结果触发另一个操作）来执行。

话说回来，传统的计算机模拟的是慢速思维，而不是快速思维。事实上，最适合模拟快速思维的是那种直接依赖物理过程的自然计算机，例如量子计算机、蛋白质计算机，特别是人工神经网络。它们与快速思维一样，对信息的处理本质上是并行的，而且执行的大都是那种逻辑分析不可能完成的计算。不幸的是，快速思维是无意识的，人工神经网络的推理也是黑箱的，理解和分析其基本规律与机制将会徒劳无功。于是一个有趣的问题出现了：自然计算机可以有效地计算哪些函数呢？是否有可能出现一种新的计算理论，可以有效地利用物理系统（如虚拟机、人工神经网络、量子计算机）的计算能力？

#### 常识智能

我一直说，传统计算机所拥有的任何「智能」都只是程序员的智能，它们只是在执行程序员用符号描述好的命令而已。

当然，随着人工神经网络的出现，情况发生了变化。人工神经网络采用完全不同的计算模式，这种模式不是靠编程，而是从庞大的数据集中进行学习。通过特定的学习，我们有许多专门解决某一类问题的「智能系统」；它们可以下国际象棋，对图像进行分类，参与电视节目等等，但是一个下象棋很厉害的系统却不能驾驶一辆汽车。

让计算机接近人类智能的第一步，是让它表现得像我们所说的强人工智能。换句话说，它们能把特定问题的解决方案与相应的技能结合起来，像人类一样对环境的刺激做出反应。

人类智能的特征是能够把对感官信息的感知/解释、信息的逻辑处理，以及可能导致行动的决策结合起来。这种能力与下棋时生成策略的能力不同。在游戏中，规则是预先确定的，而且不会改变。但与此不同的是，现实中的规则和目标会根据环境的动态变化而变化，而人类是能够适应这种变化的。

正如我将在下文中解释的那样，我们可以把意识理解为大脑在外部世界和内部世界的语义模型中「看到」自己如何行动的能力。这个模型在我们的婴儿时期就自动构建起来了。然后我们通过学习有意识地去丰富它。它是一个动态系统，它的状态一方面反映了我们对外部环境的感知，另一方面反映了我们对内部状态的意识。如果没有这样的语义模型，我们就不可能理解语言，更谈不上相互交流了。同时，在把每个人各自发展起来的语义模型联系在一起方面，语言的使用也起着重要作用。

人类的大部分智力都属于我们所说的常识。我们的大脑会使用它的语义模型来评估环境中正在发生的事情以及可能的后果。这个语义模型不断积累经验，几乎每天都在自我丰富。因此，像「父子」就可以因其他一系列常识性关系而变得丰富，例如「年龄」「地位」「支持」等，这些关系很难一一列举，也很难被形式化。

为了让计算机表现出人类的这种行为，我们必须赋予它相应的语义模型。理论上，如果我们能够对自然语言进行分析和形式化，按照层级构建出概念之间关系的语义网络，再加上表征和更新知识的规则，我们就可以构建出这样一个模型。例如，在定义「父子」时，我们需要想象出这个词所包含的所有相关关系和规则，并把它们都形式化。不幸的是，尽管进行了 50 多年的研究，我们在这个方向上却几乎没有取得任何进展。

举个例子，人类几乎立刻就可以把图 5-1 中显示的一系列图像解释为一次飞机事故。因为人在理解的过程中会使用语义模型的常识知识，将感知到的一系列图像的上下文联系起来。相比之下，计算机可以分析每张图像中感知到的信息，可以识别甚至可以把单个图像中出现的对象联系起来，但它无法分析和理解图像之间的动态关系，因为它缺乏得出相同结论的知识。

图 5-1 人类天生具有常识推理能力

#### 认知复杂性：理解的边界

理解意味着能够将观察所得到的东西与头脑中已掌握的关系联系起来。我们之所以能够认识到力与加速度之间的比例关系或有机体随时间的指数增长，是因为我们已经在学校学过或通过经验掌握了相关的概念及其性质。

由于任何一个现象都是由大量因素共同影响产生的，当我们研究一个现象时，我们需要假设某些因素是主要的，而其他因素则是次要的（因而可以忽略），从而将问题进行简化。这种简化并没有一个固定的规则。例如，在许多情况下，不考虑摩擦可以使问题得到简化；但在有些情况下（如骑自行车），摩擦对现象的运动是至关重要的，不能忽视。

但有些现象（如气象、经济、社会等方面的现象）过于复杂，起关键影响的因素数量相当大，因此也就无法利用上面的方式进行简化。我们无法从理论上研究这些现象，不是因为我们不能理解这些现象的因果关系，而是因为发掘这些观察到的现象之间的关系涉及人类思维无法把握的内在复杂性。

众所周知，人类的思维受到认知复杂度（我们将其定义为掌握某种关系所需的时间）的限制。实验证明，我们的大脑能够关联的参数数量的上限大约是五个（一个关系与四个参数）。人类无法同时建立起大量操作单位之间的关系，这对我们理解世界是一个非常大的限制，这导致我们人类的思维并不具备理解复杂现象的能力，也限制了我们所能构建的理论与制造的工件的复杂性。现有的科学理论所涉及的独立变量和概念都比较少。以我个人的经验来看，复杂的理论很难掌握，也很难使用，如何检验它们的有效性往往也是一个难题。我们人类的运气非常好，物理学的基本规律是简单的，所以牛顿和爱因斯坦才有可能得出正确的规律。

现象是复杂的，而人类思维对复杂现象的认知具有局限性。在过去的科学中，人类通过简化构建了一种研究复杂现象的方式，但这种方式并不能解决所有的复杂现象的问题。正是在这些问题上，我相信人与计算机之间协作，可以在一定程度上帮助我们克服认知局限，建立起一种新的研究复杂现象的方式。我会在讨论机器生成知识的有效性后解释这些。

### 5.2 弱人工智能

活着的有机体和人类，可以被看作是与计算机具有某些相似之处的计算机器：它们都使用内存和语言。特别是硬件/软件与大脑/心灵的对应关系，值得我们关注。

但是，它们之间也有一些重要的区别。人类思维的计算具有「弹性」—— 它具有天生的适应机制，正是这种适应机制使得语言和概念的产生成为可能。

而计算机在计算速度和准确性方面却远远超过人类思维。因此在大量解决方案的检索问题或者大量数据的组合问题上，计算机往往能够超越人类。例如在国际象棋上，IBM（国际商业机器公司）的「深蓝」打败了人类顶级选手；在知识竞赛上，IBM 的「沃森」打败了人类的专家；甚至在复杂度高到天文数字的围棋上，谷歌公司的「阿尔法围棋」也打败了国际围棋大师。在这类问题中，人类被击败的事实使一些人开始相信计算机比人类「更聪明」。

我们有必要简单地介绍一下人工智能的演变。人工智能诞生于 20 世纪 50 年代中期，当时是信息学的一个分支，目的是「研究和设计智能的系统」。从 60 年代中期开始，人工智能的支持者开始鼓吹人类可以制造出与自己智能相媲美的机器，他们强调「在 20 年内，机器将能做到人可以做的任何工作」「在一代人之内…… 创造‘人工智能'的问题将得到实质性解决」。2 当然，由于种种原因，这些预言并没有实现。原因之一是人们对计算理论的局限性缺乏了解。而另一个更深刻的原因是，要想建造一台行为像人类的机器，我们必须先理解和分析人类智能的工作机制，而当时神经科学并没有强大到那种程度。

后来，人工智能研究的重点和范围在不断变化，研究的热度和资金也随之改变。这段时间有两段被称为「人工智能寒冬」的时期，分别是 20 世纪 70 年代初期和 80 年代后期。

但是，进入 21 世纪后，人们对人工智能的热情又重新被点燃起来，这主要归功于机器学习和数据分析方面取得的成就。随之而来的是人们对人工智能的重要性和影响，尤其是对自主系统和服务的发展前景，产生了一种「狂热的乐观情绪」。

许多人仍然认为，智能就是形成决策来解决复杂却定义明确的问题。他们相信，采用机器学习的方法，足以解决这类问题。

但我不认同这种观点。人类智能的特征是自主行为以及对内、外部环境变化的适应。这是人类大脑能够创造新知识，理解从未遇到过的情况，以及设定新目标的关键所在。目前机器学习并不能做到一点。只有当某一天，计算机系统能够自主执行大量任务，并且能够适应不断变化的环境时，我们才可以说人工智能和人类智能之间的差距正在消失。

#### 图灵测试

为了判断一台计算机 A 是否和人类 B 一样聪明，艾伦·图灵提出了一个测试方法。测试过程包括：询问者 C 向 A 和 B 分别提出问题，然后 A 和 B 分别为每个问题提供相应的答案（见图 5-2），然后由询问者 C 比较 A 和 B 的答案。如果询问者 C 无法分辨出哪个是计算机，哪个是人类，那么可以得出结论，计算机和人同样聪明。

Q: 下了吗：是的，下了

Q2: 你饿了吗？A2: 恐的我

IA 我是程序度

图 5-2 图灵测试和中文房间

哲学家约翰·罗杰斯·塞尔对图灵测试的相关性提出了质疑。他提出了一个「中文房间」的思想实验，实验的布置如图 5-2 右图所示：A 向一个封闭的房间发送一个中文问题，在房间里的 B（可能是人，也可能是计算机）并不懂中文，但却可以访问一个巨大的数据库，这个数据库包含所有可以用中文表达的问题以及它们相应的中文答案。这在理论上是可行的，因为中文的问题是有限的。当 B 收到一个问题时，B 将搜索数据库，找到相应的答案并将答案提供给 C。这个过程可以通过按字母顺序排列查找的方法来实现自动化。从外部来看，我们会误以为 B 真的可以理解中文，但实际却并非如此。通过这个思想实验，我们可以得出结论，即计算机可以通过操纵字符串做到即使并不理解问题含义，也能给出似乎理解了的答案。因此，图灵测试以及所有其他比较行为的测试在相关性上都不够准确。

关于图灵测试的另一个争论是，有一些特定的问题可能反而是人类无法回答的。例如，如果询问者问「π 小数点后面的第 100 位数字是多少」，计算机可以立即给出回答，而人类如果只靠智力是无法回答的。因此，在面对这类问题时，计算机远胜于人类。

请注意，我们是通过观察和研究行为来理解世界的。因此，在方法论上唯一适用的标准就是比较行为，但我们看到这种方式不能达到我们的目的。

然而，如果我们使用本体论标准，那么做出区分是可行的。即使不确切知道人类思维是什么，我们也可以肯定地说计算机不是思维，因为思维可以构建计算机，而在目前情况下，计算机却无法构最后我想强调，智力的标准不能被简化为问答游戏；它应该是建思维。

关于构建能够取代人类、在复杂环境中执行任务的系统。这是一个比图灵测试更有雄心的目标。关于方法论的问题我们将在本章第三节中（涉及自主系统）进一步讨论。

#### 机器学习与科学知识

机器学习和数据分析领域的最新进展表明，机器正确地生成知识并做出预测是可能的。这些技术可以识别数据中的复杂关系，而这些关系可以显示出因果关系并进一步做出预测。

但这种方式得出的结论具有概率性，我们能说某个关系以多大概率是正确的，但却很难确定它是否正确。3 于是我们要问，人工神经网络生成的知识，其有效性有多大？我们在多大程度上能够信任它？回答这两个问题，我们需要比较一下科学知识的发展方式和机器学习产生知识的方式，看一看它们之间的关键差异。

我之前说过，科学方法能够促进知识的发展，从而让我们可以解释观察到的世界。科学发现是观察者经过学习的结果，他创建一个可以解释和预测现象的模型，进而形成一个理论。

而人工神经网络生成知识的方式则是对大规模数据进行长期「学习」。通过学习代表因果关系的数据，神经网络可以用一种外推方法来估计某个原因最可能导致的结果。成功率取决于网络的「训练」程度，但我们不能确定这种「学习」到的反馈是否正确。此外，我们无法利用模型来准确地理解人工神经网络是如何工作的，这使我们无法估计错误响应的可能性。

图 5-3 显示了研究物理现象的科学方法（质量 m 的物体通过力 F 产生加速度 a）与人工神经网络学习认知的过程（如何识别猫或狗的图像）之间的差异。在这两种情况下，它们都有一个共同的目标：得出描述因果关系的输入－输出函数。在第一种情况下，它是给定力 F 与产生的加速度 a 之间的关系；而在后一种情况下，它是输入图像所描绘的内容，与「猫」或「狗」的判断之间的关系。在这两种情况下，一开始都有一个学习的阶段。

1. 实验

2. 学习

3. 解释

F1，F2，－Fn

al，a2，...an

F=ma

（模型）

m

F

（质量）

a

（力）

（加速度）

伽利略

隐藏层

隐藏层

图像

输出层

il，i2，in

rl，r2，＂＂m 输入层

？

（猫，狗）

输出

［73］ ［N，3］

（NA（43）

非解释性

图像

人工神经网络

图 5-3 科学知识和机器学习知识产生的过程

在物理实验中，实验者（比如伽利略）通过把原因和结果联系起来而学习。他利用自己的抽象能力和创造力，假设因果之间存在一种比例关系。经过实验的验证，这个假设最终成了一条「定律」。我们可以将这条「定律」描述成数学模型，然后借助数学知识来检验它的有效性（见第 2 章「知识的类型及其有效性」小节）并了解其在极端情况下的表现。

类似地，机器学习一开始也需要有一个实验的过程，在这个实验过程中由实验者对图像进行标记。然后通过调整其参数来「训练」人工神经网络，使它能对其中的每个图像 i 做出正确的响应 rm。与科学方法的不同之处在于，我们无法通过数学模型来描述人工神经网络的输入输出行为。例如在图 5-2 的例子中，如果要构建数学模型，我们就需要对猫和狗的概念进行形式化，但这几乎是不可能的。但是请注意，如果人工神经网络的输入和输出是物理量，对其做形式化就没有理论限制了。我们可以通过了解人工神经网络各部分的结构和行为，从理论上计算出表征输入和输出关系的数学函数。

在数学模型无法起作用的情况下，人工神经网络就显得特别有用。例如在图 5-2 下图的例子中，数学便没有了用武之地，因为我们不知道如何从理论上去定义图像的含义，这和把自然语言进行形式化一样困难。

#### 一种新的知识：不需要理解就能预测

人类思维的本性限制了我们探索知识的能力，计算机能否帮助我们克服这种限制呢？答案显然是肯定的。我们可以利用计算机来克服认知复杂性的障碍，发展并验证能够解释复杂现象的新理论。于是，我们有了一个生成新型科学知识的流程，其中的规律不是由人类思维设计的、明确表述的数学关系，而是使用计算机发现的、可能很复杂的关系。对这种关系的分析可能具有预测性，但由于不能通过明确的数学模型来描述，因此肯定会限制我们对现象更深入的理解。

因此在计算机的辅助下，我们有了一种新型的知识，它让我们无须借助数学分析进行理解，便可以做出预测。

人工智能和超级计算机的使用正在为人类知识的发展铺设一条新路。这是多年前我与一位地震学家朋友讨论时提出的论点。他告诉我，也许在不久的将来，谷歌在预测地震方面会比专家做得更好。我不知道这是否会成为现实。但我认为分析大数据的新技术，即使不了解复杂现象的本质，也可以提高预测这些现象的成功率。以地震为例，如果我们将某个地点的地震活动与全球的地震活动联系起来，也许我们可以在没有或几乎没有理论的情况下就做出正确的预测。

当然，我们必须权衡使用这些知识产生的影响。「云服务」正在成为人们面临复杂问题时的救命稻草。这究竟是好是坏？通过人工智能技术生成和使用知识，无须理解问题即做出预测，尤其是用它们来做关键决策…… 对此，我们是否应该谨慎对待呢？

### 5.3 超越弱人工智能：自治

#### 自主系统

传统计算机与人类的区别在于，传统计算机会自动执行某些预定的功能，是一个自动化系统；而人类则具有自主行动的能力，也就是说，人可以对环境的变化做出反应，也可以在内部目标的驱动下主动采取行动。

而今天，人工智能的应用使我们向前迈出了重要的一步，即从自动化系统发展为自主系统。对于自主系统，我们期待它能够在复杂任务中取代人类，人们的目标是希望达到在没有人工干预的情况下，把人工智能与自动化的流程结合起来，从而实现更高的效率。在这个系统中，人的作用是设定和调整目标，而目标的实现则完全交给自主系统来完成。例如，在自动驾驶中，我们只需要输入目的地，自动驾驶系统就能帮我们把车开到相应的位置；在智能工厂或智能农场中，我们只需要输入生产指标，整个系统就能帮我们管理工厂/农场，从而完成生产指标。

在这一点上，我必须解释一下自动化系统和自主系统之间的区别。为此，我将按照设计难易的顺序来介绍五种不同的系统：恒温器、自动列车、下棋机器人、足球机器人和自动驾驶汽车（见图 5-4）。

OUTOooR 35.3

NOOOR 35.2

恒温器

自动列车

下棋机器人

9

足球机器人

自动驾驶汽车

图 5-4 自动化系统和自主系统

首先，这些系统的共同点是它们都使用计算机来控制所处的环境，从而使它们的行为达到特定的目标。计算机通过传感器接收环境状态的信息并计算命令，然后将这些命令发送给执行器，执行器执行适当的操作以实现目标。

恒温器控制加热器的运行，将房间的温度保持在最大值和最小值之间。当传感器测量到环境温度达到最小值时，它会命令加热器开始工作；当环境温度达到最大值时，它就让加热器停止工作。自动列车具有更复杂的控制系统。它能够使得列车在抵达不同站点的时候，按相应的加速度来控制列车停在预定的位置。这个系统要考虑列车沿途的传感器信号，这些信号能够确定列车的位置。设计这样一个系统，在原理上没有任何困难，需要特别考虑的只是如何加速和减速，以确保乘客的安全和舒适。

下棋机器人面对的环境相对简单，其状态由棋子在棋盘上的位置决定。但是，它的控制系统极其复杂，和前两个系统相比，这个系统无法提前设计。因为棋盘上有大量的组合，而且要想赢得游戏，每个组合还需要多计算几步可能的着数，这将是一个天文数字。因此，棋子的移动不能预先设定好，而是需要在每一步中动态地去计算。对于每个状态，机器人会利用已有的知识来计算动作（移动棋子）策略，从而获得最佳结果。

足球机器人面临着更加复杂的环境，这个环境是由所有球员的位置和速度确定的，与前一个例子的主要区别在于环境是动态变化的。因此，足球机器人必须能够监测环境的变化，以便实时做出反应。这意味着它必须及时准确地分析来自其摄像机的图像，以便尽可能忠实地反映球场的状态。此外，机器人的目标也并非固定的，而是要根据其在球场上的角色和位置进行动态计算。例如，有时候其目标是防守，而有时候则需要进攻。对于每个特定的目标，其系统都需要在一定的时间内计算出相应的战术，并考虑对手可能的反应。

自动驾驶汽车无疑是最复杂的系统。首先，物理环境是动态变化的，这不再限于一个球场或棋盘，而是一个开放的环境。其次，车辆的数量和周围障碍物的位置也在发生变化，系统需要适时地检测到它们。再次，系统对环境信息的获得，并不像实验环境那样一成不变，而是取决于地理状况以及可用的基础设施（交通管制传感器和设备、通信网络）。最后，每辆车都有一个极其复杂的控制系统，它使用一个多目标管理的计算机来制定策略，其首要考虑的目标就是安全，其次是舒适。当它选定一组兼容的目标后，计算机会算出相应的策略。

上述比较显示了自动化系统和自主系统之间的显著差异。自主系统在某种程度上显示出与人类相似的智能。恒温器和自动列车只是简单的自动化系统，因为它们有固定的目标，在规定好的环境下执行设定好的任务。另外三个系统的特点是自主性，因为它们具有类似于生物体的能力，它们在生成和管理知识时具有双重目的性：一方面，它们要「理解」外部环境；另一方面，它们要灵活地管理多个目标，并确定相应的行动来实现这些目标。

实现自主系统和服务是物联网的核心目标。如果这个目标实现了，那么我们将更有信心说，计算机智能可以起到比在游戏中击败人类更重要的作用。

#### 自主系统的功能和组织的特征

根据上述比较，我提出一个自主系统的架构，它可以清楚地展示其中五个关键功能如何协同工作以实现自主性。类似的模型也可用于从理论上理解意识的基本心理功能是如何结合的（见第 6 章「意识的组成部分」小节）。

自主系统接受和处理来自内部环境和外部环境的信息并计算命令，执行器执行这些命令从而改变环境状态。例如，在图 5-5 中，系统是自动驾驶汽车的自动驾驶仪。此处的内部环境是指系统控制下车辆的方向和速度；外部环境，我们看到三辆车、一个行人和一处交通信号灯。系统处理有关内部和外部环境的信息，发出命令并执行操作。为了能及时实现自动驾驶的目标，这些操作必须在有限的时间内完成。

认清形势

概念

环境感知

感觉信息

对感觉信息的理解

知识库

感受器

·概念

障碍

·属性

方法

状态表示

构建/升级环境模型

内部环境外部环境

新知识

自我学习

状态

·知识涌现

形成决策

·目标涌现

目标管理（策略）

新目标

行动

自主媒介

策略规划（手段） 指令

触发器

图 5-5 自主系统的体系结构及其五个关键功能

一个自主系统包括五个关键功能，其中两个是用来理解环境状况的（环境感知和状态表示），两个用于决策（目标管理和策略规划），另外一个赋予了系统自我学习的能力。

自主系统还配备有知识库，其中存储了对识别和管理感知信息特别有用的知识。知识首先包括与环境中的物体及其属性有关的概念以及决策方法。在自动驾驶的例子中，系统需要「汽车」、「行人」和「灯光」等概念来「理解」外部环境。每一个概念的存储库可能包含有关这个概念的特征属性的信息，以便系统能更好地进行预测，例如，它需要知道某一款汽车的最大速度和加速度。

环境感知功能从环境中接收感知信息（图像或别的信号），然后根据存储库中的概念，对这些信息进行分类。在上面的例子中，来自外部环境的感知信息包含三辆汽车、一个行人和一处交通信号灯，以及它们的位置和运动状态的相应信息；关于内部环境，感知信息涉及车辆的运动状态，例如速度和加速度。感知功能通常由人工神经网络来完成，这是目前唯一适合此目标的技术。

感知到的信息被传递给状态表示函数，这种函数的功能是建立一个系统外部和内部环境的模型。该模型具有表示环境的状态变量，例如障碍物的动力学属性和车辆的状态。模型根据受控车辆或其周围障碍物可能发生的状态变化来产生动作。为了尽可能及时地反映环境的动态变化，模型必须实时更新。

决策模块调用环境模型。决策模块有两种功能：目标管理和策略规划。

所谓目标管理，即从一组预先确定的目标中选择与环境模型的当前状态相匹配的兼容目标子集。目标管理也决定了我们所说的策略规划。系统的目标分为积极目标和消极目标。消极目标是要避开糟糕的情况，例如避免碰撞等安全目标。积极目标是要尽量达到理想条件，例如优化乘客舒适度、减少燃料消耗，以及顺畅地从一个地点移动到另一个地点。我们还可以区分短期目标（如安全目标）中期目标（如操控车辆超车或驶过十字路口）和长期目标（如完成整个行程）。及时选择关键的目标对于自主系统来说至关重要，因为它非常复杂，要满足实时响应就需要有足够的计算时间。

策略规划功能可以对目标管理进行补充和完善。该功能决定了系统的策略。对于每组选定的目标，策略规划功能函数会计算出一系列命令给执行器，执行器执行相应的操作。就避免碰撞这个目标而言，策略规划功能必须充分考虑制动、加速度和方向盘角度等来控制车辆的速度和方向。对于汽车的每一类操作，系统都必须有适当的策略来控制。

最后，第五个关键功能是自我学习，对知识库里的知识进行管理和更新。知识的更新是通过创建新知识来完成的：（1）环境，例如，基于模型数据分析中积累的知识形成的新概念；（2）适应环境变化的新目标，或改变与目标选择相关的参数值。自我学习功能是人类自主的一个关键特征。一个从未在雪地上开过车的人，可以通过仔细测试各种策略并以风险最小化为目标来调整自己的行为。在现实中，系统的自我学习潜力仅限于参数优化，但不能创建全新的概念或目标。

请注意，系统的功能是有周期性的。循环从感知开始，然后更新环境模型的表示。接下来是决策，这时有可能会选择新的目标，或者继续执行上一个周期中未完成的策略。单个循环的持续时间必须足够短，才能实现一些短期目标（保证安全驾驶的反应时间通常在 1/10 秒数量级），而实现长期目标可能需要数百万个循环（到达目的地）。显然，在一个循环中选择新目标，必须与已经选择但尚未实现的目标相兼容。

上述架构将「自主」定义为：为了适应环境的变化，系统在没有人为干预的情况下实现一系列目标的能力。为了实现「自主」，需要将五个相互独立的功能 —— 环境感知、状态表示、目标管理、策略规划和自我学习 — 结合起来。

这种定义让我们能够对自动化系统和自主系统做出一个区分。恒温器是一个自动化系统，因为它不需要五个关键功能中的任何一个。尽管自动列车使用感知功能来分析图像，但它主要还是一个自动化系统。而另外几个系统尽管复杂程度不同，但都是自主系统。

对于下棋机器人来说，环境感知和状态表示功能相对简单，因为环境及其可能的变化是缓慢且明确的。决策也是基于明确定义的规则做出来的。困难在于预测对手的战术并计算出成功的战术。

对于足球机器人来说，由于感知到的信息是动态的，它的环境感知和状态表示功能就复杂得多。它的策略也要考虑与同一球队中其他机器人合作时的动态变化。根据机器人在赛场上的位置，它的目标有时可能是进攻性的，有时是防御性的。通过球员之间的合作所形成的战术也是动态的。为了达到功能协调的目的，知识的使用就显得很重要，这些知识包括游戏规则以及通过学习对方球员，特别是对方的整个球队的特点而动态获得的知识。

最后，自动驾驶汽车是最难实现的系统之一，因为其环境非常复杂，需要管理多个目标并需要适时地适应环境。

#### 我们应该信任自主系统吗

要实现物联网的愿景，开发可靠的自主系统至关重要。这既是一项科学挑战，也是一项技术挑战，同时还包含巨大的经济和政治竞争。这就是为什么所有主要的科技公司都在投资这个领域，尤其是自动驾驶汽车，因为有相当大的经济利益。参与这场竞争的公司包括谷歌及其子公司 Waymo、苹果、英特尔及其子公司 Mobileye、优步、阿里巴巴、华为、腾讯等，当然还包括所有主要的汽车制造商，其中特斯拉处于领先地位。

工业界采用的解决方案主要是依靠人工神经网络，因为传统计算机执行的算法技术无法有效地解决感知问题。

在这里我必须指出，在关键的自主系统中使用人工神经网络一直是个备受争议的问题，因为它可能存在严重的安全隐患。直到最近，关键系统的构建还必须基于科学知识和数学模型。当我们建造一座桥梁或设计一架飞机的自动驾驶系统时，使用数学模型可以让我们预测这些系统在各种场景中的表现，并且我们可以很有把握地说，使用它们是安全的，例如对于民航飞机，每小时飞行的非危险故障率通常低于 10°。需要强调的是，飞机的所有组件都是根据独立认证的机构制定的法规和标准开发的。同样，当顾客购买烤面包机或汽车轮胎时，权威机构已经根据理论和实验数据对产品进行了检验，并且可以保证，如果顾客使用的方法正确，那么就不会有生命危险。

而机器学习系统不是基于模型的，而是基于「积累的」经验知识。当然，我们可以通过实验来确定它们是否在正常工作。但即使大量的实验数据证明它的工作状态是完美的，我们也无法像用科学方法那样，信心十足地说它们将继续正常工作（见本章「机器学习与科学知识」小节）。独立组织使用的认证方法需要系统具备可解释性，但机器学习系统无法做到。

如今，为了避免停止使用神经网络的自主系统的发展，同时也为了保持国家在这一领域的领先，美国主管当局接受了制造商对产品进行「自我认证」后使用这些系统。这意味着是制造商 —— 而不是独立的权威机构 —— 来保证产品的安全，并在发生事故时承担全部责任。因此，如果汽车的自动驾驶系统出现故障，制造商必须赔偿所有损失并补偿受害者。

这一政策变化没有给制造商强加客观的安全标准，即允许每个制造商自由设定，这会带来严重的风险。人的生命简单地变成了一个方程的参数，而经济标准和技术标准在这些方程里反而显得更重要。在我看来，如果我们不能保证足够的安全性和可靠性，那么就应该限制自主系统的使用。

### 5.4 人工智能：威胁与挑战

我不想特意去讨论计算机和人工智能所带来的可能性。它们能为人类带来的好处可谓数不胜数，而且大家都耳熟能详了。媒体也经常讨论计算机和人工智能给我们的生活、工作和学习方式带来的根本变化。流程和服务的自动化为人们带来了效率的优势。在没有直接人工干预的情况下，我们便能以最佳方式对能源、电信和运输等部门的资源进行「实时」控制，从而实现规模经济和质量经济。

接下来，我想要深入讨论的是计算机和人工智能所带来的风险，这些风险有些是假想的，有些则是实际存在的。

#### 假想的风险

最近，关于计算机「超智能」的神话越来越多。根据其中一个版本，计算机智能最终将超过人类智能，我们最终可能会成为机器的宠物。

史蒂芬·霍金、比尔·盖茨和埃隆·马斯克等人都支持这类观点。有些人受到雷蒙德·库茨魏尔的影响，认为技术奇点即将到来，当机器的计算能力超过人脑的计算能力时，技术奇点就会出现。显然，这些观点缺乏严肃性，是站不住脚的。再强大的机器也不足以战胜人类的智慧。但他们的这些想法在媒体中找到了滋生的温床，被不加批判地广泛传播，在很大程度上引起了公众的共鸣。我认为科学界应该对这种蒙昧主义和信口开河的混杂产物做出反应，并基于科学和技术标准，对人工智能的前景给出清醒的评估。

不幸的是，人们喜欢相信惊心动魄的故事以及想象中的危险。舆论很容易被假想的威胁（如外星人入侵或根据玛雅历法推算的世界末日）影响。相比之下，人们对通过冷静和理性的分析所发现的真正风险却置若罔闻，对其做出反应时常常为时已晚（例如，经济危机本可预见并提前做出防范，但最终却因为无所作为而导致经济崩溃）。

对于以上假想的风险，我引用著名科幻作家艾萨克·阿西莫夫提出的三条基本道理准则，机器人必须遵守：（1）不伤害人类；（2）服从人类；（3）保护自己。当然，我们使用的计算系统并不是科幻小说中的「邪恶机器人」。但没有人想过这些系统是否会违反上述任何一条（或所有）准则，并造成严重后果。当然，我们不能像科幻小说中写的那样，将这些后果归咎于机器人的恶意。

#### 实际风险和挑战

人们都在热议计算机智能的假想风险，也许把真正的风险掩盖住了。而这些真正的风险才是问题所在，因为它们涉及社会组织的类型及其所服务的关系，特别是社会和政治性质的问题。

失业

很久以前人们就发现，自动化程度不断提高带来的一个风险是，机器人使用越普遍的行业失业率越高。因此，我们会看到农业和工业等部门，以及可以被自动化替代的服务部门的工作岗位数量在逐渐减少。而需要创造力的职业（如系统编程和设计），或者虽然不需要特殊资质但不易被系统化的职业（如邮件分发）仍然会有工作机会。除了引发高失业率之外，自动化的趋势还会进一步扩大需要技能和知识的高薪工作与其他体力劳动之间的差距。

当然，有些人认为，传统工作岗位的消失会被新需求所创造的岗位抵消。我认为，除非对职业结构进行彻底改革，否则失业和工资差距的问题将会恶化。我不会进一步讨论这个问题。

防护、安全和风险管理

当自动化集成程度超过某个水平时，信息系统如果缺乏安全保护可能是极其危险的。众所周知，即使对那些最重要的系统，人们也无法做到全面保护它们不遭受网络攻击，我们充其量只能希望及时发现入侵者。不幸的是，由于技术和其他原因，计算机系统在可预见的未来仍然极易受到攻击。这意味着我们不能排除灾难的发生，特别是国家之间出现紧张局势所引发的灾难。今天，网络战已经不再是由个人黑客发动，而是由组织良好的企业甚至国家发动。

一个相关的安全风险是，系统的解决方案往往相互依赖，这些解决方案一般是由越来越复杂的技术基础设施提供的，就像金字塔一样，以一种经验的方式堆叠起来。大家都知道，对于一些用旧的编程语言（如 Fortran）编写的复杂软件，我们是无法更改的。不幸的是，大型计算机系统并不像机电系统那样以模块化方式构建。想要在不破坏大型计算机系统功能的前提下分离出它们的某些组件，并用同等甚至更好的组件进行替换，不是一件容易的事。这种变动所面临的风险难以评估。

这种替换和改进的困难使我们不得不依赖某些初始的选择，这是一种束缚。例如，如果你要把交通规则从靠右行驶改为靠左行驶，那么所面临的成本和风险将是巨大的。目前的互联网协议在安全性和反应性方面都不具备我们所期望的特性，然而由于当初的选择，我们只能继续使用这些协议。

我已经在讨论中指出，在引入人工智能和自主系统的领域，其风险管理与在其他领域有显著的差异。在这些领域中，不再有独立的国家机构来保证和控制系统的质量及安全。这个责任转移给了制造商。其中的风险是显而易见的，因为用户的安全级别将不再由透明的技术标准决定，而是由制造成本和能够覆盖事故赔偿金的保险成本之间的最佳平衡值来决定。

不幸的是，目前被大量采用的信息和电信技术被看作是理所当然。没有人问我们应该开发什么样的技术，为什么要开发，或者如何以最合适的方式使用现有的技术，也没有关于这些技术对经济、社会和政治会产生什么影响的公开辩论。

各国政府和国际组织明显是缺席和不作为的。他们好像认为技术进步本身就是目的。他们很少关心互联网上发生的违法行为。他们认为风险不可避免，因此干脆对其放任自流，就好像进步一定会带来某些不可避免和无法控制的弊病一样。

大型科技公司的宣传口号也显得十分愚蠢，例如「科技向善」或「科技守护安全」。谷歌、推特和脸书都有响亮的口号，例如「不作恶」、「帮助提升公众交流的集体健康、开放和文明程度」，以及「赋予人们建立社区的权利，让世界更紧密地联系在一起」。当然，如果期望这些公司关心创新和技术革命所带来的社会问题，那就太天真了。

因此，公众舆论仍然处于混乱迷失状态，而且在一定程度上被那些既不负责也不客观的声音操纵了。一些人夸大了风险，而另一些人则为了推广技术应用而淡化风险。公众却乐于接受错误的思想，并随波逐流。

那些对经济和社会组织顺畅运作至关重要的流程和服务，其自动化程度越来越高，但与此同时也导致对网络控制的决策越来越集中化。这个问题本质上是政治问题：决策的民主控制才是合理、安全地使用基础设施和服务的关键。

#### 技术依赖

技术的应用解决了人们的许多实际问题并使生活变得更舒适，但这也意味着我们丧失了某些解决问题的技能。例如，今天很少有人知道如何使用摩擦生火，这是史前人类掌握的基本生存技能。今天的人们也不知道如何在野外生存或建造小屋来保护自己。直到 20 世纪（包括 20 世纪）乘法口诀表一直是儿童数学教育的基础，然而在未来，孩子们也许不再需要背诵它了。担心人们过度依赖技术并非杞人忧天。因为现在技术不仅是解决单个问题，而且为人们提供了全面的解决方案。这意味着我们正在过渡到一种新的生活方式 —— 技术提供大量的服务，减轻了我们管理决策的负担。在这种生活方式中，有越来越多的技能/知识不再是我们必须掌握的了。那么，哪些基本技能/知识是我们必须掌握的呢？

为了解释其中的风险，有些人引用了「温水煮青蛙」的寓言。如果我们突然提高水温，青蛙就会从锅里跳出来。然而，如果我们逐渐提高水温，青蛙最初会感觉很舒服，并会一直待在锅里直到死去。

目前，社交媒体的用户愿意提供他们的个人数据，以换取更高质量的服务。然而这却是控制舆论的重要基础。每个人的个人喜好和信息对他们来说当然没有商业价值。然而，对非常大的数据集进行深入分析得出的结果，不仅对资源和系统的可预测性与控制性来说至关重要，而且对于市场和群体行为的可预测性与控制性也非常关键。可能我们还不理解这些信息的重要性，因为这些信息仍然是秘密，只掌握在那些当权者和愿意为此付费的人手中。

我发现个人自由面临两种威胁。

第一种威胁是侵犯隐私权，它常常打着为了保护社会免受恐怖主义或犯罪行为侵害的旗号。有许多计划是通过开发特定的技术解决方案来增加对个人的监控。例如征信系统（为了利用个人信誉建立征信，它允许用户在在线社区中相互评分）。利用这样的系统，有人就可以通过武断的程序和标准来污蔑或排斥其他公民。毋庸置疑，对于这些侵犯隐私的工具的使用，有必要建立一个监管框架。第二种威胁来自自主系统和服务的广泛使用，而这往往会打着提高效率的旗号。普及自主系统和服务的愿景正在通过物联网得到推广。这个愿景的构想是在没有人为干预的情况下实现关键资源和基础设施管理的自动化。其中的决策标准可能非常复杂，以至于超出了人类理解和控制的范围。因此，我们可能会形成一个技术专制的系统，尤其是因为自动化使决策越来越集中。因此，真正的风险是计算机生成的知识被不受控制地用于决策，并在关键流程中取代人类。

正确、合理地使用人工智能和自主系统取决于以下两个因素。第一，根据客观标准评估我们是否可以信任计算机生成的知识。这是目前正在研究的课题 —— 希望这些研究能够给我们提供一个答案。我们正在尝试开发「可解释的」人工智能，让我们能够理解并在某种程度上控制系统的行为。此外，我们需要一种评估知识的新方法，来弥合科学知识与人工智能经验知识之间的差距。

第二，全社会的警惕性和政治责任感。当使用计算机生成的知识做出关键决策时，我们必须确保这些知识是安全的和中立的。自主系统的安全性必须得到独立机构的认证，而不是留给开发它们的人。在这方面，立法并建立监管框架，以及让机构参与风险管理可能会起到一定的作用。我们将在后面的章节（见第 6 章「安全与自由」小节）讨论这些问题。