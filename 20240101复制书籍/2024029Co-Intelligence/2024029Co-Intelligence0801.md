Ethan Mollick.(2024).2024029Co-Intelligence_Living-and-Working-with-AI.Penguin Publishing Group => 

8 AI AS A COACH

The biggest danger to our educational system posed by AI is not its destruction of homework, but rather its undermining of the hidden system of apprenticeship that comes after formal education. For most professional workers, leaving school for the workforce marks the beginning of their practical education, not the end. Education is followed by years of on-the-job training, which can range from organized training programs to a few years of late nights and angry bosses yelling at you about menial tasks. This system was not designed in a centralized way as parts of our educational system were, but it is critical to the way we actually learn to do real work.

People have traditionally gained expertise by starting at the bottom. The carpenter's apprentice, the intern at a magazine, the medical resident. These are usually pretty horrible jobs, but they serve a purpose. Only by learning from more experienced experts in a field, and trying and failing under their tutelage, do amateurs become experts. But that is likely to change rapidly with AI. As much as the intern or first-year lawyer doesn't like being yelled at for doing a bad job, their boss usually would rather just see the job done fast than deal with the emotions and errors of a real human being. So they will do it themselves with AI, which, if not yet the equivalent of a senior professional in many tasks, is often better than a new trainee. This could create a major training gap.

In fact, Professor Matthew Beane, who studies robotics at UC Santa Barbara, showed that this is already happening among surgeons. Medical robots have been in hospitals for over a decade, helping perform surgeries while doctors nearby operate them with video game–like controllers. While the data on surgical robots is mixed, they seem to be helpful in many cases. They also create a huge problem in training.

In regular surgical training, experienced doctors and trainee residents can work next to each other, with the doctor carefully helping the resident as they watch and try techniques. With robotic surgery, there is just one seat that controls the robot, usually filled by the senior surgeon, while trainees are reduced to watching, getting brief turns at the machine, or just using simulators. Under tremendous time pressure, residents had to choose between learning traditional surgery skills or figuring out how to use these new robots on their own time. While many doctors ended up undertrained, those who wanted to learn how to use robotic surgery equipment turned away from official channels. They did their own "shadow learning" by watching YouTube channels or training more on live patients than they probably should have.

This same sort of training crisis is going to spread as AI automates more and more basic tasks. Even as experts become the only people who can effectively check the work of ever more capable AIs, we are in danger of stopping the pipeline that creates experts. The way to be useful in the world of AI is to have high levels of expertise as a human. The good thing is that educators know something about how to make experts. Doing so, ironically, means returning to the basics—but adapted for a learning environment that has already been revolutionized by AI.

Building Expertise in the Age of AI

AI is good at finding facts, summarizing papers, writing, and coding tasks. And, trained on massive amounts of data and with access to the internet, Large Language Models seem to have accumulated and mastered a lot of collective human knowledge. This vast and tappable storehouse of knowledge is now at everyone's fingertips. So it might seem logical that teaching basic facts has become obsolete. Yet it turns out the exact opposite is true.

This is the paradox of knowledge acquisition in the age of AI: we may think we don't need to work to memorize and amass basic skills, or build up a storehouse of fundamental knowledge—after all, this is what the AI is good at. Foundational skills, always tedious to learn, seem to be obsolete. And they might be, if there was a shortcut to being an expert. But the path to expertise requires a grounding in facts.

Learning any skill and mastering any domain requires rote memorization, careful skills building, and purposeful practice, and the AI (and future generations of AI) will undoubtedly be better than a novice at many early skills. For example, researchers at Stanford found that the GPT-4 AI scored higher than first- and second-year medical students at their final clinical reasoning exams. The temptation, then, might be to outsource these basic skills to the AI. After all, doctors are happy to use medical apps and the internet to help diagnose patients instead of simply memorizing medical information. Isn't this the same thing?

The issue is that in order to learn to think critically, problem-solve, understand abstract concepts, reason through novel problems, and evaluate the AI's output, we need subject matter expertise. An expert educator, with knowledge of their students and classroom, and with pedagogical content knowledge, can evaluate an AI-written syllabus or an AI-generated quiz; a seasoned architect, with a comprehensive grasp of design principles and building codes, can evaluate the feasibility of an AI-proposed building plan; a skilled physician, with extensive knowledge of human anatomy and diseases, can scrutinize an AI-generated diagnosis or treatment plan. The closer we move to a world of Cyborgs and Centaurs in which the AI augments our work, the more we need to maintain and nurture human expertise. We need expert humans in the loop.

So let's consider what it takes to build expertise. First, it requires a basis of knowledge. Humans actually have many memory systems, and one of them, our working memory, is the brain's problem-solving center, our mental workspace. We use our working memory's stored data to search our long-term memory (a vast library of what we have learned and experienced) for relevant information. Working memory is also where learning begins. However, working memory is limited in both capacity and duration, with an average adult capacity of 3 to 5 "slots" and a retention duration of less than 30 seconds for each new chunk of information we are learning. Despite these limitations, working memory has strengths, such as the ability to recall or cue an unlimited number of facts and procedures from long-term memory for problem-solving. Therefore, while working memory has limitations when dealing with new information, these limitations disappear when dealing with previously learned information stored in long-term memory. In other words, to solve a new problem, we need connected information, and lots of it, to be stored in our long-term memory.And that means we need to learn many facts and understand how they are connected.

After that, we have to practice. It isn't just a certain amount of practice time that is important (10,000 hours is not a magical threshold, no matter what you have read), but rather, as psychologist Anders Ericsson discovered, the type of practice. Experts become experts through deliberate practice, which is much harder than merely repeating a task multiple times. Instead, deliberate practice requires serious engagement and a continual ratcheting up of difficulty. It also requires a coach, teacher, or mentor who can provide feedback and careful instruction, and push the learner outside their comfort zone.

Take, for instance, the world of classical piano. Imagine two students: Sophie and Naomi. Sophie spends her afternoons playing the same pieces she's comfortable with over and over again. She might do this for hours on end, believing that sheer repetition will improve her skills. She feels a sense of accomplishment as she gets better and better at this work. Naomi, on the other hand, conducts her practice sessions under the guidance of a seasoned piano instructor. She begins by playing scales and then moves on to progressively more challenging pieces. When she makes mistakes, her instructor points them out, not to chastise her but to help her understand and rectify them. Naomi also regularly sets goals for herself, like mastering a particularly tricky section of a piece or improving her speed and agility on certain passages. The process is much less fun than Sophie's experience, because Naomi's challenges escalate with her skill, making sure she is always facing some degree of difficulty. Yet over time, even if both students clock in the same number of practice hours, Naomi will likely surpass Sophie in skill, precision, and technique. This difference in approach and outcome illustrates the gap between mere repetition and deliberate practice. The latter, with its elements of challenge, feedback, and incremental progression, is the true path to mastery.

But this sort of practice is very hard. It requires a plan, as well as a coach who can continually provide feedback and mentorship. Good coaches are rare, and are skilled experts in their own right, making it hard to get the coaching required for success in deliberate practice. AI may be able to help directly address these issues, creating a better training system than we have today.

Let's step into the world of architecture. Envision two budding architects, Alex and Raj. Both have just graduated from top-tier architecture schools, brimming with fresh ideas and an eagerness to design. Alex begins his journey by drafting designs using traditional methods. He frequently reviews famous architectural blueprints and gets feedback from a senior architect in his firm once a week. He believes that by continuously sketching and refining his designs, he will gradually improve. While this process does help him learn, it's limited by the frequency of feedback and the depth of analysis that his mentor can provide in a short period.

Raj, conversely, integrates an AI-driven architectural design assistant into his workflow. Each time he creates a design, the AI provides instantaneous feedback. It can highlight structural inefficiencies, suggest improvements based on sustainable materials, and even predict potential costs. Moreover, the AI offers comparisons between Raj's designs and a vast database of other innovative architectural works, highlighting differences and suggesting areas of improvement. Instead of just iterating designs, Raj engages in a structured reflection after every project, thanks to the insights from the AI. It's akin to having a mentor watching over his shoulder at every step, nudging him toward excellence.

Over several months, the difference between Alex's and Raj's growth trajectories becomes evident. While Alex's designs do mature and evolve, the pace of his growth is significantly slower. His once-a-week feedback sessions, although valuable, don't provide the immediate, in-depth analysis that Raj benefits from after every single design iteration. Raj's approach, with the aid of AI, embodies the essence of deliberate practice. His consistent, rapid feedback loop, combined with targeted suggestions for improvement, ensures that he's not just practicing more; he's practicing better. In this context, the AI is more than just a tool for Raj; it serves as an ever-present mentor, ensuring that each attempt isn't just about producing another design, but about consciously understanding and refining his architectural approach.

Today's AI cannot achieve this entire vision. It is not able to connect complex concepts, and it still hallucinates too much. Yet, in our experiments at Wharton, we have found that today's AI still makes a pretty impressive coach in limited ways, offering timely encouragement, instruction, and other elements of deliberate practice. For example, we built a simulator using AI to teach people how to pitch their ideas. Users first receive an instruction session and a chance to ask the AI questions about what they learned (where the AI is prompted to provide advice on pitching the way I do in my classes). Next, they go into a practice session, where a different prompt has the AI simulate a venture capitalist, grilling them about their pitch and idea. The whole time, another instance of the same AI is gathering data about their performance, including secret "notes" kept by the previous AIs. At the end of the practice session, this AI grades them on their performance before passing them to a final AI, prompted to act as a mentor. This final interaction helps them make sense of what they learned and encourages them to try again. While we had to improvise around the weak spots of current AI models with this elaborate system, such as its lack of memory, in the future, we might expect an AI to handle all these roles naturally. This could be a big boost to gaining expertise.

When Everyone Is an Expert

I have been making the argument that expertise is going to matter more than before, because experts may be able to get the most out of AI coworkers and are likely to be able to fact-check and correct AI errors. But even with deliberate practice, not everyone can become an expert in everything. Talent also plays a role. As much as I might love to be a world-class painter or soccer star, I never will be, no matter how much I practice. In fact, for the most elite athletes, deliberate practice explains only 1 percent of their difference from ordinary players—the rest is a mix of genetics, psychology, upbringing, and luck.

And this doesn't apply just to athletes. Silicon Valley tells stories of the "10x engineer." That is, a highly productive software engineer is up to 10 times better than an average one. This is actually a topic that has been studied repeatedly, although most of those studies are quite old. But those experiments find an even larger effect than 10x. The gap between the programmers in the top 75th percentile and those in the bottom 25th percentile can be as much as 27 times along some dimensions of programming quality. Add this to my own research looking at a job that many people find incredibly boring and cookie-cutter—middle management. In my study of the video game industry, I found that the quality of the middle manager overseeing a game explained more than a fifth of the game's eventual revenues. That was a bigger effect than the entire senior management team, and more than the designers who came up with the creative ideas for the game itself.

If you are able to find, train, and retain these top workers, you get tremendous benefits. A large part of schooling and work is focused on getting people to this highly skilled state. However, people who are good at one skill may not be good at another. Modern professional work consists of a wide range of activities rather than a single specialization. For example, the job of a doctor may require many tasks, like diagnosing patients, providing treatment, offering advice, filling out expense reports, and overseeing the office staff. It is unlikely that any doctor is equally good at all these tasks. Even the best workers have weak spots, requiring that they be part of larger organizations to ensure they can focus on their area of expertise.

Except, as we discussed earlier, we already know one major effect of AI: it levels the playing field. If you were in the bottom half of the skill distribution for writing, idea generation, analyses, or any of a number of other professional tasks, you will likely find that, with the help of AI, you have become quite good. This isn't a new phenomenon—the robot surgeons we discussed at the start of the chapter are the most helpful for the lowest performers—but AI is much more general purpose than robot surgeons.

In field after field, we are finding that a human working with an AI co-intelligence outperforms all but the best humans working without an AI. In our study of Boston Consulting Group, where previously the gap between the average performances of top and bottom performers was 22 percent, the gap shrank to a mere 4 percent once the consultants used GPT-4. In creative writing, getting ideas from AI " effectively equalizes the creativity scores across less and more creative writers," according to one study. And law students near the bottom of their class using AI equalized their performance with folks at the top of the class (who actually saw a slight decline when using AI). The authors of the study concluded, "This suggests that AI may have an equalizing effect on the legal profession, mitigating inequalities between elite and nonelite lawyers." It gets more extreme. I participated in a panel discussion of the future of education with the CEO of Turnitin, the plagiarism-detecting company. He said, "Most of our employees are engineers and we have a few hundred of them . . . and I think in eighteen months we will need twenty percent of them, and we can start hiring them out of high school rather than four-year colleges. Same for sales and marketing functions." I could hear gasps from the audience.

So will AI result in the death of expertise? I don't think so. As we discussed, jobs don't consist of just one automatable task, but rather a set of complex tasks that still require human judgment. Plus, because of the Jagged Frontier, it is unlikely to do every task that a worker is responsible for. Improving the performance in a few areas need not lead to replacement; instead, it will allow workers to focus on building and honing a narrow slice of area expertise, becoming the human in the loop.

But it is possible that there may be a new type of expert arising. While, as we discussed in the last chapter, prompt crafting is unlikely to be useful for most people, that doesn't mean it is entirely useless. It may be that working with AI is itself a form of expertise. It is possible that some people are just really good at it. They can adopt Cyborg practices better than others and have a natural (or learned) gift for working with LLM systems. For them, AI is a huge blessing that changes their place in work and society. Other people may get a small gain from these systems, but these new kings and queens of AI get orders of magnitude improvements. If this scenario is true, they would be the new stars of our AI age and would be sought out by every company and institution, the way other top performers are recruited today.

I, along with my frequent collaborator and expert on teaching with new technologies (and spouse), Dr. Lilach Mollick, have had some experience of this ourselves. As the hype and anxiety around AI built in the summer of 2023, we found ourselves in demand as some of the people who could best combine knowledge of pedagogy with deep experience in creating prompts. The big AI companies, including OpenAI and Microsoft, shared our prompts as the examples to use in classrooms, and the prompts themselves were cited and passed around educational institutions around the world. While we didn't think of ourselves as having a special skill in prompting, we found that we were very good at making AI dance to our tune. We don't really know why we are good at this (Experience? A background in game design and teaching? An ability to take the "perspective" of the AI, of the instructor, and of the student? Our experience in writing instructions for a variety of audiences?), but it suggests that there may be a role for humans who are experts at working with AI in particular fields. We just haven't quite pinpointed the specific skills or expertise that taps into the ability to "speak" to the AI.

An AI future requires that we lean into building our own expertise as human experts. Since expertise requires facts, students will still need to learn reading, writing, history, and all the other basic skills required in the twenty-first century. We have already seen how this broad-based knowledge can help people get the most out of AI. And besides, we need to continue to have educated citizens rather than delegate all our thinking to machines. Students may also need to start to develop a narrow focus, picking an area where they are better able to work with AI as experts themselves. At the same time, our total range of abilities will grow broader, as the AI fills gaps and helps mentor us to increase our own skills. If the capabilities of AI do not change radically, it is likely that AI truly becomes our co-intelligence, helping us fill the gaps in our own knowledge and pushing us to become better ourselves. But this is not the only future we need to be thinking about.

8 AI 作为教练

AI 对我们的教育系统最大的威胁并不是它会让学生的家庭作业变得无用，而是它有可能破坏正式教育之后的隐性学徒系统。对于大多数专业工作者来说，离开学校进入职场只是他们实际教育的开始，而不是终点。在教育结束后，他们会经历多年的在职培训，这可能包括有组织的培训项目，也可能是几年熬夜加班和被愤怒的老板责骂琐碎任务的经历。虽然这个系统不像我们的教育系统那样经过集中设计，但它对我们学会如何进行真正的工作至关重要。

传统上，人们通过从底层做起获得专业知识。无论是木匠的学徒、杂志的实习生，还是医学住院医师，这些工作虽然通常很辛苦，但却非常重要。只有通过向更有经验的专家学习，并在他们的指导下不断尝试和失败，业余者才能成为专家。但是，随着 AI 的快速发展，这一切可能会迅速改变。尽管实习生或初级律师不喜欢因工作失误而被责骂，他们的老板通常更愿意看到工作快速完成，而不是处理员工的情绪和错误。因此，老板们可能更倾向于使用 AI 来完成这些任务。虽然 AI 目前在许多任务上还无法完全胜任资深专业人士的工作，但它通常比新手表现得更好。这可能会导致一个重大的培训空白。

事实上，加州大学圣塔芭芭拉分校的 Professor Matthew Beane 研究发现，这种情况在外科医生中已经出现了。医疗机器人已经在医院中存在了十多年，帮助医生进行手术，而医生则在旁边用类似电子游戏的控制器操作它们。虽然关于手术机器人的数据褒贬不一，但在许多情况下，它们确实是有帮助的。然而，它们也在培训中造成了巨大的问题。

在传统的外科培训中，经验丰富的医生和实习住院医生可以一起工作，医生会手把手地指导住院医生学习技术。而在机器人手术中，只有一个座位可以控制机器人，通常由资深外科医生操作，实习医生只能观看、偶尔短暂操作机器，或使用模拟器。在紧张的时间压力下，住院医生必须在学习传统手术技能和自己抽时间学习机器人操作之间做出选择。许多医生因此训练不足，而那些想要学机器人手术的人则转向非官方渠道，通过观看 YouTube 视频或在实际患者身上进行更多练习来进行「影子学习」。

随着 AI 自动化越来越多的基础任务，这种培训危机也会蔓延。尽管专家仍是唯一能够有效检查强大 AI 工作的人，但我们有可能阻断培养专家的渠道。在 AI 时代，要在人类社会中发挥作用，需要具备高水平的专业知识。好在教育者已经掌握了培养专家的方法。讽刺的是，这需要回归基础，但要适应已经被 AI 革命化的学习环境。

在 AI 时代培养专业知识

AI 擅长寻找事实、总结论文、写作和编程任务。大语言模型通过大量数据训练和互联网访问，似乎已经掌握了大量的人类知识。这一庞大的知识库现在人人可及。因此，似乎教学基本知识已经过时。然而，事实恰恰相反。

在 AI 时代，获取知识存在一个悖论：我们可能认为不需要花时间记忆和掌握基本技能，或者建立起基本的知识储备 —— 毕竟，这是 AI 擅长的事情。学习基础技能总是枯燥乏味的，似乎变得不再重要。如果存在快速成为专家的捷径，这些技能可能会被抛弃。但是，成为专家的道路仍然需要扎实的知识基础。

学习任何技能和掌握任何领域都需要死记硬背、细致的技能培养和有针对性的练习。AI（以及未来几代 AI）在许多初级技能上无疑会比新手表现得更好。例如，斯坦福大学的研究人员发现，GPT-4 AI 在临床推理考试中的得分高于一、二年级的医学生。因此，我们可能会倾向于将这些基本技能外包给 AI。毕竟，医生们乐于使用医疗应用程序和互联网来帮助诊断患者，而不是单纯依靠记忆医学信息。这又有什么不同呢？

问题在于，为了学习批判性思维、解决问题、理解抽象概念、应对新问题并评估 AI 的输出，我们需要具备专业知识。例如，一位了解学生和课堂情况并且具有教学知识的专家教育者，可以评估 AI 撰写的课程大纲或生成的测验；一位熟悉设计原则和建筑规范的资深建筑师，可以评估 AI 提出的建筑计划是否可行；一位拥有丰富人体解剖和疾病知识的医生，可以仔细审查 AI 生成的诊断或治疗方案。随着我们逐步迈向一个 AI 增强我们工作的世界，我们更需要保持和培养人类的专业知识。我们需要专家的参与。

那么，我们来看看如何建立专业知识。首先，需要一个知识基础。人类实际上有多种记忆系统，其中之一是我们的工作记忆，这是大脑处理问题的中心，我们的思维工作空间。我们利用工作记忆中存储的数据，来在长期记忆（我们所学和经历的庞大图书馆）中搜索相关信息。工作记忆也是学习的起点。然而，工作记忆的容量和持续时间都是有限的，普通成年人的工作记忆容量平均为 3 到 5 个单位，每个新学习的信息块的保留时间不到 30 秒。尽管存在这些限制，工作记忆也有其优势，例如能够从长期记忆中回忆或提示出无限数量的事实和程序用于解决问题。因此，虽然工作记忆在处理新信息时有局限性，但当处理长期记忆中已学过的信息时，这些限制就不再存在了。换句话说，为了解决新问题，我们需要将大量相关信息存储在长期记忆中。这意味着我们需要学习许多事实并理解它们之间的联系。

接下来，我们必须进行练习。重要的不仅仅是练习时间的长短（无论你读到什么，10000 小时都不是一个神奇的门槛），而是心理学家 Anders Ericsson 发现的，练习的类型。专家通过刻意练习成为专家，这比简单重复任务要困难得多。刻意练习需要认真投入，并不断提升难度。它还需要教练、老师或导师提供反馈和细致指导，推动学习者走出舒适区。

以古典钢琴领域为例。想象两个学生：Sophie 和 Naomi。Sophie 花她的下午时间一遍又一遍地演奏她熟悉的曲子。她可能会这样做几个小时，因为她认为单纯的重复会提高她的技能。她在这项工作中越来越熟练，并因此感到一种成就感。另一方面，Naomi 在经验丰富的钢琴导师的指导下进行练习。她先从弹奏音阶开始，然后逐渐转向更具挑战性的曲目。当她犯错误时，她的导师会指出来，不是为了责备她，而是为了帮助她理解和改正这些错误。Naomi 还定期为自己设定目标，比如掌握某个特别棘手的段落或在某些段落上提高她的速度和灵活性。相比之下，这个过程远没有 Sophie 的经历那么有趣，因为随着 Naomi 技能的提高，她面临的挑战也在增加，使她始终面临一定程度的困难。然而，随着时间的推移，即使两位学生的练习时间相同，Naomi 在技能、精确度和技术方面可能会超过 Sophie。这种方法和结果的差异说明了单纯重复和刻意练习之间的区别。后者，具有挑战性、反馈和逐步进步的元素，是通向掌握的真正道路。

但这种练习非常困难。它需要计划，以及能够持续提供反馈和指导的教练。优秀的教练很少见，而且本身就是技术专家，这使得获得成功所需的刻意练习指导变得困难。AI 可能能够直接解决这些问题，创建一个比我们今天更好的培训系统。

让我们走进建筑的世界。想象一下两个新晋建筑师，Alex 和 Raj。他们刚刚从顶尖的建筑学校毕业，充满了新颖的想法和设计的热情。Alex 开始了他的职业生涯，采用传统的方法进行设计。他经常研究著名的建筑蓝图，并且每周都会从公司的一位高级建筑师那里获得反馈。他相信，通过不断地绘制和改进设计，他会逐渐提高。尽管这个过程确实有助于他的学习，但受到反馈频率和导师能够提供的分析深度的限制。

相比之下，Raj 将 AI 驱动的建筑设计助手融入了他的工作流程。每次他创建一个设计时，AI 都会立即提供反馈。AI 可以指出结构上的低效之处，提出基于可持续材料的改进建议，甚至能预测潜在的成本。此外，AI 还会将 Raj 的设计与庞大的创新建筑作品数据库进行比较，突出差异并建议改进领域。Raj 不仅仅是在反复修改设计，而是在每个项目完成后进行系统的反思，这要归功于 AI 提供的见解。这就像是每一步都有一个导师在他身边，指引他走向卓越。

几个月后，Alex 和 Raj 的成长轨迹差异变得明显。虽然 Alex 的设计确实在成熟和演变，但他的成长速度明显较慢。他每周一次的反馈会议虽然有价值，但并没有提供 Raj 每次设计迭代后所享受的即时且深入的分析。Raj 的方法，在 AI 的帮助下，充分体现了刻意练习的精髓。他持续的快速反馈循环，加上针对性的改进建议，确保了他不仅练习得更多，还练习得更好。在这种情况下，AI 对于 Raj 来说不仅仅是一个工具；它充当了一个随时在旁的导师，确保每次尝试不仅是制作另一个设计，而是有意识地理解和完善他的建筑方法。

今天的 AI 还无法完全实现我们对其的期望。它仍然难以连接复杂的概念，并且经常产生幻觉。然而，在我们沃顿商学院的实验中，我们发现当前的 AI 在某些方面仍然表现出色，能够提供及时的鼓励、指导以及其他有助于刻意练习的要素。例如，我们用 AI 构建了一个模拟器，教人们如何推销他们的想法。用户首先接受指导课程，并有机会向 AI 提问他们所学到的内容（此时 AI 会被提示提供推销建议，就像我在课堂上所做的那样）。接下来，他们进入练习课程，在这个过程中，另一个提示让 AI 模拟一个风险投资家，对他们的推销和想法进行严格的质询。在整个过程中，另一个同样的 AI 实例正在收集他们的表现数据，包括之前 AI 保留的秘密「笔记」。在练习课程结束时，这个 AI 会对他们的表现进行评分，然后将他们传递给最后一个 AI，该 AI 被提示作为导师。这最后的互动帮助他们理解所学内容，并鼓励他们再试一次。虽然我们不得不针对当前 AI 模型的弱点（如缺乏记忆）进行即兴调整，但在未来，我们可能期望 AI 能够自然地处理所有这些角色，这将大大加速专业知识的获取。

当每个人都是专家时

我一直在论证，专业知识在未来会变得更加重要，因为专家能够充分利用 AI 同事，并且有能力核实和纠正 AI 的错误。然而，即使经过刻意练习，也不是每个人都能成为各个领域的专家。天赋在其中也起着关键作用。就像我再怎么热爱绘画或足球，也无法通过练习成为世界级的画家或足球明星。事实上，对于最顶级的运动员来说，刻意练习只解释了他们与普通选手差异的 1%，其余的则是遗传、心理、成长环境和运气的综合作用。

这种情况不仅限于运动员。硅谷流传着「10 倍工程师」的故事，也就是说，一名高效的软件工程师比普通工程师效率高 10 倍。其实，这个话题已经被反复研究过，尽管大多数研究都比较久远。但实验发现，效果甚至超过了 10 倍。在编程质量的某些方面，排名前 75% 的程序员与排名后 25% 的程序员之间的差距可以高达 27 倍。再加上我自己对一份许多人认为非常无聊且重复的工作的研究 —— 中层管理。在我对视频游戏行业的研究中，我发现负责监督游戏的中层管理者的素质，对游戏最终收入的影响超过五分之一。这比整个高级管理团队的影响还要大，甚至超过了那些提出创意的设计师。

如果能找到、培养并留住这些顶尖人才，你将受益匪浅。大量的教育和工作都致力于将人们培养成高技能的状态。然而，一个人在某项技能上表现出色，并不意味着在其他技能上也同样出色。现代的专业工作往往包括多种任务，而不仅仅是单一的专业化。例如，医生的工作涉及多种任务，如诊断病人、进行治疗、提供建议、填写费用报告以及管理办公室员工。很难有医生在所有这些任务上都同样擅长。即使是最优秀的专业人士也有自己的弱点，因此需要依靠更大的团队来确保他们能专注于自己的专业领域。

然而，正如我们之前讨论的那样，人工智能的一个主要影响是它使竞争环境更加公平。假如你在写作、创意生成、分析或其他许多专业任务上处于技能分布的下半部分，你可能会发现，在人工智能的帮助下，你的能力显著提升。这并不是一个新现象 —— 正如我们在本章开头提到的，机器人外科医生对表现较差的医生帮助最大 —— 但人工智能的应用范围更为广泛。

在各个领域，我们发现人类与 AI 协作的表现优于绝大多数未使用 AI 的人类。在我们对波士顿咨询集团的研究中，之前顶尖和底层表现者之间的平均差距为 22%。一旦顾问们使用了 GPT-4，这个差距缩小到仅 4%。在创意写作中，一项研究表明，从 AI 获取创意「有效地平衡了创意分数，无论是创意较多的作家还是创意较少的作家」。而班级排名靠后的法律学生使用 AI 后，其表现与排名靠前的学生持平（实际上，排名靠前的学生在使用 AI 时表现略有下降）。研究的作者总结道，「这表明 AI 可能对法律职业具有平衡效应，缓解了精英律师和非精英律师之间的不平等。」情况变得更加极端。我参加了一个关于教育未来的讨论小组，参与者包括 Turnitin（一个抄袭检测公司）的 CEO。他说，「我们的大多数员工都是工程师，我们有几百人。我认为在十八个月内我们只需要其中的 20%，并且我们可以开始从高中而不是四年制大学雇佣他们。销售和市场职能也是如此。」我听到观众发出了惊叹声。

那么 AI 会导致专业知识的消亡吗？我不这么认为。正如我们讨论的那样，工作不仅仅由一个可自动化的任务组成，而是一组仍然需要人类判断的复杂任务。此外，由于 Jagged Frontier 的存在，它不太可能完成工人负责的每一项任务。在某些领域提高表现不一定会导致替代；相反，它将允许工人专注于构建和磨练狭窄的专业领域，成为循环中的人类。

但是，可能会有新类型的专家出现。虽然正如我们在上一章讨论的那样，提示词设计对于大多数人来说不太可能有用，但这并不意味着它完全没用。可能与 AI 一起工作本身就是一种专业技能。有些人可能在这方面确实有天赋。他们可以比其他人更好地采用半机械人实践，并且在使用大语言模型（LLM）系统时有着天生（或后天习得）的优势。对于他们来说，AI 是一种巨大的福音，改变了他们在工作和社会中的地位。其他人可能从这些系统中获得小幅提升，但这些新的 AI 之王和王后会获得数量级的提升。如果这种情况属实，他们将成为我们 AI 时代的佼佼者，并会像今天其他顶尖人才一样被每家公司和机构追捧。

我和我的长期合作者兼新技术教学专家（也是我的配偶）Dr. Lilach Mollick，有一些亲身经历。随着 2023 年夏季对 AI 的炒作和焦虑日益高涨，我们发现自己成了需求很高的人，因为我们能够很好地将教学法知识与丰富的提示（prompt）创建经验结合起来。大型 AI 公司，包括 OpenAI 和 Microsoft，分享了我们的提示，作为课堂上的示例，这些提示本身也被引用并在世界各地的教育机构之间传阅。虽然我们并不认为自己在提示创建方面有特别的技能，但我们发现我们非常擅长让 AI 按照我们的意图运行。我们并不确切知道为什么我们在这方面做得很好（是因为经验？是因为我们有游戏设计和教学背景？是因为我们能够从 AI、教师和学生的「视角」来看问题？还是因为我们有为各种受众编写说明的经验？），但这表明在特定领域内擅长与 AI 合作的人类可能有其角色。我们只是还没有完全确定是什么具体技能或专业知识能够帮助我们「与 AI 对话」。

一个充满 AI 的未来要求我们更加专注于培养自身的专业知识。因为成为专家需要掌握事实，学生仍然需要学习阅读、写作、历史等二十一世纪所需的基本技能。我们已经看到，这种广博的知识可以帮助人们更好地利用 AI。此外，我们仍然需要培养受过良好教育的公民，而不是把所有思考都交给机器。学生们可能还需要开始专注于某个具体领域，从而能够更好地与 AI 协同工作。

与此同时，我们的整体能力范围将会变得更广，因为 AI 能够填补空白，并指导我们提升技能。如果 AI 的能力没有发生根本性的变化，它可能会成为我们的「共智」，帮助我们弥补知识的不足，并推动我们自身的进步。但我们也需要思考其他可能的未来。