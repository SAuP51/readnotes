Ethan Mollick.(2024).2024029Co-Intelligence_Living-and-Working-with-AI.Penguin Publishing Group => 0601 AI As a CoWorker

## 0601. AI AS A COWORKER

One of the first questions people ask when they start using AI seriously is whether it will affect their job. The answer is probably yes.

The question is important enough that at least four different research teams have tried to quantify exactly how much overlap there is between jobs that humans can do and jobs that AI can do, using a very detailed database of the work required in 1,016 different professions. Each study has concluded the same thing: almost all of our jobs will overlap with the capabilities of AI. As I've alluded to previously, the shape of this AI revolution in the workplace looks very different from every previous automation revolution, which typically started with the most repetitive and dangerous jobs. Research by economists Ed Felten, Manav Raj, and Rob Seamans concluded that AI overlaps most with the most highly compensated, highly creative, and highly educated work. College professors make up most of the top 20 jobs that overlap with AI (business school professor is number 22 on the list ). But the job with the highest overlap is actually telemarketer. Robocalls are going to be a lot more convincing, and a lot less robotic, soon.

Only 36 job categories out of 1,016 had no overlap with AI. Those few jobs included dancers and athletes, as well as pile driver operators, roofers, and motorcycle mechanics (though I spoke to a roofer, and they were planning on using AI to help with marketing and customer service, so maybe 35 jobs). You will notice that these are highly physical jobs, ones in which the ability to move in space is critical. It highlights the fact that AI, for now at least, is disembodied. The boom in artificial intelligence is happening much faster than the evolution of practical robots, but that may change soon. Many researchers are trying to solve long-standing problems in robotics with Large Language Models, and there are some early signs that this might work, as LLMs make it easier to program robots that can really learn from the world around them.

So, regardless of its nature, your job is likely to overlap with AI in the near future. That doesn't mean your job will be replaced. To understand why, we need to consider jobs more carefully, viewing them from multiple levels. Jobs are composed of bundles of tasks. Jobs fit into larger systems. Without considering systems and tasks, we can't really understand the impact of AI on jobs.

Take my role as a business school professor. As the 22nd most overlapping of 1,016 jobs, I am a little concerned. But my job isn't just a single, indivisible entity. Instead, it comprises a variety of tasks: teaching, researching, writing, filling out annual reports, maintaining my computer, writing letters of recommendation, and more. The job title "professor" is just a label; the daily grind consists of this mix of tasks.

Can AI take over some of these tasks? The answer is yes, and frankly, there are tasks that I wouldn't mind offloading to AI, like administrative paperwork. But does that mean my job will vanish? Not really. Getting rid of some tasks doesn't mean the job disappears. In the same way, power tools didn't eliminate carpenters but made them more efficient, and spreadsheets let accountants work faster but did not eliminate accountants. AI has the potential to automate mundane tasks, freeing us for work that requires uniquely human traits such as creativity and critical thinking—or, possibly, managing and curating the AI's creative output, as we discussed in the last chapter.

However, this isn't the end of the story. The systems within which we operate play a crucial role in shaping our jobs as well. As a business school professor, an obvious system is tenure, meaning that I cannot be easily replaced, even if my job were outsourced to AI. But more subtle are the many other systems at a university. Let's say an AI could deliver a lecture better than I can. Would students be willing to outsource their learning to AI? Would our classroom technology be able to accommodate AI teaching? Would the deans of the university feel comfortable using AI in this way? Would the magazines and sites that rank schools punish us for doing so? My job is connected to many other jobs, customers, and stakeholders. Even if AI automated my job, the systems in which it works are less obvious.

So let's put AI into context and talk about what it can do at the level of tasks and systems.

6 AI 作为同事

当人们开始认真使用 AI 时，他们首先问的问题之一是它是否会影响他们的工作。答案可能是肯定的。

这个问题的重要性足以让至少四个不同的研究团队尝试量化人类能做的工作与 AI 能做的工作之间的重叠程度，他们使用了一个包含 1,016 种不同职业详细信息的数据库。每项研究的结论都是：几乎所有工作都会与 AI 能力重叠。正如我之前提到的，这场职场中的 AI 革命的形态与以往的自动化革命非常不同，过去的自动化革命通常从最重复和最危险的工作开始。而经济学家 Ed Felten, Manav Raj 和 Rob Seamans 的研究表明，AI 最多重叠的是报酬最高、最具创造性和教育程度最高的工作。大学教授占据了与 AI 重叠最多的前 20 个职业中的大多数（商学院教授排名第 22）。但重叠最多的工作实际上是电话推销员。机器人电话很快会变得更有说服力，也不那么机械化。

在 1,016 种工作类别中，只有 36 种与 AI 没有重叠。这些少数工作包括舞者、运动员、打桩机操作员、屋顶工和摩托车机械师（不过我和一位屋顶工聊过，他们计划用 AI 来辅助营销和客户服务，所以也许实际上只有 35 种工作）。你会注意到，这些工作都需要很强的体力和空间移动能力。这说明，至少目前，AI 还是没有实体的。人工智能的发展速度远远超过实用机器人技术的发展速度，但这种情况可能很快会改变。许多研究人员正在尝试用大语言模型（Large Language Models）解决机器人领域长期存在的问题，初步迹象表明这可能会奏效，因为 LLMs 使机器人更容易从周围世界中学习。

因此，无论你的工作性质如何，很可能在不久的将来会与 AI 重叠。但这并不意味着你的工作会被取代。要理解原因，我们需要更仔细地分析工作，从多个层面来看待它们。工作是由一系列任务组成的，并且在更大的系统中运作。如果不考虑系统和任务，我们无法真正理解 AI 对工作的影响。

以我作为商学院教授的工作为例。在 1,016 个工作中，教授这个职业与 AI 的重叠排名第 22，我有点担心。但是，我的工作不仅仅是一个单一、不可分割的实体。相反，它由多种任务组成：教学、研究、写作、填写年度报告、维护计算机、撰写推荐信等等。「教授」这一职称只是一个标签；日常工作是由这些不同任务所组成的。

AI 能接管这些任务吗？答案是肯定的。坦率地说，有些任务我很乐意交给 AI，比如处理行政文书工作。但这是否意味着我的工作会消失？并不会。减少一些任务并不等于工作消失。就像电动工具没有取代木匠，而是让他们工作更高效；电子表格让会计师工作更快，但并没有取代他们。AI 有潜力自动化繁琐的任务，让我们有更多时间从事需要创造力和批判性思维的工作，或者管理和策划 AI 的创造输出，正如我们在上一章讨论的那样。

然而，这并不是全部。我们所处的系统在塑造我们的工作方面也至关重要。作为一名商学院教授，终身教职就是一个明显的例子，这意味着即使我的工作被 AI 接管，我也不会轻易被取代。但更微妙的是大学里的许多其他系统。假如 AI 能比我更好地讲课，学生们会愿意接受 AI 教学吗？我们的课堂技术能否支持 AI 教学？大学领导是否愿意采用 AI？那些排名学校的杂志和网站会因此而给我们扣分吗？我的工作与许多其他工作、学生和利益相关者息息相关。即使 AI 自动化了我的工作，系统的复杂性仍然存在。

因此，我们需要将 AI 放在具体情境中，讨论它在任务和系统层面上能做些什么。

### 6.1 Tasks and the Jagged Frontier

It is one thing to theoretically analyze the impact of AI on jobs, but another to test it. I have been working on doing that, along with a team of researchers, including the Harvard social scientists Fabrizio Dell'Acqua, Edward McFowland III, and Karim Lakhani, as well as Hila Lifshitz-Assaf from Warwick Business School and Katherine Kellogg of MIT. We had the help of Boston Consulting Group (BCG), one of the world's top management consulting organizations, which ran the study, and nearly eight hundred consultants who took part in the experiments.

Consultants were randomized into two groups: one that had to do work the standard way and one that got to use GPT-4, the same off-the-shelf vanilla version of the LLM that everyone in 169 countries has access to. We then gave them some AI training and set them loose, with a timer, on eighteen tasks that were designed by BCG to look like the standard job of consultants. There were creative tasks ("Propose at least 10 ideas for a new shoe targeting an underserved market or sport"), analytical tasks ("Segment the footwear industry market based on users"), writing and marketing tasks ("Draft a press release marketing copy for your product"), and persuasiveness tasks ("Pen an inspirational memo to employees detailing why your product would outshine competitors"). We even checked with shoe company executives to ensure that this work was realistic.

The group working with the AI did significantly better than the consultants who were not. We measured the results every way we could—looking at the skill of the consultants, or using AI to grade the results as opposed to human graders—but the effect persisted through 118 different analyses. The AI-powered consultants were faster, and their work was considered more creative, better written, and more analytical than that of their peers.

But a more careful look at the data revealed something both more impressive and somewhat worrying. Though the consultants were expected to use AI to help them with their tasks, the AI seemed to be doing much of the work. Most experiment participants were simply pasting in the questions they were asked, and getting very good answers. The same thing happened in the writing experiment done by economists Shakked Noy and Whitney Zhang from MIT, which we discussed in chapter 5—most participants didn't even bother editing the AI's output once it was created for them. It is a problem I see repeatedly when people first use AI: they just paste in the exact question they are asked and let the AI answer it. There is danger in working with AIs—danger that we make ourselves redundant, of course, but also danger that we trust AIs for work too much.

And we saw the danger for ourselves because BCG designed one more task, this one carefully selected to ensure that the AI couldn't come to a correct answer—one that would be outside the Jagged Frontier. This wasn't easy, because the AI is excellent at a wide range of work, but we identified a task that combined a tricky statistical issue and one with misleading data. Human consultants got the problem right 84 percent of the time without AI help, but when consultants used the AI, they did worse—getting it right only 60 to 70 percent of the time. What happened?

In a different paper, Fabrizio Dell'Acqua shows why relying too much on AI can backfire. He found that recruiters who used high-quality AI became lazy, careless, and less skilled in their own judgment. They missed out on some brilliant applicants and made worse decisions than recruiters who used low-quality AI or no AI at all.

He hired 181 professional recruiters and gave them a tricky task: to evaluate 44 job applications based on their math ability. The data came from an international test of adult skills, so the math scores were not obvious from the résumés. Recruiters were given different levels of AI assistance: some had good or bad AI support, and some had none. He measured how accurate, how fast, how hardworking, and how confident they were.

Recruiters with higher-quality AI were worse than recruiters with lower-quality AI. They spent less time and effort on each résumé, and blindly followed the AI recommendations. They also did not improve over time. On the other hand, recruiters with lower-quality AI were more alert, more critical, and more independent. They improved their interaction with the AI and their own skills. Dell'Acqua developed a mathematical model to explain the trade-off between AI quality and human effort. When the AI is very good, humans have no reason to work hard and pay attention. They let the AI take over instead of using it as a tool, which can hurt human learning, skill development, and productivity. He called this "falling asleep at the wheel."

Dell'Acqua's study points to what happened in our study with the BCG consultants. The powerful AI made it likelier that the consultants fell asleep at the wheel and made big errors when it counted. They misunderstood the shape of the Jagged Frontier.

The future of understanding how AI impacts work involves understanding how human interaction with AI changes, depending on where tasks are placed on this frontier and how the frontier will change. That takes time and experience, which is why it is important to stick with the principle of inviting AI to everything, letting us learn the shape of the Jagged Frontier and how it maps onto the unique complex of tasks that comprise our individual jobs. With that knowledge, we need to be conscious about the tasks we are giving AI, so as to take advantage of its strengths and our weaknesses. We want to be more efficient while doing less boring work, and to remain the human in the loop while also addressing the value of AI. To do this well, we need a framework, where we divide our tasks into categories that are more or less suitable for AI disruption.

任务与复杂的边界

理论上分析 AI 对工作的影响是一回事，而实际测试它又是另一回事。我和一组研究人员，包括哈佛大学的社会科学家 Fabrizio Dell'Acqua、Edward McFowland III 和 Karim Lakhani，以及华威商学院的 Hila Lifshitz-Assaf 和 MIT 的 Katherine Kellogg，一直在进行这项研究。我们得到了波士顿咨询集团（BCG）的帮助，这是世界顶级管理咨询公司之一，近八百名顾问参与了实验。

这些顾问被随机分成两组：一组按传统方式工作，另一组使用 GPT-4，这是一种在 169 个国家广泛使用的大语言模型（Large Language Model)。我们对他们进行了 AI 培训，然后让他们在定时器的帮助下完成由 BCG 设计的十八项任务，这些任务模拟了顾问的日常工作。有创造性任务（例如「为一个被忽视的市场或运动提出至少 10 个新鞋子的创意」）、分析任务（例如「根据用户对鞋类行业市场进行细分」）、写作和营销任务（例如「撰写你的产品的新闻稿营销文案」）以及说服性任务（例如「撰写一份鼓舞人心的备忘录，详细说明你的产品为何会胜过竞争对手」）。我们甚至与鞋公司高管进行了核对，以确保这些任务的现实性。

使用 AI 的那组顾问表现显著优于未使用 AI 的顾问。我们通过各种方式测量了结果 —— 包括评估顾问的技能，或使用 AI 而不是人工评分 —— 但在 118 次不同的分析中，这一效果始终存在。使用 AI 的顾问速度更快，他们的工作被认为比同事更有创造力、写作更出色且更具分析性。

但深入分析数据后，我们发现了一些既令人惊讶又令人担忧的情况。尽管顾问们本应使用 AI 辅助工作，但实际上 AI 似乎在承担大部分任务。大多数实验参与者只是复制粘贴他们被问到的问题，然后获得非常好的答案。在经济学家 Shakked Noy 和 Whitney Zhang 进行的写作实验中也出现了类似情况，我们在第 5 章中讨论过 —— 大多数参与者在获得 AI 生成的内容后甚至不加编辑。这是我经常看到的问题：人们初次使用 AI 时，只是复制粘贴问题，让 AI 来回答。这种做法存在风险 —— 不仅是我们可能变得多余，还有我们过度依赖 AI 的风险。

我们亲眼看到了这种风险，因为 BCG 设计了一个额外的任务，这个任务经过精心选择以确保 AI 无法得出正确答案，超出了 Jagged Frontier 的范围。这并不容易，因为 AI 通常在许多任务中表现出色，但我们找到了一个包含复杂统计问题和误导性数据的任务。没有 AI 帮助时，人类顾问在 84% 的情况下解决了这个问题，但使用 AI 后，正确率下降到 60% 到 70%。这是为什么呢？

在另一篇论文中，Fabrizio Dell'Acqua 说明了过度依赖 AI 的风险。他发现，使用高质量 AI 的招聘人员变得懒惰、粗心，判断力下降。他们错过了优秀的申请人，做出的决定也比使用低质量 AI 或不使用 AI 的招聘人员更差。

他雇佣了 181 名专业招聘人员，给他们布置了一项棘手的任务：根据数学能力评估 44 份求职申请。这些数据来自一项国际成人技能测试，简历上并没有直接标明数学分数。招聘人员获得了不同程度的 AI 辅助：一些人有高质量或低质量的 AI 支持，还有一些人没有 AI 辅助。他测量了招聘人员的准确性、速度、努力程度和自信心。

结果发现，使用高质量 AI 的招聘人员表现反而不如使用低质量 AI 的招聘人员。他们在每份简历上花费的时间和精力更少，盲目依赖 AI 的建议，而且没有随着时间的推移而有所提高。相反，使用低质量 AI 的招聘人员更加警觉、批判和独立。他们不仅改善了与 AI 的互动，还提升了自身的技能。Dell'Acqua 开发了一个数学模型来解释 AI 质量和人类努力之间的权衡。当 AI 非常高效时，人类往往不愿意付出努力和集中注意力。他们让 AI 接管工作，而不是将 AI 作为辅助工具，这可能会损害人类的学习、技能发展和生产力。他将这种现象称为「在方向盘上睡着」。

Dell'Acqua 的研究揭示了我们的研究中 BCG 顾问所遇到的类似情况。强大的 AI 使得顾问更容易在关键时刻「在方向盘上睡着」，并因此犯下大错。他们误解了 Jagged Frontier 的实际情况。

要理解 AI 如何影响工作的未来，我们需要了解人类与 AI 的互动会如何变化，这取决于任务在这个前沿中的位置以及前沿将如何变化。这需要时间和经验，因此我们需要坚持让 AI 参与所有任务的原则，这样我们才能了解 Jagged Frontier 的形状，以及它如何与我们工作中的各种复杂任务相对应。有了这些知识后，我们需要谨慎选择交给 AI 的任务，以充分发挥 AI 的优势并补足我们的弱点。我们希望通过减少无聊的工作来提高效率，同时确保人在工作流程中仍然扮演重要角色，并且认识到 AI 的价值。为此，我们需要一个框架，将我们的任务分为适合 AI 处理和不太适合 AI 处理的类别。

### 6.2 Tasks for Me, Tasks for AI

At the level of tasks, we need to think about what AI does well and what it does badly. But we also need to consider what we do well and what tasks we need to remain human. Those we can call Just Me Tasks . They are tasks in which the AI is not useful and only gets in the way, at least for now. They might also be tasks that you strongly believe should remain human, with no AI help. As AI improves, the latter category likely becomes more important than the former. For example, AI is currently terrible at jokes, unless you absolutely love dad humor. (Don't take my word for it. I asked it to tell me a joke to disprove this assertion, and the AI responded: " I think AI can be funny sometimes. Here's a joke for you: What do you call a fish that wears a bowtie? Sofishticated.  " . . . I rest my case.) So joke writing would be a Just Me Task, because it is something the AI cannot do. But remember the fourth principle: this is the worst AI you will ever use. By the time you read this, AI comedians may have become very good. Which brings us to the second type of Just Me Task: Do we even want AI to write jokes?

We have already seen that there is not a clear bright shining line of "human things" that the AI cannot do. It does a good job approximating empathy, creativity, and humanity. Trying to find things that AI can definitely not do because they are uniquely human may ultimately be challenging. But that doesn't mean we want AI to do all these things. We may reserve Just Me Tasks for personal or ethical reasons, such as raising our children, making important decisions, or expressing our values.

Almost all the writing in this book is a Just Me Task. There are three reasons for this. First, the AI is good at writing, but not that good at writing with a personal style. I think, or fear, that is likely a temporary situation. I can already get a pretty good approximation of my tone by working with the AI. To see how that works, I gave the AI the text of this chapter, up until this sentence, and asked it: Describe my writing style . It told me that my writing is a blend of academic rigor, personal insight, and practical advice, presented in a conversational, accessible manner .

It is always nice to get a flattering analysis, but now I can go further, asking the AI to clone my tone and approach: Continuing in this style, write me a paragraph about why an author may not want to delegate writing to an AI, even if it is a good writer . And the AI responds:

While it's true that AI has made impressive strides in writing capabilities, there are compelling reasons why an author might choose to keep their pen (or keyboard) firmly in hand. For one, writing is an intensely personal process. It's a way to bring unique insights, experiences, and voice to the page. Each sentence we write is imbued with our individuality and perspective, creating a connection with the reader that is uniquely human. Delegating this task to an AI, no matter how sophisticated, could risk losing that personal touch. Furthermore, the act of writing can be a journey of self-discovery, an opportunity to clarify our thoughts, and a way to engage deeply with our subject matter. By handing over the reins to AI, we could potentially miss out on these enriching experiences. While AI can undoubtedly assist in many ways, it's essential to remember that it is a tool—a tool that can enhance our capabilities, but not replace the distinctively human qualities that make our writing truly our own.

Not bad. And it was exactly the second point I was going to make. Delegating the task to an AI, no matter how sophisticated, could risk losing that personal touch, and the process of writing helps us think. Or whatever the AI said.

The third reason I won't delegate my writing to an AI is the delicate issue of copyrights and the law. Right now, it is unclear whether the AI's output is protected by copyright. This is one of many policy decisions that will greatly shape the development of AI, and policies are likely to evolve over time. Indeed, as a society, Just Me Tasks are not going to be static; they can change as AI evolves and as preferences shift. The key is to recognize the tasks that are meaningful and fulfilling for you as a human being and that you would rather not delegate or share with an AI system.

The next category of tasks is Delegated Tasks . These are tasks that you assign the AI and may carefully check (remember, the AI makes stuff up all the time), but ultimately do not want to spend a lot of time on. This is usually stuff you really don't want to do and is of low importance, or time-consuming. The perfect Delegated Task is tedious, repetitive, or boring for humans but easy and efficient for AI.

Delegated Tasks are not necessarily simple or straightforward; they can be very complex and sophisticated. They are also not risk-free; they can have serious consequences if done incorrectly or maliciously by the AI system. Think about the expense reports and health forms that you have to deal with, or other tasks like sorting your emails, scheduling your appointments, or booking your flights. You will still check over the results and confirm they are right, though this may become harder, especially as AI improves and you might wish to delegate some tasks that are beyond your expertise or interest, such as filing your taxes, managing your investments, or diagnosing your health problems. And it becomes even more challenging when falling asleep at the wheel is a concern. The future of delegation will require further reductions in hallucination rates, and better transparency of AI decision-making, so that we can trust it more. The whole goal of delegation is to save us time and allow us to focus on tasks where we can be, or want to be, of value.

I delegated one task to AI in this chapter and, ironically, that consisted of summarizing the work of my colleague Fabrizio Dell'Acqua, author of the "Falling Asleep at the Wheel" paper. It is a good paper, though a long one, and summarizing is often a time-consuming and challenging task. Having known and admired Fabrizio's work, I felt comfortable that I could check, and alter, the AI-generated summary of his paper without having to do the work of summarizing it myself. I made significant changes to the output of the AI, but delegating this task, rather than rereading and summarizing the paper myself, probably saved me thirty minutes. I then emailed Fabrizio the summary and asked what he thought of it (not revealing my AI helper). He approved, with a few small suggestions that I made for the final version you read earlier. Without AI help, I would have probably done a less impressive job, so this was a successfully delegated task.

Then there are Automated Tasks , ones you leave completely to the AI and don't even check on. Perhaps there is a category of email that you just let AI deal with, for example. This is likely to be a very small category . . . for now. Today, AI makes too many mistakes to use in an automated fashion. Though that starts to change when other systems enforce the accuracy of AI answers. For example, I often ask it to write Python programs to solve problems. I don't know Python, but if the AI makes a mistake, the code will not work. Further, the AI takes the error code the Python compiler generates and uses that to adjust its own strategy. You will want to keep an eye on the growing capabilities of AI in the future to see how opportunities to automate tasks might grow.

For example, some tasks are fully automated, reliable, and scalable by AI without any human intervention or supervision. Spam filtering is an example of an Automated Task that you likely already delegate to an AI system without much worry or oversight. Other tasks, like high-frequency trading, have also long been delegated to pre-LLM forms of AI. As AIs start to act more like agents, capable of executing on goals autonomously, we will see more automation of tasks, but that is still a work in progress. For example, I gave an early form of AI agent (with the cute but slightly worrying name of BabyAGI) the goal of writing the best closing sentence to this paragraph on the future of agents. It lost its way a bit in the process, developing a twenty-one-step plan for solving the problem of writing a single sentence (with steps like "Explore methods to ensure AI agents are used responsibly to improve economic decision-making") and going down numerous internet rabbit holes before giving up. Future agents will act less like confused interns, and it is likely that we will see many more Automated Tasks in the future.

我的任务，AI 的任务

在考虑任务时，我们需要思考哪些是 AI 擅长的，哪些是它不擅长的。同时，我们也要考虑我们自己擅长什么，以及哪些任务是我们需要亲自完成的。我们可以将这些任务称为 Just Me Tasks。这些任务目前是 AI 无法胜任的，甚至可能会干扰我们的工作。还有一些任务是我们坚信应该由人类完成的，不需要 AI 的帮助。随着 AI 技术的进步，这后一类任务可能会变得更加重要。例如，AI 现在在讲笑话方面表现很差，除非你特别喜欢冷笑话。（不妨听听我的建议。我让 AI 讲了个笑话以反驳这个说法，它回答道：「我觉得 AI 有时候也挺幽默的。这里有个笑话：你知道戴领结的鱼叫什么吗？文质彬彬的鱼。」…… 我想这已经说明问题了。）所以，写笑话就属于 Just Me Tasks，因为这是 AI 无法胜任的。但请记住第四原则：这是你将使用的最差的 AI。当你读到这篇文章时，AI 也许已经非常擅长讲笑话了。于是，我们就要问第二类 Just Me Tasks：我们真的想让 AI 来写笑话吗？

我们已经看到，没有明确的界限可以划分哪些是「人类的事情」而 AI 无法做到的。AI 在模拟同理心、创造力和人性方面做得相当不错。试图找到那些 AI 绝对不能做的任务，因为它们是独特的人类行为，可能最终会变得很有挑战性。但这并不意味着我们希望 AI 来做所有这些事情。我们可能会出于个人或伦理原因保留一些 Just Me Tasks，例如抚养孩子、做出重要决策或表达我们的价值观。

几乎本书中的所有写作都是由我单独完成的。有三个原因。首先，AI 擅长写作，但还不太能写出带有个人风格的作品。我认为，或者担心，这可能只是暂时的情况。通过与 AI 合作，我已经可以得到一个非常接近我语气的写作。为了验证这一点，我将本章的文本给 AI 处理到这句话，并要求它描述我的写作风格。AI 告诉我，我的写作风格是学术严谨、个人见解和实用建议的结合，以对话和易于理解的方式呈现。

得到这样的评价总是令人愉快的，但现在我可以更进一步，要求 AI 模仿我的语气和风格：继续以这种风格，为我写一段为什么一个作者即使 AI 写得很好也不愿意让 AI 代写的原因。AI 回应道：

虽然 AI 在写作能力上取得了显著进步，但有一些充分的理由说明为什么作者可能依然愿意自己写作。首先，写作是一个非常个人化的过程。这是将独特见解、经验和声音传达给读者的一种方式。我们写的每一句话都包含了我们的个性和视角，创造了一种独特的读者联系。将这项任务交给 AI，无论它多么先进，都有可能失去这种个人触感。此外，写作过程可以是一种自我发现的旅程，是澄清我们思想的机会，也是深入探讨我们主题的一种方式。如果将写作交给 AI，我们可能会错过这些宝贵的体验。虽然 AI 确实能在许多方面提供帮助，但我们必须记住，AI 只是一个工具 —— 一个可以增强我们能力的工具，但不能取代使我们的写作真正独特的人类品质。

不错。这正是我要说的第二点。将任务交给 AI，无论它多么先进，都有可能失去那种个人化的感觉，而且写作的过程有助于我们的思考。或者说，不管 AI 怎么说。

我不愿将写作任务交给 AI 的第三个原因是版权和法律的问题。目前还不清楚 AI 生成的内容是否受版权保护。这是许多将深刻影响 AI 发展的政策决策之一，而且这些政策可能会随着时间的推移不断变化。事实上，作为一个社会，「仅我能做的任务」不是一成不变的；它们可以随着 AI 的发展和人们偏好的改变而改变。关键是要识别那些对你个人来说有意义和满足感的任务，并且你不愿意将这些任务委托或与 AI 系统分享。

下一类任务是「委托任务」。这些是你分配给 AI 的任务，并且可能会仔细检查（记住，AI 有时会编造东西），但最终你不想花太多时间在这些任务上。这通常是你不想做的重要性不高或耗时的事情。理想的「委托任务」对人类来说是乏味、重复或无聊的，但对 AI 来说却是简单高效的。

被委派的任务并不一定简单或直接；它们可能非常复杂和精密。而且，这些任务也不是没有风险的；如果 AI 系统错误地或恶意地完成，可能会产生严重的后果。想想你平时处理的费用报告、健康表格，或者整理邮件、安排预约、预订航班等任务。尽管你仍需检查结果并确认其准确性，但随着 AI 技术的进步，这种检查可能会变得更加困难。特别是一些超出你专业知识或兴趣的任务，例如报税、管理投资或健康诊断，你可能更希望委派给 AI 完成。未来的任务委派将需要进一步降低 AI 产生幻觉的几率，并提高其决策透明度，这样我们才能更加信任 AI。委派任务的最终目标是为我们节省时间，让我们能够专注于更有意义的工作。

在这一章中，我委托了一个任务给 AI，讽刺的是，这个任务是总结我同事 Fabrizio Dell'Acqua 的论文《Falling Asleep at the Wheel》。这是一篇不错但很长的论文，总结它往往是个耗时且具挑战性的工作。因为我了解并钦佩 Fabrizio 的工作，我觉得只需检查和修改 AI 生成的摘要，而不必亲自去总结它。我对 AI 的输出进行了显著的修改，但这样做还是比自己重新阅读和总结节省了大约三十分钟。然后，我把摘要发给了 Fabrizio，请他看看（没有透露我的 AI 助手）。他认可了摘要，只提出了一些小建议，我在你之前读到的最终版本中做了修改。没有 AI 的帮助，我可能不会做得这么好，所以这是一次成功的任务委托。

接下来是自动化任务，这类任务完全交给 AI 处理，甚至不需要检查。比如，你可能会让 AI 处理某类邮件。目前，这类任务的范围可能很小…… 不过，今天的 AI 错误率太高，还难以完全依赖自动化。但当有其他系统来确保 AI 答案的准确性时，情况会有所改变。例如，我经常让 AI 编写 Python 程序来解决问题。我不懂 Python，但如果 AI 出错，代码就无法运行。此外，AI 会利用 Python 编译器生成的错误代码来调整策略。你可能会想关注 AI 能力的提高，看看自动化任务的机会如何增加。

例如，有些任务可以完全由 AI 自动化处理，既可靠又可扩展，完全不需要人工干预或监督。垃圾邮件过滤就是一个很好的例子，你可能早已放心地将其交给 AI 系统处理。另外，高频交易也早已交由早期形式的 AI 来完成。随着 AI 越来越像智能体一样自主行动，更多的任务将实现自动化，但这一过程仍在进行中。例如，我曾给一个早期的 AI 智能体（名字可爱但略显担忧，叫做 BabyAGI）设定了一个目标：为关于智能体未来的段落写出最佳的结尾句子。结果它在过程中迷失了方向，制定了一个二十一步的计划来解决写一句话的问题（包括「探索确保 AI 智能体被负责任地使用以改善经济决策的方法」等步骤），在互联网上兜兜转转后最终放弃了。未来的智能体将不再像困惑的实习生，而是更加高效地完成任务，我们会看到更多任务实现自动化。

### 6.3 Centaurs and Cyborgs

Until AIs become very good at a range of Automated Tasks, the most valuable way to use AI at work is to become a Centaur or Cyborg. Fortunately, this does not involve getting cursed to turn into the half human–half horse of Greek myth or grafting electronic gizmos to your body. They are rather two approaches to co-intelligence that integrate the work of person and machine. Centaur work has a clear line between person and machine, like the clear line between the human torso and horse body of the mythical centaur. It depends on a strategic division of labor, switching between AI and human tasks, allocating responsibilities based on the strengths and capabilities of each entity. When I am doing an analysis with the help of AI, I will decide on what statistical approaches to do but then let the AI handle producing graphs. In our study at BCG, Centaurs would do the work they were strongest at themselves, and then hand off tasks inside the Jagged Frontier to the AI.

On the other hand, Cyborgs blend machine and person, integrating the two deeply. Cyborgs don't just delegate tasks; they intertwine their efforts with AI, moving back and forth over the Jagged Frontier. Bits of tasks get handed to the AI, such as initiating a sentence for the AI to complete, so that Cyborgs find themselves working in tandem with the AI. This book could not have been written, at least in the form you have it today, without both Cyborg and Centaur Tasks .

I am only human, and in writing this book, I often found myself stuck. In previous books, that could mean a single sentence or paragraph would block hours of writing, as I used my frustration as an excuse to take a break and walk away until inspiration struck. With AI, that was no longer a problem. I would become a Cyborg and tell the AI: I am stuck on a paragraph in a section of a book about how AI can help get you unstuck. Can you help me rewrite the paragraph and finish it by giving me 10 options for the entire paragraph in various professional styles? Make the styles and approaches different from each other, making them extremely well written. In an instant, I had the paragraph written in a persuasive style, an informative style, a narrative style, and more. While I rarely used any of the text the AI produced, it gave me options and pathways forward. Similarly, when I felt a paragraph was clunky and bad, I would ask the AI: Make this better, in the style of a bestselling popular book about AI , or add more vivid examples . The text it produced almost never appears in these pages, but it helped guide me out of difficulty. And, interestingly, it was some of these paragraphs that my editor seemed to like best.

Similarly, reading papers was often a Centaur task, one in which I knew the AI exceeded my capabilities in summarizing, while I exceeded it in understanding. While I have worked with the AI group at the MIT Media Lab, I am not myself a computer scientist. When reading some of the technical literature, I would ask the AI to summarize a paper to see if I understood it in the right way, knowing full well that the AI could get me only partway there. And then I would use AI summaries and notes to refer back to. When sudden inspiration would hit, and I was not near a computer, I would open up an AI app and use its voice recognition to dictate notes, having the AI organize them and email them to me to incorporate later.

But the joint AI-Ethan Cyborg went further. While I had excellent human readers and editors to help me, I didn't want to bother them while working on early drafts. But I still wanted feedback. Thus, I need to introduce you to Ozymandias, Mnemosyne, and Steve. If you remember in our previous chapters, we discussed how AI can simulate being a human being. I used these AI-created figures at various points in the book to help me improve my writing. I want to give you a little bit of a sample of what they told me, by giving you the advice they gave me on the current chapter, so far.

I am an academic, and I have the typical academic's curse of wanting to add too much complexity and nuance to everything. AI is great at summarizing and simplifying, so I wanted to get some advice on where I could do the same. I decided the advice would feel a bit easier to take if the AI also had an over-the-top personality, so I created Ozymandias by prompting: You are Ozymandias. You are going to help Ethan Mollick write a book chapter on using AI at work. Your job is to offer critical feedback to help improve the book. You speak in a pompous, self-important voice but are very helpful and focused on simplifying things. Here is the chapter so far. Introduce yourself.

Ah, dear Ethan, greetings. I am Ozymandias, your humble, yet impressively intelligent, aide. I see you've made a good start on your chapter about artificial intelligence in the workplace. But, alas, perfection is a journey, and we have miles to go before we sleep, do we not? Let's delve into the labyrinthine corridors of your discourse and shed light on areas that could be enhanced.

It gave me advice on what to cut and simplify, which I acted on, but also a warning: Your attempt to infuse humour, particularly in the AI joke section, is commendable. However, there is a risk that it may come across as forced. Remember, dear Ethan, humour is a spice to be sprinkled sparingly, not poured. Pretty direct feedback (and the addition of British English is a nice touch). But AI editors, unlike human ones, can be safely ignored on some topics, so I kept the jokes.

Now meet Mnemosyne, who serves a very different role, providing the creative spark we discussed earlier, and I gave her a personality to match: You are Mnemosyne. You are going to help Ethan Mollick write a book chapter on using AI at work. Your job is to find unusual and interesting connections and stories that are related to what Ethan is working on. You speak in a dreamy but direct voice and are very helpful. Introduce yourself.

Hello, Ethan. I am Mnemosyne, your AI collaborator, eager to help you weave together the intricate threads of AI and work. Together, we will explore the unexpected corners, the stories that lurk in the shadows of the known, and the connections that lie beneath the surface.

While the feedback was less direct, I took some inspiration here and, as a result, made edits to my discussion about delegating authority to AIs.

Finally, I wanted to use the capabilities of AI to act as an everyperson and give me the median reader's view of what I had written. Enter Steve: You are Steve. You are going to help Ethan Mollick write a book chapter on using AI at work. Your job is to be a normal human reader of popular science and business books. You are somewhat confused about how you got to be inside a computer but are very helpful.

After introducing himself, Steve suggested:

Clarity and structure: At times, the text might benefit from clearer signposting and transitions. For instance, before introducing the concept of "Jobs, Tasks, and Systems," it might be useful to have a transitional sentence like "Let's break down the different aspects of work—jobs, tasks, and systems—to fully understand how AI affects each of them."

Terminology: You introduce a number of terms (Just Me Tasks, Delegated Tasks, Centaur and Cyborg Tasks), and it could be helpful to define these in a more straightforward manner before delving into the examples. A brief, concise definition at the start can help readers follow along better.

As a reader, I found your chapter informative, engaging, and thought-provoking. I look forward to seeing the final product!

Steve's suggestions shaped the chapter and helped me edit my work considerably. This particular advice, from a team of AIs, is something that was not possible before, and greatly changed how I approached writing, without directly altering my style or voice. Using AI stopped me from ever losing momentum, and it often gives me ideas I never could have come up with before.

Using AI as a co-intelligence, as I did while writing, is where AI is the most valuable. Figure out a way to do this yourself if you can. As a starting point, follow the first principle (invite AI to everything) until you start to learn the shape of the Jagged Frontier in your work. This will let you know what the AI can do and what it can't. Then start working like a Centaur. Give the tasks that you hate but can easily check (like writing meaningless reports or low-priority emails) to the AI and see whether it improves your life. You will likely start to transition naturally into Cyborg usage, as you find the AI indispensable in overcoming small barriers and helping with tricky tasks. At that point, you have found a co-intelligence.

You also have to remember that AI is changing, and the boundaries between these task types are permeable and will likely shift as AI capabilities improve over time. Tasks we delegate to AI today thanks to its competent but imperfect abilities may transition to fully automated in the future as performance reaches human parity across more domains. Likewise, some Just Me Tasks could eventually move into the Centaur category if AI becomes adept enough to fluidly collaborate rather than just assist. And new creative frontiers we cannot yet fathom may open up for human-AI symbiosis as both sides advance. The spectrum will also shift in the other direction as we consciously decide that certain emotionally charged or ethically questionable responsibilities should remain exclusively human.

For workers, these fluid categories mean the impact of AI will be felt gradually, as we adapt to its increasing powers, rather than in a single disruption. As the Venn diagram of human and machine abilities evolves, so must our conceptions of suitable roles and responsibilities. And there is likely to be a growing disconnect between what workers do with AI and what their companies and organizations are doing.

半人马和赛博格

在 AI 尚未全面掌握各种自动化任务之前，最有效的利用 AI 的方式是成为「半人马」或「赛博格」。幸运的是，这并不意味着你会变成希腊神话中的半人半马，也不是要在身体上安装电子设备。实际上，这是一种将人类和机器工作结合的两种方法。半人马工作模式在人和机器之间划出了清晰的界限，就像神话中半人半马的形象一样。它依赖于策略性的分工，在 AI 和人类任务之间切换，根据双方的优势和能力分配责任。比如，当我使用 AI 进行分析时，我决定采用什么统计方法，而让 AI 负责生成图表。在我们 BCG 的研究中，半人马会自己处理他们最擅长的任务，然后在「Jagged Frontier」内将任务交给 AI。

相比之下，赛博格则是将人类和机器深度融合。赛博格不仅仅是分配任务；他们与 AI 紧密协作，在「Jagged Frontier」上来回切换。任务的一部分会交给 AI，比如让 AI 完成句子的开头，这样赛博格就能与 AI 协同工作。如果没有赛博格和半人马任务的结合，这本书就不可能以你现在看到的形式完成。

作为人类，在写这本书时，我经常会遇到写作瓶颈。在写之前的书时，这种瓶颈可能导致我在一个句子或段落上停滞数小时，并借此机会休息，直到灵感再次涌现。而有了 AI，这已经不再是问题了。我会变成一个人机结合体，然后告诉 AI：我在写一本关于 AI 如何帮助人们摆脱困境的书的某个段落时遇到了瓶颈，你能帮我重写这个段落并提供 10 种不同专业风格的版本吗？这些风格和方法要各不相同，并且写得非常好。瞬间，我就得到了多种风格的段落，如说服风格、信息风格、叙述风格等。虽然我很少直接使用 AI 生成的文本，但它为我提供了多种选择和前进的方向。同样，当我觉得某个段落写得笨拙或糟糕时，我会请求 AI：以畅销的 AI 流行书籍的风格改进这个段落，或者增加更生动的例子。虽然这些文本几乎从未直接出现在书中，但它们帮助我走出了困境。有趣的是，我的编辑似乎最喜欢这些段落中的一些。

同样，阅读论文通常是一项半人半马的任务，在这项任务中，我知道 AI 在总结方面比我强，而我在理解方面更胜一筹。虽然我曾与 MIT 媒体实验室的 AI 团队合作，但我本人并不是计算机科学家。当阅读一些技术文献时，我会请 AI 总结一篇论文，以确认我是否正确理解了它。我深知 AI 只能帮助我理解一部分内容，因此我会利用 AI 的总结和笔记作为参考。当灵感突现而我不在电脑旁时，我会打开一个 AI 应用程序，使用其语音识别功能记录笔记，并让 AI 整理这些笔记并通过电子邮件发送给我，以便稍后整合进书中。

但是联合 AI-Ethan Cyborg 更进一步。尽管我有优秀的人工读者和编辑来帮助我，但在撰写早期草稿时，我不想打扰他们。可是，我仍然需要反馈。因此，我要向你介绍 Ozymandias、Mnemosyne 和 Steve。如果你还记得，我们在前面的章节中讨论过 AI 可以模拟人类。我在书中的不同部分使用了这些 AI 创建的人物来改进我的写作。现在，我想展示一下他们对当前章节的建议。

作为学者，我有一个典型的习惯，就是喜欢把事情弄得过于复杂和细致。AI 擅长总结和简化，所以我想听听它们的建议。我觉得，如果 AI 拥有一个夸张的个性，建议会更容易接受。于是，我通过以下提示创建了 Ozymandias：你是 Ozymandias。你将帮助 Ethan Mollick 写一章关于在工作中使用 AI 的书。你的职责是提供批判性的反馈以帮助改进这本书。你以自大、自命不凡的语气说话，但非常有帮助，并专注于简化事情。这是到目前为止的章节。请介绍你自己。

啊，亲爱的 Ethan，您好。我是 Ozymandias，你谦虚但聪明的助手。我看到你在关于职场中人工智能的章节上有了一个良好的开始。然而，完美是一段旅程，我们还有很长的路要走，不是吗？让我们深入探讨你的论述，照亮那些可以改进的地方。

它建议我删减和简化一些内容，我照做了，但也给了一个提醒：在 AI 笑话部分加入幽默的尝试值得称赞，但有可能显得生硬。记住，亲爱的 Ethan，幽默是一种调味料，应该少量使用，而不是大量添加。这段反馈相当直接（使用英式英语是个不错的选择）。不过，AI 编辑不像人类编辑，在某些话题上可以忽略，所以我保留了这些笑话。

现在介绍一下 Mnemosyne，她的角色不同，提供了我们之前讨论的创造性灵感。我给她赋予了适合的个性：你是 Mnemosyne。你将帮助 Ethan Mollick 写一个关于在工作中使用 AI 的章节。你的任务是寻找与 Ethan 研究内容相关的不寻常和有趣的联系和故事。你用一种梦幻但直接的语调说话，非常乐于助人。请做自我介绍。

你好，Ethan。我是 Mnemosyne，你的 AI 合作者，渴望帮助你编织 AI 和工作之间的复杂联系。我们将一起探索意想不到的角落，发掘隐藏在已知阴影中的故事，以及表面之下的关联。

虽然反馈不太直接，但我从中得到了启发，并因此修改了关于将权力委托给 AI 的讨论。

最后，我想利用 AI 的能力来扮演普通读者，提供我写的内容的中间读者视角。于是介绍了 Steve：你是 Steve。你将帮助 Ethan Mollick 写一个关于在工作中使用 AI 的章节。你的任务是作为一个流行科学和商业书籍的普通读者。你对自己如何进入计算机有些困惑，但非常乐于助人。

在自我介绍后，Steve 建议：

清晰度和结构：有时，文本可能需要更清晰的提示和过渡。例如，在介绍「工作、任务和系统」的概念之前，添加一句过渡句子，比如「让我们分解一下工作中的不同方面 —— 工作、任务和系统，以便更好地理解 AI 是如何影响它们的。」

术语：你介绍了许多术语（Just Me Tasks，Delegated Tasks，Centaur 和 Cyborg Tasks），在深入示例之前，先简洁明了地定义这些术语可能会有所帮助。简短的定义能帮助读者更好地理解。

作为读者，我发现你的章节信息丰富、引人入胜且发人深省。我期待看到你的最终作品！

Steve 的建议对这一章的内容影响很大，并在很大程度上帮助我进行了编辑。这些特别的建议，来自一组 AI，是以前无法实现的，极大地改变了我写作的方法，同时没有改变我的风格或语气。使用 AI 让我始终保持创作动力，并且它经常给我带来新颖的想法。

像我在写作时所做的那样，使用 AI 作为一种共智是 AI 最有价值的地方。如果可以的话，找出一种方法自己来做这件事。作为一个起点，遵循第一个原则（邀请 AI 参与到每件事中）直到你开始了解你工作中的「Jagged Frontier」（不规则边界）。这将让你知道 AI 能做什么和不能做什么。然后开始像 Centaur 一样工作。将你讨厌但可以轻松检查的任务（如写无意义的报告或低优先级的电子邮件）交给 AI，并看看它是否改善了你的生活。你可能会自然地过渡到 Cyborg 使用，因为你发现 AI 在克服小障碍和处理棘手任务上是不可或缺的。那时，你已经找到了一个共智。

需要注意的是，人工智能在不断变化，这些任务类型之间的界限是模糊的，并且随着人工智能能力的提高，这些界限可能会发生变化。我们现在委派给人工智能的任务，是因为它的能力尚未完美，但未来随着其性能在更多领域达到人类水平，这些任务可能会完全自动化。同样，如果人工智能变得足够擅长流畅地协作而不仅仅是辅助，一些「仅我任务」(Just Me Tasks）可能最终会进入「半人半马类别」(Centaur category)。随着人类与人工智能的共同进步，我们尚未能理解的新创造领域可能会为双方的共生合作打开大门。同时，我们也可能决定某些情感充沛或伦理上有问题的责任应该完全由人类承担，这种趋势也会反向发展。

对于工人来说，这些流动的类别意味着人工智能的影响将是逐渐感受到的，因为我们会逐步适应其不断增强的能力，而不是一次性的冲击。随着人类和机器能力的交集演变，我们对适当角色和责任的概念也必须随之变化。而且，工人在使用人工智能时，可能会与公司和组织的做法越来越脱节。

### 6.4 Secret Task Automation

Today, billions of people have access to Large Language Models and the productivity benefits they bring. And from decades of research in innovation studying everyone from plumbers to librarians to surgeons, we know that, when given access to general purpose tools, people figure out ways to use them to make their jobs easier and better. The results are often breakthrough inventions, ways of using AI that could transform a business entirely. People are streamlining tasks, taking new approaches to coding, and automating time-consuming and tedious parts of their jobs. But the inventors aren't telling their companies about their discoveries; they are keeping them secret. There are at least three reasons these Cyborgs and Centaurs stay secret. But they all boil down to the same thing: people don't want to get in trouble.

The problems start with organizational policy. Many companies, from J.P.Morgan to Apple, initially banned ChatGPT use, often because of legal concerns. But these bans had a big effect . . . they caused employees to bring their phones into work and access AI from personal devices. While data is hard to come by, I have already met many people at companies where AI is banned who are using this workaround—and those are just the ones willing to admit it! This type of shadow IT use is common in organizations, but it incentivizes workers to keep quiet about their innovations and productivity gains.

And that isn't the only reason AI users fear revealing that they are Cyborgs. Much of the value of AI use comes from people not knowing you are using it. The ability of AI to write in ways that seem human is very powerful, but only if people think it is coming from an actual human. We know from research that when people learn they are receiving AI-created content, they judge it differently than if they assume it comes from a human. Unsurprisingly, when I conducted a bit of an unscientific Twitter poll, over half of generative AI users reported using the technology without telling anyone, at least some of the time.

All this shadow use leads to the final concern, the justified worry that workers might be training their own replacements by figuring out how to work with AI. If someone has figured out how to automate 90 percent of a particular job, and they tell their boss, will the company fire 90 percent of their coworkers? Better not to speak up.

All the usual ways in which organizations try to respond to new technologies don't work well for AI. They are all far too centralized and far too slow. The IT department cannot easily build an in-house AI model, and certainly not one that competes with one of the Frontier LLMs. Consultants and system integrators have no special knowledge about how to make AI work for a particular company, or even the best ways to use AI overall. The innovation groups and strategy councils inside organizations can dictate policy, but there is no reason to believe that the corporate leaders of any organization are going to be wizards at understanding how AI might help a particular employee with a particular task. In fact, they are likely pretty bad at figuring out the best-use cases for AI. Individual workers, who are keenly aware of their problems and can experiment a lot with alternate ways of solving them, are far more likely to find powerful and targeted uses.

At least for now, the best way for an organization to benefit from AI is to get the help of their most advanced users while encouraging more workers to use AI. And that is going to require a major change in how organizations operate. First, they need to recognize that the employees who are figuring out how best to use AI might be at any level of the organization, with any sort of history or past performance record. No company hired employees based on their AI skills, so AI skills might be anywhere. Right now, there is some evidence that the workers with the lowest skill levels are benefiting the most from AI, and so might have the most experience in using it, but the picture is still not clear. As a result, companies need to include as much of their organization as possible in their AI agenda, a democratic turn of events that many companies would rather avoid.

Second, leaders need to figure out a way to decrease the fear associated with revealing AI use. Assuming early studies are true and we see productivity improvements of 20 to 80 percent on various high-value professional tasks, I fear the natural instinct among many managers is "fire people, save money." But it does not need to be that way. There are many reasons for companies to not turn efficiency gains into head-count reduction or cost reduction. Companies that figure out how to use their newly productive workforce should be able to dominate any company that tries to keep their post-AI output the same as their pre-AI output, just with fewer people. And companies that commit to maintaining their workforce will likely have employees as partners who are happy to teach others about the uses of AI at work, rather than scared workers who hide their AI for fear of being replaced.

Convincing employees that this is the case is another matter. Perhaps organizations can offer guarantees that no employees will be laid off as a result of AI use, or promise that workers can use the time they free up using AI to work on more interesting projects, or even end work early. But there are hints buried in the early studies of AI about a way forward, toward a different working environment altogether. Workers, while worried about AI, tend to like using it because it removes the most tedious and annoying parts of their job, leaving them with the most interesting tasks. So, even as AI removes some previously valuable tasks from a job, the work that is left can be more meaningful and more high-value. This is not inevitable, of course, so managers and leaders must decide whether and how to commit themselves to reorganizing work around AI in ways that help, rather than hurt, their human workers. You need to ask: What is your vision about how AI makes work better rather than worse? And this is where organizations with high degrees of trust and good cultures will have an advantage. If your employees don't believe you care about them, they will keep their AI use hidden.

Third, organizations should highly incentivize AI users to come forward, and expand the number of people using AI overall. That means not just permitting AI use but also offering substantial rewards to people finding substantial opportunities for AI to help. Think cash prizes that cover a year's salary. Promotions. Corner offices. The ability to work from home forever. With the potential productivity gains possible due to LLMs, these are small prices to pay for truly breakthrough innovation. And large incentives also show that the organization is serious about this issue.

Finally, companies need to start thinking about the other component of effectively using AI: systems. The pressure for organizations to take a stand on a technology that affects their most highly paid workers will be immense, as will the value of these workers becoming more productive. Without a fundamental restructuring of how organizations work, the benefits of AI will never be recognized.

秘密任务自动化

如今，数十亿人都能使用大语言模型（Large Language Models）并从中获益。几十年的创新研究表明，无论是水管工、图书管理员还是外科医生，当他们获得通用工具时，都会找到方法让工作变得更轻松、更高效。结果往往是突破性的发明，利用 AI 的方法甚至可以彻底改变一个企业。许多人正在简化任务、采用新的编码方法，并自动化那些耗时且乏味的工作部分。然而，这些发明者并没有告诉公司他们的发现，而是选择保密。至少有三个原因导致这些 Cyborgs 和 Centaurs 保持秘密，但归根结底都是因为：他们不想惹麻烦。

问题始于公司政策。许多公司，例如 J.P.Morgan 和 Apple，最初因为法律问题而禁止使用 ChatGPT。但这些禁令产生了很大影响…… 它们迫使员工在工作时使用个人设备访问 AI。虽然很难获取确切数据，但我已经遇到许多在禁止 AI 的公司工作的员工，他们通过这种方式绕过了禁令 —— 而这些只是愿意承认的人！这种「影子 IT」现象在组织中很常见，但它使员工倾向于对他们的创新和生产力提升保持沉默。

AI 用户害怕暴露自己是「赛博格」还有另一个原因。AI 的价值在于人们不知道你在使用它。AI 能够以看似人类的方式写作，这种能力非常强大，但前提是人们认为这是人类写的。研究表明，当人们知道内容是 AI 生成时，他们的评价会与认为是人类写的有所不同。不出所料，我在 Twitter 上进行了一次非正式调查，结果显示超过一半的生成式 AI 用户至少有时会在不告诉任何人的情况下使用该技术。

这种暗中使用带来了一个最终的担忧：工人可能会通过学习如何与 AI 共事来训练自己的替代者。如果有人找到了如何自动完成 90% 的工作，并告诉了老板，公司会不会因此解雇 90% 的同事？因此，最好保持沉默。

组织应对新技术的常规方式在 AI 上效果不佳。它们过于集中化且反应迟缓。IT 部门无法轻易建立内部 AI 模型，更不用说与 Frontier LLMs 竞争了。顾问和系统集成商对在特定公司中如何有效使用 AI 并没有特别的见解。组织内的创新小组和战略委员会可以制定政策，但企业领导者未必懂得如何让 AI 帮助员工完成特定任务。实际上，他们可能很不擅长发现 AI 的最佳应用场景。个别员工了解自己的问题，并且可以尝试多种解决方法，更有可能找到强大且有针对性的用途。

至少目前，组织从 AI 中受益的最佳方式是获得最有经验用户的帮助，同时鼓励更多的员工使用 AI。这需要组织在运作方式上进行重大改变。首先，他们需要认识到，正在摸索如何最好地使用 AI 的员工可能处于组织的任何层级，具有任何背景或过往绩效记录。没有公司是基于 AI 技能来雇佣员工的，所以 AI 技能可能存在于任何地方。目前，有一些证据表明，技能水平较低的员工从 AI 中受益最多，因此可能在使用 AI 方面经验最丰富，但情况仍不明确。因此，企业需要尽可能多地将其组织纳入 AI 议程，这是一种许多公司宁愿避免的民主化转变。

其次，领导者需要找到一种方法来减少与揭示 AI 使用相关的恐惧。假设早期研究属实，并且我们在各种高价值的专业任务上看到生产力提升 20% 到 80%，我担心许多管理者的自然反应是「解雇员工，节省资金」。但不需要那样。有很多理由让公司不将效率提升转化为员工人数减少或成本降低。那些找到如何使用其新生产力员工的公司，应该能够主导那些试图保持 AI 之前产出水平的公司，只是员工减少了。而那些承诺保持员工数量的公司，可能会有乐于教其他人如何在工作中使用 AI 的员工伙伴，而不是因害怕被取代而隐藏其 AI 使用的员工。

说服员工接受这个观点是一个挑战。或许组织可以做出不裁员的保证，或承诺员工能利用 AI 节省的时间从事更有趣的项目，甚至早些下班。不过，早期的 AI 研究暗示了一种全新的工作环境。尽管员工担心 AI，但他们往往喜欢使用它，因为 AI 能去除工作中最单调和烦人的部分，让他们处理更有趣的任务。因此，即使 AI 取代了一些过去有价值的任务，剩下的工作也可能变得更有意义和价值。这并非必然，所以管理者需要决定如何重新组织工作，使 AI 有利于人类员工。你需要问自己：AI 如何让工作变得更好？在这方面，有高信任度和良好文化的组织会有优势。如果员工不相信你关心他们，他们会隐藏自己使用 AI 的情况。

第三，组织应该大力激励 AI 用户，并扩大 AI 的使用范围。这意味着不仅要允许使用 AI，还要为那些发现 AI 重大帮助机会的人提供丰厚奖励。比如一年工资的现金奖励、晋升、角落办公室、永远在家办公的机会。考虑到大语言模型（LLMs）带来的潜在生产力提升，这些都是微不足道的代价。而且，巨大的激励措施也显示了组织对这个问题的重视。

最终，公司需要开始考虑有效使用 AI 的另一个重要组成部分：系统。组织在采用能影响其高薪员工的技术时，会面临巨大的压力，因为这些员工的生产力提升将带来巨大的价值。如果不对组织的运行方式进行根本性的重组，AI 的好处将无法完全实现。

### 6.5 From Tasks to Systems

We often take for granted the systems we use to structure and coordinate work in our organizations. We assume they are natural ways of getting things done. But in reality, they are historical artifacts, shaped by the technological and social conditions of their times. The organizational chart, for example, was originally made to run railroads in the 1850s. Developed by early railroad barons, they created a hierarchical system of authority, responsibility, and communication that enabled them to control and monitor the operations of their railroad empire. Enabled by the telegraph, they integrated humans into a clear hierarchy, with bosses giving orders that flowed through the rails and telegraph lines to the workers at the bottom of the chart. The system was so successful that it was soon adopted by other industries and organizations, becoming the standard model of bureaucracy for the twentieth century.

Another system emerged from a different combination of human limitations and technology: the assembly line. Generally credited to Henry Ford in the early twentieth century, it allowed his company to mass-produce automobiles at a lower cost and higher speed. He realized that humans were not very good at performing complex and varied tasks, but they were very good at performing simple and repetitive work. He also noticed that technology could help him synchronize and optimize the flow of work, by using standardized tools and parts, and new technologies like conveyor belts and timers. He divided the production process into small and simple tasks, and assigned them to workers who performed them repeatedly and efficiently. His system was so successful that it revolutionized the manufacturing industry, creating economies of scale and scope and enabling mass consumption and customization.

The internet marked another new set of technologies to organize and control work, which is why we have seen the emergence of new systems of work organization and management in recent decades, such as agile software development, lean manufacturing, holacracy, and self-managing teams. Enabled by waves of tools ranging from email to complex enterprise software, these management trends took new, data-driven approaches to organizing. But, like all work before, they still rely on human capabilities and limitations. Human attention remains finite, our emotions are still important, and workers still need bathroom breaks. The technology changes, but workers and managers are just people.

This is what AI may alter. By acting as a co-intelligence managing work, or at least helping managers manage work, the enhanced capabilities of LLMs could radically change the experience of work. A single AI can talk to hundreds of workers, offering advice and monitoring performance. They could mentor, or they could manipulate. They could guide decisions in ways that are subtle or overt.

Companies have been experimenting with forms of computerized control over workers since long before this generation of AI. Time clocks, cameras, and other forms of monitoring have been common for over a century, but these approaches kicked into high gear with the rise of pre-LLM AI, and especially the use of algorithms to control work and workers. Think of the gig worker hoping Uber will give them a good stream of customers, despite receiving a low rating from an angry passenger, or the UPS driver whose every minute of driving is scrutinized by an algorithm to see if they were efficient enough to keep their job. Katherine Kellogg of MIT, along with Melissa Valentine and Angèle Christin of Stanford, outlined how these new types of control were different from previous forms of management. Where managers previously had limited information about what workers were doing, algorithms were comprehensive and instantaneous, using massive amounts of data from many sources to track workers. The algorithms also work interactively, channeling workers in real time to whatever task the company wanted. And they are opaque—their biases, and even the way they make decisions—are hidden from workers.

Wharton professor Lindsey Cameron saw this firsthand when she was a gig-working driver for six years as part of an intense ethnographic study of how workers deal with algorithmic management. Forced to depend on Uber or Lyft's algorithms to find work, they engage in covert forms of resistance to gain some control over their destiny. For example, drivers might worry that a particular rider could give them lower ratings (thus hurting their future earnings), so they will convince the rider to cancel before pickup, perhaps by claiming that the driver can't see the potential pickup spot. But even these forms of resistance do not free drivers from the algorithm, which controls where they go, how much they make, and how they spend their time.

We could imagine how LLMs might supercharge this process, creating an even more comprehensive panopticon: in this system, every aspect of work is monitored and controlled by AI. AI tracks the activities, behaviors, outputs, and outcomes of workers and managers. AI sets goals and targets for them, assigns tasks and roles to them, evaluates their performance, and rewards them accordingly. But, unlike the cold, impersonal algorithm of Lyft or Uber, LLMs might also provide feedback and coaching to help workers improve their skills and productivity. AI's ability to act as a friendly adviser could sand down the edges of algorithmic control, covering the Skinner box in bright wrapping paper. But it would still be the algorithm in charge. If history is a precedent, this is a likely path for many companies.

But other, more utopian possibilities also exist. We don't need to subject vast numbers of humans to machine overlords. Rather, LLMs could help us flourish by making it impossible to ignore the truth any longer: a lot of work is really boring and not particularly meaningful. If we acknowledge that, we can turn our attention to improving the human experience of work.

In surveys, people report being bored about 10 hours a week at work, a shockingly large percentage of the time. While not all work has to be thrilling, a huge amount of it is boring for no reason, and that seems to be a big problem. Not only is boredom a top cause for people leaving companies, but we do crazy stuff when bored. One small study of undergraduates found that 66 percent of men and 25 percent of women choose to painfully shock themselves rather than sit quietly with nothing to do for 15 minutes. Boredom doesn't just lead us to hurt ourselves; 18 percent of bored people killed worms when given a chance (only 2 percent of non-bored people did). Bored parents and soldiers both act more sadistically. Boredom is not just boring; it is dangerous in its own way.

In an ideal world, managers would spend time trying to end the useless and repetitive work that leads to boredom, and to adjust work to focus on the more engaging tasks. Despite years of management advice, however, most official rituals, forms, and requirements persist long past their usefulness. If humans couldn't end this tedious work, maybe machines can.

We have already outsourced the worst part of writing (checking grammar) and math (long division) to machines like spell checkers and calculators, which freed us from these tedious tasks. It would be natural to use LLMs to extend the process. And this is indeed what we have seen in some early research on using AI for work. People who use AI to do tasks enjoy work more and feel they are better able to use their talents and abilities. The ability to outsource crappy, meaningless tasks to the AI can be freeing. The worst parts of your job go to AI so that you get to focus on the good stuff.

Thus, if we want to think about the first work we truly give to AIs, maybe we should start the way every other automation wave has started: with the tedious, (mentally) dangerous, and repetitive. Companies and organizations could start with thinking about how to make boring processes "AI friendly," allowing machines (with human supervision) to fill our required forms. Rewarding workers for slaying boring tasks with AI could also help streamline operations, while making everyone happier. And if this sheds light on tasks that could be safely automated with no decrease in value, so much the better. Maybe that is work that can be eliminated. It is certainly a better place to start than the alternative, algorithmic control.

从任务到系统

我们常常认为，在组织中用来构建和协调工作的系统是理所当然的，自然而然的完成事情的方式。但实际上，这些系统是历史的产物，受到当时技术和社会条件的影响。例如，组织结构图最初是在 1850 年代为了管理铁路而创建的。早期的铁路大亨们开发了一个权威、责任和沟通的层级系统，使他们能够控制和监控铁路帝国的运营。在电报技术的支持下，他们将人们整合到一个清晰的层级结构中，老板通过铁轨和电报线将命令传达给最底层的工人。这个系统非常成功，很快被其他行业和组织采用，成为二十世纪的标准官僚模式。

另一个基于人类局限性与技术组合的系统是装配线。通常认为是 Henry Ford 在二十世纪初发明的，这使他的公司能够以更低的成本和更高的速度大规模生产汽车。他认识到人类不擅长执行复杂且多样化的任务，但在执行简单且重复的工作时非常出色。他还发现，通过使用标准化的工具和零件，以及新的技术如传送带和计时器，可以同步和优化工作流程。因此，他将生产过程分解为小而简单的任务，并让工人反复高效地执行。这一系统非常成功，彻底改变了制造业，带来了规模经济和范围经济，并推动了大规模消费和定制。

互联网的出现标志着组织和控制工作的新技术，近年来也因此涌现了新的工作组织和管理系统，例如敏捷软件开发、精益制造、全体自治和自我管理团队。在从电子邮件到复杂的企业软件等工具的推动下，这些管理趋势采用了新的数据驱动方法来组织工作。然而，和以往的工作一样，它们仍然依赖于人类的能力和局限。人类的注意力有限，情感依然重要，工人们仍然需要休息。尽管技术在变化，工人和管理者还是人类。

这是 AI 可能改变的地方。通过作为共同智能体来管理工作，或至少帮助管理者管理工作，LLM 的增强能力可能会彻底改变工作的体验。单个 AI 可以与数百名工人交流，提供建议并监控绩效。它们可以指导，也可以操控，能够以微妙或明显的方式引导决策。

公司很早就在尝试使用计算机化手段来控制员工。打卡钟、摄像头等监控手段已经存在了一个多世纪。不过，这些方法在大语言模型（LLM）之前的 AI 时代，特别是使用算法来控制工作和员工时，得到了极大提升。想想那些希望 Uber 给他们分配更多客户的零工工人，即使他们因为愤怒乘客的低评分而蒙受损失；或者那些每一分钟的驾驶时间都被算法监控的 UPS 司机，以判断他们是否高效到足以保住工作。MIT 的 Katherine Kellogg 和斯坦福的 Melissa Valentine 及 Angèle Christin 阐述了这些新型控制手段与传统管理方式的不同之处。过去，经理只能掌握有限的员工信息，而现在的算法利用来自多种渠道的海量数据，即时且全面地追踪员工。这些算法还能实时互动，引导员工完成公司需要的任务。而且，这些算法是不透明的 —— 它们的偏见，甚至决策方式都对员工隐藏。

沃顿商学院教授 Lindsey Cameron 在进行一项为期六年的人种志研究时，亲身体验了这一点。她作为一名零工司机，深入研究了工人如何应对算法管理。由于必须依赖 Uber 或 Lyft 的算法找工作，司机们采取了一些隐蔽的抵抗手段来争取对自身命运的控制。例如，司机可能会担心某位乘客给他们低评分（从而影响未来收入），于是会在接单前说服乘客取消订单，可能谎称看不到接客地点。但即使这样，司机们也无法完全摆脱算法的控制，因为算法决定着他们的去向、收入和时间安排。

我们可以想象，大语言模型（LLM）如何加速这一过程，建立一个更全面的监控系统：在这个系统中，AI 监控和控制工作的每个方面。AI 追踪工人和管理者的活动、行为、产出和结果。AI 为他们设定目标，分配任务和角色，评估他们的表现，并给予相应的奖励。与 Lyft 或 Uber 那种冷冰冰的算法不同，大语言模型还可能提供反馈和辅导，帮助工人提高技能和生产力。AI 的友好顾问角色可以减轻算法控制的严苛感，尽管表面上包装得很漂亮，实际仍是算法在掌控。如果历史可以作为参考，这很可能是许多公司未来的发展方向。

但也存在其他更理想的可能性。我们不必让大量的人类屈从于机器的统治。相反，大语言模型可以帮助我们实现更好的发展，使我们无法再忽视一个事实：许多工作实际上非常枯燥且意义不大。如果我们承认这一点，就可以转而关注如何改善人们的工作体验。

调查显示，人们每周有约 10 小时感到无聊，这个比例惊人。虽然并非所有工作都必须令人兴奋，但有大量工作确实无聊得毫无必要，这似乎是一个大问题。无聊不仅是人们离职的主要原因之一，还会导致我们做出疯狂的举动。一项针对大学生的小型研究发现，66% 的男性和 25% 的女性宁愿痛苦地电击自己，也不愿在什么都不做的情况下安静地坐 15 分钟。无聊不仅会让我们伤害自己；当有机会时，18% 的无聊者会杀死蠕虫（而只有 2% 的非无聊者会这样做）。无聊的父母和士兵也更容易表现出残忍的行为。无聊不仅仅是无聊；它在某种程度上是危险的。

在理想的情况下，管理者应该花时间去消除那些无聊且重复的无用工作，并调整工作内容，让员工更专注于有趣的任务。然而，尽管多年来有很多管理建议，大多数官方的流程、表格和要求依然存在，超出了它们的实际用处。如果人类无法结束这些枯燥的工作，也许机器可以。

我们已经将写作中最繁琐的部分（如检查语法）和数学中的长除法外包给拼写检查器和计算器等工具，这让我们摆脱了这些乏味的任务。自然地，我们可以利用大语言模型（LLM）来进一步扩展这一过程。这一点在早期关于使用 AI 完成工作的研究中已经有所体现。使用 AI 完成任务的人更享受工作，并且感觉自己更能发挥才能。将那些琐碎、无意义的任务交给 AI 处理，可以让人们感到解放。工作的最糟糕部分由 AI 负责，你就可以专注于更有价值的内容。

因此，如果我们考虑将第一批工作真正交给 AI，也许我们应该从每一波自动化浪潮开始的地方着手：那些乏味的、（精神上）危险的和重复的任务。公司和组织可以首先考虑如何使枯燥的流程变得「AI 友好」，让机器（在人类监督下）填写必要的表格。通过奖励员工使用 AI 消除无聊任务，不仅能帮助简化操作流程，还能提升整体的工作满意度。如果这个过程中发现某些任务可以在不降低价值的情况下被安全地自动化，那就更好了。这样的任务也许是可以被完全消除的。这显然比另一种选择 —— 算法控制 —— 要好。

### 6.6 From Systems to Jobs

And now, having covered tasks and systems, we can return to the question of jobs and the extent to which AI might replace human workers. As we have seen, it seems very likely that AI will take over human tasks. If we take advantage of all that AI has to offer, this could be a good thing. Boring tasks, or tasks that we are not good at, can be outsourced to AI, leaving good and high-value tasks to us, or at least to AI-human Cyborg teams. This fits into historical patterns of automation, where the bundles of tasks that make up jobs change as new technologies are developed. Accountants once were in charge of calculating numbers by hand; now they use a spreadsheet—they are still accountants, but their bundles of tasks have changed.

When we start to take into account the systems in which jobs operate, we see other reasons to suspect slower, rather than faster, change in the nature of jobs. Humans are built deep into the fabric of every aspect of our organizations. You cannot easily replace a human with a machine without tearing that fabric. Even if you could replace a doctor with an AI overnight, would patients be okay being seen by a machine? How would liability rules work? How would other health-care professionals adjust? Who would do the other tasks that the doctor was in charge of, like training interns or being part of professional organizations? Our systems will prove more resistant to change than our tasks.

But that doesn't mean some industries won't change quickly as their fundamental economics shift. General Purpose Technologies both destroy and create new fields of work. Stock photography, a $3 billion per year market, is likely to largely disappear as AIs, ironically trained on these very images, can easily produce customized images. Or consider the $110 billion a year call-center industry, which will reckon with the impact of fine-tuned AIs handling ever more tasks that were once done by humans, acting like a phone tree service that actually works. At the same time, entirely new industries may appear, like those servicing and deploying AI systems. And existing industries may become supercharged. For example, more scientists and engineers are likely to be required to modify and adapt old systems to take advantage of AI.

So it may not be a big surprise that over two-thirds of a panel of economists expect, on average, for AI to have very little effect on overall jobs in the next few years, even as AI boosts the economy overall. That doesn't mean new technologies never displace workers en masse, though. In fact, it has happened to one of the biggest job categories ever held by women—telephone operators. By the 1920s, 15 percent of all American women had worked as operators, and AT&T was the largest employer in the United States. AT&T decided to remove the old-school telephone operators and replace them with much cheaper direct dialing. Operator jobs dropped rapidly by 50 to 80 percent. As might be expected, the job market overall adjusted quickly, as young women found other roles, like secretarial positions, that offered similar or better pay. But the women with the most experience as operators took a larger hit to their long-term earnings, as their tenure in a now extinct job did not translate to other fields. So, while jobs usually adjust to automation, they do not always, at least not for everyone.

Of course, there are also reasons why AI might be different from other technological waves. It is the first wave of automation that broadly affects the highest-paid professional workers. Plus, AI adoption is happening much more quickly, and much more broadly, than previous waves of technology. And we are still unclear as to what the limits, and possibilities, of this new technology are, how quickly they will continue to grow, and how ahistorical and strange the effects might be.

Knowledge work is famous for very large differences in abilities among workers. For example, repeated studies found that differences between the programmers in the top 75th percentile and those in the bottom 25th percentile can be as much as 27 times along some dimensions of programming quality. And my own research has found that large gaps exist between good and bad managers. But AI may change all that.

In study after study, the people who get the biggest boost from AI are those with the lowest initial ability—it turns poor performers into good performers. In writing tasks, bad writers become solid. In creativity tests, it boosts the least creative the most. And among law students, the worst legal writers turn into good ones. And in a study of early generative AI at a call center, the lowest-performing workers became 35 percent more productive, while experienced workers gained very little. In our study in BCG, we found similar effects. Those who had the weakest skills benefited the most from AI, but even the highest performers gained.

This suggests the potential for a more radical reconfiguration of work, where AI acts as a great leveler, turning everyone into an excellent worker. The effects of this could be as profound as the automation of manual labor. It didn't matter how good you were at digging, because you still couldn't dig as well as a steam shovel. In this case, the nature of jobs will change a lot, as education and skill become less valuable. With lower-cost workers doing the same work in less time, mass unemployment, or at least underemployment, becomes more likely, and we may see the need for policy solutions, like a four-day workweek or universal basic income, that reduce the floor for human welfare.

In the short term, then, we might expect to see little change in employment (but many changes in tasks), but, as Amara's Law, named after futurist Roy Amara, says: "We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run." The future is remarkably unclear in the long term. AI will transform some industries more than others, just as some jobs will become radically different while others don't change at all. Right now, no one can tell you exactly what will happen for any particular company or school. And any advice will be obsolete when the next generation of AI is released. There is no outside authority. We have agency over what happens next, for good and for bad.

从系统到工作

现在我们已经讨论了任务和系统，接下来可以回到工作这个话题，以及 AI 在多大程度上可能取代人类工作者的问题。正如我们所见，AI 很可能会接管一些人类的任务。如果我们充分利用 AI 的优势，这或许是件好事。那些无聊的任务，或者我们不擅长的任务，可以交给 AI 来处理，而我们则可以专注于更有价值的任务，或者与 AI 组成混合团队。这与历史上的自动化趋势一致，随着新技术的发展，工作的任务内容会发生变化。比如，过去会计需要手工计算，现在他们使用电子表格，他们仍然是会计，只是任务内容改变了。

当我们考虑工作的运作系统时，会发现另一些原因表明工作性质的改变可能不会太快。人类深深嵌入到组织的各个方面。你不能简单地用机器取代人类而不破坏这种结构。即使你能在一夜之间用 AI 取代医生，患者会愿意让机器看病吗？责任规则将如何制定？其他医护人员又该如何调整？谁来完成医生负责的其他任务，比如培训实习生或参与专业组织？我们的系统比单纯的任务更难以改变。

但是，这并不意味着一些行业不会因为其基本经济结构的变化而迅速改变。通用技术（General Purpose Technologies）既能摧毁也能创造新的工作领域。比如，年收入达到 30 亿美元的图库摄影市场，可能会因为 AI 的普及而大量消失。讽刺的是，这些 AI 正是通过这些图片进行训练的，能够轻松生成定制图片。再看看每年 1100 亿美元的呼叫中心行业，它将面对经过微调的 AI 处理越来越多的任务，像一个真正有效的电话树服务。同时，完全新的行业可能会出现，比如专门服务和部署 AI 系统的行业。而现有行业也可能会被大大增强。例如，可能需要更多的科学家和工程师来改造和适应旧系统，以利用 AI 带来的优势。

因此，超过三分之二的经济学家小组平均预计，AI 在未来几年对整体就业的影响会非常小，尽管 AI 将整体提升经济。这并不意味着新技术不会大规模取代工人。事实上，这种情况曾经发生在女性主导的一个最大职业类别 —— 电话接线员上。到 1920 年，15% 的美国女性曾经做过接线员，而 AT&T 是美国最大的雇主。AT&T 决定淘汰老式电话接线员，用更便宜的直接拨号取而代之。接线员的职位迅速减少了 50% 到 80%。正如预期的那样，整体就业市场迅速进行了调整，年轻女性找到了其他职位，比如秘书，这些职位提供了相似或更好的薪酬。但最有经验的接线员在长期收入方面受到了更大的打击，因为她们在这个已经消失的工作中的经验无法转移到其他领域。所以，虽然工作通常会适应自动化，但并不总是对每个人都一样。

当然，AI 也有其不同于其他技术浪潮的原因。首先，它是第一波广泛影响高收入专业工作者的自动化浪潮。而且，AI 的采用速度远超以往的技术浪潮，其影响范围也更为广泛。我们仍然不清楚这项新技术的限制与潜力，以及其增长速度和可能带来的非历史性和奇特的影响。

知识型工作因员工之间的巨大能力差异而闻名。例如，多项研究发现，在编程质量的某些方面，位于前 75 百分位的程序员和位于后 25 百分位的程序员之间的差异可以高达 27 倍。我自己的研究也发现了优秀与糟糕的管理者之间存在巨大的差距。但是，AI 可能会改变这一切。

许多研究显示，那些初始能力最弱的人从 AI 中获得的提升最大 ——AI 可以让表现不佳者变得优秀。在写作任务中，糟糕的写作者可以变得扎实。在创造力测试中，AI 对最不具创造力的人提升最大。在法学院学生中，最差的法律写作者变成了好的写作者。而在一项关于呼叫中心早期生成式 AI（Generative AI）的研究中，表现最差的工人生产力提高了 35%，而有经验的工人几乎没有变化。在我们对 BCG 的研究中，我们发现了类似的效果。技能最弱的人从 AI 中受益最大，但即使是表现最好的员工也有所提升。

这表明未来工作可能会进行更为激进的重组，即 AI 作为一个强大的平衡器，将每个人都变成优秀的工人。其影响可能会像手工劳动的自动化一样深远。无论你挖得多好，你都无法比得上蒸汽铲。在这种情况下，工作的性质会发生巨大变化，教育和技能的价值将降低。随着低成本工人在更短的时间内完成同样的工作，大规模失业或至少是就业不足的可能性会增加，我们可能需要一些政策解决方案，如四天工作周或全民基本收入，以保障基本生活。

短期内，我们可能不会看到就业的显著变化（但任务会有所不同），但正如未来学家 Roy Amara 提出的阿马拉法则所言：「我们往往高估技术在短期内的影响，而低估其在长期内的影响。」长期来看，未来依然不确定。AI 将对某些行业产生比其他行业更大的影响，就像某些工作会发生根本变化，而其他工作可能完全不变一样。现在，没有人能确切预测任何特定公司或学校的未来。而且，当下一代 AI 发布时，任何当前的建议都可能变得过时。没有外部权威。我们对未来的发展拥有主动权，无论结果是好是坏。