Ethan Mollick.(2024).2024029Co-Intelligence_Living-and-Working-with-AI.Penguin Publishing Group =>

## 0701. AI AS A TUTOR

Here's a secret: we have long known how to supercharge education; we just can't quite pull it off. Benjamin Bloom, an educational psychologist, published a paper in 1984 called " The 2 Sigma Problem." In this paper, Bloom reported that the average student tutored one-to-one performed two standard deviations better than students educated in a conventional classroom environment. This means that the average tutored student scored higher than 98 percent of the students in the control group (though not all studies of tutoring have found as large an impact). Bloom called this the two sigma problem, because he challenged researchers and teachers to find methods of group instruction that could achieve the same effect as one-to-one tutoring, which is often too costly and impractical to implement on a large scale. Bloom's two sigma problem has inspired many studies and experiments to explore alternative teaching methods that could approximate the benefits of direct tutoring. However, none of these methods has been able to consistently match or surpass the two sigma effect of one-to-one tutoring that Bloom claimed. This suggests that there is something unique and powerful about the interaction between a tutor and a student that cannot be easily replicated by other means. So it is not surprising that a powerful, adaptable, and cheap personalized tutor is the holy grail of education.

This is where AI comes in. Or where AI, hopefully, comes in. As remarkable as today's AIs are, we have not reached the point where they can replace human teachers with magical textbooks. Though we are certainly at an inflection point where AI will reshape how we teach and learn, both in schools and after we leave them. At the same time, the ways in which AI will impact education in the near future are likely to be counterintuitive. They won't replace teachers but will make classrooms more necessary. They may force us to learn more facts, not fewer, in school. And they will destroy the way we teach before they improve it.

7 AI 作为导师

其实我们早就知道如何显著提升教育质量，但一直未能实现。教育心理学家 Benjamin Bloom 在 1984 年发表了一篇名为《2 Sigma 问题》的论文。在这篇论文中，Bloom 报告称，接受一对一辅导的学生平均成绩比传统课堂环境中的学生高出两个标准差。也就是说，接受辅导的学生成绩超过了控制组中 98% 的学生（尽管并非所有辅导研究都得出了如此大的效果）。Bloom 将其称为「两西格玛问题」，因为他希望研究人员和教师能找到群体教学的方法，达到与一对一辅导相同的效果。然而，一对一辅导通常成本高且难以大规模实施。

受 Bloom 的两西格玛问题启发，许多研究和实验尝试探索可以接近一对一辅导效果的替代教学方法。然而，没有一种方法能够稳定地达到或超越 Bloom 所描述的一对一辅导的两西格玛效果。这表明，导师与学生之间的互动有其独特且强大的作用，其他方法难以复制。因此，一个强大、灵活且廉价的个性化导师成为了教育领域的圣杯。

这正是 AI 可以大显身手的地方。或者更确切地说，这是我们希望 AI 能够大显身手的地方。虽然当今的 AI 已经非常先进，但还远未达到用神奇教科书取代人类教师的程度。不过，我们确实处于一个转折点，AI 将重新定义我们在学校和未来的学习方式。同时，AI 在近期内对教育的影响可能会出人意料。它们不会取代教师，但会让教室变得更为重要。它们可能会让我们在学校学习更多的知识，而不是更少。此外，它们可能会在改进教学方法之前先颠覆现有的教学方式。

### 7.1 After the Homework Apocalypse

Education has changed remarkably little for centuries. Students gather in a class to be taught by a teacher. They do homework to practice what they learned and then get tested to ensure they have retained their knowledge. Then they move on to the next topic. At the same time, research on the science of teaching has advanced a lot. For example, we know that in-class lectures are not the most effective way to teach and that topics need to be interwoven together in order for students to retain what they know. Unhappily for students, however, research shows that both homework and tests are actually remarkably useful learning tools.

So it is a blow that the first impact of Large Language Models at scale was to usher in the Homework Apocalypse. Cheating was already common in schools. One study of eleven years of college courses found that when students did their homework in 2008, it improved test grades for 86 percent of them, but it helped only 45 percent of students in 2017. Why? Because over half of students were looking up homework answers on the internet by 2017, so they never got the benefits of homework. And that isn't all. By 2017, 15 percent of students had paid someone to do an assignment, usually through essay mills online. Even before generative AI, 20,000 people in Kenya earned a living writing essays full time.

With AI, cheating is trivial. In fact, the core capabilities of AI seem almost built for cheating. Think about common types of homework assignments. Many of them involve reading and then summarizing or reporting on what was read. These assignments expect that students will absorb the reading and engage in some sort of intellectual struggle with it. AI, however, is very good at summarizing and applying information. And it can now read PDFs. Or even entire books. This means that students will be tempted to ask the AI for help summarizing written content. Sure, the results can contain errors and simplifications, but even if they are correct, these summaries will shape a student's thinking. Further, taking this shortcut may lower the degree to which the student cares about their interpretation of a reading, making in-class discussions less intellectually useful because the stakes are lower. Or consider problem sets. We already saw how AI is acing key exams for graduate school, so your kid's fourth-grade geometry assignment is unlikely to stand in its way.

And, of course, AI has come for the king of assignments, the essay. Essays are ubiquitous in education, where they serve many purposes, from demonstrating how students think to providing an opportunity for reflection. But they are also really easy for any LLM to generate, and AI-based essays are getting better and better. At first, AI style was conspicuous, but newer models write in a less awkward and circular way and can easily be prompted to write in a style appropriate for a student. Plus, the problem of hallucinated references and obvious errors is now much less common and easy to catch. Mistakes are subtle, rather than obvious. References are real. Additionally, and most important: there is no way to detect whether or not a piece of text is AI-generated . A couple of rounds of prompting remove the ability of any detection system to identify AI writing. Even worse, detectors have high false-positive rates, accusing people (and especially nonnative English speakers) of using AI when they are not. You cannot ask an AI to detect AI writing either—it will just make up an answer. Unless you are doing in-class assignments, there is no accurate way of detecting whether work is human-created.

And while I am sure that in-class essay writing will come back in style as a stopgap measure, AI does more than help students cheat. Every school or instructor will need to think hard about what AI use is acceptable: Is asking AI to provide a draft of an outline cheating? Requesting help with a sentence that someone is stuck on? Is asking for a list of references or an explainer about a topic cheating? We need to rethink education. We did it before, if in a more limited way.

When the calculator was first introduced in schools, the reaction was surprisingly close to the initial concerns I hear about students using AI for tasks like writing today. As education researcher Sarah J. Banks writes, in the early days of their popularity in the mid-1970s, many teachers were eager to incorporate calculators into their classrooms, recognizing the potential for increased student motivation and engagement. After students learned the basics, these teachers believed, they should be given the opportunity to use calculators to tackle more realistic and complex problems. However, not everyone shared this enthusiasm. Some teachers were hesitant to adopt calculators, as their effects had not been thoroughly researched, and they believed that curriculum should be adapted before introducing new technology. A mid-1970s survey found that 72 percent of teachers and laypeople did not approve of seventh-grade students using calculators. One concern was the inability to help students understand and identify their errors, for the calculators did not log the buttons that students pressed, making it difficult for teachers to see and correct mistakes. Early research similarly found that parents were worried that their children would become dependent on the technology and forget basic mathematical skills. Doesn't that sound familiar?

Attitudes shifted quickly, and by the late 1970s, parents and teachers became more enthusiastic and saw the potential benefits of calculator use, such as improved attitudes toward learning, and ensuring their children were well equipped for a technology-driven world. A year or two later, another study revealed that 84 percent of teachers wanted to use calculators in their classrooms, but only 3 percent were employed by schools that provided calculators. Teachers were generally untrained in their use and needed support from administration and parents to incorporate them into their classrooms. Despite the lack of official policies, many teachers continued to insist on calculators in their classes. The debate persisted into the 1980s and early 1990s, with some teachers still believing that calculators hindered students' acquisition of basic skills while others considered them essential tools for the future. By the mid-1990s, calculators were part of the curriculum and were used to complement other ways of learning math. Some tests allowed them, some did not. A practical consensus was achieved. Math education did not fall apart, though debate and research continues today, a half century after the calculator appeared in classrooms.

To some extent, AI will follow a similar path. There will be assignments where AI assistance is required and some where AI use is not allowed. In-school writing assignments on non-internet-enabled computers, combined with written exams, will ensure students learn basic writing skills. We'll find a practical consensus that will allow AI to be integrated into the learning process without compromising the development of critical skills. Just as calculators did not replace the need for learning math, AI will not replace the need for learning to write and think critically. It may take a while to sort it out, but we will do so. In fact, we must do so—it's too late to put the genie back in the bottle.

The calculator completely changed what was valuable to teach, and the nature of math teaching overall—huge modifications that were mostly for the good. And this revolution took a long time. Unlike AI, though, calculators started off as expensive and limited tools, giving schools time to integrate them into lessons as they were slowly adopted over a decade. The AI revolution is happening much faster and more broadly. What happened to math is going to happen to nearly every subject in every level of education, a transformation without the delay.

So students will cheat with AI. But as we saw with user innovation earlier, they also will begin to integrate AI into everything they do, raising new questions for educators. Students will want to understand why they are doing assignments that seem obsolete thanks to AI. They will want to use AI as a learning companion, a coauthor, or a teammate. They will want to accomplish more than they did before, and will also want answers about what AI means for their future learning paths. Schools will need to decide how to respond to this flood of questions.

The Homework Apocalypse threatens a lot of good, useful types of assignments, many of which have been used in schools for centuries. We will need to adjust quickly to preserve what we are in danger of losing and to accommodate the changes AI will bring. That will take immediate effort from instructors and education leaders and clearly articulated policies around AI use. But the moment isn't just about preserving old types of assignments. AI provides the chance to generate new approaches to pedagogy that push students in ambitious ways.

I have made AI mandatory in all my classes for undergraduates and MBAs at the University of Pennsylvania. Some assignments ask students to "cheat" by having the AI create essays, which they then critique—a sneaky way of getting students to think hard about the work, even if they don't write it. Some assignments allow unlimited AI use but hold the students accountable for the outcomes and facts produced by the AI, which mirrors how they might work with AI in their postschool jobs. Other assignments use the new capabilities of AI, asking students to conduct interviews with the AI before they speak to people at real organizations. And some of the assignments take advantage of the fact that the AI enables the impossible. For example, my first assignment to students in my Wharton entrepreneurship class now reads:

Make what you are planning on doing ambitious to the point of impossible; you are going to be using AI. Can't code? Definitely plan on making a working app. Does it involve a website? You should commit to creating a prototype working site, with all-original images and text. I won't penalize you for failing if you are too ambitious.

Any plan benefits from feedback, even if it just gives you permission to discuss what might go wrong. Ask the AI to give you 10 ways your project could fail and a vision of success, using the prompts from class. And, to make it interesting, ask three famous figures to criticize your plan. You can invoke entrepreneurs (Steve Jobs, Tory Burch, Jack Ma, Rihanna), leaders (Elizabeth I, Julius Caesar), artists, philosophers, or any other people you think would be useful to critique your strategy in their voice.

Thus, while classes that are focused on teaching essays and writing skills will return to the nineteenth century, with in-class essays handwritten in blue books, other classes will feel like the future, with students carrying out the impossible every day.

Of course, all this raises the even bigger question: What should we actually teach? Even slow-moving educational institutions are recognizing that teaching about AI will play an important role in education, with the US Department of Education suggesting, within just months of the release of ChatGPT, that AI will need to be embraced in classrooms. Some pundits go further, arguing that we need to focus on working with AI. We should, they argue, teach basic AI literacy, and probably "prompt engineering," about the art and science of creating good prompts for AIs.

家庭作业终结之后

几个世纪以来，教育方式几乎没有发生显著变化。学生们在教室里听老师讲课，回家做作业巩固所学内容，然后通过测试来检验知识掌握情况。接着，他们继续学习下一个主题。与此同时，教学科学研究却取得了显著进展。例如，我们现在知道，课堂讲座并不是最有效的教学方式，主题的交织讲授更有助于知识的记忆。然而，对于学生来说，不幸的是，研究表明，家庭作业和测试实际上是非常有效的学习工具。

因此，大规模使用大语言模型的第一个重大影响就是引发了家庭作业危机。作弊在学校里已经很普遍。一项对十一年大学课程的研究发现，2008 年学生做作业时，有 86% 的人提高了考试成绩，而到了 2017 年，这一比例仅为 45%。为什么会出现这种变化？因为到 2017 年，超过一半的学生在网上查找作业答案，这使得他们无法从作业中获得应有的学习益处。而这还不是全部。到 2017 年，15% 的学生曾付钱给别人完成作业，通常是通过在线的论文写作服务。即使在生成式 AI（Generative AI）出现之前，肯尼亚就有 20,000 人靠全职写论文为生。

有了 AI，作弊变得更加简单。实际上，AI 的核心功能似乎几乎就是为作弊而设计的。想想常见的家庭作业类型。许多作业要求学生阅读材料，然后总结或报告阅读内容。这些作业期望学生能够吸收阅读内容并进行一定的思考和分析。然而，AI 非常擅长总结和应用信息。而且它现在可以阅读 PDF 文件，甚至整本书。这意味着学生会更倾向于让 AI 帮助他们总结书面内容。虽然结果可能包含错误和简化，但即使是正确的总结也会影响学生的思维方式。此外，依赖这种捷径可能会降低学生对阅读理解的重视程度，使得课堂讨论的质量下降，因为学生的投入减少了。再考虑一下问题集。我们已经看到 AI 在研究生入学考试中表现优异，所以你孩子的四年级几何作业对它来说根本不是问题。

当然，AI 也开始挑战最经典的作业形式 —— 论文。论文在教育中无处不在，它们的作用多种多样，不仅可以展示学生的思维方式，还能提供反思的机会。然而，任何大语言模型（LLM）现在都能轻松生成论文，而且 AI 写的论文质量越来越高。最初，AI 的写作风格很明显，但新的模型写作更流畅，不再那么别扭和重复，甚至可以被引导写出符合学生风格的文章。再者，虚构引用和明显错误的问题也少了很多，更容易被发现。现在的错误变得更加隐蔽，不再那么显而易见。引用也是真实的。而且，最重要的是：没有办法确定一段文字是否是 AI 生成的。经过几轮提示后，任何检测系统都很难识别 AI 写作。更糟糕的是，检测器的误报率很高，常常错误地指责人们（尤其是非英语母语者）使用了 AI，即使他们没有。你也不能指望 AI 来检测 AI 写作 —— 它只会编造一个答案。除非是在课堂上完成作业，否则没有准确的方法来判断作品是否由人类创作。

虽然我相信，作为一种临时措施，课堂上的论文写作可能会重新流行起来，但 AI 的作用远不止帮助学生作弊。每个学校或老师都需要认真思考哪些 AI 的使用是可以接受的：请求 AI 提供一个大纲草稿算作弊吗？请求帮助解决一个句子的问题呢？请求提供参考文献列表或某个主题的解释呢？我们需要重新思考教育。我们以前也做过，尽管范围较小。

当计算器首次被引入学校时，反应与今天听到的学生使用 AI 完成写作任务的担忧非常相似。教育研究员 Sarah J. Banks 写道，在 20 世纪 70 年代中期，计算器刚开始流行时，许多教师迫不及待地想把它们带入课堂，因为他们看到了计算器提高学生动机和参与度的潜力。这些教师认为，在学生掌握了基础知识后，可以让他们使用计算器来解决更复杂和现实的问题。

然而，大家并非都如此热情。一些教师对引入计算器持保留态度，认为在技术效果尚未充分研究之前，应该先调整课程。一项 20 世纪 70 年代中期的调查显示，72% 的教师和普通人不赞成七年级学生使用计算器。他们担心，计算器没有记录学生按下的按钮，教师难以发现和纠正错误，从而无法帮助学生理解和识别错误。早期研究也发现，家长们担心孩子会依赖计算器，忘记基本的数学技能。这些担忧是不是听起来很熟悉？

态度迅速转变，到 1970 年代末，家长和教师对使用计算器的态度变得更加热情，认为计算器有潜在的好处，比如改善学习态度，并确保孩子们能够适应以技术为驱动的世界。一两年后，另一项研究显示 84% 的教师希望在课堂上使用计算器，但只有 3% 的教师所在的学校提供计算器。教师们普遍未经过相关培训，需要行政部门和家长的支持才能将计算器纳入课堂。尽管缺乏官方政策，许多教师仍坚持在课堂中使用计算器。争论持续到了 1980 年代和 1990 年代初，一些教师仍然认为计算器妨碍了学生掌握基本技能，而另一些教师则认为它们是未来的必备工具。到 1990 年代中期，计算器成为课程的一部分，并用于补充其他数学学习方式。一些考试允许使用计算器，另一些则不允许。达成了一个实用的共识。数学教育并没有崩溃，尽管争论和研究仍在继续，半个世纪后计算器首次出现在课堂上。

在某种程度上，AI 将遵循类似的路径。有些作业需要 AI 辅助，有些作业则不允许使用 AI。在非联网电脑上的校内写作作业，结合书面考试，将确保学生学习基本的写作技能。我们将找到一个实用的共识，使 AI 能够被整合到学习过程中，而不影响关键技能的发展。就像计算器没有取代学习数学的需要一样，AI 也不会取代学习写作和批判性思维的需要。可能需要一段时间来理清这一点，但我们会做到。事实上，我们必须做到 —— 已经无法回头了。

计算器的出现彻底改变了数学教学的内容和方式，这一变革虽然耗时长久，但大多是积极的。然而，与计算器不同，AI 革命来得更快更广泛。计算器初期昂贵且功能有限，学校有时间慢慢将其整合进课程。而 AI 的迅速普及将对几乎所有学科和教育层次产生快速且深远的影响。

因此，学生可能会利用 AI 作弊。但正如我们在用户创新中看到的，他们也会将 AI 融入到学习的各个方面，这将对教育者提出新的挑战。学生们会质疑为何要完成那些在 AI 帮助下显得过时的作业。他们希望将 AI 作为学习伙伴、共同作者或团队成员，期待比以往取得更大成就，并想了解 AI 对未来学习的影响。学校需要决定如何应对这些问题。

AI 的出现威胁到了许多长期存在并有益的作业形式。我们需要迅速调整，保护那些面临失去风险的内容，并适应 AI 带来的变化。这需要教育工作者和领导者立即行动，制定明确的 AI 使用政策。但这不仅仅是保护旧的作业形式。AI 还提供了创造新教学方法的机会，可以以更有雄心的方式推动学生进步。

我已经在宾夕法尼亚大学的本科生和 MBA 课程中强制引入了 AI。一些作业会要求学生通过让 AI 撰写文章来「作弊」，然后对这些文章进行批评 —— 这实际上是让学生深入思考作品，即使他们没有亲自写作。还有一些作业允许学生无限制使用 AI，但学生必须对 AI 生成的内容和事实负责，这模拟了他们未来工作中与 AI 共事的场景。还有些作业利用 AI 的新功能，要求学生在与真实组织的人交流前，先与 AI 进行模拟采访。此外，还有一些作业利用 AI 的能力来实现看似不可能的任务。例如，我在沃顿创业课上的第一个作业现在是这样的：

让你的计划变得雄心勃勃到几乎不可能实现的程度，因为你将使用 AI。不会编程？那就计划制作一个能运行的应用程序。涉及网站吗？你要承诺创建一个包含所有原创图片和文本的原型网站。如果因为过于雄心勃勃而失败，我不会惩罚你。

任何计划都能从反馈中受益，即使只是让你有机会讨论可能出错的地方。使用课堂上的提示，让 AI 提供 10 种项目可能失败的方式和一个成功的愿景。为了增加趣味性，请三位著名人物来批评你的计划。你可以选择企业家（Steve Jobs, Tory Burch, Jack Ma, Rihanna），领导人（Elizabeth I, Julius Caesar），艺术家，哲学家，或任何你认为有帮助的人，以他们的口吻来批评你的策略。

因此，尽管一些注重写作技能的课程会回到十九世纪，要求学生在蓝皮书上手写文章，但其他课程则会像未来一样，每天都有学生在挑战不可能的任务。

当然，这一切都引出了一个更大的问题：我们到底应该教什么？即使是反应较慢的教育机构也认识到，教授 AI 知识将在教育中发挥重要作用。美国教育部在 ChatGPT 发布仅几个月后就建议在课堂上应用 AI。一些专家更进一步，认为我们需要专注于如何与 AI 合作。他们主张我们应该教授基本的 AI 素养，可能还包括「提示工程」(prompt engineering)，即创建有效提示的艺术和科学。

### 7.2 Teaching about AI

In 2023, many companies advertised six-figure salaries for "AI whisperer" roles, and for good reason—as we have seen, working with AI is far from intuitive. And any time a new job title with high pay appears, so does a huge number of courses, instruction manuals, and YouTube channels offering the knowledge you (yes, YOU) need to get rich today.

To be clear, prompt engineering is likely a useful near-term skill. But I don't think prompt engineering is so complicated. You actually have likely read enough at this point to be a good prompt engineer. Let's start with the third principle I shared earlier—treat AI like a person and tell it what kind of person it is. LLMs work by predicting the next word, or part of a word, that would come after your prompt, sort of like a sophisticated autocomplete function. Then they continue to add language from there, again predicting which word will come next. So the default output of many of these models can sound very generic, since they tend to follow similar patterns that are common in the written documents the AI was trained on. By breaking the pattern, you can get much more useful and interesting outputs. The easiest way to do that is to provide context and constraints, as we saw in chapter 5.

For slightly more advanced prompts, think about what you are doing as programming in prose. You can give the AI instructions and it mostly sort-of follows them. Mostly, because there is a lot of randomness associated with AI outputs, so you will not get the consistency of a standard computer program. But it can be worth thinking about how you can provide a very clear and logical prompt to the AI.

A lot of active research is happening around the best way to "program" an LLM, but one practical implication is that it can help to give the AI explicit instructions that go step by step through what you want. One approach, called chain-of-thought prompting, gives the AI an example of how you want it to reason, before you make your request. Even more usefully, you can also provide step-by-step instructions that build on each other, making it easier to check the output of each step (letting you refine the prompt later), and which will tend to make the output of your prompts more accurate.

Here is an example: let's say I wanted to include a good analogy of an AI tutor in this chapter, and wanted to get help from an AI. I could simply ask for one: Tell me a good analogy for an AI tutor . And the response was a little unsatisfying: An AI tutor is like a musical metronome , because it is consistent, adaptable, and a mere tool.

Now we can try applying some of these other techniques: Think this through step by step: come up with good analogies for an AI tutor. First, list possible analogies. Second, critique the list and add three more analogies. Next, create a table listing pluses and minuses of each. Next, pick the best and explain it. Here, GPT-4 considered a dozen suggestions, from personal trainer to gardener, and created a table comparing them all, before settling on a GPS system, which, much like an AI tutor, is designed to assist users in navigating unfamiliar terrain. It provides real-time feedback, adjusts recommendations based on changing conditions (e.g., traffic or construction), and offers alternative routes when the user goes off track. Similarly, an AI tutor guides students through the academic terrain, offering real-time feedback, adjusting based on the student's progress, and providing alternative learning paths when necessary. This analogy also emphasizes the idea that while the tool provides guidance, it's up to the user (or student) to drive and make the journey, reinforcing the collaborative nature of learning with AI. Much improved, due to a little prompt engineering.

However, all of this remains much less a science than an art, and AIs still work more like people than software. For example, in a study where AIs tested many different kinds of prompts, Google's most advanced model responded best to a prompt that began " Take a deep breath and work on this problem step by step!" Given their inability to breathe, or to panic, I don't think anyone would have suspected that this would be the most effective way to get an AI to do what you want, but it scored higher than the best logical prompts that humans created.

After this complexity, prompt crafting might be a little confusing and intimidating. So I have good news for you (and bad news for the people who want to make prompt crafting the future of education). Being "good at prompting" is a temporary state of affairs. The current AI systems are already very good at figuring out your intent, and they are getting better. If you want to do something with AI, just ask it to help you do the thing. "I want to write a novel; what do you need to know to help me?" will get you surprisingly far. And remember, AI is only going to get better at guiding us, rather than requiring us to guide it. Prompting is not going to be that important for that much longer.

This doesn't mean we shouldn't teach about AI in schools. It is critical to give students an understanding of the downsides of AI, and the ways it can be biased or wrong or can be used unethically. However, rather than distorting our education system around learning to work with AI via prompt engineering, we need to focus on teaching students to be the humans in the loop, bringing their own expertise to bear on problems. We know how to teach expertise. We try to do it in school all the time, but it is a hard process. AI might make it easier.

教授 AI 知识

在 2023 年，许多公司为「AI 低语者」提供了六位数的薪水，这并非没有理由 —— 如我们所见，与 AI 合作并非直观。而每当出现一个新的高薪职位时，就会有大量的课程、操作手册和 YouTube 频道提供你（是的，你）需要的知识，以便快速致富。

需要明确的是，提示工程可能是一项有用的技能。但我不认为提示工程如此复杂。实际上，你可能已经读了足够多的内容，可以成为一个好的提示工程师。让我们从我之前分享的第三条原则开始 —— 把 AI 当作一个人，并告诉它是什么样的人。大语言模型（LLM）通过预测在你的提示之后会出现的下一个词，或部分词，就像一个高级的自动完成功能一样工作。然后，它们继续添加语言，再次预测下一个词会是什么。因此，这些模型的默认输出可能听起来非常普通，因为它们倾向于遵循 AI 所训练的书面文档中常见的模式。通过打破这种模式，你可以获得更有用和有趣的输出。最简单的方法是提供上下文和约束，正如我们在第 5 章中所看到的那样。

对于稍微复杂一些的提示，你可以把它看作是在用文字编程。你可以给 AI 指令，虽然它大多会遵循这些指令，但由于 AI 输出中存在大量随机性，因此你不会获得像标准计算机程序那样的一致性。不过，考虑如何向 AI 提供非常清晰而逻辑的提示是值得的。

目前，有大量积极的研究在探讨如何「编程」大语言模型（LLM)。一个实际的应用是，给 AI 提供明确的逐步指示会有所帮助。一种方法叫做链式思维提示（chain-of-thought prompting)，就是在你提出请求之前，给 AI 一个推理的示例。更有用的是，你还可以提供逐步构建的指示，这使得检查每个步骤的输出变得更容易（你可以在之后改进提示），同时这也会使你的提示输出更准确。

举个例子：假设我想在这一章中加入一个关于 AI 导师的好比喻，并且希望从 AI 那里得到帮助。我可以简单地请求：告诉我一个关于 AI 导师的好比喻。然而，结果有点不令人满意：AI 导师就像一个音乐节拍器，因为它是一致的、适应性强的，只是一种工具。

现在我们可以尝试使用一些其他的方法了：一步一步地思考这个问题，为 AI 教师找到合适的类比。首先，列出可能的类比。然后，评估这些类比并添加三个新的类比。接着，创建一个表格，列出每个类比的优缺点。最后，选择最好的一个并进行解释。在这个过程中，GPT-4 考虑了十几个建议，从私人教练到园丁，并创建了一个表格来对比它们的优缺点，最终选择了 GPS 系统。这种系统与 AI 教师类似，旨在帮助用户导航不熟悉的领域。它提供实时反馈，根据变化的条件（如交通或施工）调整建议，并在用户偏离路线时提供替代路线。同样，AI 教师引导学生完成学业，提供实时反馈，根据学生的进展进行调整，并在必要时提供替代学习路径。这一类比还强调了一个重要的概念：尽管工具提供了指导，但最终是用户（或学生）在驾驶和完成旅程，这强化了与 AI 协同学习的本质。通过一些提示工程，这一过程得到了很大的改进。

然而，这一切更多的是一门艺术而非科学，AI 的工作方式更像人而不是软件。例如，在一项研究中，AI 测试了多种不同类型的提示，Google 最先进的模型对一个以「深呼吸，逐步解决这个问题！」开头的提示反应最好。考虑到 AI 无法呼吸或感到恐慌，没有人会想到这会是让 AI 达到最佳表现的最有效方式，但它的得分高于人类设计的最佳逻辑提示。

在面对如此复杂的情况时，提示设计可能会显得有些令人困惑和畏惧。所以我要告诉你一个好消息（对于那些希望提示设计成为未来教育核心的人来说可能是坏消息）。「擅长提示」只是暂时的状态。当前的 AI 系统已经非常擅长理解你的意图，而且它们还在不断进步。如果你想用 AI 做点什么，只需要直接请它帮忙即可。例如，「我想写一本小说，你需要知道些什么来帮助我？」这种简单的请求就能带来很大的帮助。请记住，AI 只会越来越擅长指导我们，而不是需要我们去指导它。提示设计的重要性将逐渐降低。

这并不意味着我们不应该在学校教授 AI 知识。让学生了解 AI 的缺陷、可能的偏见和错误，以及不道德使用的风险是非常重要的。然而，我们不应该因为提示工程而扭曲我们的教育系统，而是应该专注于培养学生以自身的专业知识来解决问题。我们知道如何教授专业知识，并一直在努力实现这一目标，尽管这很难。AI 可能会让这一过程变得更加容易。

### 7.3 Flipped Classrooms and AI Tutors

We know something about what the classrooms of the future will look like. AI cheating will remain undetectable and widespread. AI tutoring will likely become excellent, but not a replacement for school. Classrooms provide so much more: opportunities to practice learned skills, collaborate on problem-solving, socialize, and receive support from instructors. School will continue to add value, even with excellent AI tutors. But those tutors will change education. They already have. Just a few months after the release of ChatGPT, I noticed that students were raising their hands less to ask basic questions. When I asked why, one student told me, "Why raise your hand in class when you can ask ChatGPT a question?"

The biggest change will be in how teaching actually happens. Today, that is often by an instructor lecturing a class. A good lecture can be a powerful thing, but it takes work—to be effective it needs to be well organized, include opportunities for students to interact with the teacher, and continuously relate ideas back to one another. In the near term, AI can help instructors prepare lectures that are grounded in content and take into account how students learn. We have already been finding that AI is very good at assisting instructors to prepare more engaging, organized lectures and make the traditional passive lecture far more active.

In the longer term, however, the lecture is in danger. Too many involve passive learning, where students simply listen and take notes without engaging in active problem-solving or critical thinking. Moreover, the one-size-fits-all approach of lectures doesn't account for individual differences and abilities, leading to some students falling behind while others become disengaged due to a lack of challenge.

A contrasting philosophy, active learning, reduces the importance of the lecture, asking students to participate in the learning process through activities like problem-solving, group work, and hands-on exercises. In this approach, students collaborate with one another and the instructor to apply what they've learned. Multiple studies support the growing consensus that active learning is one of the most effective approaches to education, but it can take effort to develop active learning strategies, and students still need proper initial instruction. So how can active learning and passive learning coexist?

One solution to incorporating more active learning is by "flipping" classrooms. Students would learn new concepts at home, typically through videos or other digital resources, and then apply what they've learned in the classroom through collaborative activities, discussions, or problem-solving exercises. The main idea behind flipped classrooms is to maximize classroom time for active learning and critical thinking, while using at-home learning for content delivery. The value of flipped classrooms seems to be mixed, ultimately depending on whether they encourage active learning or not.

So the problem with implementing active learning lies in the lack of quality resources, from teacher time to the difficulty of finding good "flipped" learning materials, thus maintaining a status quo where active learning remains rare. This is where AI comes in as a partner, not a replacement, since human teachers can fact-check and guide the AI in ways that will help their class. AI systems can help teachers generate customized active learning experiences to make classes more interesting, from games and activities to assessments and simulations. For example, history professor Benjamin Breen used ChatGPT to create a Black Death simulator, in which students got a more immersive sense of what it might be like to live during the time of the plague than they would from a standard textbook. His students generally loved the assignment but also did things that surprised him, taking advantage of the flexibility of the AI to lead peasant revolts or develop the first vaccines against the plague. It is hard to imagine consistently getting these sorts of educational experiences before AI.

But AI allows for more fundamental changes to how we learn, beyond providing classroom activities. Imagine introducing high-quality AI tutors into the flipped classroom model. These AI-powered systems have the potential to significantly enhance the learning experience for students and make flipped classrooms even more effective. They provide personalized learning, where AI tutors can tailor instruction to each student's unique needs while continually adjusting content based on performance. This means that students can engage with the content at home more effectively, ensuring they come to class better prepared and ready to dive into hands-on activities or discussions.

With AI tutors taking care of some of the content delivery outside of class, teachers can devote more time to fostering meaningful interactions with their students during class. They can also use insights from the AI tutors to identify areas where students might need extra support or guidance, enabling teachers to provide more personalized and effective instruction. And with AI assistance, they can design better active learning opportunities in class to make sure that learning sticks.

This isn't a far-future pipe dream. Tools from Khan Academy (and some of our own experiments) suggest that existing AI, when properly prepared, is already an excellent tutor. Khan Academy's Khanmigo goes beyond the passive videos and quizzes that made Khan Academy famous by including AI tutoring. Students can ask the tutor to explain concepts, of course, but it is also capable of analyzing patterns of performance to guess at why a student is struggling with a topic, providing much deeper help. It can even answer that most challenging of questions, "Why should I bother learning this?" by explaining how a topic like cellular respiration relates to a student who wants to be a football player (the AI's argument: it will help them understand nutrition and therefore athletic performance).

Students are already using AI as a learning tool. Teachers are already using AI to prep for class. The change is already here, and we will all encounter it sooner or later. It may force us to change models, but it will be in a way that ultimately enhances learning and reduces busywork. And, most exciting, this change is likely to be worldwide. Education is the key to increasing incomes and even intelligence. But two-thirds of the world's youth, mostly in less developed countries, are missing basic skills because the school systems have failed them. The benefits of educating the world are immense; one recent study suggests that closing the gap would be worth five times this year's global GDP! The solution has always seemed to be to use education technology (EdTech to its friends). But every EdTech solution has fallen short of the dream of providing high-end education, as we've discovered the limitations of various programs that ranged from providing kids with free laptops to creating massive video courses. Other ambitious EdTech projects have also run into similar issues deploying high-quality products at scale. Progress is being made, but it is not fast enough.

But AI has changed everything: teachers of billions of people around the world have access to a tool that can potentially act as the ultimate education technology. Once the exclusive privilege of million-dollar budgets and expert teams, education technology now rests in the hands of educators. The ability to unleash talent, and to make schooling better for everyone from students to teachers to parents, is incredibly exciting. We stand on the cusp of an era when AI changes how we educate—empowering teachers and students and reshaping the learning experience—and, hopefully, achieve that two sigma improvement for all. The only question is whether we steer this shift in a way that lives up to the ideals of expanding opportunity for everyone and nurturing human potential.

翻转课堂和 AI 导师

我们对未来的课堂有一些预见。AI 作弊将依然难以检测且普遍存在。AI 辅导可能会变得非常出色，但不会取代学校。课堂不仅仅是学习知识的场所，它还提供了练习技能、协作解决问题、社交和获得教师支持的机会。即使有了优秀的 AI 导师，学校的价值依然不可替代。这些导师已经在改变教育。就在 ChatGPT 发布几个月后，我注意到学生们举手问基本问题的次数减少了。当我询问原因时，一位学生告诉我，「为什么要在课堂上举手提问，而可以直接问 ChatGPT 呢？」

教学方式将发生最大的变化。现如今，教学通常是由讲师向班级授课。一场好的讲座可以非常有影响力，但要有效，它需要精心组织，提供学生与教师互动的机会，并且持续地将各种观点联系起来。在短期内，AI 可以帮助讲师准备内容扎实且符合学生学习方式的讲座。我们已经发现，AI 在帮助讲师准备更吸引人、组织更严密的讲座方面非常擅长，使传统的被动讲座变得更加活跃。

然而，从长远来看，讲座的地位可能会受到威胁。许多讲座都涉及被动学习，学生只是听讲和记笔记，而没有参与到积极的解决问题或批判性思维中。此外，讲座的一刀切方式并没有考虑到个体差异和能力，导致一些学生落后，另一些学生由于缺乏挑战而失去兴趣。

与之相对的理念是主动学习，这种方法减少了讲座的重要性，要求学生通过解决问题、小组合作和实践练习等活动参与到学习过程中。在这种方法中，学生与彼此和讲师合作应用他们所学的知识。多项研究表明，主动学习是最有效的教育方法之一，但开发主动学习策略需要投入努力，并且学生仍然需要适当的初始指导。那么，主动学习和被动学习如何共存呢？

一种引入更多主动学习的方法是采用「翻转课堂」的方式。学生通常在家通过视频或其他数字资源学习新概念，然后在课堂上通过协作活动、讨论或解决问题的练习来应用所学知识。翻转课堂的主要理念是最大化课堂时间用于主动学习和批判性思维，同时利用在家学习进行内容传递。翻转课堂的效果好坏不一，关键在于是否能够真正鼓励主动学习。

因此，实施主动学习的挑战在于缺乏高质量的资源，从教师的时间到找到优质的「翻转课堂」学习材料的困难，从而使主动学习仍然较为稀少。这时，AI 可以作为合作伙伴而非替代品出现，因为人类教师可以对 AI 进行事实核查和指导，从而帮助课堂教学。AI 系统可以帮助教师生成定制的主动学习体验，使课堂更有趣，从游戏和活动到评估和模拟。例如，历史教授 Benjamin Breen 使用 ChatGPT 创建了一个黑死病模拟器，通过这个模拟器，学生比通过标准教科书更能身临其境地感受到生活在瘟疫时期的情景。他的学生普遍喜欢这个作业，但也做了一些令他惊讶的事情，比如利用 AI 的灵活性发动农民起义或开发出第一批针对瘟疫的疫苗。可以想象，在 AI 出现之前，很难持续获得这种类型的教育体验。

但是，AI 不仅仅是提供课堂活动，它还能从根本上改变我们的学习方式。想象一下，将高质量的 AI 导师引入翻转课堂模式。这些 AI 系统能够显著提升学生的学习体验，使翻转课堂更加高效。AI 导师可以根据每个学生的独特需求定制教学内容，并根据学生的表现不断调整。这意味着学生可以在家中更有效地学习，从而在课堂上更好地参与实践活动和讨论。

有了 AI 导师在课外负责部分内容传授，教师可以在课堂上花更多时间与学生进行有意义的互动。他们还可以利用 AI 导师提供的洞见，识别出学生需要额外帮助的领域，从而进行更有针对性的教学。在 AI 的协助下，教师还能设计更好的课堂互动和实践机会，确保学生的学习效果更加持久。

这并不是遥不可及的梦想。Khan Academy 的工具（以及我们自己的一些实验）表明，现有的 AI 如果经过充分准备，已经可以成为出色的导师。Khan Academy 的 Khanmigo 不仅包含了使其闻名的被动视频和测验，还引入了 AI 辅导功能。学生不仅可以要求 AI 导师解释概念，还能通过分析学生的表现模式，找出他们在某个主题上遇到的困难，从而提供深入的帮助。它甚至可以回答那个最具挑战性的问题，「为什么我要学习这个？」，通过解释例如细胞呼吸这样的主题与学生未来职业的关系（例如，AI 会告诉想成为足球运动员的学生，这有助于他们理解营养与竞技表现的关系）。

学生们已经开始使用 AI 作为学习工具，教师也在利用 AI 进行课堂准备。这一变化已经到来，我们迟早会面对。虽然它可能会迫使我们改变现有的模式，但最终将以增强学习效果和减少繁琐工作的方式进行。而且，最令人兴奋的是，这种变化可能会在全球范围内发生。教育是提高收入和智力的关键。然而，全球有三分之二的年轻人，主要集中在欠发达国家，缺乏基本技能，因为学校系统未能满足他们的需求。教育全球化的好处是巨大的；一项最近的研究表明，弥合这一差距的价值相当于今年全球 GDP 的五倍！一直以来，解决方案似乎是使用教育技术（简称 EdTech）。但每一个 EdTech 方案都未能实现提供高端教育的梦想，因为我们发现了各种计划的局限性，这些计划从为孩子们提供免费笔记本电脑到创建大规模视频课程不等。其他雄心勃勃的 EdTech 项目在大规模部署高质量产品时也遇到了类似的问题。尽管有进展，但速度还不够快。

然而，AI 改变了一切：全球数十亿人的教师现在可以使用一种潜在的工具，这种工具可以作为终极教育技术。曾经只有百万美元预算和专家团队才能使用的教育技术，现在掌握在教育工作者手中。释放潜能的能力，使得从学生到教师再到家长的每个人的教育体验变得更好，令人无比兴奋。我们正处在一个时代的风口浪尖，AI 正在改变我们的教育方式 —— 赋予教师和学生新的能力，重塑学习体验 —— 并且，希望能为所有人带来两个西格玛的提升。唯一的问题是，我们是否能以符合扩大机会和培养人类潜力理想的方式来引导这一转变。
