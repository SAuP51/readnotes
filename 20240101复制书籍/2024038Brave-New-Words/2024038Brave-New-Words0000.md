Salman Khan.(2024).2024038Brave-New-Words.Penguin Publishing Group => xx

About the Author

Salman Khan is the founder and CEO of Khan Academy, a nonprofit with the mission of providing a free, world-class education for anyone, anywhere. His lessons on YouTube have revolutionized learning, garnering billions of views globally. Recognized as one of Time 's 100 Most Influential People inthe World, Khan is also the founder of schoolhouse.world, Khan Lab School, and Khan World School, and the author of The One World Schoolhouse.

## Introduction

Introduction: Let's Write a New Story Together

You can't cross the sea merely by standing and staring at the water.

— Rabindranath Tagore

But, whatever you do, do not let the past be a straitjacket!

— Robert A. Heinlein, The Moon Is a Harsh Mistress

It was New Year's Day 2023 when my eleven-year-old daughter, Diya, and I decided to spend the afternoon writing a short story together. As I set a laptop on the kitchen counter for us, Diya landed on our story's premise and then began to type. Our main character was a sassy influencer. She called her Samantha. Samantha had gotten stranded on a deserted island. "It's wonderful," I said as Diya tinkered with the story.

At which point, as if stepping into the pages of a science fiction novel or some alternate reality, Diya typed directly to her fictional character.

Samantha then responded directly to Diya, her words appearing on the screen. "Hi Diya and Sal, this is Samantha. This storytelling adventure you are writing is quite splendid! You've created a modern twist on the classic deserted-island tale!"

On the page, Diya typed, "How is life on the deserted island?"

"Life on this deserted island has been quite the unexpected adventure," Samantha replied. "I've had to learn how to survive without my usual comforts, but I've also discovered some hidden talents I never knew I had!"

"What kind of talents?" Diya asked.

Samantha replied, "For one, I've become quite skilled at building makeshift shelters using palm leaves and branches. I've also learned how to catch fish with my bare hands and start a fire using only sticks and dry leaves!"

Without missing a beat, Diya wrote, "Why don't you use your scarf to make a hammock?"

"Use my scarf? No way!" Samantha replied. "This is a designer piece, and I can't risk getting it ruined. Now, what do you say we keep writing this story I'm in together? What should happen next?"

"I think we should do what Samantha says," I said.

Diya agreed. Returning to the computer, she typed, "What if, all of a sudden, Samantha's best friend, Emily, appears on her sailboat. She's here to rescue her."

"I love it!" Samantha wrote the next part on her own. " ‘Samantha couldn't believe her eyes when she saw her best friend, Emily, sailing toward the island on a small sailboat. She waved her arms frantically, trying to catch Emily's attention. As the sailboat approached the shore, Samantha's excitement grew. She couldn't wait to tell Emily about her adventures on the island and hear how Emily had managed to find her.' Okay, now it's your turn again, Diya and Sal! Write the next two sentences, and let's see how their reunion unfolds."

So, to recap: my eleven-year-old daughter and I were now having a real conversation with a make-believe character. This was some Kurt Vonnegut–level absurdity. The world as I knew it had suddenly shifted toward a strange new reality.

It would never be the same again—not for us, and not for anyone else on the planet.

The Offer

To explain how we got to this incredible scenario, let's back up a bit.

Twenty years earlier, my young cousin Nadia needed help learning math, so I made her a proposition: I had a day job as a hedge-fund analyst, and with a background in computer science I offered to provide remote individual lessons to her using instant messaging or talking over the phone. The tutoring seemed to work for her, and word soon got around my family that I was offering free tutoring. Within the year, I found myself tutoring nearly a dozen cousins on a regular basis.

To help them, I started writing web-based math practice software so that they could remediate gaps in their knowledge and learn at their own pace while I kept track of what they were mastering. I called the website the only decent domain name I could find—Khan Academy. Realizing the power of one-on-one learning, I soon thought about how I might scale this platform to give thousands, or maybe even millions, of students like my cousins the benefit of tutor-like instruction.

Based on a suggestion from a friend, I began recording video lessons that I posted on YouTube to complement the software. By 2009, my website was getting 50,000 learners every month, each one hungry for academic help. Many users, I would discover, were students who saw Khan Academy as the personal tutor they or their family could not afford. Today, Khan Academy is a nonprofit with more than 250 employees that serves more than 150 million learners in more than fifty languages around the world. Scaling world-class, personalized learning, as is often embodied by one-on-one tutoring for students, remains the beating heart of our mission to provide a free, world-class education for anyone.

My long-held aspiration for the organization was that it would act as a tutor for every learner in the world, an endeavor that has always been our true north. This wasn't simply a matter of scaling personalized support for the sake of it. Long before Khan Academy, decades of research (and intuition) pointed to the idea that kids could learn much more if the pacing adapted to the student and allowed each one to truly ace a subject (that is, mastery learning). This contrasts with the status quo, where a class of thirty students often moves on to the next concept even when a good portion of the students haven't yet displayed proficiency. Obviously, getting every student a dedicated on-call human tutor is cost prohibitive. The only viable solution is to work with technology. It seemed to me that AI technology might someday turn out to be an important part of that puzzle, maybe even the holy grail of truly emulating a real tutor.

I am not alone in having this dream. The science fiction writer Neal Stephenson wrote about the potential influence of technology on education in his novel The Diamond Age . The book is set in a future world that introduces the concept of using AI, in the form of a highly advanced interactive book and app called A Young Lady's Illustrated Primer , to provide personalized education to its young users. The Orson Scott Card novel Ender's Game imagines a battle school that employs advanced AI technology to test and train students' strategic thinking and decision-making skills through a personal AI tutor called Jane. Isaac Asimov's short story "The Fun They Had" describes a school of the future that uses advanced technology to revolutionize the educational experience, enhancing individualized learning and providing students with personalized instruction and robot teachers. Such science fiction has gone on to inspire very real innovation. In a 1984 Newsweek interview, Apple's co-founder Steve Jobs predicted computers were going to be a bicycle for our minds, extending our capabilities, knowledge, and creativity, much the way a ten-speed amplifies our physical abilities. For decades, we have been fascinated by the idea that we can use computers to help educate people.

What connects these science fiction narratives is that they all imagined computers might eventually emulate what we view as intelligence. Real-life researchers have been working for more than sixty years to make this AI vision a reality. In 1962, the checkers master Robert Nealey played the game against an IBM 7094 computer, and the computer beat him. A few years prior, in 1957, the psychologist Frank Rosenblatt created Perceptron, the first artificial neural network, a computer simulation of a collection of neurons and synapses trained to perform certain tasks. In the decades following such innovations in early AI, we had the computation power to tackle systems only as complex as the brain of an earthworm or insect. We also had limited techniques and data to train these networks.

The technology has come a long way in the ensuing decades, driving some of the most common products and apps today, from the recommendation engines on movie streaming services to voice-controlled personal assistants such as Siri and Alexa. AI has gotten so good at mimicking human behavior that oftentimes we cannot distinguish between human and machine responses. Meanwhile, not only has the computation power developed enough to tackle systems approaching the complexity of the human brain, but there have been significant breakthroughs in structuring and training these neural networks. One of the more recent breakthroughs came in 2017 with the advent of transformer technology from Google, which allows for, among other things, better and faster training and more accuracy in how words and ideas connect based on this training information.

How good these systems can get is usually related to the complexity and architecture of the underlying "model." Think of a model as a computational representation that tries to mimic or simulate something in the real world. For example, when meteorologists try to predict the path of a hurricane, they use weather models that contain a software representation of billions or trillions of smaller volumes of the atmosphere and forecast how those smaller volumes would likely interact with one another. In the case of large language models, they are specifically designed to model associations between words. In this case we're modeling not atmospheric conditions but neurons and synapses. Large language models such as GPT-4, short for Generative Pre-trained Transformer, are essentially big, powerful—albeit digital—"word brains" trained on a colossal amount of information from books, articles, websites, and all sorts of written material.

By analyzing and processing this vast amount of text, the language model learns the patterns, the language, and the context of how words, sentences, and paragraphs fit together. If you were to ask a large language model like GPT-4 a question, it would know what to reply based on its training from all those books, web pages, video transcripts, and social media posts. What it lacks in real-world sensory experiences of the human brain, it compensates for by having exposure to more language than any human might hope to read, watch, or listen to in multiple lifetimes.

It was against this backdrop in the summer of 2022 that I received an email from Greg Brockman and Sam Altman. They were the president and the CEO, respectively, of OpenAI, one of the groundbreaking research laboratories working in the field of friendly, or socially positive, artificial intelligence. The organization wanted to meet and talk about a potential collaboration with us. I didn't realize it yet, but the world was about to be turned upside down.

For context, OpenAI was still four months away from releasing ChatGPT and seven months away from releasing GPT-4, the eventual rollout of which is what they wanted to discuss. I was intrigued but skeptical that there would be anything we could do together. I didn't have a strong view that some of the newer-generation generative AIs would be immediately applicable to our mission. Advances in AI technology had already done some interesting things around writing that sounded credible, but in my mind the technology didn't yet seem to have a real handle on knowledge and also lacked the ability to perform logical or deductive reasoning or reliably produce legitimate facts. At the same time, however, I had a lot of respect for what OpenAI had already accomplished. So we scheduled some time together and met.

Each successive generation of these models typically had far more complexity, bluntly measured by the number of parameters they contained. The best way to think of a parameter is a number describing the strength of a connection between two nodes in the neural net that represent the large language model. You can view it as a representation of the strength of a synapse between two neurons in a brain. When it was first launched in 2018, GPT-1 had more than 100 million parameters. Just a year later, GPT-2 had more than 1 billion. GPT-3 had more than 175 billion. GPT-4 was likely to have on the order of 1 trillion parameters.

The OpenAI leadership felt that GPT-4 was going to surprise folks with its enhanced capabilities, which they believed would both excite and possibly unnerve a lot of people. Because of this, they were looking to launch it alongside a small number of trusted partners that might be able to showcase socially positive and real-world examples; Khan Academy was the first organization that came to mind. The second reason they wanted to reach out to us was to help evaluate the AI itself. They needed to show that GPT-4 was capable of deductive reasoning, critical thinking, and actually dealing with knowledge. The OpenAI team aspired to see how GPT-4 would perform on college-level biology questions, and we had thousands of these.

I found myself suddenly exhilarated to be one of the first people on the planet to see the capabilities of GPT-4. Based on past experience, I knew the time to really explore a technology is when it's on its way toward getting good. If you invest and test it properly when most still believe that it's a toy, or a distraction, you put yourself in position to really reap its benefits when it is ready for prime time. This was the case in the infancy of video learning, when plenty of naysayers said YouTube was simply an idle pastime. But early pioneers showed us that on-demand videos were so much more than cats playing piano and that, in fact, you could use them to help people learn.

Today, it's commonplace for students to learn almost anything they want using on-demand videos, and it's become much more accepted in the classroom. Khan Academy has played a leading role here, using video to support on-demand help for hundreds of millions of learners around the world. We've also shown that rather than somehow being a substitute for the teacher, videos can off-load pieces of a lecture, freeing up more time for personalized learning, hands-on activities, or classroom conversation. This arguably makes the teachers more valuable, not less. And now it was time to see if generative AI could do the same—support students and let teachers move up the value chain.

Sam and Greg started their GPT-4 demo by showing me an AP biology multiple-choice question they had pulled directly from the College Board's website. They asked me for the answer. After reading through it, I said the answer is C . They then asked GPT-4 to answer the question using a chat interface (similar to what folks are now used to with ChatGPT). A moment later, GPT-4 answered the question correctly.

I didn't say anything right away, but secretly I started to get goose bumps, even as I remained somewhat skeptical. "Wait a second," I said. "This is an AI that can already answer a biology question at an AP level?" Maybe it just got lucky on this example, I thought. "Can you ask it to explain how it got the answer?"

Greg typed, "Please explain how you got the answer." Within seconds, GPT-4 provided us with a clear, simple, and thorough explanation. Not only that, but it was so conversational that it might as well have been a human being answering, not a machine.

At this point, I gave up on hiding my amazement.

"Can you ask it to explain why the other choices aren't correct?"

Greg obliged, and a moment later GPT-4 explained why all other answer possibilities in the AP question were wrong.

Next, I asked Greg if GPT-4 was capable of writing an original AP-level question.

It did, and then it wrote ten more.

Two months later, I visited Bill Gates to give an update on Khan Academy, and I learned why the OpenAI folks had shown an AP biology question. Bill told me that when he first encountered GPT-3, he was impressed, but he had told the OpenAI team that he'd only be really impressed if it was capable of passing the AP biology exam. What the OpenAI team had shown me in that first demo was that GPT-4 could now do so.

"This changes everything," I said to Greg and Sam, my mind spinning with possible ways that GPT-4 might allow us to reimagine education, credentials, work, and human potential.

"We were kind of thinking the same thing," Sam said. "It is not perfect yet, but the technology is getting better. Who knows? If we get it right, this might be something educators will want to use."

Technology that we had until recently thought of as something straight out of Star Trek was suddenly very real. The innovation imagined by the greatest science fiction writers had become a reality.

Time for a Hack-AI-Thon

In the early 1940s, Claude Shannon, a brilliant mathematician, produced several consequential theories. Among them, he mapped out a theory of electronic communication that would become the basis of digital technology. In 1948, while working for Bell Labs, he started dabbling in the field we now know as artificial intelligence. Shannon decided to play with how an algorithm approximates language. He published a paper in The Bell System Technical Journal called "A Mathematical Theory of Communication." It was the early days of digital computers—well before the advent of the internet—and Shannon's information theory first made the case that a series of probabilistic processes could approximate the English language. By keeping track of how many times words appeared in a text, he devised an algorithm where he was able to predict what word was most likely to come next. Eventually, this small language model generated a sentence. The better this process got, the more natural the sentence sounded. It's an oversimplification, but the likes of GPT-3 and GPT-4 are essentially far more complex large language models based on training a neural net in very specialized ways, and the underlying idea can be traced back to this early work by Shannon.

Soon after the development of Shannon's work, we saw another great mind enter the realm that was to become artificial intelligence—a computer scientist by the name of Alan Turing. Above and beyond his work breaking German codes and helping us beat the Nazis, Turing explored the concept of AI and whether machines can reach a point where they can mimic human intelligence convincingly. In 1950, he wrote a foundational paper titled "Computing Machinery and Intelligence," where he introduced the concept of the imitation game, which we now know as the Turing test. Imagine you are having a conversation, but you can't see the person you are talking to. It could be a person you are chatting with on your computer or phone. Now, if you can't see or physically interact with the other person, how can you tell if you are talking to a human or a machine? That's the essence of the Turing test. To perform the test, there's usually a judge involved who is responsible for evaluating the responses from both the human and the machine. The goal for the machine is to convince the judge that it is, in fact, a human. It needs to demonstrate intelligence, understanding, and the ability to hold a coherent conversation, just as a person would. Turing proposed that if a machine could consistently fool the judge into thinking it's human, we could consider it intelligent. In other words, if the machine can pass the Turing test, it would imply that it possesses humanlike intelligence.

When I accepted Sam and Greg's offer to field-test the new GPT-4 technology in the summer of 2022, I wondered how close it might be to passing the Turing test. I had studied artificial intelligence at MIT in the mid-1990s. Back then, there were simple programs that could trick a person for a few interactions but nothing that could consistently feel human across a long, detailed conversation. It always seemed fantastical that one day a machine might actually pass the Turing test, let alone in my lifetime, and it was thrilling to actually try out a technology that seemed on the cusp of passing it, or that perhaps had already done so. This advancement could be tantamount to scientists achieving cold fusion or faster-than-light travel.

As the initial wave of excitement crested, I also started thinking about the societal implications of a seemingly intelligent technology. While capable of solving so many problems, AI was also capable of introducing some potential downsides. If this large language model was going to be able to help tutor students, then it was going to be capable of writing essays for them too. What if the new version of GPT managed to be only a crutch for our students, preventing them from developing their own research and writing skills? It also occurred to me that if GPT-4 had the capacity to empower folks by helping them communicate and solve problems, then it also potentially threatened to dislocate many people from their jobs and their sense of purpose. A convincingly human technology capable of being a great tutor might also be a technology that bad actors could use to defraud or brainwash unsuspecting people.

My mind continued to spin a great variety of dark scenarios and outcomes—from data collection on our kids to the potentially addictive quality of the technology. I understood that the disruptive nature of the AI meant that we all needed to take it seriously. Beyond OpenAI, there are several other organizations investing heavily in large language models, including Microsoft, Google, and Meta, not to mention state actors like Russia and China. All of the technology giants had been using some form of artificial intelligence for years to feed us the ads, videos, search results, and social media posts with which we engage on an hourly basis. But this AI seemed different—because it was. Science fiction authors have always drawn the distinction between an artificial specialized intelligence that can optimize one thing versus an artificial general intelligence that can reason across many tasks like a human being, the latter case being the one that could lead to both utopian and dystopian futures.

To many, large language models like GPT-4 approach artificial general intelligence because they can write about, and seemingly reason about, any subject, making them relevant almost anywhere. Generative AI can also construct and make sense of images. While it was clear that generative AI was going to change our world in ways we might scarcely imagine, it also occurred to me that it was not up to me or Khan Academy to decide whether we were comfortable with this technology moving forward. It was already moving forward. As someone trying his best to use technology for good, I wondered if we might be able to utilize generative AI to achieve the greatest positive effect and edge us closer to that utopian scenario, especially in the realm of education.

With unexpected access to OpenAI's newest model, I sat down at my computer on that very afternoon, a Friday. I was glued to it for most of the weekend. After ten hours planted at the computer, I tried to shut off and sleep, but my mind was racing at all that the technology was capable of and how we, as educators, might use it with our learners. I saw that the implications of GPT-4 were nothing short of revelatory. Not only was it able to solve complex problems and answer tricky questions, but it was also able to explain its reasoning and generate new questions on its own. It was able to take on personas with humanlike characteristics. After prompting GPT-4, I got it to act as a math tutor, a science tutor, and a language tutor, each one possessing the ability to drive a conversation.

What really caught my attention, though, was its ability to write in different tones and styles. For instance, as part of my GPT-4 learning journey, I could not resist the temptation to have GPT technology rewrite the Declaration of Independence in the voice of Donald Trump:

Folks, let me tell you, it is time for us to declare our independence from this failing government and this terrible leader, King George III. I mean, this guy is a total disaster. He's been taking away our rights, he's been ignoring the will of the people, and he's been more interested in lining his own pockets than actually helping the people. It is just sad, really, really sad.

But we, the people, we're not going to stand for it any longer. We're going to make our own country, and it is going to be the best country, the greatest country the world has ever seen. Believe me, nobody knows more about making a country great than I do. We're going to have the best economy, the best military, the best everything. It is going to be tremendous.

Next, I asked GPT-4 to write the Declaration of Independence in the style of Dr. Seuss:

In the land of the free and the home of the brave

A new nation was born, no longer a slave

To the rule of a king across the sea

We declared our independence, and shouted with glee

With a pen in hand and a fire in our hearts

We wrote down our grievances, every last part

No more taxes without representation

No more soldiers in our homes, no more frustration

We hold these truths to be oh so true

That all men are equal, yes me and you

We have rights that can't be taken away

Life, liberty, and happiness, we're here to stay.

Tricks like this became somewhat commonplace once people had access to ChatGPT, but at the time I was one of the first to have access to this type of technology and attempt such prompts. And GPT-4 was frankly much better than the first iteration of ChatGPT, which wouldn't be released to the public for another few months. I found the results of my prompts to be impressive, hilarious, and even a little scary. When I asked it questions or requested recommendations, it gave me answers that felt completely authentic. There was no person behind the scenes typing these responses, nor was there an algorithm generating the text with traditional if-then-type logic that other algorithms typically worked from. I did not get canned and robotic answers either. Instead, I received varied responses to the same query every time I asked it, responses that took into account the context of my conversation with it up to that point.

More specifically, it made me realize the potential of this technology to transform the way we think about K–12 and higher education and beyond. The AI was not quite perfect yet. It was getting math incorrect more than I liked, but I could even see improvement as I got better at prompting it. By the end of that weekend, I wondered what might happen if I gathered dozens of the brightest minds in technology and education to play around with the platform alongside me. OpenAI agreed to grant access to another thirty or so engineers, content creators, educators, and researchers on the Khan Academy team to experiment with GPT-4.

It was time for a hackathon.

Every six months, we have a week at Khan Academy where employees are allowed to work on pretty much anything they want related to our mission. I presented GPT-4 to a small subset of our team and let them have at it. Through collaboration and innovation, we brainstormed, designed, and developed really cool and consequential ideas. What we eventually came to call the hack-AI-thon elicited dozens of completely new concepts and education modalities that no one had ever thought of before. For instance, what if the AI was able to help teachers write their lesson plans? What if it could enter into a debate with a student? What if it could create projects? What if it could help a student remove stressors or inspire a student to create new ideas? What if the technology was able to quiz a student or lead a student in a review session? Educators would be able to create novel activities that students could do with the AI. The AI might help students compose essays, making them better writers by providing them with immediate feedback.

From here, the hack-AI-thon participants explored questions about safety, security, and bias. (Remember, this was well before OpenAI released ChatGPT to the public.) We flagged some clear concerns: Was it really a good idea for students to be using generative AI to write their essays, perform their research, take tests for them, or even help them apply to college? Artificial intelligence, we worried, might turn our kids into a generation of cheaters who were not going to learn anything. With the AI taking over, parents who once helped their kids with homework might lose an important point of connection. As for teachers, was this going to be a boon, or was this going to undermine their ability to teach students? At no point did I think that AI was going to put teachers out of work, and in the best-case scenario it was going to accelerate their ability to teach their students, but I also worried it might undermine that ability in critical ways too.

Nearly two decades earlier, I had seen similar fears around on-demand video in education: Was it going to be a distraction for students? Was it going to lower their attention spans? Would it isolate students instead of promoting connections between them and their teachers? How were students going to be able to know what to watch? Whom would they ask if they got stuck on a subject and had questions?

It's never a good idea to let fear stop you from exploring, however. The more time we spent testing GPT-4, the more we realized how to mitigate problems with solutions that in many ways made the upsides even better. To address concerns around cheating, for instance, we considered what it would take to create an AI tutor that refused to give students answers. Like a good human tutor, it would instead ask leading questions. When we thought about student safety, we considered creating a system that logged all conversations and made them transparent to teachers and parents. To encourage human-to-human connectivity, we suggested tools that teachers and students could use to give them more time and energy for themselves and for each other.

By the end of the hack-AI-thon, our team started to feel increasingly confident that GPT-4 was going to be a game changer for education. Used properly, it would positively affect how teachers planned, instructed, and graded. By bringing artificial intelligence into the classroom, educators could tackle entrenched problems in education that we had not been able to solve with existing technology and resources. Soon, students might be able to learn faster and retain more information than ever before, proving AI to be the ultimate learning tool for accelerating human intelligence and potential. AI might hasten learning globally and even get us closer to realizing a world in which every person on earth had access to affordable world-class learning. This technology had the potential to revolutionize how we communicate, create, and consume information the same way that, twenty years earlier, we marveled at the educational possibilities of the internet, and twenty years before that, the personal computer, and twenty years before that, the calculator.

As for me, I was left invigorated. I became increasingly confident that with proper care we could mitigate the risks and potential downsides of generative AI. It was clear that even though we were among the first people on the planet to incorporate this technology, as soon as the world got wind of it, everything was going to change dramatically—and not over the span of generations but within months.

Engaging the Principle of Educated Bravery

At the end of November 2022, two months after our hack-AI-thon, we were still exploring the possibilities of the technology when OpenAI released ChatGPT to the public. This initial release layered a chat interface over GPT-3.5, which had been out for several months. Even though it was suboptimal, operating on a model far less powerful than GPT-4, it immediately captured the world's imagination. Within days, millions of folks were using it, and social media and the press seemed to talk about nothing else.

Alongside this initial wave of excitement, many expressed concern about a potential epidemic of student cheating, AI-produced factual errors or hallucinations, bias, and questions about the sources of information from which ChatGPT drew its data. In real time, we were watching a society starting to struggle with the implications of a powerful but imperfect tool, and nowhere more so than in the realm of education. Within weeks of ChatGPT's launch, school districts around the country were banning it. It lit a fire in our belly at Khan Academy. We had to show not only that there were solutions to mitigating many of these risks but that AI could truly be transformational for education. We wanted to show this with real tools in real schools and not just with theoretical talk.

Within months, OpenAI was planning to release GPT-4 to the public, and when it did, we would need answers to the cheating problem, to the problem of transparency, to the problem of moderation. We had to show that AI could be valuable for teachers and learners in actual educational environments, that it could provide every teacher with support to write lesson plans, to monitor the progress of a classroom, to give real-time feedback, and even to modulate teacher burnout. We had to show AI's real value to students as a Socratic tutor, as a debating partner, as a guidance counselor, as a career coach, and as a driver of better outcomes in their academics. So, alongside OpenAI, we created a rapid prototyping team that began to build an AI-infused education platform we would come to call Khanmigo.

It was in that spirit of pushing its capabilities with novel applications and creating safeguards that I had an idea. Everyone was talking about AI enabling cheating by writing papers for students, but what if it didn't write for them at all? What if, instead, it wrote with them?

This was where I found myself on New Year's Day 2023, when I asked my daughter, Diya, to write a story with me—and GPT-4. This was far from the first time I had asked Diya to be a part of an education experiment or to test out a prototype for us. Usually, these informal testing sessions involved having Diya, one of my sons, or another very patient accomplice like a student or teacher at Khan Lab School or Khan World School try to navigate a new exercise to make sure that the interface between students and technology worked reasonably well. I've always found this do-it-yourself user research incredibly helpful and grounding. My "accomplices" like it, too, because it allows them to kick the tires of a new program or innovation that can make a real difference in the lives of learners. This was never truer than with GPT-4. So I created a prompt for GPT-4, telling it to write a story with us, not for us. I told it how we wanted to interact conversationally and with what type of tone.

Diya then started to create her story about Samantha, the social influencer rescued from a desert island by her best friend, Emily. Diya would write a bit and then the large language model took over for a stretch. Samantha introduced herself, told us about her life, and joined us in co-creating the story. To our mutual amazement, Samantha, via GPT-4, made the adventure come alive with engaging and entertaining dialogue and perfectly captured the personalities of Diya's two characters. Together, Diya and the AI continued to create. Their story had its share of heartwarming, hilarious, and sad moments, from Samantha's concern for her designer wardrobe to the touching reaction when Diya's character Emily fell ill and passed away.

Throughout the interaction, the AI demonstrated its ability to engage in meaningful and complex dialogue. It responded to Diya's prompts in a way that felt natural and authentic. As a parent, I found it uplifting to watch my daughter interact with GPT-4 as her imagination sprouted in this new way. The AI she was working alongside accurately captured the fictionalized world Diya was creating and kept track of the existing conversation between her and the characters. It also remembered the rules Diya had set within the story world, as well as the information she gave the AI earlier in the conversation. The AI was expanding her mind and helping her writing and creativity grow. Where writing was usually a unidirectional activity, with the creator pushing the ideas onto the paper, this act of writing—choosing the right words and finding the right voice—had become a two-way interaction between human and machine, making my daughter, at eleven years old, one of the very first people on the planet to write a story and have it talk back to her as she was creating it!

This was absolutely mind-blowing. Here we were, working with a technology that took writing, and everything we knew about teaching and learning in all domains, to another level. The need to get this functionality to every learner on the planet was suddenly clear to me. The future potential of how we learn and teach was changing before my eyes. As my daughter and "Samantha" were busy writing their story, thanks to AI, we were about to write a new story about education, one that was to challenge people to be careful about, but not fearful of, change.

Now the world is waking up to the possibilities of large language models and what is in store for education. To take advantage of this technology requires some creativity and bravery too. Not blind bravery, but something I have started to call educated bravery, a kind of courage that comes from acknowledging the rational trepidation we all face when presented with sudden advances in technology and then informing ourselves of both the challenges and the potential it presents.

To get the very best from this technology, we need to reconsider what is now possible. We also need to ponder how to mitigate the risks, our fears, and our hesitations. This requires rethinking everything from the role of teachers, to how kids use multimedia, to how people get credentialed, to how to help graduates find jobs once they enter the workforce.

We are at a turning point in education, one with far-reaching implications that is changing, and will continue to change, everything about learning, work, and human purpose.

引言：让我们一起写一个新故事

你不能仅仅站在岸边凝视大海就能跨越它。

—— Rabindranath Tagore

但是，不管你做什么，都不要让过去成为束缚！

—— Robert A. Heinlein, The Moon Is a Harsh Mistress

那是 2023 年的元旦，我和 11 岁的女儿 Diya 决定一起写一个短篇故事度过下午。我把笔记本电脑放在厨房的柜台上，Diya 想出了我们的故事情节并开始打字。我们的主角是一个活泼的网红，她叫 Samantha。Samantha 被困在一个荒岛上。「太棒了，」我说，当 Diya 在故事上进行修改时。

这时，就像进入了科幻小说的情节一样，Diya 直接对她的虚构角色打字。

Samantha 直接回应了 Diya，她的话出现在屏幕上。「嗨 Diya 和 Sal，我是 Samantha。你们写的这个冒险故事非常精彩！你们创造了一个现代版的经典荒岛故事！」

Diya 在页面上打字，「荒岛上的生活怎么样？」

「在这个荒岛上的生活是一场意想不到的冒险，」Samantha 回答。「我不得不学会在没有通常舒适条件的情况下生存，但也发现了自己一些隐藏的才能！」

「什么样的才能？」Diya 问。

Samantha 回答，「首先，我变得非常擅长用棕榈叶和树枝搭建临时庇护所。我还学会了徒手抓鱼，并用木棍和干叶生火！」

Diya 写道，「你为什么不用围巾做一个吊床呢？」

「用围巾？绝对不行！」Samantha 回答。「这是设计师的作品，不能冒险弄坏。现在，我们继续写这个故事，接下来应该发生什么？」

「我觉得我们应该听 Samantha 的，」我说。

Diya 点点头，回到电脑前打字道：「如果突然间，Samantha 的好朋友 Emily 出现在她的帆船上，她是来救她的。」

「这个主意太棒了！」Samantha 接着写了下一段。「‘当 Samantha 看到她最好的朋友 Emily 驶着一艘小帆船向岛上靠近时，简直不敢相信自己的眼睛。她拼命挥手，试图引起 Emily 的注意。帆船越靠越近，Samantha 的兴奋之情也不断高涨。她迫不及待地想告诉 Emily 她在岛上的冒险经历，并听听 Emily 是如何找到她的。'好了，现在轮到你们了，Diya 和 Sal！写下接下来的两句话，让我们看看她们的重逢会如何展开。」

回顾一下：我和我十一岁的女儿现在正在和一个虚构的角色进行真实的对话。这种情景简直像是出自 Kurt Vonnegut 的小说。世界在我眼中突然变成了一个奇妙的新现实。

从此以后，一切都改变了 —— 不仅对我们，对全世界的每个人都是如此。

提议要解释我们是如何来到这个不可思议的情景的，我们需要回溯一下。

二十年前，我年轻的表妹 Nadia 需要数学辅导，于是我提出了一个建议：我当时在对冲基金做分析师，有计算机科学背景，我提议通过即时消息或电话为她提供远程一对一辅导。这种辅导对她很有效，消息很快在家族中传开了。一年之内，我发现自己已经定期为近十位表兄弟姐妹进行辅导。

为了帮助他们，我开始编写一个基于网络的数学练习软件，让他们可以补足知识差距，并按照自己的节奏学习，同时我能跟踪他们的学习进度。我给这个网站取名为「可汗学院」（Khan Academy），这是我能找到的唯一合适的域名。意识到一对一学习的巨大力量，我很快想到了如何扩大这个平台，让成千上万甚至数百万像我堂兄弟姐妹一样的学生受益。

在朋友的建议下，我开始录制视频课程，并将它们发布在 YouTube 上，以补充软件的使用。到 2009 年，我的网站每月有 50,000 名学习者，他们都渴望获得学术帮助。我发现，许多用户是那些将可汗学院视为他们或他们家里无法负担的私人导师的学生。今天，可汗学院是一家非营利组织，拥有超过 250 名员工，为全球超过 50 种语言的 1.5 亿学习者提供服务。提供世界级的个性化学习，正如一对一辅导那样，仍然是我们提供免费、世界级教育的核心使命。

我一直希望这个组织能成为全球每个学习者的导师，这也是我们始终追求的目标。这不仅仅是为了推广个性化支持。早在 Khan Academy 出现之前，数十年的研究（以及我们的直觉）就表明，如果学习进度能根据学生的需要进行调整，并让每个学生真正掌握所学内容（即掌握学习），孩子们可以学到更多。相比之下，当前的教育模式常常是在一个班级中，即使有很多学生还没有掌握所学内容，也会继续推进下一个概念。显然，为每个学生配备一个随时待命的人类导师成本过高。唯一可行的解决方案是利用技术。在我看来，AI 技术可能会成为解决这个问题的重要途径，甚至有可能是完美模拟真实导师的终极方法。

我并不是唯一一个有这种梦想的人。科幻小说作家 Neal Stephenson 在他的小说《The Diamond Age》中，描述了技术对教育的潜在影响。故事设定在一个未来世界，提出了使用 AI（人工智能）的理念，这种 AI 通过一个高度先进的互动书籍和应用程序，名为《A Young Lady's Illustrated Primer》，为年轻用户提供个性化教育。Orson Scott Card 的小说《Ender's Game》则描绘了一所战斗学校，利用先进的 AI 技术，通过一个名为 Jane 的个人 AI 导师来测试和训练学生的战略思维和决策能力。Isaac Asimov 的短篇小说《The Fun They Had》描述了一个未来学校，利用先进技术彻底改变教育体验，加强个性化学习，为学生提供个性化辅导和机器人教师。这些科幻作品激发了许多现实中的创新。在 1984 年的《Newsweek》采访中，苹果公司的联合创始人 Steve Jobs 预测，计算机将像自行车扩展我们的身体能力一样，扩展我们的思维能力、知识和创造力。几十年来，我们一直对利用计算机来帮助教育人们的想法充满热情。

这些科幻故事的共同点在于，它们都设想计算机有一天能模仿人类的智能。实际上，研究人员已经为实现这一 AI 愿景努力了超过六十年。1962 年，跳棋大师 Robert Nealey 与 IBM 7094 计算机对弈，结果被计算机击败。而早在 1957 年，心理学家 Frank Rosenblatt 就创建了 Perceptron，这是第一个人工神经网络，用计算机模拟神经元和突触来执行特定任务。在早期 AI 创新之后的几十年里，我们的计算能力只能处理像蚯蚓或昆虫大脑一样复杂的系统，且用于训练这些网络的技术和数据也非常有限。

在接下来的几十年里，技术取得了巨大进步，推动了当今一些最常见的产品和应用程序的发展，例如电影流媒体服务中的推荐引擎和语音控制个人助手（如 Siri 和 Alexa）。AI 在模仿人类行为方面变得如此出色，常常让我们难以分辨人类与机器的回应。与此同时，计算能力的发展使我们能够处理接近人脑复杂性的系统，并且在构建和训练神经网络方面也取得了重大突破。2017 年，谷歌推出了 Transformer 技术，这项技术带来了更快、更好的训练效果，并且在根据训练信息连接词语和概念方面更加精确。

这些系统的性能通常与底层模型的复杂性和架构有关。可以将模型看作是试图模拟现实世界某些事物的计算表示。例如，当气象学家试图预测飓风的路径时，他们会使用天气模型，这些模型包含数十亿或数万亿个较小体积的大气，并预测这些小体积之间可能如何相互作用。在大语言模型的情况下，它们是专门设计来建模单词之间的关联。在这种情境下，我们的建模对象不是大气条件，而是神经元和突触。大语言模型（Large Language Model），如 GPT-4（生成式预训练 Transformer 的缩写），本质上是庞大而强大的「文字大脑」，通过从书籍、文章、网站和各种书面材料中获取的海量信息进行训练。

通过分析和处理这些大量文本，语言模型学会了单词、句子和段落如何组合在一起的模式、语言和上下文。如果你向像 GPT-4 这样的大语言模型提问，它会根据从所有这些书籍、网页、视频转录和社交媒体帖子中获得的训练给出回答。虽然它缺乏人类大脑的真实世界感官体验，但它通过接触比任何人类在多次生命中可能阅读、观看或聆听的更多语言来弥补这一点。

在这样的背景下，2022 年夏天，我收到了 Greg Brockman 和 Sam Altman 的一封电子邮件。他们分别是 OpenAI 的总裁和首席执行官，OpenAI 是一家从事友好或社会积极人工智能研究的开创性实验室。该组织希望与我们会面并讨论潜在的合作。当时我还没有意识到，世界即将被颠覆。

当时，OpenAI 还需要四个月才会发布 ChatGPT，并且发布 GPT-4 还要七个月。他们希望讨论即将到来的发布。我对此很感兴趣，但也怀疑我们能否合作。我不认为新一代的生成式 AI（Generative AI）会立即对我们的任务有帮助。虽然 AI 技术在写作方面已经取得了一些令人印象深刻的成果，但在我看来，这些技术还未能真正掌握知识，也缺乏逻辑推理和演绎推理的能力，无法可靠地产生准确的事实。不过，我对 OpenAI 的成就非常敬佩。因此，我们安排了一次会面。

每一代这些模型的复杂性通常更高，可以通过它们包含的参数数量来衡量。参数可以看作是描述大语言模型中神经网络两个节点之间连接强度的数字，就像大脑中两个神经元之间的突触强度。2018 年首次推出时，GPT-1 有超过 1 亿个参数。一年后，GPT-2 有超过 10 亿个参数。GPT-3 拥有超过 1750 亿个参数。GPT-4 预计会有大约 1 万亿个参数。

OpenAI 的领导层认为 GPT-4 的增强能力会令许多人感到惊讶，他们相信这会让很多人既兴奋又可能感到不安。因此，他们希望与少数值得信赖的合作伙伴一起推出，以展示对社会有益的实际应用案例；可汗学院是他们首先想到的组织。他们想联系我们的另一个原因是希望我们能帮助评估 AI 本身。他们需要证明 GPT-4 具有推理能力、批判性思维和实际处理知识的能力。OpenAI 团队希望看看 GPT-4 在大学水平的生物学问题上的表现，而我们有成千上万个这样的题目。

我突然感到非常兴奋，因为我是全球首批见识到 GPT-4 能力的人之一。根据以往的经验，我知道在技术即将成熟时进行探索是最佳时机。如果你在大多数人还认为它只是玩具或分心的东西时就进行正确的投资和测试，当它准备好进入主流时，你就能够真正收获它的好处。这与视频学习初期的情况类似，当时很多人质疑 YouTube 只是一个用来消磨时间的娱乐平台。但早期的先驱者向我们展示了按需视频远不止是猫弹钢琴，事实上，你可以用它们来帮助人们学习。

如今，学生们几乎可以通过点播视频学习任何内容，这种方式在课堂上也越来越普及。Khan Academy 在这方面起到了重要作用，通过视频为全球数亿学习者提供了点播帮助。我们发现，视频不仅不会取代教师，反而可以分担部分讲解任务，让教师有更多时间进行个性化教学、动手实践或课堂讨论。这不仅没有降低教师的价值，反而让他们变得更加重要。现在，我们来看生成式 AI 是否也能做到这一点 —— 帮助学生学习，同时让教师提升自己的教学价值。

Sam 和 Greg 开始展示他们的 GPT-4 演示，他们从 College Board 网站上找来一道 AP 生物学选择题，问我答案是什么。我看了看，回答是 C 。然后他们让 GPT-4 通过聊天界面回答这个问题（类似于大家现在习惯使用的 ChatGPT）。片刻之后，GPT-4 正确地回答了问题。

我没立即说话，但内心已经有些激动，尽管还有些疑惑。「等一下，」我说，「这是一个能回答 AP 生物学问题的 AI 吗？」也许这只是个巧合，我想。「你能让它解释一下是怎么得出答案的吗？」

Greg 输入了：「请解释一下你是如何得到答案的。」几秒钟之内，GPT-4 给出了一个清晰简单且全面的解释。而且，它的解释如此自然，仿佛是一个人在回答，而不是机器。

这时，我的惊讶之情已经掩饰不住了。

「你能让它解释为什么其他选项是不正确的吗？」

Greg 照做了，片刻之后，GPT-4 解释了为什么其他选项是错误的。

接着，我问 Greg，GPT-4 是否能够编写一个原创的 AP 水平的问题。

它做到了，而且还写了十篇。

两个月后，我拜访了 Bill Gates，汇报 Khan Academy 的进展，并了解到 OpenAI 团队为什么展示 AP 生物学问题。Bill 告诉我，当他第一次接触 GPT-3 时感到惊讶，但他对 OpenAI 团队说，只有当它能通过 AP 生物考试时，他才会真正被震撼。OpenAI 团队在第一次演示中向我展示的是 GPT-4 现在可以做到这一点。

「这将改变一切，」我对 Greg 和 Sam 说，我的脑海中浮现出 GPT-4 可能重新定义教育、资格认证、工作和人类潜力的各种方式。

「我们也有同感，」Sam 回应道。「虽然它还不完美，但技术在不断进步。谁知道呢？如果我们做到位了，这可能会成为教育工作者的新工具。」

那些我们曾认为只存在于《星际迷航》中的技术，现在变成了现实。最伟大的科幻作家所设想的创新已经成真。

是时候举行 Hack-AI-Thon 了。

在 20 世纪 40 年代早期，数学家 Claude Shannon 提出了几项重要理论。其中，他制定了一种电子通信理论，这一理论后来成为数字技术的基础。1948 年，他在为 Bell Labs 工作时，开始探索我们今天称之为人工智能的领域。Shannon 尝试研究算法如何模拟语言，并在《贝尔系统技术杂志》上发表了题为《通信的数学理论》的论文。那时，数字计算机刚刚起步，还远未有互联网的出现。Shannon 通过信息理论首次提出，可以用一系列概率过程来近似英语语言。他通过记录单词在文本中出现的频率，设计了一种算法，能够预测下一个最有可能出现的单词。最终，这个小型语言模型生成了一句话。随着这一过程的不断改进，生成的句子也越来越自然。简而言之，像 GPT-3 和 GPT-4 这样的模型实际上是通过非常专业的神经网络训练而成的更复杂的大语言模型，而其基本思想可以追溯到 Shannon 的这项早期工作。

在 Shannon 的工作之后，另一位伟大的计算机科学家 Alan Turing 进入了人工智能的领域。除了他在破译德国密码和帮助击败纳粹的贡献之外，Turing 还探讨了 AI 的概念以及机器是否能模仿人类智能。1950 年，他发表了一篇奠基性的论文《计算机器与智能》，在文中提出了模仿游戏的概念，即我们现在称之为图灵测试的东西。

想象一下，你正在和一个人对话，但你看不到对方。你可能是在电脑或手机上聊天。这时，你如何判断对方是人还是机器？这就是图灵测试的核心。测试中一般会有一位评判员来评估人类和机器的回答。机器的目标是让评判员相信它是人类，表现出智能、理解和连贯的对话能力。Turing 提出，如果机器能持续欺骗评判员，使其认为它是人类，那我们就可以认为这台机器是智能的。换句话说，通过图灵测试的机器具有人类般的智能。

在 2022 年夏天，我接受了 Sam 和 Greg 的邀请，测试新的 GPT-4 技术。我不禁好奇，这项技术是否接近通过图灵测试。上世纪 90 年代中期，我在 MIT 学习人工智能。当时，有些简单的程序能在短暂的互动中骗过人类，但还没有能持续进行长时间对话并保持人类般感觉的程序。机器能够通过图灵测试一直以来都像是幻想，更别说在我的有生之年。然而，现在亲自试用这种可能接近通过图灵测试的技术，甚至可能已经通过了，这让我感到非常兴奋。这一进步堪比科学家实现冷聚变或超光速旅行。

在最初的兴奋之后，我也开始思考这种智能技术的社会影响。虽然 AI 能够解决很多问题，但也可能带来一些潜在的负面影响。如果这个大语言模型可以辅导学生，那么它也可以为他们写论文。万一新版本的 GPT 只是给学生提供了一个拐杖，反而阻碍了他们发展自己的研究和写作能力呢？我还想到，如果 GPT-4 能够通过帮助人们沟通和解决问题来赋能他们，那么它也可能让许多人失去工作和自我价值感。一种能够成为优秀导师的技术，也可能被不法分子用来欺骗或洗脑毫无防备的人。

我的脑海里不断浮现出各种担忧的情景，从对孩子们的数据收集到技术可能带来的成瘾性。我意识到，AI 的颠覆性要求我们必须认真对待它。除了 OpenAI，还有许多公司在大语言模型上投入巨大，包括 Microsoft、Google 和 Meta，更不用说俄罗斯和中国这样的国家力量。科技巨头们多年来一直在用某种形式的人工智能向我们推送广告、视频、搜索结果和社交媒体内容，这些我们每天都在接触。但这种 AI 显然不同，因为它确实与众不同。科幻作家一直区分能够优化单一任务的专用人工智能和能够像人类一样处理多任务的通用人工智能，后者可能带来乌托邦或反乌托邦的未来。

对许多人来说，像 GPT-4 这样的语言模型接近通用人工智能，因为它们能够写作并似乎能够推理任何主题，使其几乎在任何领域都有用。生成式 AI（Generative AI）还能生成和理解图像。尽管生成式 AI 显然会以我们难以想象的方式改变世界，但我意识到，决定是否接受这项技术并不是我或 Khan Academy 能左右的。它已经在前进。作为一个努力用技术做好事的人，我在思考能否利用生成式 AI 实现最大的正面影响，特别是在教育领域，推动我们向更美好的未来迈进。

那天下午（一个星期五），由于意外获得了 OpenAI 最新模型的访问权限，我坐在电脑前。整个周末，我几乎都在电脑前度过。连续十个小时后，我试图关机睡觉，但大脑依旧停不下来，想着这项技术的各种可能性，以及我们作为教育者如何与学生一起使用它。我意识到 GPT-4 的潜力真是令人惊叹。它不仅能解决复杂问题和回答棘手问题，还能解释其推理过程，并自行生成新问题。它甚至可以模拟具有类人特征的角色。在使用 GPT-4 后，我让它扮演了数学导师、科学导师和语言导师，每个导师都能进行对话。

但真正吸引我注意的是它能够以不同的语气和风格写作。举个例子，作为我学习 GPT-4 的一部分，我忍不住让 GPT 技术用唐纳德·特朗普的语气重写《独立宣言》：

朋友们，让我告诉你们，是时候宣布我们从这个失败的政府和这个糟糕的领导人乔治三世国王那里独立了。我的意思是，这个人简直是个彻底的灾难。他一直在剥夺我们的权利，他一直在无视人民的意愿，他对填满自己的口袋比真正帮助人民更感兴趣。这真的很悲哀，非常非常悲哀。

但是我们人民，不会再忍受下去了。我们要建立自己的国家，并且它将成为最棒的国家，世界上有史以来最伟大的国家。相信我，没有人比我更懂得如何让一个国家伟大。我们将拥有最好的经济，最好的军队，最好的所有一切。这将是巨大的。

接着，我让 GPT-4 用 Dr. Seuss 的风格写了《独立宣言》：

在自由之地和勇敢之家的国度，一个新的国家诞生了，不再受制于海外的国王我们宣布了独立，欢呼雀跃手握笔杆，心中燃烧着激情我们逐条写下了不满无代表不纳税不再有士兵驻扎在家中，不再有挫折我们坚信这些真理所有人都是平等的，不论你我我们拥有不可剥夺的权利生命、自由和幸福，我们将长存。

这种技巧在 ChatGPT 普及后变得很常见，但当时我是最早尝试这种技术的人之一。坦白说，GPT-4 比第一代的 ChatGPT 要好得多，第一代 ChatGPT 还要几个月后才向公众发布。我发现我的提示结果既令人印象深刻，也相当搞笑，甚至有点吓人。当我向它提问或请求建议时，它的回答感觉非常真实。没有人在幕后输入这些回应，也没有传统的 if-then 逻辑生成的文本。我收到的不是千篇一律和机械化的回答。相反，每次我问同一个问题时，回应都不同，并且考虑到了我之前与它的对话内容。

更具体地说，这让我看到了这项技术在 K-12 教育和高等教育领域的巨大潜力。虽然 AI 还不够完美，经常出数学错误，但随着我不断优化提示，效果也在逐渐改善。那个周末结束时，我在想，如果能召集几十位技术和教育领域的顶尖人才一同试用这个平台，会发生什么呢？OpenAI 也同意为 Khan Academy 团队中的大约三十名工程师、内容创作者、教育工作者和研究人员提供 GPT-4 的访问权限，让他们展开实验。

于是，我们决定举行一次黑客马拉松。

在 Khan Academy，每隔六个月，我们会有一周的时间让员工自由探索与公司使命相关的项目。我向团队中的一小部分成员展示了 GPT-4，大家便开始了头脑风暴和创新设计，开发出许多非常有意义的点子。这个我们称之为 hack-AI-thon 的活动引发了数十个全新的教育理念和模式。比如，AI 能否帮助教师编写课程计划？能否与学生进行辩论？能否创建项目？能否帮助学生减压或激发他们的创造力？能否测试学生或带领他们复习？教育者可以设计出学生与 AI 互动的新活动。AI 还可以帮助学生写作，通过即时反馈提高他们的写作水平。

从这里开始，hack-AI-thon 的参与者们探讨了关于安全性、安全和偏见的问题。（要记住，这是在 OpenAI 发布 ChatGPT 之前的很久。）我们发现了一些明显的担忧：让学生使用生成式 AI（Generative AI）来写论文、进行研究、替他们考试，甚至帮助他们申请大学，真的合适吗？我们担心人工智能可能会使我们的孩子变成一代不学无术的作弊者。随着 AI 的普及，曾经帮助孩子们做作业的父母可能会失去一个重要的沟通机会。对于教师来说，这到底是一个福音，还是会削弱他们的教学能力？我从未认为 AI 会让教师失业，在最理想的情况下，它会提升教师的教学能力，但我也担心它在某些关键方面会削弱这种能力。




大约二十年前，我也曾看到对教育中按需视频的类似担忧：它会成为学生的干扰吗？会降低他们的注意力吗？会让学生变得孤立而不是促进他们与教师之间的联系吗？学生们怎么知道该看什么？如果他们在某个科目上遇到困难，有问题要问，他们会向谁求助？

然而，探索永远不应被恐惧阻碍。我们在测试 GPT-4 的过程中，发现了许多解决问题的办法，这些办法在一定程度上还增强了其优点。比如，为了防止作弊，我们设想了一个拒绝直接给出答案的 AI 导师。这个导师像优秀的人工导师一样，提出引导性的问题。在考虑学生安全时，我们设计了一个记录所有对话并对老师和家长透明的系统。为了促进人与人之间的交流，我们建议提供一些工具，帮助教师和学生节省时间和精力。

在 hack-AI-thon 结束时，我们团队越来越相信，GPT-4 会成为教育领域的一个变革者。恰当运用它，会对教师的计划、教学和评分方式产生积极影响。将人工智能引入课堂，教育者可以解决那些现有技术和资源无法解决的顽固问题。学生有望比以往更快地学习和掌握更多知识，证明 AI 是提升人类智能和潜力的终极工具。人工智能可能会加速全球的学习进程，甚至让每个人都能享受到负担得起的世界一流教育。这项技术可能彻底改变我们的沟通、创造和信息消费方式，正如二十年前互联网、四十年前个人电脑和六十年前计算器带来的变革一样。

至于我，我感到充满活力。我越来越相信，通过适当的措施，我们可以减轻生成式 AI（Generative AI）的风险和潜在缺点。很明显，即使我们是最早使用这项技术的人之一，一旦全世界得知它的存在，变化将会在几个月内迅速发生。

探索勇敢与智慧的原则

2022 年 11 月底，在我们举办黑客马拉松活动两个月后，我们依然在探索这项技术的潜力。此时，OpenAI 向公众发布了 ChatGPT。这个初始版本在 GPT-3.5 上添加了一个聊天界面，而 GPT-3.5 已经推出了几个月。尽管这个版本不如 GPT-4 强大，但它立刻引起了全球的关注。仅在几天内，数百万人开始使用它，社交媒体和新闻媒体几乎都在讨论它。

然而，在这初期的兴奋浪潮中，许多人对学生作弊、AI 生成的事实错误或幻觉、偏见以及 ChatGPT 的数据来源表示担忧。我们目睹了社会开始应对这个强大但不完美的工具带来的影响，尤其是在教育领域。ChatGPT 推出几周内，全国各地的学区纷纷禁止使用它。这激发了我们在可汗学院的热情。我们必须证明不仅有解决方案来减轻这些风险，而且 AI 真的可以变革教育。我们希望用真实的工具和真实的学校来展示这一点，而不仅仅是理论上的讨论。

几个月内，OpenAI 计划发布 GPT-4。一旦发布，我们需要解决作弊、透明度和审核等问题。我们必须证明 AI 在实际教育环境中对教师和学生的价值。AI 可以帮助教师编写课程计划、监控课堂进度、提供实时反馈，甚至减轻教师的工作压力。我们还需要展示 AI 对学生的实际价值，如作为导师、辩论伙伴、指导顾问、职业教练，推动他们在学术上取得更好的成绩。为此，我们与 OpenAI 合作，组建了一个快速原型设计团队，开始开发一个名为 Khanmigo 的 AI 教育平台。

正是在这种探索新应用并建立安全保障的精神下，我产生了一个想法。大家都在说 AI 会通过为学生写论文来助长作弊，但如果 AI 不为他们写，而是与他们一起写呢？

2023 年元旦，我邀请女儿 Diya 和我，还有 GPT-4 一起写一个故事。这不是我第一次让 Diya 参与教育实验或测试原型。通常，我会请 Diya、我的儿子，或者 Khan Lab School 或 Khan World School 的学生或老师帮忙，尝试新的练习，确保学生和技术的互动顺畅。我发现这种亲自参与的用户研究非常有帮助，而且非常贴近实际。我的「助手们」也喜欢这种体验，因为他们可以试用一些真正能够影响学习者生活的新项目或创新。对于 GPT-4，这次体验尤为真实。所以我给 GPT-4 设置了一个提示，让它和我们一起写故事，而不是代替我们写。我告诉它我们希望以对话的方式互动，并且保持一定的语气。

然后 Diya 开始创作她的故事，讲述社交明星 Samantha 被她的好友 Emily 从荒岛上救出的经历。Diya 写了一部分，接着大语言模型接手继续。Samantha 自我介绍，讲述她的生活，并加入我们的创作过程。令我们惊讶的是，Samantha 通过 GPT-4 生动地再现了冒险故事，通过引人入胜的对话完美呈现了 Diya 创造的两个角色的个性。Diya 和 AI 一起继续创作。他们的故事充满了暖心、搞笑和悲伤的时刻，从 Samantha 对她的设计师衣橱的担忧，到 Emily 生病去世时的感人反应。

在整个互动过程中，AI 展现了它进行复杂且有意义对话的能力。它对 Diya 的提示回应得非常自然和真实。作为一名家长，我看到我的女儿通过 GPT-4 发挥她的想象力，感到非常振奋。Diya 使用的 AI 精准地捕捉了她所创造的虚构世界，并且能够跟踪她与角色之间的对话。它还记住了 Diya 在故事中设定的规则以及她之前提供的信息。AI 拓展了她的思维，帮助她提升写作和创造力。通常，写作是一个单向的活动，创作者将想法写在纸上，而现在，这种写作 —— 选择合适的词语和找到合适的表达方式 —— 变成了人类和机器之间的双向互动。我的女儿，年仅十一岁，成为了世界上最早在创作时与故事互动的人之一！

这种体验实在令人惊叹。我们正在使用一种将写作以及教学和学习提升到新高度的技术。我突然意识到，将这种功能带给所有学习者的重要性。我们学习和教学的未来潜力在我眼前改变。当我的女儿和「萨曼莎」忙于写他们的故事时，感谢 AI，我们正在书写一个关于教育的新篇章，这个篇章将挑战人们要谨慎对待但不必害怕变化。

现在，全球开始意识到大语言模型的潜力以及它们对教育的巨大影响。要充分利用这种技术，不仅需要创造力，还需要一种我称之为「理性勇气」的态度。这种勇气源于我们在面对技术飞速发展时的合理担忧，并通过了解其挑战和潜在机会来增强自己。

为了最大化这项技术的优势，我们需要重新审视当前的可能性。同时，我们也要考虑如何减轻风险、缓解恐惧和克服犹豫。这意味着我们需要重新思考从教师的角色，到孩子如何使用多媒体，再到人们如何获得认证，以及如何帮助毕业生找到工作等各个方面。

我们正处于一个教育的转折点，这个转折点将带来深远的影响，并且正在改变和将继续改变学习、工作以及人类目标的方方面面。