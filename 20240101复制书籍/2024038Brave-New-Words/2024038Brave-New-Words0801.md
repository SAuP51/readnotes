## Part VIII: AI, Assessments, and Admissions

Not everything that can be counted counts, and not everything that counts can be counted.

—William Bruce Cameron

Evaluation is creation: hear it, you creators! Evaluating is itself the most valuable treasure of all that we value. It is only through evaluation that value exists: and without evaluation the nut of existence would be hollow. Hear it, you creators!

—Friedrich Nietzsche

The Future of K–12 Assessments

It has become fashionable to bash standardized tests in the United States. Every state has "summative" assessments at the end of each school year to measure how students and schools are performing. People often criticize these tests for being too narrow—they primarily use multiple-choice questions that target a subset of what is actually important in life. This can create pressure for educators to similarly narrow their focus in the classroom.

That's not all, though. Others argue that these tests take time away from learning and are not really actionable. By the time the scores come in over the summer, or at the beginning of the following school year, kids have moved on to a new grade with a new teacher. In addition, students have very little incentive to care about showing their best work on a test that is not connected to their grades. Also, demographic differences in performance can lead to claims of bias against some groups or schools. As education has become more politically charged, the lack of transparency into what these tests actually assess makes people skeptical.

Let's take a step back, however. When people raise objections to standardized tests, I like to interrogate what part they don't like and whether they are throwing out the baby with the bathwater. If they are against assessments altogether, I ask them how we can get better at anything without measuring it. And if we are going to measure, standardizing that measurement is arguably fairer, since it applies the same standard to everyone (versus "unstandardized" assessment). If the issue is with the perceived narrowness of what these tests measure, wouldn't the answer be to broaden the scope of the assessments to make them richer rather than abandon them entirely? Likewise, if the critique is around actionability or transparency, couldn't we make the tests more actionable and transparent?

Most of all, even though standardized tests might be imperfect, does removing them really make things more or less equitable? If a school serving underrepresented groups doesn't know where and how their students may be falling behind, how can they begin to fix the problem? Is it somehow better for educators, students, and families to not know their gaps? Eventually, these deficits will surface regardless. This is likely to happen years later, in college or in the workforce, when it is much harder to fix after years of falling behind.

I'd rather think about how we can improve standardized tests rather than try to remove them entirely. Solutions have existed even before generative AI. Let's consider the critique that there isn't much that teachers can do with the standardized testing results. Well, if the assessments could feed into a software platform for personalized practice—for example, having students work on addressing different weak points based on the standardized testing data—the information becomes actionable. Over time, the personalized practice software would make sense of a student's previous assessments and provide that student with more targeted recommendations.

Khan Academy has, in fact, done this for some standardized tests for many years now. That is, we use standardized testing information to better differentiate practice in a classroom, improving student outcomes. In a study of more than three hundred thousand students using standardized test scores to inform personalized practice on our platform, " students who engaged . . . during the 2021–22 school year at the recommended dosage of 30+ minutes per week exceeded growth projections by 26% to 38%, depending on grade."

Continuous standardized assessments while students are learning also avoids taking away valuable instruction time. Every exercise on our platform is standardized, and we have millions of data points about how students from different grade levels and demographics perform on them. Rather than just having students take a traditional state summative test once or twice a year, they can regularly practice their skills on our platform. Educators can then use the generated data to measure student learning in a standardized way. This gives a more accurate and regular read on how a student is performing. That data then becomes actionable by driving student recommendations for further learning. This type of continuous assessment offers higher-quality data points on a much more regular basis. Where traditional standardized tests might cover fifty to one hundred questions once or twice a year, continuous assessments can glean this much information every week without them even feeling like a separate evaluation. This approach also addresses the issue with student motivation: you are more likely to care if your daily practice is also assessing you in a standardized way behind the scenes, as that work impacts your class progress and grades.

Much of the political angst over assessments and what is happening inside the classroom is due to external stakeholders like parents and politicians not being able to directly observe what students are experiencing. Instead, they rely on second- and thirdhand accounts, which might not be entirely accurate, or they fail to understand how high-level standards tangibly manifest in a test or classroom.

The lack of transparency and flexibility of traditional standardized assessment stems from both the expense of creating the assessment items and the fact that they must remain secure; if any of them leak, the entire assessment can become invalid. On the other hand, if you have easily accessible online platforms that adaptively assess from a large bank of items—think hundreds of thousands of questions—you can let more stakeholders try out the assessment whenever they want without undermining it. This is because an adaptive assessment will give every student a different sequence of questions based on how they performed on previous ones. It's unlikely that two students will ever see the same set of questions.

Generative AI holds the potential to help with all of this. Large language models aren't yet good enough to make high-quality assessment items completely on their own, but they can help a human question writer/reviewer become much more productive. Eventually, this will allow us to produce many more items with the same resources, enabling a new wave of even more transparent and accessible assessments.

This still leaves the question of how to deepen and broaden the skills that standardized assessments can measure. While multiple- choice or numeric-entry questions can get you pretty far when assessing some types of skills, they can't really capture how well you write, engage with a problem, or think creatively. Historically, these more nuanced tasks have been prohibitively expensive to assess widely. To gauge even basic open-ended questions, you need expert human reviewers working with complex rubrics and systems to ensure consistency. Richer assessments akin to a thesis defense for a PhD or a job interview have historically been impossible to do at scale.

This is about to change. The latest generation of large language models holds the potential to allow us to conduct this type of rich assessment economically and universally.

Consider reading comprehension: Today, students read a passage and then answer a few multiple-choice questions based on it. These questions might ask something about, say, the author's intent, followed by four choices. In the coming years, we will increasingly see assessments use generative AI to engage students about their views or the author's intent without the need for multiple choices. It will ask students to just write or speak their thoughts, and the AI will be able assess that response in a consistent way. Even better, it will be able to engage in a conversation with students about why they feel that way and discuss the evidence they are drawing on. The entire assessment will resemble a fluid, wide-ranging conversation with a thoughtful, empathetic, and fun mentor. Parts of it might involve role-playing or trying to work through a simulation. It wouldn't necessarily even have to be separate from learning. The same AI tutor that is there to help you would also build up evidence of what you know and don't know.

This goes beyond language and reading comprehension. In math, the AI can ask students to explain their reasoning or develop a proof. In science, it might assess how well a student can design an experiment or critique a research paper, arguably two of the most powerful elements to becoming a scientist. AI-driven simulations can assess student problem-solving skills. As AI takes on increasing visual capabilities, it will be able to critique and assess visual works, pictures, or videos of a presentation.

Of course, using AI for assessment can rightfully make folks wary. What if the AI has biases that are not immediately apparent? What if it makes mistakes? I try to compare this kind of hypothetical to the status quo. Current assessments are written by thoughtful but fallible human beings with their own biases. We already know that by not leveraging AI, we are limiting ourselves to a much narrower type of assessment that arguably magnifies a bias toward prioritizing easy-to-measure skills over ones that are harder to measure but perhaps more important. Historically, when we have been able to administer richer assessments, like in PhD oral thesis defenses or job interviews, they are inconsistent and rife with more bias than any current standardized exam. Generative AI allows us to capture the best of both worlds: standardization and scale with richness and nuance. Because of its potential accessibility, stakeholders will have a far easier time trying it out and auditing it themselves.

I am not saying that we should blindly assume that any AI assessment is going to be good. In fact, I am afraid a lot of people are going to create some very bad ones, rife with bias. I also believe, however, that with proper care, transparency, and guardrails, we can mitigate the risks and develop assessments that are far richer, more accurate, and fairer than those that we have today. This will have positive consequences for the education system as a whole, reopening the aperture of what makes a quality education. By measuring skills long thought to be immeasurable, such as communication, creativity, and curiosity, it will naturally motivate the system to care a lot more about developing the whole person.

The AI of College Admissions

The classic components considered in college admissions are grades, standardized tests, extracurriculars, essays, and letters of recommendation. AI will change how most if not all of these factors are valued, developed, and evaluated.

I've already argued that generative AI is going to transform schoolwork and grading in the classroom; students will be able to do much richer assignments, and teachers will have more support grading them. I've also discussed how standardized assessment is likely to change. Assessment will be deeper, much more continuous, and indistinct from learning. Over time, either standardized tests like SATs and ACTs will move in this direction, or new assessments will enter the space to take advantage of the opportunity.

Other than extracurriculars, the remaining components—essays and recommendations—both involve writing. This is the most obvious place where large language models introduce some very big ethical questions. Teachers and guidance counselors may use generative AI to write their recommendation letters. Students are likely to use large language models to generate impressive-sounding essays that misrepresent their actual writing ability or creativity. This poses a challenge for admissions officers to accurately evaluate the validity of applicants' work.

And yet heads of admissions at top universities tell me that the advent of generative AI has simply shined the spotlight on inequities that they have known about since long before large language models arrived. Take the Varsity Blues scandal, for example. This was a case in which wealthy celebrity parents paid hundreds of thousands of dollars to hire an unethical college admissions coach who not only wrote application essays but went as far as completely fabricating extracurricular activities, including photos. While this is an extreme example, an entire industry exists around college admissions coaches that only affluent families can afford. The going rate in Silicon Valley, where I live, is roughly four hundred dollars per hour for the top coaches. This can amount to tens of thousands of dollars to assist one student through a college admissions cycle. What do these coaches do? The more ethical ones advise students on how to approach extracurriculars and essay topics, help families think through good college options, and provide students with thoughtful feedback on early essay drafts. At the more unethical side of the spectrum, they might provide so much editing of a student's essay that they are essentially writing it for them. Either way, these affluent students receive significant help. Even if they do not hire a coach, many of these families have a lot of insider knowledge about the byzantine college admissions process and use it to give their children a leg up.

Tools like ChatGPT are obviously much more accessible to a broad group of people who never could have afforded high-priced college admissions coaches. And like these coaches, generative AI can be used for ethical and unethical purposes, as well as everything in between. It has now opened the door for everyone to play in the ethical gray area that was once only the domain of the affluent.

Something similar is likely to happen when it comes to recommendations. High-priced admissions coaches can't write recommendations, but guidance counselors and teachers serving wealthier students tend to have a lot more knowledge of how to give their students the best shot at university admission. Wealthier schools also tend to have smaller classes in which teachers and guidance counselors can get to know their students better and have more time to spend on each student's recommendation. Now someone writing a reference can work with generative AI tools to better express the strength of an applicant.

So, on the positive side, generative AI can help close the gap between the rich and poor. Now everyone—not just the affluent—needs to decide how much help is too much help. On the negative side, less-ethical students are likely to push the envelope, putting the more-ethical students at a disadvantage. Meanwhile, admission directors need to wrestle with whether this entire exercise of writing essays even still provides a credible signal for admissions.

To address that, it's worth questioning why essays and recommendations are part of admissions in the first place. In most countries, admission to highly selective universities is a fairly objective process. In India, entry to the hyperselective Indian Institutes of Technologies (IITs) is based solely on the Joint Entrance Exam (JEE). IITs admit the students with the top test scores, permitting quotas for some underrepresented groups. Not only do the highest scorers get their pick of IIT campuses, they also get to select their majors first. In India, this is a deliberate attempt to steer clear of the corruption that has often infected other institutions in the country. Nothing remotely subjective like essays, recommendations, or extracurriculars is involved.

On the other hand, admissions directors at highly selective universities in the United States will talk about subjective things like "building a community of diverse future leaders." Yes, they index on test scores and grades to some degree, but many of these institutions could fill their freshmen classes many times over with students who have perfect test scores and GPAs. Put another way, at some top schools, half of the applicant pool will have grades and test scores indicating that they could more than succeed academically if admitted, yet the university will only be able to admit 3–6 percent of them. This leads to a highly subjective process of trying to gauge the student's personality and backstory through essays, extracurriculars, and recommendations. Have the students overcome obstacles? Do they seem collaborative? Are they likely to make an impact on the world one day? These are big, deep questions to ask about young people who are seventeen or eighteen years old. I think many people are skeptical of how well admissions officers can judge these qualities based on some essays and recommendations that are subject to significant outside influence.

Extracurriculars are arguably a more tangible display of a student's leadership or commitment to community, but this, too, can be hard to judge. Did the student win the international science fair on their own? Is it a coincidence that their experiment studied heart disease and their mother is an academic cardiologist? Was that volunteer work really substantive or just something that sounds impressive?

This has all led to a randomness in American competitive college admissions that is clear to anyone who has been involved in the process. Many of the brightest, most collaborative, and poised people have been rejected far more than one might expect. The assumption is usually that they weren't sufficiently represented by glowing recommendations or unique essays. On the other hand, visit any highly selective college and you will meet many impressive young people. You are also likely to meet many who are struggling academically or do not seem to embody traits like humility, collaboration, or leadership. Most assume that these students were unusually good at constructing a paper narrative about themselves and gaming the system—or that their family was good at hiring someone who did this for them.

But what if we could have more standardized ways of evaluating "soft skills" like leadership, collaboration, empathy, and community service? Even better, what if this were coupled with ensuring deep academic competency? It turns out that this predates AI, but AI is going to take things to another level.

In 2020, I launched Schoolhouse.world to give anyone free, live tutoring via Zoom. This was more needed than ever, considering how many students were falling behind because of the COVID-19 pandemic. We have been able to keep it free by enlisting vetted volunteers to do the tutoring. The first step of the vetting process is to ensure the volunteers have mastery of the material they are going to tutor. They take the appropriate assessments while a separate tool records their face and screen. The volunteers have to explain their reasoning out loud. If they get at least a 90 percent on the assessment, the video is submitted for peer review. Assuming that everything looks good, they are allowed to start their tutoring journey, which still involves more vetting and training on the craft of tutoring itself. It's a rigorous method, ensuring quality tutors. After every tutoring session, students rate the volunteers. The volunteers have a transcript page that summarizes all the subjects they are certified in, the number of sessions they have run, their average rating, and any other qualitative feedback from the community that they'd like to highlight.

Jim Nondorf, the head of admissions at the University of Chicago, reached out to me soon after, asking if they could use the Schoolhouse.world tutor transcript for college admissions. His rationale was that any high school student who was a highly rated tutor for, say, calculus, surely knows the material well, especially considering our rigorous vetting process. Even more, if they have done many tutoring sessions and are highly rated, they are also likely to have strong leadership, communication, and empathy skills, not to mention their commitment to helping others by spending hours tutoring for free. We thought this was a great idea, and that fall, the University of Chicago made the Schoolhouse.world transcript an optional part of their application process. By the next admissions cycle, MIT had signed up as well. Fast-forward three years, and the list has grown to eighteen universities, including Yale, Brown, Caltech, Georgia Tech, and Columbia, with more added each year.

They all value the Schoolhouse.world transcript for the same reason that Jim Nondorf does: it is a dynamic and standardized way of measuring both subject-matter competency and communication, empathy, community service, and leadership. Unlike in the past, when admission officers didn't have a lot to go on if a student said that they did regular community service, on the Schoolhouse transcript, the extent and quality of their service is quantified in a standardized way. It is pretty much impossible to fake being a high-quality tutor over hundreds of sessions. Because of this, I learned during early conversations with several of these schools that students submitting these transcripts generally have a higher acceptance rate than the broader pool. A side benefit to all this is that it also provides a strong incentive for ambitious high schoolers to become tutors and help others.

How does AI play into this? First of all, Schoolhouse.world is already using AI to give volunteer tutors feedback on their tutoring sessions. The AI can "observe" Zoom sessions via the transcripts and give the tutors pointers on how they can improve. In the near future, it will give tutors real-time tips on how to serve their students better. Eventually, it will be able to provide narrative assessments of the tutor's style and capability on the Schoolhouse.world transcript, providing yet another rich input for admissions officers. Most important, the Schoolhouse.world example starts to point to how we can reimagine admissions altogether with AI.

Rather than essays or recommendations alone, what if the AI could do extensive text- or voice-based interviews with students, guidance counselors, and teachers? A protocol like ours could ensure that the interviewee is alone and not being fed answers by anyone. Eventually, the AI might make use of the video as well, which would be hard for a person to game. The interviewing AI would be aware of the student's grades, SAT/ACT scores, and extracurricular activities and then use that information to provide accurate references. Students could still submit essays and recommendations, but the AI could dig deep into interviewees to ensure that students authentically know what they are talking about.

Admissions interviews, typically conducted by alumni living in the same area as the student, are not conducted uniformly across all prospective students, and those that take place are incredibly inconsistent with one another. They can be useful for admissions officers to screen out applicants with obvious red flags, but they aren't super useful for comparing the bulk of students who all seem exceptional on paper. AI allows this process to become far more scalable, consistent, and auditable. In this context, the AI can consistently summarize its interactions and rate them in multiple dimensions based on a rubric created by the admissions office.

There is even the possibility that AI agents can vouch for the student themselves, just like a teacher who knows the student well. Think about it this way: an AI platform like Khanmigo has been working with you for some period of time. Whether you have used it for a month or for many years of schooling, it knows your strengths and your passions and can plausibly render a dynamic picture of who you are. When it is time to apply to college, the AI can write a recommendation letter for you. The letter is standardized across every student who uses the platform, only it has different memories based on its experiences with each learner. Imagine if everyone in the country had the same teacher. This teacher would actually be a pretty good arbiter. If we wanted to take this to the extreme—and it is not clear that we do—the AI recommender could talk to the AI interviewer on the admissions side to see if there is a good fit.

I know this raises fears of bias in both directions. There are some biases you want. You want the process to be biased toward thoughtful, collaborative young people who could be tomorrow's humble future leaders. You of course don't want it to be biased along lines of gender, race, religion, or geography. A 100 percent bias-free solution might be impossible, but that shouldn't be the hurdle. Instead, any AI system needs to be demonstrably better than the status quo, which usually involves all sorts of bias. This is not hypothetical. In a 2018 Supreme Court case, it was clearly established that Harvard admissions officers consistently rated Asian American applicants lower on personality traits, oftentimes arbitrarily overruling the observations of in-person interviewers. Harvard's admissions process scored applicants in five categories—"academic," "extracurricular," "athletic," "personal," and "overall"—ranking students from 1 to 6, with 1 being the best. White applicants got higher personal ratings than Asian Americans, with 21.3 percent of white applicants getting a 1 or 2 compared to 17.6 percent of Asian Americans. Alumni interviewers gave Asian Americans personal ratings comparable to those of white applicants, but the admissions office issued them the worst scores of any racial group.

It took a major lawsuit for this data to surface. Most of the time, the biases embedded in this very opaque process are well hidden. The power of an AI-based interviewer and assessor is that they can be audited. You can test them with identically qualified applicants with different demographics and publish the results to ensure consistency across race, gender, or background.

Rather than introducing new problems in college admissions, AI is forcing us to realize existing deficiencies while offering the possibility for positive change. Used thoughtfully, perhaps with a bit of educated bravery, it might enable us to move to a fairer and more transparent world.