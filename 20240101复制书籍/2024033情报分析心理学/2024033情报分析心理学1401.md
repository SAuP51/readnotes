第三部分认知偏见 ［第九章］

## 0901. 什么是认知偏见

本章将以极短的篇幅概括论述认知偏见的本质。本章后面

的四章会具体介绍在评估证据、分析因果关系、判断可能性以

及评估情报报告过程中的认知偏见。

在本书第二章和第三章中，我们讨论了人类思维过程的基本局限。

认知心理学和决策学方面的大量研究都是基于这样一个基本前提，即这

些认知局限导致人们采用各种简化策略和经验方法来减轻在判断和决策

过程中处理信息的思维负担。这些简化的经验方法通常可以帮助我们

应对复杂和模糊问题，但在许多时候也会导致可预见的错误判断，也就

［1］原注：这一研究深受下面这篇具有开创性价值的文章的启发：AmosTversky

and Daniel Kahneman，＂Judgment under Uncertainty: Heuristics and Biases，＂Science，27September 1974，Vol.185，pp.1124-1131。此外，有关该研究的综述还可见于以下几部著作： Robin Hogarth，Judgment and Choice （New York: John Wiley ＆ Sons，1980），Richard Nisbett and Lee Ross，Human Inference: Strategies and Shortcomings of Human Judgment （Englewood Cliffs，NJ: Prentice-Hall，1980），and Robyn Dawes，Rational Choice in an Uncertain World （New York: Harcourt Brace Jovanovich College Publishers，1988），其中第一部著作把这一领域的研究按照主题组织起来，做了一份精彩的参考文献。［第九章］什么是认知偏见 145

是认知偏见。

一、认知偏见的特点

认知偏见是因简化信息处理策略引起的思维错误。我们有必要将认

知偏见与其他形式的偏见，如文化偏见、组织偏见，或因个人原因产生

的偏见区分开来。换言之，认知偏见的根源并不是针对某一判断的情感

或知识偏好，而是处理信息过程中下意识的思维方式。认知偏见是可预

见的、持续存在的思维错误。例如：

某物体的目视距离一定程度上取决于其清晰程度。它越清

晰，看起来距离就越近。这种规律是有一定道理的，因为在任

何环境之下，物体的距离越远，看起来就越模糊。但是，如果

在判断距离时完全依赖这一规律，就会导致一系列错误。具体

地说，能见度低的情况下，物体轮廓会模糊，此时物体的距离

经常会被高估。相反，能见度好的情况下，物体清晰可见，其

距离又容易被低估。因此，假如以物体的清晰度作为判断其距

离远近，就会导致常见的偏见。

这种判断距离的经验法则相当有用。它在多数情况下是起作用的，

有助于我们应对生活中的模糊性和复杂性问题。但在某些可预见的环境

中，这种经验也会让我们形成有偏见的判断。

认知偏见与视觉上的错觉有一点很相似：即使我们了解其本质，但

［1］: Amos Tversky and Daniel Kahneman，＂Judgment under Uncertainty: Heuristics and Biases，＂Science，27 September 1974，Vol. 185，pp. 1124-1131.146 情报分析心理学

错误仍然无法避免。意识到偏见切实存在，并不能保证更精确的认知。因此，要克服认知偏见是极度困难的。

二、认知偏见的影响

心理学家进行了大量实验，目的是确定人们依据不完整或模糊信息做出判断时会使用哪些简化的经验规则，并且（至少在实验室环境中）显示出这些经验法是如何左右判断和决定的。在接下来的四章，我们会讨论与情报分析密切相关的认知偏见，因为这些偏见会影响证据评估、认识因果关系、预测可能性以及情报报告的后续评估。

在讨论具体的偏见之前，我们有必要先研究一下这些实验证据的性质，考虑我们可以在多大程度上总结出一般性规律，并判断在美国情报界是否也流行这些偏见。

心理实验揭示了某个偏见的存在，但这并不意味着每个人的每个判断都存在偏见，而只能说明在任何一个群体中多数人的多数判断或多或少存在偏见。这种实验证据应作为概括群体倾向的依据，而不能成为确定各个个体思维的依据。

我认为，这些实验得出的结论也同样适用于情报分析人员。不像其他许多心理实验使用未毕业大学生作为被试，这些实验大多数被试都是来自各领域的专家，有内科医生、股市分析师、赌马分析师、国际象棋大师、研究项目主管，还有职业心理学家。大多数情况下，实验中进行的思维任务都很实际，也就是说这些任务类似于专家们日常工作中需要做出的判断。

当我们把实验室结论运用到现实世界时，不可避免地会出现一定［第九章什么是认知偏见 147

的误差，但中情局情报分析培训班的学员们知道这些观点后，发现它们很有意义、具有启发性。笔者也曾以美国海军研究生院（NavalPostgraduate School）国家安全事务系的军官们为被试，做过一些同样的简化实验。［第十章］

证据评估中的偏见

评估证据（evaluation of evidence）是分析工作的一个关

键步骤。但人们依据哪些证据，以及如何理解证据却会受到

一系列外部因素的影响。叙述生动和细节具体的信息的影响

往往过高，而可能拥有更大证明作用的抽象信息或统计数据

却往往被忽视。我们也几乎从不考虑缺乏证据会有什么后果。

人类思维对证据的一致性过于敏感，却对证据的可靠性不甚

敏感。最后，即使证据已被彻底否定，但它形成的印象还会

继续存在。

情报分析人员是在一种独特的信息环境中工作的。证据来源异乎寻常的广泛，包括报纸和通讯社、美国使馆官员的观察、特工和临时线人的报告、与外国政府的情报交换、照相侦察、通信情报，等等。每一种来源都具备特有的优点和弱点、潜在或现实的偏见，以及可能被操纵与欺骗的不足之处。这个信息环境最显著的特点就是多样性：来源众多，［1］原注：笔者曾将本章原文以非保密形式发表在 1981 年夏季号的《情报研究》杂志上，题目相同。［第十章］证据评估中的偏见 149

而且各种来源的可靠性不同，每种来源报告的信息通常不完整且时常与

其他来源的信息不符，甚至冲突。信息的可靠性无法确定且相互冲突，

这是情报分析工作的一大顽疾，而在获得所有证据之前就要对当前事件

迅速做出判断则是另一顽疾。

分析人员对于信息流人的控制相当有限。要求情报线人报告某些具

体问题往往既难协调又耗费时间。某些重要问题的证据比较零碎或根本

不存在。绝大部分人力情报来源的信息充其量是二手货。

在这样的环境下，意识到偏见并要避免尤为困难。本章将讨论的大

部分偏见相互之间并无联系，只是因为它们都与证据评估相关所以才归

纳在一起。

一、把生动性当标准

信息对人类思维的影响与它作为证据的实际价值之间并不成正

比。具体地说，生动、具体、亲身经历的信息对我们思维的影响力，

要远远超过证据价值高得多但平淡、抽象的信息。比如：

1. 人们直接认知的信息，也就是说亲眼所见或亲耳所闻得到

的信息，要比证据价值可能更大却是二手的信息影响力更大；

2. 案例叙述和轶闻要比信息量更大的抽象总结或统计数据

影响力大。

［1］原注：笔者在本章中所引用的观点和例子绝大部分源自：RichardNisbettand Lee Ross，Human Inference: Strategies and Shortcomings of Social Judgment （Englewood Cliffs，NJ: Prentice-Hall，1980），Chapter 3.150 情报分析心理学

我们亲身经历的事情要比通过书面阅读了解的更加难忘；具体的词

汇比抽象词汇更易记住（remember）；而一切词汇都要比数字更容易回

忆（recall）。简言之，具有上述特点的信息更容易吸引和控制我们的注

意力。它们比抽象的推理或统计摘要更易存储和记忆，因此不仅在当前

影响更大，而且今后也会继续影响我们的思维。

情报分析人员通常面对的都是二手信息。他们得到的信息来自他人

书面文字的转述，而不是亲眼所见或亲耳所闻。这多少是由于受自己的

中情局公开雇员身份所限。相比学术界和政府中的同行们，大部分情报

分析人员待在对象国的时间、与该国国民的接触都要少一些。他们偶尔

到对象国访问，或是同对象国国民直接对话，这些都是难忘的经历。这

样的经历可能产生全新的领悟，但也可能具有欺骗性。

如果权衡证据的方式适当，具体和感性认识得到的信息能够也应该

被赋予更高重视。绝大多数情况下，当抽象理论或二手报告与个人观察

之间发生矛盾时，后者都会占据上风。有许多不要相信二手数据的警

语，比如，「不要相信纸上写的」，「统计数据什么也说明不了」，「眼见

为实」，「我自己就是从密苏里州来的……」，等等。

令人奇怪的是，我们的语言中没有一条类似的格言警告人们不要被

自己的观察误导。眼见并不一定为实。

情报分析人员和特工的亲身观察，可能与二手描述一样具有欺骗

性。绝大部分访问外国的人所接触的仅仅是当地人中的一小部分，这

些人只能代表这个国家社会中的一个小群体。结果往往就是片面和扭

曲的认识。

此类错误有一种常见形式，即把某个单一的生动事例置于比通过大

量统计数据或抽象推理得出的结论更高的地位。如果某个准备购车的人

不经意间听到另一个陌生人抱怨自己的沃尔沃牌汽车有问题，这种抱怨

［1］原注 ： A. Paivio，Imagery and Verbal Processes （New York: Holt，Rinehart ＆ Winston，1971）.［第十章证据评估中的偏见 151

对他的影响，也许同《消费者报告》（Consumer Reports）中关于进口轿车年均维护费用的统计数据一样大。如果这样的个人意见来自于他的兄

弟或好友，很可能更受重视。但从逻辑上看，这条新信息不过为《消费

者报告》中的统计数据增加了一个新样本。一个沃尔沃牌汽车车主的个

人经验几乎没有证据价值。

尼斯比特（Nisbett）与罗斯（Ross）将此称为「‘有个人……'症

候」（the「man-who＂syndrome），并列举了以下不同例子：

1.「但我认识一个人，他每天抽 3 包烟，却活到了 99

岁」；

2.「我从没去过土耳其，但上个月我碰到一个去过的人，

他认为……」

显然，「有个人……」的说法作为证据的实际价值，往往低于引述

者的期望和听者的感受。

把生动性作为决定证据影响力的标准，所造成的最严重后果就是：

某些类型的证据虽然价值极高，但仅仅由于比较抽象而影响极其有限。

特别是缺少丰富和具体细节的统计数据，它们常常会被遗漏、忽视或极

度轻视。

例如，美国公共卫生署长（SurgeonGeneral）关于吸烟与癌症存

在联系的报告本应导致人均烟草消费量下降，但过去 20 多年间这种

变化从未出现。医生们对此的反应尤其具有启发意义。相比普通大

众，所有的医生都知道这项统计性证据，并且也更了解吸烟造成的健

康问题，但他们对这项证据的反应却因自身的医学专业不同而迥然相

［1］ Richard Nisbett and Lee Ross，Human Inference: Strategies and Shortcomings of Social Judgment （Englewood Cliffs，NJ: Prentice-Hall，1980），p. 56.152 情报分析心理学

异。卫生署长的报告发表 20 年之后，每天都进行肺部 X 光检查的放

射科医生的吸烟率最低。诊断和治疗肺癌患者的内科医生吸烟的可能

性也很小，但许多其他专业的医生却继续吸烟。医生继续吸烟的概率

大小，同其专业与肺部疾病联系的远近直接相关。换言之，即使是最

能够理解和接受统计数据的医生，生动的亲身经历的影响也要远远超

过有效的统计数据。

无数个人轶事、对不同信息来源或敏感或漠然的真实记录和受控实

验可以反复证明：「数据归纳虽然在逻辑上意义重大，影响力却要小于

那些不太重要但更加生动的证据。」同样的，情报分析人员也不重视统

计信息。

除非轶事或个人经历具有典型意义，否则分析人员不应该赋予它们

过高价值，在可以获得基于更有效的样本之上的综合数据时，甚至可以

完全不理会它们。

二、缺乏证据

情报分析工作的一个显著特点，是往往缺乏关键信息。情报分析人

员一般依据问题的重要性和他们察知的情报用户的需求，而不太考虑能

否获得信息。分析人员不得不最大限度地利用现有的信息，虽然有时候

也会考虑到仍然缺失许多相关信息这一点。

在理想状态下，情报分析人员能够确定缺少哪些相关证据，并将这

一点作为因素考虑进去。他们还要能够预测缺失证据的可能影响，并相

［1］: Richard Nisbett and Lee Ross，Human Inference: Strategies and Shortcomings of Social Judgment （Englewood Cliffs，NJ: Prentice-Hall，1980），p. 56.

［2］原注：同上，p.57。［第十章］证据评估中的偏见 153

应地调整自己对最终判断的信心。不幸的是，这样的理想状态并不会经

常出现。实验显示，「看不到，不用想」这句话较好地反映了证据缺乏

造成的影响。

我们可以用故障树这种示意图来展示这个问题。故障树可以显示出

无论怎样努力仍可能产生错误的所有因素。因此，它经常被用于分析诸

如核反应堆或太空船等复杂系统的可靠性。

心理学家曾向几组经验丰富的技师展示了一幅故障树，显示汽车未

能正常启动的所有原因。这幅树图有 7 个主树枝，分别代表电池电量

不足、启动系统失灵、点火系统失灵、燃油系统失灵、引擎的其他问

题、恶作剧或故意破坏，以及其他问题，并且每个主树枝又被分为更小

的分树枝。其中一组技师见到了完整的树图，他们被要求在看完后想象

出汽车无法正常启动的 100 种不同情况。然后，心理学家要求这一组技

师分析这 100 个情况中各有多少个分别可归因于故障树的 7 个主树枝。

第二组技师只看到了部分树图，因为 3 个主树枝被故意略去，目的是检

验被试对被略去内容的敏感程度。

如果第二组技师们的判断能够反映出他们意识到有信息缺失，那么

本应归人被略去的 3 个主树枝的故障就应该被归人「其他问题」中。但

事实上，被归人「其他问题」的故障数量只达到了应有的一半。这表

明，见到不完整树图的技师们并未充分认识到一部分导致汽车未能正常

启动的原因缺失了，而且也未能将这一事实充分融人自己的判断。以普

通人为对象重复这项实验，缺失主树枝造成的影响会更加明显。

与情报分析工作中的绝大部分问题相比，「汽车未能启动」的实验

说明，基于脉络清晰的信息之上的分析判断相当简单。作为被试的技师

［1］: Baruch Fischhoff，Paul Slovic and Sarah Lichtenstein，Fault Trees: Sensitivity of Estimated Failure Probabilities to Problem Representation，Technical Report PTR-1042-77-8 （Eugene，OR: Decision Research，1977）.154 情报分析心理学

们经验丰富，本应该也应当意识到向他们所展示的简略了的故障树缺失

了相关变量。情报分析人员也经常遇到类似的问题。数据缺失在情报问

题分析中十分常见，但要意识到重要信息缺失，而且还要把这一事实融

入情报问题的分析判断中，那就要比更为具体实在的「汽车未能启动」

的实验问题难得多了。

要解决这个问题，情报分析人员应该切实清楚那些信息缺失的相关

变量，根据这些变量的信息缺失情况考虑其他假设，然后据此调整自己

的判断，尤其是要相应调整自己对判断的信心。此外，还应考虑信息的

缺失究竟是正常现象，还是表明事态出现了异常或停滞。

三、过分注重一致性

一系列证据如果内在一致，则有助于提高我们对自己所做判断的信

心。从某种意义上讲，一致性（consistency）显然是评估证据的适宜

指针之一，它指的是提出各种解释或估计，然后挑选出在逻辑上一致的

情况下覆盖证据最多的那个。但某些情况下，一致性也会具有欺骗性。

信息之所以一致，可能是因为它们之间高度相关（correlated）或彼此重

复。在这种情况下，许多相关报告能提供的信息几乎和一份报告相等。

另外，如果信息是从极少数样本或仅从偏好的样本中抽取获得，那么也

会造成一致性。

在情报分析中，比如要判断俄罗斯军官或某些非洲民族的政治态

度，如果分析人员掌握的信息极少，这样的问题就极可能产生。如果掌

握的证据彼此一致，分析人员通常就会忽视这一事实，即这些证据代表

［1］: Amos Tversky and Daniel Kahneman，＂Judgment under Uncertainty: Heuristics and Biases，＂Science，Vol. 185（27 September 1974），p. 1126.（第十章证据评估中的偏见 155

的只是庞大多样群体中的极少数样本，因此并不可靠。这不仅仅是一个

必要性的问题，而是因为：无论掌握的信息多么糟糕，我们都只能依靠

它们进行分析。信息的一致性会产生一种虚幻的有效性。

这种过分依赖少量样本的倾向，被称为「少数定律」（lawofsmall

numbers）。这个词是对「多数定律」（law of large numbers）的戏谑反称。「多数定律」是一条统计学的基本原理，即大量样本将在很大程度

上代表被分析的对象群体，民意调查依据的正是这一原理。但绝大部分

人并非生来具有统计头脑，对于取得可靠结论之前所需样本的大小并没

有任何直觉认识。所谓的「少数定律」的意思是，我们会本能地犯下把

少数样本当作大量样本使用的错误。

即使是受过全面的统计学训练的数学心理学家也会犯这样的错误。

设计实验时，这些心理学家会犯下严重错误，比如认识不到少数数据样

本必然存在的大量错误和高度不可靠性，对最初少量数据反映的发展趋

势盲目自信，对在另一群不同被试身上重复这项实验也能得到完全相同

结果的问题产生不合理的高度期待，等等。

情报分析人员是否会对仅从极少数据，特别是显示出一致性的

极少数据中得出的结论过分自信呢？在面对少量但具备一致性的证

据时，分析人员必须考虑这些证据能够在多大程度上代表已有的信

息。如果还有更多的报告，那么新信息与已有证据也一致的可能性有

多大？如果分析人员仅有少量证据，又不能确定这些证据的代表性如

何，那么无论这些信息如何高度一致，都不应对基于这些证据所做的

判断过分自信。

［1］: Amos Tversky and Daniel Kahneman，＂Judgment under Uncertainty: Heuristics and Biases，＂ Science，Vol. 185 （27 September 1974），pp. 1125-1126.156 情报分析心理学

四、处理准确性不确定的证据

很多因素决定了获得的信息不可能完全准确，比如：理解错误、认

知错误，或是只掌握部分信息；对最终来源存有偏见；在从次级来源、

来源（线人）、专案官（case officer）、通报官（reports officer）到分析人员的整个上报过程中出现信息扭曲；分析人员对信息存在错误认知或

错误理解，等等。此外，分析人员工作时运用的大部分证据是从记忆中

检取来的，而他们往往记不住自己头脑中信息的来源，更不用提最初得

到这些信息时他们对其准确性有多大的判断了。

人们的思维难以处理各种复杂的概率关系（probabilisticrelationship），因此会使用一些简单的经验法则以减轻处理信息时的负担。对准确性或

可靠性无法确定的信息进行处理时，分析人员总是倾向于做出简单的对

错判断。如果他们否定某项证据，就会倾向于彻底排除，不让它在思考

时发挥任何作用；如果他们接受某项证据，就倾向于全盘接受，而忽视

有关准确性或可靠性的判断必然存在一定错误概率。这一现象被称为

「最佳猜想」（bestguess）策略。这种策略会简化准确性不确定的信息的

融合过程，却会忽视其中的某些不确定性。如果情报分析人员对信息仅

有 70％—80％的肯定程度，却将其作为 100％准确的信息来作为判断的

依据，那就会得出过分自信的结论。

还有一个更复杂的策略，先假定已掌握的所有信息完全准确可靠，

然后依据这些信息做出判断，最后再运用某个反映了信息预计有效性的

因素来调低自己对判断的预期值。比如，已掌握的证据显示某事件很有

［1］: Charles F. Gettys，Clinton W. Kelly III，and Cameron Peterson，＂The Best Guess Hypothesis in Multistage Inference，＂Organizational Behavior and Human Performance，10，3（1973），pp. 365-373； and David A. Schum and Wesley M. DuCharme，＂Comments on the Relationship Between the Impact and the Reliability of Evidence，＂ Organizational Behavior and Human Performance，6（1971），pp. 111-131.［第十章］证据评估中的偏见 157

可能（75％的概率）会发生，但分析人员不能确定这一判断所依据的

证据是否完全准确可靠。于是，分析人员考虑到证据的不确定性，将事

件发生的预计概率（assessed probability）降低（如降至 60％）。这种方法是对「最佳猜想」策略的改进，但是与计算概率的数学公式相比，仍

然会得出预期值过高的判断。

在数学术语中，两个事件的联合概率等于各自概率的乘积。请设

想这样的情景：你接到一份报告，称 X 事件极可能（概率为 75％）是

真实的。如果这份报告准确无误，那么，你判断 Y 事件就很可能（概

率也是 75％）会发生。而 Y 事件实际发生的概率其实只有 56％，即由

两个 75％相乘而得来。

然而，实际工作可没这么简单。分析人员必须要考虑许许多多准确性

和可靠性均不相同的证据，而这些证据的准确性和可靠性有复杂的关联且

又能导致各种不同概率的潜在结果。显然，人们不能通过准确的数学计算

将所有的概率关系考虑进来。在进行直觉判断的时候，我们会不知不觉地

去寻找走出迷宫的捷径，而这些捷径必然导致在一定程度上忽视不完全可

靠的信息中存在的不确定性。除非分析时分析人员能够把问题分解到足够

细微的程度，足以对各个信息的概率都做出判断，然后再运用数学公式把

分别完成的概率判断整合起来，否则他们无力改变上述状况。

同样的情况也会影响我们对一些信息的判断反应，因为这些信息貌

似合乎情理，但其可靠性从一开始就值得怀疑。例如，从情报渠道传来

的报告中经常涉及似乎是外国官员私下谈话的内容。其实，很多情况下

我们并不清楚这些外国大使、内阁成员或其他官员的私下谈话反映的是

［1］原注： Edgar M. Johnson，＂The Effect of Data Source Reliability on Intuitive Inference，＂ Technical Paper，p. 251（Arlington，VA: US Army Research Institute for the Behavior and Social Sciences，1974）.

［2］编注：joint probability，联合概率，统计学中的一种专业术语，指两个事件同时发生的概率。158 情报分析心理学

真实的个人观点、轻率的言辞、对美国政府的故意欺骗，还是经外国政

府批准且认为最好应该通过非正式渠道传达的真实信息。

得到此类报告的分析人员通常无法判断信息来源的动机，只能依据

信息的价值对其做出判断。这样做，分析人员通常会受到看似合理的因

果联系（causallinkage）的影响。如果这些因果联系是已被分析人员掌握

的信息，那么，除了支持现有观点外，这种报告几乎毫无影响。如果报

告反映了新的看似合理的因果联系，分析人员就会重整思路，将其纳人

思考范围。看来，信息是否对分析人员思维造成影响完全取决于其内容，

而有关来源可靠性的警示却不会削弱信息的影响程度。即使知道信息来

自一个不受控制且有可能正在试图进行欺骗的来源，信息的影响也未必

会削弱。

五、不可信证据造成的印象持续存在

即使某一证据被证明完全不可信后，它所造成的印象往往持续存

在。心理学家们对这一现象的兴趣日益浓厚，因为他们进行的实验中很

多时候都要求欺骗被试。比如，需要让被试相信自己在完成某项任务时

表现相当成功或失败，或者相信自己拥有某种特殊能力或人格特征。当

然，事实并非如此。心理学的职业道德要求在实验结束后，应该让被试

从这些错误印象中解脱出来，但事实证明这绝非易事。

即使被试已被告知他们的表现成功与否，实际上取决于训练好坏，

但他们还是很难改变对自己解决问题的逻辑能力的错误印象。另一项

［1］: R. R. Lau，M. R. Lepper，and L. Ross，＂Persistence of Inaccurate and Discredited Personal Impressions: A Field Demonstration of Attributional Perseverance，＂ paper presented at 56Annual Meeting of the Western Psychological Association （Los Angeles，April 1976）.［第十章］证据评估中的偏见 159

类似实验中，心理学家要求被试区分真假自杀留言，然后给出与被试的

实际表现毫不相关的反馈评价。被试被随机分成两组，其中一组得到较

高评价，而另一组获得的评价较低。即使当被试得知受到了欺骗，知道

反馈评价的好坏完全取决于自己被分在哪个组后，他们对于任务的困难

程度以及自身表现的错误印象依然持续存在。此外，不仅是实验的直接

参与者，甚至实验的观察者中也出现了同样现象。

这种现象可能是几种认知过程共同作用的结果。人们的思维倾向于

把新信息放在既有印象的背景中做出解释，但仅此一条并不足以解释为

什么在新信息已经毫无疑问地否定了原有证据的可信性之后，既有印象

仍难以抹去。

一个有趣但未经证实的解释是，思维具有寻求因果解释的强烈倾

向。本书下一章将就此进行详细讨论。一旦得到证据，人们就会假定一

系列因果关系来解释这一证据。比如，在有关自杀留言的实验中，一个

被试认为自己之所以能出色地区别真实与伪造的自杀留言，原因在于她

善于换位思考，并从一位自杀了的小说家的作品中获得了启示。而另一

位被试则将自身的失败归因于对想要自杀的人了解太少。认知到的因果

关系越强，证据造成的印象也就越深。

即使知道有关自己表现的反馈并不真实，被试仍然从不真实的反馈

出发来推论自己完成这项任务的能力强弱。虽然最初想到的证据现在已

被完全否定，但是，先前形成的对自己能力强弱的因果解释却仍能够轻

易地进入思维。打个比喻，铃儿一敲响，它就不会停唱。

［1］: Lee Ross，Mark R. Lepper，and Michael Hubbard，＂Perseverance in Self-Perception and Social Perception: Biased Attributional Processes in the Debriefing Paradigm，＂Journal of Personality and Social Psychology，32，5，（1975），pp. 880-892.

［2］: Lee Ross，Mark R. Lepper，Fritz Strack，and Julia Steinmetz，＂Social Explanation and Social Expectation: Effects of Real and Hypothetical Explanations on Subjective Likelihood，＂ Journal of Personality and Social Psychology，33，11 （1977），p. 818.160 情报分析心理学

真实世界中的绝大多数情况都是模糊不清的，这会加剧上述现象的出现。而且，在现实中，很少能像在上述实验环境中那样彻底否定某一证据。设想一下，比如某天你得知一个长期的秘密情报线人实际上一直被敌方控制，而你早已依据这一线人提供的情报形成了一系列的印象。你此时很有可能强调，线人尽管被敌方控制，但提供的情报是真实的，或者干脆怀疑那份声称线人受敌方控制的报告的可信度。在后一种情形下，牢固的印象本身甚至可以影响到如何评估已否定这种印象的证据。［第十一章］

因果认知中的偏见

要解释历史、理解当前、预测未来，都需要对因果关系做出判断。这些判断常常会受人们的意识无法控制的因素所扭曲，而这一现象影响着情报分析人员的许多判断。为了让周围环境看来合理有序，我们常常试图寻找并相信已经找到了那些实际上是偶然或随机现象背后的原因。外国能多有效地执行一个连贯、协调、理性的计划？我们预测这些国家未来情况的能力如何？对这两个问题，我们的估计常常过高，而且还倾向于认为原因一定与结果相对应，重大事件背后必然隐藏着重大的原因。

推论行为的动因时，个人性格以及行为体本身的性质往往被过分关注，而决定行为的环境因素则得不到足够重视。此外，人们还会高估自己的重要性，认为自己是其他行为体行动的原因和目标。最后，由于不了解证明某种关系所需信息的种类和数量，人们经常臆想出根本不存在的关系。

认识因果关系，可不像我们了解子或树木一样简单。哪怕我们亲眼见到两个小球相撞后，原本静止的那个小球开始运动，我们也认识不 162

情报分析心理学

到其中的因果关系。一个小球推动另一个小球运动这一结论来自复杂的

推理过程，而不是直接的感官认知。推理过程的基础是时空中具体事件

的排列，以及关于这一现象的某种理论或逻辑解释。

对因果关系的推理，我们有好几种分析模式。在较为正式的分析工

作中，我们采用统称为「科学方法」的各种手段进行推理。科学家先提

出假设，然后对所研究现象的大量案例进行数据搜集，并进行统计分

析，从而检验假设。即便如此，因果关系也不能被完全确定。因此，科

学家们又尝试证伪而非证实某个假设。只有在无法证伪时，假设才会被

接受。

从众多具备可比性的案例中搜集数据，以检验有关因果关系的假

设，这种方法并不适用于情报界关注的绝大多数问题，特别是在涉及与

外国意图相关、具有广泛政治或战略意义的问题时更是如此。当然，这

种方法在情报工作中还有更大的应用空间，应当鼓励在政治、经济和战

略研究中更多地应用这种科学方法。然而，在现实的情报分析工作中，

我们使用的主要方法与此相去甚远，常用的是历史学家而非科学家的方

法，而这妨碍了我们准确推理因果关系。

对确定因果关系的方法和标准，一位科学家以下的界定要比绝大多

数历史学家更为清晰：

历史学家的目的在于将研究的事物统一连贯起来。我认

为，他们采用的方法是去寻找某些支配性概念或重要思想来说

明所研究的事物，或者探寻这些思想之间的联系，然后通过概

念或思想针对研究时段中的事件构建出一段「有意义的」叙

述，并以此来理解具体的事实。

［1］ ： W. H. Walsh，Philosophy of History: An Introduction （Revised Edition: New York: Harper and Row，1967）； p. 61.［第十一章］因果认知中的偏见 163

这里的关键就在于连贯性（coherence）和叙述性，正是在这两条原则下，观察到的结论被组织成有意义的结构和模式。而历史学家们通常只观察单一案例，却不关注众多可比性案例当中存在的共变模式 （pattern of covariation，即两个事件相互关联，一个发生改变，另一个也会随之变化）。再者，历史学家注重观察多个变量同时发生的变化，因此，即使运用共变原理通常也无法厘清变量之间的复杂关系。尽管如此，通过叙述，历史学家却可以将观察到的极端复杂的现象组织起来；而通过想象，他们又可将支离破碎的数据构建成连贯的故事。

使用历史学家的这种分析模式的情报分析人员，说白了就是个说书先生。他们根据此前发生的事件编织一个故事情节，情节决定了这个不完整故事的可能结局。这个情节就是由「支配性概念或重要思想」构成，分析人员以此来推断所掌握数据之间存在的关系模式。分析人员当然不是在进行小说写作，尽管想象是要受到限制的，但分析人员可以有无数方式来组织现有数据去形成一个有意义的故事，因此分析中必然包括想象。对想象起限制作用的，是现有证据以及连贯性原则。形成的故事必须具有逻辑，且连贯、完整、前后呼应，还要与现有证据一致。

由于连贯性是一个主观概念，因此认识到历史学家式的，或者说叙述性的分析方法必然要求讲述连贯的故事这一点，有助于我们解释分析人员间存在的许多分歧。这一分析方法需要在分析前设定某些原则或思维模式来确定事件之间的相互关系。与我们的讨论更密切相关的一点是，将连贯性而非科学观察作为判断真相的标准，可能会导致偏见，从而对所有分析人员产生不同程度的影响。对连贯性的判断会受到很多外在因素的影响，而且一旦分析人员倾向于认为某些类型的解释较之其他解释更为连贯，就会更相信前者。164 情报分析心理学

一、偏好因果解释

寻求连贯性导致的偏见之一就是偏好因果解释。连贯性意味着有

序，所以人们会自然而然地将观察结果归纳为规律性的模式和关系。如

果我们没有发现明显的模式，那首先想到的是理解还不透彻，而不会想

到面对的是没有任何目的或原因可言的随机现象。如果实在行不通，许

多人还会把无法理解的事情归结为上帝的意旨或命运，也就是冥冥之中

注定的事。他们绝不相信事情的最终结果，是由各种随机且无法预见

的互动力量决定的。人们通常不会接受偶然或随机的概念，甚至连玩色

子的人在掷色子时看起来都像是觉得自己能够在一定程度上控制点数一

样。「因为」这个词在日常用语中的泛滥，反映的就是人们寻找事情

原因的偏好。

人们总是期望有规律可循的事情表现出规律性，随机事件表现出随

机性。但是，事实并非如此。随机的事件中往往也会表现出规律性。连

掷一枚硬币 6 次，这是一个随机过程，但可能 6 次都是正面朝上。连掷

6 次硬币会有 32 种可能性，但无论是什么结果，多数看起来都不像是

「随机」的。这是因为随机性是在生成数据的过程中伴随的一种属性。

有些情况下，随机性可以通过科学的（统计性的）分析显示出来。然而，

人们的直觉几乎从不会认为事件是随机的。在任何一组数据中，人们都

能够发现明显的规律；在任何一组事件中，人们都能创造出连贯的叙述。

为了让环境看来有序，人们常常试图去为实际上随机的现象寻找原

［1］ ： Ellen J. Langer，＂The Psychology of Chance，＂ Journal for the Theory of Social Behavior； 7（1977），pp. 185-208.

［2］: Daniel Kahneman and Amos Tversky，＂Subjective Probability: A Judgment of Representativeness，＂ Cognitive Psychology，3（1972），pp. 430-454.［第十一章］因果认知中的偏见 165

因并相信自己找到了原因。在第二次世界大战当中，伦敦人对德国的轰

炸模式做出多种因果解释，并以此决定应该住在哪里，应该何时躲进防

空洞。而战后的调查却发现，炸弹爆炸的位置几乎是随机分布的。

德国人可能是想有规律地轰炸，但其轰炸目标却不停地改变，同时

也不可能全部实现，因此最终的结果就是炸弹落点接近随机分布。伦敦

人只关注那几个支持他们有关德国人意图的假设的炸弹落点，而不去关

注那些不符合该假设的众多其他炸弹落点。

一些古生物学方面的研究似乎也显示了同样的倾向。一个古生物学

家小组开发出一种模拟动物种群进化的计算机程序。在程序中，从一个

时期到下一个时期的进化演变，不是由自然选择或其他规律性过程决

定，而是由计算机产生的随机数字决定。这个程序产生的进化模式与古

生物学家一直试图理解的自然进化模式比较相似。从直觉上看来，假设

性的进化事件似乎有着明显的规律，但实际上是随机产生的。

还有一个对随机事件强加因果解释的例子，则来自对心理学家工作

实践的研究。当实验结果偏离预期时，他们很少会将这些偏差归因于样

本的差异，而是总能为这种矛盾找到另一种更具说服力的因果解释。

甚至在对鸽子进行的条件反射行为实验中，斯金纳（B.F.Skinner）

也发现了类似的现象。这项实验的通常模式是通过食物给鸽子施加正面

强化措施，也就是说鸽子要在特定时间啄某个特定的杠杆才能得到食

物。为了定时得到食物，鸽子就要学会按一定的顺序啄动这些杠杆。斯

金纳证明，即使喂食完全是随机的，鸽子们仍然「学会」了按照一定的

［1］: W. Feller，An Introduction to Probability Theory and Its Applications （3 Edition； New York: Wiley，1968），p.160.

［2］: Gina Bari Kolata，＂Paleobiology: Random Events over Geological Time，＂Science，189（1975），pp. 625-626.

［3］: Amos Tversky and Daniel Kahneman，＂Belief in the Law of Smal Numbers，＂ Psychological Bulletin，72，2（1971），pp. 105-110.166 情报分析心理学

模式啄动杠杆（斯金纳将此称为「迷信行为」）。

这些例子说明，在最难找到固定模式的军事和外交事务中，许多事

件根本没有合理的因果解释。毫无疑问，这会影响到预测，也要求对情

报分析人员的合理期望不应过高。

二、偏好认为存在集中指挥

与偏好因果解释相类似，人们还倾向将外国政府（或任何形式的团

体）的行为，看作在集中指挥和计划下有意为之的结果。「…… 绝大多

数人难以理解意外事故、无意造成的后果、巧合，以及微不足道的原因

导致的巨大影响等现象。相反，他们总是能发现统一协调的行动、计

划和阴谋诡计。」外国在多大程度上讲求连贯、理性且目标最大化的政

策？情报分析人员往往对此估计过高，因为这会使解释看起来更为连

贯、更有逻辑性、更理性。同样的偏见会使分析人员和决策者高估其他

国家未来发展的可预见性。

分析人员十分清楚，往往正是意外事故、失误、巧合、善意政策的

意外后果、命令执行不当、半独立官僚机构之间的讨价还价或者不合

时宜地按标准程序行事等，才是导致最后结果的原因。这些原因意味

着，现实世界是无序的，事件发生的原因更多的是意外而非有意行为。

此外，由于及时记录随机和通常无法预测的因素的证据很少，因而难以

［1］原： B. F. Skinner，＂Superstition in the Pigeon，＂ Journal of Experimental Psychology，38 （1948），pp. 168-172.

［2］注： Robert Jervis，Perception and Misperception in International Politics （Princeton，NJ: Princeton University Press，1976），p.320.

［3］原注：更多历史案例参见: Robert Jervis，Perception and Misperception in International Politics（Princeton，NJ: Princeton University Press，1976），pp.321-323.［第十一章］因果认知中的偏见 167

把这些因素融人到连贯的叙述中。只有在回忆录问世和政府文件公开之

后，人们才可以在历史的视角下得到完整的故事。

这种偏见的后果非常严重。如果情报分析人员认为外国政府的行

动是逻辑严密、集中指挥性计划的结果，那么就可能导致他们犯下种

种错误：1. 如果外国政府行为的原因在于不断变化或前后不一致的

价值观、官僚机构讨价还价、完全的误解或失策，那么对其行

为的预期可能最终落空；

2. 从外国官员的个别言论或开展的行动中，得出事关重大

的推论可能并不保险，因为这些言论或行动是个人而非集中指

挥的产物；

3. 过高估计美国影响外国政府行为的能力；

4. 将不连贯的政策解读为狡诈以及马基雅维利式的阴谋，

而不是理解为领导软弱、犹豫不决、各种官僚或政治利益博弈

的产物。

三、注重因果间的相似性

如果无法对共变关系进行系统分析，而且似乎同时存在几种可能的

因果解释，那么人们就会使用一条简单的检验规则，即用因果属性之间

的相似性去判断因果关系。也就是说，他们由「与结果属性相对应或相

似为基础去推断」原因属性。比如，沉重的东西声音就会大，优雅的

［1］原注： Harold H. Kelley，＂The Processes of Causal Attribution，＂ American Psychologist （ February 1973），p. 121.168 情报分析心理学

东西动起来就会美，体型大的野兽脚印就会大，等等。当涉及物理属性

时，这种推理通常是正确的。

然而，在条件并不适用的情况下，人们也仍然习惯于运用这种推

理。例如，分析人员通常认为，经济事件主要是经济原因造成的，大事

件就会有大后果，小事件则不可能影响历史进程。虽然这样的因果对应

关系可以让叙述更为连贯，也因而更具逻辑性和说服力，但不能指望这

样的推理与历史事实相符。

对这种认为原因必然与结果类似的假定，戴维·费希尔（DavidH.

Fischer）称作「同一性谬误」（fallacy of identity）。他还举了历史上西班牙「无敌舰队」的例子。英国人在 1588 年击败「无敌舰队」，几个世

纪以来，历史学家一直对这一事件的重要意义大书特书。费希尔在逐一

批驳这些观点后指出：

简言之，击败「无敌舰队」这件事看起来重大且颇有戏

剧性，但除了导致西班牙派出「无敌舰队」的战略瓦解外，

并没有造成其他巨大后果。这个判断肯定会刺痛所有英国人

的爱国热情和我们大家的审美感受。因为我们认为，大事件

总有大后果。②

依据因果相似性进行推理的倾向，通常总是与前述的认为存在集中

指挥的偏见相伴相随。这两种偏见说明为什么阴谋论具有强大的说服

力。阴谋论往往用于解释看似没有重大原因的重大影响。比如，「……

就凭一个像李·哈维·奥斯瓦尔德（LeeHarvey Oswald）这样的小人物

［1］原： David Hacket Fischer，Historian＇s Fallacies （New York: Harper Torchbooks，1970），p.177.

［2］原注：同上，p.167。［第十一章因果认知中的偏见 169

就能改变世界历史，这（似乎）太离谱了。」与肯尼迪遇刺造成的后果

相比，奥斯瓦尔德宣称的行刺动机太微不足道，在许多人听来无法达到

连贯、一致的叙述标准。如果像失误、事故、个人反常行为这样的「微

小」原因都能造成重大后果，那就意味着重大事件背后往往是随意和随

机性的原因，而非有意为之的结果。

与大多数人相比，情报分析人员能够更多地接触到国际社会中的真

实阴谋、政变和反叛的确凿证据。尽管如此，也许正因为如此，绝大部

分情报分析人员都不太认同一般意义上的阴谋论。虽然分析人员的偏见

可能不会以阴谋论这种极端形式表现出来，但这一偏见也确实潜移默化

地影响了他们的分析判断。在分析因果关系时，分析人员认定的原因通

常都与其要解释的结果相符，并且往往将事件归因为人们有意的行动或

可预见的影响，而非人性的弱点、困惑或无意行为。

四、误判行为的内外因

关于人们如何评判人类行为的原因，许多研究都使用了一个基本的

二分法，即把其原因分为内因和外因两种属性。内因包括个人的态度、

信仰、性格等；外因则包括激励与约束、身份要求、社会压力，以及其

他个人无法控制的因素。这些研究考察了人们在何种情况下会把行为归

因于行为体本身的性格特征，何种情况下又归因于行为体所面对的形势

特性。

人们对他人或外国政府行为原因的判断差异，会影响他们对该行为

的反应。把对方的行为原因归结于个人或政府的本身，或是归结于个人

［1］: Richard E. Nisbett and Timothy DeC. Wilson，＂Telling More Than We Can Know: Verbal Reports on Mental Processes，＂ Psychological Review （May 1977），p. 252. 170

情报分析心理学

或政府无法控制的环境局限性，这两种不同情况将导致人们对友善或敌

对的行为采取不同应对措施。

判断行为的原因时，人们易犯的一个主要错误是高估内因的作用，

而低估外因的作用。在观察他人行为时，我们倾向于推断其行为是由个

人特点或性格脾气造成的，并期望在其他情况下，这些内在因素也会决

定其行为。虽然外在环境因素也可能影响他人对行为的选择，但这一点

往往得不到足够重视。这一普遍偏见，已被在各种条件下进行的大量实

验所证实。在外交和军事关系实践中，人们也经常发现这一现象。

是否容易产生这种偏见，取决于人们是在观察自己还是他人的行

为。人们倾向于将他人的行为归因于行为体本身的特质，而将自己的行

为几乎完全归因于自身所处形势的影响。之所以有区别，是因为在很大

程度上行为体与观察者掌握的信息不同，而人们对自己更加熟悉。

行为体非常清楚自己在以往相似形势下的行为。在研究自身行为的

原因时，我们总是回想我们从前的行为，并关注行为如何受到不同形势

的影响。于是，形势中的不同因素构成了解释我们自身行为的基础。而

我们作为观察者时，情况完全相反，因为我们一般并不了解他人以往的

行为，所以倾向于将某人的行为与其他人在类似形势下的行为进行比

较。行为体与观察者在掌握信息种类和数量方面的差异，不仅适用于

人，也适用于政府。

行为体亲身参与其所观察的行为，会增大偏见产生的可能性。「在

［1］: Lee Ross，＂The Intuitive Psychologist and his Shortcomings: Distortions in the Attribution Process，＂in Leonard Berkowitz，ed.，Advances in Experimental Social Psychology. Volume 10 （New York: Academic Press，1977），p. 184.

［2］ ： Robert Jervis，Perception and Misperception in International Politics （Princeton，NJ: Princeton University Press，1976），Chapter 2.

［3］ ： Edward E. Jones，＂How Do People Perceive the Causes of Behavior?＂ American Scientists，64（1976），p. 301.［第十一章因果认知中的偏见 171

观察者同时又是行为体的情况下，他可能会夸大情况的特殊性，强调他

人对自己行为的反应中的内在原因。」这是因为观察者认为，自己的行

为（对他人行为）不具有刺激性，而他人都清楚地理解自己，并且自己

的行为经过精心设计，能够产生预期的反应。确实，与其他行为体互动

的观察者会认为，是他自己主导了形势，而其他行为体只对这一形势做

出反应。如果行为体没有做出预期的反应，观察者形成的合乎逻辑的推

断就是：原因在于行为体，而不是形势本身。

在各种背景下权衡行为的内因和外因，情报分析人员对这种问题非

常熟悉。当外国某新任领导人执政后，分析人员就会评估领导层变动对

政府政策带来的可能影响。比如，前国防部长担任首相后是否会继续推

动增加国防预算？基于新首相之前在其他职位上的表现，分析人员会将

其已知的行为倾向，与当前形势对其政策选择的限制进行比较。在当前

形势中，如果有关已知的限制因素的信息相对完整，那么分析人员就有

可能对此问题做出准确判断。如果缺乏此类信息，他们就会倾向于假定

个人行为倾向将导致其重复过去的行为，结果做出错误判断。

再说说苏联人侵阿富汗的例子。苏联人对自己行为的看法显然与美

国人截然不同。原因内外属性的理论说明，苏联领导人会将人侵行动看

作对当时南亚局势，如伊斯兰民族主义通过伊朗和阿富汗向苏联境内渗

透等的必要反应。此外，他们会将美国不能正确理解苏联「合法的」国

家利益这一反应，看作是美国一贯敌意的结果。

［1］: Daniel Heradstveit，The Arab-Israeli Conflict: Psychological Obstacles to Peace（Oslo: Universitetsforlaget，1979），p. 25.

［2］: 参 Richards J. Heuer，Jr.，＂Analyzing the Soviet Invasion of Afghanistan: Hypotheses from Causal Attribution Theory＂（Studies in Comparative Communism，Winter1980）一文。这些有关苏联入侵阿富汗的评论完全依赖于心理学研究的结果，而不是依赖于有关苏联在阿富汗的行动或美国对此反应的信息。对「人们通常如何

处理信息」进行概括总结后，我们可以发现的一个特点就是，他们处理信息的规律 172 情报分析心理学

相反，观察者倾向于将苏联的侵略行动归因于其政权的侵略扩张

本性。对苏联的反感，加上不了解苏联人眼中形势造成的限制因素，

可能会加剧确定因果关系过程中的偏见。此外，由于这种偏见一定

程度上源于不了解环境的压力和约束，我们可以预料，因为决策者并

不是苏联问题专家，所以他们会比苏联问题分析专家有更强烈的偏

见。专家对形势变化的了解更为深入，可以更好地将这些变化情况考

虑进来。

有时，专家由于深深沉浸在对象国家事务中，以致他们开始具有对

象国领导人的视角和偏见。冷战中，中情局的苏联问题专家和中国问题

专家在分析中苏关系时长期存在分歧。比如，在中苏 1969 年爆发边境

冲突期间，苏联问题专家就认为中国人的行为具有「挑衅性质」。这些

专家倾向于从苏联统治者的视角，来认识边界历史和划分走向。而中国

问题专家的看法则与此相反，那就是傲慢的俄国人一贯如此，中国人不

过是对苏联的高压政策做出反应罢了。换言之，这些分析人员各自采

取了与他们所熟悉国家的领导人相同的、有偏见的视角。而对冲突事件

因果关系的客观分析，本来应该介乎两种立场之间。

1978-1979 年间，埃及与以色列的和平谈判提供了另一个例子，

显示了因果推断过程中存在着明显的偏见。当时，一位观察家如此评

论道：

「或多或少」适用于许多情况，却不一定能合理解释某一特定情况。显然，有许多

其他因素影响了对苏联行动的分析，其中包括有关苏联政策背后推动因素的成见。

这样做的目的是为了揭示心理学研究与分析过程的相关性，而不是要争论对苏联政

策的其他解释的优点。因此，笔者把这个任务留给读者：请判断你对苏联入侵阿富

汗的理解，在多大程度上受到这种要把原因归于某一属性的倾向的影响。

［1］: Edward Jones and Richard Nisbett，＂The Actor and The Observer: Divergent Perceptions of Their Behavior，＂ in Edward Jones et al.，Attribution: Perceiving the Causes of Behavior （New Jersey: General Learning Press，1971）. p.93.

［2］原注：这些观点源于笔者与中情局分析人员的私下讨论。［第十一章］因果认知中的偏见 173

埃及人将他们愿意与以色列签署和约的意愿归因于自己爱

好和平的天性；而以色列人则认为埃及人的媾和愿望源于其不

断恶化的经济状况，还有逐渐认识到了以色列的军事优势。同

时，以色列人也认为自己希望和解是因为他们一贯爱好和平。

然而，埃及认为以色列在诸如西奈等问题上之所以做出让步，

是由于外部压力，诸如美国的援助承诺和制裁威胁等。此外，

另一些埃及人则把以色列令人不快的行为，如在约旦河西岸兴

建犹太人定居点等归因于犹太复国主义的扩张性。如果以色

列没有在约旦河西岸兴建定居点，埃及人又会认为原因来自于

外部因素的制约，如西方对以色列兴建定居点的谴责等。与之

相反，以色列人会把埃及过去威胁将其赶入大海等令人不快的

行为，归咎于埃及反对在中东地区存在一个犹太国家的一贯立

场。而当埃及人不再发出类似威胁之后，以色列人则认为这是

外部环境，如以色列的相对军事优势等影响的结果。

按照如此方式归结因果关系的偏见长期存在，不是简单地出于私利

的结果，也不是由于对手的宣传，而是人们在许多不同环境下归结内因

和外因时通常采取的方式。这种现象可以理解，也可以预见。

一般来说，如果因果关系的归结受到偏见的影响，就会为个人之

间、政府之间的不信任和误会埋下种子。因此，对彼此的行为动因，我

们也常常会形成完全不同的看法。

［1］: Raymond Tanter，＂Bounded Rationality and Decision Aids，＂ essay prepared

for the Strategies of Conflict Seminar，Mont Pelerin，Switzerland，11-16 May 1980.174 情报分析心理学

五、高估自己的重要性

个人和政府都倾向于高估自己成功影响他人行为的程度。对于前

面总结的规律，即观察者通常将他人行为归因于行为体的本性，这是一

个例外。这种现象之所以出现，主要是因为个人十分了解自己为影响他

人行为做出的努力，却对可能影响他人决定的其他因素了解不足。

在评估美国政策对其他国家政府行为的影响时，分析人员往往会

十分清楚美国的行为及意图，但在很多情况下却并不了解对象国家政

府内部的运作、政治压力、政策冲突，以及可能影响其最终决策的其

他因素。

这种偏见最近已导致美国没能预见到印度将进行核武器试验。其

实，印度新政府当选的部分原因就是因为它承诺该国将拥有核武器，但

大多数美国情报分析人员显然将印度新政府的承诺看作拉选票的说辞，

而相信印度会迫于经济制裁和外交压力放弃加入核俱乐部。在这个案例

里，分析人员高估了美国政策影响印度决策的能力。

当某国的行为与美国意愿一致时，在没有充分的反面证据的情况

下，最明显的解释就是美国政策有效地影响了该国决策。相反，当某

国行为与美国意愿相违背时，那么通常就会被归因于美国无法控制的因

素。无论是人还是政府，都很少考虑到自身行为可能会产生无意的后

果。他们都会认为自己的意图已经被准确领会，而且除非有外部因素干

扰，否则自己的行为肯定会产生预期结果。

［1］原注：本节内容很大程度上源: Robert Jervis，Perception and Misperception

in International Politics （Princeton，NJ: Princeton University Press，1976），Chapter 9.［2］原注：同理，对于那些并非我们政策意图影响的国家而言，我们也可能低估

了我们的行动对其产生的实际影响。［第十一章］因果认知中的偏见 175

众多的调查和实验都表明，人们通常认为自己成功的原因在于自己的行为，而失败的原因在于其他。当孩子、学生或工人表现出色时，家长、老师或上司至少会把部分功劳归于自己；但当他们表现不好时，那么这些指导者很少会主动承担责任。竞选成功的国会议员一般认为是自己的行为对最终的胜利起到了重大作用，而失败者则会将失利归咎于自己无法控制的因素。

还有一个例子，就是苏联解体后一些美国人表现出的自大情绪。根据一些人的观点，苏维埃社会主义共和国联盟之所以会最终消亡，完全是因为美国政策的强硬，比如大幅增加国防开支和「星球大战计划」等，正是这些行动最终让苏联领导人意识到无法再与美国抗争。就苏联解体原因的问题，美国媒体采访了许多专业或非专业人士，把这类说法炒作了好几周。但绝大多数严肃的学者十分清楚，苏联解体有着许多原因，其中最重要的是苏联体制的本质造成的内部原因。

人们和政府倾向于过高地估计自身的重要性，也体现在他们认为自己是他人或外国政府行为的目标。他们对于后者的行为对自己造成的影响十分敏感，并且通常会认为这些行为和结果都是有意为之。他们对行为的其他原因或结果并不太清楚，也因此忽视其重要性。

在分析其他行为体行为方式的原因时，人们通常会产生这样一个疑问：「那个人或政府追求的目标是什么？」但目标通常是从行为的结果推理得来的，而我们最为清楚也常常认为是最重要的结果，却往往就是那些对我们自身产生影响的结果。如此一来，对我们造成伤害的行为，一般都会被认为是有意针对我们的敌意行动。当然，这种解释很多时候是准确的。但人们有时却无法认识到，有些行为虽然看起来好像是故意针对他们，实际上却是基于其他原因做出的决策无意产生的后果。176 情报分析心理学

六、虚假的相关关系

本章开头曾论述过将共变关系作为推论因果关系的基础。该论述指出，人们可以凭借直觉观察共变关系，也可能通过统计来了解共变关系。本节将讨论在共变关系中，直觉观察究竟会在多大程度上与统计测量相偏离。

共变关系的统计测量，被称为相关关系（correlation）。如果某一事

件的存在意味着另一事件的存在，那么我们就说这两个事件是相关的。

如果某一变量发生变化，而另一变量也会相应发生类似程度的变化，那么这两个变量之间也是相关的。仅存在相关关系并不意味着必然存在因

果关系。例如，两个事件可能由同一个原因引起，而不是一个事件引发另一个事件。但如果两个事件或变化确实同时发生，并且在时间上一个事件总是紧随另一事件，人们通常就会推论：先发生的事件是后发生

事件的原因。因此，对相关关系的认识如果不准确，就会导致错误认识因果关系。

对相关关系的判断是所有情报分析工作的基础。比如，「经济状况

不断恶化导致反对党的政治支持上升」，「国内问题可能会令政府在外交

上采取冒险主义政策」，「军政府统治常常会造成民主架构崩溃」，「以实

力为后盾的谈判更为有效」等假定，都是基于对变量间相关关系的直觉

判断。很多时候，这些假定都是正确的，却很少受到系统观察和统计分

析的检验。

对人和政府一般行为方式的常识性假定，是大量情报分析工作的基

础。但问题是，人们还可以随意引用相互矛盾的「规律」去解释、预测

或证明类似情况下出现的不同行为。比如，「欲速则不达」与「当断不

断，反受其乱」就是两个相互矛盾的解释和警语。当它们被单独使用［第十一章］因果认知中的偏见 177

时，两者的道理都能分别说得通。可它们一旦被放到一起，其道理显得

就很愚蠢。同理，「绥靖助长侵略」与「妥协才能达成协议」，是另外一

对相似的矛盾说辞。

遇到此类明显矛盾的情况时，我们会脱口而出地辩解道，「一切取

决于……」。能否意识到必须添加这样的限定语，是下意识的信息处理

过程与有意识的系统分析之间的区别之一。能添加上述限定条件，就是

有见地的分析工作的特征，而添加限制条件的频率则反映了分析工作的

严谨态度。

当某种联系实际并不存在却被人们认为存在时，就出现了虚假的相

关关系。通过对一系列案例的研究，我们可以得知，人们好像总是关注

那些能够支持存在某种联系的事例，却会忽视那些不支持该联系的事

例。几项实验表明，人们并不能凭直觉知道自己究竟需要哪些信息，去

评估两个事件或变量间的关系。由此看来，人们的直觉理解中并没有类

似统计学中的相关关系概念。

心理学家曾对护士进行实验，测试他们学会判断某个疾病症状与诊

断结果间的联系或相关关系的能力。每个护士看到了 100 张卡片，每

张卡片代表了一位病人。每张卡片的上方有一排代表不同症状的 4 个字

母，下方有一排代表不同诊断结果的 4 个字母。护士们被要求只关注其

中代表某一症状的字母 A，还有代表某一诊断结果的字母 F，然后再判

断症状 A 是否与诊断结果 F 相关。换言之，以从这 100 位「病人」中

获得的经验为基础，症状 A 的出现能否有助于确诊疾病 F? 心理学家

［1］原注：本段内容主要源于以下文章的观点和说法：Baruch Fischhoff，「ForThose Condemned to Study the Past: Reflections on Historical Judgment，＂ in R.A.Shweder and D. W. Fiske，eds.，New Directions for Methodology of Behavioral Science: Fallible Judgment in Behavioral Research （San Francisco: Jossey-Bass，1980）.

［2］: Jan Smedslund，＂The Concept of Correlation in Adults，＂ Scandinavian Journal of Psychology，Vol. 4（1963），pp. 165-173. 178 情报分析心理学

改变 A 与 F 之间的关联程度，多次重复了这项实验。

你可以暂时把自己想象为实验中的护士。你已经观察完了所有卡片，并发现其中大约 25 张卡片，或者说四分之一的病例中，症状 A 与疾病 F 同时存在。那么，你能否说两者之间存在联系呢？为什么？仅仅依靠支持 A 与 F 之间存在联系这一假设的出现次数，就做出这样的判断是否合适？你还需要知道些什么？统计一下有症状 A 却没有疾病 F 的病例数目是否会有所帮助？假如也有 25 张卡片是这样的情况（有症状 A 却没有疾病 F），于是 100 张卡片中有 50 张上有症状 A 存在，其中 25 张同时有 A 和 F。换言之，在观察到的症状 A 的所有病例中，有一半的病人患有疾病 F。这是否足以确立一种联系，或者还有必要知道究竟有多少患上了疾病 F 却没有症状 A 的病例？

实际上，为了确定这样的联系存在，心理学家需要信息去填写两横两竖的 4 个单元格。表 11-1 阴影部分正是这样的形式，为我们展示了上述实验的一次测试情况。它显示，在上述病例中症状和疾病间有 4 种可能的组合。

表 11-1

A

没有 A

F

25

25

没有 F

25

25

在 19 个看到这 100 张代表 A 和 F 不同可能性组合的卡片的被试中，有 18 个人认为 A 和 F 之间至少存在微弱联系，有几个甚至认为存在强烈联系。事实上，两者之间根本没有任何相关关系。其中，超过一半的被试是仅仅依据 A 和 F 都出现的次数来判断的，即表 11-1 阴影部［第十一章］因果认知中的偏见 179

分左上单元格所表示的内容。这些被试都要尝试确定 A 和 F 之间究竟有无联系。在被试观察卡片时，发现其中 25％的病例符合「症状与疾病完全相关」的想法，而这似乎足以作为证据支持这种假设的联系。另一部分人数略少的被试则采用了相对而言更复杂的推理方法。他们观察全部有 A 存在的病例，然后再从这些病例中找有多少还存在 F。这实际上是表 11-1 阴影部分左列所表示的内容。而剩余的一部分被试则不愿意采用统计推理。当被要求阐述他们的推理过程时，他们说有的病例存在这种联系，而有的病例则不存在。

在多次参加这项实验的 86 个被试中，没有一个显示出对「相关关系」这个概念的直觉理解。也就是说，没有一个人清楚地了解，要准确判断是否存在某种联系，人们必须知道表 11-1 阴影部分中 4 个单元格内的全部信息。在统计学中，两横两竖表格中对角线上两个方格的数值之比，所呈现的就是最基本的相关关系。换言之，无论哪一格中的比例较高，都代表着两个变量之间存在着强烈的统计学联系。

现在，让我们来考虑一个类似的相关关系问题，这也是情报分析人员感兴趣的话题：战略欺骗具有哪些特点，分析人员如何才能发现战略欺骗？研究战略欺骗时的一个重要问题是：与这种欺骗相关的事物是什么？当分析人员从历史角度研究案例时，会发现哪些现象伴随战略欺骗出现，与后者存在联系，并最终可以被解读为后者的征候？是否存在着某些与战略欺骗相联系的行动，或某些最有可能发生战略欺骗的条件？这样，我们就可以说，由于观察到了事物 X、Y 或 Z，就意味着欺骗计划极有可能正在实施。它就类似于这样的情形：一个医生观察到了某种症状，就能够得出患者可能患有某种疾病的推论。这本质上就是一个相关关系问题。如果我们能够确定与战略欺骗相关的某些事物，就非常有助于发现对手的战略欺骗。180 情报分析心理学

有种假设认为，在高风险情形时最容易出现欺骗。如果这个假设

正确，分析人员遇到这种情况时就应该对欺骗行动保持高度警惕。我们

可以列举出许多个支持这一假设的著名例子，如珍珠港事件、诺曼底登

陆以及德国闪击苏联，等等。高风险情形时出现欺骗行动的例子不胜枚

举，因此，这个假设似乎具有强有力的例证支持。但请想一想，如果完

全从经验的角度出发，究竟需要知道哪些事情才足以证明实际存在这样

的联系。表 11-2 就分析这一问题建立了一个表格。

表 11-2

高风险

低风险

欺骗

68

？

没有欺骗

35

巴顿·惠利（BartonWhaley）研究了 1914-1968 年间在军事战略

行动中出现过突袭或欺骗手段的 68 个案例。让我们假设在所有这些

案例中，都存在某种形式的欺骗或突袭情况，并把数字「68」填进表格

阴影部分的左上单元格中。而这些案例中，究竟有多少具有高风险却没

有使用欺骗手段呢？这个问题需要认真思考，而找出答案十分困难。因

为研究者很少会努力去统计反面例证，记录那些某种事情没有发生的情

况。但幸运的是，惠利倒是做了一个粗略的估计。他认为在这段时间内

的「大战略」案例中，约有三分之一到一半的案例既无欺骗也没有突袭

行动。这样，我们就可以把数字「35」填进表 11-2 阴影部分的左下单

［1］: Robert Axelrod，＂The Rational Timing of Surprise，＂ World Politics，XXXI

（January 1979），pp. 228-246.

［2］: Barton Whaley，Stratagem: Deception and Surprise in War （Cambridge，MA:

Massachusetts Institute of Technology，unpublished manuscript，1969），p. 247.［第十一章因果认知中的偏见 181

元格中。

在风险不高的案例中，又有多少使用了欺骗手段呢？这就是表 11-2 阴影部分右上格表示的内容。这一格与右下格里的数字都很难估计，完成它们需要研究极大数量的案例，其中就包括低风险的情形在内。在这样的语境下，究竟什么才算是「低风险」呢？「高风险」的情形是可以确定的，但低风险情形的数量和种类却可能无穷无尽。由于存在这个困难，我们恐怕无法使用完整的两横两竖表格去分析欺骗与高风险间的联系了。

尽管只需表 11-2 阴影部分左侧一列表格，就足够我们使用了。但这样我们就无法在案例中对「高风险」与「低风险」进行比较，也就无法从经验角度证明，人们应该在高风险情形中对敌方的欺骗行动提高警惕。如果与高风险的战略情形相比，战术情形下欺骗行动更加常见，那么，分析人员就会更加相信高风险情形下容易出现欺骗行动。

由于没有足够的数据，我们不能十分确定欺骗与高风险情形间是否存在某种联系。但凭直觉，我们可能感觉这种联系是存在的，而这种感觉或许是正确的。这种感觉之所以会产生，可能主要是因为我们倾向于关注表 11-2 阴影部分左上格中的案例，而它们确实体现出了这种联系。相反，由于另一些案例没有体现这种联系，显得毫不起眼，我们就容易忽略它们。

在这里，我们要从中吸取的经验，并不是要求分析人员应对每一种联系都进行统计分析。分析人员通常并没有所需的数据、时间或兴趣，但他们至少应大致了解需要掌握哪些情况才能判断是否存在某种联系。这显然不能靠人类的直觉本能，因为它并不是我们天生的本领，而必须通过学习才能被掌握。处理这些问题时，分析人员必须强迫自己考虑表格中的单元格，以及需要填入每个格子中的数据。

即使分析人员听从上述告诫，但如果没有严格遵循科学的流程进行 182 情报分析心理学

观察和记录结果，也还是会有某些因素让他们的判断发生偏差。这些因

素会影响人们回忆起表格中的内容。比如，人们更容易地回想起发生了

什么，而不会想起没有发生什么。「大体而言，历史只记录人们曾经做

了什么，而不记录他们没做过什么。」

因此，那些存在欺骗行动的案例，要比没有欺骗情形的案例更容易

让人回想起来。相比那些不能证明分析人员所研究的联系存在的例子，

他们会更容易记住那些能够证明这种联系存在的例子。由于认知在一定

程度上受到期望的影响，分析人员可能会遗漏或忽视反面案例。对于刚

刚发生的事、亲身经历的事和产生重大影响的事等等，人们的印象也更

为深刻。如果分析人员没有有意识地去思考表格中所有案例，而仅凭直

觉做出判断，那么上述因素将极大地影响他们对相关关系的认知。

许多错误的理论之所以能一直存在，是因为它们看起来十分合理，

也是因为人们一直记录着支持这些理论的经验，而非否定这些理论的经

验。罗斯对此描述道：

…… 依赖直觉的观察者有选择地记录那些可能涉及 X 与

Y 之间联系的数据。符合其假设和预期的数据会被认为是可

靠、有效和具有代表性的，没有错误的，也不会受到「第三方

变量（third-variable）的影响」。这样的数据被认为是 X 与 Y

之间的「真正」…… 联系的体现。相反，与直觉的…… 期望或

理论明显相左的数据则不太可能受到关注，而且常常被认为是

不可靠、充满错误、不具代表性的，或者受到了第三方变量的

干扰。因此，如果某个科学家凭直觉认为胖子都比较活泼，或

者更具体地讲，认为肥胖导致性格活泼，那么，他就会将性格

［1］: E. H. Carr，What is History? （London: Macmillan，1961），p. 126，cited by Fischhoff，op. cit.［第十一章］因果认知中的偏见 183

活泼的胖子视为自己理论的有力证据。他根本不会去考虑某个

人的快乐可能完全是装出来的，或者是幸福家庭生活的产物，

而不是肥胖的结果。相反，这个科学家碰到抑郁的胖子时，会

在把有关情况输入数据库前进行非常仔细的斟酌。比如，他会

试图确认这个人在那天情绪低落是否是一个例外情况，是不是

感冒了或是遇到了让人沮丧的事，而不会认为那是此人的一种

固有性格特征。需要特别强调的是，如果按照上述方式记录数

据，哪怕是随机产生的一组数据都能产生强烈的相关关系。

［1］: Lee Ross，＂The Intuitive Psychologist and his Shortcomings: Distortions in the Attribution Process，in Leonard Berkowitz，ed.，Advances in Experimental Social Psychology. Volume 10 （New York: Academic Press，1977），pp. 208-209. ［第十二章］

概率评估中的偏见

在可能性或概率的初步判断过程中，人们通常会依赖一些能极大减轻决策压力的简化规则。凭借「可用性」（availability）规则，人们可以通过想象类似事件的案例，或者回想起类似事件的数量，就能轻松判断某件事的发生概率。而运用「锚定」（anchoring）策略时，人们会首先选取几个自然的起始点进行初步估计，再通过新信息或新分析来校正结果。通常，人们都不会对最初判断做出充分调整。但是，这些都可能造成概率误差或失误。

类似「可能」、「大概」等关于可能性或概率的表述通常都会造成一定的模糊性，让读者更容易认为报告与自己原有的观点一致。想定出现的概率通常会被错误估计。除非能反映因果关系，否则有关「事前概率」（prior probability）的数据一般都会被忽视。

一、可用性规则

评估可能性或概率时，人们经常使用的一条简化经验规则，就是［第十二章］概率评估中的偏见 185

「可用性规则」。在这里，「可用性」指的是可想象性，或记忆中的可检

取性。心理学家已经证明，人们在判断某事件发生的概率时，经常会下

意识地运用两种思维线索：一是他们能否轻易想起与这一事件相关的事

例；二是他们能轻易回想起类似事件发生的数量或频率。只要人们评

估某事件发生的频率或概率时，依据的是自己能想到或回忆起类似事件

的难易程度，那么，他们就是在使用可用性规则。

通常情况下，这一规则行之有效。如果某事件确实比另一事件的发

生频率更高，也就意味着前者发生的概率更大，因此，我们也就能回忆

起更多的相关例证。更可能发生的事件，通常比不大可能发生的事件更

易于被人想起来。人们实际上经常以这些假定为前提进行推理。比如，

评估自己获得升职的概率时，我们会回想曾处于类似位置或有相似经历

的同事获得升职的例子。评估某个政客输掉竞选的概率时，我们想象的

就是他可能失去公众支持的方式。

尽管这一规则常常行之有效，但如果许多与所评估事件概率并不相

关的因素让人们难以想起类似事件，他们往往就会误人歧途。事件发生

的时间离现在有多久，我们是否亲身参与其中，是否有某些令人难以忘

怀的相关生动细节，以及该事件在当时呈现出的重要程度等等，都影响

着我们回忆起这些事件的能力。但是，上述几点和影响判断的其他一些

因素，其实与事件发生的真实概率之间并无联系。

设想现在有两个烟民，其中一位的父亲死于肺癌，而另一位所认识的

人中却没有一个患肺癌。尽管一个肺癌病例在统计学的风险评估上影响甚

微，但父亲死于肺癌的那个烟民更可能认为吸烟损害健康。再设想一下两

位中情局官员，一位恰好认识奥德里奇·埃姆斯，而另外一位不认识任何

［1］: Amos Tversky and Daniel Kahneman，＂Availability: A Heuristic for Judging Frequency and Probability，＂ Cognitive Psychology，5 （1973），pp. 207-232.

［2］编注：奥德里奇·埃姆斯（Aldrich Ames，1941—），美国中情局的一名前反 186 情报分析心理学

叛徒，情况又会怎样？哪一位更有可能认识到内部出现叛徒的巨大风险？

要想象苏联解体是十分困难的，因为在此之前 50 年中类似事件非

常罕见。那么，现在想象俄罗斯重归共产党统治有多困难呢？这倒不难

了，部分原因是我们对于苏联仍然有着鲜活的记忆。但这是否就可以成

为评估该事件发生概率的坚实基础呢？在没有认真分析形势的情况下，

如果分析人员仅凭直觉迅速做出判断，就很可能受到可用性偏见的影

响。某个可能的想定越是与人们的经验一致，就越容易被想象到，可能

性看起来也就越大。

与普通人相比，情报分析人员受到可用性偏见的影响也许较小，因

为他们要评估所有可用信息，而不是迅速做出简单的推断。另一方面，

决策者与新闻记者没有足够的时间和渠道去了解事件细节，所以必须走

捷径。而运用可用性规则判断事件发生的概率，就是一条明显的捷径。

情报分析人员在工作中涉及的许多事件都会具有特性：

……（这些事件）具有如此的独特性，以致在评估它们的

可能性时，（我们）已有的历史经验难以提供有用的关联性。

考虑这些事件时，通常我们会构建出不同的想定，也就是说引

导当前形势与目标事件相联系的一个个故事。我们能想到的想

定的合理性，或者能想到想定的难度，都会成为判断事件可能

性的线索。如果我们想象不出任何合理的想定，那么这个事件

就会被认为不可能发生，或者发生的可能性很小。如果能够轻

易想出好几个想定，或者某一个想定特别有说服力，所讨论的

事件看起来就很可能发生。

情报官员和情报分析专家，1994 年被证实先后曾为苏联和俄罗斯充当间谍，后来被

美国判处终身监禁，并被剥夺保释权。

［1］: Amos Tversky and Daniel Kahneman，＂Availability: A Heuristic for Judging［第十二章］概率评估中的偏见 187

越南战争的初期，美国决策者们就必须设想这样的想定：假如派出

或不派出美军去保卫南越，分别会发生什么情况。在判断不同结果的概

率时，高层领导人受到了两个看似具有可比性的想定的强烈影响，即第

二次世界大战前绥靖政策的失败和朝鲜半岛干涉行动的成功。

就像许多外部因素影响记忆对事件的检取能力一样，这些因素也会

影响对未来事件想定的想象能力。奇怪的是，分析本身就是这种外部因

素之一。仔细地构建一个未来可能事件的想定，会让该事件更容易被想

象到，也因而增大了该事件在人们眼中的可能性，这就是一些中情局情

报分析人员的经验。这些人在工作中运用各种专业分析工具，而这些工

具要求，或者说特别适合于分析那些发生概率不大但相当重要的假设。

（本书第六章和第八章都曾分别讨论过这些技巧。）这样分析的结果往往

使得「不太可能」的想定多少获得一些认真的对待。心理实验也证实了

同样现象的存在。

总之，可用性规则常常被用于判断可能性、概率或频率。在许多不

能保证或无法进行详细分析的情况下，该规则可以节省大量时间，因此

人们也就很难做出其他选择。然而，走这条捷径时，情报分析人员应当

保持清醒的认识，清楚地了解这些方法的长处和短处，并知道自己什么

时候最容易被误导。如果他们一旦意识到自己正在使用可用性规则，就

应格外小心。要对可能性或概率进行严谨分析，就必须找出决定局势结

果的众多变量，并评估所有变量的各自优势及变量间的互动关系。

Frequency and Probability，＂ Cognitive Psychology，5（1973），p. 229.

［1］: John S. Carroll，＂The Effect of Imagining an Event on Expectations for the Event: An Interpretation in Terms of the Availability Heuristic＂，Journal of Experimental Social Psychology，14（1978），pp. 88-96.188 情报分析心理学

二、锚定现象

人们本能和下意识地用来简化判断过程的另一个策略就是「锚定」。

通过此前对同一问题的分析或粗略推算，我们得出一些最先的起始点，

以作为预期判断的初步估值。然后，根据新信息或新的分析结果，我们

再对这个起始点进行调整。但很明显，这种起始点就如同一个锚，限制

了调整幅度，导致最终的估值比应有结果更接近起始点。

我们可以用课堂上的一个练习展示锚定现象。这个练习要求一群学生

估计一个或几个已知的数字，如联合国中非洲国家所占比例等。首先，告

诉其中一半学生一个较小的百分比，再告诉另一半学生一个相对较大的百

分比，让每组学生各自以自己被告知的数字作为估计的起点。然后，随着

对这个问题的思考，他们不断调整数字，直到获得最接近他们认为的正确

答案为止。在这样的一项实验中，锚定数字为 10％的被试最终得出的平均

估值是 25％，而锚定数字为 65％的被试的平均估值则是 45％。

由于调整幅度不充分，那些从较高的数字出发开始估计的被试所得出

的估值，要远高于从较低数字开始的被试。甚至完全随意确定的出发点都

能成为「锚」，产生拖拽或惯性作用，阻碍人们对估计结果进行充分调整。

当分析人员进人全新的分析领域，需要完善前人的判断或评估时，

前人的这些「遗产」也可能会产生这样的「锚定效应」。许多证据表明，

即便分析人员首先做出自己的初步判断，然后再尝试根据新信息或进一

步的分析对判断加以修正，他们通常也都无法对判断做出充分的调整。

有些实验显示分析人员往往对自己的判断过分自信，而锚定现象在一定

程度上解释了这种现象。在评估未来导弹或坦克的产量时，军事分析人员往

［1］: Amos Tversky and Daniel Kahneman，＂Judgment under Uncertainty: Heuristics and Biases，＂Science，Vol. 185，Sept. 27，1974，pp. 1124-1131.［第十二章］概率评估中的偏见 189

往不能精确估计具体数字，因此，他们首先从高到低设定一个范围，然后预

计实际产量有 75％的概率会达到此范围之内。如果多次评估都显示分析人

员对自己判断的信心比较恰当，那么真正的产量有 75％的时间里应该落在

上述预计范围之内，而 25％的时间里可能不在范围内。但在实验条件下，

绝大多数被试都过分自信，真实数字落在预计范围之外的概率要大得多。

如果预计范围时，与范围上限和下限相关的信息相对可靠，这个范

围就可能比较准确。但如果预计范围时，我们以某个最可能的单一猜测

为出发点，然后通过简单的上下推导来确定上限和下限，锚定现象就会

出现，那调整就可能不充分。

对锚定现象的原因，我们至今还没有充分的认识。人们最初的判断

或预计就像是一个钩子，而他们的第一印象或初步估算结果就挂在上

面。在进一步重新估算时，他们又会将这个钩子作为一个起点，而不会

从头开始。但我们还不清楚，为什么这样做会限制随后推理的范围。

有证据显示，仅仅意识到锚定问题的存在还不足以克服它。这是

有关认知偏见的实验中的普遍发现。在实验中，即使被试知道偏见是存

在的，并被要求尽力避免或弥补偏见造成的影响，偏见仍会发生作用。

考虑到锚定现象或问题客观存在，避免锚定偏见的一个技巧，也许

就是忽略我们自己或他人此前做出的判断，完全重新思考问题。换言

之，我们要有意识地避免将此前存在的任何判断作为思考的起始点。目

［1］原注：如果实验中被试预计产量有 98％会达到预计范围之内，那真实数

字就有 40％-50％的概率会落在预计范围外。参见：AmosTverskyandDaniel Kahneman，＂Anchoring and Calibration in the Assessment of Uncertain Quantities，＂ （Oregon Research Institute Research Bulletin，1972，Nov. 12，No. 5），and M. Alpert and H. Raiffa，＂A Progress Report on The Training of Probability Assessors，＂Unpublished manuscript，Harvard University，1968.

［2］: M. Alpert and H. Raiffa，＂A Progress Report on The Training of Probability Assessors，＂Unpublished manuscript，Harvard University，1968.190 情报分析心理学

前，尚无实验证据证明这样做的可能性或有效性，但似乎值得一试。或

者，有时候，我们也可以通过严谨的统计方法或程序，来避免人为失

误。比如，通过使用贝叶斯统计分析，依据新信息修正前面的判断，人

们就能够避免锚定偏见。

三、不确定性的表述

有两种表述概率的方式。一种是统计概率，它依据的是与相对频率

（relative frequency）有关的经验证据。但绝大多数的情报判断所应对的

情况，都是独一无二的，无法以统计概率表述其可能性。另一种就是主

观概率或个人概率，是情报分析中的常用表述方式。这样的判断表达的

是，分析人员个人对某种解释或判断正确性的相信程度。它和「这匹马

有 75％的概率获胜」这样的判断有些相似。

用言语表述不确定性，诸如「可能」、「很可能」、「不太可能」、

「会」、「有可能」等等，属于用主观概率做判断的形式，一直都被认为

是造成模糊和误解的根源。说一件事「有可能」或者「会」发生时，是

指它发生的概率包含了从 1％到 99％的可能性。为了清楚表述自己的

意思，分析人员必须学会使用数值概率或几率比值来表述不确定性。

［1］: Nicholas Schweitzer，＂Bayesian Analysis: Estimating the Probability of Middle East Conflict，＂in Richards J. Heuer，Jr.，ed.，Quantitative Approaches to Political Intelligence: The CIA Experience （Boulder，CO: Westview Press，1979）. Jack Zlotnick，＂Bayes＇ Theorem for Intelligence Analysis，＂ Studies in Intelligence，Vol. 16，No. 2（Spring 1972）. Charles E. Fisk，＂The Sino-Soviet Border Dispute: A Comparison of the Conventional and Bayesian Methods for Intelligence Warning，＂ Studies in Intelligence，Vol. 16，No. 2（Spring 1972），originally classified Secret，now declassified。后两篇文章已被重新收录出版，均可见于以下图书： H. Bradford Westerfield，Inside CIA＇s Private World: Declassified Articles from the Agency＇s Internal Journal，1955-1992 （New Haven: Yale University Press，1995）.［第十二章］概率评估中的偏见 191

正如本书第二章所解释的那样，人们总是倾向于看到自己期望看到

的事情，而且新信息也总是会被吸收融人既有观念。用言语表述不确定

性时，这一特点尤为明显。这些表述语言本身没有任何明确意义，它们

只是空壳而已。但读者或听者却会通过这些言语的语境，以及自己心中

对这个语境已经形成的明确看法，来理解它们的意思。

用模棱两可的言语表述情报结论时，读者会用自己已经确立的看法来

判断，并对结论的解读倾向于与既有看法一致，这就产生了偏见。这也许

就是那么多情报用户都说他们并没有从情报报告中得到什么的原因。

在分析人员的培训课中，我们可以很容易地证实这一现象。首先，给

学员们分发一份简短的情报报告，让他们划出所有关于不确定性的表述；

然后，要求他们在每处表述上方，根据他们认为报告作者想要在此表达的

数值概率，写下具体数字。通过这种方式，我们可以了解学员们对报告的

理解程度。对学员们而言，这是一个绝好的了解这一现象的经历，因为他

们对报告的理解通常会差别巨大，因此也会对此现象留下深刻印象。

一项实验中，一位情报分析人员被要求在评估中用具体的数值概

率，来代替自己在先前一篇文章中的概率限定语。他原来的说法是：

「停火协议仍然有效，但有可能在一周内被打破。」那位分析人员说，

自己在这个说法中想要表达的意思是：「停火协议在一周内被打破的

概率大约有 30％。」而协助他撰写报告的另一位分析人员却说，她认

为停火被打破的概率大约是 80％。然而，在共同起草报告时，这两位

分析人员都相信，他们在可能发生什么事情上意见是一致的。显然，

他们之间没能有效沟通，更不要说与报告的读者进行有效沟通。

中情局国家评估办公室首任主任谢尔曼·肯特，是最早认识到对

［1］原注：对于这一现象的另一解释，请参见本书第十三章。

［2］原注： Scot Barclay et al，Handbook for Decision Analysis （McLean，VA: Decisions and Designs，Inc. 1977），p. 66.192 情报分析心理学

不确定性不精确的表述将带来沟通问题的人之一。几十年前，肯特

就对决策者如何解读一篇国家情报评估报告中的「极可能」（serious

possibility）这个词感到震惊。很不幸的是，几十年后的今天，分析人

员与决策者之间，以及分析人员彼此之间存在沟通误会的现象却仍然普

遍存在。

笔者清楚记得，就一位重要线人是否可靠的问题，我曾与一个同事

展开过辩论。我认为该线人很可能是可靠的，而我的同事则认为线人很

可能受到了敌方的控制。长达几个月的争论之后，我让那位同事就线人

被敌人控制给出一个明确的数值概率，他说至少有 51％，而我认为线

人可靠的概率至少是 51％。当然，我们最后一致认为存在着巨大的不

确定性，而争论也就此停止。问题并不是两人在意见上有重大分歧，而

是「很可能」这个词本身具有模糊性。

表 12-1 显示的是一项实验的结果。在该实验中，被试是 23 名经常

阅读情报报告的北约军官。他们被要求阅读许多如「很不可能（highly

unlikely）的是……」这样的句子。除了关于概率的表述有变化外，所

有的句子都完全一样。接下来，他们要设想如果自己在情报报告中读到

这样的句子，会对这些表述分别给出多大百分比概率。表中每个点都代

表了一位军官给出的概率值。虽然大家对「多半」这个词的含义有广

泛共识，但对其他概率表述的解读却有巨大差异。表中的阴影部分，显

［1］注： Sherman Kent，＂Words of Estimated Probability，＂ in Donald P. Steury，ed.，Sherman Kent and the Board of National Estimates: Collected Essays （CIA，Center for the Study of Intelligence，1994）.

［2］: Scot Barclay et al，Handbook for Decision Analysis （McLean，VA: Decisions and Designs，Inc. 1977），pp.68-76.

［3］编注：此处原英文为 better than even，同 better than 50/50，通常译作「多半」、「较可能」等，在概率中表示「超过 50％」之意；同类词组还有 about even（同 about 50/50），意为「差不多」，其概率表示「大约 50％」。［第十二章］概率评估中的偏见

193

示的是肯特建议的表述范围。

关键问题是，如果情报报告使用模棱两可的语言，读者就会很容易

认为这些语言的意思与自己的已有观点一致，而报告本身对读者也就可

能起不到任何作用。当应对那些「小概率、大影响」的危险，决策者希

望制定应急方案时，这样的模糊性尤为麻烦。

表 12-1

概率表述

几乎肯定

0

极有可能

可能性很大

非常可能

i

可能性较大

i

.

很可能

我们相信

多半

差不多

我们怀疑

不大可能

不太可能

基本不可能

可能性很小

：+

几乎不可能

绝不可能 100.0.0

可能性极小 0 10 20 30 40 50 60 70 80 90 100

概率值（％）

［1］原注：本表中肯特的有关概率范围的表述语言，与从下文引用的肯特的表述

有些微差异： Sherman Kent，＂Words of Estimated Probability，＂ in Donald P. Steury，ed.，Sherman Kent and the Board of National Estimates: Collected Essays （CIA，Center for the Study of Intelligence，1994）.194 情报分析心理学

比如，设想有一份报告称，驻开罗的美国大使馆目前遭受恐怖袭击的可能性很小。如果大使原本认为袭击发生的概率不会超过 1％，那么他就不会决定采取什么行动。但如果大使原本就认为遭袭概率是 25％，他就可能会决定采取不少的预防措施。「可能性很小」这个表述与这两种解读都一致，而且也无法了解报告的作者自己表达的意思究竟是什么。

另外一种可能导致模糊的表述是「目前」这样的词。缩短预测的目标时段减小了事件发生的概率，但可能不会降低采取预防措施或制订应急方案的必要性。对无法预测准确发生时间的事件，如果使用「目前」这个词来表述，那就是说，它在未来 1 个月内发生的概率仅有 5％，但假如将时段扩展至 1 年，发生概率就能达到 60％（每月 5％，乘以 12 个月）。

情报分析人员如何才能在清楚自己确定程度的同时，又能表述不确定性呢？在表述不确定性的词组后面，用括号再加上一个数字作为限定，这或许是避免被误读的恰当方法。这种形式可以是几率比值，如「小于四分之一」；也可以是一个百分数范围，如「5％—20％」或「小于 20％」。当然，前者更为常用，因为大多数人从直觉上感到分数比百分数更容易理解。四、评估想定出现的概率

有时候，情报分析人员会以想定的形式表达自己的判断，也就是列举出一系列导致预期结果的事件。有证据显示，如果他们的判断涉及想定出现或发生的概率，那判断就会受到想定中细节的数量和性质的影响，而这与想定出现的真正可能性却无关。

一个想定中包含了用叙事性描述联系起来的一系列事件。要对想定 ［第十二章］概率评估中的偏见

195

出现的概率进行数学测算，正确的方法是将每个独立事件发生的概率相

乘。因此，对一个包含三个独立事件的想定而言，如果其中的每个事件

都有可能（各有 70％的概率）发生，那么，这个想定最终出现的概率

就是 0.7×0.7×0.7，也即刚过 34％。假如这个想定再加上第四个可能

（概率也是 70％）发生的事件，那它整体出现的概率就会减至 24％。

大多数人对于概率推理缺乏良好的直觉理解能力。一个简化此类问

题的方法是，假定（或假想）其中一个或几个可能发生的事件已经发生

了。这就会除去判断中的某些不确定性。另一个简化方法就是，以每个

事件发生概率的大致平均值为基础做出判断。上面那个例子，如果使用

平均值的方法，整个想定出现的预计概率就会为 70％。这样一来，这

个想定出现的概率似乎要比实际大出许多。

使用平均值的方法或策略时，想定中的大概率事件会抵消小概率事

件。这就违反了「链条原理」。从数学上讲，一个想定中概率最小的事

件，决定了作为一个整体的想定出现概率的上限。如果使用了平均值的

方法，更多看似合理的细节就可能被添人其中，导致人们会在判断上增

大想定出现的概率。而从数学上讲，事件数量的增加必然会减小整体想

定的出现概率。2

基础概率失误

评估形势时，分析人员有时会掌握两类证据：一种是个别案例的具

［1］编注：「链条原理」，意思是「一整个链条的强度不会超过它最弱的部分」（a

chain cannot be stronger than its weakest link），即事物的最弱部分决定了其整体强度，其所揭示的意义类似于「木桶原理」。

［2］: Paul Slovic，Baruch Fischhoff，and Sarah Lichtenstein，＂Cognitive Processes and Societal Risk Taking，＂ in J. S. Carroll and J. W. Payne，eds.，Cognition and Social Behavior （Potomac，MD: Lawrence Erlbaum Associates，1976），pp. 177-178. 196

情报分析心理学

ingy of Intelligence Analvsis

体证据；一种是对众多相似案例总结后的统计数据。后者这类统计数

据，被称为「基础概率」（baserate）或「事前概率」。「基础概率失误」

指的是这样的一种错误：除非统计数据揭示了某种因果关系，否则，这

些统计数据通常会被分析人员忽视。下面的实验就说明了这种错误。

越战期间，一架在黎明开展空中侦察行动的美军飞机遭到一架战机

的机炮攻击，但并不致命。柬埔寨和越南战机都在这一区域内活动。而

且，我们还知道以下情况：

A. 具体案例信息：遭攻击的美军飞行员认定是柬埔寨战

机。在能见度与飞行条件适宜条件下，情报分析人员对这位飞

行员识别飞机的能力进行了测试。面对一组战机样本时（越南

和柬埔寨标记的飞机各占一半），该飞行员辨识准确率为 80％，

错误率为 20％。

B. 基础概率数据：该区域内活动的战机中有 85％属于越

南，15％属于柬埔寨。

那现在的问题是：战机属于柬埔寨而非越南的概率有多大？

回答这个问题时，通常，情报分析人员的推理过程是：我们已经知

道该飞行员认定攻击战机属于柬埔寨，同时还知道他识别的准确率为

80％，因此，攻击战机来自柬埔寨的概率为 80％。然而，这个推理过程

看似合理但并不正确，因为它忽视了基础概率，那就是该区域内活动的

所有战机中有 85％来自越南。在我们了解具体的案例情况之前，基础

概率（或事前概率）就是我们了解该区域内敌方战机状况的依据。

［1］原注：这一实验的设想，源自蓝色和绿色出租车的问题，后又经弗兰克·斯特科

（Frank J. Stech）改进而成，最早见于以下文章： Daniel Kahneman and Amos Tversky，＂On

Prediction and Judgment，＂Oregon Research Institute Research Bulletin，12，14，1972.［第十二章概率评估中的偏见 197

尽管飞行员「很可能正确」地确认了敌方战机，但它来自越南的可

能性实际上更大。如果有读者不熟悉概率推理，不明白个中原因，就可

以设想那位飞行员遭遇了 100 个类似案例。于是，从上述情况 A（具体

案例信息）我们得知，越南战机被准确识别的概率为 80％，即 85 架越

南战机中有 68 架会被准确识别，还有 20％的越南战机，即 17 架会被

误认为柬埔寨战机；而由情况 B（基础概率数据）我们可以得知，100

个遭遇案例中有 85 次会遇到越南战机，15 次会遇到柬埔寨战机。

同理，80％的柬埔寨战机，即 15 架中的 12 架会被准确识别，而

20％的柬埔寨战机，即 3 架会被误认为是越南战机。综上所述，飞行

员看见的战机中有 71 架属于越南，而 29 架属于柬埔寨；而被飞行员认

定为柬埔寨的 29 架战机中，仅有 12 架确实是柬埔寨战机，其余 17 架

是误判，也就是说飞行员遭遇的实际上是越南战机。因此，尽管飞行员

当时对敌机识别的准确率达到了 80％，但当飞行员声称攻击来自柬埔

寨战机时，战机确实来自柬埔寨的概率却仅有 12/29，或者说 41％。

这看起来有些像数学游戏，其实不是。关键在于，此前飞行员观察

到越南战机的事前概率很大。之所以人们会出现理解上的困难，是因为

未经训练的直觉判断并没有融合、运用概率推理中的一些基本统计学原理。

由于事前概率似乎并不相关，因此绝大多数人不会将其融人推理过程。而

之所以看起来不相关，是因为战机在该区域出现概率的背景信息与飞行员

的观察之间没有任何因果关系。该区域内 85％的战机来自越南，15％来自

柬埔寨，这一事实并不能成为攻击来自柬埔寨而非越南战机的原因。

要更好地理解因果相关的背景信息能造成什么不同的影响，我们可

以把上述实验变化一下，将情况 B 改成如下：

［1］: Maya Bar-Hillel，＂The Base-Rate Fallacy in Probability Judgments，＂ Acta Psychologica，1980.198 情报分析心理学

尽管在该区域内出现两国战机的数目大体相同，但是挑衅

事件中约 85％来自越南战机，15％来自柬埔寨战机。

虽然形式改变了后，但情况 B 在数字和结构上其实没有变化。然

而，实验中的许多被试却显示出完全不同的心理效果，原因在于它清楚

地示了一种能联系事前概率和飞行员观察结果之间的因果解释。如果

越南人有挑衅倾向，而柬埔寨人却没有，那么，越南人比柬埔寨人更可

能挑衅这个事前概率就不会被忽视了。一旦把事前概率与因果关系联系

起来，飞行员的观察出现误判的概率立即会增大。

形式发生上述改变后，我们大多数人就可能这样推理：过去类似案

例的经验说明，挑畔一般来自越南战机。但我们又有来自飞行员的相当

可靠的报告，声称发动攻击的是柬埔寨战机。这两项互相矛盾的证据于

是相互抵消。因此，我们就无法确认究竟是哪一国的战机，而柬埔寨和

越南战机的概率约各为一半。在这个推理过程中，我们用到了基础概率

或事前概率提供的信息，并将它和具体案例信息结合起来，最后得出了

一个不需要数学计算就能最接近正确答案的结果，概率仍然是大约 41％。

当然，现实中我们很少会碰到上述实验中基础概率如此明确的情

况。当基础概率不清楚，我们必须通过推理或研究得出它时，它就更容

易被忽略。

所谓计划失误，就是指问题中的基础概率不是具体数字，而是通过

经验总结出来的。笔者本人也犯过这种错误。我在做某个研究项目的计

划时，可能会预计在 4 周内完成研究。这一判断的基础是相关的具体案

例证据，包括预想的报告篇幅、材料的可用性、项目议题的难易程度、

为可预见和不可预见的干扰因素预留的时间，等等。在这个项目前，我

［1］原注：日常生活中有许多这样的例子，具体参见： Robyn M. Dawes，Rational Choice in

an Uncertain World （Harcourt Brace Jovanovich College Publishers，1988），Chapter 5.［第十二章］概率评估中的偏见 199

曾做过类似的任务，在这方面有极丰富的经验。但与其他许多人一样，我过去也几乎从未在最初预计的时间范围内完成过哪个研究项目！然而，我还是会经受不住具体案例中方便、有力证据的诱惑。所有与项目具有因果关系的相关证据都显示，我应该能够在计划的时间内完成项目研究。就算根据经验我清楚地知道这根本不可能，我还是不会从以往的经验中汲取教训。我继续忽视那些基于以往无数类似项目的非因果性的概率证据，设定了我难以实现的完工期限。（准备本书所花费的时间，是我原来预计的两倍。可见，这些偏见确实不容易避免啊！） ［第十三章］

评估情报报告时的事后偏见

对情报分析工作的评估，包括分析人员对他们判断的自我

评估和他人对情报产品的评估。这个评估过程也会受到一系列

偏见的影响，结果就是分析人员常常高估自己的工作质量，而

其他人则会低估分析工作的价值和质量。这些偏见并非仅是出

于私利或不客观，而是人类思维过程的本质决定的，不仅难以

克服，甚至根本无法做到。

事后偏见以三种方式影响着对情报报告的评估：

1. 分析人员通常高估了自己以往判断的准确性；

2. 情报用户通常会低估可以从情报报告中获得的情况；

3. 监督者事后对情报工作失误进行分析时，通常会低估预

［1］原注：笔者最初将本章原文作为非保密文章发表在《情报研究》第 22 卷第 2 期（1978 年夏季号）上，题目为「认知偏见：事后分析的问题」（CognitiveBiases:Problems in Hindsight Analysis）。该文后来又收录于以下图书： H. Bradford Westerfield，editor，Inside CIA＇s Private World: Declassified Articles from the Agency＇s Internal Journal，1955-1992（New Haven: Yale University Press，1995）.［第十三章］评估情报报告时的事后偏见 201 测事件的实际难度。

这些偏见一点都不令人意外。因为分析人员虽然不一定能从自己身上看到这些偏见的存在，却能从别人身上看到。但出人意料的是，这些偏见并不仅是出于私利或不客观，也是固化在人类思维过程中更为广泛特征的表现之一，无法通过简单地强调客观性就可以克服。

一些心理学家们曾进行过下文所述的不同实验，尝试指导被试克服这些偏见。这些被试与实验结果间不具有任何既定利益关系。心理学家向他们阐明了这些偏见，并鼓励他们避免其影响或弥补影响产生的后果，但被试还是无法做到。认知偏见就像幻象一样，即使你知道它们存在，也无法抗拒它们的影响。

评估分析工作水平的分析人员、用户和监督者都会去做同一件事，那就是站在事后的角度分析问题。他们利用当前掌握的信息，与这些信息尚未被知晓时自己或他人已经、可能或应该掌握的信息加以比较。事后评估与情报判断截然不同，后者是从前瞻发展的角度预测问题。事后评估和事前预测这两种思维模式之间的区别，似乎就是造成偏见的根源之一。

与事前预测相比，事后评估所拥有的可靠信息数量显然要多。关于这一事实如何影响人类的思维过程，心理学家有几种解释。其中一种解释认为，当前更多可用的新信息会在事后评估过程中自然而迅速地改变我们对形势的认知，以至于我们几乎意识不到变化已经发生。新信息被获取后，会自觉而迅速地被融入我们此前形成的既有认识中。如果新信息对我们的认识意义重大，也就是说能够向我们告知当前形势发展的结果，或者回答之前并不确定的疑问，那么思维意象就会重构，把新信息纳人其中。比如，事后看来，之前被视为相关的因素可能变得不再相关，而之前被视为不相关的因素现在却可能是决定性因素。

当观点重构并吸收新信息之后，实际上也就无法准确重构之前的思 202 情报分析心理学

维模式了。正所谓，「铃儿一敲响，它就不会停唱。」如果时间过去不长，而且我们曾精确地阐述过之前的判断，就可能记起自己的判断结论，但显然无法准确重构之前形成判断的思维过程。要重构我们之前针对某形势的思考过程，或者想象那时应该思考了些什么，就不可避免地会受到我们当前思维模式的影响。我们已经知道了这一形势的最终结果，这使我们更难以想象出可能曾经考虑过的其他结果。不幸的是，知道思维以这种方式运作无助于克服它。

下文中将要描述的几项实验显示，理解这些偏见后能得到的启示是：分析人员的情报判断既没有自己想得那么好，也没有别人想得那么差。由于这些偏见通常无法克服，它们也似乎成了「事实」。因此，分析人员评估自己的工作和期望他人对自己评估时，应该把这一点考虑在内。这就要求我们应更为全面地努力做到以下几点：

1. 界定对情报分析人员应有的期望值；

2. 制定制度化的流程，以便将情报判断、预测与事实结果进行比较；

3. 衡量分析人员究竟能在多大程度上达到界定的期望值。

下面，我们的讨论将转向实验证据，它们分别从分析人员、情报用户和情报工作监督者三种视角揭示了这些偏见。

一、分析人员的视角

分析人员如想改善自身工作，就需要根据形势的后续发展，来评估过去的预测。要做到这一点，分析人员必须记得（或者能够参照）自己 ［第十三章］评估情报报告时的事后偏见

203

过去的预测，或必须依据所能回忆起预测时已掌握的信息来重构预测。

评估过程以及由此推动的学习过程是否有效，部分地取决于分析人员能

否准确回忆或重构过去的预测。

实验证据显示，对过去的预测，人们的思维中存在着错误记忆的整

体倾向。也就是说，当事件确实发生时，人们总是倾向于高估自己之

前预测事件发生的能力。相反，当事件并未发生时，他们又总是倾向于

低估自己曾经认为事件发生的概率。总之，与过去的预测相比，事件一

般总是显得都不太出人意料。这一实验证据，与分析人员的直觉经验相

一致。分析人员看起来，或让自己看起来很少会在预测所追踪的事件发

展上出现意外。

为了检验对过去预测的记忆偏见，心理学家挑选 119 位被试，要求

他们对 1972 年尼克松总统访问北京和莫斯科期间，许多可能发生的事

件概率做出预测。每次访问有 15 种不同的后果，每个被试要对每种后

果标出一个概率。这些后果涵盖了所有可能的后续发展情况，以便能得

出全面的概率值。

访问结束之后，在不同时间内，心理学家又要求同一批被试尽量准

确地回忆或重构自己前面的预测。（在之前的预测时，并没有提及还有

这项回忆任务。）然后，他们要求被试明确自己原来认为的每个事件在

访问期间是否已发生。

从做出预测到回忆这些预测之间的间隔，是 3—6 个月。在这样的情

况下，对认为自己认定的事件的确发生了这一点，84％的被试上表现出

偏见。也就是说，对于那些的确发生的事件，他们认为自己曾经做出准

确预测的概率，要远远大于之前他们实际预测的概率。与此类似，对于

［1］原注：本节内容源于下面著作中的研究: Baruch Fischhoff and Ruth Beyth，＂I Knew It Would Happen: Remembered Probabilities of Once-Future Things，＂ Organizational Behavior and Human Performance，13（1975），pp. 1-16。204

情报分析心理学

Psychoiogy of Intelligence Anaivsis

那些他们认为没有发生的事件，他们记忆中自己曾经预测会发生的概率

要小于之前他们实际预测要发生的概率，只不过这时的偏见不像前一种

情况那么明显。无论是发生还是没有发生的事件，被试在 3-6 个月之后

回忆时出现的偏见，要明显高于仅仅早两周就进行回忆的情况。

总之，一旦被试得知了最终结果，这种状况就会以某种方式影响

大多数被试对自己之前预测所保留的记忆。而且，记忆流逝的时间越

长，偏见的影响力就越大。如果将当初的预测与现在的结果进行比

较，总统访问期间发生的种种事件，看起来给人的意外程度都比应有

的小。有 84％的被试显示出了偏见，他们对自己的预测的评估要明显

好于他们的实际表现。

二、用户的视角

在评估情报产品质量时，情报用户会问自己这样的问题：「从这些

报告里，我知道了哪些原本不知道的东西？」在回答这个问题时，大多

数人都倾向于低估新信息的作用。这种「我一直都知道」的偏见，会导

致情报用户低估情报产品的价值。

人们确实会这样认识新信息的作用，以大约 320 人为被试的一系列

实验都证明了这一点。在实验中，每个被试都要回答从年鉴和百科全书

中抽出的同样 75 个事实性问题。为了测试他们对自己答案的信心，被

试同时还要给自己的每个答案选定一个在 50％-100％之间的数值来预

测答案正确的概率。

［1］原注：本节所介绍的实验源自以下报告：Baruch Fischhoff，The Perceived Informativeness of Factual Information，Technical Report DDI-I （Eugene，OR: Oregon Research Institute，1976）.［第十三章］评估情报报告时的事后偏见 205

在实验的第二步，被试被分成 3 个小组。第 1 小组又见到了曾经被问过的 25 个问题，他们被要求完全按照自己之前的答案来回答。这只是要测试被试能回忆起先前答案的能力。第 2 小组见到的是同样 25 个问题，但问题中标出了正确答案，并注明「仅供参考」。他们同样被要求重复自己之前的答案。如此就可测试当被试知道正确答案后，会在多大程度上扭曲被试对自己先前答案的记忆，因此就可以从分析人员的视角评估被试的偏见。这种偏见与上节讨论过的偏见相同，是被试在回忆自己先前预测的过程产生的。

为了把测试结果与头两个小组进行比较，第 3 小组则被出示了事前从未见过但难易程度相似的 25 个问题。虽然正确答案已经在问卷上标了出来，但心理学家要求这组被试按如同自己没见过正确答案一样来回答问题，以便测试被试回想在知道正确答案之前自己已掌握的情况。这个情形类似于要求情报用户评估自己从情报报告中获得了多少东西，而情报用户要想做到这一点，也只能通过回忆自己在读到报告前对情况了解多少。

从第 3 小组的实验中获得的数据结果最为重要。这个小组的被试明显高估了自己原先掌握的情况，而低估了自己因为看见答案而获得的帮助。对这个小组所做的两轮测试，分别在 25 个问题中的 19 个和 20 个问题上，小组的被试对自己给出正确答案的信心概率，都要大于在不知晓答案情况下本应出现的合理概率。

总之，这项实验再次证明了上一节实验的结论，即在知道答案后，人们倾向于认为自己原先知道的内容要比事实上更多。它同时也说明，人们更容易夸大自己在没有被告知正确答案的情况下就已经知道了正确答案的可能性。也就是说，人们倾向于低估自己从新信息中获得的价值，还有新信息帮助他们以更大的信心做出正确判断的程度。在一定程度上，情报用户也表现出同样的偏见，他们倾向于低估情报报告对自己 206 情报分析心理学

的价值。

三、监督者的视角

监督者，此处指的是对明显的重大情报失误进行事后调查，以此评

估情报工作表现的人。这样的调查一般都由国会、情报界人员以及中情

局或国防情报局的管理人员实施。对于那些非行政机构且不经常阅读情

报报告的人而言，对已知情报失误进行的事后评估是他们评判情报分析

工作质量的主要基础。

对情报失误进行的所有事后调查都有一个基本问题：以当时已掌握

的信息为基础，分析人员是否应该预见到将会发生什么？要对情报工作

有一个毫无偏见的评估，取决于能否不带偏见地回答这个问题。

不幸的是，某个事件一旦发生，就无法从人们的思维中抹去痕迹，

然后再重构人们之前的思维过程。在重构过去时，人们的思维存在着宿

命论倾向，认为所有发生的事件在当时的情况下都必然发生，因此也就

是可以预见的。简言之，人们倾向于认为分析人员应该能够预测事件的

发生，但依据当时的已知信息，这实际上根本无法预测。

下文的实验测试了这一假设：人们一旦知道了事情的结果，就更加

认定这个结果不可避免，而他们几乎没有意识到，正是因为知道结果，

才使自己的认识发生了这样的改变。

在一系列的实验中，心理学家使用简短的概述（150 个字）来描述

［1］原注：本节所介绍的实验源自以下著作：Baruch Fischhoff，＂Hindsight does not Equal Foresight: The Effect of Outcome Knowledge on Judgment under Uncertainty，＂ Journal of Experimental Psychology: Human Perception and Performance，1，3（1975），pp. 288-299.［第十三章］评估情报报告时的事后偏见 207

可能产生 4 种结果的不同事件。其中的一个事件是 1814 年英国人与廓尔喀人在印度的冲突。这一事件的 4 种可能结果分别是：英国人获胜；廓尔喀人获胜；和平协议未能达成，继续军事对峙；达成和平协议，但继续军事对峙。每个小组 20 个被试，共有 5 个小组分别参与了各项实验。其中 1 个小组得到的 150 字概述中仅描述了英国人与廓尔喀人的斗争但并未提及结果。其他 4 个小组得到的概述相同，却分别加上了一句提示最终结果的话 —— 当然，每个小组得到的提示各不相同。

所有 5 个小组中的被试都被要求预测上述 4 种结果的概率，并评估概述中各个数据对他们最终判断的重要性。那些已被告知某一特定结果的被试，就如同是对情报失误进行事后分析的监督者。他们尝试只依靠知晓结果前所掌握的信息，来评估最终结果出现的概率。表 13-1 展示了实验结果。

表 13-1

被试小组

结果 1

结果 2

结果 3

结果 4

未被告知结果

33.8

21.3

32.3

12.3

被告知结果 1

57.2

14.3

15.3

13.4

被告知结果 2

30.3

38.4

20.4

10.5

被告知结果 3

25.7

17.0

48.4

9.9

被告知结果 4

33.0

15.8

24.3

27.0

未被告知任何结果的那个被试小组判断发生结果 1 的概率为 33.8％，而被告知结果 1 就是实际结果的小组则认为，他们判断发生结果 1 的概率为 57.2％。人们对概率的判断显然受到了有关结果的信息的影响。与之类似，未被明确告知任何结果的小组（即实验控制组）判 208 情报分析心理学

断发生结果 2 的概率为 21.3％，而被告知结果 2 为实际结果的小组则认

为，他们判断发生结果 2 的概率为 38.4％。

6 项实验中所有预测结果（总计有 547 个被试做出了 2188 个预测）

的平均值显示：在被试知道或者相信 4 个可能结果中的 1 个已经发生

后，他们的这种事后评估该结果会发生的概率，会比事前（不知道任何

结果时）预测的概率大出约一倍。

如果被试获知某个结果的确发生了，那么，他们对各项数据与这

一结果的相关性的评估就会受到强烈影响。正如罗伯塔·沃尔斯泰特

写道：「在知道事实之后，回过头来再对有用和无用的信号加以区别

就要容易得多。在事件发生之后，当然总会存在着某个清楚无疑的信

号。既然灾难已经发生，我们现在就能清楚地看到这个信号在当时预

示着什么。但在事件发生之前，它却很模糊，并且传达着相互矛盾的

含义。」而这也许就是人们在知道结果后难以重构其知道结果前的思

维过程的原因。

对上述实验，心理学家又改换了几种形式进行，要求被试在假设

自己不知道最终结果的情况下回答问题，或者就像其他人确实不知道

结果时一样来回答问题。实验结果还是没有多少差别，仍旧表明了这

样的特点：被试几乎没有意识到，一旦自己知道了最终结果就会对自

己的认知产生影响。实验还显示，被试无法做到换位思考，去想象别

人会如何对这些形势做出判断。他们会认为，在不知道结果的情况下

人们通过解读数据而做出的预测，与被试在知道结果后对数据的解读

几乎不会有任何区别。

上述结果显示，进行事后评估时，监督者在试图确定分析人员当

时以已掌握的信息应该能够预见到什么情况时，会倾向于认为当时形

［1］: Roberta Wohlstetter，Pearl Harbor: Warning and Decision （Stanford，CA: Stanford University Press，1962），p. 387. Cited by Fischhoff.［第十三章］评估情报报告时的事后偏见 209

势发展的结果应该比实际情况更容易预见。由于未能重构一种事前（而非事后）观察形势的思维状态，监督者就会容易对情报工作吹毛求疵。

四、对实验的讨论

前文那些揭示偏见及其顽固性的实验，是美国国防高级研究计划署 （Defense Advanced Research Projects Agency）资的决策分析研究项目的一部分。遗憾的是，被试都是学生而非情报人员。但我们仍有理由相信，从这些实验结果中归纳出的结论也适用于情报界。因为这些实验研究的是人类的基本思维过程，而且结果也确实与情报人员的亲身经历相吻合。在由包括情报分析人员在内的专家们作为被试的类似心理测试中，专家们的反应与学生相似。

笔者也曾试图让情报分析人员作为被试来重复其中的一项实验，实验虽然不是十分成功，但同样能够支持之前的结论。为了测试情报分析人员通常会高估自己过去的判断这一结论的准确性，实验必须有两个前提条件：一是分析人员必须做出一系列定量预测，也就是说不能仅说某个结果可能出现，而是要使用具体的概率数字，如 75％；二是必须能够清楚地界定预测的事件是否确实发生。如果能够同时满足这两个前提条件，我们就可以回头检查分析人员对此前预测的回忆。由于中情局做出情报预测时极少采用量化概率，而且所预测事件在一定的时间段内通常无法清楚界定是否已确实发生，这些前提条件很少能被满足。

然而，我确实找到了几位分析人员，他们在两个截然不同的问题上都对事件的发生概率做出了定量预测，而且这些事件的最终结果也很清楚。我拜访了这些分析人员，请他们回忆自己之前的预测。这项微型实 210 情报分析心理学

Psychology of Intelligence Analysis 验的条件与理想状态相去甚远，最终结果也并不是特别清晰，但它们的

确支持前文那些更全面而系统的实验的结论。

所有的这一切都说明，这三类偏见不仅出现在特定的实验被试身

上，而且也出现在情报界人士身上。实际上，对于那些事业前途和声望

都取决于自己判断准确性的外国事务专家而言，他们出现这些偏见的概

率甚至更大。

五、能否克服这些偏见

对情报工作受到的带有偏见的评估，分析人员倾向于将其主要归因

于愚昧无知、自私自利、缺乏客观性等。所有这些因素也都可能是原

因，但实验显示，人类的思维过程本身就是一个主要原因。而且相较于

愚昧无知或缺乏客观性，它显得更为棘手。实验并未涉及被试的切身利益，但他们仍然表现出了分析人员所熟

知的偏见。此外，在实验条件下这些偏见极难被克服。被试被要求按照

尚不知晓结果的情况给出答案，但他们却无法做到这一点。心理学家向

其中一组被试详细介绍了这些偏见，还指出之前实验中得出的结果。但

当被试被要求对偏见造成的影响进行弥补时，他们仍然无法做到。即使

是拥有最充分的信息与最好的意愿，偏见仍然存在。

这种顽固性告诉我们，这些偏见的确是源于我们思维过程本身的性

质。那些在了解事件的实际结果后尝试重新回忆自己先前预测的分析人

员，那些思考情报报告究竟给自己的认知带来了多大影响的情报用户，

以及判断分析人员当初能否避免情报失误的监督者，他们都有一个共同

点，那就是他们的思维过程都是事后评估性的。他们都试图消除已知信

息造成的影响，以便回忆、重构或想象在获得几乎明确的信息之前曾经［第十三章］评估情报报告时的事后偏见 211 面临或本来可能面临的不确定性。

然而，似乎在获得明确或权威的信息之后，人们的思维意象会因此立刻无意识地进行重组，以便与新信息保持一致。人们过去的认知一旦被重组，想要再准确重构他们之前经历过或本来可能经历过的思维过程，即使不是不可能，也是相当困难。

有一个方法也许可以帮助人们克服这些偏见，那就是他们各自都需要提出一个问题。情报分析人员应该自问：「如果出现了相反的结果，是不是会出乎我的意料？」情报用户应该自问：「如果这篇报告告诉我相反的结果，我还会不会相信？」而情报监督者则应该自问：「如果出现了相反的结果，依据当时已掌握的信息，是不是一定能预见得到？」这些问题也许可以帮助人们回忆或重构在知道报告内容或形势发展结果前就存在的不确定性。

阅读本章的读者，特别是认为本章并没有带来多少新知识的读者，都可以用上述方法去检验它能否克服这些偏见。如果本章指出，心理实验显示分析人员未必会高估自身预测的准确性，或者情报用户未必会低估情报报告的价值，那么，你会相信吗？（答案很可能是否定的。）如果本章指出，心理实验显示这些偏见完全是由自私自利或缺乏客观性引起的，那么，你会相信吗？（答案很可能是肯定的。）如果本章认为通过有意识尝试客观评估可以克服这些偏见，那么，你又会相信吗？（答案可能是肯定的。）

这些问题也许会引导你想起在阅读本章前自己的知识或观点。如果真是这样的话，这些问题就能够提醒你注意自己在这里学到了什么，那就是：在评估情报预测的过程中存在明显的偏见；这些偏见是人类思维过程的自然产物，而并不仅仅是因为自私自利和缺乏客观性，因此，想要克服它们，非常困难。结论 ［第十四章］

改进情报分析工作

关于如何避免或解决前面各章中提及的问题，本章为情报分析人员列出了一张清单，并总结了一系列小窍门。同时，它还给情报工作管理者提出了建议，以帮助他们创造有利于改进情报分析工作的环境。

如何才能改进情报分析工作？这的确是一个挑战。有许多改进情报分析工作的传统方法，比如，为分析人员搜集更多更好的信息，改变分析流程的管理模式，增加分析人员的数量，为分析人员提供学习语言和国别地区知识的机会来提高其实质专业素养，完善雇员遵选和留用标准，改进报告撰写技巧，理顺情报分析人员与情报用户之间的关系，以及调整情报分析产品的类型，等等。

以上方法都有可能发挥重要作用。但分析工作首先是一个思维过程，而各个层次的分析人员却习惯于忽视如何改进思维这个问题。因此，为了吃透改进情报分析工作这个问题的核心和精髓，我们必须更好地理解、影响和引导分析人员的思维过程本身。［第十四章］改进情报分析工作 215

一、为情报分析人员准备的清单

下面的清单为分析人员归纳了在分析过程中避免陷阱的指导原则。依据这些指导原则工作，分析人员能够避免犯下可避免的错误，并提高判断的正确率。下面的讨论围绕分析过程中的六个关键步骤展开，它们分别是：定义问题、提出假设、搜集信息、评估假设、选择最可能的假设以及对新信息的持续监控。

（一）定义问题

作为分析人员，我们首先要确定自己或用户已经提出了正确问题。我们要敢于大胆地向上级提出建议，对任务要求做出修改。因为提出要求的决策者可能并未充分考虑他们自己的需求，或者所提的要求在层层下达的过程中遭到了曲解。我们可能比决策者本人更加清楚他们需要什么，应该需要什么或者可以怎么做。一开始时，我们务必就要让上级明白，在分析质量与在规定时间内能够完成任务这两者间存在着取舍关系。（二）提出假设

作为分析人员，我们要确定所有需要考虑且具有一定合理性的假设。首先，通过咨询同事和业外专家，我们要在清单上列出尽可能多的观点。做这一步工作时，要采取头脑风暴的方式，做到自由讨论、集思广益，直到提出所有观点之后再开始判断。

然后，我们将观点清单上的假设减少到可正式开展分析的合适数量，再进行更为细致的分析。这些假设中往往要包括一个有关欺骗的假 216 情报分析心理学

设，即某国或某组织正在为影响美国的认知或行动，而采取拒止与欺骗的措施。

在这一阶段，我们不要仅仅因为没有充分的证据支持某个合理的假设就排除它，尤其是有关欺骗的假设。如果某国正通过拒止与欺骗来隐藏真实目的，我们就不要指望在细致分析这种可能性前，就能掌握与之相关的任何证据。有关欺骗的假设，以及其他没有直接证据支持但似乎合理的假设都应该纳入下一步的分析工作中，只有在仔细思考并找到有力的反证后才能排除。

（三）搜集信息

作为分析人员，如果我们仅仅被动地依赖那些自动提供给我们的信息，就很可能无法解决所有的分析问题。为了完成工作，我们有可能需要四下寻找，挖掘更多信息。要与情报搜集人员、行动分局的其他工作人员或情报的最初分析工作者建立联系，这样常常能获得新信息。另外，我们还要通过学术专家、外国报纸和专业期刊来做搜集工作。

我们要针对所有合理的假设来搜集信息，而不是只针对那个似乎最可能的假设，以便评估所有假设。分析人员研究那些原本未被认真考虑的假设时，常常会被引人出乎意料的和不熟悉的领域。比如，如果我们要评估某个欺骗的可能性，就需要评估该国或组织采取拒止与欺骗行动的动机、机会和手段。要做到这一点，我们就需要了解美国人力和技术情报搜集力量的优势和劣势。

在搜集关于各个假设的相关信息时，不要急于判断，这一点相当重要。人们很容易依据极少的信息对某个假设形成印象，而且一旦形成，印象就难以改变。如果我们自认为已经知道了答案，就要反问什么信息［第十四章改进情报分析工作 217

会让自己改变想法，然后再去寻找相应的信息。

我们要尽量提出不同的假设，这样才能有机会平等地对待这些假

设，从而发现某些假设并没有我们刚开始设想的那样可信。然后，如果

我们能够系统地提出某个不同的假设，通常会增大该假设成立的概率。

「无论最终目的是侦破案件还是情报预测，出色的侦探必不可少的一项

素质，就是始终愿意从不同的角度、主流的或非主流的假设出发，去思

考手中的材料。」

（四）评估假设

即使有那么多的证据支持之前我们感觉最有可能的那个假设，我们

也不能被误导。同样的证据可能符合几个不同的假设。我们要集中精力

提出论据来反驳假设，而不应尽力证实它们。换言之，要特别关注那些

证明某个或某几个假设比其他假设更不可能成立的证据或假定前提。

我们要承认，可能正是决定我们如何解读证据的假定前提，而非证

据本身推动我们得出结论。如果某些假定前提涉及某国国家利益及该国

国内情况，那它们就格外重要。只要我们在分析中清晰阐述了某些假定

前提，而且分析了结论对它们的敏感性，那么这些假定前提就是可以接

受的。现在，我们需要回答的问题是：不同的假定前提，是否会导致对

证据的不同解读，并得出不同的结论？

我们可以考虑使用本书第八章提及的矩阵方法，追踪证据及其与各

个不同假设之间的联系。

要对各种认知偏见保持警惕，特别是如果我们不能充分认识怎

样从某国的角度看待某种形势，此时产生的偏见就相当危险。不要

［1］: Roberta Wohlstetter，Pearl Harbor: Warning and Decision （Stanford，CA: Stanford University Press，1962），p. 302.218 情报分析心理学

为了弥补我们认识的不足，就把美国政府或美国人在类似情况下可能的行为，套用到另一行为体身上，认为后者也可能会发生同样的行为。

我们要认识到，美国对某国的国家利益与决策过程的认知，通常与该国对自身利益的认知及其内部实际决策过程并不一致。比如 1989 一 1990 年间，众多中东问题分析人员显然都想当然地认为，为了在漫长的两伊战争之后复苏经济，伊拉克将进行部分裁军。他们还相信，巴格达认为攻击某个阿拉伯邻国并不符合伊拉克的最高利益。我们现在知道，那些分析人员都估计错了。

在对某国可能采取的行动做出判断时，我们要不吝惜时间和精力去咨询所有可能最了解该国政府实际想法及决策模式的专家们。

我们不要想当然地认为，为了达到既定目标，外国政府的一切行为都是基于理性决策而做出的。要意识到政府的行为有时候是半独立的官僚机构之间讨价还价、在不恰当的条件下按照标准操作流程行事、意外后果、没有遵从指令、混乱、事故或巧合的结果。

（五）选择最可能的假设

作为情报分析人员，我们要通过证伪而非证实假设来推动工作。概率最大或最可能的假设，往往是不利证据最少而非有利证据最多的那个假设。

阐述结论时，我们要特别注意那些被考虑过的所有合理假设。要列举出那些支持我们判断的论据和证据，还应简要说明为何其他假设被排除或被认为发生概率较小。为了避免表达模糊，在表述关键判断的不确定性之后，我们要在括号内注明发生的几率或概率的范围。［第十四章改进情报分析工作 219

（六）对新信息的持续监控

在这个快速变化和随机发展的世界，分析结论常常只具有暂时意义。当我们获得的新信息改变了自己对形势的认识时，形势或许会发生变化，也或许会保持不变。对那些需要寻找且一旦出现就意味着概率将发生重大变化的信息，我们要明确界定。

作为分析人员，我们要特别注意当新信息与之前所理解的不相符时产生的意外感。要考虑这些意外的信息是否与其他假设一致。无论多么细微的一两条意外信息，都可能是需要调整我们对当前情况的认识的最早线索，因为它们说明这种认识并不完整，甚至可能有重大错误。

二、对情报分析工作的管理

本书所讨论的认知问题，不仅对情报分析工作的实施，而且对它的管理具有意义。全书渐近结尾，本节要讨论情报分析工作的管理人员可以采取哪些措施，创造出一个有利于情报分析工作卓越发展的组织环境。这些措施可以被归纳为四大类，即研究、培训、接触不同的思维模式以及指导分析产品。

（一）支持开展研究工作

管理人员应该支持开展相关研究工作，以便加深自己对情报判断过程中所涉及的认知过程的理解。他们有必要更好地理解情报分析工作中涉及的思维技巧，如何针对求职者测试这些技巧，以及如何训练分析人员提高这些技巧。同样，分析人员也需要更充分地理解认知的局限性如 220 情报分析心理学

何影响情报分析，以及如何才能将其影响降到最低程度。他们需要简单

的工具和技巧的帮助，避免犯下本可以避免的错误。这里面有大量的研

究工作要做，但大家应从何处开始，也很难知晓。

被征募进入情报界工作的学者，应当包括认知心理学家和其他背景

各异且有兴趣研究情报分析思维过程的学者。情报界应当为那些有前途

而又愿意从事此领域研究的学者设立博士后岗位。通过这些努力，假以

时日，对分析人员应如何进行分析判断，以及哪些工具或技巧有助于他

们判断，大家就会建立更好的认识基础。

管理人员还应该支持研究情报分析人员的思维模式和内在思维模

型。由于这些思维模式或模型构成了分析人员观察外国动向的「屏幕」

或「镜头」，研究这些「镜头」的特性，与直接研究外国问题本身一样

有助于形成准确的判断。

（二）培训

针对情报分析人员的培训，大多数都侧重于组织流程、写作风格以及方

法论技巧等。文笔清晰的分析人员一般被认为思维清晰。但依据错误的分析

流程也可能写出清晰而有力的论据，只不过这些论据支持的是错误的判断。

［1］原注：格拉汉姆·阿利森有关古巴导弹危机的著作（Essence of Decision，Little，Brown＆Co.，1971）是笔者想到的一个例子。阿利森认为有 3 种政府如何运作的假

定前提，即理性角色模式、组织过程模式和官僚政治模式。他接着说明了一个分析

人员关于哪种模式最适宜对外国政府行为进行分析的已有假定前提，将导致他关

注不同的证据，从而产生不同的结论。还有一个我本人的例子，关于备受争议的

克格勃叛逃者尤里·诺森科，我给出了 5 种不同的反情报判断，请参见：Richards

J. Heuer，Jr.，＂Nosenko: Five Paths to Judgement，＂ Studies in Intelligence，Vol. 31，No.3 （Fall 1987），originally classified Secret but declassified and published in H.Bradford Westerfield，ed.，Inside CIA＇s Private World: Declassified Articles from the Agency＇s Internal Journal 1955-1992 （New Haven: Yale University Press，1995）. ［第十四章］改进情报分析工作 221

对情报判断涉及的思维和推理过程，以及可降低或克服分析工作中的认知障碍的工具，我们应该增加培训时间。本书的目的就是为这样的培训提供支持。

培训过程中如果我们能够不时地为学员提供建议和帮助，效果就会更好。在很多领域，一个经验丰富的教员如果能持续监控和指导学员们的表现，是对课堂讲授的有益补充，情报分析领域的培训也不例外。这本应是部门领导或资深分析人员的工作，但他们却经常忙于应付任务而无暇顾及。

为了指导新分析人员或向处理极难问题的分析人员提供咨询，我们值得花时间思考如何组建一支分析培训师队伍。许多行业都有的「SCORE 制度」是一个选择。SCORE 意为「退休行政人员资深顾问团」（Senior Corps of Retired Executives），是由退休行政人员组成的全国性组织，其成员自愿为刚刚创业的年轻企业家提供咨询。我们应该组建一个退休分析人员小团体，成员应当不仅拥有值得传授给新分析人员的工作技能和价值观，而且自愿（或受雇）每周花几天时间为年轻分析人员提供指导建议。

我们应该要求新人行的分析人员阅读情报分析的专业书籍和文章，每月抽出半天时间参加讨论会，交流阅读心得和成长的体会。类似的自愿交流学习项目也可以在经验丰富的分析人员中开展。这样做可以帮助分析人员更清楚自己在分析时使用的方法。除了教育作用外，就情报分析的问题开展阅读和讨论，也有助于分析人员彼此间形成共同经验和语汇，并与管理人员进行沟通。

笔者建议将以下作品列为分析人员的必读著作：罗伯特·杰维斯的《国际政治中的知觉与错误知觉》（Perception andMisperception in International Politics），普林斯顿大学出版社，1977 年版；格拉汉姆·阿利森的《决策的本质：解释古巴导弹危机》（Essenceof［1］编注：原文如此，应为 1976，可参见本书前文数处原注。222 情报分析心理学

Decision: Explaining the Cuban Missile Crisis), 小布朗出版公司，1971 年版；欧内斯特·梅的《前车之鉴：美国外交政策中运用历史经验的成

得失》("Lessons" of the Past: The Use and Misuse of History in American Foreign Policy), 牛津大学出版社，1973 年版；伊弗雷姆·卡姆的《突袭》(Surprise Attack), 哈佛大学出版社，1988 年版；理查德·贝茨的《分析、战争与决策：情报失误为何无法避免》(「Analysis,Warand Decision: Why Intelligence Failures Are Inevitable"),《世界政治》(World Politics), 总第 31 期，1978 年 10 月第 1 期；托马斯·库恩 (Thomas Kuhn) 的《科学革命的结构》(The Structure of Scientific Revolutions), 芝加哥大学出版社，1970 年版；罗宾·霍格思的《判断与选择》

(Judgement and Choice), 约翰·威利出版公司，1980 年版。虽然这些书籍和文章都是多年前的著作，但它们都是具备永恒价值的经典作品。

毫无疑问，当代的分析人员还可以推荐其他著作。有关中情局与情报界

针对情报失误进行事后分析的内容，也应该纳入这个阅读项目。

为了强化整个组织的记忆和学习，一切重大情报失误都应彻底进行

事后分析，而且也需要研究分析工作（区别于搜集工作）的成功案例。

经过整理校订后，成败两方面的分析都应集中管理，以便分析人员研究

和识别情报分析失误和成功各自的普遍特征。对分析工作成败得失的事

后因果分析的案例和结论，应当在组织内广泛传播，并应用于培训课程

之中，以提高大家对有关分析工作问题的认识。

为了激励分析人员向经验学习，在没有出现重大情报失误的情况

下，管理人员也应该要求对分析工作的表现进行经常性、系统性的事后

评估。从某一个正确或不正确的判断，我们并不能得出分析人员思维模

式正确与否的结论，因为只有被后续事件证明或未能证明的一系列相关

判断才能反映出该分析人员的思维模式正确与否。要获得对过去判断准

确性的系统反馈，通常很困难或是根本不可能，在政治情报领域尤其如第十四章］改进情报分析工作 223

此。对政治情报问题的判断通常都使用不精确的词语，而且还受到其他发展变化的影响。即使事后分析，我们也无法找到客观标准来评估绝大部分政治情报判断在当时的精准性。

然而，在经济和军事领域，预测通常都是与数量相关的，我们从中可以获得对分析工作的系统性反馈。对那些会定时更新情报预测的领域，事后评估应作为标准程序确定下来。但只有当事后评估是为了更好地理解分析工作而进行的客观研究，而不是找个替罪羊或追究责任时，事后评估才能达到学习的目的。这也说明，即使事后评估会牺牲一定的客观性，但也应该成为组织内的一项日常工作。

（三）接触不同的思维模式

官僚体制的现实会产生要求意见一致的巨大压力。管理人员应该主动作为，确保在情报界内相互竞争的合理观点最终都能出现。分析人员需要有一种安全感才敢于表达刚萌芽的新观点，大胆讨论别人的观点，而不需要害怕偏离了已有的正统观念而遭到指责。

本书的大部分讨论内容都是帮助分析人员对不同观点保持开放思维的方法。管理人员也可以为此提供帮助，大力开展使分析人员接触到不同观点的活动，如咨询业外专家、举办分析辩论会、开展分析竞赛、提出相反观点（扮演「魔鬼代言人」）、进行模拟推演，以及开展跨学科的头脑风暴等。

当要做出基于外国文化的重大判断时，情报分析人员常常会出现大卫·杰里迈亚海军上将所说的「所有人都像我们这么想」的思维，而咨询业外专家是避开这一陷阱极为重要的手段。相较于业外专家，分析人员在对象国家内生活的时间一般要短，吸收理解该国文化的机会也少。如果分析人员不能理解某一外国的文化，就不能从该国政府的角度去看 224 情报分析心理学

待问题。于是，他们就容易形成错误的镜像思维，即臆断别国领导人思

考问题的角度与自己相同。分析人员就会想当然地认为，如果双方处境

相似，别国也会采取与我们一样的行动。

镜像思维是一个常见的分析失误的根源，据说也是情报界未能预测

印度在 1998 年进行核试验的重要原因。大卫·杰里迈亚海军上将领导

一个美国政府小组对此事进行了分析后，他建议，只要出现如 1998 年

印度民族主义者赢得选举并执政这样可能导致政策变化的重大事件，我

们都应该更系统地咨询业外专家的意见。

分析报告发布之前对其进行审核，会为我们从不同视角分析问题提

供另一个机会。对分析人员寻找和评估证据时使用的思维模型，审核流

程应该明确进行质疑。比如，分析人员在报告中是否讨论了做出主要判

断时所依据的假定条件？分析人员曾经考虑但最终排除的假设是哪些，

原因是什么？哪些因素会使分析人员改变自己的观点？

在理想状况下，这种审核应该有来自分析报告所涉问题之外领域的

分析人员参与。同一部门或领域的分析人员往往会有相似的思维模式。

过去的经验显示，邀请其他部门的专家参与审核，这种其他领域的专业

知识对审核的意义重大。因为他们观察和提出的问题，常常是报告的作

者从未发现或思考过的。由于他们并不十分关注报告的内容，就更容易

找到相关假定前提，能更好地评估论点、内在一致性、逻辑性，以及确

定证据与最终结论之间的关系。参与审核的人也能够从中受益，在不受

分析议题影响下学习优秀分析工作的标准。

（四）指导分析产品

对于关键议题，管理人员应拒绝大多数只提出单一结果的分析，因

［1］: Transcript of Adm. David Jeremiah＇s news conference at CIA，2 June 1998.［第十四章］改进情报分析工作 225

为这种分析反映的是分析人员仅关注自己认为很可能正在或将要发生什么，是一种单一思维。如果失误导致的后果无法承受，或是敌方进行欺骗的概率极大时，管理人员应要求分析人员采取本书第八章提及的系统性分析步骤，明确曾经考虑过的所有假设，阐明为什么这些假设不太可能，并清晰表述事件不按预期发展的概率。

甚至在分析人员坚信事件不会发生的概率为 75％时，它还是会有 25％的发生概率。明确说明这一点，有助于更好地为决策者界定问题。决策者就会考虑：「25％的可能性是否值得去制订应急预案？」

比如，如果可能性较小的那个假设，正是新一届印度政府会履行其竞选承诺而进行核试验（就像近来发生的情况那样），那么，25％的可能性就足以要求提高技术搜集系统的警戒级别。

诸如「可能」、「很可能」、「不太可能」，「也许」和「有可能」等表述不确定性的词语，一直被人们认为是模糊和误解的根源。这些词语本身没有任何内涵。但读者或听者会通过它们所在的语境，以及自己脑海中关于讨论议题的既有观念，来赋予它们不同的涵义。情报用户对表述不精确的可能性判断的理解，则常常会受到偏见的影响而倾向于同自身既有观点保持一致。这就意味着情报报告的价值会被低估，对用户的判断影响甚微。当涉及决策者在处理那些需要制订应急计划的「小概率、大影响」的危险时，这种模糊性尤为麻烦。

情报分析工作的管理人员需要向分析人员明确说明，只要后者能够清楚地向读者说明不确定的程度、根源以及能让形势变得清晰的标志性信号，结论中即使存在不确定性也并无大碍。在括号中以几率比值或数字形式注明发生概率的范围，这应成为标准作业程序。

对那些一旦发生就可能对美国政策造成重大影响的小概率事件，如果管理人员能够分配更多的资源去继续监控和分析，就能减小未来遭遇突发意外的可能性。分析人员往往出于自身原因，不愿意花费时间去研 226 情报分析心理学

究他们认为不会发生的事件，因为虽然意外事件一旦发生就会毁了分析人员的职业生涯，但研究它们却也无助于他们事业的发展。在日常跟踪时事动态的压力下，管理人员和分析人员有必要清晰明确哪些是「小概率、大影响」事件，并分配相应资源加以分析和涵盖。

要确定哪些小概率事件值得分配资源加以研究，有一条指导原则，也就是要问下面这个问题：「无论该事件发生的概率多小，一旦决策者充分理解风险的存在，是否就会立即制订应急计划，或者采取某种形式的预防或先制行动？」如果答案是肯定的，那么即使可能性似乎很小，我们也应该分配资源展开分析。

情报工作的管理人员应该支持对关键问题进行定期而彻底的分析评估，以此避免增量分析方法产生的陷阱。如果信息是通过长期点滴积累而获得的，那么就容易被分析人员的既有观念同化。任何一条单独的信息，都不足以改变分析人员的既有观点。虽然大量信息中的各种情况累加起来意义重大，但除非把它们作为一个整体来思考，否则作用就会削弱。

最后，管理人员应把分析工作的作用与局限告知给情报用户，应当为评估分析工作确定一系列现实的预期目标并以此作为标准。

三、结论

情报分析工作是可以改进的！通常，情报分析人员要面对不完整和模糊的信息，而本书讨论的这些措施中，没有一项可以保证分析人员总能从这样的信息中得出精准的结论。情报失误必然会不时发生。然而，综合采取本书讨论的措施，无疑能够提高分析人员的成功率。英汉术语对照

actor 行为体

analogy 类比

Analysis of Competing Hypotheses (ACH) 竞争性设分析法

analytical judgment 分析判断

anchoring 锚定

assessed probability 预计概率

assumption 假定（前提）

Availability Rule 可性则

axon 轴

base rate 基础概

Bayesian Statistical Analysis 贝统计分析

beliefsystem 信任系统

best guess 最想

Board of National Estimates (美国) 国家评估委员会

case officer 专案官

causal linkage 因果联系

causal relationship 因果关系

Center for the Study of Intelligence (情) 情研究中心 CIA's Office of National Estimates 中情局国家评估办公室 cognitive bias 认知见 228 情报分析心理学

cognitive limitation 认知局限

cognitive psychology 认知心理学

cognitive trap 认知陷阱

coherence 连贯性

competing hypotheses 竞性设

competitive analysis 竞争性分析

conceptual mechanism 概念性制

conceptually-driven analysis 概驱分析

consistency 一致性

correlation 相关关系

covariation 变关系

criticalthinking 批性思维

current intelligence 动向情报

dataimmersion 信息浸

data-driven analysis

decision tree 策树

Defense Advanced Research Projects Agency (美国) 国防高级研究计划署 denial and deception 拒止与骗

Deputy Director for Intelligence (DDI)(中情局) 情报分局副局长

Deputy Director of Central Intelligence (DDCI)(美国) 中央情报副主任 Deputy Director ofCIA (DD/CIA) 中情局副局长

devil's advocate 魔代言人

diagnosticity 诊断价值

Director of Central Intelligence (DCI)(美国) 中央情报主任

Director of CIA (D/CIA) 情长

Director of National Intelligence (DNI)(美国) 国家情报总监

Directorate of Intelligence (DI)(中情局) 情分局

Directorate ofOperation (DO)(中情局) 行动分局

expectancy thesis 预论

externalizing 化英汉术语对照 229

fallacy of identity 同一性误

fault tree 障树

fMRI 功能性核磁共振成像技术

Gurkha 喀

hypothesis 设

HUMINT 人力情报

incubation period 孵化

intelligence alert 情报警戒

Intelligence Community (美国) 情界 intelligence failure 情误

intelligence officer 情官

joint probability 联概率

key variable 关键量

Law of Large Numbers 律

Law of Small Numbers 少

linchpin analysis 点析法

linchpin assumption 关性定

long division 长除法

long-term memory (LTM) 长时记忆 mathematical psychologist 数心理学家 mental block 思障

mentalimage 思意象

mental machinery 思

mentalmodel 思维模型 230 情报分析心理学

mental process 思过程

mentalrut 思维定式

mind-set 思维模式

mirror-imaging 镜像思维

National Security Council (美国) 国家安全委员会

National War College (美国) 国家战学院

Naval Postgraduate School (美国) 海军研究生院

neuron 神经元

numerical probability 率

Office of Strategic Services (OSS)(美国) 情 pattern of co-variation 变模式

pattern of relationship 关系模式

perception 认知

perceptual filter 认知滤镜

personal probability 个概率

planning fallacy 计划误

preconception 先入之见

pre-conscious 前意识

Principle of Coherence 连贯性原则

prior probability 前率

probabilistic relationship 概率关系

reconstruct 重构

regression analysis

relative frequency 相对频率

reports officer 通报官

Research and Analysis Branch (情) 研究分 restructure 重

retrieval of information 信息检取英汉术语对照 231

satisficing 法

scenario

schema 图式

selective perception 选认知

separatist 分离主义

Senior Corps of Retired Executives (SCORE) 退休行政人员资深顾问团 sensitivity analysis 敏感程度分析

sensory information storage (SIS) 感觉信息存储

short-term memory (STM) 短忆

Sinai 西奈（地名）

situational logic 情辑

source 来源，线人

SpanishArmada 西班牙「无敌舰队」

statistical measurement 统计测量

statistical probability 计率

strategic assumption 定

Strategic Defense Initiative 计

Studies in Intelligence (情)《情研究》志

subconscious 下意识

subjective probability 率

Surgeon General 公共卫生署长

synapse (神经元的) 突触，神经键

synaptic gap 突触间隙

tactical indicator 术指标

test subject 被试

third-variable 第三方变量

warning indicator 预警征

working memory 工作记忆英汉人名对照

AbrahamBen-Zvi 亚伯拉罕·本 - 兹维 AldrichAmes 奥德里奇·埃姆 Alexander George 亚山大·治 B.F.Skinner 斯金纳

BartonWhaley·惠利

BenjaminFranklin 本杰明·富兰克林 DavidH.Fischer 戴维·费希尔

David Jeremiah 大卫·杰里迈亚

Douglas MacEachin 道格拉·凯 EphraimKam 伊雷姆·卡姆

ErnestMay 特·梅

FrankAndrews 克·安德鲁 FrankStech 弗兰克·斯特科

GrahamAllison 格拉姆·阿利森 HankAppelbaum 汉克·阿佩尔鲍姆 Herbert A.Simon 伯特·西蒙英汉人名对照 233

JackDavis 杰克·戴维斯

Joseph Priestley 约瑟·普里特利 LeeHarvey Oswald 李·哈维·奥斯瓦尔德 Nisbett 尼比特

P.C.Wason 森

Richard Betts 查德

Richard Helms 查德·赫姆斯

RichardsJ. Heuer, Jr. 小查兹·霍尔 Robert Gates

Robert Jervis·

Roberta Wohlstetter·RobinHogarth 罗·霍格思

Sherman Kent

Theodore Sarbin 西奥萨

Thomas Kuhn 托

William Casey 凯西

Yuriy Nosenko 里译后记

小理查兹·J. 霍耶尔 1951 年加入美国中央情报局，先后任职于行动分局和情报分局。1975 年转作情报分析工作后，霍耶尔开始着手研究情报分析理论，并从认知心理学的角度来认识情报分析失误，撰写了大量的内部文章，他也很快成为情报分析方法论任务组的主管，负责组织情报分析研究工作。他主编过《政治情报定量方法：中央情报局的经验》等著作，被《情报研究》聘为特约撰稿人。1979 年，霍耶尔退休后，仍然活跃在情报分析界，经常以自由职业专家的身份参加各种各样的情报分析方法方面的研究项目。同时，他也受聘于中央情报局继续从事情报分析研究和培训工作。1987 年，中央情报局授予他海豹大勋章，以表彰他在解决美国情报界所面临的挑战性困难所做出的方法论方面的杰出贡献。

霍耶尔在情报分析方法方面的研究成果影响深远，《情报分析心理学》一书也是他在情报分析理论方面的代表作。本书是霍耶尔以 1978-1986 年期间为中央情报局撰写的一系列研究报告、内部文章为基础撰写而成的。该书成稿后，被中央情报局和美国其他情报机构列为培训情报分析人员的经典教材，作为情报分析高级管理领导者和组织者的必备参考读物，同时也是情报预警和反情报欺骗研究领域的重要读物。1999 年，中央情报局情报研究中心出版此书后，还于 2000 译后记 235

年 6 月协同肯特情报分析学校等机构专门组织了一场关于情报分析心理学的学术研讨会，在美国情报分析界进一步推进了情报分析心理研究方面的工作。

霍耶尔所撰写的《情报分析心理学》之所以对美国情报理论研究，并进而对情报人员培训、预警情报分析、情报失误研究等实际工作产生了重大影响，原因主要在于以下三点：

第一，本书所注重的研究对象不是一般情报分析研究中的情报产品，而是情报分析过程本身。换言之，本书关注的不是认知结果，而是认知过程，强调元认知的重要性。霍耶尔在书中提出无论是情报分析人员自己，还是情报工作的管理者，乃至情报用户，都要认识到情报分析过程中人的认知过程，而不能仅仅关注情报分析工作的组织、分析与搜集工作的衔接、情报产品的撰写等。

第二，本书提出了从认知心理学的视角来认识情报分析过程。与之前情报分析方面的理论著作相比，特别是与谢尔曼·肯特的《战略情报：为美国世界政策服务》一书所代表的「历史经验主义」流派相比，本书吸收了 20 世纪社会科学中的认知心理学、证伪主义等新式研究方法，强调研究人的内部心理过程，突出人在整个认知过程中的作用。本书所提出的一些观点，如认为完全客观和中立的情报分析不可能实现、通过证伪而不是证实来检验假设、思维的简化倾向决定了分析中偏见的产生，等等，是情报分析研究的突破与创新，是推动情报分析思维走向批判性思维的基础。

第三，本书提出了许多切实可行的实践工作方法。霍耶尔本人丰富的情报工作实践和长期的情报研究生涯，使他对于理论与实践的结合十分重视。本书的许多章节在撰写时就是为了提高某一方面的工作实效为目标的，因此，它提出了许多可用于提高分析工作水平的切实方法。本书第八章中介绍的「竞争性假设分析法」，是霍耶尔提出的一个最为重 236 情报分析心理学

要的分析实用方法。此外，书中提及的「魔鬼代言人」正是后来分析工作实践中的「B 队」方法的起源；书中强调在检验证据时，要重视证据的「诊断价值」，这实际上正是对情报分析中证据评估工作提出的基本方法指针；书中依据人在思维时认知形成很快，但印象难以消除的规律，提出了区分提出观点与评估观点阶段、尽量延迟做出结论的方法，等等。正因为贴近工作实际，本书才长期被作为中央情报局的培训教材。除了涉及情报分析过程外，本书还提出了许多建议，如培育和形成有利于分析的工作环境、重视对情报用户的教育以强化他们对情报分析工作的正确认识等等，对于改进整个情报分析工作都是有益的。

本书的独特视角、细致论述、系统性和实用性，使它在情报分析理论研究中独树一帜，奠定了开拓创新的基础。而本书的影响力也已经超出了情报界，在美国，许多商业竞争培训也把本书列为分析竞争环境、竞争对手的必读教材。情报学与心理学完美结合的经典作品

美国国家安全从业人员指定培训读物

Psychology of

Intelligence Analysis

本书重要特点一：它重点研究的不是情报分析结果，而是情报分析过程本身。作者提出，无论是情报分析人员自己，还是情报工作的管理者，乃至情报用户，都应重视情报分析过程中人的认知规律。

本书重要特点二：它从认知心理学的视角来认识情报分析过程。与历史经验主义流派相比，作者借鉴了心理学的一些研究方法，强调研究人的内部心理过程，突出人在整个认知过程中的作用。

本书重要特点三：它介绍了许多切实可行的实践工作方法。凭借丰富的情报理论与实践经验，作者提出了许多可改进分析水平的实用方法，如「竞争性假设分析法＂「魔鬼代言人」「情报分析的结构化方法」，等等。
