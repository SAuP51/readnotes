10 似易实难

Deceptively Simple

「人工智能还能做哪些事来帮助别人？」母亲在病床上的问题，让我开启了医疗服务的环境智能研究。另外，我开始思考「人工智能伦理」的议题。

2013 年夏天的一个下午，我和西尔维奥正在参加朋友女儿的成人礼。庄严的仪式结束了，接着是一场招待派对，西尔维奥想拉着我一起跳舞。音乐刚刚响起，我的手机就震动了起来，真是天助我也 —— 我一向不喜欢在公共场合跳舞。我对西尔维奥做了个手势，说我得去接个电话（他肯定觉得这个借口太方便了），然后躲到了外面。

「喂，爸爸，怎么了？」

还没等他具体说原因，我就从他的语气中听出了问题。

「我觉得你妈妈发烧了。她一直呼吸困难，还说胸口疼。你在哪儿呢？我该怎么办？」

我猛吸了一口气，心骤然沉了下去。这样的情形我已经再熟悉不过，但每次遇到，依然会感受到巨大的恐慌。母亲的身体又出问题了。

二十多年来，我们全家经历了太多次深夜惊魂和死里逃生，次数多到我都记不清了。我们在急诊室、重症监护室、手术室候诊室，还有医院的其他地方度过了生命中的一个又一个章节。母亲十几岁时就因严重的风湿热引发了心脏病，此后的几十年一直没有采取干预措施，任由病情发展。心脏问题是影响母亲身体健康的罪魁祸首，就像多米诺骨牌一样，引发了各种问题，从药物副作用到我们侥幸及时发现的几乎致命的脑出血。我和母亲一起，费尽周折地辗转于各种保险机构，寻找各种经济援助方案，甚至在美国当地治疗方案枯竭的情况下，我们还回了趟中国。一路走来，我的角色从十几岁时的中英文翻译演变成了类似非官方的个案工作者，寻求专家，安排会诊和治疗，监测症状，监督药物治疗和康复计划，但这些似乎都无法让病情稳定太久。无论以何种实际的标准衡量，照顾母亲的健康都已经成了我的第二职业。

虽然严重的威胁接二连三到来，但母亲独特的坚韧始终没有改变。对我而言，每一场新的冲击都始终伴我左右，并没有随着时间的流逝而减弱，反而成为我生活中固定的基本元素。我的潜意识里一直在等待下一个坏消息，而任何坏消息都可能是最后一个。每当手机屏幕上显示出母亲的名字，我就感到自己的胃在下沉。无论生活把我带向何方，我都觉得自己永远处于一种脆弱的状态。

又经历了两天旋风般的就诊，最近一次磨难终于告一段落。发烧导致心跳波动加剧，可能是流感所致。虽然症状严重，但好在没有危及生命。我瘫坐在病房角落的塑料座椅上，本能地打开笔记本电脑。有那么几分钟的时间，我敲击键盘，全情投入工作。在这样的时刻，热爱自己工作的价值难以言表。但我忽然感觉有点儿不对劲，周身仿佛有一种刺痛感。

是有人在盯着我看吗？

我从电脑屏幕上方瞥过去，发现母亲已经醒了。她的确在注视着我。

「你怎么样了？」我问道。

我看得出她心里有事，但我知道，她并不是在考虑自己的健康问题。

她又思考了片刻，说：「飞飞，你到底是做什么的？」

母亲的这个问题实在太奇怪，我不由得放声笑起来。

「什么？」我一边笑，一边努力认真回应，「你问我是做什么的，你是说靠什么赚钱吗？」

「我知道你是科学家，研究大脑还是电脑的，但这么多年，我们都没有讨论过你是哪种科学家。你爸爸说你是‘疯狂科学家'，但我敢肯定，不完全是这样。」

平日里一向严肃的母亲竟然开起了玩笑，也许我应该叫护士过来 —— 毕竟护士叮嘱过我，如果出现任何异常情况，就要立即呼叫她。

「没错，我不完全是疯狂科学家。」我笑着说，想了想她的问题。

笑归笑，但她说得没错。这么多年来，我一直把她当病人看待，习惯了把工作上的事情压在心底，很少与她交流。现在我想，我是否忽略了她的其他方面。即使穿着病号服、输着液，母亲仍然是那个善于思考的「教唆者」。于是，我打开了话匣子，从头开始讲起。思维的奥秘，物体分类在视觉理解中的重要性，ImageNet，图形处理器，神经网络的爆炸式发展，视觉研究领域突然瞬息万变。母亲侧耳倾听，看似认真，却带着像母亲逗弄咿呀学语的孩子般的神情。感觉有点儿不对劲。

「我听不太懂。」她停顿了一下说，「听着像科幻小说。」

我不应该感到惊讶。她很聪明，知道我在说什么，但她对科学本身从来不感兴趣。她喜欢从故事和人物的角度思考，喜欢激情和冲突。我决定即兴发挥。

「你知道，还有一两个小时，我们就能出院了，但你还需要几天的恢复时间。要是没有我、爸爸、西尔维奥或是其他人的陪同，你就没办法外出办事。但是，如果不靠我们，你自己也能出门，你觉得怎么样？」

「你是说坐公交车吗？」

「不是。就算是往返公交车站对你来说也会有些困难。我说的是有一辆能自动替你驾驶的车，从家门口接你，送你到达目的地，这一切都由它来完成。」

自动驾驶汽车领域的炫酷品牌 Waymo 和 Cruise 等还有几年的时间才会出现，但自从自动驾驶领域的先驱塞巴斯蒂安·特龙离开我们的团队，将他的专业知识带到谷歌，我就一直在思考这种汽车。越来越多的媒体关注也增强了我的兴趣。塞巴斯蒂安的项目令人印象深刻，他对一辆名为「斯坦利」的大众途锐进行了重度改装，使之成为历史上第一辆成功完成美国国防部高级研究计划局年度沙漠竞赛的纯自动驾驶汽车。尽管如此，我也没想过很快就能在路上看到完全自动驾驶的汽车。在现实世界中，驾驶要复杂得多，我认为短期内几乎无法实现。不过，我可以利用这个话题，让晦涩的理论变得更加通俗易懂。

「嗯。」她说，语气变得轻松起来，「对我这样的人来说，生活肯定会大不一样。」

接着，她又沉默了几秒钟，问了一个看似简单的问题。

「飞飞，人工智能还能做哪些事来帮助别人呢？」

我相信，从看到比德曼的数字的那一刻起，我就成了一名科学家，在这个数字的启发之下，我开启了职业旅程。母亲在病床上的问题好像只是随口一问，但每次回想起来，我对这个问题都会充满类似的崇敬之情，因为她的提问给了我机会，让我成为一名人本主义者。这是我追寻的新目标，其动机远不止满足好奇心。我无法预测这条路究竟会通向何方，但我在医院里度过了太多的岁月，答案的蛛丝马迹已经在眼前隐约可见。

现在，我第一次想把我对人工智能的毕生热爱与长期照顾他人的痛苦特权结合起来。人工智能在医院里能做什么？我们创造了能够以人类无法企及的方式观察世界的镜头，将谷歌街景变成了社会学研究。而在医疗领域，人工智能会向我们展示什么？我们设计算法，把图像变成故事，将像素转化为语言和意义。我不禁想问，在医院这个我们度过了如此多时光的地方，是不是有最需要被讲述的故事？

阿尼·米尔斯坦（Arnie Milstein）博士是医疗领域的传奇人物。他是斯坦福大学医学院教授，长期担任行业顾问，曾是临床医生，是专家中的专家。我们见面的时候，他已经将职业重心转向改善医院的医疗服务方式，如流程质量、治疗效果和患者体验等，同时降低医院的运营成本。他的头发近乎全白，彰显深厚的阅历，但他没有架子，精力充沛，总是带着微笑和天然的友善。

我和母亲在病房里讨论人工智能以来的几个月里，我一直在思考如何把人工智能与病人护理结合起来。只要有机会，我就和同事聊天，不管他们来自哪个系。我在所到之处播撒了对话的种子，其中一颗终于生根发芽 —— 一个熟人介绍我认识了阿尼。虽然刚开始交流时，我们都感到双方的领域差异悬殊，很难理解对方的研究内容，但又都感到了一种亲切感。我们都不知道等待我们的将会是什么样的合作，但我们都确信未来一定会有合作。为了启动进程，他邀请我和他一起参加在旧金山北边举行的一个闭门演示活动，了解飞利浦公司正在开发的远程医院监控技术。

在演示室里，一排护士站在装有大型平板显示器的工作站前，飞利浦公司的代表走到演示室中央：「非常感谢大家的到来。你们即将看到的是我们的 eICU 技术演示。eICU 是用于重症监护病房的远程监控解决方案，虽然目前还处于概念验证阶段，但我们已经开始在一些医院进行试点。」

我意识到，屏幕上显示的是重症监护病房病人的实时画面，视频上显示了病人生命体征的多个维度，护士可以随时在显示器前观察。一旦发现危险或异常情况，她们可以通过按钮面板立即通知现场人员。

「没有人愿意面对医疗护理中的失误，但这些失误对病人构成了持续的威胁。感染、手术工具放错位置、药物混淆、剂量错误，甚至是老年患者摔倒这样简单的事故，都会造成严重的后果。类似的错误不胜枚举。」

太可怕了。下次我在候诊室里等待的时候，更会忍不住胡思乱想了。

「可悲的是，这些失误每年造成美国约 10 万起死亡事故，其中大部分是完全可以避免的。」

等等，什么？我的大脑突然一片混乱。每年 10 万人死亡？都是失误造成的？

「有一种特别危险的错误就是病人在重症监护室中长时间无人看护。eICU 是防止这种错误的第一步，它使得规模更大、地理分布更广的团队可以更密切地关注医院里最脆弱的群体。」

这是个好主意，但我无法不去想刚刚听到的数字。

10 万。这个数字在我脑海中不断重复闪现。

「飞飞，这就是我所说的医疗保健‘黑暗角落'的一个例子。」阿尼凑过来低声说道，「不管是在医院、老年护理机构、手术室还是其他地方，都会有病人逃过临床医生的关注。」

我想起了躺在病床上的母亲，想起了我每晚刚进家门的例行事务，我担心会不会发现什么迹象，表明我不在的时候她的病情恶化了。

阿尼继续说：「这是我们努力解决长期存在的一个问题。在医疗行业，几乎每个人都超负荷工作，大家都精疲力竭了。在某种程度上，过去几十年来为他们打造的所有技术都是在帮倒忙，因为现在他们也被信息淹没了。这是一个危险的组合，太多病人因此错过了最佳治疗时机。」

演示非常完美，让人印象深刻，但在演示结束后很长一段时间，我的焦虑感依然挥之不去。

电梯门关上时，我说：「我脑子里就是忘不了那个数字。」

「每年 10 万人死亡吗？」阿尼回应道，「在过去的一二十年里，这个数字一直是激励我工作的最大动力。」

为一个具体数字无限痴迷 —— 阿尼和我的共同点比我想象的要多。

「我有个问题要问你。」他继续说，「想象一下，在任何医院、养老院，甚至是家庭护理项目中，当护理人员查房时，他们想要达成什么目标？」

我想起了在我母亲住院期间查房的医生和护士，他们中的许多人似乎只是检查了一两分钟，就匆匆赶往下一个任务。

「要跟病人有面对面的时间？要注意自己的临床态度？」

「这些当然要有，但想得再简单些。」

「我不知道，难道只是过来看看？」

「你说对了。他们在尽最大努力关注到每一位需要照顾的病人。但即使他们夜以继日地工作，真正面对每个病人的时间又有多长呢？病人的大部分时间都是无人监控的，这一点难以避免。」

「是事故都发生在没有人监控的时候吗？」我问道，「这就是每年有 10 万人白白死亡的原因吗？」

我停顿了片刻，试图理清头绪：「听起来，这些事故有一个共同点，那就是注意力。察觉。」

「没错，察觉就是关键所在。在整个医疗领域，察觉是最宝贵的资源，也是我们没有办法扩展的资源。」

我感觉自己仿佛又回到了红门咖啡馆，与彼得罗和克里斯托夫一起思考视觉体验。我想到了索普的脑电图读数、比德曼的摄影实验，还有坎维舍绘制大脑皮质解剖图的尝试。但我想的最多的还是特雷斯曼，还有她研究的核心观点：场景越混乱，理解场景所需的时间就越长。这个观点发人深思：在医疗行业，医生疲惫不堪，匆匆经过洗手台却没有认真洗手；护士分身乏术，没有注意到虚弱的病人马上就要跌倒。我的很多研究都围绕着感知的本质：感知从何而来？有什么作用？有什么潜力？而直到遇到阿尼，我才开始真正意识到感知的巨大价值。

「不好意思，」我停了一会儿说，「这些数字让我有点儿震惊了。」

演示会几周后，我去了阿尼的办公室，继续我们的讨论。我们翻阅了《人无完人》（To Err Is Human）。这本书出版于 2000 年，对医院环境中的医疗差错进行了全面调查，其中揭示的真相令人深感不安。作者得出的结论是，每年因规程和注意力方面的失误而导致的死亡人数超过了因车祸、乳腺癌和艾滋病这些众所周知的原因而逝去的生命数量。

「是的，需要花一些时间来理解和消化。」

不过，这是必要的练习。自从看完 eICU 的演示后，我们的谈话就没有停止过，兴奋之情也与日俱增，因为我们决定开展一个小型研究项目。这是我们第一次正式开会讨论计划。

「我建议我们从这个开始。」阿尼说着，用食指指向靠近页面底部的一个段落。

根据美国疾病预防控制中心的说法，「洗手是预防感染传播的最重要手段」，即便在今天也依旧如此。然而，反复的研究表明，在经历了 150 多年的发展之后，不洗手或洗手方法不当仍然是造成医疗环境中疾病传播的重要因素。

洗手问题可能听起来稀松平常，但相关问题仍然是医疗服务面对的严峻挑战。据美国疾病预防与控制中心估计，护理人员在每天巡查的过程中需要洗上百次手，每换一个病人、换一项任务，都需要洗手。鉴于人为错误的频率和性质，即使在最好的情况下，偶尔出错也在所难免。但随着轮班时间越来越久，压力和疲劳会不断加重，因而导致风险大大增加。最终，一部分错误会导致感染（正式名称是「医院获得性感染」），给患者带来巨大的痛苦，其程度难以想象。

这个可怕的话题非常适合作为我们研究的起点。在开展医学研究时，如果涉及正在接受治疗的病人，会导致一些棘手的复杂问题。而通过将注意力集中在护理人员（而不是病人）的行为上，就可以避免相关问题。据阿尼介绍，斯坦福医院的管理层对洗手问题已经研究了一段时间，不少人对新颖的解决方案翘首以盼。

我很快就了解到，阿尼是那种使命必达的人。我们结束谈话后，感觉刚过了一两个小时，他就给我发来了消息，告知我最新进展，而这些进展本身就让人感觉是不小的成就：打电话找人帮忙，安排与决策者的会面，确保医院配合研究，等等。在我自己的研究中，我越来越喜欢做规划，因为合理规划可以为新实验奠定基础，让我产生一种自豪感。但这是他的研究领域，不是我的，他打了下响指，一切就安排就绪了，我不禁惊叹不已。

不知不觉中，阿尼成为继彼得罗和克里斯托夫之后我的又一位导师，他们都有共同的特点，就是在寻求解决方案时，可以跨越学科之间的界限。随着项目的技术层面逐渐成形，我很快也可以做出自己的贡献了，我非常期待。不过，就目前而言，我很满足于跟随一位老手的脚步。再次做学生的感觉真好。

就在阿尼施展魔法的同时，我们也开始意识到挑战的艰巨性。最初，我们的目标是开发一种自动化技术，来确保护理人员在医院内始终如一地彻底洗手。虽然图像分类技术已经成为计算机视觉领域的象征，但医院项目对技术的要求比图像分类更高，甚至比我和安德烈一起完成的图片说明技术要求还要高。这一次，我们的解决方案必须能够识别特定类型的动作，也就是说，不仅要识别某种物体的存在，还要确定物体的移动方式和动作类别，而且识别准确性需要满足临床要求。

棘手的问题比比皆是。首先，「正确」洗手的分类到底是什么？「正确」洗手肯定不仅仅是确定临床医生在洗手台附近。要确定是不是把手洗干净了，算法需要识别洗手过程中的每一个步骤：靠近洗手池、打开水龙头、使用肥皂、两只手在水龙头下搓揉、长时间冲洗双手等。无论从哪个层面看，这都是我遇到过的最复杂的感知任务。

值得庆幸的是，我们的项目可以找到先例。我的实验室一直在攻克类似系统所需的诸多基础功能。例如，安德烈曾与谷歌合作开展研究项目，旨在识别体育录像中的场景，比如棒球击球手挥棒击球，或者篮球运动员运球等。这项分类任务在很大程度上依赖于对动作和行为的识别。我的另一位学生胡安·卡洛斯·尼布尔斯（Juan Carlos Niebles）的整篇博士论文的主题就是识别视频中的人类活动。他现在是哥伦比亚北方大学的教授，不久前刚和自己的学生们打造了一个名为 ActivityNet 的数据集。顾名思义，ActivityNet 就是类似于 ImageNet 的动作识别数据集，其中包含了数万个视频短片，每个短片都标注了它们所描绘的身体动作，比如走路、跑步、跳舞、演奏乐器等等。换句话说，尽管我们对于准确分析视频的设想尚未完全实现，但也并非不可能实现：这正是研究的最佳切入点。

我需要一批研究助理，于是像往常一样，给系里的研究生们发了邮件。ImageNet 等项目让我养成了保持适度期望的习惯，这次也不例外。收到的回复虽然不多，但数量也算可观。于是我制作了幻灯片来解释我们的想法，并安排了第一轮面试。与此同时，我们的项目还需要一个正式的名称。我和阿尼设想了一种旨在用智能且可靠的感知来填充空间的技术，而其最大的特点就是不会引人注目。与人类监察员不同，我们的技术将悄然融入背景之中，默默监视，只有在察觉到危险时才会发出警报。我们将其称为「环境智能」（ambient intelligence）。

「这就是我们的计划，医疗服务的环境智能。」我总结道，「有什么要问的吗？」

我只有一位听众，就坐在我办公室的红色沙发上。他是个特别聪明的双学位学生，同时在修读计算机科学和统计学。他正处于攻读博士学位的第二年，正好在寻找一个更稳定的地方来完成他剩余的研究。然而，气氛并不像我希望的那样轻松。之前三位面试者都决定不加入我们的团队，因此他成了我们的第四位面试者。我尽力掩饰我们士气低落的事实。

「我的意思是，听起来超级有趣。」他回答道，语气足够真诚。这已经是连续第四个候选人表示我们的设想「超级有趣」—— 我选择忽略这一事实。

「不过，我想知道的是，我还能不能在常规渠道发布成果，比如 NeurIPS [注：NeurIPS 全称「神经信息处理系统大会」（Conference on Neural Information Processing Systems），是机器学习和计算神经科学领域的顶级国际会议。—— 译者注] 和 CVPR 之类的。」

「当然。」我笑着说，「我们正在探索许多尚未解决的问题。」

确实如此。虽然医院并非我们惯常的研究场所，但其中涉及的计算机视觉技术绝对是最先进的。我们正在推进前沿技术的发展，需要识别人类活动，而非静态物体，这已经是精细的实验性技术。此外，我们的算法还将面临额外的压力，需要识别异常细微的动作，对准确性的要求很高。与此同时，我们也计划将物体识别提升到新的水平，因为我们的分类器将不得不应对密集的运动、混杂的背景和模糊的情况。相关工作会异常艰苦，但同时也是建立名望的好机会。

「坦率地说，我们希望能在临床上产生真正的影响。这意味着我们也要与临床工作者合作，向临床期刊投稿，而不仅仅是计算机科学领域的期刊。」

这个学生考虑了一下。「明白。但是，这类期刊的出版周期是多长？」

这是个好问题，因为学术生涯在很大程度上取决于论文发表，尤其是在最初几年。在他看来，医学期刊缓慢的出版安排就像一个锚，会在他需要冲刺时拖慢速度。他的担心不无道理。如果他发表论文的频率能达到同行的一半，就已经很幸运了。我一边回答，一边在心里暗叫不好。

「老实说，我自己还没发表过。但我的搭档米尔斯坦博士说，一般需要一两年的时间。」

他睁大了双眼，又停顿了片刻。

「这…… 比我预期的时间要长很多。我是说，发计算机科学论文通常只需要几个月。」

他说的都是显而易见的事情，但他是对的。我没有太多可以补充的。

「李教授，我还有最后一个问题。」他双手抱臂，开始提问，「我知道你花了多长时间构建 ImageNet，也清楚它对计算机视觉的重要性。对于这个，呃，环境智能的想法，我们会有类似的数据集作为支撑吗？」

我叹了口气，可能声音有点儿太大了。

答案是否定的。又一个「没有」。没有数据集。没有已知文献作为我们观点的基础。没有研究类似问题的实验室可以合作。最后，这位候选人的回复虽然礼貌，但也是否定的。

几个月过去了，我们连一个合作者都没找到，我夜不能寐。我正站在职业生涯最有意义的一个篇章边缘，有机会接受母亲的启示，真正利用人工智能为社会做些贡献。但如果没有帮助，我们将一无所获。我想起了 ImageNet 早期的孤独岁月。与现在相比，连那样的日子都显得云淡风轻了许多。

然而，今天我有了分心的奢侈机会。也许是觉察到我需要一些外力来保持头脑清醒，阿尼派我去参加一项实地考察。

「你确定这样没问题吗？」我一边调整口罩，一边问道。我一生中大部分时间都被穿着手术服的人包围着，今天是第一次自己穿上了手术服。

「当然没问题，我们经常这么干。护士、医学院的学生、实习毕业生，什么人都有。别担心，你很快就会融入。」

阿尼安排我跟随露西尔·帕卡德儿童医院的儿科医生特里·普拉切克（Terry Platchek），这样我就能观察到医生在医院轮班期间保持手部卫生的实际情况。但我想看到一切：病人、护士，所有的一切，他们的全部经历。我知道他们的世界是混乱的，我想以他们的视角来看待这一切。

我不知道自己即将面对什么。

普通病房充满了圣诞节的气氛，我简直不敢相信这里有这么多孩子。每个孩子都有自己的经历，每个都令人心碎。有些获得好消息，有些则碰上坏消息，而大多数都只是漫长而又让人麻木的治疗旅程中的又一步。有些家长问我是谁，为什么会在那里。但大多数人似乎都没有多想，因为他们只想知道自己所爱的人正在经历什么，他们已经习惯了不同的医护人员像走马灯一样地变换。

我本该记录一些机械且容易量化的东西，但我无法将视线从医护人员身上挪开；我很快就意识到，这些人才真实地展示了什么是人性化护理行为。一个好医生是信息的总汇、力量的源泉，有时甚至是病人及其家属在痛苦时刻的精神支柱。多年照顾母亲的经历让我自信对医疗领域了如指掌，但与普拉切克医生的相处彻底颠覆了这种观点。我开始确信，无论多么先进的技术，都无法取代我那天所看到的一切。

尽管如此，我认识到在某些决定性时刻，我们也非常需要新的辅助工具。我遇到了一位资深护士，她的一个病人最近摔倒了。这是她职业生涯中第一次出现这种情况，她惊讶地发现，这件事对她的影响极大。从统计学层面看，对她来说，在自己的监护下有病人受伤是不可避免的，毕竟她已经做了几十年护士。但当这一时刻终于到来时，她整个职业生涯的杰出表现并没有能帮助她缓解情绪。她的情绪非常崩溃，就像第一天上班的护士一样。无论是她，还是那位病人，都受到了严重的伤害。如果人工智能能帮助避免这种情况，那么一切努力都是值得的。

这一天对体力要求很高，轮班结束时，我已经筋疲力尽，但更疲惫的是我的精神。仿佛我重温了和母亲共同面对的每一刻，只是这一次以小时为单位不断循环播放。我茫然地与普拉切克医生握手寒暄，准备离开。但在往外走的时候，我突然想到了什么。

「特里，我很好奇，是什么让你如此愿意让我进入你的世界？老实说，我算是个局外人。」

他沉思片刻才给出答案：「你知道，最近有很多关于人工智能的新闻，老实说，大部分我都不喜欢。」

我笑了，也许带着一丝嘲讽。我知道他接下来要说什么。

「当然，如果我每天有更多工作可以被自动化，那就太好了。我明白。」他继续说，「但我有点儿厌倦科技高管们成天说的都是让我这样的人失业。只有你和阿尼似乎真正想帮助我，而不是取代我。」

我稍作思考，然后回答道：「我知道我们聊过我的母亲，还有这么多年照顾她的健康问题对我产生的影响，但这个故事还有另一面。在医院度过了那么多时间，对我而言是有好处的。」

「有什么好处呢？」

「有一种特别的东西…… 我不知道，也许可以叫作‘关怀之举'，无论是护士帮助我母亲坐起来，还是专家制定治疗策略，都感觉很特别，充满了人文关怀。这也许是我们所能做的最人性化的事情。我无法想象人工智能来取代它，我甚至不希望人工智能取代这一点。今天，科技在维持我们的生命方面发挥着重要的作用，我很感激，但毫不夸张地说，我和母亲能熬过这一切，真正的原因是人，是像你们这样的人。」

轮班还没结束，太阳已经落山。从医院出来，傍晚时分清新的空气迎面而来。相对宁静的环境让我的思绪得以舒展，全天的记忆带着沉闷的刺痛感重现。虽然我目睹了病人和家属的悲惨境遇，感到心绪不佳，但阿尼是对的，这正是我所需要的。这是计算机科学学位无法提供的教育场景：病房里的喧嚣、不确定的恳求眼神、对任何形式安慰的迫切渴望，酸痛的脚和破旧的网球鞋，休息室里冷冰冰的比萨，一小时又一小时的煎熬。

阿尼知道，虽然我在母亲身边照顾了多年，但我仍然无法真正理解临床医生的感受，所以他邀请我亲自去体验一下。

在回家的路上，我突然有了一个奇怪的想法：我很庆幸我们还没有招收任何学生助手，否则，我早已用计算机科学家的阅读清单把他们淹没，使他们习惯于从数据、神经网络和最新架构进展的角度来思考。这当然很重要 —— 在这样的项目中，科学问题是无法回避的。但我现在明白，科学并不是正确的起点。如果想让人工智能帮助人类，那么我们必须从人类自身开始思考。

我随即做出决定。从那天起，任何要加入我们团队的学生，都必须先拥有我刚刚拥有的体验，否则一行代码都不可以写。跟班学习将成为每位新成员的入门仪式，没有商量的余地。

幸运之神的眷顾加上我在医院的经历所产生的激励作用，使得工作进展迅速，我们的愿景得以延续。我和阿尼花了近两年时间，付出了比以往更多的耐心，终于组建了一支规模适宜的团队，开始了我们的工作。很明显，环境智能在一段时间内仍将是一个小众的研究领域，因为对人工智能专业知识的需求太旺盛了，竞争机会也非常诱人。但我们招募的人员素质表明，我们正在从事一项有意义的事业。毫无疑问，这是我参加过的专业能力最多元化的团队。

在我们的第一批新成员中，有计算机科学的一年级研究生、电子工程的博士生，还有研究机器人对人类活动和社交导航感知的博士后。随后，针对我招募的团队，阿尼也挑选了一批年轻医生，有医院的儿科医生、老年病医学专家，还有重症监护专家。最重要的是，我们从一开始就达成了共识，主导权不属于团队中的任何一方；阿尼和他的同事需要我们的经验来构建技术，而我们也需要他们的经验来确保技术的正确性，以确保技术不仅有效，而且尊重使用者、体现人道主义精神。

阿尼将他最令人叹服的壮举留到了最后：说服医疗机构让我们在他们的场所进行实际的技术演示。我们首先选择了两家不同的医院，一家位于帕洛阿尔托，另一家位于犹他州。我们的目标是发现手部卫生方面的疏忽，确保不会因为手部卫生而造成患者感染。接下来，我们选择了湾区的一家养老院，目标是通过跟踪老人们全天的身体活动来协助护理人员。最后，我们在斯坦福医院的重症监护室部署了一套系统，当康复患者长时间不动时，系统就会向护理人员发出警报。

然而挑战依然存在，就连阿尼的锦囊里也没有妙计了，那就是数据问题。我在这个项目之前的几年深刻认识到，若要有效地训练像我们这样的模型，数据绝对是必需品，这是毫无疑问的。我们需要大量真实、有机且尽可能多样化的数据。

但在医疗领域，我们所需的数据在本质上就是稀缺的。出于法律责任和基本隐私等显而易见的原因，患者和临床医生的行为很少被影像记录下来，而对于我们希望检测的事件（其中许多事件从一开始就是异常情况，比如跌倒），相关的清晰影像更是少之又少。这使得我们的工作比我最初想象的还要复杂。在训练模型之前，我们必须亲自收集必要的数据。

尽管如此，我们的研究势头依然如日方升。新的实验，新的假设。我们撸起袖子，使用新硬件和新软件。正如我所料，这是我的实验室尝试过的对科学技术要求最高的项目。但真正让我们豪情满怀的，却是任务本身。我们所做的一切都充满了意义，它让我成年后一直从事的职业变得如同一个全新的世界。我一直努力将私人生活与科学家的职业生涯区分开来，但现在的一切冲破了堤坝，冲刷着沿途的一切。早该如此了。

「快叫护士，」母亲恳求道，她发出微弱的呻吟声，声音小得几乎听不到，「点滴…… 又痒了。他们扎针的那个地方。」我们又回到了医院，这次是做心脏成像。这么多年来，母亲已经做了很多次心脏成像，每次就医的紧张感都比上一次更加强烈。我赶紧按铃求助。

今晚的护理人员是来自加利福尼亚中部的旅行护士曼迪。她年轻、乐观，还在努力考资格证书，争取更加稳定的职位。从她进入房间的那一刻起，我就知道我会喜欢她。

「不好意思，」我说，「我知道还没几个小时，我们都叫你三次了。」

「没关系的。」她坚持说，虽然眼神疲惫，但依然笑容满面。她有一种难以伪装的温暖。「哎哟，真是可怜！」她说着，把注意力转向母亲，全身散发着善意，「看来我们又得冲管了。我知道今晚不好过。」

这一幕我已经见过无数次了，但今天，我有了一种特别的感触。也许是因为我从曼迪的举止中看到了一丝纯真，也许是因为最近的研究让我们都成了日常护理专家。我感到喉咙有些发紧，这是我在病房里待了这么多年从未感受过的。同情、敬畏、感激，还有其他一些难以形容的复杂情绪。曼迪的出现，她这种改变他人生活的简单而真挚的关怀之举，让我感到格外温暖。我的泪水在眼眶里打转。

在以往的这种时刻，我的注意力通常都集中在母亲身上，但我们在做的研究彻底改变了我的想法。护士平均每班要走 6000 ～ 8000 米，需要完成 180 多项不同的任务，虽然疲劳的隐患有据可查，但轮班时长却在不断增加，目前平均长达 12 小时。我知道曼迪在来我们病房之前去过哪里，也知道她见过多少其他面孔，我知道她可能已经疲惫不堪，但她还是毫不吝啬地传递善意，微笑着完成了所有任务。

如果我的研究确实能帮到别人，那么像曼迪这样的护士就是我的首选。我无法想象还有什么人比她们更值得帮助。

第二天，上早班的是一位新护士苏珊。「你在这里工作吗？」她问道。

我低头看了看自己佩戴的斯坦福医学院徽章。我跟阿尼一起工作时，经常佩戴着它，这会儿忘了摘下来。

「哦，这个？」我笑着说，「不是，实际上我正在参与一个研究项目。」

「什么样的研究？」她问。

「我是计算机科学系的，我和我的学生正在合作开展利用人工智能追踪手部卫生的项目。」

她的笑容淡了一些，看起来礼貌多于友好。「那么，是有摄像头在监视我们吗？」

「不，不，不！当然不是！」这已经不是我第一次被问到这个问题了，但我每次还是会感到一阵尴尬，「更像是一个传感器，不是摄像头。没有录像。它为我们的算法分析提供了图像。算法正在学习观察不同的洗手模式。我们还在起步阶段，就是想搞清楚算法是不是能够胜任这项任务。但我保证，没人在监视你！」

我尽力保持轻松的口吻。我说的一切当然都是真的，但我也不能怪她把事情往最坏的方向想。

「好吧，那听起来还可以。」她松了口气。「你知道，」她压低声音继续说，「你们这些不叫摄像头的东西应该盯紧医生。」苏珊和曼迪一样善良，但她身上有一种犀利的感觉，她的脸上掠过一丝苦笑，「他们的卫生习惯是最糟糕的。但管理层不管他们，只会对我们护士大吼大叫。」

「老板监视器」。

更委婉的说法是「员工监控系统」。这种新型软件如雨后春笋般涌现，被广泛用于仓库和办公室等场所。许多人认为这种审查会侵犯人的隐私，甚至是不人道的。虽然软件的市场定位是提高工作效率和保护职业行为，但几乎立即遭到了劳动者的反感，也很快成为科技媒体反复报道的话题。现在，我们甚至还没有机会证明自己，研究工作就有可能被反乌托邦的联想所吞噬。我们的技术是为了病人的安全，而不是为了绩效考核，把我们的软件与监视器混为一谈起初让人觉得不公平。然而，这种担忧是可以理解的，而且事后看来，审查和监视之间的关联确实显而易见。这是我第一次接触到人工智能会在公众想象中引发恐慌的一种能力：监控能力。

回想往事，我们很容易忘记变化有多么突然。那是 2015 年，人工智能对隐私的影响仍是大多数人关注的焦点，毕竟就在短短几年前，图像分类的准确性才开始接近实用的阈值。现在，像我们这样的研究人员眨眼间就掌握了如此强大的能力，技术挑战已经让位于伦理挑战。我们在医疗领域的探索则将这一切带回了我们的实验室。

「没有人想安装老板监视器。」一位学生抱怨道。

团队刚从露西尔·帕卡德儿童医院悻悻而归，他们本想在那里完成推进试点研究的最后工作，却出乎意料地遭遇了失败。

我们的计划是安装一批传感器原型，但我们请来参与实验的各科室护士都无一例外地拒绝配合。项目严重受挫，但在与苏珊交谈之后，我早已有了心理准备。

这件事提醒我们，即使是一个明确的多学科团队，也可能存在盲点。虽然我们的临床医生知识渊博，但他们更像研究人员，而不是一线的护理人员，这种区别产生了决定性影响。简而言之，我们积累了深厚的医疗专业知识，但我们都不是护士。我和阿尼召开紧急会议，讨论我们的选择。

「我认为只有一条路可走，」一位医生建议道，「护士需要跟你们的研究人员见面。她们需要真正的沟通。」

「是的，当然。要让尽可能多的人参与进来。」另一位医生说，「需要倾听。了解他们的想法。」

第三个人附和道：「开个公开会怎么样？我可以帮忙组织。」

我心中感慨万分，感谢上帝，感谢你们每一个人。我无法想象如果没有阿尼和他的同事们，我们的研究该如何继续下去。

「我们在 IRB 相关的陈述上必须严谨。」阿尼严厉地说，「我们的合作伙伴需要得到保证，任何人的隐私都不会被泄露。一次也不行。大家都清楚了吗？」

IRB 即机构审查委员会（Institutional Review Board），是对类似我们的临床研究进行监管的机构。要达到他们的期望，确保研究获得批准，需要技巧和外交智慧，更不用说丰富的临床经验了。从我和克里斯托夫在加州理工学院进行的心理物理学研究开始，我对合规要求就已经习以为常，但对我大多数计算机科学的学生来说，这是一个全新的概念。这是真正的医学研究，涉及真实的个体，需要遵循一套全新的专业规范。

然而，我们都没预料到的是，我们的研究可能会超出 IRB 的范围。在听取学生们关于他们在医院访问的更多情况后，我们欣慰地得知，护士们并没有特别担心我们的研究本身；他们中的许多人已经了解我们，并且相信我们的动机，对我们的工作并没有异议。他们担心的是这项工作可能会导致的后果：这项技术将如何发展、供谁使用，以及它的影响范围将会如何扩大。他们的疑虑是敏锐的，同时也强调了一个事实：我们面临的挑战是如何评估人工智能的未来，而不仅仅是它的现在 —— 即使是 IRB 也没有考虑到这一点。

为了确保设备无可非议，我们规定，任何采集到的数据都不得传输到远程数据中心，或者上传到「云端」（这个术语刚刚开始被主流接受）。「云」已经成为热门词汇，几乎在任何情况下都能吸引媒体关注和风投资金，但对我们来说，它却是一种诅咒。相反，我们不得不追求另一种新兴趋势：边缘计算（edge computing），即把所有必要的计算资源都整合到设备中。这是我们的研究所需要的范式，但边缘计算本身就是独立的领域，我们对它的理解和把握还不够深入。

尽管面临巨大的工作挑战，但我们知道复杂性是不可避免的。相比之下，从互联网上批量下载图片像是一段无忧无虑的时光。我们现在需要搜集的可能是能想象到的最敏感的数据：以视频的形式捕捉人类群体真正的脆弱时刻。视频的保真度足以训练机器进行可靠的识别。而且，我们必须确保 —— 必须绝对确保 —— 从第一步开始就保护研究对象的安全和匿名，同时遵守 IRB 准则的高标准（这是我们从事相关研究工作所必备的常识和道德）以及《健康保险携带和责任法案》等法律框架。

我们的团队不断壮大。团队建立之初就很多元化，包括工程师、研究人员和医疗政策专家，很快又加入了临床医生、生物伦理学家和斯坦福大学法学院的法学博士。我们的技术合作伙伴也越来越多样化，包括传感器专家、网络安全专家等等，当然还有边缘计算专家。我们雄心勃勃，愿景宏大，尤其可喜的是，在我自己的实验室与阿尼的临床卓越研究中心（中心总部位于斯坦福大学，旨在提高医疗质量和可负担性）的通力合作和资助下，我们的项目落地了。

研究的前沿依然广阔无垠。虽然我们只回答了研究中的一小部分问题，但我们正在取得进展。最重要的是，我第一次认识到，如果将人工智能视为一门独立的学科，就会错失其最大的潜力。我们的研究表明，如果人工智能与其他领域相结合，并借助其他形式的专业知识进行推动，可能性就是无限的。

「妈妈，求你了。」

母亲最近又做了一次手术，手术结果虽好，但康复之路格外漫长。康复的关键是进行肺部锻炼，需要每天多次使用一种叫作诱导性肺量计的手持设备进行呼吸训练。她刚刚做完手术，很容易出现肺部感染，而且可能是致命的，而使用肺量计是简单有效的预防手段。

对经历过多次心脏衰竭和脑出血，又刚接受了开胸手术的人来说，这本该是一项简单的任务。然而，她拒绝了。当医生向她展示肺量计时，她假装按要求呼吸，但医生离开后，她就把肺量计放在一边。当护士来检查时，她又重复着这个戏码。当然，这一切我都看在眼里，但无论我怎么恳求，她都不愿意配合。

这根本就说不通。一连几天，我的焦虑与日俱增。我晓之以理，动之以情，但就是劝不动她。护士警告她时，她就点点头；医生责备她时，她就假装服从。但她的表演并没有改变现实：液体正在她的左肺中积聚，她必须再接受痛苦的肺积水引流手术。

最后，在重症监护室又住了几周后，她从第二次完全不必要的手术中恢复过来，这场折磨终于结束了，我们把她接回了家。疲惫不堪的我们回到后院，享受了很久以来第一个安静的下午。她不在的时候，我父亲一直忽略了花园的打理；她回来后，他如释重负，重新开始了自己的日常生活。

「妈妈，我想问你点儿事。」我不想破坏这份宁静，但内心的困惑让我无法释怀，「还记得医生们想让你用的那个小工具吗？那个肺量计？」

母亲纹丝不动，默不作声，但她的身体语言告诉我，她显然不想谈这件事 —— 人在静止状态下却能传达这么多信息，真是让人惊讶。

「妈妈，我就是想知道为什么。求你了，跟我说吧。」

过了一会儿，她终于开口说话了，但依然没有看我：「我不记得了，当时药劲很大，一切都很模糊。」

我知道这不是真的，但我没办法强迫她解释。我没有继续追问，只是享受和她在一起的时光。天气晴朗，栀子花盛开。

最后，她打破了沉默。

「你知道吗，飞飞，」她轻声说，终于看向了我，「当病人…… 太可怕了…… 太可怕了。不光是疼痛，还有失控。在那个房间里，我的身体，甚至我的思想都不属于我。房间里有那么多陌生人，我知道他们是医生和护士，但他们对我来说都是陌生人，而我却要听从他们的每一个命令…… 我受不了。」

我继续听着。

「就连你也命令我！」

我俩都笑了起来，气氛一下子轻松了许多。

「我知道你是想帮忙，」她补充道，「我知道你们都想帮我，我知道这些东西对我的健康很重要，但到了某一个临界点，我就没有办法再满足这些要求了。」

然后，她又想了一会儿，找到了背后的原因。「我一点儿尊严都没有了。彻底丧失了。在那样的时刻……」她似乎有些语无伦次。我正想鼓励她继续说下去，她就接着说完了：「甚至健康都不重要了。」

自从这个项目开展以来，我学到了很多东西。这些经验和教训缓慢地展开，常常伴随着痛苦。我开始从另一个角度看待母亲在健康方面的抗争，并对我们多年来依赖的护理人员产生了新的同理心。我对医院中人类脆弱的程度感到震惊，也为有机会为此做出一些贡献而备受鼓舞。但我学到的最深刻的一课是，个体的尊严是至高无上的 —— 这是任何数据集都无法解释、任何算法都无法优化的变量。面前这个人是我最熟悉、最在乎的人；在她脸上饱经风霜的纹路和疲惫的眼神之后，那种我长期以来熟悉的挣扎和脆弱，向我伸出手来。

两年多前，母亲只问了一句「人工智能还能做哪些事来帮助别人」，便让我的职业生涯走上了全新的道路。通过她的眼睛来看待我的领域，我的动力一下就增加了。这么多年来，推动我前进的一直是强烈的好奇心，而现在，我第一次将人工智能视为行善的工具，可以纾解像我这样的家庭每天所面临的困难。我第一次接触到了人工智能的伦理问题：对我们中的许多人来说，「人工智能伦理」是全新的议题，也会很快成为不可避免的现实。在熟悉的领域中度过职业生涯的一部分之后，我发现自己又进入了全新的世界，这个世界如此陌生，如果没有合作伙伴，我将束手无策、无所适从。与阿尼的合作给了我两个重要的启示：人工智能最伟大的胜利不仅是科学上的，也是人文上的；伟大的胜利，没有他人的帮助是不可能实现的。

11 无人可控

No One's to Control

此时，我们都处在一场全球风暴之中，我们要从根本上重新构想人工智能，使其成为以人为本的实践，这个共同的目标就是下一颗北极星。

「嗨，你是飞飞，对吧？」

我转身去看问话的人，他礼貌地做了个手势。

「我叫戴夫，」他伸出手和我握手，「前几天听到你在播客上的节目，忘了是哪一期了。你知道吗，我们风险投资公司一直在谈论人工智能，简直就是一刻不停。」他接着说，「就在过去的几个月里，我们已经完成了四个 A 轮融资，都是在这个领域。」

我笑了笑，不知道还能作何反应。那是 2014 年，风险投资的术语让我在自己的领域里感觉像个局外人。

「嘿，你见过杰弗里了吗？」他转过身向对面的另一个人招手，那个人穿的牛仔裤和羊毛套头衫看起来跟他的一模一样。

「杰弗里，过来过来，我想介绍你认识一个人！杰弗里是负责产品开发的副总裁，在……」

「好了，各位，请注意，我们可以开始了。」谢天谢地，一个声音从房间那头传来，打断了他，「我要感谢大家今晚的到来。学前班是孩子们人生的重要一步，今年我们为他们做了非常棒的规划。」

「一会儿再聊！」他挤坐在仓鼠笼旁边的小木椅上，低声说。

无论我们学术界如何看待人工智能，或者对其未来作何预测，有一点是不可否认的：人工智能已经不再由我们掌控了。十多年来，我对人工智能一直痴迷不已，它就像一层思想的外壳，悄然叠加在我的世界观之上。然而，到了 2010 年代中期，相关话题已经获得极大的公众关注，各种讨论铺天盖地、震耳欲聋。加州硅谷 101 号公路沿线的广告牌宣告着人工智能初创公司的招聘狂潮；在我的牙医候诊室里的杂志封面上，有关于人工智能的报道；开车换台时，还能从汽车收音机的谈话片段中听到关于人工智能的讨论；显然，在幼儿园家长会上，它也成了热门话题。

世界正在变得超现实。我和同事们穷尽职业生涯探索人工智能科学，但我们现在突然面对着「人工智能现象」（我还没有找到更确切的说法）。人工智能本身就充满了难以解开的谜团，现在，这项技术与各行各业、政府、记者、评论员甚至广大公众之间的互动突然激增，千丝万缕的关系与技术本身一样错综复杂。经过几十年的模拟环境开发和测试，人工智能已经进入现实世界的应用阶段。在人工智能的发展史上，充满了对其拟人化的尝试，但这些尝试带来的更多是误导，而非深刻的洞见。虽然我也不太愿意把人工智能明确地比作活的有机体，但不可否认，它已经进化出新的形态，躁动不安，嗷嗷待哺，渴望探索。

不到一年前，在我和安德烈的研究领域，谷歌迎头赶上的消息让我震惊不已，但如今却感觉已像陈年旧事。作为曾经的人工智能研究主力军，大学实验室现在已不是推动前沿发展的唯一机构。这已成为不争的事实。无论是在 GitHub 等平台上分享代码，还是在 Reddit 等论坛上讨论最新进展，我们都与谷歌、微软和脸书等科技巨头、遍布全球的初创企业、贪婪的风险投资人网络，甚至开源社区的软件开发人员共享繁荣热闹的景象。

有太多话题可以探讨。

2015 年，邓嘉和奥尔佳发表文章，回顾了 ImageNet 比赛迄今为止的影响，并分享了安德烈的研究成果：他估计人类在标注 1000 幅图像时的错误率约为 5.1%。虽然安德烈只是出于好奇才做的研究，但其结果却大大增加了比赛的刺激性。突然之间，算法不仅相互竞争，还开始与人类一决高下。2014 年，谷歌的神经网络分类器 GoogLeNet 的错误率仅为 6.67%，达到创纪录的最低水平，人类几乎要失去榜首地位了。

尽管 AlexNet 和 GoogLeNet 是计算机视觉领域的真正飞跃，但我们还远远未能了解其全部潜力。举例来说，我们确信网络深度是决定性能的关键因素，而 GPU 优惠的价格意味着我们终于有足够的处理能力，让深度达到前所未有的水平。然而，简单增加神经网络层数并不是万能之策。在初始阶段，网络深度的增加会提高图像识别准确率，但很快就会到达临界点，此后就是收益递减。我们怀揣着远大抱负，构建的神经网络越来越大，却在不经意间将网络变成了迷宫。过多的分层会破坏信号传递，导致训练过程停滞不前，使系统失去效果。

显而易见，要实现宏伟的目标难度很大，与投入多少硅片并没有直接关联。这意味着即使在现在，我们的网络也无法吸收和消化 ImageNet 等大型数据集，没有充分利用其潜力。我们需要改变现状，不断进化，不仅在规模上，更在创新上。这正是我期望 ImageNet 挑战赛能带来的激励和感召。

我终于如愿以偿。2015 年，由微软的年轻研究员何恺明带头研发的深度残差网络（Deep Residual Network，ResNet）再次改变了比赛格局。ResNet 达到了惊人的 152 层，但对网络架构进行了扭曲，允许在训练阶段绕过其中的某些层，使得不同的图像对网络中较小的子区域产生影响。

虽然经过全面训练的系统最终会充分利用其深度，但在训练阶段，没有任何一个图片示例必须覆盖整个系统。这样的架构带来了两全其美的结果。一方面，增加层数可以提高性能，吸收更多数据 ——ResNet 使用的 ImageNet 数据量超过了当时其他所有的参赛算法；另一方面，在不降低性能的前提下，保持了信号自由流动所需的简洁性。ResNet 是教科书式的范例，充分说明了在人工智能领域，创造力是推动着辉煌时刻出现的力量。

然而，ResNet 的设计只是故事的一半。ResNet 的最终效果甚至远远超出了设计者本人的预期，还因惊人的性能而登上了《纽约时报》等主流媒体的头条。ResNet 获得全球关注是意料之中的事：它的识别错误率仅为 4.5%，远远低于安德烈估算的人类错误率。简而言之，视觉分类的挑战似乎已经迎刃而解，机器轻而易举地超越了它们的创作者，完成了几年前还几乎不可能完成的任务。多么令人惊叹的里程碑啊。然而，没过多久，我们就意识到这只是开始，更多的里程碑将会陆续出现。

嘿，你在关注 AlphaGo 吗？

你知道哪边能赢吗？

我该不该赌一把？哈哈！

我的第二个孩子刚刚出生，如果有什么能让我与外界隔绝至少一两个星期，那应该就是生孩子这件事了。但我才出院几天，信息就如潮水般涌来，手机一直嗡嗡作响，提醒着我，我并没有偷得浮生半日闲的好运气。

2016 年年初，媒体对 DeepMind 的关注不断升温。DeepMind 是一家总部位于伦敦的初创公司，正在筹备一场围棋大赛，参赛双方分别是围棋大师李世石和一台机器。在此之前，这家科技公司一直名不见经传（甚至我对它的了解也只是皮毛），而现在似乎变得家喻户晓。此前一年，谷歌大举收购各类人工智能初创公司，DeepMind 以超过 5 亿美元的高价成为其中最昂贵的交易。但比价格更令人难忘的是它的使命。「他们声称正在研究 AGI。」我记得有同事带着学者特有的世事洞明的笑意告诉我。

我完全能理解同事的厌倦之情。AGI 指的是「通用人工智能」（artificial general intelligence），是一种极其复杂、灵活的人工智能，不仅能完成图像分类或跨语种文本翻译等狭隘任务，还能模拟人类一切认知能力，如分析、创造等。虽然我无法确定这个词是何时成为专业术语的，但计算机科学领域以前肯定没用过它。毕竟，「通用」智能从一开始就是人工智能的全部意义所在，前路虽长，但这并不意味着我们可以降低目标。对我们这些研究人员来说，AGI 这个新词听起来有些多余。但它读起来朗朗上口，可以让外界清楚地了解我们这个领域的终极目标，也让 DeepMind 在已经竞争激烈的生态系统中显得胆识非同一般。

我被各种问题狂轰滥炸 —— 学生、好友，甚至一些交情不深的朋友都给我发来消息，问我有没有什么预测可以分享。我确实没有，但当家里另一位人工智能教授突然拿着一瓶刚冲好的奶走进房间时，我忍不住也向他请教。

西尔维奥说：「嗯，两种可能性都有。早在 20 年前，深蓝就在国际象棋比赛中战胜了人类，」他似乎在心里算了一会，「准确地说，是 19 年前。」

书呆子就是书呆子。

「不管怎么说，」他继续说，「虽然围棋比国际象棋难很多，但仍然属于棋盘游戏。规则虽然复杂，但都非常直接明确，至少从数学角度来看是这样。」

他意识到自己越说越有教授的腔调了 —— 虽然我们说好了在家里不能这样，但经常做不到。他一边笑着，一边小心翼翼地把奶瓶放进热奶器里。我们几乎同时说出了接下来的话：「跟冲奶完全相反！」

他说得没错。围棋策略的组合数量大到无法想象，关于如何就此建模，我们俩可以侃侃而谈，但像准备一瓶婴儿配方奶，再把奶瓶放到热奶器里这样简单的事情，却依然是机器人专家的「圣杯」—— 尽管在严格控制的实验室条件下，冲调完美配方奶粉的问题已经得到解决，但在实验室之外，依然存在巨大挑战。

1997 年，国际象棋大师加里·卡斯帕罗夫（Garry Kasparov）与 IBM 的超级计算机深蓝（Deep Blue）进行国际象棋比赛，计算机正式打败了人类，消息一出，轰动一时。但是，相对于国际象棋，围棋的复杂性不仅体现在规则上，还体现在策略组合的可能性范围上。事实上，围棋的规则决定了棋子所产生的可能性范围极大：棋盘上 19×19 的格子可以带来的组合总量多达 10 的 360 次方。这个巨大的数字超过了宇宙中的粒子数量，且超过许多个量级。要下好围棋，人类需要通过毕生的实践不断培养直觉能力，在每个回合都要把理论上的无数种选择缩减为可操作性的若干种落子选择。而就算是最先进的人工智能，其认知深度也不足以复制这种能力。

的确，寻找最佳落子方法所需的计算量是巨大的，因此使用计算机下围棋难，难于上青天。尽管如此，我们仍有理由保持轻松乐观，因为围棋遵循一套明确而客观的有限规则，胜负的标准就是看哪一方的棋子在棋盘上占的地盘更大。所以与真正的登月相比，围棋可以说是相对简单的。

「即使它赢了，」西尔维奥补充道，「要想做意大利千层面的功夫超过人类，机器还需要一段时间。」

就这样一个简单的回答，西尔维奥让我对现代人工智能有了更深刻的认识，同时也让我感到饥肠辘辘。

事实上，AlphaGo 确实赢了，全球媒体纷纷报道，关注度达到了巅峰。整个世界为之沸腾，而亚洲的反应尤其狂热。对我来说，体现热度的最直接指标出现在个人生活层面。

「飞飞，我的老同学们问我你知道 AI 下围棋是怎么回事吗？」爸爸给我转了一大堆他国内的朋友发来的微信，最近这样的信息感觉没完没了。「他们听说我女儿是 AI 教授，都在问我呢！」新闻头条是一回事，但当父母和他们在国内圈子的同龄人都在讨论人工智能时，说明世界真的变了。

在这个时期，人工智能领域的转折点层出不穷。即便是最引人注目的突破，我们也不陌生，因为我们为人工智能技术奉献了一生，现在是开花结果的时候了。ResNet 和 AlphaGo 等的故事激发了各界的对话和讨论，也激励我们在自己的研究中更进一步。我意识到，人工智能的新时代不仅仅是一种现象，因此我忍不住借用了硅谷最喜欢的一个词，因为正如他们所言，这是一场「颠覆」。

我办公室里的那个小小的红色沙发，曾经见证了我们实验室众多声誉卓著的项目的诞生，如今它成为我敦促年轻人多读文献的地方。我经常要求他们，在进行研究的同时，务必为人工智能科学赖以建立的基础文献留出空间。时代不断加速发展，每个人的注意力都集中在了更热门的信息来源上，而传统文献却一直被忽视。我注意到了这个问题，起初感到恼火，后来又心生担忧。

「请大家不要每天只从 arXiv 下载最新的预印本作品了。去读一读拉塞尔和诺维格的著作，去读明斯基、麦卡锡和威诺格拉德的书，读哈特利和西塞曼的作品，读一读帕尔默写的东西。不要因为这些材料距离现在时间久就忽略它们。我们就是要多读一些以前的东西，他们的理念经得起时间的考验，依然非常重要。」

arXiv 是涵盖物理学和工程学等领域学术文章的在线资料库，其中的文章尚未在学术期刊上正式发表，但会提前以未经编辑的预印本形式提供给对内容感兴趣的读者。几十年来，预印本一直是大学文化的固定部分。然而近些年来，人工智能发展极其迅速，每周都在发生变化，甚至整个领域会在一夜之间被颠覆。为了保持与时代同步，预印本已成为重要的资料来源。如果说要学生们等上几个月去读通过同行评议的论文都是过分的要求，那么几年前编写的教科书，甚至是整整几代人之前编写的教科书被束之高阁，又有什么好奇怪的呢？

太多事情在抢占学生的注意力，文献只是个开始。科技巨头争相组建人工智能团队，公开大肆招揽人才，承诺的起薪高达六位数，有时甚至更高，还提供丰厚的股权待遇。机器学习先驱一个接一个离开了斯坦福大学，到了 2010 年代中期，连博士后都成了抢手人选。希望推出自动驾驶汽车的优步迈出了大胆的一步，从卡内基梅隆大学挖走了 40 名机器人专家，数量之多堪创纪录，几乎摧毁了这所大学的机器人研究体系。对我和同事们来说，光是目睹优步事件，就已经够难受的了，而对我的学生们来说，这件事似乎从根本上扭曲了他们对教育之意义的认识，因为他们年龄尚小、充满渴望，而且仍在寻求自己的身份和认同感。最终，这种趋势达到了顶峰 —— 至少对我个人来说是这样 —— 非常出乎我的意料。

「你真的要拒绝他们吗？安德烈，那可是全球最顶尖的学府之一啊！」

「我知道。但是我不能错过这个机会。真的很特别。」

安德烈已经完成了博士学业，即将进入人工智能史上最有前景的就业市场，即使对一个有志成为教授的人来说也是如此。普林斯顿大学给他提供了教职机会，这是我们任何一个同龄人都梦寐以求的职业快车道。然而，他却决定彻底离开学术界，加入一个没人听说过的私人研究实验室。

安德烈即将加入 OpenAI 的核心工程师团队。OpenAI 由硅谷巨头萨姆·奥特曼（Sam Altman）、埃隆·马斯克和领英首席执行官里德·霍夫曼（Reid Hoffman）共同创立，初始投资高达 10 亿美元，这充分证明硅谷对人工智能的突然崛起是多么重视，硅谷的杰出人物多么渴望在人工智能领域站稳脚跟。

OpenAI 推出后不久，我在当地的聚会上遇到了几位创始成员，其中一位举杯祝酒，但他的欢迎词颇有几分告诫的意味：「每个从事人工智能研究的人，都应该认真思考自己今后在学术界的角色。」他说这番话时没有一丝笑意，言辞中透露出明确而冷酷的信息：人工智能的未来将由那些拥有企业资源的人书写。在学术界受训多年的我想习惯性地反唇相讥，但我没有。老实说，我甚至都不确定自己是否反对他的观点。

谁也无法预测一切会走向何方。与大多数领域相比，我们的领域经历了太多起起伏伏，虽看似前程远大，但数度出师不利，「人工智能寒冬」一词就反映了其多舛的命运。但这次感觉不一样了。随着越来越多学者的深入分析，科技界、金融界和其他领域逐渐认可了一个术语：「第四次工业革命」。虽然流行语背后通常存在着夸张成分，但这个词的确名副其实，足以让决策者们铭记于心。无论是源于内心真正的热情，还是来自外部的压力，抑或是两者兼有，硅谷的高管层都在采取比以往更迅速、更大胆甚至更冒险的举动。我们即将见证这种企业理念将会带来何种结果。

「猿。」我的天哪。

这是雅虎图片托管服务 Flickr 在 2015 年 5 月自动生成的一个标签，用来描述 56 岁黑人男子威廉的单色肖像。雅虎的新技术立刻引发了各方强烈愤慨，可谓自取其祸。此后，这项技术接二连三出现失误：将达豪集中营大门的照片标记为攀爬架，把一位脸上涂有彩色粉末的白人妇女贴上了「猿」的标签。雅虎 Flickr 一经推出，即麻烦缠身。不仅是雅虎，到了 6 月，谷歌也陷入了类似的争议，因为谷歌照片服务将两个黑人青少年错误地标记为「大猩猩」。图像分类本已是老生常谈的成功技术，却在短短几周内变得非常复杂。

即使不是这些公司的员工，我们也很难不感到一丝罪恶感。虽然事故并非恶意，但这并不能让人感到宽慰。相反，无心之失所揭示的问题才更加令人不安：包括 ImageNet 在内的数据集由于缺乏多样性，导致了一系列意料之外的结果；未经充分测试的算法和存疑的决策又进一步加剧了负面影响。当互联网呈现的是以白人、西方人和男性为主的日常生活画面时，我们的技术就很难理解其他人群了。

有果必有因，正如记者兼评论员杰克·克拉克（Jack Clark）所言，问题的根源在于人工智能「男性之海」问题：科技行业的代表性不足，导致算法无意中带有偏见，在非白人、非男性用户身上表现不佳。这篇文章于 2016 年发表在彭博社网站上，是对人工智能伦理问题的最早一批讨论之一。此后，相关对话日益激烈。人们担心人工智能在做好事的同时（如支持残障人士、追踪森林砍伐、以各种新方式保护人类生命等），也有可能产生危害。

我想到了为打造 ImageNet 而挣扎奋斗的那些年 —— 即使在我们最具创造力和即兴能力的时候，也没有考虑到伦理问题。十年前，由谷歌和维基百科等组织的内容呈爆炸式增长，似乎极大地拓宽了电视和报纸等传统媒体提供的狭隘视角，为我们提供了一扇了解人类生活真实面貌的窗口。从某种程度上来说，它们确实做到了。然而，虽然一切看起来很生动，虽然我们的期望是如此热切，但所形成的图景还远远不够完整。

这个问题早就应该面对，但对话并不足以安慰我内心深处的工程师。显然，数据集不平衡是造成问题的重要原因，但还有无数其他因素值得我们考虑。模型本身是否存在问题？在依赖所有数据的算法架构中，是否隐藏着未被发现的弱点？可以促进训练过程的学习技术有问题吗？问题的数量超过了答案，而且这个差距越来越大。

这些问题也压在奥尔佳的心头。人工智能是以男性为主导的领域，作为少数女性，我们两个人多年来一直惺惺相惜，彼此分享着身为女性在人工智能领域的经历，也沮丧地发现，我们的经历非常相似。到了 2010 年代中期，奥尔佳忍无可忍，她下定决心，要么采取行动改变现状，要么离开学术界。她选择了前者，我们决定一起努力。

我们认为，从代表性问题的出现，到问题被大众真切地感受到，中间往往需要几年的时间。因此，我们向九年级和十年级的女生开放了斯坦福大学人工智能实验室课程。所有参与的学生都是经过精挑细选的，为期两周的人工智能速成课程虽然紧张，但实践证明，只需要一点点努力，就可以让每个一直被历史排除在外的参与者相信，她们同样属于这个时代、这个领域。邀请少数人群参加人工智能课程的想法非常受欢迎，我们的项目很快就像滚雪球一样发展成为全国性的非营利组织，遍布北美各地校园，使命范围也不断扩大。很快，我们也开始向有色人种学生和经济困难学生等边缘群体提供类似项目。

在短短几年后，我们的项目就正式命名为 AI4ALL，甚至吸引了一些资金，梅琳达·弗伦奇·盖茨（Melinda French Gates）的 Pivotal Ventures 创投公司和英伟达创始人黄仁勋提供了一轮融资，让项目改头换面。这个旅程可能需要几代人才能完成，现在只是迈出了一小步，但我们实现了从无到有的跨越。此外，项目还能带来一丝安慰 —— 在业界追逐人工智能未来时，往往肆意而为，缺乏自省，而我们的努力能够保证，至少有一小部分人在逆向而行。

雅虎和谷歌等公司在全球的注视和评判下得到了惨痛的教训。亲眼看到这些事件提醒我们，仅仅对下一代技术进行投资，然后期望一切顺利是不够的。普林斯顿大学向奥尔佳提供了教授职位，她接受之后，开始着手扩展自己新实验室的研究议程，不仅包括机器感知的机械原理，还涵盖更广泛的计算公平性问题，尤其强调要「去偏见」。「去偏见」是遵循严格数学要求的正式操作，旨在对潜伏在数据中的偏差进行量化和中和。这种理念体现了对社会福祉议题的深切关注，有奥尔佳这样的人据此展开研究，我对未来的希望又开始增加了。

我全心全意地相信人工智能技术的价值，它具有揭示智能奥秘的潜力，也可以带来我和阿尼在医院工作时目睹的种种实际的益处。但是，哪怕是片刻的过度自信，付出的代价也会急剧上升。更糟糕的是，这个代价将由其他人承担，很可能是最脆弱的人群。人工智能已经走出了实验室，基本脱离了我们的控制。虽然新思想、新面孔和新机构的旋风令人振奋，但也带来许多新的担忧。对我们这样经费极其紧张的研究人员来说，对人工智能领域进行商业投资的承诺似乎是天赐之物；但商业资金以巨大的力量冲刷着一切，好像一场豪赌，让人感到的不是幸运，而是不祥和担忧。

词不达意的问题依然存在。使用「现象」一词太过被动，「破坏」显得粗鲁，「革命」过于自我陶醉。现代人工智能面纱揭开，我们看到的是一个纷繁复杂的迷局。令人不安的危险感日益增长，但这种危险感是科学家天生能够识别和理解的。我产生了新的好奇心，虽然令人不适，却具有强大的吸引力。我只需要一种近距离观察危险的方式。

「到目前为止，结果令人鼓舞。在我们的测试中，由‘神经架构搜索'设计的分类器经过 ImageNet 训练后，性能超过了人类设计的同类分类器；所有工作都是靠计算机自己完成的。」

那是 2018 年，在加州山景城的谷歌总部中心 Googleplex，我坐在谷歌大脑（Google Brain）的长会议桌一端。谷歌大脑是谷歌最著名的人工智能研究机构之一。此次会议的主题是「神经架构搜索」（Neural Architecture Search，NAS），这是一种可以自动搜索神经网络的优化架构。神经架构搜索的发展成果特别令人激动，几个月来在谷歌内部持续引发热议。

此类模型的行为方式是由一系列参数决定的，这些参数在速度与准确性、内存与效率以及其他关注点之间进行权衡。对一两个参数进行微调非常容易，但要实现所有参数之间的平衡，往往是一项考验人类能力的任务，即使是专家也很难把每个参数都调整到最佳状态。如果能实现自动化调节，将会带来极大的便利，显然是值得追求的目标。自动化还能降低人工智能的使用难度，让越来越多的非技术用户在没有专家指导的情况下，使用人工智能构建自己的模型。此外，用机器学习模型来设计机器学习模型，并且能够迅速超越人类的能力，的确非常富有诗意。

但所有功能都是有代价的。单个模型的训练成本依然很高，只有资金最雄厚的实验室和公司才负担得起，而神经网络架构搜索则需要训练数千个模型。这项创新很了不起，但从算力的角度来看，造价也极其昂贵。成本问题是会议讨论的重点之一。

一位研究人员问道：「这是在什么样的硬件上运行的？」

「在整个过程中的任何时刻，我们都在同时测试 100 种不同的配置，每种配置训练 8 个特性略有不同的模型，所以共有 800 个模型在同时训练，每个模型都分配了独立的 GPU。」

「这么说，我们大约要……」

「800 个 GPU，没错。」

800 个 GPU ！2012 年，AlexNet 只需要两个 GPU 就能改变世界，现在的需求却飞速增加，其速度之快令人目眩，以后更会有增无减。根据我自己实验室的预算，英伟达最强大的 GPU 成本约为 1000 美元（这也解释了为什么我们自己只有十几个 GPU）。此外，还需要把这么多高性能处理器连接到一起，确保所有芯片昼夜不停地模拟运算，同时设备可以维持在可接受的温度范围内，这些都需要花费时间和人力。此外还要选择合适的地点。网络硬件占据大量的物理空间，耗电量巨大，因此不可能在普通车库或卧室中搭建。即使是像我们这样的大学实验室，也很难建造出如此庞大的网络。我靠在椅背上，环视了一下房间，想知道是否还有其他人和我一样对此感到沮丧。

2016 年，我即将迎来 21 个月的学术休假，暂时离开教授职位。我的收件箱被来自英伟达、优步和谷歌等公司的邀请信息淹没了。我保持着一种久经磨炼的本能，对这些信息一概不予理睬，却越来越多地发现自己停下来片刻，关注这些信息。我叹了口气，跟以前相比，现在去科技公司工作也许会更有意义，哪怕只是一点点。

我不得不承认，进入私营企业工作的想法不再像从前那样陌生。身边已经有数不清的同事实现了转型，就连我的学生也纷纷放下学业，到世界各地的科技公司进行高薪实习，有的更是一去不复返。如今，一切变化如此之快，我不得不怀疑，我对加入企业的厌恶是不是已经过时了？我想看看斯坦福大学和科学期刊之外的现代人工智能是什么样子。也许，眼下正是好机会，至少可以让我暂时体验一番。

经过再三考虑，我最终决定接受谷歌云的人工智能首席科学家一职。虽然此时的谷歌是一家有近 20 年历史的大公司，但云计算部门才成立一年左右，我觉得这是帮助谷歌从头开始打造人工智能的好机会。我还碰巧认识公司新任命的谷歌云首席执行官黛安娜·格林（Diane Greene）。她曾是虚拟化巨头 VMware 的联合创始人，是为数不多征服硅谷的女性，我期待着在性别比例极不平衡的行业里与她并肩工作。

这不像我本科时得到的那份看似光鲜亮丽的华尔街工作，也不像我在加州理工学院得到的麦肯锡快车道职位（当时我还因为要不要接受这个职位纠结了很久）。我一度把企业的工作当成是具有嘲讽意味的贿赂，目的是让我放弃实验室，但现在，我无法再继续假装它是一种贿赂。这是一份邀请，让我可以运营规模更大的实验室。其能力远超我的想象，我可以使用任何规模的高性能算力，由博士组成的研究团队比我在斯坦福大学能召集到的任何团队都要大几个数量级。最吸引我的是，我可以获得我以前做梦都无法想象的海量数据。当然，我的工作会受到公司产品路线图的驱动，至少是间接驱动，但这些产品始终是基础研究的下游，正是基础研究让它们成为可能。

最重要的是，谷歌云意味着我看到的不是一个，而是成千上万个人工智能的应用案例。随着云服务在人们能想象的几乎任何行业找到立足点，谷歌和其他云服务提供商也成了各行各业的固定伙伴。我有机会看到人工智能在制造业、农业、保险业、运输和物流业、零售业、金融服务业甚至政府部门的应用情况，以及为其提供支持的数据。其规模之大、种类之多，是任何一所大学都无法同时提供的。

我并不打算完全离开斯坦福大学，即使在学术休假期间也是如此，所以我花了一些时间来敲定细节。我会继续每周在校园里待一天，这样我就可以与实验室保持联系，并跟学生们见面。显然，后勤工作将是个挑战，但我已经做出决定。

我在大学这些年的所见所闻也不少，但谷歌云幕后的一切仍然出乎我的意料。科技行业的财富、权力和雄心向来名声在外。在亲身经历后，我觉得实际情况比传闻有过之而无不及。我看到的一切都比我所习惯的更大、更快、更精密、更复杂。

光是食物的丰富程度就令人咋舌。休息室里的零食、饮料和专业级意式咖啡机比我在斯坦福大学或普林斯顿大学见到的要多得多。几乎每栋大楼的每一层都设有这样的休息室。而这一切，都还只是我在进入自助餐厅之前所看到的。

其次就是科技。这么多年来，我们一直用的是 2000 年代的投影仪和视频会议设备，故障频发，性能很不稳定，经常让人大为恼火。相比之下，谷歌的会议现场就像科幻小说里的场景。无论是可容纳 50 人的高管会议室，还是供一人使用的衣柜大小的会议箱，每个房间都配备了最先进的远程呈现技术，只需轻点触摸屏，就能启动一切。

还有就是人才。谷歌人才济济，令人叹为观止。回想起自己花了两年时间才招募到三位合作者来帮助建立医院环境智能，我不禁自愧不如。在谷歌，15 人的团队已经准备就绪，只等我立即加入。而这仅仅是个开始 —— 在短短 18 个月内，我们的规模扩大了 20 倍。拥有优秀资历的博士似乎随处可见，让我觉得一切皆有可能。无论人工智能的未来会怎样，谷歌云都是我了解世界的窗口，而世界正以最快的速度向未来迈进。

我在斯坦福大学度过的每个周五更是突显了大学与企业之间的差异。随着我就任新职的消息不胫而走，我每天都能接到实习申请。这在某种程度上是可以理解的，因为我的学生（偶尔还有教授）只是在尽力建立人际关系网。不过，让我担忧的是，我和他们的每一次谈话，无一例外都以同样的请求结束：在他们看来，最有趣的研究是不可能在私营实验室之外实现的。即使在斯坦福大学这样的地方，预算也不够多。事实上，预算往往还差得远。企业研究不仅是更有利可图的选择，而且正在越来越成为唯一的选择。

最后就是数据。数据是谷歌整个品牌建立的基石。ImageNet 让我第一次看到了大规模数据的惊人潜力，也奠定了我此后几乎所有研究的理念基础。我和乔恩一起研究了几十年以来的汽车模型，和安德烈一起研究了大量图片和相关说明，和蒂姆尼特一起研究了整个美国的街景图像和人口普查局的记录 —— 数据量不断增长，人工智能的能力也与日俱增。现在，我被数据环绕了，不仅丰富程度难以言表，所涵盖的类别也超乎我的想象：来自农业企业的数据，他们希望可以更好地了解植物和土壤；来自媒体行业客户的数据，他们希望谷歌可以帮助他们整理内容库；来自制造商的数据，目的是减少产品缺陷；等等。几个月过去了，我穿行于两家最有能力为人工智能的未来做出贡献的机构之间。这两家机构都人才辈出，极富创造力和远见卓识。两家机构都在科技史上有着深厚的根基。它们甚至可以从同一条高速公路进出，在国道 101 上只相隔几个出口。然而，行业准入壁垒宛如一座大山高耸在地平线上，峰顶远高于云层，在知名高校和顶级私企之间，似乎只有一方拥有足够的资源来适应这个时代。

我的思绪不断地回到那 800 个 GPU 上，它们在应对一个教授和她的学生们无法想象的计算任务。如此多的晶体管，如此巨大的热量，如此巨额的资金。「疑惑」这样的字眼并不能表达我逐渐感到的惊惧。

人工智能正在成为一种特权，一种排他性极强的特权。

从 ImageNet 时代开始，规模的重要性就已经显而易见，但近年来，「越大越好」的观点几乎被赋予了宗教般的意义。媒体上充斥着城市街区大小的服务器设施的图片，关于「大数据」的讨论永无休止，不断强化着这样的观点：规模是神奇催化剂，是机器中的幽灵，可以将人工智能的旧时代与令人窒息的梦幻未来区分开来。虽然相关分析可能会有些简化，但本质上并没有错。没有人能否认，神经网络确实在这个资源丰富的时代蓬勃发展：惊人的数据量、大规模分层架构和大量互联的硅片确实带来了历史性变化。

这对科学意味着什么呢？如果我们的工作秘诀可以简化为赤裸裸的量化，简化为蛮力制胜，那么努力思考和创新又有什么意义呢？如果一些想法在层数太少、训练样本太少或 GPU 太少的情况下似乎会失败，而在数量增加到足够多的时候突然又可以高效运转，那么对于算法的内部运作机制，我们又能得到什么教训呢？我们发现自己越来越多地从经验角度观察人工智能，就好像它是自己出现的一样，仿佛人工智能是需要先识别、后理解的东西，而不是根据第一原理设计产生的技术。

我们与人工智能之间的关系正在发生转变，对我这样的科学家而言，这样的前景令人深思。在谷歌云的新职位上，我可以鸟瞰越来越依赖于各个层面技术的世界，但我们不能坐而论道、惊叹于一切的神奇。这种奢侈我们负担不起。新一代人工智能所能做的一切，无论是好是坏，无论是在预期之内，还是在意料之外，都因其设计本身缺乏透明度而变得复杂。神经网络的结构本身充满了神秘色彩，它是由微小的、权重微妙的决策单元组成的巨大集合体。这些决策单元孤立地看毫无意义，但以最大的规模组织起来时，却强大得令人咋舌，几乎无法为人类所理解。我们可以从理论的、抽象的意义上谈论神经网络：它们能做什么，它们达到目标需要什么样的数据，它们训练后的性能特征大致在哪个范围；但从一次调用到下一次调用，它们在内部到底做了什么，却是完全不透明的。

由此带来的后果特别令人担忧，这就是一种被称为「对抗攻击」的新型威胁。在对抗攻击中，输入内容的唯一目的是迷惑机器学习算法，以达到反直觉甚至破坏性的目的。举例来说，一张照片看上去是描绘了某种明确的事物（比如蓝天下的长颈鹿），但可以通过单个像素颜色的细微变动进行修改。尽管这种像素颜色的变化是人类肉眼无法察觉的，却会在神经网络中引发一连串的故障。如果对抗攻击设计得当，虽然原始图像看起来没有任何变化，但算法会把「长颈鹿」这样的正确分类变成「书架」或「怀表」等错误分类。先进技术无法辨认野生动物照片的场景可能会让人觉得好笑，但如果对抗攻击的目的是愚弄自动驾驶汽车，导致汽车对停车标志，甚至人行横道上的儿童进行错误分类，就绝对不能用好笑来形容了。

当然，提高工程技术水平可能会有所帮助。「可解释的人工智能」，或简称为「可解释性」，正在成为新的研究方向，令人备受鼓舞。可解释的人工智能试图将神经网络近乎神奇的计算进行简化，转变成人类可以仔细研究和理解的形式。但相关研究尚处于起步阶段，无法保证能够达到其支持者所期望的高度。与此同时，这项技术所要诠释的模型却已经开始在世界各地大量出现。

即使是完全可解释的人工智能也仅仅是第一步。如果在算法设计完成后，再加入安全性和透明度等考虑因素，无论设计得多么精妙，都不足以满足要求。下一代人工智能必须从开发之初就采取与现在完全不同的理念。以激情为起点固然很好，但我们要面对的是纷繁复杂而又不起眼的挑战，要取得真正的进展，就必须有敬畏之心。而硅谷似乎缺乏这种心态。

学术界早就意识到人工智能可能会带来负面冲击，比如缺乏透明度、容易受到偏见和对抗性影响等等。然而，由于研究规模有限，风险一直只存在于理论层面。我的实验室最有现实影响力的工作是环境智能研究。由于临床法规的制约，我们对工作热情保持谨慎和克制，因此有足够的机会来应对相关隐患。但现在，市值接近万亿美元的公司已经掌握了主导权，潜在风险的发展步伐也急剧加快。无论是否准备就绪，这些问题都需要以商业速度加以解决。

每个问题单独来看都令人担忧，但它们共同指向了一个未来，其特点是监督减少、不平等加剧，如果处理不当，甚至可能导致迫在眉睫的数字独裁主义问题。走在全球最大公司之一的走廊里，我不禁陷入沉思，问题的确很尴尬，尤其是考虑到同事们的诚意和良苦用心。这些都是制度性问题，而不是个人问题。现在还没有出现胡子拉碴的典型恶棍，我们还没有遇到真正的现实问题，此时提出这些挑战，只会让人更加困惑。

我回想起与阿尼共事的情景，想起当时要在几家医院部署手工制作的小型原型设备是多么困难。在高度谨慎的医疗领域，创新是逐步展开的，虽然有时令人沮丧，但总体上也让人感到心安。我想知道医疗领域的做法是否值得广泛效仿。

硅谷的傲慢态度向来为外界所诟病。在人工智能时代，尽管我们对潜在风险的认知不断加深，企业的夸夸其谈也上升到了新的高度。首席执行官们在世界各地的舞台上发表主题演讲，有些内容高瞻远瞩，有些则拙劣不堪，还有一些是彻头彻尾的侮辱。企业高管们承诺将在不久后推出自动驾驶汽车，设计出高超精湛的肿瘤检测算法，实现工厂的端到端自动化。至于被先进技术取代了工作的人（出租车司机、长途卡车司机、装配线工人甚至放射科医生）的命运，商业领域的态度似乎介于半心半意的「再培训」和几乎不加掩饰的漠不关心之间。

无论首席执行官和自诩为未来学家的人的言论如何彻底脱离公众，技术的日益普及都会进一步加剧人们对人工智能的恐惧。在这个时代，里程碑接二连三地出现，最可怕的情景正在逼近。在人工智能领域的历史上，第一次出现了流血事件。

在亚利桑那州坦佩市，优步先进技术集团正在测试一辆自动驾驶原型汽车。伊莱恩·赫茨伯格（Elaine Herzberg）推着自行车过马路时，被这辆车撞倒身亡。两年多前，优步策划了卡内基梅隆大学机器人系团队离职记，而现在，优步的自动驾驶项目成了公众嘲讽的对象。如果说人工智能如今频频遭遇偏见让我和同事们感到难过，那么我们现在的感受则无法用语言来形容。优步的品牌已经声名狼藉，其原因与技术本身关系不大。尽管我们很容易将事故归咎于优步，但很明显，这绝对不会是最后一个类似的事故。

的确，更多教训很快就出现了。2016 年，ProPublica [注：ProPublica 是一家总部设在美国纽约的非营利性媒体，其新闻报道以调查为主，主要涉及政府、商业、刑事司法和环境等主题。—— 译者注] 的一系列调查显示，有偏见的人工智能被广泛应用于处理贷款申请，甚至协助法官做出假释决定等方面。类似的报道还显示，在某些招聘中，求职者会先经过人工智能技术的筛选，然后才有真人面试官进行面试。此类做法往往会在无意中造成歧视性影响，这一点并不令人意外。伊莱恩·赫茨伯格的死亡理所当然地导致优步自动驾驶团队解散，并对整个领域造成了负面影响，但上述更微妙、更机构化的伤害却不可能迅速得到纠正。相关问题几乎是无声无息的，影响范围更广，而监管则少之又少。期待出现同样程度的公愤是不现实的。但好在公众意识在不断提高，媒体也认识到，当涉及人工智能的报道时，不应忽视偏见、公平和隐私等问题。

无法问责算法、特定人群受到不公平待遇、一个人意外死亡，这些都是人工智能领域出现的新局面。审视局面，我得出结论：简单的标签已经不再适用。甚至连「失控」等措辞都显得委婉。人工智能不是现象，不是颠覆，不是难题，也不是特权。我们面对的是一种自然力量。它是如此宏伟，如此强大，如此反复无常，既能轻易激发灵感，也很容易摧毁一切。要让人工智能值得信任，需要的远不止商业公司空洞的陈词滥调。

人工智能甚至不是科技界对公共利益的唯一威胁，这使得情况变得更加复杂。在人工智能领域出现问题的时候，剑桥分析公司也爆出丑闻。在 2016 年美国总统大选期间，公众普遍对虚假信息表示担忧。关于社交媒体和新闻源过滤气泡的不良影响的报道也在不断增加。种种事件都有一个共同之处：世界正在逐渐意识到，数据不仅有价值，而且具有影响力，甚至可以产生前所未有的决定性影响。

到 2018 年，已经没有人再质疑其中的利害关系了。对脸书和 Instagram 等社交媒体应用的审查不断加强，因为它们提供的超个性化内容可能会导致青少年出现抑郁和焦虑。社交媒体利用人工智能打磨定制化内容，以实现最大程度的「用户参与」，这种趋势令人不安。亚马逊使用一系列监控工具（包括监控腕带）实时追踪工人的工作效率，这种仓库管理方式受到媒体抨击。微软在试图推广其人工智能面部识别技术时，遭到了隐私权倡导者和公民自由组织的批评。我自己也被卷入争议的中心。当时谷歌云与美国国防部签订的一份合同（内部称为 Maven 项目）引发了广泛的争论。几个月后，紧张局势从公司内部蔓延到媒体，重新点燃了大众关于技术在军事事务中所扮演角色的长期争议。科技抵制浪潮已经来临，人工智能难以独善其身。

「我们就在这儿等着。」我说。

时间是早上 5:30。我看着护士把母亲推进手术室。她又要做心脏手术了，这是迄今为止创伤最大的一次。中国家庭向来不善于用语言表达对彼此的感情，我在心里默默地说出了剩下的祝福。

我爱你，妈妈。

我不知道该做些什么。几分钟后，我无精打采地站起身，在大厅里踱来踱去，找到了一张远离喧嚣的安静长椅，颓然坐下。长椅的金属表面比我想象的还要冰冷，我不禁打了个寒战。只有我一个人，满脑子都是我还没准备好面对的种种思绪，左手边空空如也 —— 在其他日子里，母亲总会坐在我的左边。她也许会发脾气，会评头论足，但她总是在那里，总是在我身边。

片刻之后，我意识到周围并非空无一人。父亲找到了我。他看起来欲言又止，似乎不知道如何开口。

「飞飞……」他的语气异常严肃，甚至有一种成年人的口吻。但我感觉到的不是力量或威望，而是脆弱。

「我小时候，人人都喜欢我父亲，」他停顿了一会儿，继续说道，「尤其是我。我跟你说过他的事吗？我们家并不富裕，但过得还算舒适，尤其是在我们这样的小城镇。我的成长过程很幸运，我觉得自己…… 很特别。」

我不知道该怎么理解我听到的话。他很少谈起他的过去 —— 缺席的祖父、他似乎从未摆脱的童年，还有我和母亲之外的家庭成员。但他继续说了下去，深入讲述着我从未听过的故事。

父亲委婉地讲到，因为他的母亲患有某种说不清的严重精神疾病，他从小就没有在自己母亲身边。尽管如此，或者更可能正因为如此，他的父亲 —— 也就是我的祖父 —— 对他溺爱有加。祖父并非富有之人，也没有显赫身份，只是个小官员，但生活在那样的小城镇里，即使是微不足道的行政地位也能带来一些好处。对父亲来说，那是一段快乐的时光，远离了那个时代的纷杂是非，经历了我想象中他那种性格的人在童年时期必定经历的各种冒险。

当他告诉我他儿时最喜欢的宠物时，我忍不住笑出声来：一只熊，一只真正的熊，而且是他亲手养大的。后来那只熊长得太大了，变得非常危险，他们没有办法，只能捐给了动物园。当然，我不应该感到惊讶，大多数男孩哪怕只有一点儿名义上的特权，也会梦想着进个好学校、谋个好职位，但父亲毕竟与大多数男孩不同。他当然会利用这个小小特权换取一只熊，牵着它在小镇上漫步。我内心的紧绷逐渐舒展开来。以传统的标准来衡量，他也许不是一个称职的父亲，但像这样的时刻还是让人印象深刻。他真的能在任何场合给人带来温暖。

但故事至此发生了转折，因为祖父突然罹患重病。病情开始得很神秘（那个时代经常会这样），而且由于他们很少与人交往，祖父的病逐渐恶化。只有父子俩相依为命，小镇物资有限，有效治疗几乎是不可能的。父亲束手无策，祖父日益憔悴疲劳，食欲急剧下降，变得神志不清。

因为照顾不周，祖父的身体迅速垮了下来，几个月后就无法自理。父亲只能守在床边，眼睁睁地看着祖父的身体一天天衰弱下去。父亲整个世界的中心崩塌了，但他却无能为力。当祖父最终去世时，父亲觉得生命毫无意义、毫无尊严。姗姗来迟的医生跟父亲解释说，是极度营养不良加剧了祖父的胃肠道疾病，最终使他的身体不堪重负。但对一个突然变得如此孤立无援的男孩来说，解释已经无关紧要。一切都毫无道理可言。

那是 1961 年，父亲当时只有 14 岁。

祖父去世后，没有任何亲人来照料父亲。不可思议的是，祖父的一位同事主动收养了父亲，成为他的法定监护人。祖父同事让父亲继续上学，满足了他的基本需求，并确保他顺利毕业。祖父同事的慷慨让父亲熬过了那段原本会让他生不如死的日子，但从此之后，他就像变了一个人。

祖父去世后，父亲的一部分也随之消逝，留下的只是一个孩子的一部分，这是他所热爱的世界曾经存在过又消失的唯一证据。因此，他决心保持原样。即使他长大成人，获得学位，并最终为人夫、为人父，他也继续过着记忆中的那个男孩的生活。

父亲笑容温暖，喜欢玩冒着傻气的文字游戏，一生都拒绝承担责任，但在这一切的背后，隐藏着一种无法治愈的痛苦，多年后依然让他难以自拔。所有的遭遇和痛苦塑造了他唯一的信念，随时间推移而变得更加坚定：虽然反复无常、残酷无情的世界夺走了他的父亲，却永远带不走他。这个世界也永远不会夺走我的母亲，永远不会带走我。

在那一刻，我恍然大悟。父亲并不是在简单地向我讲述我们家族的历史，也不是在讲述他与母亲一样渴望逃离的私人原因。这个男人之所以说这些话，是因为他急于想让女儿做好失去母亲的心理准备。在几十年的新生活之下，埋藏着他最古老、最深沉的悲伤，现在他把这份悲伤挖掘出来，这样我们才有勇气共同面对新的伤痛。他是在保护我。这么多年来，我一直以为他的青春期从未结束，但事实是，他的青春期早已结束了，而且结束得太快。他一直像个被时间定格的孩子，但在医院的那一刻，我看到了新的一面。在这一切的背后，是一颗父亲的心在跳动。

我在人工智能领域的第二个十年已经来到尾声，在谷歌的第二年也即将结束，我感到前所未有的不安。我所在的领域正处于混乱之中，而这种混乱似乎也渗透到了我的内心。我也逐渐意识到，一种模式似乎定义了我的人生。无论情况有多么艰难，都会有一些事情唤醒我，让我思考在这一切之中，生而为人究竟意味着什么。每一次，我都心怀感激。

不管在何种场合，关于职业伦理的对话都需要花费一番心思，但有一次讨论让我尤其紧张。那是 2018 年秋季的一天，我站在一间拥挤的会议室里，到场的都是现场向我汇报工作的工程师和产品经理。在回答团队提问的时候，我感觉就像在高空走钢丝。不管是我们行业还是其他行业，都经历了太多动荡，从文化到政治，我觉得早该进行反思了。

我开口讲话，句子之间有很长的停顿：「从我记事起，我就对物理学充满热爱。但是，科学之美与曼哈顿计划等事物紧密相连。这就是现实。人工智能也有自己的隐患，无论是机器人杀手，还是大范围的监控，甚至只是通过自动化让我们 80 亿人失业。这些都是可怕的事情，值得我们担心。但它们也是极端情况，不太可能明天就发生。」

我再次陷入长时间的停顿，酝酿着下一句话。

「我想，这就是问题真正变得棘手的地方。因为在此期间，有太多其他事情需要考虑。既有许多积极的方面，也有很多负面的因素，有些事情可能明天就会发生。所以，我希望你们能理解我们所面临的机遇。无论接下来会发生什么，我们都要在其中发挥作用。我们必须认真对待。这就是伦理框架的重要性所在。它可以帮助我们在迈出每一步之前进行评估。」

会议室里安静了片刻。

「嗯，我能问个问题吗？」会议室最角落里传出一个声音。这声音来自谷歌新聘用的研究科学家，她才华横溢，技术水平很高，最近刚从世界最顶尖的学校毕业。然而，听起来她有些胆怯。「‘伦理框架'这个概念……」

「请说。」

「具体是什么意思？」

这个问题比我想象的更为基础，也许我们每个人都需要如此发问。

加入我们的团队，利用大数据、分析和人工智能，帮助本地单身人士找到真爱！正在招聘中！

我在后座上眯着眼睛看着国道 101 上的另一块广告牌。我开始怀疑，人工智能的真正威胁是否在于除了人工智能，我们已经不可能再做其他广告了。自从几个月前和团队讨论了我们工作的伦理问题，这个问题就一直萦绕在我的脑海中。同事的声音打断了我的思绪。

「嘿，看看这个。」他边说边递给我几页打印好的文件，「这是公关团队整理的谈话要点，我们可能会用到。」

清晨时分，我们的车随着向南行驶的车流缓慢移动。我低头看了看材料，露出微笑，但让我精神振奋的并不是纸上的字。我们正在前往山景城，要去参加谷歌一年一度的传统招聘活动，这是我第二次参加了。谷歌会让数百名来自世界各地的暑期实习生聚集到 Googleplex，与领导层会面，帮助他们更深入地了解自己的职业发展道路。对公司来说，这是一次招聘活动。而对我来说，这是一个可以远离公司事务的好机会，唤起了我作为教育工作者最美好的时光。满屋子都是聪明、年轻、有远见的思想家，而我将有机会跟他们交流。

在谷歌，我通常很乐于照本宣科，这与我做教授时畅所欲言的风格完全不同。作为谷歌的发言人，意味着要对众多高管、公关顾问甚至律师负责，因此不按规定行事的想法会让我感到非常害怕。我的发言通常都是围绕人工智能和商业的老生常谈，彬彬有礼地讲给这个记者、那个记者或一群分析师听，不会出任何纰漏。我几乎到了熟能成诵的地步。

但身处这个奇怪的时代，我的内心渴望变革。我的思绪又回到了与团队的会议上。最后一个问题反复出现：「伦理框架」到底是什么意思？我越思考，就越觉得自己想得并不清楚。我自己对「伦理框架」的大部分概念源于非传统职业生涯中的意外收获：在加州理工学院与克里斯托夫一起向机构审查委员会提出建议；多年来在医院与像阿尼这样的人合作，陪同医生查房，倾听护士的关切，从而加深了对他们的了解；家中一直让我担心的父母；我青少年时期的移民生活。

一个严峻的事实是，医疗等领域拥有经过几个世纪甚至几千年的时间建立起来的规范、先例和伦理基础；其伦理基础以生与死这一无法回避的现实为依据。相比之下，人工智能还处于发展的早期阶段，其本身几乎没有明确的伦理准则。我们领域的自我认识之路才刚刚起步。因此，缺乏伦理框架的不仅仅是谷歌，也不仅仅是像那位提出问题的年轻工程师一样的个人，而是我们所有人。

我假装对公关团队准备的材料很感兴趣，扫视着用荧光笔突出显示的段落，但这一次我已经暗下决心：在面对 700 名未来最有影响力的科技工作者发表演讲时，无论结果如何，我都不会用别人准备好的发言稿；我决定要完全发自肺腑地讲话。此外，随着我的学术休假即将结束，我有非常多的反思要和大家分享。

在谷歌云工作的日子虽然常常让人迷失方向，但我却无比感激。我得到了科学家少有的机会：在最大范围内与受到我领域研究影响的人会面，从他们的角度来审视相关影响，哪怕只是一瞬间。两年来，我经常与金融服务、农业、医疗、能源、娱乐和交通等行业的初创企业，以及财富 500 强企业的高管、产品设计师和各类开发人员进行交流。这些经历给我带来的经验和教训比我想象的更清晰、更让人谦卑，也无比直接地提醒我，人工智能已不再是智力上的好奇探索，而是即将改变全人类生活的社会转折点。归根结底，我知道，如果一个机构不在某种程度上对人工智能技术加以考量，那么它将无法生存下去。这些迹象是明确无误的。我日复一日、周复一周、月复一月地反思我所看到的一切，试图更好地理解我们所面临的拐点，思考如何负责任地驾驭它。我为此感到自豪，也怀抱着乐观的心态，依然充满热情。但同时，我也深感这份责任从来没有像现在这样沉重。

无论我接下来要去哪里，我的旅程都将从我站在台上面对实习生时所说的话开始。过去两年，我一直专注于传递企业信息，现在我将不再担任企业信息的传声筒，我决定直抒胸臆。虽然我还没有准备好措辞，但我打算承认，前路崎岖而艰难，无论是学生还是教授，实习生还是首席执行官，没有人知道答案。有坏消息要面对，有难以接受的真相要处理，而且很可能会造成伤害。但也有好消息：现在一起面对还为时不晚。

登上讲台时，熟悉的紧张感在我的胃里翻腾。不过，我最喜欢的观众就是学生，看到他们的目光，我感到了安慰。

「下午好！」我对着麦克风说，「很高兴来到这里。」

那一天，只有这两句话是讲稿里的。

两周前，母亲刚刚接受了心脏外科手术，这是我们家与不敢想象的事件最近的一次接触。而就在现在，我已经从母亲的声音中听到了单调的藐视 —— 她的语调一如寻常。无论健康还是生病，年轻还是年老，这都是她的自然状态。

「这个话题我们都讨论 20 年了，飞飞。」母亲说道。

我转过头看了看屏幕，那封邮件依然清晰可见。在一封日期为 2018 年 6 月 7 日的邮件中，美国众议院科学、太空和技术委员会的副主任似乎在邀请我做证。对一个从未出席过国会听证会的人来说，这是一个令人生畏的邀请，而且听证会定在 26 日，距离现在还有不到三周的时间。我想到导致当前情形的种种因素：科技抵制浪潮、有偏见的人工智能等等，觉得接受邀请似乎是个绝对糟糕的主意。我知道母亲此时此刻是多么需要我陪在床前（不管她是否承认），因此心情更加糟糕。老实说，我只想让她替我做决定，让她坚称我现在离开是对她极大的不负责任。但她一如既往地没有打算给我提供便利。

「飞飞，你还记得我们在肯尼迪机场降落的那一刻吗？我们刚来到这个国家的时候？你爸爸没有来接我们，我们当时是什么心情？」

「当然记得。」

「我们在行李提取处的那几个小时多无助啊，都吓坏了。现在，20 年过去了，你收到了这样的邀请，要去这个国家的首都，要去为你最热爱的课题做听证了。」

「是的，但如果事情没那么简单呢？如果他们认为我是丑闻的一部分呢？如果……」

「那你就为自己辩护！你要告诉他们，你已经为这个国家奉献了 20 年，你的家人为了成为这个国家的成员付出了一切，你拒绝被当成外人对待！」如果这番话是出自别人之口，我一定会嗤之以鼻。用这样的语气面对国会委员会，我们大多数人只会更擅长想象，而不是实际行动。但我了解母亲，如果有人敢质疑她的人格，她肯定会这么说。我在想，是不是可以让她替我出庭做证。

「想想全世界有多少人对参加这样的事情求之不得。公开听证会。领导人和公民之间的公开对话。」

随着一声槌响，听证会开始了。此刻，已经没有回头路可走。

「科学、太空和技术委员会听证会现在开始。」委员会主席、弗吉尼亚州众议员芭芭拉·科姆斯托克（Barbara Comstock）对着麦克风淡淡地说，「早上好，欢迎各位来到今天的听证会。今天听证会的主题为‘人工智能 —— 威力越大，责任越大'。」

至少我听出了其中一句话是电影《蜘蛛侠》里的台词，说明我还是有一定能力的。即便如此，各种神经质的担忧还是在我脑海中纷纷闪现。无数双眼睛仿佛要钻进我的后脑，我开始重新审视把自己带到这里来的旅程的每一个细节。我的移民生活、我在日益分裂的技术发展中扮演的角色、科技抵制浪潮等等，所有的一切。

然而，随着听证会的进行，我越发觉得，我对这一时刻的过度忧虑是错误的。代表们逐个发言，每个发言都经过了深思熟虑，展现出孜孜以求的姿态，让我倍感惊讶。他们的声音带着好奇心、诚意和探索真实观点的意愿，尽管这些观点可能很复杂。渐渐地，我意识到自己并不是来接受严厉的质询的。在听证会上，我甚至有机会讲述母亲的病情，讲述她对我在人工智能和医疗交叉领域研究方面的激励和启发。我曾担心听证会会演变成对抗的局面，但结果只是一场对话，探讨的是更简单但更深刻的议题：未来几十年里，美国人的生活会呈现何种面貌？

当我提到母亲的时候，科姆斯托克众议员将目光从准备好的发言稿上移开，直接与我交谈，分享了她对美国人口老龄化所面临挑战的看法。

得克萨斯州众议员兰迪·韦伯（Randy Weber）发言时也询问了母亲的健康状况。我高兴地向他保证，她的病情很稳定，我已经可以离开她的身边来参加听证会，而且她现在就在病床上看着电视直播。「嗨，妈妈！」众议员科姆斯托克对着摄影机俏皮地插了一句，众议员韦伯也用温和的亲切语调表达了自己的祝福。这次交流出乎意料地充满了温馨，消除了我内心残存的恐惧。

我将一切美好感受转化成语言，介绍了我心目中人工智能的潜力和应有的样子。我讲述了启动 AI4ALL 公益项目的经历，以及项目启动以来，我学到了什么。我谈到了环境智能，分享了这个话题对我的意义。我还谈到了未来，表示相信人工智能可以为缩小世界各地的机会差距做出贡献。

这是我就人工智能话题进行过的最友好的对话。在伊利诺伊州众议员比尔·福斯特（Bill Foster）的影响下，我们甚至谈及了更专业的领域。他是一位拥有物理学博士学位的政治家，在从政之前曾在能源部费米国家加速器实验室工作。他的求知欲激励了我，也再次验证了人工智能是多么新颖的研究领域，比化学、生物学和物理学等更成熟的学科要年轻几个世纪。即使是现代人工智能，也更接近于牛顿出现前伽利略和第谷·布拉赫所处的时代，当时人们正在对各种现象进行观察、归纳和预测，但统一的模型尚未正式形成。我说，我们生活在一个令人兴奋的初生时代，仍在企足而待「古典」时代的黎明。

「感谢各位证人的证词和各位委员的提问。记录将保留两周时间。」众议员韦伯说，「听证会到此结束。」随着法槌的再次敲响，听证会结束了。

我心想：「好吧。」我眨了几下眼睛，似乎才意识到刚刚发生了什么。我终于可以自由呼吸了。

当我走回酒店时，对首都街头的气氛感觉完全不同了。我的肾上腺素水平开始下降，思绪也变得更加清晰。我感觉更像真正的自己了。但我仍然没有方向，不知道接下来应该追随怎样的北极星。

我重新打开手机，信息通知声近乎不断。我没有查看消息，而是给西尔维奥打了个电话：「嘿，妈妈怎么样了？有什么新消息吗？」

「你妈妈很好，我刚给护士打电话确认了一下。你自己呢？」

「据我所知，我活下来了。你觉得怎么样？」

「我觉得一切都很顺利。」他说，「我这辈子都没看过这么长时间的 C-SPAN [注：C-SPAN 是美国的一个有线电视和卫星电视网，直播和录播美国国会听证会、白宫新闻发布会、政治活动以及其他与公共事务相关的内容。—— 译者注] 直播。我看不出你有多紧张。」

谢天谢地。不只是我一个人这样想。

「但你知道吗？可能是电影看多了，让我产生了错误的想象，我觉得你的听证会也没想象的那么刺激。」他笑着补充道。

我笑得比想象中更大声。

听证会终于落下帷幕，而我还在想象听证会可能会发生的各种情景。会议时间本可以更长，本来可以有更多的证人、涉及更广泛的专业知识；会议议程可能涵盖更多议题，会议成果也可能以更多的形式公布。但是，即使是「更长」和「更多」等词语，也让人感觉言不尽意。要探讨的话题实在太多了。

此外，我们仍身处一场全球风暴之中。每天似乎都有新的头条新闻报道自动化对全球劳动者构成的威胁。随着人工智能在监控领域的应用日趋成熟，记者和人权活动家的担忧与日俱增，对隐私和个人尊严的古老威胁也在现代社会出现。尽管最初出现了强烈抗议，但算法偏见仍然笼罩着整个人工智能技术，此外还有往往与算法偏见相关的代表性问题。

我曾经把人工智能视作纯粹的科学，而现在，我用了很多不同的词来形容其化身：「现象」「颠覆」「谜题」「特权」「自然之力」。但当我穿过首都的街道返回酒店时，一个新词占据了我的思维。如今，人工智能是一种责任，是我们所有人共同承担的责任。

我确信，这是一个值得面对的挑战。深度学习飞速发展，每一年都感觉像是要面对一个全新的领域，其应用的深度和多样性增长得如此之快，甚至全职研究生和博士后也很难跟上文献的步伐，更不用说教授们了。可能性无穷无尽，挑战也永无止境。即使在这样一个黑暗的时代，人工智能也具有无与伦比的激励力量。面对全球亟待解决的问题，面对具有历史意义的机遇，面对可能需要几代人的努力才能揭开谜底的未知，真正解决所有问题的答案远远不是公司战略或学术课程所能提供的。

是什么让硅谷的公司如此强大？不仅仅是它们数十亿美元的资金或数十亿用户，也不仅仅是因为它们拥有惊人计算能力和数据储备，让学术实验室的资源相形见绌。它们之所以强大，是因为成千上万个才华横溢的人在同一个屋檐下共同努力。但公司只能利用这些人才，而无法塑造他们。我一遍又一遍地看到类似的情况：才华横溢的技术专家几乎可以建造任何东西，但问及工作的伦理问题时，他们却一脸茫然。

是时候重新评估人工智能教育的各个层面了。未来几年，从业者需要的不仅是专业技术知识，他们还必须了解哲学、伦理学，甚至法律。他们需要看到阿尼确保环境智能团队所看到的一切，他们需要将其融入众多学科中。研究工作也必须不断发展。在经历了这一天之后，我知道我们需要一种新的政策方法，首先要对民选官员（就像我刚刚遇到的那些政府官员一样）进行人工智能方面的普及教育。

想象空间是巨大的，但愿景需要一个重要的纽带串联起来，这个纽带就是大学。早在有人利用人工智能谋取利益之前，人工智能就已经在大学里起步了。在大学校园里，仍然最有可能感受到某些意想不到的研究突破带来的火花。感知机、神经网络、ImageNet，以及后来的很多东西都出自大学。我想建立的一切都已经在那里扎下了根基。我们只需要加以利用。

我们要从根本上重新构想人工智能，使其成为以人为本的实践，这个共同的目标就是下一颗北极星。在我看来，与其说这是旅程方向的改变，不如说是旅程范围的扩展。人工智能一直以来都追求科学性，而现在，它必须也追求人性。人工智能应该秉承最优秀的学术传统，保持合作和敬畏，同时不惧怕直面现实世界。毕竟，星光是多样的。一旦白色的光辉展开，各种颜色就会发出耀眼夺目的光芒。

12 下一颗北极星

The Next North Star

人工智能的未来仍然充满不确定性，我们有很多理由保持乐观，也同样有很多理由感到担忧。但一切都源于比单纯的技术更深层次、更有影响的问题：在我们创造的过程中，是什么在激励着我们的心灵和思想？

再次回到讲台上的感觉真好。

英伟达礼堂灯光柔和而中性，却充满了活力。礼堂里座无虚席，求知若渴的学生们有的坐在地板上，有的坐在楼梯上，还有的背靠后墙，双腿交叉，膝上放着笔记本电脑。此外，还有数百人在远程加入课堂，总人数有 600 左右。那是 2019 年的春天，是「CS231n：卷积神经网络视觉识别」课程开设的第三年，选课人数呈爆炸式增长。这门课很快就成了我最喜欢教授的课程。

站在讲台上，我想起了在普林斯顿大学读大一时的情景，当时我怀着敬畏之情第一次进入拥挤的礼堂，匆忙寻找座位。我还记得，我的内心充满了期待，当闲聊声逐渐消散，教授出现时，他仿佛超人一般瞬间征服了全班同学。如今，我成了站在讲台上的那个人，而现在我才意识到，原来我们都是彻头彻尾的普通人。我们也许略有成就，但依然有弱点，依然会犯错，而犯错的方式是学生时代的我无法想象的。不管怎样，课堂对我来说仍然是具有特殊意义的场所，而这样的时刻让我热血沸腾。

对于在场的许多人来说，今天是他们第一次接触到我钟爱已久的思想，而我也有幸成为传递者。跟随鲍勃（当时我还称他为萨贝拉先生）学习的经历依然历历在目，它提醒着我，一位老师可以在年轻人的生命中留下无比深刻的烙印。我们被赋予了分享一种特殊喜悦的权利：学习知识的快感、新的可能性带来的冲击。当然，这种感觉不会持久，因为学习的喜悦最终会因为职业发展、出版要求、求职面试，甚至风险投资和收入预测而变得复杂。但在眼下的时光里，思想才是唯一重要的事。也许礼堂里的一些人即将发现自己有了值得追寻的目标。

我必须承认，自从我上次在大学授课以来，人工智能行业已经发生了翻天覆地的变化。在此期间的几年里，我亲眼见证了太多事情。我看到了谷歌的会议室，巨大的数据中心如仓库般大小；我走进过医院，也曾在华盛顿特区的街道上忐忑不安地穿行。现在，人工智能依然是我最热爱的科学，不过它已经超越了纯粹的科学范畴。无论这些学生将来会成为研究人员、产品设计师、企业高管、政策制定者，还是从事其他我无法想象的职业，他们都将继承巨大的责任。

我高声说道：「无论是解决数据中的偏见，还是保护医院里的病人，这一切的共同点是我们的技术如何对待人，尤其是如何保护个体的尊严。‘尊严'，这是我一直强调的关键词。最重要的问题就是，人工智能如何才能尊重人的尊严呢？这个问题是一切研究工作的立足点。」

这并不是我事先准备的最周全的时刻，一些听众可能会觉得有点意外。但我的话都发自内心，我也知道，这不会是我最后一次谈论相关问题。

「以人为本的人工智能。」这个词我琢磨了好几个月，现在终于说了出来，「我一直这样表述自己的理念。我希望这个词能恰如其分地诠释我今后的职业生涯。我希望在未来的岁月里，‘以人为本的人工智能'对你们所有人都能有一定的意义。」

下课后，学生们排起了队，来询问后续问题 —— 课程的第一天通常会是这样。长长的队伍从教室前方的讲台一直蜿蜒到了后墙。

「您好，李教授。」一个学生走到队伍前面时，向我问好，「我对深度学习特别感兴趣。我已经读了所有我能找到的书。」

「我也觉得深度学习非常激动人心！你选择了一个很棒的领域。」

「ImageNet 是您做的，对吗？」

「我得到了很多帮助，但没错，是我做的。」我笑着说。获得知名度从来不是投身科学的好理由，但来自他人的积极反馈总是让人感到欣慰。

「我想知道，从那以后您有过什么别的想法吗？」

哎哟。良好的自我感觉到此为止。

当然，这就是本科生的魅力所在。他们往往是笨嘴拙舌，但却非常善于开门见山。我本来想分享一些我的实验室正在研究的想法，但在最后一刻改变了主意。

「我确实有一些新想法。它们还处于早期阶段，不过我对此持乐观态度。事实上，我刚在一分钟前提到过。」

「您是说，以人为中心的人工智能？」

「以人为本。」我笑着回答，「至少，我认为是这样。具体名称我还在想。」

「嗯……」学生挠了挠头，「听起来很有意思，只是我没想到会在这样的课堂上听到。我很好奇，伦理、社会与编写代码之类的工作有什么关系呢？」

盖茨计算机科学大楼给我的感觉既宏伟又内敛。大厅里天花板高耸，地面上铺着大理石，像博物馆一样回响，拱形剧院大小的教室恰如其分地向思想的力量致敬。但我最熟悉的是楼上狭窄的走廊，这里就是我的实验室和斯坦福大学人工智能实验室的所在地。现在，大楼的一层翻新翼楼有了新的变化，成了斯坦福大学以人为本人工智能研究院（Stanford Institute for Human-Centered Artificial Intelligence，简称「斯坦福 HAI」）的总部。

斯坦福大学的计算机科学院系属于美国最早的一批计算机院系之一，能在其核心成立一个明确的人本主义组织，其象征意义令我倍感振奋。斯坦福 HAI 目标远大，旨在成为跨学科合作中心。这种雄心并非停留在诗意的愿景上，而是已经成为现实。在日常的任意一天，我都很可能遇到像斯坦福大学法学院的何恩文（Dan Ho）、政治学教授罗布·赖克（Rob Reich）、人文学科教授米歇尔·伊拉姆（Michele Elam），或者从弦理论物理学家转行成为计算神经科学家的苏里亚·甘古利（Surya Ganguli）这样的人物。他们都欣然同意成为斯坦福 HAI 的一员，直接与人工智能专业的学生和研究人员合作，探索我们领域之间的交叉点，分享他们在职业生涯和生活中积累的专业知识。我们甚至吸引了来自校外的合作伙伴，包括麻省理工学院的著名经济学家埃里克·布林约尔松（Erik Brynjolfsson）。他横跨美国，来到斯坦福大学，就是为了帮助斯坦福 HAI 更好地理解人工智能对就业、财富和现代世界权力集中的影响。有时，我感觉整个学科似乎正在重生，其活力水平甚至超出了我几年前的想象。

很多合作都改变了我对未来可能性的思考，其中一次合作尤其重要。十年前，我第一次见到约翰·埃切门迪，当时他还是大学教务长，而我则是来自东海岸的移民，正痴迷于尚未完成的 ImageNet。在接下来的几年里，我们成了邻居和朋友，我对他作为学者的深厚学识也愈加敬佩。不仅如此，在多年的管理生涯中，约翰对高等教育领域的内部运作方式（好的、坏的，甚至是卡夫卡式的）也积累了丰富的专业知识。他完全知道如何才能把斯坦福 HAI 那些看似不太可能实现的愿景变为现实。对于以人为本的人工智能，他不只是嘴上讲讲，也不只是宣扬其优点，而是要一砖一瓦地倾心构建。因此，当他同意担任斯坦福 HAI 的联合主任，与我并肩作战时，我知道我们的确有机会让研究院取得成功。

在我们的合作成果中，我个人最喜欢的是国家研究云计划（National Research Cloud，NRC）。国家研究云是一个完全由公共资金和资源（而非营利部门）支持的共享人工智能开发平台，目标是让全世界的学者、初创企业、非政府组织和政府都能开展人工智能研究，从而确保我们的领域不会永远被科技巨头或者我们这样的大学所垄断。

两年前，国家研究云平台还只是个想法而已。如果没有斯坦福 HAI，它可能会永远停留在理念的层面。斯坦福 HAI 包括了法律和公共政策专家的多元化团队把这一概念变为使命。特别是约翰，他利用自己职业生涯累积的宝贵人脉资源，招募全国各地的大学组成联盟，这是我在学术界见过的最了不起的联盟。经过了一系列的思想交流、建议磋商、跨国飞行和理性辩论，他很快就形成了完备的立法蓝图，并将其提交给了国会。要使人工智能成为真正具有包容性的追求，我们还有很长的路要走，但国家研究云平台这样的成就是朝着正确方向迈出的重要步伐。

2020 年 9 月，在距离我们初次对话近十年后，我和阿尼发表了题为《用环境智能照亮医疗保健的黑暗空间》的论文，对我们的研究进行了全面的回顾，并介绍了我们对智能传感器的完整构想。智能传感器可以扩展医生和护士的感知范围，帮助他们以前所未有的规模和一致性应对医疗保健环境中的混乱状况。

论文描述了环境智能在医院的各个场景中可以发挥的作用，包括改善老年人护理、协助慢性疾病管理、识别精神疾病症状、在整个手术过程中跟踪手术工具的使用、在整个轮班过程中提高临床医生的卫生状况等等。论文没有发表在专注于计算机科学、人工智能或信息处理的期刊上，而是登上了《自然》杂志 —— 这也许是整个科学领域最杰出的一大期刊。这提醒我们，最好的研究往往不是在我们各自领域的象牙塔中孤立完成的，而是在科学的整体共享空间中实现的，研究人员应该毫不犹豫地在全球范围内展开跨学科合作。

我为这项工作深感自豪，但前路依然漫漫。就在《自然》杂志发表这篇论文的几个月后，12 月份的《柳叶刀》（TheLancet）杂志发表了一篇题为《在医疗机构中使用环境智能的伦理问题》的反驳文章。这篇文章直言不讳、推理透彻，对我们工作的意义进行了公正而严谨的审视。用作者的话来说，环境智能在提升医疗服务水平方面的潜力与「一系列伦理问题」同时存在，其中很多问题涉及大规模的数据收集和新的隐私隐患等方面。文章还进行了更深入的哲学探讨：在这种沉浸式、分散监控技术的环境中，知情同意的本质究竟是什么？虽然读到对自己研究成果的评论文章总会让人心里颇不是滋味，但这篇文章中呈现的正是人工智能所需要的伦理论述，我对其中的大部分内容深表赞同。

环境智能很可能永远是我实验室的研究重点之一。每当我看到父母，就能想起为什么这项研究对我来说如此重要。正因为如此，即使是现在，我也会每天抽出时间来了解最新的实验、试验和监管动态。过去几年，人工智能领域在物体识别方面取得了许多突破，针对照片甚至视频生成的描述已与真人无异，发展速度之快令人窒息。然而，回顾过去，一条共同的主线越来越难以忽视：尽管技术非常先进复杂，但其本质都是被动观察；无论具体形式如何，其实都是算法在告诉我们它看到了什么。我们的模型学会了观察，有时观察得非常细致、非常准确，但也仅此而已。我最近常常思考，除此以外，一定还有什么更有意义的事情。

咖啡时间结束了，我和一个学生手里拿着带盖纸杯，走回实验室。

「嘿，你还记得几年前你第一天上课时问了我一个什么问题吗？我很好奇你是不是一直记得。」

「对，我还记得。」他微笑着回忆道，「我问你伦理和人工智能有什么关系。」

「怎么样？」我报以微笑，「你觉得自己找到答案了吗？」

他叹了口气，抬头望着天空，耀眼的光彩正在渐渐褪去，天色傍晚。

「说实话吗？还没有。我肯定思考过这个问题，不想是不可能的。新闻上天天都在报这些事。我甚至还上了赖克教授的课。」

他指的是「计算机、伦理和公共政策」这门课，课程是由计算机科学家迈赫兰·萨哈米（Mehran Sahami）、政策学者杰里米·温斯坦（Jeremy Weinstein）和政治学家、伦理学家罗布·赖克共同开设的（赖克仍然是斯坦福 HAI 的创始贡献者之一）。我点了点头。

「我知道从理论上来讲，这些东西很重要。」他喝了一口咖啡，「但有什么用吗？飞飞，我的机器人还不能从烤面包机里拿出面包呢。研究本身就够让人沮丧的了，而且感觉每个人都在不停地发论文。我已经在担心下一次会议和它的截稿日期了！我的研究成果还非常初级，我到底应该拿出多少脑力去研究伦理问题呢？」

这个问题很好。尽管人工智能在过去十年中取得了不可思议的进展，但很多研究仍处于起步阶段。尤其是机器人技术，这项技术是出了名的难，即使在深度学习普及的时代，机器人技术的发展步伐也相对缓慢。在这样的时刻，以人为本的人工智能可能很难让人接受。

「你知道吗，」我开始说道，「我当学生也不是太久以前的事，但那会儿，让计算机区分辨小猫和小狗都几乎还是科幻小说的情节。然后，深度学习在一夜之间改变了一切，我们的算法被用于我们曾经认为还需要几十年才能实现的领域。想想看，我们现在有多少人在谈论面部识别。记者、政客、活动家…… 突然之间，他们都提出了问题，而且都是好问题！这一切会导致更多的监控吗？会带来更有偏见的算法吗？甚至会导致人工智能武器的问世吗？一切都来得太快了。」

我们到了实验室。我在读卡器上刷了一下门卡，我们推开双扇门走了进去。

「我想说的是，」我总结道，「事情的变化可能会比你想象的要快得多。」

我知道我没有说服他，或者说没有完全说服他。虽然他心存疑虑，但还是很关注这个问题，一直在听我讲。愿意倾听就是一个好的起点。

新入行的人产生怀疑情绪是很正常的。但在实验室里，以人为本的精神随处可见，白板上还留着前一天晚上的项目笔记，这个项目的目标是在保护信息所有者隐私的同时，利用敏感信息对神经网络进行训练；另一个类似的项目则是在不影响最终模型有效性的前提下，将图像数据集中的人脸进行模糊处理。

我们甚至也开始用批判的眼光审视自己的研究成果。ImageNet 包含了我们最初从互联网上搜罗的数百万张照片，我们通过研究，对数据集吸收的偏见（包括种族、性别和性取向）进行量化。在研究结果的指导下，我们替换了大量图片，以更加平衡地展现人类群体的全貌，并删除了具有冒犯性的类别标签。

也许最鼓舞人心的 —— 至少对我来说 —— 是我们的工作从未如此贴近现实世界。一位初级研究员的机器夹不起吐司固然令人遗憾，但除此之外，这十年来，机器感知领域的复兴已经从根本上改变了机器人技术，现在已经很难将其与人工智能本身区分开来。仿佛是为了说明这一点，金属长凳上摆了两条光滑的机械手臂，它们的名字非常亲切，一个叫作「查理」，一个叫作「艾达」，正在耐心地等待下一次训练。如今，它们就像任何算法一样，已经成为我们实验室工作不可或缺的一部分。

当然，硬件再先进、再亮眼，也只是达到目的的一种工具。因此，我们工作的指导原则依然关注人类的福祉，而不仅仅是追求程序的效率。这就是我们与数字经济实验室合作背后的理念。数字经济实验室是斯坦福 HAI 下属的成立不久的研究小组，这个小组利用美国劳动局的调查结果，以更好地了解人们对于自身工作价值的看法：他们在哪些方面欢迎自动化带来的便利，在哪些方面认为自动化的渗透具有威胁性，甚至是非人性化的。我首次意识到这种区别，是在跟阿尼一起研究环境智能的时候。我认识到，人工智能应始终致力于提高人类的能力，而不是与人类竞争。现在，这一理念成为我们实验室的基本价值观。这种价值观究竟意味着什么，这是每个研究人员都要自己回答的问题，但令人振奋的例子比比皆是。例如，我们实验室最重要的工作之一，就是对住宅、办公室和医院等日常空间进行极其细致的三维建模，而每个空间都有各种不同的种类、平面图和风格。我们努力让算法沉浸在人们生活和工作的环境中，沉浸在智能机器可能发挥最大作用的应用场景中，尤其是帮助身患疾病和残疾的人群。一个相关项目通过使用虚拟现实头盔和运动跟踪手套，帮助研究人员捕捉有形、有意义的任务（如叠衣服、准备食物等），并对动作进行数字编码，由此创建评估机器人性能的基准。还有一项研究探索了新的机器学习方法。研究人员设计出了具有天生好奇心的数字代理机器，并将其置于鼓励它们玩耍的虚拟环境中，因为玩耍是儿童与周围环境建立直觉联系的重要方式。

每一个故事都代表着一个变化 —— 我们对数据的看法发生了变化，对数据的期望也发生了变化。我们曾经试图给算法类似百科全书式的意识，希望算法可以识别所有的类别和事物，而现在，我们的目标更为广泛。我们想对万事万物所蕴含的空间、时间甚至意义有更深入的了解。我们的目标不仅仅是数量上的增加，还有细节和细微差别的扩展。新的数据处理方法不仅仅是简单的整理和编目，而是要模拟整个环境，模拟在环境中展开的行动。这就是为什么随着技术复杂性出现爆炸式增长，我们研究背后的人本主义也在不断发展。要形成对现实生活的整体观，为了创造比以往任何时候都更加真实的世界表征，我们需要深度和保真度，而在我看来，即使目前最先进的技术也达不到这种需求。因此，我们再次热血沸腾，迎接挑战。我们再次需要进化。

当然，进化的确切形式仍是个谜，但耐人寻味的蛛丝马迹已经初露端倪。随着进化所需的数据集规模日益增长，组织足够的人力所涉及的成本、时间甚至伦理问题不断增加。近年来，更具影响力的发展之一是出现了越来越多的模型训练新方法，这些方法可以突破人工整理数据集出现的瓶颈。模型的数据处理能力主要包括模型规模、并行操作的能力，以及自主识别有用模式的能力（文献中称之为「注意力」）等方面。模型在数据处理方面的进展使得用大规模数据集进行训练成为可能。有时，数据集的规模甚至构成了互联网的很大一部分。以文本为例，训练数据通常包括整个维基百科、各大图书馆的书籍和学术期刊，甚至是像 Reddit 这类在线论坛的历史帖子。在对每个单词、空格和标点符号进行分析之后，就可以生成人类语言的统计模型。这个模型是如此庞大，却又如此浓缩，只需要简短的提示，就可以让想法的种子变成茂密的参天大树，将一句话（无论是问句、陈述句还是对话）扩展成一篇洋洋洒洒的生动散文。这些模型现在通常被称为「大型语言模型」（Large Language Model，LLM），其所呈现的语句极为流畅，与人类的语言能力惊人地接近，让读者很容易忘记自己阅读的文字其实并不是真人写的。

经过多年的计算机视觉研究突破，大型语言模型正在推动自然语言处理的复兴，也很可能预示着人工智能的下一个伟大时代即将来临。具体而言，一种称为 Transformer 的新型机器学习模型成为自 2012 年的 AlexNet 以来神经网络设计中最大的进化飞跃。Transformer 具备了所有让大型语言模型成为可能的必要特性：规模庞大，通过处理大量并行数据块来加速训练，并拥有极其复杂的注意力机制。不管怎么看，Transformer 都是一个里程碑，甚至可以说是一个转折点；它一经发布，就立刻展示出了惊人的能力，甚至连其背后的专家们都感到震惊，而这些进展至今都没有放缓。

初次接触到由大型语言模型生成的文本时，我感到非常超现实，不禁想起了当年与安德烈合作开展的研究。当时，我们看到人工智能写出一个完整的句子来描述自己看到的东西（尽管措辞略显笨拙），是多么兴奋啊。而仅仅几年后，算法已经成为文笔流畅的文字大师，可以回答问题、编写故事，甚至还能解释笑话。更重要的是，新兴的「多模态」网络不仅限于在文本上进行训练，还可以利用照片、音频、录音甚至视频进行训练，从而学会了生成不同形式的媒体内容。这种进展常常让人感觉比计划提前了一两代；在短短十年左右的时间里，算法已经从难以识别照片内容，发展到以超人水平进行识别，现在甚至可以创造全新的图片 —— 这些图片看起来跟真实的摄影作品无异，但完全是合成的，并且往往具有惊人的逼真度和细节。看起来，深度学习时代似乎已经让位于一场新的革命，生成式人工智能时代即将来临。

即使对我来说，生成式人工智能也经常看起来就像魔法一样。而这项技术的核心再次展现了大规模数据的力量。可以肯定的是，「规模」是其中的关键词。AlexNet 首次亮相时，网络参数为 6000 万个，刚好足以对 ImageNet 数据集进行合理解释，至少可以解释部分子集。相比之下，Transformer 的参数已经增长到数千亿个，足以利用文本、照片、视频等形式的数据进行训练。这无疑带来了无尽的工程挑战，但其中所体现的科学性却出奇的优雅。从杨立昆的邮编阅读器、福岛的新认知机，甚至罗森布拉特的感知机时代开始，这些可能性似乎就一直在等待着我们的发现。从 ImageNet 时代开始，所有这一切都存在于某个地方，蕴藏着巨大的潜力。我们要做的，只是把一个简单的想法变得足够宏大而已。

然而，我越来越感觉到，这样的解释只触及了技术细节，并没有回答更本质的问题。大型语言模型，即使是多模态的大型语言模型，可能也并不具备真正意义上的「思考」能力。看看就知道了：大型语言模型很容易出现荒谬的概念性失误，也乐于编造听起来合理但实际上毫无意义的胡言乱语。了解这些事实有助于我们避免过分迷恋模型的能力。然而，随着大型语言模型生成的文本、图像、语音和视频越来越复杂，真与假之间的界限愈加模糊。越来越多的评论家开始质疑，为我们敲响警钟：作为个人、机构，甚至社会，我们究竟有没有能力区分真实和虚构？当人们意识到这一切还只是 1.0 版本时，这种发问尤其令人警醒。

就这样，科技不断发展。算法语言表达的高级程度已逼近人类水平。机器人正在逐渐学会应对真实的环境。视觉模型不仅可以通过照片进行训练，还可以在全三维世界中进行沉浸式实时训练。人工智能能够像识别内容一样流畅地生成内容。与此同时，伦理问题在我们周围不断涌现，与人类经济社会发展的关联也日益紧密。但这就是科学一直以来的样子。随着旅程的展开，前路只会变得更漫长、更复杂。无穷无尽的分叉、不断扩大的视野、新的发现、新的危机、新的争论，故事永远处于第一幕。

曾经，我做出决定，要把自己的一生奉献给这个鲜为人知的领域；因为这个决定，我比想象中走得更远。因为历史的偶然，我这一代人亲眼见证了人工智能从学术奥秘转变为头条新闻。我因此有机会周游世界，与全球的领导者同聚一堂，并在最近几年中站在最大的平台上发表演讲。耀眼的灯光、绚丽的色彩、一排排的观众似乎可以无限延伸到地平线，这些都是难得的特权，每一个都是意想不到的荣誉。

但实验室仍然是我最喜欢的地方：荧光灯管嗡嗡作响，座椅硬邦邦的，咖啡早就不新鲜了，没完没了地点鼠标、敲键盘，记号笔在白板上发出吱吱声。自从 2012 年 AlexNet 诞生，自从 2006 年我和邓嘉创建 ImageNet，自从彼得罗把西蒙·索普的脑电图研究报告打印稿放在我桌上，发生了太多事情。「相信我，这是你想读的内容。」即使是现在，北极星依然照耀着我前行的道路。旅程仍在召唤，还有更多的目标等待我去追逐。

我时常回想起与彼得罗和克里斯托夫初次见面的情景，当时他们在我心中就是学术巨人。我很难想象有人会把我也看成是那样的人 —— 单凭我的身材，就可能让我失去「巨人」的资格。但在某种程度上，我确实有一点儿权威人物的气场。我的导师们教会了我如何善用威严：要将其作为一种感召，而不是障碍。对于每一个愿意通过个人努力来到这里的学生，我想告诉你们：如果你真的对这些事物充满热情，无论你是谁，无论你来自哪里，你都属于这里。让我们共同创造未来！

午后阳光明媚，太阳渐渐西斜，但空气依然暖和，我们躲在凉亭的树荫下，享受着宁静的时刻。母亲静静地坐着，满心欢喜地看着外孙外孙女在草坪上踢足球，他们奔跑着，笑声、尖叫声回荡。父亲尽力跟上他们的脚步，和他们一起欢笑，看着就像个年轻人。对以「玩」为毕生追求的父亲来说，成为外祖父后，他终于找到了适合自己的节奏 —— 这个角色对他没有任何要求，他只需要做爱玩的自己就好。

手机震动，我低头看了一眼，发现是斯坦福 HAI 的政策主管发来的信息。

国家研究云刚刚在参议院获得通过

这是一个更大法案的一部分

即将提交总统

一分钟后，我又收到一条信息，是琼·萨贝拉发来的，还附带了一段视频。我点击播放按钮，看到两双热切的小手撕开了配套的包装纸，露出两套《星球大战》乐高套装，我听到了兴奋的尖叫声。

「孩子们，你们应该说什么呢？」我听到琼在镜头外问道，「谢谢飞飞阿姨和西尔维奥叔叔！」两个声音高兴地齐声回答。

镜头里是鲍勃的两个孙子。他的书呆子气和想象力显然延续到了他的孙辈身上。但两个小家伙毫无掩饰的喜悦告诉我，鲍勃的内向性格已经消失无踪。我能想象到，如果鲍勃听到这样的话，脸上会露出怎样的笑容。

挂断视频后，我回到了群聊，里面有琼、她的儿子马克，还有我。几年来，我们在群里分享着个人的生活和成就：重要的里程碑、生日庆祝、膝关节置换手术后的恢复情况、新工作、新宠物、喜悦的消息、悲伤的消息，以及生命岁月中的点点滴滴。

在帕西帕尼高中的数学课上，我不安地向鲍勃求助，从此我们的生命开始相交，我的移民生活得以改变。现在，我们两个家庭横跨美国，三代人之间依然保持着紧密的联系。鲍勃是我的老师、我的知己、我的朋友；在我几乎无法表达自己的时候，他是我的救命稻草。萨贝拉一家的餐桌上总是摆着自制的布朗尼蛋糕，时至今日，这仍是我受到过最好的同理心教育。萨贝拉一家无疑是我自己家庭的延伸。我无法想象没有他们的生活，就像我无法想象没有父母的生活一样。这就是为什么十多年后，鲍勃的离去仍然让我感到心痛。但我们的对话从未停止过，他的记忆仍在倾听，我仍在向他倾吐心声。

关于这个国家，让我学到最多的就是与萨贝拉一家的交往。爱国主义教育从高中就开始了，历史课上的宏大叙事令人崇敬，却与移民群体真实生活的凄凉现状，甚至遭受的暴力形成了鲜明对比，所以这些课程从来没有真正触及我的内心深处。几十年来，我和其他人一样沉浸在紧张的局势中，面临党派纷争、文化断层、选举周期以及其他一切。我对这个国家最深刻的理解不是来自新闻，也不是来自某个论战家的专栏文章，甚至不是来自教科书，而是源于有幸结识萨贝拉一家。他们是我在这片土地上最珍视的人道主义典范，他们闪耀着人性的光辉，在我看来，这才是真正的美国精神。

推拉玻璃门发出橡胶摩擦般的吱吱声，我转过身来。西尔维奥朝我们走来，手里空空如也。

「午餐呢？」我半开玩笑地问道，肚子已经饿得咕咕叫了。

「答辩进行了很长时间。」他叹了口气，露出毫无歉意的微笑。他知道，我既能分享他的快乐，也能理解他的疲惫。

在过去的几个小时里，他在仔细剖析他最新的博士候选人的论文，质疑她的观点，听取她的解释，并最终授予她学位。不难想象，整个过程远远超出了预定的时间，西尔维奥被那种熟悉的激情紧紧抓住了。我们两个都是这样，一旦激情沸腾，就会久久难以平息。

我又看了一眼手机，发消息的都是熟悉的名字。最近的聊天记录里有奥尔佳和邓嘉，两人现在都在普林斯顿大学任教，依然活跃在计算机视觉研究的最前沿。尤其是奥尔佳，她是人工智能领域公平和透明的坚定倡导者，还把 AI4ALL 带到了自己的新校园。仍在加州理工学院任教的彼得罗也给我发来了信息，向我介绍他的博士生利用计算机视觉支持全球保护和可持续发展的工作。还有一条来自我十几年来的研究伙伴和朋友阿尼，他跟我分享了环境智能的最新进展。

无论我如何界定自己的身份 —— 是华人、美国人，还是名誉上的意大利人 —— 我早已摆脱了对「格格不入」的恐惧，因为我一路上遇到太多真诚的人，他们给了我太多善意。移民之路并不平坦，但我始终心存感激。

即使是母亲持续多年的健康问题，也不能简单地用幸运与不幸来衡量，其背后的故事要复杂得多。不可避免的事情还能拖延多久，才能让人觉得不再那么不可避免？近 30 年的旅程虽然坎坷，但我不得不承认，以不幸家庭的标准来看，我们家是幸运的。生活虽然艰辛，但我们并没有失去亲人，没有经历悲伤和哀悼，我们在一起度过了所有的时光，我不禁对此也深怀感恩。

这些天来，我发现自己时常陷入沉思。我经常想起父母的成长岁月，母亲被困在自我吞噬的文化中，而父亲则迷失在悲剧里，从来没有完全解脱。我还记得，当我们登上飞机离开我们熟悉的生活时，我看到母亲的双手颤抖不止；当我们在肯尼迪机场行李提取处等待时，夜幕降临，我和母亲被困机场，父亲却迟迟未到，我们的内心充满了恐惧；我想起干洗店里闷热的气息和嗡嗡的机械声；我想起第一次看到普林斯顿大学的情景。

回顾我的职业生涯，我相信，这段漂洋过海的经历给我留下了深刻的烙印。然而，直到现在我才意识到，这种烙印将继续影响我的研究和思考。我想到母亲，是什么样的紧张局势促使她孤注一掷、远走他乡？而如今，她竟然在位于帕洛阿尔托的自家后院里安度晚年。科学家的生活与移民的生活和冒险家的生活一样，对他们来说，「家」从来都不是个明确的概念。最好的作品总是在边界上诞生，在那里，思想永远被困在来去之间，由陌生土地上的陌生人探索，既是局内人又是局外人。但这正是我们如此强大的原因。独特的身份让我们保持独特的视角，赋予我们自由挑战现状的能力。

人工智能的未来仍然充满不确定性，我们有很多理由保持乐观，也同样有很多理由感到担忧。但一切都源于比单纯的技术更深层次、更有影响的问题：在我们创造的过程中，是什么在激励着我们的心灵和思想？我相信，这个问题的答案也许比其他任何问题的答案都更能决定我们的未来。很多事情都取决于问题由谁来回答。随着人工智能领域逐渐变得更加多元、更加包容、对其他学科的专业知识更加开放，我也越来越有信心：我们能正确回答这个问题。

在现实世界中，存在着一颗北极星，那是小熊星座中最明亮的恒星。而在思想的世界里，却存在无数个类似的导航指引。每一种新的追求，每一个新的痴迷，都悬挂在黑暗的地平线上，闪烁着耀眼的光芒，向不懈追寻的人们招手致意。这就是为什么我最大的快乐在于知道旅程永远不会结束，我也永远不会停歇。总会有新的事物等着我去追逐探索。对科学家而言，想象力就如同布满北极星的璀璨天空。

