李飞飞.(2024).2024096我看见的世界.(赵灿.译).中信出版社 => 1101 无人可控

## 1101. 无人可控

No One's to Control

此时，我们都处在一场全球风暴之中，我们要从根本上重新构想人工智能，使其成为以人为本的实践，这个共同的目标就是下一颗北极星。

「嗨，你是飞飞，对吧？」

我转身去看问话的人，他礼貌地做了个手势。

「我叫戴夫，」他伸出手和我握手，「前几天听到你在播客上的节目，忘了是哪一期了。你知道吗，我们风险投资公司一直在谈论人工智能，简直就是一刻不停。」他接着说，「就在过去的几个月里，我们已经完成了四个 A 轮融资，都是在这个领域。」

我笑了笑，不知道还能作何反应。那是 2014 年，风险投资的术语让我在自己的领域里感觉像个局外人。

「嘿，你见过杰弗里了吗？」他转过身向对面的另一个人招手，那个人穿的牛仔裤和羊毛套头衫看起来跟他的一模一样。

「杰弗里，过来过来，我想介绍你认识一个人！杰弗里是负责产品开发的副总裁，在……」

「好了，各位，请注意，我们可以开始了。」谢天谢地，一个声音从房间那头传来，打断了他，「我要感谢大家今晚的到来。学前班是孩子们人生的重要一步，今年我们为他们做了非常棒的规划。」

「一会儿再聊！」他挤坐在仓鼠笼旁边的小木椅上，低声说。

### 01

无论我们学术界如何看待人工智能，或者对其未来作何预测，有一点是不可否认的：人工智能已经不再由我们掌控了。十多年来，我对人工智能一直痴迷不已，它就像一层思想的外壳，悄然叠加在我的世界观之上。然而，到了 2010 年代中期，相关话题已经获得极大的公众关注，各种讨论铺天盖地、震耳欲聋。加州硅谷 101 号公路沿线的广告牌宣告着人工智能初创公司的招聘狂潮；在我的牙医候诊室里的杂志封面上，有关于人工智能的报道；开车换台时，还能从汽车收音机的谈话片段中听到关于人工智能的讨论；显然，在幼儿园家长会上，它也成了热门话题。

世界正在变得超现实。我和同事们穷尽职业生涯探索人工智能科学，但我们现在突然面对着「人工智能现象」（我还没有找到更确切的说法）。人工智能本身就充满了难以解开的谜团，现在，这项技术与各行各业、政府、记者、评论员甚至广大公众之间的互动突然激增，千丝万缕的关系与技术本身一样错综复杂。经过几十年的模拟环境开发和测试，人工智能已经进入现实世界的应用阶段。在人工智能的发展史上，充满了对其拟人化的尝试，但这些尝试带来的更多是误导，而非深刻的洞见。虽然我也不太愿意把人工智能明确地比作活的有机体，但不可否认，它已经进化出新的形态，躁动不安，嗷嗷待哺，渴望探索。

不到一年前，在我和安德烈的研究领域，谷歌迎头赶上的消息让我震惊不已，但如今却感觉已像陈年旧事。作为曾经的人工智能研究主力军，大学实验室现在已不是推动前沿发展的唯一机构。这已成为不争的事实。无论是在 GitHub 等平台上分享代码，还是在 Reddit 等论坛上讨论最新进展，我们都与谷歌、微软和脸书等科技巨头、遍布全球的初创企业、贪婪的风险投资人网络，甚至开源社区的软件开发人员共享繁荣热闹的景象。

有太多话题可以探讨。

2015 年，邓嘉和奥尔佳发表文章，回顾了 ImageNet 比赛迄今为止的影响，并分享了安德烈的研究成果：他估计人类在标注 1000 幅图像时的错误率约为 5.1%。虽然安德烈只是出于好奇才做的研究，但其结果却大大增加了比赛的刺激性。突然之间，算法不仅相互竞争，还开始与人类一决高下。2014 年，谷歌的神经网络分类器 GoogLeNet 的错误率仅为 6.67%，达到创纪录的最低水平，人类几乎要失去榜首地位了。

尽管 AlexNet 和 GoogLeNet 是计算机视觉领域的真正飞跃，但我们还远远未能了解其全部潜力。举例来说，我们确信网络深度是决定性能的关键因素，而 GPU 优惠的价格意味着我们终于有足够的处理能力，让深度达到前所未有的水平。然而，简单增加神经网络层数并不是万能之策。在初始阶段，网络深度的增加会提高图像识别准确率，但很快就会到达临界点，此后就是收益递减。我们怀揣着远大抱负，构建的神经网络越来越大，却在不经意间将网络变成了迷宫。过多的分层会破坏信号传递，导致训练过程停滞不前，使系统失去效果。

显而易见，要实现宏伟的目标难度很大，与投入多少硅片并没有直接关联。这意味着即使在现在，我们的网络也无法吸收和消化 ImageNet 等大型数据集，没有充分利用其潜力。我们需要改变现状，不断进化，不仅在规模上，更在创新上。这正是我期望 ImageNet 挑战赛能带来的激励和感召。

我终于如愿以偿。2015 年，由微软的年轻研究员何恺明带头研发的深度残差网络（Deep Residual Network，ResNet）再次改变了比赛格局。ResNet 达到了惊人的 152 层，但对网络架构进行了扭曲，允许在训练阶段绕过其中的某些层，使得不同的图像对网络中较小的子区域产生影响。

虽然经过全面训练的系统最终会充分利用其深度，但在训练阶段，没有任何一个图片示例必须覆盖整个系统。这样的架构带来了两全其美的结果。一方面，增加层数可以提高性能，吸收更多数据 ——ResNet 使用的 ImageNet 数据量超过了当时其他所有的参赛算法；另一方面，在不降低性能的前提下，保持了信号自由流动所需的简洁性。ResNet 是教科书式的范例，充分说明了在人工智能领域，创造力是推动着辉煌时刻出现的力量。

然而，ResNet 的设计只是故事的一半。ResNet 的最终效果甚至远远超出了设计者本人的预期，还因惊人的性能而登上了《纽约时报》等主流媒体的头条。ResNet 获得全球关注是意料之中的事：它的识别错误率仅为 4.5%，远远低于安德烈估算的人类错误率。简而言之，视觉分类的挑战似乎已经迎刃而解，机器轻而易举地超越了它们的创作者，完成了几年前还几乎不可能完成的任务。多么令人惊叹的里程碑啊。然而，没过多久，我们就意识到这只是开始，更多的里程碑将会陆续出现。

嘿，你在关注 AlphaGo 吗？

你知道哪边能赢吗？

我该不该赌一把？哈哈！

我的第二个孩子刚刚出生，如果有什么能让我与外界隔绝至少一两个星期，那应该就是生孩子这件事了。但我才出院几天，信息就如潮水般涌来，手机一直嗡嗡作响，提醒着我，我并没有偷得浮生半日闲的好运气。

2016 年年初，媒体对 DeepMind 的关注不断升温。DeepMind 是一家总部位于伦敦的初创公司，正在筹备一场围棋大赛，参赛双方分别是围棋大师李世石和一台机器。在此之前，这家科技公司一直名不见经传（甚至我对它的了解也只是皮毛），而现在似乎变得家喻户晓。此前一年，谷歌大举收购各类人工智能初创公司，DeepMind 以超过 5 亿美元的高价成为其中最昂贵的交易。但比价格更令人难忘的是它的使命。「他们声称正在研究 AGI。」我记得有同事带着学者特有的世事洞明的笑意告诉我。

我完全能理解同事的厌倦之情。AGI 指的是「通用人工智能」（artificial general intelligence），是一种极其复杂、灵活的人工智能，不仅能完成图像分类或跨语种文本翻译等狭隘任务，还能模拟人类一切认知能力，如分析、创造等。虽然我无法确定这个词是何时成为专业术语的，但计算机科学领域以前肯定没用过它。毕竟，「通用」智能从一开始就是人工智能的全部意义所在，前路虽长，但这并不意味着我们可以降低目标。对我们这些研究人员来说，AGI 这个新词听起来有些多余。但它读起来朗朗上口，可以让外界清楚地了解我们这个领域的终极目标，也让 DeepMind 在已经竞争激烈的生态系统中显得胆识非同一般。

我被各种问题狂轰滥炸 —— 学生、好友，甚至一些交情不深的朋友都给我发来消息，问我有没有什么预测可以分享。我确实没有，但当家里另一位人工智能教授突然拿着一瓶刚冲好的奶走进房间时，我忍不住也向他请教。

西尔维奥说：「嗯，两种可能性都有。早在 20 年前，深蓝就在国际象棋比赛中战胜了人类，」他似乎在心里算了一会，「准确地说，是 19 年前。」

书呆子就是书呆子。

「不管怎么说，」他继续说，「虽然围棋比国际象棋难很多，但仍然属于棋盘游戏。规则虽然复杂，但都非常直接明确，至少从数学角度来看是这样。」

他意识到自己越说越有教授的腔调了 —— 虽然我们说好了在家里不能这样，但经常做不到。他一边笑着，一边小心翼翼地把奶瓶放进热奶器里。我们几乎同时说出了接下来的话：「跟冲奶完全相反！」

他说得没错。围棋策略的组合数量大到无法想象，关于如何就此建模，我们俩可以侃侃而谈，但像准备一瓶婴儿配方奶，再把奶瓶放到热奶器里这样简单的事情，却依然是机器人专家的「圣杯」—— 尽管在严格控制的实验室条件下，冲调完美配方奶粉的问题已经得到解决，但在实验室之外，依然存在巨大挑战。

1997 年，国际象棋大师加里·卡斯帕罗夫（Garry Kasparov）与 IBM 的超级计算机深蓝（Deep Blue）进行国际象棋比赛，计算机正式打败了人类，消息一出，轰动一时。但是，相对于国际象棋，围棋的复杂性不仅体现在规则上，还体现在策略组合的可能性范围上。事实上，围棋的规则决定了棋子所产生的可能性范围极大：棋盘上 19×19 的格子可以带来的组合总量多达 10 的 360 次方。这个巨大的数字超过了宇宙中的粒子数量，且超过许多个量级。要下好围棋，人类需要通过毕生的实践不断培养直觉能力，在每个回合都要把理论上的无数种选择缩减为可操作性的若干种落子选择。而就算是最先进的人工智能，其认知深度也不足以复制这种能力。

的确，寻找最佳落子方法所需的计算量是巨大的，因此使用计算机下围棋难，难于上青天。尽管如此，我们仍有理由保持轻松乐观，因为围棋遵循一套明确而客观的有限规则，胜负的标准就是看哪一方的棋子在棋盘上占的地盘更大。所以与真正的登月相比，围棋可以说是相对简单的。

「即使它赢了，」西尔维奥补充道，「要想做意大利千层面的功夫超过人类，机器还需要一段时间。」

就这样一个简单的回答，西尔维奥让我对现代人工智能有了更深刻的认识，同时也让我感到饥肠辘辘。

事实上，AlphaGo 确实赢了，全球媒体纷纷报道，关注度达到了巅峰。整个世界为之沸腾，而亚洲的反应尤其狂热。对我来说，体现热度的最直接指标出现在个人生活层面。

「飞飞，我的老同学们问我你知道 AI 下围棋是怎么回事吗？」爸爸给我转了一大堆他国内的朋友发来的微信，最近这样的信息感觉没完没了。「他们听说我女儿是 AI 教授，都在问我呢！」新闻头条是一回事，但当父母和他们在国内圈子的同龄人都在讨论人工智能时，说明世界真的变了。

在这个时期，人工智能领域的转折点层出不穷。即便是最引人注目的突破，我们也不陌生，因为我们为人工智能技术奉献了一生，现在是开花结果的时候了。ResNet 和 AlphaGo 等的故事激发了各界的对话和讨论，也激励我们在自己的研究中更进一步。我意识到，人工智能的新时代不仅仅是一种现象，因此我忍不住借用了硅谷最喜欢的一个词，因为正如他们所言，这是一场「颠覆」。

我办公室里的那个小小的红色沙发，曾经见证了我们实验室众多声誉卓著的项目的诞生，如今它成为我敦促年轻人多读文献的地方。我经常要求他们，在进行研究的同时，务必为人工智能科学赖以建立的基础文献留出空间。时代不断加速发展，每个人的注意力都集中在了更热门的信息来源上，而传统文献却一直被忽视。我注意到了这个问题，起初感到恼火，后来又心生担忧。

「请大家不要每天只从 arXiv 下载最新的预印本作品了。去读一读拉塞尔和诺维格的著作，去读明斯基、麦卡锡和威诺格拉德的书，读哈特利和西塞曼的作品，读一读帕尔默写的东西。不要因为这些材料距离现在时间久就忽略它们。我们就是要多读一些以前的东西，他们的理念经得起时间的考验，依然非常重要。」

arXiv 是涵盖物理学和工程学等领域学术文章的在线资料库，其中的文章尚未在学术期刊上正式发表，但会提前以未经编辑的预印本形式提供给对内容感兴趣的读者。几十年来，预印本一直是大学文化的固定部分。然而近些年来，人工智能发展极其迅速，每周都在发生变化，甚至整个领域会在一夜之间被颠覆。为了保持与时代同步，预印本已成为重要的资料来源。如果说要学生们等上几个月去读通过同行评议的论文都是过分的要求，那么几年前编写的教科书，甚至是整整几代人之前编写的教科书被束之高阁，又有什么好奇怪的呢？

太多事情在抢占学生的注意力，文献只是个开始。科技巨头争相组建人工智能团队，公开大肆招揽人才，承诺的起薪高达六位数，有时甚至更高，还提供丰厚的股权待遇。机器学习先驱一个接一个离开了斯坦福大学，到了 2010 年代中期，连博士后都成了抢手人选。希望推出自动驾驶汽车的优步迈出了大胆的一步，从卡内基梅隆大学挖走了 40 名机器人专家，数量之多堪创纪录，几乎摧毁了这所大学的机器人研究体系。对我和同事们来说，光是目睹优步事件，就已经够难受的了，而对我的学生们来说，这件事似乎从根本上扭曲了他们对教育之意义的认识，因为他们年龄尚小、充满渴望，而且仍在寻求自己的身份和认同感。最终，这种趋势达到了顶峰 —— 至少对我个人来说是这样 —— 非常出乎我的意料。

「你真的要拒绝他们吗？安德烈，那可是全球最顶尖的学府之一啊！」

「我知道。但是我不能错过这个机会。真的很特别。」

安德烈已经完成了博士学业，即将进入人工智能史上最有前景的就业市场，即使对一个有志成为教授的人来说也是如此。普林斯顿大学给他提供了教职机会，这是我们任何一个同龄人都梦寐以求的职业快车道。然而，他却决定彻底离开学术界，加入一个没人听说过的私人研究实验室。

安德烈即将加入 OpenAI 的核心工程师团队。OpenAI 由硅谷巨头萨姆·奥特曼（Sam Altman）、埃隆·马斯克和领英首席执行官里德·霍夫曼（Reid Hoffman）共同创立，初始投资高达 10 亿美元，这充分证明硅谷对人工智能的突然崛起是多么重视，硅谷的杰出人物多么渴望在人工智能领域站稳脚跟。

OpenAI 推出后不久，我在当地的聚会上遇到了几位创始成员，其中一位举杯祝酒，但他的欢迎词颇有几分告诫的意味：「每个从事人工智能研究的人，都应该认真思考自己今后在学术界的角色。」他说这番话时没有一丝笑意，言辞中透露出明确而冷酷的信息：人工智能的未来将由那些拥有企业资源的人书写。在学术界受训多年的我想习惯性地反唇相讥，但我没有。老实说，我甚至都不确定自己是否反对他的观点。

谁也无法预测一切会走向何方。与大多数领域相比，我们的领域经历了太多起起伏伏，虽看似前程远大，但数度出师不利，「人工智能寒冬」一词就反映了其多舛的命运。但这次感觉不一样了。随着越来越多学者的深入分析，科技界、金融界和其他领域逐渐认可了一个术语：「第四次工业革命」。虽然流行语背后通常存在着夸张成分，但这个词的确名副其实，足以让决策者们铭记于心。无论是源于内心真正的热情，还是来自外部的压力，抑或是两者兼有，硅谷的高管层都在采取比以往更迅速、更大胆甚至更冒险的举动。我们即将见证这种企业理念将会带来何种结果。

「猿。」我的天哪。

这是雅虎图片托管服务 Flickr 在 2015 年 5 月自动生成的一个标签，用来描述 56 岁黑人男子威廉的单色肖像。雅虎的新技术立刻引发了各方强烈愤慨，可谓自取其祸。此后，这项技术接二连三出现失误：将达豪集中营大门的照片标记为攀爬架，把一位脸上涂有彩色粉末的白人妇女贴上了「猿」的标签。雅虎 Flickr 一经推出，即麻烦缠身。不仅是雅虎，到了 6 月，谷歌也陷入了类似的争议，因为谷歌照片服务将两个黑人青少年错误地标记为「大猩猩」。图像分类本已是老生常谈的成功技术，却在短短几周内变得非常复杂。

即使不是这些公司的员工，我们也很难不感到一丝罪恶感。虽然事故并非恶意，但这并不能让人感到宽慰。相反，无心之失所揭示的问题才更加令人不安：包括 ImageNet 在内的数据集由于缺乏多样性，导致了一系列意料之外的结果；未经充分测试的算法和存疑的决策又进一步加剧了负面影响。当互联网呈现的是以白人、西方人和男性为主的日常生活画面时，我们的技术就很难理解其他人群了。

有果必有因，正如记者兼评论员杰克·克拉克（Jack Clark）所言，问题的根源在于人工智能「男性之海」问题：科技行业的代表性不足，导致算法无意中带有偏见，在非白人、非男性用户身上表现不佳。这篇文章于 2016 年发表在彭博社网站上，是对人工智能伦理问题的最早一批讨论之一。此后，相关对话日益激烈。人们担心人工智能在做好事的同时（如支持残障人士、追踪森林砍伐、以各种新方式保护人类生命等），也有可能产生危害。

我想到了为打造 ImageNet 而挣扎奋斗的那些年 —— 即使在我们最具创造力和即兴能力的时候，也没有考虑到伦理问题。十年前，由谷歌和维基百科等组织的内容呈爆炸式增长，似乎极大地拓宽了电视和报纸等传统媒体提供的狭隘视角，为我们提供了一扇了解人类生活真实面貌的窗口。从某种程度上来说，它们确实做到了。然而，虽然一切看起来很生动，虽然我们的期望是如此热切，但所形成的图景还远远不够完整。

这个问题早就应该面对，但对话并不足以安慰我内心深处的工程师。显然，数据集不平衡是造成问题的重要原因，但还有无数其他因素值得我们考虑。模型本身是否存在问题？在依赖所有数据的算法架构中，是否隐藏着未被发现的弱点？可以促进训练过程的学习技术有问题吗？问题的数量超过了答案，而且这个差距越来越大。

这些问题也压在奥尔佳的心头。人工智能是以男性为主导的领域，作为少数女性，我们两个人多年来一直惺惺相惜，彼此分享着身为女性在人工智能领域的经历，也沮丧地发现，我们的经历非常相似。到了 2010 年代中期，奥尔佳忍无可忍，她下定决心，要么采取行动改变现状，要么离开学术界。她选择了前者，我们决定一起努力。

我们认为，从代表性问题的出现，到问题被大众真切地感受到，中间往往需要几年的时间。因此，我们向九年级和十年级的女生开放了斯坦福大学人工智能实验室课程。所有参与的学生都是经过精挑细选的，为期两周的人工智能速成课程虽然紧张，但实践证明，只需要一点点努力，就可以让每个一直被历史排除在外的参与者相信，她们同样属于这个时代、这个领域。邀请少数人群参加人工智能课程的想法非常受欢迎，我们的项目很快就像滚雪球一样发展成为全国性的非营利组织，遍布北美各地校园，使命范围也不断扩大。很快，我们也开始向有色人种学生和经济困难学生等边缘群体提供类似项目。

在短短几年后，我们的项目就正式命名为 AI4ALL，甚至吸引了一些资金，梅琳达·弗伦奇·盖茨（Melinda French Gates）的 Pivotal Ventures 创投公司和英伟达创始人黄仁勋提供了一轮融资，让项目改头换面。这个旅程可能需要几代人才能完成，现在只是迈出了一小步，但我们实现了从无到有的跨越。此外，项目还能带来一丝安慰 —— 在业界追逐人工智能未来时，往往肆意而为，缺乏自省，而我们的努力能够保证，至少有一小部分人在逆向而行。

雅虎和谷歌等公司在全球的注视和评判下得到了惨痛的教训。亲眼看到这些事件提醒我们，仅仅对下一代技术进行投资，然后期望一切顺利是不够的。普林斯顿大学向奥尔佳提供了教授职位，她接受之后，开始着手扩展自己新实验室的研究议程，不仅包括机器感知的机械原理，还涵盖更广泛的计算公平性问题，尤其强调要「去偏见」。「去偏见」是遵循严格数学要求的正式操作，旨在对潜伏在数据中的偏差进行量化和中和。这种理念体现了对社会福祉议题的深切关注，有奥尔佳这样的人据此展开研究，我对未来的希望又开始增加了。

我全心全意地相信人工智能技术的价值，它具有揭示智能奥秘的潜力，也可以带来我和阿尼在医院工作时目睹的种种实际的益处。但是，哪怕是片刻的过度自信，付出的代价也会急剧上升。更糟糕的是，这个代价将由其他人承担，很可能是最脆弱的人群。人工智能已经走出了实验室，基本脱离了我们的控制。虽然新思想、新面孔和新机构的旋风令人振奋，但也带来许多新的担忧。对我们这样经费极其紧张的研究人员来说，对人工智能领域进行商业投资的承诺似乎是天赐之物；但商业资金以巨大的力量冲刷着一切，好像一场豪赌，让人感到的不是幸运，而是不祥和担忧。

词不达意的问题依然存在。使用「现象」一词太过被动，「破坏」显得粗鲁，「革命」过于自我陶醉。现代人工智能面纱揭开，我们看到的是一个纷繁复杂的迷局。令人不安的危险感日益增长，但这种危险感是科学家天生能够识别和理解的。我产生了新的好奇心，虽然令人不适，却具有强大的吸引力。我只需要一种近距离观察危险的方式。

### 02

「到目前为止，结果令人鼓舞。在我们的测试中，由‘神经架构搜索'设计的分类器经过 ImageNet 训练后，性能超过了人类设计的同类分类器；所有工作都是靠计算机自己完成的。」

那是 2018 年，在加州山景城的谷歌总部中心 Googleplex，我坐在谷歌大脑（Google Brain）的长会议桌一端。谷歌大脑是谷歌最著名的人工智能研究机构之一。此次会议的主题是「神经架构搜索」（Neural Architecture Search，NAS），这是一种可以自动搜索神经网络的优化架构。神经架构搜索的发展成果特别令人激动，几个月来在谷歌内部持续引发热议。

此类模型的行为方式是由一系列参数决定的，这些参数在速度与准确性、内存与效率以及其他关注点之间进行权衡。对一两个参数进行微调非常容易，但要实现所有参数之间的平衡，往往是一项考验人类能力的任务，即使是专家也很难把每个参数都调整到最佳状态。如果能实现自动化调节，将会带来极大的便利，显然是值得追求的目标。自动化还能降低人工智能的使用难度，让越来越多的非技术用户在没有专家指导的情况下，使用人工智能构建自己的模型。此外，用机器学习模型来设计机器学习模型，并且能够迅速超越人类的能力，的确非常富有诗意。

但所有功能都是有代价的。单个模型的训练成本依然很高，只有资金最雄厚的实验室和公司才负担得起，而神经网络架构搜索则需要训练数千个模型。这项创新很了不起，但从算力的角度来看，造价也极其昂贵。成本问题是会议讨论的重点之一。

一位研究人员问道：「这是在什么样的硬件上运行的？」

「在整个过程中的任何时刻，我们都在同时测试 100 种不同的配置，每种配置训练 8 个特性略有不同的模型，所以共有 800 个模型在同时训练，每个模型都分配了独立的 GPU。」

「这么说，我们大约要……」

「800 个 GPU，没错。」

800 个 GPU ！2012 年，AlexNet 只需要两个 GPU 就能改变世界，现在的需求却飞速增加，其速度之快令人目眩，以后更会有增无减。根据我自己实验室的预算，英伟达最强大的 GPU 成本约为 1000 美元（这也解释了为什么我们自己只有十几个 GPU）。此外，还需要把这么多高性能处理器连接到一起，确保所有芯片昼夜不停地模拟运算，同时设备可以维持在可接受的温度范围内，这些都需要花费时间和人力。此外还要选择合适的地点。网络硬件占据大量的物理空间，耗电量巨大，因此不可能在普通车库或卧室中搭建。即使是像我们这样的大学实验室，也很难建造出如此庞大的网络。我靠在椅背上，环视了一下房间，想知道是否还有其他人和我一样对此感到沮丧。

2016 年，我即将迎来 21 个月的学术休假，暂时离开教授职位。我的收件箱被来自英伟达、优步和谷歌等公司的邀请信息淹没了。我保持着一种久经磨炼的本能，对这些信息一概不予理睬，却越来越多地发现自己停下来片刻，关注这些信息。我叹了口气，跟以前相比，现在去科技公司工作也许会更有意义，哪怕只是一点点。

我不得不承认，进入私营企业工作的想法不再像从前那样陌生。身边已经有数不清的同事实现了转型，就连我的学生也纷纷放下学业，到世界各地的科技公司进行高薪实习，有的更是一去不复返。如今，一切变化如此之快，我不得不怀疑，我对加入企业的厌恶是不是已经过时了？我想看看斯坦福大学和科学期刊之外的现代人工智能是什么样子。也许，眼下正是好机会，至少可以让我暂时体验一番。

经过再三考虑，我最终决定接受谷歌云的人工智能首席科学家一职。虽然此时的谷歌是一家有近 20 年历史的大公司，但云计算部门才成立一年左右，我觉得这是帮助谷歌从头开始打造人工智能的好机会。我还碰巧认识公司新任命的谷歌云首席执行官黛安娜·格林（Diane Greene）。她曾是虚拟化巨头 VMware 的联合创始人，是为数不多征服硅谷的女性，我期待着在性别比例极不平衡的行业里与她并肩工作。

这不像我本科时得到的那份看似光鲜亮丽的华尔街工作，也不像我在加州理工学院得到的麦肯锡快车道职位（当时我还因为要不要接受这个职位纠结了很久）。我一度把企业的工作当成是具有嘲讽意味的贿赂，目的是让我放弃实验室，但现在，我无法再继续假装它是一种贿赂。这是一份邀请，让我可以运营规模更大的实验室。其能力远超我的想象，我可以使用任何规模的高性能算力，由博士组成的研究团队比我在斯坦福大学能召集到的任何团队都要大几个数量级。最吸引我的是，我可以获得我以前做梦都无法想象的海量数据。当然，我的工作会受到公司产品路线图的驱动，至少是间接驱动，但这些产品始终是基础研究的下游，正是基础研究让它们成为可能。

最重要的是，谷歌云意味着我看到的不是一个，而是成千上万个人工智能的应用案例。随着云服务在人们能想象的几乎任何行业找到立足点，谷歌和其他云服务提供商也成了各行各业的固定伙伴。我有机会看到人工智能在制造业、农业、保险业、运输和物流业、零售业、金融服务业甚至政府部门的应用情况，以及为其提供支持的数据。其规模之大、种类之多，是任何一所大学都无法同时提供的。

我并不打算完全离开斯坦福大学，即使在学术休假期间也是如此，所以我花了一些时间来敲定细节。我会继续每周在校园里待一天，这样我就可以与实验室保持联系，并跟学生们见面。显然，后勤工作将是个挑战，但我已经做出决定。

我在大学这些年的所见所闻也不少，但谷歌云幕后的一切仍然出乎我的意料。科技行业的财富、权力和雄心向来名声在外。在亲身经历后，我觉得实际情况比传闻有过之而无不及。我看到的一切都比我所习惯的更大、更快、更精密、更复杂。

光是食物的丰富程度就令人咋舌。休息室里的零食、饮料和专业级意式咖啡机比我在斯坦福大学或普林斯顿大学见到的要多得多。几乎每栋大楼的每一层都设有这样的休息室。而这一切，都还只是我在进入自助餐厅之前所看到的。

其次就是科技。这么多年来，我们一直用的是 2000 年代的投影仪和视频会议设备，故障频发，性能很不稳定，经常让人大为恼火。相比之下，谷歌的会议现场就像科幻小说里的场景。无论是可容纳 50 人的高管会议室，还是供一人使用的衣柜大小的会议箱，每个房间都配备了最先进的远程呈现技术，只需轻点触摸屏，就能启动一切。

还有就是人才。谷歌人才济济，令人叹为观止。回想起自己花了两年时间才招募到三位合作者来帮助建立医院环境智能，我不禁自愧不如。在谷歌，15 人的团队已经准备就绪，只等我立即加入。而这仅仅是个开始 —— 在短短 18 个月内，我们的规模扩大了 20 倍。拥有优秀资历的博士似乎随处可见，让我觉得一切皆有可能。无论人工智能的未来会怎样，谷歌云都是我了解世界的窗口，而世界正以最快的速度向未来迈进。

我在斯坦福大学度过的每个周五更是突显了大学与企业之间的差异。随着我就任新职的消息不胫而走，我每天都能接到实习申请。这在某种程度上是可以理解的，因为我的学生（偶尔还有教授）只是在尽力建立人际关系网。不过，让我担忧的是，我和他们的每一次谈话，无一例外都以同样的请求结束：在他们看来，最有趣的研究是不可能在私营实验室之外实现的。即使在斯坦福大学这样的地方，预算也不够多。事实上，预算往往还差得远。企业研究不仅是更有利可图的选择，而且正在越来越成为唯一的选择。

最后就是数据。数据是谷歌整个品牌建立的基石。ImageNet 让我第一次看到了大规模数据的惊人潜力，也奠定了我此后几乎所有研究的理念基础。我和乔恩一起研究了几十年以来的汽车模型，和安德烈一起研究了大量图片和相关说明，和蒂姆尼特一起研究了整个美国的街景图像和人口普查局的记录 —— 数据量不断增长，人工智能的能力也与日俱增。现在，我被数据环绕了，不仅丰富程度难以言表，所涵盖的类别也超乎我的想象：来自农业企业的数据，他们希望可以更好地了解植物和土壤；来自媒体行业客户的数据，他们希望谷歌可以帮助他们整理内容库；来自制造商的数据，目的是减少产品缺陷；等等。几个月过去了，我穿行于两家最有能力为人工智能的未来做出贡献的机构之间。这两家机构都人才辈出，极富创造力和远见卓识。两家机构都在科技史上有着深厚的根基。它们甚至可以从同一条高速公路进出，在国道 101 上只相隔几个出口。然而，行业准入壁垒宛如一座大山高耸在地平线上，峰顶远高于云层，在知名高校和顶级私企之间，似乎只有一方拥有足够的资源来适应这个时代。

我的思绪不断地回到那 800 个 GPU 上，它们在应对一个教授和她的学生们无法想象的计算任务。如此多的晶体管，如此巨大的热量，如此巨额的资金。「疑惑」这样的字眼并不能表达我逐渐感到的惊惧。

人工智能正在成为一种特权，一种排他性极强的特权。

### 03

从 ImageNet 时代开始，规模的重要性就已经显而易见，但近年来，「越大越好」的观点几乎被赋予了宗教般的意义。媒体上充斥着城市街区大小的服务器设施的图片，关于「大数据」的讨论永无休止，不断强化着这样的观点：规模是神奇催化剂，是机器中的幽灵，可以将人工智能的旧时代与令人窒息的梦幻未来区分开来。虽然相关分析可能会有些简化，但本质上并没有错。没有人能否认，神经网络确实在这个资源丰富的时代蓬勃发展：惊人的数据量、大规模分层架构和大量互联的硅片确实带来了历史性变化。

这对科学意味着什么呢？如果我们的工作秘诀可以简化为赤裸裸的量化，简化为蛮力制胜，那么努力思考和创新又有什么意义呢？如果一些想法在层数太少、训练样本太少或 GPU 太少的情况下似乎会失败，而在数量增加到足够多的时候突然又可以高效运转，那么对于算法的内部运作机制，我们又能得到什么教训呢？我们发现自己越来越多地从经验角度观察人工智能，就好像它是自己出现的一样，仿佛人工智能是需要先识别、后理解的东西，而不是根据第一原理设计产生的技术。

我们与人工智能之间的关系正在发生转变，对我这样的科学家而言，这样的前景令人深思。在谷歌云的新职位上，我可以鸟瞰越来越依赖于各个层面技术的世界，但我们不能坐而论道、惊叹于一切的神奇。这种奢侈我们负担不起。新一代人工智能所能做的一切，无论是好是坏，无论是在预期之内，还是在意料之外，都因其设计本身缺乏透明度而变得复杂。神经网络的结构本身充满了神秘色彩，它是由微小的、权重微妙的决策单元组成的巨大集合体。这些决策单元孤立地看毫无意义，但以最大的规模组织起来时，却强大得令人咋舌，几乎无法为人类所理解。我们可以从理论的、抽象的意义上谈论神经网络：它们能做什么，它们达到目标需要什么样的数据，它们训练后的性能特征大致在哪个范围；但从一次调用到下一次调用，它们在内部到底做了什么，却是完全不透明的。

由此带来的后果特别令人担忧，这就是一种被称为「对抗攻击」的新型威胁。在对抗攻击中，输入内容的唯一目的是迷惑机器学习算法，以达到反直觉甚至破坏性的目的。举例来说，一张照片看上去是描绘了某种明确的事物（比如蓝天下的长颈鹿），但可以通过单个像素颜色的细微变动进行修改。尽管这种像素颜色的变化是人类肉眼无法察觉的，却会在神经网络中引发一连串的故障。如果对抗攻击设计得当，虽然原始图像看起来没有任何变化，但算法会把「长颈鹿」这样的正确分类变成「书架」或「怀表」等错误分类。先进技术无法辨认野生动物照片的场景可能会让人觉得好笑，但如果对抗攻击的目的是愚弄自动驾驶汽车，导致汽车对停车标志，甚至人行横道上的儿童进行错误分类，就绝对不能用好笑来形容了。

当然，提高工程技术水平可能会有所帮助。「可解释的人工智能」，或简称为「可解释性」，正在成为新的研究方向，令人备受鼓舞。可解释的人工智能试图将神经网络近乎神奇的计算进行简化，转变成人类可以仔细研究和理解的形式。但相关研究尚处于起步阶段，无法保证能够达到其支持者所期望的高度。与此同时，这项技术所要诠释的模型却已经开始在世界各地大量出现。

即使是完全可解释的人工智能也仅仅是第一步。如果在算法设计完成后，再加入安全性和透明度等考虑因素，无论设计得多么精妙，都不足以满足要求。下一代人工智能必须从开发之初就采取与现在完全不同的理念。以激情为起点固然很好，但我们要面对的是纷繁复杂而又不起眼的挑战，要取得真正的进展，就必须有敬畏之心。而硅谷似乎缺乏这种心态。

学术界早就意识到人工智能可能会带来负面冲击，比如缺乏透明度、容易受到偏见和对抗性影响等等。然而，由于研究规模有限，风险一直只存在于理论层面。我的实验室最有现实影响力的工作是环境智能研究。由于临床法规的制约，我们对工作热情保持谨慎和克制，因此有足够的机会来应对相关隐患。但现在，市值接近万亿美元的公司已经掌握了主导权，潜在风险的发展步伐也急剧加快。无论是否准备就绪，这些问题都需要以商业速度加以解决。

每个问题单独来看都令人担忧，但它们共同指向了一个未来，其特点是监督减少、不平等加剧，如果处理不当，甚至可能导致迫在眉睫的数字独裁主义问题。走在全球最大公司之一的走廊里，我不禁陷入沉思，问题的确很尴尬，尤其是考虑到同事们的诚意和良苦用心。这些都是制度性问题，而不是个人问题。现在还没有出现胡子拉碴的典型恶棍，我们还没有遇到真正的现实问题，此时提出这些挑战，只会让人更加困惑。

我回想起与阿尼共事的情景，想起当时要在几家医院部署手工制作的小型原型设备是多么困难。在高度谨慎的医疗领域，创新是逐步展开的，虽然有时令人沮丧，但总体上也让人感到心安。我想知道医疗领域的做法是否值得广泛效仿。

硅谷的傲慢态度向来为外界所诟病。在人工智能时代，尽管我们对潜在风险的认知不断加深，企业的夸夸其谈也上升到了新的高度。首席执行官们在世界各地的舞台上发表主题演讲，有些内容高瞻远瞩，有些则拙劣不堪，还有一些是彻头彻尾的侮辱。企业高管们承诺将在不久后推出自动驾驶汽车，设计出高超精湛的肿瘤检测算法，实现工厂的端到端自动化。至于被先进技术取代了工作的人（出租车司机、长途卡车司机、装配线工人甚至放射科医生）的命运，商业领域的态度似乎介于半心半意的「再培训」和几乎不加掩饰的漠不关心之间。

无论首席执行官和自诩为未来学家的人的言论如何彻底脱离公众，技术的日益普及都会进一步加剧人们对人工智能的恐惧。在这个时代，里程碑接二连三地出现，最可怕的情景正在逼近。在人工智能领域的历史上，第一次出现了流血事件。

在亚利桑那州坦佩市，优步先进技术集团正在测试一辆自动驾驶原型汽车。伊莱恩·赫茨伯格（Elaine Herzberg）推着自行车过马路时，被这辆车撞倒身亡。两年多前，优步策划了卡内基梅隆大学机器人系团队离职记，而现在，优步的自动驾驶项目成了公众嘲讽的对象。如果说人工智能如今频频遭遇偏见让我和同事们感到难过，那么我们现在的感受则无法用语言来形容。优步的品牌已经声名狼藉，其原因与技术本身关系不大。尽管我们很容易将事故归咎于优步，但很明显，这绝对不会是最后一个类似的事故。

的确，更多教训很快就出现了。2016 年，ProPublica [注：ProPublica 是一家总部设在美国纽约的非营利性媒体，其新闻报道以调查为主，主要涉及政府、商业、刑事司法和环境等主题。—— 译者注] 的一系列调查显示，有偏见的人工智能被广泛应用于处理贷款申请，甚至协助法官做出假释决定等方面。类似的报道还显示，在某些招聘中，求职者会先经过人工智能技术的筛选，然后才有真人面试官进行面试。此类做法往往会在无意中造成歧视性影响，这一点并不令人意外。伊莱恩·赫茨伯格的死亡理所当然地导致优步自动驾驶团队解散，并对整个领域造成了负面影响，但上述更微妙、更机构化的伤害却不可能迅速得到纠正。相关问题几乎是无声无息的，影响范围更广，而监管则少之又少。期待出现同样程度的公愤是不现实的。但好在公众意识在不断提高，媒体也认识到，当涉及人工智能的报道时，不应忽视偏见、公平和隐私等问题。

无法问责算法、特定人群受到不公平待遇、一个人意外死亡，这些都是人工智能领域出现的新局面。审视局面，我得出结论：简单的标签已经不再适用。甚至连「失控」等措辞都显得委婉。人工智能不是现象，不是颠覆，不是难题，也不是特权。我们面对的是一种自然力量。它是如此宏伟，如此强大，如此反复无常，既能轻易激发灵感，也很容易摧毁一切。要让人工智能值得信任，需要的远不止商业公司空洞的陈词滥调。

人工智能甚至不是科技界对公共利益的唯一威胁，这使得情况变得更加复杂。在人工智能领域出现问题的时候，剑桥分析公司也爆出丑闻。在 2016 年美国总统大选期间，公众普遍对虚假信息表示担忧。关于社交媒体和新闻源过滤气泡的不良影响的报道也在不断增加。种种事件都有一个共同之处：世界正在逐渐意识到，数据不仅有价值，而且具有影响力，甚至可以产生前所未有的决定性影响。

到 2018 年，已经没有人再质疑其中的利害关系了。对脸书和 Instagram 等社交媒体应用的审查不断加强，因为它们提供的超个性化内容可能会导致青少年出现抑郁和焦虑。社交媒体利用人工智能打磨定制化内容，以实现最大程度的「用户参与」，这种趋势令人不安。亚马逊使用一系列监控工具（包括监控腕带）实时追踪工人的工作效率，这种仓库管理方式受到媒体抨击。微软在试图推广其人工智能面部识别技术时，遭到了隐私权倡导者和公民自由组织的批评。我自己也被卷入争议的中心。当时谷歌云与美国国防部签订的一份合同（内部称为 Maven 项目）引发了广泛的争论。几个月后，紧张局势从公司内部蔓延到媒体，重新点燃了大众关于技术在军事事务中所扮演角色的长期争议。科技抵制浪潮已经来临，人工智能难以独善其身。

### 04

「我们就在这儿等着。」我说。

时间是早上 5:30。我看着护士把母亲推进手术室。她又要做心脏手术了，这是迄今为止创伤最大的一次。中国家庭向来不善于用语言表达对彼此的感情，我在心里默默地说出了剩下的祝福。

我爱你，妈妈。

我不知道该做些什么。几分钟后，我无精打采地站起身，在大厅里踱来踱去，找到了一张远离喧嚣的安静长椅，颓然坐下。长椅的金属表面比我想象的还要冰冷，我不禁打了个寒战。只有我一个人，满脑子都是我还没准备好面对的种种思绪，左手边空空如也 —— 在其他日子里，母亲总会坐在我的左边。她也许会发脾气，会评头论足，但她总是在那里，总是在我身边。

片刻之后，我意识到周围并非空无一人。父亲找到了我。他看起来欲言又止，似乎不知道如何开口。

「飞飞……」他的语气异常严肃，甚至有一种成年人的口吻。但我感觉到的不是力量或威望，而是脆弱。

「我小时候，人人都喜欢我父亲，」他停顿了一会儿，继续说道，「尤其是我。我跟你说过他的事吗？我们家并不富裕，但过得还算舒适，尤其是在我们这样的小城镇。我的成长过程很幸运，我觉得自己…… 很特别。」

我不知道该怎么理解我听到的话。他很少谈起他的过去 —— 缺席的祖父、他似乎从未摆脱的童年，还有我和母亲之外的家庭成员。但他继续说了下去，深入讲述着我从未听过的故事。

父亲委婉地讲到，因为他的母亲患有某种说不清的严重精神疾病，他从小就没有在自己母亲身边。尽管如此，或者更可能正因为如此，他的父亲 —— 也就是我的祖父 —— 对他溺爱有加。祖父并非富有之人，也没有显赫身份，只是个小官员，但生活在那样的小城镇里，即使是微不足道的行政地位也能带来一些好处。对父亲来说，那是一段快乐的时光，远离了那个时代的纷杂是非，经历了我想象中他那种性格的人在童年时期必定经历的各种冒险。

当他告诉我他儿时最喜欢的宠物时，我忍不住笑出声来：一只熊，一只真正的熊，而且是他亲手养大的。后来那只熊长得太大了，变得非常危险，他们没有办法，只能捐给了动物园。当然，我不应该感到惊讶，大多数男孩哪怕只有一点儿名义上的特权，也会梦想着进个好学校、谋个好职位，但父亲毕竟与大多数男孩不同。他当然会利用这个小小特权换取一只熊，牵着它在小镇上漫步。我内心的紧绷逐渐舒展开来。以传统的标准来衡量，他也许不是一个称职的父亲，但像这样的时刻还是让人印象深刻。他真的能在任何场合给人带来温暖。

但故事至此发生了转折，因为祖父突然罹患重病。病情开始得很神秘（那个时代经常会这样），而且由于他们很少与人交往，祖父的病逐渐恶化。只有父子俩相依为命，小镇物资有限，有效治疗几乎是不可能的。父亲束手无策，祖父日益憔悴疲劳，食欲急剧下降，变得神志不清。

因为照顾不周，祖父的身体迅速垮了下来，几个月后就无法自理。父亲只能守在床边，眼睁睁地看着祖父的身体一天天衰弱下去。父亲整个世界的中心崩塌了，但他却无能为力。当祖父最终去世时，父亲觉得生命毫无意义、毫无尊严。姗姗来迟的医生跟父亲解释说，是极度营养不良加剧了祖父的胃肠道疾病，最终使他的身体不堪重负。但对一个突然变得如此孤立无援的男孩来说，解释已经无关紧要。一切都毫无道理可言。

那是 1961 年，父亲当时只有 14 岁。

祖父去世后，没有任何亲人来照料父亲。不可思议的是，祖父的一位同事主动收养了父亲，成为他的法定监护人。祖父同事让父亲继续上学，满足了他的基本需求，并确保他顺利毕业。祖父同事的慷慨让父亲熬过了那段原本会让他生不如死的日子，但从此之后，他就像变了一个人。

祖父去世后，父亲的一部分也随之消逝，留下的只是一个孩子的一部分，这是他所热爱的世界曾经存在过又消失的唯一证据。因此，他决心保持原样。即使他长大成人，获得学位，并最终为人夫、为人父，他也继续过着记忆中的那个男孩的生活。

父亲笑容温暖，喜欢玩冒着傻气的文字游戏，一生都拒绝承担责任，但在这一切的背后，隐藏着一种无法治愈的痛苦，多年后依然让他难以自拔。所有的遭遇和痛苦塑造了他唯一的信念，随时间推移而变得更加坚定：虽然反复无常、残酷无情的世界夺走了他的父亲，却永远带不走他。这个世界也永远不会夺走我的母亲，永远不会带走我。

在那一刻，我恍然大悟。父亲并不是在简单地向我讲述我们家族的历史，也不是在讲述他与母亲一样渴望逃离的私人原因。这个男人之所以说这些话，是因为他急于想让女儿做好失去母亲的心理准备。在几十年的新生活之下，埋藏着他最古老、最深沉的悲伤，现在他把这份悲伤挖掘出来，这样我们才有勇气共同面对新的伤痛。他是在保护我。这么多年来，我一直以为他的青春期从未结束，但事实是，他的青春期早已结束了，而且结束得太快。他一直像个被时间定格的孩子，但在医院的那一刻，我看到了新的一面。在这一切的背后，是一颗父亲的心在跳动。

我在人工智能领域的第二个十年已经来到尾声，在谷歌的第二年也即将结束，我感到前所未有的不安。我所在的领域正处于混乱之中，而这种混乱似乎也渗透到了我的内心。我也逐渐意识到，一种模式似乎定义了我的人生。无论情况有多么艰难，都会有一些事情唤醒我，让我思考在这一切之中，生而为人究竟意味着什么。每一次，我都心怀感激。

### 05

不管在何种场合，关于职业伦理的对话都需要花费一番心思，但有一次讨论让我尤其紧张。那是 2018 年秋季的一天，我站在一间拥挤的会议室里，到场的都是现场向我汇报工作的工程师和产品经理。在回答团队提问的时候，我感觉就像在高空走钢丝。不管是我们行业还是其他行业，都经历了太多动荡，从文化到政治，我觉得早该进行反思了。

我开口讲话，句子之间有很长的停顿：「从我记事起，我就对物理学充满热爱。但是，科学之美与曼哈顿计划等事物紧密相连。这就是现实。人工智能也有自己的隐患，无论是机器人杀手，还是大范围的监控，甚至只是通过自动化让我们 80 亿人失业。这些都是可怕的事情，值得我们担心。但它们也是极端情况，不太可能明天就发生。」

我再次陷入长时间的停顿，酝酿着下一句话。

「我想，这就是问题真正变得棘手的地方。因为在此期间，有太多其他事情需要考虑。既有许多积极的方面，也有很多负面的因素，有些事情可能明天就会发生。所以，我希望你们能理解我们所面临的机遇。无论接下来会发生什么，我们都要在其中发挥作用。我们必须认真对待。这就是伦理框架的重要性所在。它可以帮助我们在迈出每一步之前进行评估。」

会议室里安静了片刻。

「嗯，我能问个问题吗？」会议室最角落里传出一个声音。这声音来自谷歌新聘用的研究科学家，她才华横溢，技术水平很高，最近刚从世界最顶尖的学校毕业。然而，听起来她有些胆怯。「‘伦理框架'这个概念……」

「请说。」

「具体是什么意思？」

这个问题比我想象的更为基础，也许我们每个人都需要如此发问。

### 06

加入我们的团队，利用大数据、分析和人工智能，帮助本地单身人士找到真爱！正在招聘中！

我在后座上眯着眼睛看着国道 101 上的另一块广告牌。我开始怀疑，人工智能的真正威胁是否在于除了人工智能，我们已经不可能再做其他广告了。自从几个月前和团队讨论了我们工作的伦理问题，这个问题就一直萦绕在我的脑海中。同事的声音打断了我的思绪。

「嘿，看看这个。」他边说边递给我几页打印好的文件，「这是公关团队整理的谈话要点，我们可能会用到。」

清晨时分，我们的车随着向南行驶的车流缓慢移动。我低头看了看材料，露出微笑，但让我精神振奋的并不是纸上的字。我们正在前往山景城，要去参加谷歌一年一度的传统招聘活动，这是我第二次参加了。谷歌会让数百名来自世界各地的暑期实习生聚集到 Googleplex，与领导层会面，帮助他们更深入地了解自己的职业发展道路。对公司来说，这是一次招聘活动。而对我来说，这是一个可以远离公司事务的好机会，唤起了我作为教育工作者最美好的时光。满屋子都是聪明、年轻、有远见的思想家，而我将有机会跟他们交流。

在谷歌，我通常很乐于照本宣科，这与我做教授时畅所欲言的风格完全不同。作为谷歌的发言人，意味着要对众多高管、公关顾问甚至律师负责，因此不按规定行事的想法会让我感到非常害怕。我的发言通常都是围绕人工智能和商业的老生常谈，彬彬有礼地讲给这个记者、那个记者或一群分析师听，不会出任何纰漏。我几乎到了熟能成诵的地步。

但身处这个奇怪的时代，我的内心渴望变革。我的思绪又回到了与团队的会议上。最后一个问题反复出现：「伦理框架」到底是什么意思？我越思考，就越觉得自己想得并不清楚。我自己对「伦理框架」的大部分概念源于非传统职业生涯中的意外收获：在加州理工学院与克里斯托夫一起向机构审查委员会提出建议；多年来在医院与像阿尼这样的人合作，陪同医生查房，倾听护士的关切，从而加深了对他们的了解；家中一直让我担心的父母；我青少年时期的移民生活。

一个严峻的事实是，医疗等领域拥有经过几个世纪甚至几千年的时间建立起来的规范、先例和伦理基础；其伦理基础以生与死这一无法回避的现实为依据。相比之下，人工智能还处于发展的早期阶段，其本身几乎没有明确的伦理准则。我们领域的自我认识之路才刚刚起步。因此，缺乏伦理框架的不仅仅是谷歌，也不仅仅是像那位提出问题的年轻工程师一样的个人，而是我们所有人。

我假装对公关团队准备的材料很感兴趣，扫视着用荧光笔突出显示的段落，但这一次我已经暗下决心：在面对 700 名未来最有影响力的科技工作者发表演讲时，无论结果如何，我都不会用别人准备好的发言稿；我决定要完全发自肺腑地讲话。此外，随着我的学术休假即将结束，我有非常多的反思要和大家分享。

在谷歌云工作的日子虽然常常让人迷失方向，但我却无比感激。我得到了科学家少有的机会：在最大范围内与受到我领域研究影响的人会面，从他们的角度来审视相关影响，哪怕只是一瞬间。两年来，我经常与金融服务、农业、医疗、能源、娱乐和交通等行业的初创企业，以及财富 500 强企业的高管、产品设计师和各类开发人员进行交流。这些经历给我带来的经验和教训比我想象的更清晰、更让人谦卑，也无比直接地提醒我，人工智能已不再是智力上的好奇探索，而是即将改变全人类生活的社会转折点。归根结底，我知道，如果一个机构不在某种程度上对人工智能技术加以考量，那么它将无法生存下去。这些迹象是明确无误的。我日复一日、周复一周、月复一月地反思我所看到的一切，试图更好地理解我们所面临的拐点，思考如何负责任地驾驭它。我为此感到自豪，也怀抱着乐观的心态，依然充满热情。但同时，我也深感这份责任从来没有像现在这样沉重。

无论我接下来要去哪里，我的旅程都将从我站在台上面对实习生时所说的话开始。过去两年，我一直专注于传递企业信息，现在我将不再担任企业信息的传声筒，我决定直抒胸臆。虽然我还没有准备好措辞，但我打算承认，前路崎岖而艰难，无论是学生还是教授，实习生还是首席执行官，没有人知道答案。有坏消息要面对，有难以接受的真相要处理，而且很可能会造成伤害。但也有好消息：现在一起面对还为时不晚。

登上讲台时，熟悉的紧张感在我的胃里翻腾。不过，我最喜欢的观众就是学生，看到他们的目光，我感到了安慰。

「下午好！」我对着麦克风说，「很高兴来到这里。」

那一天，只有这两句话是讲稿里的。

### 07

两周前，母亲刚刚接受了心脏外科手术，这是我们家与不敢想象的事件最近的一次接触。而就在现在，我已经从母亲的声音中听到了单调的藐视 —— 她的语调一如寻常。无论健康还是生病，年轻还是年老，这都是她的自然状态。

「这个话题我们都讨论 20 年了，飞飞。」母亲说道。

我转过头看了看屏幕，那封邮件依然清晰可见。在一封日期为 2018 年 6 月 7 日的邮件中，美国众议院科学、太空和技术委员会的副主任似乎在邀请我做证。对一个从未出席过国会听证会的人来说，这是一个令人生畏的邀请，而且听证会定在 26 日，距离现在还有不到三周的时间。我想到导致当前情形的种种因素：科技抵制浪潮、有偏见的人工智能等等，觉得接受邀请似乎是个绝对糟糕的主意。我知道母亲此时此刻是多么需要我陪在床前（不管她是否承认），因此心情更加糟糕。老实说，我只想让她替我做决定，让她坚称我现在离开是对她极大的不负责任。但她一如既往地没有打算给我提供便利。

「飞飞，你还记得我们在肯尼迪机场降落的那一刻吗？我们刚来到这个国家的时候？你爸爸没有来接我们，我们当时是什么心情？」

「当然记得。」

「我们在行李提取处的那几个小时多无助啊，都吓坏了。现在，20 年过去了，你收到了这样的邀请，要去这个国家的首都，要去为你最热爱的课题做听证了。」

「是的，但如果事情没那么简单呢？如果他们认为我是丑闻的一部分呢？如果……」

「那你就为自己辩护！你要告诉他们，你已经为这个国家奉献了 20 年，你的家人为了成为这个国家的成员付出了一切，你拒绝被当成外人对待！」如果这番话是出自别人之口，我一定会嗤之以鼻。用这样的语气面对国会委员会，我们大多数人只会更擅长想象，而不是实际行动。但我了解母亲，如果有人敢质疑她的人格，她肯定会这么说。我在想，是不是可以让她替我出庭做证。

「想想全世界有多少人对参加这样的事情求之不得。公开听证会。领导人和公民之间的公开对话。」

### 08

随着一声槌响，听证会开始了。此刻，已经没有回头路可走。

「科学、太空和技术委员会听证会现在开始。」委员会主席、弗吉尼亚州众议员芭芭拉·科姆斯托克（Barbara Comstock）对着麦克风淡淡地说，「早上好，欢迎各位来到今天的听证会。今天听证会的主题为‘人工智能 —— 威力越大，责任越大'。」

至少我听出了其中一句话是电影《蜘蛛侠》里的台词，说明我还是有一定能力的。即便如此，各种神经质的担忧还是在我脑海中纷纷闪现。无数双眼睛仿佛要钻进我的后脑，我开始重新审视把自己带到这里来的旅程的每一个细节。我的移民生活、我在日益分裂的技术发展中扮演的角色、科技抵制浪潮等等，所有的一切。

然而，随着听证会的进行，我越发觉得，我对这一时刻的过度忧虑是错误的。代表们逐个发言，每个发言都经过了深思熟虑，展现出孜孜以求的姿态，让我倍感惊讶。他们的声音带着好奇心、诚意和探索真实观点的意愿，尽管这些观点可能很复杂。渐渐地，我意识到自己并不是来接受严厉的质询的。在听证会上，我甚至有机会讲述母亲的病情，讲述她对我在人工智能和医疗交叉领域研究方面的激励和启发。我曾担心听证会会演变成对抗的局面，但结果只是一场对话，探讨的是更简单但更深刻的议题：未来几十年里，美国人的生活会呈现何种面貌？

当我提到母亲的时候，科姆斯托克众议员将目光从准备好的发言稿上移开，直接与我交谈，分享了她对美国人口老龄化所面临挑战的看法。

得克萨斯州众议员兰迪·韦伯（Randy Weber）发言时也询问了母亲的健康状况。我高兴地向他保证，她的病情很稳定，我已经可以离开她的身边来参加听证会，而且她现在就在病床上看着电视直播。「嗨，妈妈！」众议员科姆斯托克对着摄影机俏皮地插了一句，众议员韦伯也用温和的亲切语调表达了自己的祝福。这次交流出乎意料地充满了温馨，消除了我内心残存的恐惧。

我将一切美好感受转化成语言，介绍了我心目中人工智能的潜力和应有的样子。我讲述了启动 AI4ALL 公益项目的经历，以及项目启动以来，我学到了什么。我谈到了环境智能，分享了这个话题对我的意义。我还谈到了未来，表示相信人工智能可以为缩小世界各地的机会差距做出贡献。

这是我就人工智能话题进行过的最友好的对话。在伊利诺伊州众议员比尔·福斯特（Bill Foster）的影响下，我们甚至谈及了更专业的领域。他是一位拥有物理学博士学位的政治家，在从政之前曾在能源部费米国家加速器实验室工作。他的求知欲激励了我，也再次验证了人工智能是多么新颖的研究领域，比化学、生物学和物理学等更成熟的学科要年轻几个世纪。即使是现代人工智能，也更接近于牛顿出现前伽利略和第谷·布拉赫所处的时代，当时人们正在对各种现象进行观察、归纳和预测，但统一的模型尚未正式形成。我说，我们生活在一个令人兴奋的初生时代，仍在企足而待「古典」时代的黎明。

「感谢各位证人的证词和各位委员的提问。记录将保留两周时间。」众议员韦伯说，「听证会到此结束。」随着法槌的再次敲响，听证会结束了。

我心想：「好吧。」我眨了几下眼睛，似乎才意识到刚刚发生了什么。我终于可以自由呼吸了。

当我走回酒店时，对首都街头的气氛感觉完全不同了。我的肾上腺素水平开始下降，思绪也变得更加清晰。我感觉更像真正的自己了。但我仍然没有方向，不知道接下来应该追随怎样的北极星。

我重新打开手机，信息通知声近乎不断。我没有查看消息，而是给西尔维奥打了个电话：「嘿，妈妈怎么样了？有什么新消息吗？」

「你妈妈很好，我刚给护士打电话确认了一下。你自己呢？」

「据我所知，我活下来了。你觉得怎么样？」

「我觉得一切都很顺利。」他说，「我这辈子都没看过这么长时间的 C-SPAN [注：C-SPAN 是美国的一个有线电视和卫星电视网，直播和录播美国国会听证会、白宫新闻发布会、政治活动以及其他与公共事务相关的内容。—— 译者注] 直播。我看不出你有多紧张。」

谢天谢地。不只是我一个人这样想。

「但你知道吗？可能是电影看多了，让我产生了错误的想象，我觉得你的听证会也没想象的那么刺激。」他笑着补充道。

我笑得比想象中更大声。

听证会终于落下帷幕，而我还在想象听证会可能会发生的各种情景。会议时间本可以更长，本来可以有更多的证人、涉及更广泛的专业知识；会议议程可能涵盖更多议题，会议成果也可能以更多的形式公布。但是，即使是「更长」和「更多」等词语，也让人感觉言不尽意。要探讨的话题实在太多了。

此外，我们仍身处一场全球风暴之中。每天似乎都有新的头条新闻报道自动化对全球劳动者构成的威胁。随着人工智能在监控领域的应用日趋成熟，记者和人权活动家的担忧与日俱增，对隐私和个人尊严的古老威胁也在现代社会出现。尽管最初出现了强烈抗议，但算法偏见仍然笼罩着整个人工智能技术，此外还有往往与算法偏见相关的代表性问题。

我曾经把人工智能视作纯粹的科学，而现在，我用了很多不同的词来形容其化身：「现象」「颠覆」「谜题」「特权」「自然之力」。但当我穿过首都的街道返回酒店时，一个新词占据了我的思维。如今，人工智能是一种责任，是我们所有人共同承担的责任。

我确信，这是一个值得面对的挑战。深度学习飞速发展，每一年都感觉像是要面对一个全新的领域，其应用的深度和多样性增长得如此之快，甚至全职研究生和博士后也很难跟上文献的步伐，更不用说教授们了。可能性无穷无尽，挑战也永无止境。即使在这样一个黑暗的时代，人工智能也具有无与伦比的激励力量。面对全球亟待解决的问题，面对具有历史意义的机遇，面对可能需要几代人的努力才能揭开谜底的未知，真正解决所有问题的答案远远不是公司战略或学术课程所能提供的。

是什么让硅谷的公司如此强大？不仅仅是它们数十亿美元的资金或数十亿用户，也不仅仅是因为它们拥有惊人计算能力和数据储备，让学术实验室的资源相形见绌。它们之所以强大，是因为成千上万个才华横溢的人在同一个屋檐下共同努力。但公司只能利用这些人才，而无法塑造他们。我一遍又一遍地看到类似的情况：才华横溢的技术专家几乎可以建造任何东西，但问及工作的伦理问题时，他们却一脸茫然。

是时候重新评估人工智能教育的各个层面了。未来几年，从业者需要的不仅是专业技术知识，他们还必须了解哲学、伦理学，甚至法律。他们需要看到阿尼确保环境智能团队所看到的一切，他们需要将其融入众多学科中。研究工作也必须不断发展。在经历了这一天之后，我知道我们需要一种新的政策方法，首先要对民选官员（就像我刚刚遇到的那些政府官员一样）进行人工智能方面的普及教育。

想象空间是巨大的，但愿景需要一个重要的纽带串联起来，这个纽带就是大学。早在有人利用人工智能谋取利益之前，人工智能就已经在大学里起步了。在大学校园里，仍然最有可能感受到某些意想不到的研究突破带来的火花。感知机、神经网络、ImageNet，以及后来的很多东西都出自大学。我想建立的一切都已经在那里扎下了根基。我们只需要加以利用。

我们要从根本上重新构想人工智能，使其成为以人为本的实践，这个共同的目标就是下一颗北极星。在我看来，与其说这是旅程方向的改变，不如说是旅程范围的扩展。人工智能一直以来都追求科学性，而现在，它必须也追求人性。人工智能应该秉承最优秀的学术传统，保持合作和敬畏，同时不惧怕直面现实世界。毕竟，星光是多样的。一旦白色的光辉展开，各种颜色就会发出耀眼夺目的光芒。