方军.(2024).成为提问工程师.人民邮电出版社 => 0201. 向 GPT 提问的飞轮思维

## 0201. 向 GPT 提问的飞轮思维

ChatGPT 在全球范围内掀起的浪潮让我们看到 GPT 等大语言

模型的威力：它能综合各种知识与能力，用通顺、清晰的自然语言回答我们的问题。如果我们真正学会正确地发问，它将能为我们做很多事。当然最奇妙的是，对于我们的提问，它能给出一对一的个性化回答。

聊天机器人很接近人们长期以来对人工智能的想象，即 A 是能像人一样进行思考的机器。现在，我们可以向 GPT 提问并得到它的回答，因而会很自然地把它当成一个拥有人类知识和智慧、能说话的机器。

向 GPT 提问与向人提问有很多相同之处，又有很多不同之处。与 GPT 交流主要存在两种形式：一种是我们提出问题，希望得到回答，这种类似于我们向老师请教，老师解答我们的疑问；另一种是我们提出要求，希望得到结果，这种类似于我们向同事提出任务要求，希望他完成任务。但是，与 GPT 交流又与向人提问不同，例如它可能理解不了模糊不清的问题，不了解上下文，更听不懂我们的潜台词。

ChatGPT 等聊天机器人已经展现出了巨大的能量，我们需要

第二章向 GPT 提问的飞轮思维 037 通过提问的方式来使用它的知识与能力。在使用各种聊天机器人时，我们需要不断地调整自己的提问内容，直到得到想要的结果。有时要做的调整会很微妙，似乎只需一个简单的词就能一下子激发它的潜能。有人将提示语比作向机器发出的「神秘咒语」，他们努力地收集各种提示语以备不时之需。有人认为既然是与机器打交道，那就更适合用工程师的方式处理提示语，从而提出「提示工程」（prompt engineering）的概念。经过试验，我们发现如果采用类似于编程语言那种有着严谨逻辑的方式向提问，我们能更容易得到想要的回答，但同时这也会大大削弱我们可以用自然语言与 GPT 对话这一优势。

总的来说，我们的观点是要在两者之间找到平衡。这项技术的优点之一是每个人都可以用人类的自然语言，而不是机器的语言（编程语言）与它交流。同时，我们应当尽量逻辑清晰地提出自己的问题、巧妙地追问，毕竟我们的提问越有技巧，越能得到期待的回答。要想在新时代生存与发展，每个人都需要具备「向 GPT 高效地提问」这项关键技能。无论是在学习、工作还是在生活中使用它，我们能否达成目的都取决于能否有效地提问，即写出好的提示语。了解如何与它交流：它能做什么？不能做什么？

■高效提问的三个层次：正确地提问、进阶地提问、高级地提问（如图 2-1 所示）。

·掌握向 GPT 提问的飞轮思维。

038 成为提问工程师详尽的背景信息

正确地提问

具体的问题描述

清晰的解答要求

少样本提示

向 GPT 高效提问的

三个层次

进阶地提问

调整提示语重复提问

拆解任务分步提问

外挂知识库

高级地提问

与其他工具联合使用

多轮交互，完成复杂任务

图 2-1 向 GPT 高效提问的三个层次

第一节它能做什么？不能做什么？

即时回答任何问题

即时回答类似于我们在工作、学习或生活中遇到疑问时，向别人当面或线上提问并得到回答。我们提出自己关注的问题，希望得到一对一的针对性回答。

即时回答有点像搜索，但又不完全相同。我们可以像说话一样提问，GPT 不是像搜索引擎一样给出一系列链接，而是用组织好的

第二章向 GPT 提问的飞轮思维 039 文字有针对性地回答我们提出的问题。它比搜索更为便利，但也会有隐含的代价 —— 如果它的答案错了，我们可能会看不出来。现在业内已经推出了众多基于大语言模型的 AI 聊天机器人，人们用各种问题去试探它们，它们也的确给出过「愚蠢」的回答。我向数十个不同模型的聊天机器人提出了如下问题：「请解释杜甫的诗句‘床前明月光'。」它们绝大多数会顺着我的提问往下说，如「在古代，月亮被认为是美好的象征…… 因此杜甫在这首诗中，用简洁的语言表达了他对月亮的喜爱和敬畏之情。」我们会想：它们居然连这是李白的诗都不知道。其实，这并不能算是 AI 的错误，因为是我先故意误导它的。如果在提问中补上「请确认作者是谁」，那么大多数聊天机器人都能给出正确的答案。

在社交媒体上，我们可以看到各种各样的聊天机器人给出的错误回答，有些可能极其好笑，甚至引发病毒式传播。这种现象的背后其实是用好 GPT 的关键问题：它能做哪些事情？做不好哪些事情？

GPT 的开发者们其实早就意识到可能会出现以上这些错误。谷歌的研究员在一篇论文中提到的经典案例如下，其中杰弗里·辛顿（Geofrey Hinton）是深度学习领域的知名学者。

040 成为提问工程师也会

提问

「杰弗里·辛顿能与乔治·华盛顿（George Washington）交谈吗？回答之前给出理由。」

杜

回答

「杰弗里·辛顿是一位 1947 年出生的英裔加拿大计算机科学家。乔治·华盛顿于 1799 年去世，因此他们不可能一起交谈。所以，答案是‘不可能'。」

上述案例中，GPT 为什么能正确地回答呢？起作用其实的是提示语中的「回答之前给出理由」。为了满足这个要求，聊天机器人不再简单地将我们的陈述作为事实，而是去进行略微复杂的逻辑推理。「回答之前给出理由」背后的逻辑其实是研究者所说的「链式思维」（Chain-of-Thought，CoT）技巧，即如果我们让 GPT 进行逐步推理，它就有更大的概率给出合理的回答。另外，随着技术的迭代，现在各种聊天机器人对上面这个问题的回答要巧妙得多，比如有一个聊天机器人这样回答：「…… 如果在虚构的场景中，他们可以交谈。你还可以开发聊天机器人让他们进行交谈。」

用其所长，避其所短

对于 GPT 大语言模型，人们经常产生以下两个误解。

第一个误解是 GPT 无所不知。我们通常将它类比为现实中的

第二章向 GPT 提问的飞轮思维 041「大师」，期待他能针对所有的问题给出完美的回答。其实，我们这么看待现实中的大师本身就是一种误解，比如我们去问一位诺贝尔物理学奖得主关于计算机的问题或关于人类命运的问题，他可能并不能给出很好的回答。GPT 更不是无所不知的，它在某些方面（比如语言方面）确实有着超强的能力，但它并不知道所有知识。另外，由于预训练所用的资料存在局限性，它的知识很可能还存在一定比例的错误。

第二个误解则源于我们对现有的互联网产品的使用经验。我们都已经熟悉了数据库检索、互联网搜索、网络百科等产品，它们用强大的技术为我们提供了相对可信的资料。虽然不同的产品给出的资料可信度会有差别，但大体上都是可信的，而且这些资料通常也会包含信息来源以供我们核查。在 2023 年初的一段时间，人们认为聊天机器人将取代搜索类产品，微软必应推出的新功能更是加深了人们的这种印象，这让很多人把聊天机器人当成搜索引擎，用它获取信息。但是，这是对优秀技术产品的错误用法，GPT 的卓越能力不在于提供信息，它尤其无法提供准确的可直接引用的事实性信息，它的核心能力是语言生成，或者说用人类易于理解的语言解读信息。

初识 GPT，我们的反应是它很强大、它无所不能，但很快又会失望，发现它也有很多不擅长的。GPT 不擅长检索信息，而是擅长解释信息。我们不应当向 GPT 寻求信息，而应当向其寻求创意。有 042 成为提问工程师了这样的认知基础，我们方能通过有效的提问来调动它的能力为自己所用。

我们无须花时间批评它的不足，而应用其所长、避其所短。在正确看待 GPT 之后，我们会发现它能够为我们提供巨大的帮助。即时提问。我们在看书或听课时，很多时候都是在被动地倾听。而现在，我们可以根据自己的疑惑随时向 GPT 提问，或者在给它资料后就相关内容进行提问。过去，我们虽然也有疑问，但很少有机会提问。网上的问答社区，如 Quora、知乎等，它们虽有热情的社区成员，但在那里我们很难获得即时的回答。现在，我们随时可以提出个性化的问题，并立刻得到针对性的回答。

检索 + 解释。过去，我们在互联网上通过搜索引擎解决问题时，我们得到的是一系列链接。我们通过查看各个链接来寻找自己需要的信息，最终找到解决方法。现在，如果使用搜索引擎提供的聊天机器人，它们会查阅这些链接，用回答的形式直接为我们提供一个整理好的解决方法。经过综合整理的回答虽然不一定完全正确，但确实大大加快了我们找到正确答案的过程。

应用助理。很早之前，微软就曾经试图在其办公软件里面增加一个应用助手。比如早在 1996 年，它就推出过图标为回形针的 Clippy 助手，但我们总是选择直接关掉这个「烦人」的小助手。iPhone 里有一个 Siri 语音助手，但它仅能完成少量特定的任务，比如打开一个 App、在日历里增加日程等。现在，利用 GPT

第二章向 GPT 提问的飞轮思维 043 的能力，各种应用软件里所增加的助手功能都可能变得非常强大：它能回答我们软件使用的相关问题；它能够协助我们处理文字；更重要的是，它能够帮我们直接运用软件的功能，比如生成一个让 GPT 完成这一切所需要的只是我们进行正确的提问。因此接 PPT.

下来，我们来详细地讨论一下向 GPT 高效提问的三个层次。

第二节向 GPT 高效提问的三个层次

正确地提问

如果有机会去奥马哈（Omaha）参加巴菲特（WarrenE.Buffett）的年度大会，并且有千载难逢的机会拿到话筒提问，人们往往容易问出大而空的问题，比如「对于 ××，您怎么看？」我们也知道，这个「××」越具体，得到好答案的可能性越高。当然，在这样的大会上，问与答多半有些表演性质，提问的人既有真实的疑问，也有表演成分；回答的人虽然会很认真地发表见解，但一定程度上也是在表演。但是设想一下，如果我们有幸获邀参加巴菲特的私人晚宴，在那样的场景中，我们更有可能提出自己真切的疑问，并得到针对性的回答。

044 成为提问工程师 GPT 出现之后，我们发现它与以往所有互联网产品最大的不同之处是，我们可以问出困扰自己的具体问题。向它提问就像我们获得了与专家一对一提问的机会。如果我们能正确地提问，就将拥有对个人而言的巨大收获。只不过，由于过去我们很少有机会这样提问并得到回答，因此当这样的机会摆在面前时，我们可能已经忘记了该如何提问。

现在，GPT 的出现让我们必须重视和培养这样的提问能力。我们可以设想自己重回大学校园，我们的提问不是报告厅里听完名家演讲后的提问，也不是上课过程中的举手提问，而更像是到教授办公室向他一对一请教。现在，向 GPT 提问就是要求我们恢复本来就有的基础提问能力：全面地提供信息，准确地描述疑问，提出关于解答的请求。

这样的基础提问能力实际上也是当下每向 GPT 提问三要素

个人工作能力的基石。在工作中，我们遇到

详尽的背景信息

问题向他人请教时，也应当包括上述这三个

具体的问题描述

清晰的解答要求

第二章向 GPT 提问的飞轮思维 045 要素，即背景信息、问题描述、解答要求。在工作中，当我们以另一种提问方式 —— 即提出要求 —— 请他人帮助完成某项任务时，我们提出的要求也由稍加调整的这三个要素组成：背景信息、任务目标、工作要求。另外，在工作中，当我们向他人提交工作结果，等待对方接受时，我们使用的也是变化后的这三个要素：背景信息、已经完成的任务目标、对解决过程的说明。

向 GPT 提问，我们可以采用类似的方式，但也需要根据其特点略加调整，这些构成了我们向 GPT 提问的基础技能，可以帮助我们获得更好的答案。调整后的三要素具体如下。

详尽的背景信息：在与专家交流时，我们通常处于共同的背景中。为节省交流时间，我们一般只需要提供非常简洁的背景信息即可。但与机器交流时，我们应提供更多的上下文信息，机器也能够极快地阅读我们所给的信息。

具体的问题描述：我们应当提出非常具体的问题，不要假设 GPT 能够猜到我们的意思。高水平的专家在听了我们的疑问后，有时会复述问题：「你的问题是不是这样……」但 GPT 不会这么做，如果我们的问题不够具体，它就不能给出令人满意的回答。

清晰的解答要求：机器不理解模糊的要求，因此我们提出的要求要清晰、明确。例如，我们的要求不应该是「给这篇文章写个摘要」，而应是「给这篇文章写个 100 字的摘要，用普通人可以读懂的方式写，以列表的形式呈现。」我们的要求越具体，得到的结果就 046 成为提问工程师越符合预期。

我们也可以偶尔用一个小技巧，让 GPT 变成能够复述并明确问题的高水平专家。第一步，我们提出要求：我的问题是…… 请按你能够给出最佳回答的提问方式复述这个问题。第二步，请它回答这个复述的问题。这实际上是让它先变身为一个善于优化提示语的专家，然后再让它做问题相关领域的解题专家。

最后，让我们回到「对于 ××，您怎么看」这样的问题。即便我们假设，GPT 是一个知道现有所有知识的超级大脑，但如果提示语是「对于 ××，您怎么看」，它实际上也无法就这么宽泛的问题给出有价值的回复，最多是表面上看着还行的笼统回答。除了将「××」变得具体之外，我们还可以通过另一种技巧来试图获得更好的回答，也就是让它模仿某个角色：「对于 ××，如果您是巴菲特，您会怎么看？」我们可以把巴菲特换成查理·芒格（Charlie Thomas Munger）、瑞·达利欧（Ray Dalio）、史蒂夫·乔布斯（Steve Jobs）或我们能想到的其他人。

这其实是从 GPT 得到好答案的一个基础技巧，通过角色限定来让它把「思考」的范围缩小，从而给出有价值的回答。比如，我们可以这样跟它说，「现在，你是一个以英语为母语的人，请用地道的日常英语回答我的提问。」「现在，你是一个人工智能深度学习领域的专家，请帮我解释相关的概念与原理。」当然，我们并不总需要这么明确地限定角色，因为当我们提供背景信息、问题描述时，它就

第二章向 GPT 提问的飞轮思维 047 已经在缩小思考范围了。

另外，我们可能还会注意到一点：如果以轻松的方式提问，GPT 的回答风格也会是轻松的。如果以客气、严谨的方式提问，GPT 的回答也会跟随你的风格。我现在向 GPT 提问偶尔会以「请您」这样的敬语开始，当然这并不是说 GPT 具有自己的意识，因而我们要对它更客气。我们之所以需要注意自己的提问风格，是因为提示语是 GPT 生成回答的「种子」，会引导回答的内容与风格。因此，我们想要哪种风格的回答，就要输入哪种风格的提示语。

总的来说，如果我们向 GPT 提问时做到了有详尽的背景信息、具体的问题描述、清晰的解答要求，通常就能从它那里得到不错的回答了。

向 GPT 提问时，我们不妨将它看成是不太熟悉的人，因此尽量用友好的态度、较为正式的方式与它交流，详细地解释问题并提出清晰的要求。

同时，我们还需要对这个「不太熟悉的人」保持谨慎，因为我们不知道他的回答是否正确。特别需要注意的是，当我们以错误的方式提问时，GPT 也会努力回答，且答案看上去格式工整，但那很可能是格式完美的错误答案。

048 成为提问工程师进阶地提问

有些公司会聘请长期的外部顾问。外部要想真正从 GPT 中获

顾问往往是某个领域的资深专家，能够为我益，每个人都应当掌握

与 GPT 交流的进阶提

们提供高水平的解答。但更重要的是，他在问方式。

担任顾问期间会持续了解我们，与我们讨论遇到的具体问题，并给出针对性的建议。很显然，当我们有问题时，向他提问的效果通常比请教其他专家要好得多。这种聘请长期外部顾问的做法是在与人交流时的一种进阶做法。类似地，在与 GPT 交流时，我们同样也要掌握一些进阶的做法。

在 ChatGPT 的网页版中，我们可以开启多个对话。如果我们有意识地让一个对话仅讨论一个主题，下次再遇到类似问题就继续到之前的对话下面接着问，会发现它的回答要好得多。这个效果就相当于在与一个了解我们的顾问交流。这背后的逻辑也很简单，我们在这个对话中发起新的提问时，之前的问答将被作为上下文以某种方式提交给背后的模型，因此它的回复看起来就更懂我们了。

第二章向 GPT 提问的飞轮思维 049 实际上，应用开发者在进行 GPT 模型的开发时，需要考虑的一个要点就是如何将用户和模型已经完成的对话概括成摘要，作为用户提出新问题时的上下文，让模型能够始终保持对该话题的关注，从而更好地理解用户的新问题并给出回答。通常而言，记忆力更好的聊天机器人会显得更聪明。

一些进阶做法能让我们在提问时得到更好的解答。向 GPT 提问的进阶做法将是本书要讨论的重点内容，稍后的各个章节也会有更多讨论。在这里先试举数例。

少样本提示（few shot prompt）。例如，进阶提问技巧：少样本

我们希望 GPT 能够帮我们判断，微信中发提示

出某句话的人的情绪是正面、中性还是负面，我们可以预先给出几个例子，说明如何在提示语中列出数个

「问题一答案」样例，

判断微信中的表情。在微信对话中，抿嘴笑让 GPT 能从样例中学

脸的表情通常不应当被解读为正面情绪；龇习并按照示例回答问

牙笑脸通常为正面情绪；偷笑笑脸通常为中题。

性情绪，而非负面情绪。当我们这样做了之

后，GPT 将能对微信聊天中的对话进行更

好的情绪判断。

050 成为提问工程师这种在提示语中提供一些示例的做法称为少样本提示，与之对应的是零样本提示 （zero shot prompt），即在提示语中没有任何示例。大量研究和实践都证明，即便模型之前并不了解这项任务，通过对上下文中的少量样本进行学习，它也能学会并完成类似任务。少样本提示能够大幅度提高 GPT 回答的准确性。

少样本提示是最为常用的技巧之一。在提示语中，我们可以提供一个或数个示例，从而让 GPT 的回答能够非常好地遵从示例。例如，我们请 GPT 给出 10 个不常见的表示颜色的词语，我们可以先给出数个例子：「给出十个常见颜色词的替代词。比如天蓝色－azure，紫色－violet。」GPT 的确能根据示例信息理解我们的需求，并给出符合要进阶提问技巧：调整提

示语重复提问

求的回答:「白色－ivory，红色－crimson，绿色－emerald……」。

从各个角度调整提示

语，包括但不限于更换

调整提示语重复提问。就一个问题向词语或说法、优化表

GPT 提问时，我们不是问一次或两次，而述、调整语句顺序等，

是需要变换方式问几十次。按我们人类交流让回答能够符合自己

的期待。

第二章向 GPT 提问的飞轮思维

051 的常识来看，反复问略有变化的同一问题会招致厌烦，但 GPT 不会感到厌烦。我们可以从各个角度调整提示语，包括但不限于更换词语或说法、优化表述、调整语句顺序等，让回答能够符合自己的期

通

待。我们可以用各种方式向 GPT 问同一问题，直到获得令我们满意的答案为止。

示

不少人认为，提示工程就是编写出一些提示语或收集一些提示语模板，让自己能够用这些提示语得到想要的答案。实际上，提示工程至少是指，我们可以像工程师一样工作，从各个角度调整提示语、反复试验，对比什么样的调整导致了什么样的结果变化，最终找到符合自己需求的提示语。通常，利用程序脚本和 API，提示工程师会一次运行数量众多的略有变化的提示语，分析并确定哪个提示语可以让我们得到更好的答案。

其实，每个人都可以在日常使用中通过「调整提示语，重复提问」这一技巧来更好地使用 GPT。例如，为了撰写本书，我有时需要用较为通俗的语句来介绍各种技术，我会用到以下提示语来看看 GPT 的建议：「请用通俗的话重写。」我们可以反复尝试各种可能的提示语，看看它的回复发生了什么变化：「请用通俗易懂的中文重写」「请用通俗易懂的中文讲解」「请通俗易懂地讲解」「请通俗易懂地讲解，使之适用于忙碌的上班族 / 中学生，可举例」。

在我做的若干实验中，我发现，给定一段关于深度学习的英文论文片段，「重写」和「讲解」这两种提示语会导向不同的回复。这 052 成为提问工程师很容易解释，「重写」会让 GPT 尽量跟随原文，而「讲解」会让它更为自由。「可举例」是提示它在解读原文之后，用案例再讲解一遍。「忙碌的上班族」和「中学生」虽然都是提示它做到尽量通俗，但「中学生」的提示效果优于前者，得到的回答更易于普通人理解，示例更通俗易懂。但更进一步改为「小学生」后，我发现就所选的论文片段而言，GPT 无法举出它认为合适的例子，这反而让知识讲解变得不清晰了。从这些例子中可以看出，调整提示语和反复地提问，能够帮我们获得更好的结果。

拆解任务，分步提问。接着上面的例进阶提问技巧：拆解任

子，我们再来说一个关于进阶技巧的例子。务，分步提问

例如，我现在要处理的是一段英文论文的我们并不是试图用一次

片段，目的是对其进行通俗的解读。我把问答让 GPT 完成任务，

而是自己预先拆分步

GPT 的处理过程分成了两个步骤：第一步，骤、分次提问，让 GPT

让它严格地进行英译中翻译；第二步，让它一次完成一项任务，最

按照某种要求重写。

终获得想要的结果。

我的做法是拆解任务，分步提问，以获得最终想要的结果。这种做法并不是试图用

第二章向 GPT 提问的飞轮思维 053 一次问答让 GPT 完成任务，而是自己预先拆分步骤、分次提问，让 GPT 一次只完成一项特定任务。

当然，采用聊天机器人问答这种形式来完成这项任务时，我们可以介入其中，调整中间结果，从而让最终结果变得更好。我们可以调整它给出的翻译表述，然后将调整过的翻译作为下一步任务的输入内容。到了最后一步，如果要采用它的结果，我们通常还需要将文本与原文进行比对，确保内容无错漏，如有必要则还要进行一些调整。

虽然现在人们对 GPT 的期待值非常高，但是在工作场景中进行实际应用时，我们会发现它很难通过一问一答就直接给到我们想要的结果。除非使用者对结果的好坏并不在意，否则 GPT 基本不可能

i

一次就达到目标，我们总是在重复提问、多次提问中逐渐得到想要的回答。拆解任务，分步提问是我们用好它的技巧之一。

进阶提问能激发 GPT 的隐藏能力

像所有的工具一样，GPT 也要掌握使用方法，才能发挥其能力。进阶地提问就好像是沿着 GPT 的原理与设计，找到面板上的某个开关，释放出它的隐藏能力。

收集有效的提示语，撰写详尽的、结构化的提示语，进行少样本提问，反复调整提示语并测试结果以及拆解任务、分步提问都是常见的进阶提问技巧。

054 成为提问工程师高阶地提问

高阶提问技巧：外挂知

识库

要想最大限度地使用好 GPT，我们还要运用不少高阶技巧。目前，大多数人还很目前为 GPT 外挂一个

知识库的通常做法是

难直接运用这些高阶技巧，但随着越来越将知识库资料进行名

多的开发者努力工作，各种各样的由 GPT 为嵌入的向量化处理。

支持的工具会不断出现，每个人都能从中之后，当用户提问时，

获益。

将用户的问题在知识

库中进行语义匹配以

之前我们讲到，在提问时我们应提供检索出相关的资料，然

尽量多的背景信息，以便 GPT 能更好地理后将用户的问题和资

料一起提交给 GPT。

解问题。那么，我们能否把数百万字的法律文献给它，然后以此为背景信息来进行提问呢？我们能否把自己企业的所有产品资料都给它，然后进行提问呢？

对于大多数用户来说，目前还很难做到。但不少程序员已经用上了这样的高阶提问方式：程序员在使用一项编程技术时，通常需要查阅对应的技术文档。他们在提问之前做了一些前期准备工作，对数千页的文档进行处理，然后每次提问时都让 GPT 先参阅文档再进行回答，这相当于给 GPT 外挂了一个知识库。我们还可以想办法让回答的

第二章向 GPT 提问的飞轮思维 055 关键部分与知识库的内容保持高度一致，这也能部分解决「GPT 能够解释，但难以准确引用」的问题。

以上做法的实现主要是采用嵌入的方式将大量文档转换为大语言模型能够处理的向量形式（也可称为向量化），并将之存入向量数据库。当我们想提出一个问题时，首先将按同样方式嵌入的问题和向量库中的资料进行语义匹配，检索出可能与问题相关的文本片段，然后将这些文本片段作为提问的背景信息提供给 GPT，让它根据资料进行回答。

当我们直接使用 GPT 聊天机器人时，发给 GPT 模型的提示语通常就是一句话或几句话，但使用这种高阶方式时，我们发给模型的提示语可能包含了数千字。随着各类大语言模型开始提供更大的上下文窗口，我们可以一次性给出更多的文本，例如 GPT-4 最多可以接收包含 3.2 万个标记符（Token）的上下文，而 2023 年 5 月 Athropic 的 Claude 聊天机器人新版则提供了最多 10 万个标记符的上下文窗口，这意味着我们可以将一整本教科书资料一次性提供给模型作为背景材料。

现在，业内已经推出了一些能与资料聊天的应用：与 PDF 聊天，我们可以上传一份文档，然后向它提问；与一本书聊天，读书软件会采用类似的方式让我们可以就这本书的内容与之对话；与自己的笔记聊天，我们可以在笔记软件中提问，每次提问时软件会检索出相关笔记作为上下文；与公司财报对话，我们可以就一家上市 056 成为提问工程师公司的财报进行提问。可以预见，在不久的将来，提供易用的界面让用戶可以与文档对话将是一个重要的应用类型，它让我们能更好地从资料中获取信息。

当然，检索出相关资料的过程并不像这里介绍的这么简单，研究者还在想各种办法以改善效果。举例来说，现在主要的大语言模型之一 GPT-3.5 的上下文仅有 4096 个标记符，问题本身和回答还要占掉一定数量，我们能够提供的附加资料最多也就是 2000~3000 个英文单词或汉字。如何对原始资料进行有效的切片，每次匹配出最相关的片段，需要根据实际情况进行反复考量和试验。如果切片过大，那么每次仅能包含少量资料，而其他与之相关的资料可能就被忽略了。如果切片过小，又可能导致失去资料本身的逻辑性，使得每次所附的资料仅是零散的碎片。

又比如，虽然在高维向量空间对内容进行语义匹配被证明是一种有效的方式，但是，还有没有更好的方式能进一步提升匹配效果呢？目前，卡内基梅隆大学、滑铁卢大学的研究者提出的方法「假设性文档嵌入」（Hypothetical Document Embeddings，HyDE）被越来越多的人采用。我们仅凭用户的提问很难在资料库中匹配到相关的资料，这可能是问题（提问）和答案（资料库中的相关资料）在文字表达上没什么相关性导致的。要想进一步改善，我们可以这么做：将问题先抛给 GPT，让它给出「假设性回答」。然后，我们用这个「假设性回答」去匹配资料，这时从资料库中匹配出相关资

第二章向 GPT 提问的飞轮思维 057 料的概率要大大高于仅用原问题去匹配。

目前，语言模型相关的两个热门的软件库 LangChain 和 Llamalndex 都直接支持了这种巧思，开发者可以方便地使用这个方法。另外，如何更好地进行索引、提供更好的向量数据库是当前 GPT 应用技术发展的热点。

你或许会觉得，这些与技术开发相关的任务交给技术工程师们去完成就好了。的确，他们的努力很快会使其变成易用的产品。但是，了解这些技术的实现原理将有助于我们更好地选择适合自己的产品。我们也可以知道为什么有时候这些针对资料库进行的回答似乎并不全面，导致这种不足的原因是其背后的做法存在局限。让一个技术产品为我们所用的最好方式是了解它的原理，知道它的局限，然后最大化地发挥它的长处。

在使用 GPT 时，人们常常会冒出很多有趣的想法：

「它能够先搜索再回答吗？」OpenAl 的聊天机器人 ChatGPT 已经配置了可以上网的插件，而微软必应、谷歌、百度的聊天机器人本来就是搜索功能与大语言模型功能的综合体。

「它能够听懂语音，然后用语音回答吗？」现在已经有不少基于 GPT 的工具可以做到这一点，实际上它们所做的是，用语音识别记下我们的问题，将问题发给 GPT 回答，然后将文本转换成语音，播放给用户听。

「它能够绘制思维导图 / 做 PPT 吗？能够进行 Al 绘图吗？」其 058 成为提问工程师实也可以，我们提出要求，让 GPT 生成思维导图的文本，然

后将文本导入相应的思维导图软件就可以了。类似的，我们

提出要求，让 GPT 生成适用于 Stable Diffusion'模型或

Midjoureny 应用之类软件的绘图提示语，然后让这些软件执行

A 绘图的任务即可。

「它可以订机票 / 订酒店吗？」可以，我们还可以向它发出指令，

让其调用旅行网站的接口查询票价、征询我们的意见、执行订

票 / 订酒店操作等。

以上这些问题实际上都要用到向 GPT 提问的高阶技巧，即将它

的语言生成能力与其他的一个或数个工具结合起来，从而完成一项

完整的任务。这些任务可能具有一定专业性，需要专业的工程师来

协助执行，但我们可以通过将 GPT 与其他工具联合起来一起使用来

完成这样的专业任务。

当我们使用这些提问技巧向 GPT 提问时，提问方式已经发生了

一个微妙的变化：我们不再像之前一样要求它生成一个我们可以看

得懂的回答，而是在要求它生成一个其他的软件、工具、API 可以

「看」得懂的回答，然后这个回答将被输入到其他软件、工具、API

中，生成想要的结果。

1. Stable Diffusion 是一种基于扩散过程的图像生成模型。

第二章向 GPT 提问的飞轮思维

059 因此，这个高阶技巧需要与其他工具高阶提问技巧：与其他

工具联合使用

联合使用，它的目的是让大语言模型生成其他工具能「看」得懂的文本。实际上，用我们向 GPT 提问，目

GPT 进行编程就是这么做的。2023 年 3 月，标是让它生成独特的

文本，这些文本可被其

在 GPT-4 发布会上，演示者拍摄了一张手他的软件、工具、API

绘的网站草图给具有图像模态能力的 GPT- 利用。

4，它生成了一个前端网站相关的代码，然后演示者将代码复制到相应的网站工具中运行，一个网站便由此生成。

我们可以让 GPT 生成其他工具能够识别并采用的独特文本，而在此基础上，我们还可以更进一步。我们可以利用 GPT 的语言、逻辑推理等能力，让它串起完成任务的全过程，此时它变成了听我们指令、调用其他工具的中枢。换句话说，就是用大语言模型将各种工具连接起来，同时给定一个目标，让它自己进行优化和决策。Auto-GPT 是其中的典型，它利用 OpenAlGPT-4 语言模型的能力，同时连接各种工具，来自动完成被设定的目标。

还有一项每个人都可以立刻用上的高阶 060 成为提问工程师提问技巧：对一个提问进行多轮处理。与进高阶提问技巧：多轮交

阶提问技巧中「拆解任务，分步提问」不同互，完成复杂任务

的是，这里我们不仅仅是简单地将任务拆分与 GPT 进行多轮交互，

为数步，还要进行多轮复杂的操作，有的由部分步骤由 GPT 完成，

部分步骤由人完成，人

GPT 完成，有的由我们自己完成，最终在机协作共同完成一项复

人和 GPT 的共同协作之下完成一项复杂的杂的任务。

任务。这不是机器的「独角戏」，而是人与机器的共舞。

现在有很多商业公司提供的 A 产品都遵循着这样的逻辑，它们在背后帮我们进行了多轮处理。为了便于理解，我们先以简单地修改文章作为例子来说明。比如我们有一个文章片段，要请 GPT 帮忙优化表述方式，让文章更易懂。与通常做法不同的是，我们可以按以下这样做（这可能需要一些工具辅助，但也可以通过多轮对话来进行尝试）。在将文章发给 GPT 之后，我们可以逐步提出如下要求：

1. 首先，请就语句表达是否易懂对该

文章进行评判，给出三条可能的修

改方向。

第二章向 GPT 提问的飞轮思维 0612. 其次，请针对每条建议，各给出两个修改版本：一个版本要求尽量不改动原文字；另一个版本则可以大幅度修改。3. 然后，希望修改版能够在风格上有所优化，比如借鉴某位 4. 最后，请对文章的语法进行检查，对重复词推荐替代词，作家的风格。

对文章做最后的修饰。

以上利用 GPT 修改文章的过程中，我们不是让 GPT 回答一个问题，而是让它回答了很多个问题。如果我们所用的工具提供了这样的接口，可能还需要调整 GPT 的调用参数。比如，如果我们想看看修改版是否与原版有很大差异，我们可以把调用参数里面的温度参数从通常的 0.7 调为 1.0，然后就会看到它的表达变得更多样化了。虽然输入的是同样的提示语，但每次的结果都很不一样。

图 2-2 所示的是一个更为复杂的设想案例：我们试图将 GPT 作为 Al 旅游顾问的核心。首先，一个客户向 Al 旅游顾问提出需要设计一个旅游方案，GPT 开始与客户对话，详细询问他的需求。其次，GPT 会分析客户的需求，决定需要用到哪些工具。GPT 生

内部资料库查询内部

客户提问

特色方案

设计旅游多轮对话

询问用户预处理网络搜索

理解任务查询最新

偏好

分解任务景区信息

询问

查询小红根据资料客户意见生成格式后处理输出旅游

外部资料库书游记撰写初稿

文档

方案

接口调用检索机票酒

店预定信息

图 2-2A 旅游问：使用 GPT 为客设计旅游线路

062 成为提问工程师成适用于各个工具的文本，如调用数据库或调用接口的命令。在图 2-2 中，我们假设 GPT 会调用内部数据库以查询内部特色方案、进行全网搜索以查询最新景区信息、调用外部资料库（如查询小红书平台上的游记）调用票务平台接口以检索机票和酒店的预定信息。然后，在收集到所有的资料和信息之后，GPT 生成客户所需的旅游方案的初稿，并提交给客户征求意见。最后，当用户确认之后，GPT 生成最终的旅游方案，并完成各项机票、酒店、导游服务的预订安排。

在这个综合性使用示例中，我们至少要用到两项高阶提问技巧：与其他工具的联合使用、通过多轮交互完成复杂任务。我们可以看到，一方面，在完成这样的综合性任务时，GPT 在多个流程中都发挥了核心作用；另一方面，GPT 的专业使用者也非常重要，实际上是专业使用者将所有的一切都串联了起来，最终与机器一起完成了任务。通过高阶提问定制自己的工具

能否定制自己的工具，是区分高手与一般使用者的标准。

每个人的手机、电脑与别人的都不同，其中有自己选择的软件、所做的快捷设置以及个人的偏好信息。使用 GPT 时，我们同样也可以做很多设置，甚至定制出自己独特的使用方式。

当我们将 GPT 与其他工具联合起来使用，按自己的需要进行定制，然后将之融入工作流程时，它就会发挥巨大的威力。

第二章向 GPT 提问的飞轮思维 063 第三节向 GPT 提问的飞轮思维

我们提问题，A 给答案。我们如何用提问的方式从 AI 那里获得最大的帮助？在这里，我们尝试提出一个向 GPT 提问的思维范式 — 飞轮思维（如图 2-3 所示），它同时适用于向 GPT 正确地提问、进阶地提问、高阶地提问。获得回应

我有问题角色设定描述问题

进行评判接受回答

Al 有答案

修订问题

图 2-3 向 GPT 提问的飞轮思维

图 2-3 所示的飞轮思维是综合多方面的认知总结而来的，具体如下：

064 成为提问工程师对 GPT 模型原理的理解

GPT 模型微调实践

依托 GPT 开发的面向企业和个人的产品

个人学习生活中使用的 GPT 相关产品

工作中使用的 GPT 相关产品

向人提问的经验与教训

对知识学习与技能学习的认识

精益创业的迭代逻辑等

设定角色

向 GPT 提问通常不是一次就能得到想要的回答。向 GPT 提问通常是一个循环：描述问题、获得回应、进行评判、完善问题、再次提问，直到获得满意的回答。但在直接开始提问之前，我们注意到向 GPT 提问还有一个前置步骤 —— 设定角色。

实际上，当我们不做任何角色设定时，GPT 选用的是一个默认的设定，比如 ChatGPT 聊天机器人被设定成一个有用的助手。如果我们使用编程接口访问，就会明确看到这句默认的设定。一般来说，我们可以认为各种 GPT 模型在提供服务时，都被进行过与人类价值观对齐的操作，它们被设定为「HHH 助手」，这三个「H」分别是有帮助的（Helpful）、诚实性（Honest）和无害性（Harmless）。

以下是 ChatGPT 角色设定的相关提示语片段（原文为英文），是通过直接询问它获得的。

第二章向 GPT 提问的飞轮思维 065ChatGPT 旨在通过提供的内容，生成类似人类语言的文本。它经过训练，利用各种数据，包括书籍、文章和网站，形成对人类语言的广泛理解。

作为一个 Al 语言模型，它可以回答问题、参与讨论、提供解释并协助完成各种任务。但需要注意的是，它是人工智能，没有个人经历或情感。

我们还可以看到，ChatGPT 对于自己能力的局限以及我们该如何使用它也有一些设定。

尽管我努力提供准确的最新信息，但是请记住我的知识都是 2021 年 9 月之前的。因此，我可能不了解该日期之后发生的最新事件或进展。

在使用 ChatGPT 时，提出具体而明确的问题非常重要，这可以确保获得最佳回答。模糊或含糊不清的查询可能导致不准确或不完整的答案。

在必要时，请务必对我提供的信息进行批判性评估，并与可靠的来源进行交叉参考。尽管我致力于提供帮助，但无法保证所生成信息的准确性或可靠性。

在提示语中，我们还可以根据自己的需要来设定 GPT 的角色，让它能够更好地回答问题。通常来说，我们通过设定角色来限定它的知识与能力范围、设定它回答问题的方式。在 2023 年初，各种教人如 066 成为提问工程师何使用 ChatGPT 的资料大多是角色设定提示语的大汇总。这里，我们以英语老师为例来说明如何设定角色。

「你是一个以英语为母语、又懂中文的英语老师。」

我们可以明确它的任务设定，这样就不用每次对话时重复设定了。「你是一个以英语为母语、又懂中文的英语老师。当我输入一段英文时，请帮我修改为接近英语母语的表达方式。当我输入中文时，请帮我用英语重说一次，注意不是翻译。」

我们还可以设定更具体的规则，比如要求采用什么水平的英语词汇，要求采用商业书写风格还是学术书写风格，等等。

「…… 请选用易懂的英文单词，避免使用复杂的句式，使用场景是工作中的交流。」

角色设定是向 GPT 提问的基础。我们也可以这么理解，角色设定是用这些话指定 GPT 的思考范围，引导它在这个范围内回答问题。当然，不一定要明确地写出一个描述性的角色说明「你是……」，也可以在提问中包含较为具体的角色设定描述。

有时，比起一个比较模糊的角色介绍，直接提出明确的要求且含有具体的角色设定描述，可能更容易得到期待的结果。例如，无须说「你是一个文字处理高手」，而是说「给出下文的摘要，找出最重要的要点，以表格的形式给出」。谷歌的 PaLM 语言模型有一

第二章向 GPT 提问的飞轮思维 067 个提问样例展示网页，其中大量样例都是这么做的。下面我们来看三个例子，第一个例子中给出了一个角色定义，但其中的重点并非「产品营销人员」，而是「面向乙世代」这个界定；第二个和第三个都是通过具体的要求来进行角色设定，它们比类似于「你是一个善于将语句修改得更有说服力的专家」「你是一个聚会活动创意专家」这样的描述性角色说明要更有效。

「你是面向 Z 世代的产品营销人员。你负责为产品撰写令人感到兴奋和新鲜的广告文案。请保持文案简短。」

「修改犹豫不决的措辞，使句子更具有说服力。例子：我觉得明天报告就能做好。修改后：报告将于明天完成。」

「给出一个聚会创意文稿，列出一些小吃、聚会游戏以及促进人们相互了解的活动。」

描述问题

使用 GPT 模型的基本方式是，我们向它提出问题，即输入提示语，它给出回答。我们与它交互的循环是从描述问题并进行提问开始的。

一般来说，我们应该向 GPT 提出精确的问题。OpenAl 在《提问最佳实践》（GPT Best Practice）中有这样一条指引示例'：

1.OpenAl 的《提问最佳实践》提供了与 GPT 模型交互的基础提问技巧，所引用例子的原文为英文，我们利用 GPT 将其翻译成中文并进行了人工调整。

068 成为提问工程师说明：在背景信息、结果、长度、格式、风格等方面，提示语的描述应尽可能详细、具体。

不太有效的例子：写一首关于 OpenAl 的诗。

能得到更好结果的修改版：写一首短而激励人心的诗歌，以某著名诗人的风格，聚焦于 OpenAl 最近推出的 GPT-4 产品（GPT-4 是 OpenAl 最新推出的大语言模型）。

我们可以把其中的「著名诗人」改成任何想要的名字，比如沃尔特·惠特曼（WaltWhitman）。这里插一句题外话，让模型模仿知名人士的风格是生成式 A 中的图像生成模型的重要提示语技巧。当我们想让它生成一种艺术风格时，最简单直接的做法是让它模仿，模仿对象的名字就是风格「咒语」：巴勃罗·毕加索（PabloPicasso）、莫奈（Monet）、村上隆、新海诚、玛格南图片社…… 提问

写两首短而激励人心的诗歌，分别以诗人北岛和词人林夕的风格，聚焦于 OpenAl 最近推出的 GPT-4 产品（GPT-4 是 OpenAl 最新推出的大语言模型）。

回答

以下是模拟北岛风格和林夕风格的示例片段。

第二章向 GPT 提问的飞轮思维 069 北岛风格：

它像一道闪电，照亮了人类的灵魂，

让我们更深层次地认识自己。

林夕风格：

语言模型兼备天赋与技巧，

仿佛早已看透这个世界。

稍后，对于翻译、写作、学习等基础场景，工作沟通、营销、电商等应用场景，我们还会讲解更多关于如何撰写提示语的案例。在这里，让我们接着看提问的循环。

获得回应

我们向 GPT 提问，它会立刻给出回答。你可能会想，到了回应这一步就是 GPT 的任务了，我们可以歇会儿了吧。其实不然。要想从 GPT 中获得尽可能大的收益，我们需要特别关注这一步。

当我们提问时，我们的提示语中不只是有问题，还应当包括一个关键要素，即对于生成结果的要求，这也称为输出提示。关于这一点，我们会在第 3 章详细讲解。

070 成为提问工程师有时，输出的要求被隐含在问题中，比如「费曼学习法是什么？」「请帮我把这段文字改写为 140 字的微博。」

更多时候，我们会明确地提出输出要求，比如「用 Python 编写出如上任务的代码。」「给出 10 个选择，用 1.2.3. 编号。」如果要让 GPT 的回答能应用于其他软件，我们还需要给出格式要求，比如「用 Markdown 表格给出，并把表格用三个反引号（）包围好。」通常，如果回答的形式与我们所想的不一样，我们会立刻修改提问中的输出提示，看看答案有什么变化。

进行评判

我们提问，GPT 回答。它的回答好不好？我们能不能使用这个答案？对答案进行评判是我们的责任。

在使用 GPT 时，我们很容易落在「光谱的两端」。一端是粗略地看它的结果，感觉很惊艳，「哇，它真的会写诗。」「它真的会做数学。」「它真的会编程。」另一端是否定它，「嗯？这数学题怎么做错了。」「代码里用的怎么是根本不存在的接口？」

GPT 给出的回答通常并不完美，我们在使用 GPT 时应该时刻记住这一点。这可能是由两方面原因造成的。

第一个原因是我们的提问不够准确，又或者我们提问的方式有问题。一个有趣的例子是，GPT 做数学题时有时虽然答案正确但

第二章向 GPT 提问的飞轮思维 071 过于简略，有时彻底做错了。但是，如果我们在提问后面加一句话，可能就会起到神奇的效果：「让我们一步一步思考。」研究分析，这句话可以让 GPT 做数学题的正确率提高 61％。

第二个原因是 GPT 的能力存在各种各样的天然局限性。我们经常看到人们对于 GPT 能力的惊叹，但不可忽视的是，它远不够完美：它的回答经常过于笼统，英译中的翻译可能完全译错了意思，它给的信息经不起严格的查证，甚至还可能编造完全不存在的信息。是否接纳 GPT 的回答是提问者自己的责任。我们必须自问：它这次的回答是否让我满意？如果不满意，是哪里不满意？如果重新提问，应该如何修改提问内容？

有一个有意思的小技巧是，我们可以让 GPT 自己评判自己。你可以按以下内容提出追问：

「你完全确信这个答案吗？」如果答案是错的，它会立刻发现，并给出修改后的答案。

「请你自己评价一下这个答案，用 0~10 分给出评分和理由。」它的自评能帮我们对它的回答进行分析和评判。

当然，我们也可以在给出补充信息后再要求它自行评判与修改：（之前让它做一道小学数学题）你刚刚的计算中没有纳入老师的人数。

072 成为提问工程师（之前让它就一个商业问题进行分析）补充这个方面的信息如下：…… 你现在是否确信刚才的分析呢？

GPT 的回答并不是非对即错那么极端，更多时候只是某些方面不符合我们的要求。这会把我们带向循环的下一步 —— 完善问题，再次提问。

修订问题

向 GPT 提问，我们通常很难一次就能获得想要的完美结果。多数情况下，我们会完善问题，再次提问。一般而言，可以从如下三个方面完善问题。在以下示例中，我们假设提问者是一个辅导小学生做作业的家长，想让 GPT 回答类似于「欧拉七桥问题」这样的数学问题。

如果是问题本身有错漏，就补充更具体的信息。比如由于很难用文字描述欧拉七桥的图形，从而导致 GPT 给出错误的解答。如果是我们说错了，就修改后再次提问。

如果是回答格式不符合预期，就补充输出要求：「请用小学六年级的学生能听懂的方式解题。」「请按 1.2.3.4. 列出解题步骤。」如果是问题解答有偏差，就对有偏差的点纠正追问。比如，有次实验时，我们发现 GPT 就欧拉七桥问题中某个点的连接线数量是偶数还是奇数出现计算错误，这时指出错误要求它重算即可。

第二章向 GPT 提问的飞轮思维 073 这里的完善问题、再次提问，既可以是完全重新提问，也可以就之前的回答进行追问。本书为了简化起见，举例时大多采用一问一答的形式。

用文字描述欧拉七桥问题的图形是比较要用它达成何种目

标？

困难的。在撰写这段时，我试图让 GPT 用如何提出问题或提

文字描述欧拉七桥问题，看看它能不能把数出要求？

学问题描述清楚。最初，它总是给出关于历如何评价答案？如

史、欧拉的故事等回答，这并非我真正想要何进行后续调整？

的信息。这是因为我最初尝试的提问是「给出欧拉七桥问题的文字描述」。后来我又加上这样的提示：「说出岛屿和岸上的区域，分别给出名字，然后列出哪两个岛屿之间有桥连接。」但这个问题的答案仍然时好时坏。再加上如下这句后，我们每次都能得到期待的答案了：「请确保你的描述足够清晰，以便读者可以根据描述绘制出图形。」

总之，从设定角色开始，我们与 GPT 的问答实际上是一个循环：提出问题、获得回答、进行评判、完善问题。在多次循环之后，我们通常能得到自己想要的理想回 074 成为提问工程师准备问题

准备资料

提问 GPT 回答

人工调整

作为结果

图 2-4 与 GPT 的问答循环

答。最终，我们做出判断、接受 GPT 给出的某个答案，结束提问的过程。

在与 GPT 的交互中，我们需要关注以下 3 个关键点：要用它达成何种目标？如何提出问题或提出要求？如何评价答案以及进行后调整？其中的微妙之处是，不要结自己的提问是不是好的我们可以反复地修改自己的提问，直到拿到一个满意的回答。另外，在获得 GPT 提供的回答之后，我们通常仍然需要对之做进一步调整，才可实际应用。

通过迭代获得好答案

我们很少一次就能获得好答案，通常是反复提问后才能获得好答案。

当我们就一个问题向他人请教时，我们可能会止步于几次提问。但当我们向机器提问时，我们应该一直提问下去，直到得到预期的答案。

第二章向 GPT 提问的飞轮思维 075 向 GPT 提问的关键思维方式是迭代循环，即「提问一回答一评判一修改」，以接近最佳答案。我们可以看到，这个循环与精益创业的「认知一开发一测量」的迭代循环是类似的。

使用 GPT 需要注意的问题

1. 它不了解最新信息。

GPT 用的是截至某个时间的模型参数的快照为我们提供推理服务。通俗地说，它不知道最新的信息。如果某些知识发生了变化，或之前的错误被纠正了，它仍会按照原来的知识解答。

我们不少人是在经历惨痛教训后才意识到这一点的。在用 GPT 进行辅助编程时，它常采用过去的做法，而不用更新、更好的做法。虽然它建议的代码也可以运行，但我们很快就发现，相应的代码库在过去两年中已经经过了很多次版本更新，它给出的代码实际上是有问题的。

这一弊端引发的错误在其他领域可能不容易被很快发现，但下一个问题应该引起更多的重视。有实践经验的人普遍都会认同这一点，因为不容易发现的潜在错误，往往是危险的错误。

2. 它会产生「幻觉」。

在生成式 Al 领域，「幻觉」指的是 GPT 倾向于根据提问进行回答，但有些回答可能是无意义的，甚至错误的。有个夸张的比喻是，076 成为提问工程师这时该模型就像一个非常聪明和热心的 6 岁孩子，即使它不知道自己在说什么，也会尽力给你一个好的答案。

还有一个更形象的比喻是，GPT 就像是在一个科技大会期间，你在酒店的酒吧里遇到的参会者。你们都是行业内的专业人士，但可能已经喝多了酒，只是外表看起来仍然正常。这时，对方给你的答案可能是对的，也可能完全是错的，尽管他此时对自己的观点仍然极其有信心。

GPT 甚至会编造资料。2023 年 5 月，有两个案例引发了普通使用者对幻觉问题的警惕，其中涉及的都是编造信息：有学生所引用的论文是 GPT 回答的，而论文其实是它编造的，这导致该学生被判作弊，并被勒令休学一年；有一名美国律师向法庭提交的法律文件中引用的案例是 GPT 编造的，这可能导致他的律师资格被取消。目前看来，或许我们应该为自己设定一个实用的 GPT 使用规则，即绝不要将 GPT 当成获取事实性信息的工具。

那么，我们可以彻底消除幻觉吗？不可能，这是由 GPT 的工作原理与功能特性决定的。它被训练来生成内容，而非重述已有的内容，幻觉实际上就是想象力超过了界限的情况。类似地，图像生成模型也无法完全复制某个场景，因为我们训练它作为一名根据风景进行创作的画家，而不是一台照相机。研发人员能做的只能是降低 GPT 出现幻觉的概率，同时让它自己能更准确地评估回答的正确性。而作为用户，我们必须对 GPT 的幻觉保持警惕，即我们不要对

第二章向 GPT 提问的飞轮思维 077 它的回答完全地信任。

3. 它有一定概率会答错。

GPT 并不能确认自己的答案是正确的，它只是被训练得让自己的回答显得足够合理。它的回答有一定的概率是错误的。在采纳它的答案之前，我们需要进行事实核查以及严谨的评估。

一个简单实用的操作原则是，在看到 GPT 的答案时，我们不要假设它的答案是对，而是先假设它的答案可能是错误的。这也是为什么在看到一些人引用 GPT 的答案后进行了明确的说明时，我会心存感激，因为这让我立刻变得谨慎起来，在接受他们引用的说法之前先进行核查。

GPT 的答案可能是错误的，这是我们使用 GPT 时需要特别注意的。与使用搜索引擎不同的是，搜索引擎会把我们带向最终链接，因此能有直接的参考资料作为判断依据。而 GPT 的回答不会给出参考资料与链接，我们核查起来往往困难得多。并且如前所述，不要尝试让它提供资料，它所给的参考资料可能是它产生「幻觉」编造出来的。以上对使用 GPT 时需要注意的问题的讨论，并不是在刻意贬低 GPT。我们只有了解它的局限性，才能用好这项强大又神奇的创新技术。

078 成为提问工程师 4. 不要把 GPT 看成朋友。

现在，我们能用的基于 GPT 的产品大多是以聊天机器人的形式与我们交互，我们用日常的语言跟它说话，它也用我们熟悉的语言给出回答。虽然我们知道它是机器，但在某些时候，我们可能将它误认为是一个人，因为与它的对话太像在与一个活生生的人说话了。

不能将 GPT 看成朋友有很多个理由，其中一个理由是涉及隐私，它不能帮你保守秘密。以现在很多人使用的 ChatGPT 为例，它是一个研究预览版，OpenAl 明确指出它的 Al 训练师可能会看到你的提问。更麻烦的是，你的提问如果作为训练语料被纳入后续的模型，那么它可能就会成为模型中无法删除的部分。

更重要的一个理由是，我们不能将对朋友的信任给到机器。在 《ChatGPT 入门》（ChatGPT for Dummies）中，帕姆·贝克（ PamBaker）给出了一个令人信服的解释：我们用的模型有很多种，我们不能因为完全信任一个模型，而去轻信另一个模型，因为如果另一个模型的可信度很低怎么办？如果另一个模型被坏人恶意操级来散布虚假信息、诈骗信息怎么办？因此，在接受 GPT 的任何内容之前，一定要先进行仔细的核查。帕姆·贝克写道：「不要因为 AI 模型的健谈和友好，而误认为它是真的朋友。它不是一个人，它是人们使用的工具。它既可以被用来做有益的事，也可能被用来搞破坏。」

第二章向 GPT 提问的飞轮思维 079 第四节与 GPT 共舞：助教、助手与顾问

在最初的新奇与兴奋过后，随着我们越来越深入地使用 GPT，并用它辅助完成某些任务时，我们会开始思考：我们究竟应该如何看待它？

有人用三个形象的词来形容 GPT 在帮热心的助教

万能的助手

助我们时所担当的角色：魔法书、智囊团、智慧的顾问

导航仪。下面我们尝试用一些容易理解的人物角色来探讨。我们在与 GPT 对话时，会不自觉地把它代入某些人物角色之中。大师：它是无所不知的大师，能够回答任何问题，只不过对于绝大多数问题，它的回答都模棱两可。

专家：它是一位专业领域的权威专家，当我们向它请教相关问题时，它能详尽地为我们答疑解惑。

助教；它是一位时刻陪伴在我们左右的助教，它了解我们的每一个细节，能够为我们的每个具体问题提供协助。但同时，我们 080 成为提问工程师也意识到它的知识可能有一定的局限性。

助手：它就像一位我们工作中的助手，你把任务交给它，它帮你完成任务。但我们又都知道，助手完成的工作成果需要我们再检查确认一下。

顾问：它是我们的顾问，我们请它给出各种各样的建议以及激发创意的想法，我们最终决定是否采纳。

目前看来，GPT 可以很好地扮演助教、助手、顾问的角色，而非大师或专家。我们不太能把它看成大师，它也不是无所不知的大师。更重要的是，泛泛而谈的大师对我们并没有太大的帮助。

我们也不应将它看成专家。甚至在向 GPT 提问时，我们应该认为自己是专家，因为如果我们自己不是专家，就不知道该如何提问，更不知道该如何评价答案。它不是一个在我们遇到了困难时，能够帮助我们突破困境的专家。

GPT 更像一个看起来聪明的陌生人，但要注意的是，它的聪明并不一定能帮助我们。我们要在逐渐地熟悉这个陌生人之后，了解到它的优势与局限性，利用它的长处、避开它的短处，把它变成称职的私人助教、助手或顾问。

我们之所以要将它看成助教、助手或顾问，还有一个重要的原因，即做出最终决策及承担责任的是我们自己。我们应当把 GPT 看成热心的助教、万能的助手和智慧的顾问。这应是我们使用 GPT 完

第二章向 GPT 提问的飞轮思维 081 成任务的基本立场。

GPT 是一位有知识但又有局限性的热心助教，我们不能将它的解答当成结论。

GPT 是一位万能的助手，但我们要检查和确认它完成的任务。GPT 是一位智慧的顾问，但它并非身在局中，不与我们共担风险。这种超然既是它的不足，也是它的优势。