## 0401. Practitioner's Guide to Collaboration

The rapid growth of social networks across organizational boundaries and the increased geographic distribution of their members are changing how analysis needs to be done within the intelligence profession and even more so in business. Analysis in the intelligence profession and other comparable disciplines is evolving from being predominantly an activity done by a single analyst to a collaborative group process. The increased use of Structured Analytic Techniques is one of several factors spurring this transition to more collaborative work products.

In this chapter, we identify three different groups that engage in analysisâ€”two types of teams and a group described here as a "social network." We recommend that analysis be done in two phases: (1) an initial, divergent analysis phase often conducted by a geographically distributed social network and (2) a convergent analysis phase done by a smaller analytic team.

The chapter provides some practical guidance on how to take advantage of the collaborative environment while preventing or avoiding the many well-known problems associated with small-group processes. Many things change when the internal thought processes of analysts are externalized in a transparent manner so that evidence is shared early and differences of opinion are identified, refined, and easily critiqued by others. The chapter then identifies problems known to impair the performance of teams and small groups and concludes with some practical measures for limiting the occurrence of such problems.

4.1 Social Networks and Analytic Teams

Teams and groups can be categorized in several ways. When the purpose of the group is to generate an analytic product, it seems most useful to deal with three types: the traditional analytic team, the special project team, and teams supported by social networks. Traditional teams are usually co-located and focused on a specific task. Special project teams are most effective when their members are co-located or working in a synchronous virtual world. Teams supported by social networks can operate effectively in co-located, geographically distributed, and synchronous as well as asynchronous modes. These three types of groups differ in leadership, frequency of face-to-face and virtual-world meetings, breadth of analytic activity, and amount of time pressure under which they work. 1

Traditional analytic team: This is the typical work team assigned to perform a specific task. It has a leader appointed by a manager or chosen by the team, and all members of the team are collectively accountable for the team's product. The team may work jointly to develop the entire product, or each team member may be responsible for a specific section of the work. Historically, in the U.S. Intelligence Community, many teams were composed of analysts from a single agency, and involvement of other agencies was through coordination during the latter part of the production process rather than by collaborating from the beginning. This approach is now evolving because of changes in policy and easier access to secure interagency communications and collaborative software. Figure 4.1a shows how the traditional analytic team works. The core analytic team, with participants usually working at the same office, drafts a paper and sends it to other members of the community for comment and coordination. Ideally, the core team will alert other stakeholders in the community of their intent to write on a specific topic; but, too often, such dialogue occurs much later, when the author is seeking to coordinate the finished draft. In most cases, analysts must obtain specific permissions or follow established procedures to tap the knowledge of experts outside the office or outside the government. Special project team: Such a team is usually formed to provide decision makers with near real-time analytic support during a crisis or an ongoing operation. A crisis support task force or field-deployed interagency intelligence team that supports a military operation exemplifies this type of team. Members typically are in the same physical office space or are connected by video communications. There is strong team leadership, often with close personal interaction among team members. Because the team is created to deal with a specific situation, its work may have a narrower focus than a social network or regular analytic team, and its duration may be limited. There is usually intense time pressure, and around-the-clock operation may be required. Figure 4.1b is a diagram of a special project team. Social networks: Experienced analysts have always had their own network of experts in their field or related fields with whom they consult from time to time and whom they may recruit to work with them on a specific analytic project. Social networks are critical to the analytic business. Members of the network do the day-to-day monitoring of events, produce routine products as needed, and may recommend the formation of a more formal analytic team to handle a specific project. This form of group activity is now changing dramatically with the growing ease of cross-agency secure communications and the availability of collaborative software. Social networks are expanding exponentially across organization boundaries. The term "social network," as used here, includes all analysts in government or business working anywhere in the world on any issue. It can be limited to a small group with special clearances or comprise a broad array of government, business, nongovernmental organization (NGO), and academic experts. The network can be in the same office, in different buildings in the same metropolitan area, or, increasingly, at multiple locations around the globe.

Description Figure 4.1A Traditional Analytic Team Source: Pherson Associates, LLC, 2019.

Description Figure 4.1B Special Project Team Source: Pherson Associates, LLC, 2019.

The key problem that arises with social networks is the geographic distribution of their members. For widely dispersed teams, air travel is often an unaffordable expense. Even within the Washington, D.C., metropolitan area, distance is a factor that limits the frequency of face-to-face meetings, particularly as traffic congestion becomes a growing nightmare. From their study of teams in diverse organizations, which included teams in the U.S. Intelligence Community, Richard Hackman and Anita Woolley came to this conclusion:

Distributed teams do relatively well on innovation tasks for which ideas and solutions need to be generated but generally underperform face-to-face teams on decision-making tasks. Although decision-support systems can improve performance slightly, decisions made from afar still tend to take more time, involve less exchange of information, make error detection and correction more difficult, and can result in less participant satisfaction with the outcome than is the case for face-to-face teams. 2

In sum, distributed teams are appropriate for many, but not all, team tasks. Using them well requires careful attention to team structure, a face-to-face launch when members initially come together, and leadership support throughout the life of the team to keep members engaged and aligned with collective purposes. 3

Research on effective collaborative practices has shown that geographically and organizationally distributed teams are most likely to succeed when they satisfy six key imperatives of effective collaboration:

Mutual Trust. Know and trust one another; this usually requires that they meet face to face at least once. Mission Criticality. Feel a personal need to engage with the group to perform a critical task. Mutual Benefit. Derive mutual benefits from working together. Access and Agility. Connect with one another virtually on demand and easily add new members. Incentives. Perceive incentives for participating in the group, such as saving time, gaining new insights from interaction with other knowledgeable analysts, or increasing the impact of their contribution. Common Understanding. Share a common lexicon and understanding of the problem with agreed lists of terms and definitions. 4

4.2 Dividing the Work

Managing the geographic distribution of the social network can be addressed by dividing the analytic task into two parts: (1) exploiting the strengths of the social network for divergent or creative analysis to identify ideas and gather information and (2) forming a smaller analytic team that employs convergent analysis to meld these ideas into an analytic product. When the draft is completed, it goes back for review to all members of the social network who contributed during the first phase of the analysis, and then back to the team to edit and produce the final paper.

Structured Analytic Techniques, web-based discussions, and other types of collaborative software facilitate this two-part approach to analysis. The use of Exploration Techniques to conduct divergent analysis early in the analytic process works well for a geographically distributed social network communicating online. The products of these techniques can provide a solid foundation for the smaller analytic team to do the subsequent convergent analysis. In other words, each type of group performs the type of task for which it is best qualified. This process is applicable to most analytic projects. Figure 4.2 shows the functions that collaborative websites can perform.

A project leader informs a social network of an impending project and provides a tentative project description, target audience, scope, and process to be followed. The leader also broadcasts the name and internet address of the collaborative virtual workspace to be used and invites interested analysts knowledgeable in that area to participate. Any analyst with access to the collaborative network is authorized to add information and ideas to it. Any of the following techniques may come into play during the divergent analysis phase as specified by the project leader:

Collaboration in sharing and processing data using other techniques, such as timelines, sorting, networking, mapping, and charting, as described in chapters 5 and 6 . Some form of brainstorming, as described in chapters 6 and 9 , to generate a list of driving forces, variables, players, and so on. Ranking or prioritizing the list, as described in chapter 5 .

Description Figure 4.2 Functions of a Collaborative Website Source: Pherson Associates, LLC, 2019. Putting the list into a Cross-Impact Matrix, as described in chapter 7 , and then discussing and recording in the web discussion stream the relationship, if any, between each pair of driving forces, variables, or players in that matrix. Developing a list of alternative explanations or outcomes (hypotheses), as described in chapter 7 . Developing a list of relevant information for consideration when evaluating generated hypotheses, as described in chapter 7 . Doing a Key Assumptions Check, as described in chapter 7 . This can take less time using a synchronous collaborative virtual setting than when done in a face-to-face meeting; conducting such a check can uncover the network's thinking about key assumptions.

Most of these steps involve making lists, which can be done quite effectively in a virtual environment. Making such input online in a chat room or asynchronous email discussion thread can be even more productive than a face-to-face meeting. Analysts have more time to think about and write up their thoughts. They can look at their contribution over several days and make additions or changes as new ideas come to them.

Ideally, a project leader should oversee and guide the process. In addition to providing a sound foundation for further analysis, this process enables the project leader to identify the best analysts for inclusion in the smaller team that conducts the project's second phaseâ€”making analytic judgments and drafting the report. The project lead should select second-phase team members to maximize the following criteria: level of expertise on the subject, level of interest in the outcome of the analysis, and diversity of opinions and collaboration styles among members of the group. The action then moves from the social network to a small, trusted team (preferably no larger than eight analysts) to complete the project, perhaps using other techniques, such as Analysis of Competing Hypotheses, Red Hat Analysis, or What If? Analysis. At this stage in the process, the use of virtual collaborative software is usually more efficient than face-to-face meetings. Software used for exchanging ideas and revising text should allow for privacy of deliberations and provide an audit trail for all work done.

The draft report is best done by a single person. That person can work from other team members' inputs, but the report usually reads better if it is crafted in one voice. As noted earlier, the working draft should be reviewed by those members of the social network who participated in the first phase of the analysis.

4.3 Value of Collaborative Processes

In our vision for the future, intelligence analysis increasingly becomes a collaborative enterprise, with the focus shifting "away from coordination of draft products toward regular discussion of data and hypotheses early in the research phase." 5 This is a major change from the traditional concept of intelligence analysis as largely an individual activity with coordination as the final step in the process. In this scenario, instead of reading a static, hard copy paper, decision makers would obtain analysis of the topic of interest by accessing a web-based knowledge database that was continuously updated. The website might also include dropdowns providing lists of key assumptions, critical information gaps, or indicators; a Source Summary Statement; or a map showing how the analytic line has shifted over time.

In a collaborative enterprise, Structured Analytic Techniques are the process by which collaboration occurs. Just as these techniques provide structure to our individual thought processes, they can also structure the interaction of analysts within a small team or group. Because the thought process in these techniques is transparent, each step in the technique prompts discussion within the team. Such discussion can generate and evaluate substantially more divergent information and new information than can a group that does not use a structured process. When a team is dealing with a complex issue, the synergy of multiple minds using structured analysis is usually more effective than the thinking of a lone analyst. Structured Analytic Techniques when paired with collaborative software can provide a framework to guide interagency collaboration and coordination and connect team members in different offices, agencies, parts of traffic-congested metropolitan areas, and even around the world.

Team-based analysis can, of course, bring with it a new set of challenges equivalent to the cognitive biases and other pitfalls faced by the individual analyst. However, using structured techniques that guide interaction among members of a team or group can minimize well-known group-process problems. A structured process helps keep discussions from getting sidetracked and facilitates the elicitation of alternative views from all team members.

Analysts have found that use of a structured process helps to depersonalize arguments when there are differences of opinion. This is discussed further in the review of Adversarial Collaboration techniques at the end of chapter 8 . Moreover, today's information technology and social networking programs make structured collaboration much easier than in the past.

4.4 Common Pitfalls with Small Groups

As more analysis is done collaboratively, the quality of intelligence products is increasingly influenced by the success or failure of small-group processes. The various problems that afflict small-group processes have been the subject of considerable research. 6 One might reasonably be concerned that more collaboration will create more conflict and more interagency battles. However, as we explain here, it turns out that the use of Structured Analytic Techniques frequently helps analysts avoid many of the common pitfalls of the small-group process.

Some group-process problems are obvious to anyone who has tried to arrive at decisions or judgments in a group meeting. Guidelines for how to run meetings effectively are widely available, but many group leaders fail to follow them. 7 Key individuals are absent or late, and participants are unprepared. Senior members or those with strong personalities often dominate meetings, and some participants are reluctant to speak up or to express their true beliefs. Discussion can get stuck on several salient aspects of a problem, rather than covering all aspects of the subject. Decisions are hard to reach and, if reached, may not be implemented. Such problems are often magnified when the meeting is conducted virtually, over telephones or computers.

If you had to identify, in one word, the reason that the human race has not achieved, and never will achieve, its full potential, that word would be meetings.

Dave Barry, American humorist

Academic studies show that "the order in which people speak has a profound effect on the course of a discussion. Earlier comments are more influential, and they tend to provide a framework within which the discussion occurs." 8 Once that framework is in place, discussion tends to center on that framework, to the exclusion of other options. This phenomenon is also easily observed when attending a panel discussion at a conference. Whoever asks the first question or two in the Q&A session often sets the agenda (or the analytic framework, depending on the astuteness of the question) for the remainder of the discussion.

Much research documents that the desire for consensus is an important cause of poor group decisions. Development of a group consensus is usually perceived as success but often indicates failure. Premature consensus is one of the more common causes of suboptimal group performance. It leads to failure to identify or seriously consider alternatives, failure to examine the negative aspects of the preferred position, and failure to consider the consequences that might follow if the preferred position is wrong. 9 This phenomenon is what is commonly called Groupthink.

Academic researchers have documented other problems that are less obvious, but no less significant. Often, some reasonably satisfactory solution is proposed on which all members can agree, and the discussion is ended without further search to see if there may be a better answer. Such a decision often falls short of the optimum that might be achieved with further inquiry; it is an example of the misapplied heuristic called Satisficing. Another phenomenon, known as group "polarization," leads in certain predictable circumstances to a group decision that is more extreme than the average group member's view prior to the discussion. "Social loafing" is the term used to describe the phenomenon that people working in a group will often expend less effort than if they were working to accomplish the same task on their own. In any of these situations, the result is often an inferior product that suffers from a lack of analytic rigor.

4.5 Benefiting from Diversity

Improvement of group performance requires an understanding of these problems and a conscientious effort to avoid or mitigate them. The literature on small-group performance is virtually unanimous in emphasizing that groups make better decisions when their members bring to the table a diverse set of ideas, opinions, and perspectives. What Premature Closure, Groupthink, Satisficing, and the polarization of group dynamics all have in common is a failure to recognize assumptions, to work from a common lexicon, and to adequately identify and consider alternative points of view.

Laboratory experiments have shown that even a single dissenting opinion, all by itself, makes a group's decisions more nuanced and its decision-making process more rigorous. 10 "The research also shows that benefits from dissenting opinions occur regardless of whether or not the dissenter is correct. The dissent stimulates a reappraisal of the situation and identification of options that otherwise would have gone undetected." 11 To be effective, however, dissent must be genuineâ€”not generated artificially, a common pitfall in applying Team A/Team B Analysis or the Devil's Advocacy technique. 12

Small, distributed asynchronous groups are particularly good at generating and evaluating lists of assumptions, indicators, drivers, potential explanations of current events, or potential outcomes. They are also good for making lists of pros and cons on a given subject. With the aid of distributed group-support software, the group can categorize items on a list and prioritize, score, rank, scale, or vote on them. For such tasks, a distributed, virtual asynchronous meeting may be more productive than a traditional face-to-face meeting. That is because analysts have more time to think about their input; they can reflect on their contribution over several hours or days and make additions or changes as additional ideas come to mind. If rank or position of some group members is likely to have an undue influence, group members can provide their input anonymously.

Briefly, then, the route to better analysis is to create small groups of analysts who are strongly encouraged by their leader to speak up and express a wide range of ideas, opinions, and perspectives. The use of Structured Analytic Techniquesâ€”and silent brainstorming techniques in particularâ€”will generally ensure that all participants contribute to the process. These techniques prod all participants to engage, and a more diverse set of ideas are put on the table. They guide the dialogue among analysts as they share evidence and alternative perspectives on the meaning and significance of the evidence. Each step in the technique prompts relevant discussion within the team. Such discussion can generate and evaluate substantially more divergent information and new ideas than can a group that does not use such a structured process.

The more heterogeneous the group, the lower the risk of Premature Closure, Groupthink, Satisficing, and polarization. Use of a structured technique also sets a clear step-by-step agenda for any meeting where that technique is used. This makes it easier for a group leader to keep a meeting on track to achieve its goal. 13

The same procedures work either on classified systems or with outside experts on an unclassified network. Open-source information has rapidly come to play a larger role in intelligence analysis than in the past. Distributed asynchronous collaboration followed by distributed synchronous collaboration that uses some of the basic structured techniques is one of the best ways to tap the expertise of a group of knowledgeable individuals. The Delphi Method, discussed in chapter 8 , is one well-known method for accomplishing the asynchronous phase, and virtual collaboration systems are showing increasing promise for optimizing work done in the synchronous phase.

4.6 Advocacy versus Objective Inquiry

The desired diversity of opinion is, of course, a double-edged sword, as it can become a source of conflict that degrades group effectiveness. 14 It is not easy to introduce true collaboration and teamwork into a community with a history of organizational rivalry and mistrust. Analysts must engage in inquiry, not advocacy, and they must be critical of ideas but not people.

In a task-oriented team environment, advocacy of a specific position can lead to emotional conflict and reduced team effectiveness. Advocates tend to examine evidence in a biased manner, accepting at face value information that seems to confirm their own point of view and critically evaluating any contrary evidence. Advocacy is appropriate in a meeting of stakeholders that one is attending for the purpose of representing a specific interest. It is also "an effective method for making decisions in a courtroom when both sides are effectively represented, or in an election when the decision is made by a vote of the people." 15 However, it is not an appropriate method of discourse within a team "when power is unequally distributed among the participants, when information is unequally distributed, and when no clear rules of engagement existâ€”especially about how the final decision will be made." 16 An effective resolution may be found only through the creative synergy of alternative perspectives.

Figure 4.6 displays the differences between advocacy and the objective inquiry expected from a team member or a colleague. 17 When advocacy leads to emotional conflict, it can lower team effectiveness by provoking hostility, distrust, cynicism, and apathy among team members. Such tensions are often displayed when challenge techniques, such as Devil's Advocacy and Team A/Team B Analysis, are employed (a factor that argued strongly for dropping them from the third edition of this book). On the other hand, objective inquiry, which often leads to cognitive conflict, can lead to new and creative solutions to problems, especially when it occurs in an atmosphere of civility, collaboration, and common purpose. Several effective methods for managing analytic differences are described at the end of chapter 8 .

Figure 4.6 Advocacy versus Inquiry in Small-Group Processes Source: Pherson Associates, LLC, 2019.

We believe a team or group using Structured Analytic Techniques is less vulnerable to group-process traps than a comparable group doing traditional analysis because the techniques move analysts away from advocacy and toward inquiry. This idea has not yet been tested and demonstrated empirically, but the rationale is clear. These techniques work best when an analyst is collaborating with a small group of other analysts. Just as these techniques provide structure to our individual thought processes, they play an even stronger role in guiding the interaction of analysts within a small team or group. 18

Some techniques, such as the Key Assumptions Check, Analysis of Competing Hypotheses (ACH), and Argument Mapping, help analysts gain a clear understanding of how and exactly why they disagree. For example, many CIA and FBI analysts report that they use ACH to gain a better understanding of the differences of opinion between them and other analysts or between analytic offices. The process of creating an ACH matrix requires identification of the evidence and arguments being used and ascertaining the basis for labeling items and arguments as either consistent or inconsistent with the various hypotheses. Review of this matrix provides a systematic basis for identification and discussion of differences between two or more analysts.

CIA and FBI analysts also note that jointly building an ACH matrix helps to depersonalize arguments when differences of opinion emerge. 19 One side might suggest evidence that the other had not known about, or one side will challenge an assumption and a consensus will emerge that the assumption is unfounded. In other words, ACH can help analysts, operators, and decision makers learn from their differences rather than fight over them. Other structured techniques, including those discussed in the section on Adversarial Collaboration in chapter 8 , do this as well.

4.7 Leadership and Training

Considerable research on virtual teaming shows that leadership effectiveness is a major factor in the success or failure of a virtual team. 20 Although leadership usually is provided by a group's appointed leader, it can also emerge as a more distributed peer process. A trained facilitator can increase a team's effectiveness (see Figure 4.7 ). When face-to-face contact is limited, leaders, facilitators, and team members must compensate by paying more attention than they might otherwise devote to the following tasks:

Articulating a clear mission, goals, specific tasks, and procedures for evaluating results. Defining measurable objectives with milestones and timelines for achieving them. Establishing a common lexicon. Identifying clear and complementary roles and responsibilities. Building relationships with and among team members and with stakeholders. Agreeing on team norms and expected behaviors. Defining conflict resolution procedures. Developing specific communication protocols and practices. 21

As illustrated in Figure 4.7 , the interactions among the various types of team participantsâ€”whether analyst, leader, facilitator, or technologistâ€”are as important as the individual roles played by each. For example, analysts on a team will be most effective not only when they have subject-matter expertise or knowledge that lends a new viewpoint, but also when the rewards for their participation are clearly defined by their manager. Likewise, a facilitator's effectiveness is greatly increased when the goals, timeline, and general focus of the project are establishing with the leader in advance. When roles and interactions are explicitly defined and functioning, the group can more easily turn to the more challenging analytic tasks at hand.

As greater emphasis is placed on intra- and interoffice collaboration and more work is done through computer-mediated communications, it becomes increasingly important that analysts be trained in the knowledge, skills, and abilities required for facilitation and management of both face-to-face and virtual meetings, with a strong emphasis on using silent brainstorming techniques and Adversarial Collaboration during such meetings. Training is more effective when it occurs just before the skills and knowledge must be used. Ideally, it should be fully integrated into the work process and reinforced with mentoring. Good instructors should aspire to wear three different hats, acting in the roles of coaches, mentors, and facilitators.

Multi-agency or intelligence communityâ€“wide training programs of this sort could provide substantial support to interagency collaboration and the formation of virtual teams. Whenever a new interagency or virtual team or a distributed global project team is formed, all members should have benefited from training in understanding the pitfalls of group processes, performance expectations, standards of conduct, differing collaboration styles, and conflict resolution procedures. Standardization of this training across multiple organizations or agencies will accelerate the development of a shared analytic culture and reduce the start-up time needed when launching a new interagency project or orchestrating the work of a globally distributed group.

Description Figure 4.7 Effective Small-Group Roles and Interactions Source: Pherson Associates, LLC, 2019.

Notes

1. This chapter was inspired by and draws on the research done by the Group Brain Project at Harvard University. That project was supported by the National Science Foundation and the CIA Intelligence Technology Innovation Center. See in particular J. Richard Hackman and Anita W. Woolley, "Creating and Leading Analytic Teams," Technical Report 5 (February 2007), http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.456.4854&rep=rep1&type=pdf

2. Hackman and Woolley, "Creating and Leading Analytic Teams," 8.

3. Ibid.

4. Randolph H. Pherson and Joan McIntyre, "The Essence of Collaboration: The IC Experience," in Scientific Underpinnings of "Collaboration" in the National Security Arena: Myths and Realityâ€”What Science and Experience Can Contribute to Its Success , ed. Nancy Chesser (Washington, DC: Strategic Multi-Layer Assessment Office, Office of the Secretary of Defense, Director of Defense Research and Engineering/Rapid Reaction Technology Office, June 2009).

5. Vision 2015: A Globally Networked and Integrated Intelligence Enterprise (Washington, DC: Director of National Intelligence, 2008), 13.

6. For example, Paul B. Paulus and Bernard A. Nijstad, Group Creativity: Innovation through Collaboration (New York: Oxford University Press, 2003).

7. J. Scott Armstrong, "How to Make Better Forecasts and Decisions: Avoid Face-to-Face Meetings," Foresight 5 (Fall 2006).

8. James Surowiecki, The Wisdom of Crowds (New York: Doubleday, 2004), 184.

9. Charlan J. Nemeth and Brendan Nemeth-Brown, "Better Than Individuals? The Potential Benefits of Dissent and Diversity for Group Creativity," in Group Creativity, eds. Paul B. Paulus and Bernard A. Nijstad (New York: Oxford University Press, 2003), 63â€“64.

10. Surowiecki, The Wisdom of Crowds, 183â€“184.

11. Nemeth and Nemeth-Brown, "Better Than Individuals?" 73.

12. Ibid., 76â€“78.

13. This paragraph and the previous paragraph express the authors' professional judgment based on personal experience and anecdotal evidence gained in discussion with other experienced analysts. As discussed in chapter 11 , there is a clear need for systematic research on this topic and other variables related to the effectiveness of Structured Analytic Techniques.

14. Frances J. Milliken, Caroline A. Bartel, and Terri R. Kurtzberg, "Diversity and Creativity in Work Groups," in Group Creativity, eds. Paul B. Paulus and Bernard A. Nijstad (New York: Oxford University Press, 2003), 33.

15. Martha Lagace, "Four Questions for David Garvin and Michael Roberto," Working Knowledge: Business Research for Business Leaders (Harvard Business School weekly newsletter), October 15, 2001, http://hbswk.hbs.edu/item/3568.html

16. Ibid.

17. The table is from David A. Garvin and Michael A. Roberto, "What You Don't Know about Making Decisions," Working Knowledge: Business Research for Business Leaders (Harvard Business School weekly newsletter), October 15, 2001, http://hbswk.hbs.edu/item/2544.html .

18. This paragraph expresses our professional judgment based on personal experience and anecdotal evidence gained in discussion with other experienced analysts. As we discuss in chapter 11 , there is a clear need for systematic research on this topic and other variables related to the effectiveness of Structured Analytic Techniques.

19. This information was provided by two senior educators in the U.S. Intelligence Community.

20. Jonathan N. Cummings, "Leading Groups from a Distance: How to Mitigate Consequences of Geographic Dispersion," in Leadership at a Distance: Research in Technologically-Supported Work , ed. Susan Weisband (New York: Routledge, 2007).

21. Sage Freechild, "Team Building and Team Performance Management." Originally online at www.phoenixrisingcoaching.com . This article is no longer available online.

Descriptions of Images and Figures

Back to Figure

The broader social network, such as academia, nongovernmental organizations, and business, includes governmental social network, such as intelligence communities and government agencies. The governmental social network includes the core analytic team. The barrier separating each network signifies established rules of engagement for cross-boundary interaction.

Back to Figure

The broader social network, such as academia, nongovernmental organizations, and business, includes intelligence community and governmental organizations. They are signals intelligence, open-source intelligence, human intelligence, geospatial intelligence, and measurement and signals intelligence. The intelligence community includes the special project team, and has direct reach back with the project team and the broader social network. The barrier between the networks signifies established rules of engagement for cross-boundary interaction.

Back to Figure

Websites can aid analytic collaboration by summarizing facts, capturing the analytic process, and tracking and validating judgments, so that analysts can better share, understand, and challenge judgments regardless of physical geography, time elapsed, or analyst turnover. Summarizing facts: What is known; How it is known; Confidence in it; Any factual changes and why. Capturing the analytic process: Key assumptions; Conceptual frameworks; Relevant models; Indicators; Scope; Known unknowns. Tracking and validating judgments: Virtual library; Internal analytic integrity; External transparency.

Back to Figure

Leader articulates goals, establishes team, and enforces accountability. Facilitator identifies appropriate techniques, and leads structured analytic sessions. Technologist builds and optimizes tools. Analysts are subject-matter experts. Leader and facilitator agree on project timeline, focus, and applicability of small-group process. Leader and analysts clearly articulate individual performance expectations, evaluation metrics, and rewards for constructive participation. Analysts, facilitator, and technologists build and maintain collaborative analytic workspace, identify technology needs. All participants work from same key analytic question; establish agreed team norms and expectations for communications, dispute resolution, and allocation of individual responsibilities.