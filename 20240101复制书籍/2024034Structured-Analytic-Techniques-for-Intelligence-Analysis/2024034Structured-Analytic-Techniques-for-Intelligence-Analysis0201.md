## 0201. The Role of Structured Techniques

2.1 Two Types of Thinking

In the last thirty years, important gains have been made in psychological research on human judgment. Dual process theory, positing two systems of decision making called System 1 and System 2, has emerged as the predominant approach. 1 The basic distinction between System 1 and System 2 is intuitive versus analytical thinking.

System 1 Thinking is intuitive, fast, efficient, and often unconscious. It draws naturally on available knowledge, experience, and often a long-established mental model of how people or things work in a specific environment. System 1 Thinking requires little effort; it allows people to solve problems and make judgments quickly and efficiently. Although it is often accurate, intuitive thinking is a common source of cognitive biases and other intuitive mistakes that lead to faulty analysis. Three types of cognitive limitations—cognitive bias, misapplied heuristics, and intuitive traps—are discussed later in this chapter. System 2 Thinking is analytic. It is slow, methodical, and conscious, the result of deliberate reasoning. It includes all types of analysis, such as critical thinking and Structured Analytic Techniques, as well as the whole range of empirical and quantitative methods.

The description of each Structured Analytic Technique in this book includes a discussion of which cognitive biases, misapplied heuristics, and intuitive traps are most effectively avoided, overcome, or at least mitigated by using that technique. The introduction to each family of techniques also identifies how the techniques discussed in that chapter help counter one or more types of cognitive bias and other common intuitive mistakes associated with System 1 Thinking.

Intelligence analysts have largely relied on intuitive judgment—a System 1 process—in constructing their analyses. When done well, intuitive judgment—sometimes referred to as traditional analysis—combines subject-matter expertise with basic thinking skills. Evidentiary reasoning, historical method, case study method, and reasoning by analogy are examples of this category of analysis. 2 The key characteristic that distinguishes intuitive judgment from structured analysis is that intuitive judgment is usually an individual effort in which the reasoning remains largely in the mind of the individual analyst until it is written down in a draft report. Training in this type of analysis is generally acquired through postgraduate education, especially in the social sciences and liberal arts, and often along with some country or language expertise.

This chapter presents a taxonomy that defines the domain of System 2 Thinking. A taxonomy is a classification of all elements of some body of information or knowledge. It defines the domain by identifying, naming, and categorizing all the various objects in a specialized discipline. The objects are organized into related groups based on some factor common to each object in the group.

The word "taxonomy" comes from the Greek taxis , meaning arrangement, division, or order, and nomos , meaning law. Classic examples of a taxonomy are Carolus Linnaeus's hierarchical classification of all living organisms by kingdom, phylum, class, order, family, genus, and species that is widely used in the biological sciences. The periodic table of elements used by chemists is another example. A library catalog is also considered a taxonomy, as it starts with a list of related categories that are then progressively broken down into finer categories.

Development of a taxonomy is an important step in organizing knowledge and furthering the development of any discipline. Rob Johnston developed a taxonomy of variables that influenced intelligence analysis but did not go into depth on analytic techniques or methods. He noted that "a taxonomy differentiates domains by specifying the scope of inquiry, codifying naming conventions, identifying areas of interest, helping to set research priorities, and often leading to new theories. Taxonomies are signposts, indicating what is known and what has yet to be discovered." 3

Robert Clark has described a taxonomy of intelligence sources. 4 He also categorized some analytic methods commonly used in intelligence analysis, but not to the extent of creating a taxonomy. To the best of our knowledge, no one has developed a taxonomy of analytic techniques for intelligence analysis, although taxonomies have been developed to classify research methods used in forecasting, 5 operations research, 6 information systems, 7 visualization tools, 8 electronic commerce, 9 knowledge elicitation, 10 and cognitive task analysis. 11

After examining taxonomies of methods used in other fields, we found that there is no single right way to organize a taxonomy—only different ways that are useful in achieving a specified goal. In this case, our goal is to gain a better understanding of the domain of Structured Analytic Techniques, investigate how these techniques contribute to providing a better analytic product, and consider how they relate to the needs of analysts. The objective has been to identify various techniques that are currently available, identify or develop additional potentially useful techniques, and help analysts compare and select the best technique for solving any specific analytic problem. Standardization of terminology for Structured Analytic Techniques will facilitate collaboration across agency and international boundaries during the use of these techniques.

Description Figure 2.1 System 1 and System 2 Thinking Source: Pherson Associates, LLC, 2019.

The taxonomy presented in Figure 2.1 distinguishes System 1, or intuitive thinking, from the four broad categories of analytic methods used in System 2 Thinking. It describes the nature of these four categories, one of which is structured analysis. The others are critical thinking, empirical analysis, and quasi-quantitative analysis. This chapter describes the rationale for these four broad categories. In the next chapter , we review the six categories or families of Structured Analytic Techniques.

2.2 Developing a Taxonomy of Structured Analytic Techniques

Intelligence analysts employ a wide range of methods to deal with an even wider range of subjects. Although this book focuses on the field of structured analysis, it is appropriate to identify some initial categorization of all the methods to see where structured analysis fits. Many researchers write of only two general approaches to analysis, contrasting qualitative with quantitative, intuitive with empirical, or intuitive with scientific. Others might claim that there are three distinct approaches: intuitive, structured, and scientific. In our taxonomy, we have sought to address this confusion by describing two types of thinking (System 1 and System 2) and defining four categories of System 2 Thinking.

The first step of science is to know one thing from another. This knowledge consists in their specific distinctions; but in order that it may be fixed and permanent, distinct names must be given to different things, and those names must be recorded and remembered.

—Carolus Linnaeus, Systema Naturae (1738)

Whether intelligence analysis is, or should be, an art or science is one of the long-standing debates in the literature on intelligence analysis. As we see it, intelligence analysis has aspects of both spheres. The range of activities that fall under the rubric of intelligence analysis spans the entire range of human cognitive abilities, and it is not possible to divide it into just two categories—art and science—or to say that it is only one or the other. The extent to which any part of intelligence analysis is either art or science is entirely dependent upon how one defines "art" and "science."

The taxonomy described here posits four functionally distinct methodological approaches to intelligence analysis. These approaches are distinguished by the nature of the analytic methods used, the type of quantification if any, the type of data that is available, and the type of training that is expected or required. Although each method is distinct, the borders between them can be blurry.

Critical thinking . Critical thinking, as defined by longtime intelligence methodologist and practitioner Jack Davis, is the application of the processes and values of scientific inquiry to the special circumstances of strategic intelligence. 12 Good critical thinkers will stop and reflect on who is the client, what is the question, where can they find the best information, how can they make a compelling case, and what is required to convey their message effectively. They recognize that this process requires checking key assumptions, looking for disconfirming data, and entertaining multiple explanations. Most students are exposed to critical-thinking techniques at some point in their education—from grade school to university—but few colleges or universities offer specific courses to develop critical thinking and writing skills. Structured analysis . Structured Analytic Techniques involve a step-by-step process that externalizes the analyst's thinking in a manner that makes it readily apparent to others, thereby enabling it to be reviewed, discussed, and critiqued piece by piece. For this reason, structured analysis usually becomes a collaborative effort in which the transparency of the analytic process exposes participating analysts to divergent or conflicting perspectives. We believe this type of analysis helps to mitigate some of the adverse effects of a single analyst's cognitive limitations, an ingrained mindset, and the whole range of cognitive biases, misapplied heuristics, and intuitive traps. Frequently used techniques include Cluster Brainstorming, Foresight analysis, Indicators, Analysis of Competing Hypotheses, and Key Assumptions Check. Structured techniques are taught in undergraduate and graduate school programs as well as many intelligence service training courses and can be used by analysts who do not have a background in statistics, advanced mathematics, or the hard sciences. Empirical analysis . When large stores of quantitative data or social media reporting are available, analysts can engage quantitative methods to study the available information or "Big Data." Quantifiable empirical data are so different from expert-generated data that the methods and types of problems the data are used to analyze are also quite different. Econometric modeling is a common example of this method. With the mushrooming of data obtainable from social media providers and the internet of things, sophisticated algorithms can identify trends and test hypotheses. Empirical data are collected by various types of sensors and are used, for example, in analysis of weapons systems or public response to a new product placement. Training is generally obtained through graduate education in statistics, economics, cyber analysis, or the hard sciences. Quasi-quantitative analysis . When analysts lack the empirical data needed to analyze an intelligence problem, one strategy is to fill the gaps using expert-generated data. Many methods rely on experts to rate key variables as High, Medium, Low, or Not Present, or by assigning a subjective probability judgment. Experts use special procedures to elicit these judgments, and the ratings usually are integrated into a larger model that describes a phenomenon, such as the vulnerability of a civilian leader to a military coup, the level of political instability, or the likely outcome of a legislative debate. This category includes methods such as Bayesian inference, dynamic modeling, and simulation. Training in the use of these methods is provided through graduate education in fields such as mathematics, information science, political science, operations research, or business.

No one of these four methods is better or more effective than another. All are needed in various circumstances to optimize the odds of finding the right answer. The use of multiple methods over the course of a single analytic project should be the norm, not the exception. For example, even a highly quantitative technical analysis may entail assumptions about motivation, intent, or capability that are best handled with critical thinking approaches and/or structured analysis. A brainstorming technique might be used to identify the variables to include in a dynamic model that uses expert-generated data to quantify these variables.

Of these four methods, structured analysis is the "new kid on the block," so it is useful to consider how it relates to System 1 Thinking. System 1 Thinking combines subject-matter expertise and intuitive judgment in an activity that takes place largely in an analyst's head. Although the analyst may gain input from others, the analytic product is frequently perceived as the product of a single analyst, and the analyst tends to feel "ownership" of his or her analytic product. The work of a single analyst is particularly susceptible to the wide range of cognitive pitfalls described in Psychology of Intelligence Analysis, Critical Thinking for Strategic Intelligence, and throughout this book. 13

Structured analysis, which is System 2 Thinking, follows a step-by-step process that can be used by an individual analyst, but we believe a group process provides more benefit. Structured Analytic Techniques guide the dialogue among analysts with common interests as they work step-by-step through an analytic problem. The critical point is that this approach exposes participants with various types and levels of expertise to alternative ideas, evidence, or mental models early in the analytic process and helps even experts avoid some common cognitive pitfalls. The structured group process that identifies and assesses alternative perspectives can also help to avoid Groupthink, the most common problem of small-group processes.

When used by a group or a team, structured techniques can become a mechanism for information sharing and group learning that helps to compensate for gaps or weaknesses in subject-matter expertise. This is especially useful for complex projects that require a synthesis of multiple types of expertise.

2.3 Dealing with Cognitive Limitations

As good as intuitive judgment often is, such judgment is still System 1 activity in the brain and is subject to many different types of cognitive limitations. Potential causes of such biases and mental mistakes include professional experience leading to an ingrained analytic mindset, training or education, the nature of one's upbringing, type of personality, a salient personal experience, or personal equity in a decision.

In this chapter, we distinguish between three types of cognitive limitations (see Figure 2.3 ):

Cognitive biases are inherent thinking errors that people make in processing information. They prevent an analyst from accurately understanding reality even when all the needed data and evidence that would form an accurate view is in hand. Heuristics are experience-based techniques that can give a solution that is not guaranteed to be optimal. The objective of a heuristic is to produce quickly a solution that is good enough to solve the problem at hand. Analysts can err by overrelying on or misapplying heuristics. Heuristics help an analyst generate a quick answer, but sometimes that answer will turn out to be wrong. Intuitive traps are practical manifestations of commonly recognized cognitive biases or heuristics that analysts in the intelligence profession—and many other disciplines—often fall victim to in their day-to-day activities.

There is extensive literature on how cognitive biases and heuristics affect a person's thinking in many fields. Intuitive traps, however, are a new category of bias first identified by Randolph Pherson and his teaching colleagues as they explored the value of using Structured Analytic Techniques to counter the negative impact of cognitive limitations. Additional research is ongoing to refine and revise the list of eighteen intuitive traps.

All cognitive biases, misapplied heuristics, or intuitive traps, except perhaps the personal equity bias, are more frequently the result of fast, unconscious, and intuitive System 1 Thinking and not the result of thoughtful reasoning (System 2). System 1 Thinking—though often correct—is more often influenced by cognitive biases and mindsets as well as insufficient knowledge and the inherent unknowability of the future. Structured Analytic Techniques—a type of System 2 Thinking—help identify and overcome the analytic biases inherent in System 1 Thinking.

Behavioral scientists have studied the impact of cognitive biases on analysis and decision making in many fields, such as psychology, political science, medicine, economics, business, and education ever since Amos Tversky and Daniel Kahneman introduced the concept of cognitive biases in the early 1970s. 14 Richards Heuer's work for the CIA in the late 1970s and the 1980s, subsequently followed by his book Psychology of Intelligence Analysis , first published in 1999, applied Tversky and Kahneman's insights to problems encountered by intelligence analysts. 15 Since the publication of Psychology of Intelligence Analysis , other authors associated with the U.S. Intelligence Community (including Jeffrey Cooper and Rob Johnston) have identified cognitive biases as a major cause of analytic failure at the CIA. 16

Figure 2.3 Glossary of Cognitive Biases, Misapplied Heuristics, and Intuitive Traps

This book is a logical follow-on to Psychology of Intelligence Analysis , which described in detail many of the biases and heuristics that influence intelligence analysis. 17 Since then, hundreds of cognitive biases and heuristics have been described in the academic literature using a wide variety of terms. As Heuer noted many years ago, "Cognitive biases are similar to optical illusions in that the error remains compelling even when one is fully aware of its nature. Awareness of the bias, by itself, does not produce a more accurate perception." 18 This is why cognitive limitations are exceedingly difficult to overcome. For example, Emily Pronin, Daniel Y. Lin, and Lee Ross observed in three different studies that people see the existence and operation of cognitive and motivational biases much more in others than in themselves. 19 This explains why so many analysts believe their own intuitive thinking (System 1) is sufficient.

Analysts in the intelligence profession—and many other disciplines—often fall victim to cognitive biases, misapplied heuristics, and intuitive traps that are manifestations of commonly recognized biases. Structured Analytic Techniques help analysts avoid, overcome, or at least mitigate their impact.

How a person perceives information is strongly influenced by factors such as experience, education, cultural background, and what that person is expected to do with the data. Our brains are trained to process information quickly, which often leads us to process data incorrectly or to not recognize its significance if it does not fit into established patterns. Some heuristics, such as the fight-or-flight instinct or knowing you need to take immediate action when you smell a gas leak, are helpful. Others are nonproductive. Defaulting to "rules of thumb" while problem solving can often lead to inherent thinking errors, because the information is being processed too quickly or incorrectly.

Cognitive biases , such as Confirmation Bias or Hindsight Bias, impede analytic thinking from the very start. 20 Misapplied heuristics , such as Groupthink or Premature Closure, could lead to a correct decision based on a non-rigorous thought process if one is lucky. More often, they impede the analytic process because they prevent us from considering a full range of possibilities. Intuitive traps , such as Projecting Past Experiences or Overinterpreting Small Samples, are mental mistakes practitioners make when conducting their business. A classic example is when a police detective assumes that the next case he or she is working will be like the previous case or a general prepares to fight the last war instead of anticipating that the next war will have to be fought differently.

Unfortunately for analysts, these biases, heuristics, and traps are quick to form and extremely hard to correct. After one's mind has reached closure on an issue, even a substantial accumulation of contradictory evidence is unlikely to force a reappraisal. Analysts often do not see new patterns emerging or fail to detect inconsistent data. An even larger concern is the tendency to ignore or dismiss outlier data as "noise."

Structured Analytic Techniques help analysts avoid, overcome, or at least mitigate these common cognitive limitations. Structured techniques help analysts do the following:

Reduce error rates. Avoid intelligence and other analytic failures. Embrace more collaborative work practices. Ensure accountability. Make the analysis more transparent to other analysts and decision makers.

2.4 Matching Cognitive Limitations to Structured Techniques

Figure 2.4 Matching Cognitive Limitations to the Six Families of Structured Techniques

In this book, we proffer guidance on how to reduce an analyst's vulnerability to cognitive limitations. In the overview of each family of Structured Analytic Techniques, we list two cognitive biases or misapplied heuristics as well as two intuitive traps that the techniques in that family are most effective in countering (see Figure 2.4 ). The descriptions of each of the sixty-six techniques include commentary on which biases, heuristics, and traps that specific technique helps mitigate. In our view, most techniques help counter cognitive limitations with differing degrees of effectiveness, and the matches we selected are only illustrative of what we think works best. Additional research is needed to empirically validate the matches we have identified from our experience teaching the techniques over the past decade and exploring their relationship to key cognitive limitations.

2.5 Combating Digital Disinformation

The growing use of social media platforms to manipulate popular perceptions for partisan political or social purposes has made democratic processes increasingly vulnerable in the United States and across the world. Largely unencumbered by commercial or legal constraints, international standards, or morality, proponents of Digital Disinformation 21 have become increasingly adept at exploiting common cognitive limitations, such as Confirmation Bias, Groupthink, and Judging by Emotion. History may show that we have grossly underestimated how easy it has been to influence popular opinion by leveraging cognitive biases, misapplied heuristics, and intuitive traps.

Digital Disinformation is purposely intended to mislead the reader. Perpetrators of Digital Disinformation compose compelling and seemingly coherent narratives that usually dismiss inconsistent evidence and ignore basic rules of logic. The primary objective of digital deceivers is to provide incorrect information in a seemingly persuasive format that confirms the readers' biases and either hardens mental mindsets or sows apathy or disbelief in the ability to know the truth. 22 Uncritical readers will often believe they have "found the truth" when actually they are functioning as both victims and perpetrators of cognitive bias, misapplied heuristics, and intuitive traps.

Purposeful misinformation, conspiracy theories, deception, and active measures have been used by activists and nation-states to influence people for decades, if not centuries. 23 Such efforts at perception management appear to have had greater impact in recent years because of the following:

The breadth and volume of misinformation has become staggering, owing to the power of social media platforms. The speed of the spread of disinformation is breathtaking as stories can quickly go "viral," spreading to millions of readers. A Massachusetts Institute of Technology study in Science documents that false rumors travel across the internet six times faster than factual stories. 24 People appear to be increasingly seeking simple answers to complex problems. Social network platforms usually present information in simplified form, which makes the message more digestible but far less nuanced—and often inaccurate. 25

The incentives for digital deceivers to leverage social media platforms to manipulate popular perceptions have also increased dramatically because of the following:

Millions of people can be reached almost instantaneously. Few perpetrators are held accountable for their posts. Perpetrators can micro-target their messages to those most easily swayed and open to persuasion.

Another underlying and often overlooked factor explaining the growing impact of Digital Disinformation is the susceptibility of individuals to false messaging. Perpetrators of conspiracy theories know what is most likely to "stick" in the minds of their audiences. This "stickiness" is usually attributable to the exploitation of human vulnerabilities that are manifestations of omnipresent, and well-ingrained, cognitive biases, misapplied heuristics, and intuitive traps.

Perpetrators of Digital Disinformation know that the best way to manipulate popular perceptions is to exploit well-ingrained cognitive limitations. They can anticipate when a person is likely to fall victim to a cognitive bias or to misapply a heuristic, and they leverage this knowledge to increase the impact of their messaging. Experts in false messaging, for example, are aware that people's perceptions of data are strongly influenced by their past experiences, education, cultural values, and how they identify themselves. People with different backgrounds will perceive information differently.

Moreover, knowledge of someone's social media profile greatly facilitates the process of identifying how best to package misinformation to reinforce that person's thinking. With the explosive growth in the use of social media platforms and databases, the use of such micro-targeting strategies has proven increasingly effective in product marketing and more recently in political campaigns.

Two of the most powerful biases that perpetrators of misinformation exploit are Confirmation Bias—seeking only information that confirms your viewpoint—and Vividness Bias—focusing attention only on the most vivid possibility. 26 , 27 Digital deceivers have also become masters of exploiting misapplied heuristics, such as the Anchoring Effect, Groupthink, and Satisficing. Intuitive traps that create vulnerabilities include Judging by Emotion, Presuming Patterns, and Overinterpreting Small Samples.

Recognizing one's vulnerability to Digital Disinformation is insufficient for mitigating the threat. A more productive strategy is needed—one that involves the use of critical thinking strategies and Structured Analytic Techniques. People are less likely to be deceived if they make it a habit to evaluate the quality of the evidence used to support a claim and ask what other credible, alternative narratives could explain what has occurred. Four Structured Analytic Techniques that are particularly effective in helping counter the impact of Digital Disinformation are as follows: 28

Key Assumptions Check . Making explicit and questioning the assumptions that guide an analyst's interpretation of evidence and the reasoning underlying a judgment or conclusion. Analysis of Competing Hypotheses . The evaluation of information against a set of alternative hypotheses to determine the consistency/inconsistency of each piece of data against each hypothesis and the rejection of hypotheses with much inconsistent data. Premortem Analysis and Structured Self-Critique . A systematic process using brainstorming and checklist procedures to identify critical weaknesses in an argument and assess how a key analytic judgment could be spectacularly wrong.

Notes

1. For further information on dual process theory, see the research by Jonathan Evans and Keith Frankish, In Two Minds: Dual Processes and Beyond (Oxford, UK: Oxford University Press, 2009); and Pat Croskerry, "A Universal Model of Diagnostic Reasoning," Academic Medicine 84, no. 8 (August 2009).

2. Reasoning by analogy can also be a structured technique called Structured Analogies, as described in chapter 8 .

3. Rob Johnston, Analytic Culture in the U.S. Intelligence Community (Washington, DC: CIA Center for the Study of Intelligence, 2005), 34.

4. Robert M. Clark, Intelligence Analysis: A Target-Centric Approach , 2nd ed. (Washington, DC: CQ Press, 2007), 84.

5. Forecasting Principles website, last accessed November 6, 2019, www.forecastingprinciples.com/files/pdf/methodsselectionchart.pdf

6. Russell W. Frenske, "A Taxonomy for Operations Research," Operations Research 19, no. 1 (January–February 1971).

7. Kai R. T. Larson, "A Taxonomy of Antecedents of Information Systems Success: Variable Analysis Studies," Journal of Management Information Systems 20, no. 2 (Fall 2003).

8. Ralph Lengler and Martin J. Epler, "A Periodic Table of Visualization Methods," n.d., www.visual-literacy.org/periodic_table/periodic_table.html

9. Roger Clarke, Appropriate Research Methods for Electronic Commerce (Canberra, Australia: Xanax Consultancy Pty Ltd., 2000), www.forecastingprinciples.com/files/pdf/methodsselectionchart.pdf

10. Robert R. Hoffman, Nigel R. Shadbolt, A. Mike Burton, and Gary Klein, "Eliciting Knowledge from Experts," Organizational Behavior and Human Decision Processes 62 (May 1995): 129–158.

11. Robert R. Hoffman and Laura G. Militello, Perspectives on Cognitive Task Analysis: Historical Origins and Modern Communities of Practice (Boca Raton, FL: CRC Press/Taylor and Francis, 2008); Beth Crandall, Gary Klein, and Robert R. Hoffman, Working Minds: A Practitioner's Guide to Cognitive Task Analysis (Cambridge, MA: MIT Press, 2006).

12. See Katherine Hibbs Pherson and Randolph H. Pherson, Critical Thinking for Strategic Intelligence, 2nd ed. (Washington, DC: CQ Press/SAGE, 2017), xxii.

13. Richards J. Heuer Jr., Psychology of Intelligence Analysis (Washington, DC: CIA Center for the Study of Intelligence, 1999; reprinted by Pherson Associates, LLC, Reston, VA, 2007).

14. Amos Tversky and Daniel Kahneman, "Judgment under Uncertainty: Heuristics and Biases," Science 185, no. 4157 (1974): 1124–1131.

15. Psychology of Intelligence Analysis was republished by Pherson Associates, LLC, in 2007, and can be purchased on its website at shop.globalytica.com.

16. Jeffrey R. Cooper, Curing Analytic Pathologies: Pathways to Improved Intelligence Analysis (Washington, DC: CIA Center for the Study of Intelligence, 2005); Rob Johnston, Analytic Culture in the U.S. Intelligence Community: An Ethnographic Study (Washington, DC: CIA Center for the Study of Intelligence, 2005).

17. Heuer, Psychology of Intelligence Analysis.

18. Ibid., 112.

19. Emily Pronin, Daniel Y. Lin, and Lee L. Ross, "The Bias Blind Spot: Perceptions of Bias in Self versus Others," Personality and Social Psychology Bulletin 28, no. 3 (2002): 369–381.

20. Definitions of these and other cognitive biases, misapplied heuristics, and intuitive traps mentioned later in this chapter are provided in Figure 2.3 on pages 24–25 .

21. Efforts to purposefully mislead or misinform have also been described as "Fake News," "False News," or "Agenda-Driven News." The phrase most often used in the public domain is Fake News, but the inaccurate use of this term to describe any critical news reporting has undermined its usefulness.

22. Rob Brotherton, "Five Myths about Conspiracy Theories," Washington Post , January 17, 2019, https://www.washingtonpost.com/outlook/five-myths/five-myths-about-conspiracy-theories/2019/01/17/0ef1b840-1818-11e9-88fe-f9f77a3bcb6c_story

23. The term "active measures" refers to actions taken by the Soviet Union, and later Russia, beginning in the 1920s to influence popular perceptions through propaganda, false documentation, penetration of institutions, persecution of political activists, and political violence, including assassinations. For more information, see the testimony of Gen. (ret.) Keith B. Alexander, Disinformation: A Primer in Russian Active Measures and Influence Campaigns, United States Senate Select Committee on Intelligence , March 30, 2017, https://www.intelligence.senate.gov/sites/default/files/documents/os-kalexander-033017.pdf .

24. Soroush Vosoughi, Deb Roy, and Sinan Aral, "The Spread of True and False News Online," Science 359, no. 6380 (2018): 1146–1151.

25. Elisa Shearer and Jeffrey Gottfried, News Use across Social Media Platforms 2017 , (Washington, DC: Pew Research Center, September 7, 2017), http://www.journalism.org/2017/09/07/news-use-across-social-media-platforms-2017/

26. A fuller discussion of this issue can be found in Randolph H. Pherson and Penelope Mort Ranta, "Cognitive Bias, Digital Disinformation, and Structured Analytic Techniques," Revista Romănă de studii de intelligence ( Romanian Journal of Intelligence Studies ), Vol. 21, 2019). The article was inspired in large part by observations made during the U.S. presidential election in 2016. Similar dynamics, however, have been observed in subsequent elections in France, Germany, and several other European states as well as the Brexit campaign in the United Kingdom.

27. A review of the cognitive biases and misapplied heuristics most often experienced by intelligence analysts can be found in Katherine Hibbs Pherson and Randolph H. Pherson, Critical Thinking for Strategic Intelligence , 2nd ed. (Washington, DC: CQ Press/SAGE, 2017), 55.

28. Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019), 5, 9, 19, 31, 43, 53.

注释

1. 关于双重过程理论的进一步信息，请参阅 Jonathan Evans 和 Keith Frankish 的研究，《在两个心灵中：双重过程及其超越》（牛津，英国：牛津大学出版社，2009 年）；以及 Pat Croskerry，「诊断推理的通用模型」，《学术医学》84，第 8 期（2009 年 8 月）。

2. 类比推理也可以是一种结构化技术，称为结构化类比，如第 8 章所述。

3. Rob Johnston，《美国情报界的分析文化》（华盛顿特区：CIA 情报研究中心，2005 年），第 34 页。

4. Robert M. Clark，《情报分析：以目标为中心的方法》，第 2 版（华盛顿特区：CQ 出版社，2007 年），第 84 页。

5. 预测原理网站，最后访问日期为 2019 年 11 月 6 日，网址为 www.forecastingprinciples.com/files/pdf/methodsselectionchart.pdf。

6. Russell W. Frenske, "运筹学分类法，" 运筹学研究 19, 第 1 期 (1971 年 1 月 - 2 月)。

7. Kai R. T. Larson, "信息系统成功的前因分类：变量分析研究，" 管理信息系统杂志 20, 第 2 期 (2003 年秋季)。

8. Ralph Lengler 和 Martin J. Epler, "可视化方法的周期表，" 无日期，网址为 www.visual-literacy.org/periodic_table/periodic_table.html。

9. Roger Clarke, 电子商务的适当研究方法 (堪培拉，澳大利亚：Xanax 咨询有限公司，2000 年), 网址为 www.forecastingprinciples.com/files/pdf/methodsselectionchart.pdf。

10. Robert R. Hoffman, Nigel R. Shadbolt, A. Mike Burton, 和 Gary Klein, "从专家中提取知识，" 组织行为与人类决策过程 62 (1995 年 5 月)：129–158。

11. Robert R. Hoffman 和 Laura G. Militello, 认知任务分析的视角：历史起源与现代实践社群 (博卡拉顿，FL：CRC 出版社 / 泰勒与弗朗西斯，2008 年); Beth Crandall, Gary Klein, 和 Robert R. Hoffman, 工作中的思维：认知任务分析实践者指南 (剑桥，MA：MIT 出版社，2006 年)。

12. 参见 Katherine Hibbs Pherson 和 Randolph H. Pherson, 战略情报的批判性思维，第 2 版 (华盛顿，DC：CQ 出版社 / SAGE, 2017 年), xxii。

13. Richards J. Heuer Jr., 情报分析心理学 (华盛顿，DC：CIA 情报研究中心，1999 年；由 Pherson Associates, LLC 在 2007 年再版，雷斯顿，VA)。

14. Amos Tversky 和 Daniel Kahneman, "不确定性下的判断：启发式与偏差，" 科学 185, 第 4157 期 (1974 年)：1124–1131。

15. 情报分析心理学在 2007 年被 Pherson Associates, LLC 重新出版，并可以在其网站上购买，网址为 shop.globalytica.com。

16. Jeffrey R. Cooper 所著的《治愈分析病理：改善情报分析的途径》（华盛顿特区：中央情报局情报研究中心，2005 年）以及 Rob Johnston 的《美国情报界的分析文化：一项人种学研究》（华盛顿特区：中央情报局情报研究中心，2005 年）。

17. Heuer 的《情报分析心理学》。

18. 同上，第 112 页。

19. Emily Pronin、Daniel Y. Lin 和 Lee L. Ross 的论文《偏见盲点：自我与他人偏见的感知》，发表于《人格与社会心理学公报》第 28 卷第 3 期（2002 年），第 369-381 页。

20. 本章后面提到的认知偏差、误用启发式方法和直觉陷阱的定义，以及其他相关术语，均在第 24-25 页的图 2.3 中详细解释。

21. 故意误导或错误信息在中文中常被称为「假新闻」、「错误新闻」或「议程驱动的新闻」。尽管「假新闻」是最常用的术语，但由于该词被不准确地用于描述任何批评性的新闻报道，其准确性和有效性受到了质疑。

22. Rob Brotherton 在《华盛顿邮报》上发表的文章《阴谋论的五个迷思》（2019 年 1 月 17 日），网址为 https://www.washingtonpost.com/outlook/five-myths/five-myths-about-conspiracy-theories/2019/01/17/0ef1b840-1818-11e9-88fe-f9f77a3bcb6c_story，探讨了关于阴谋论的常见误解。

23. 「积极措施」一词指的是苏联及后来的俄罗斯自 1920 年代起采取的一系列行动，旨在通过宣传、伪造文件、渗透机构、迫害政治活动家以及政治暴力（包括暗杀）等手段影响公众的看法。退役将军基思·B·亚历山大（Keith B. Alexander）在美国参议院情报特别委员会上的证词《虚假信息：俄罗斯积极措施和影响运动的入门》（2017 年 3 月 30 日）提供了更多相关信息，网址为 https://www.intelligence.senate.gov/sites/default/files/documents/os-kalexander-033017.pdf。

24. Soroush Vosoughi, Deb Roy, 和 Sinan Aral 在《在线真假新闻的传播》（Science 359, no. 6380 (2018)：1146–1151）一文中探讨了真假新闻在网络上的传播现象。

25. Elisa Shearer 和 Jeffrey Gottfried 在 《2017 年跨社交媒体平台的新闻使用》（Washington, DC：Pew Research Center, September 7, 2017）报告中分析了新闻在不同社交媒体平台上的使用情况，报告链接为：http://www.journalism.org/2017/09/07/news-use-across-social-media-platforms-2017/

26. Randolph H. Pherson 和 Penelope Mort Ranta 在《认知偏差、数字虚假信息与结构化分析技术》（Revista Romănă de studii de intelligence (Romanian Journal of Intelligence Studies), Vol. 21, 2019）一文中对这一问题进行了深入讨论。该文主要受到 2016 年美国总统选举期间观察到的现象启发，类似的动态也在后续的法国、德国以及其他欧洲国家的选举以及英国脱欧运动中被观察到。

27. Katherine Hibbs Pherson 和 Randolph H. Pherson 在《战略情报的批判性思维》第 2 版（Washington, DC：CQ Press/SAGE, 2017）一书的第 55 页中，回顾了情报分析员最常遇到的认知偏差和误用启发式的情况。

28. Randolph H. Pherson 在《分析工具与技术手册》第 5 版（Tysons, VA：Pherson Associates, LLC, 2019）一书中，详细介绍了分析工具和技术的各个方面，分别在第 5、9、19、31、43、53 页进行了阐述。

Descriptions of Images and Figures

Back to Figure

In system 1 thinking, the judgment is intuitive. System 2 thinking involves critical thinking, structured analysis, quasi-quantitative analysis, and empirical analysis. Critical thinking is qualitative with known data and includes getting started, source validation, argumentation, and presentation. Structured analysis is qualitative with known and unknown data, and includes exploration, diagnostic, reframing, and foresight. Quasi-Quantitative Analysis is quantitative with known and unknown data, and includes computer-based tools using expert-generated data. Empirical analysis is quantitative with known data, and includes data-based computer tools and visualization techniques.

在系统 1 的思考模式中，我们的判断往往是基于直觉的，这种思考方式快速且自动化。而系统 2 的思考模式则更为复杂，它包括批判性思考、结构化分析、准定量分析和实证分析。批判性思考是一种定性分析，它依赖于已知的信息，并涉及问题的提出、信息的验证、论点的构建以及结果的展示。结构化分析则更加深入，它不仅考虑已知信息，还会探索未知领域，通过分析来诊断问题、重新构思解决方案，并对未来进行预测。准定量分析则运用了定量方法，它使用计算机工具来处理专家提供的数据，以便对问题进行量化分析。实证分析则专注于已有的数据，通过计算机工具和可视化技术来揭示数据背后的规律和趋势。





0201 结构化技术的作用

2.1 两种思维类型近三十年来，心理学领域在人类决策研究方面取得了显著进展。双过程理论，即区分两种决策系统 —— 系统 1 和系统 2，已成为该领域的核心理论。系统 1 代表直觉思维，而系统 2 则代表分析思维。

系统 1 思维是直觉性的，它快速、高效，且往往是无意识的。这种思维方式依赖于人们已有的知识、经验和长期形成的心理模型，这些模型描绘了人或事物在特定环境中的行为模式。系统 1 思维不需要太多努力，它使人们能够迅速且高效地解决问题和做出判断。然而，尽管直觉思维通常准确，但它也是认知偏差和其他直觉错误的温床，这些错误可能导致错误的分析。本章稍后将详细讨论三种认知限制：认知偏差、误用启发式和直觉陷阱。

系统 2 思维则是分析性的，它缓慢、有条理，且是有意识的。这种思维方式涉及深思熟虑的推理，包括批判性思维、结构化分析技术以及各种实证和定量方法。

本书对每种结构化分析技术的描述都详细讨论了该技术如何帮助避免、克服或至少减轻特定的认知偏差、误用启发式和直觉陷阱。此外，每种技术家族的介绍部分还指出了本章讨论的技术如何针对与系统 1 思维相关的认知偏差和其他常见直觉错误提供解决方案。

情报分析师在构建分析时主要依赖于直觉判断 —— 一种系统 1 的过程。当运用得当时，直觉判断 —— 有时被称为传统分析 —— 结合了专业知识和基本思维技能。证据推理、历史方法、案例研究方法和类比推理是这种分析类别的例子。2 直觉判断与结构化分析的主要区别在于，直觉判断通常是个体努力，推理过程主要存在于分析师的头脑中，直到它被写入草稿报告中。这种分析技能的培养通常在研究生教育阶段进行，特别是在社会科学和文科领域，并且通常伴随着一些国家或语言专业知识。

本章提出了一种定义系统 2 思维领域的分类法。分类法是对某些信息或知识体中所有元素的分类。它通过识别、命名和分类某一专业学科中的所有不同对象来定义领域。根据组内各对象共有的某一特征，这些对象被归类为相关组。

「分类法」一词源自希腊语 taxis，意味着安排、划分或顺序，以及 nomos，意味着法律。分类法的经典例子包括卡尔·林奈的生物科学中广泛使用的所有生物的等级分类，按界、门、纲、目、科、属和种进行分类。化学家使用的元素周期表是另一个例子。图书馆目录也被认为是一种分类法，因为它从一个相关类别的列表开始，然后逐渐细分为更精细的类别。

发展分类学是组织知识和推动学科进步的基石。罗伯特·约翰斯顿创建了一种影响情报分析变量的分类体系，但并未深入探讨分析技术和方法。他强调，「分类学如同指南针，通过明确研究领域、统一命名规则、界定研究焦点、确立研究重点，并往往引领新理论的诞生，从而区分不同的知识领域。」3

罗伯特·克拉克对情报来源进行了分类。4 同时，他也对情报分析中常用的分析方法进行了分类，但并未形成完整的分类学体系。截至目前，尽管在预测、运筹学、信息系统、可视化工具、电子商务、知识提取、认知任务分析等领域已经建立了研究方法的分类学，11 但在情报分析领域，尚未有人开发出分析技术的分类学。

经过对其他领域方法分类学的研究，我们认识到，组织分类学并无固定模式，关键在于其能否有效服务于特定目标。我们的目标在于深入理解结构化分析技术领域，探究这些技术如何提升分析质量，并考察它们与分析师需求的契合度。我们的任务是梳理现有技术，发掘或创造新的有用技术，并协助分析师在众多技术中挑选出最适合解决特定问题的工具。结构化分析技术的术语标准化将促进跨机构和国际间的协作。

图 2.1 的描述：系统 1 与系统 2 思维来源：Pherson Associates, LLC, 2019。

图 2.1 展示的分类法将系统 1（直觉思维）与系统 2 思维中运用的四种主要分析方法进行了区分。这四种方法包括结构化分析、批判性思维、实证分析和准定量分析，本章将详细阐述它们的特点和原理。下一章将深入探讨结构化分析技术的六个主要类别。

2.2 结构化分析技术的分类法构建情报分析人员面对多样化的主题，采用多种分析方法。本书虽专注于结构化分析，但首先对所有分析方法进行分类，有助于我们理解结构化分析在众多方法中的定位。一些研究者将分析方法简化为两类对比，如定性与定量、直觉与实证、直觉与科学。另一些则认为存在直觉、结构化和科学三种不同的分析方法。我们的分类法旨在澄清这一问题，通过区分系统 1 和系统 2 两种思维模式，并详细定义系统 2 思维的四种分析类别。

科学探索的第一步是识别事物的差异。这种识别基于事物的具体特征，而为了确保这些知识的稳定性和持久性，我们需要为不同的事物赋予特定的名称，并记录和记忆这些名称。

— 卡洛勒斯·林奈，《自然系统》（1738）

情报分析究竟是艺术还是科学，这一问题在情报分析领域的文献中一直存在争议。我们认为，情报分析实际上融合了艺术与科学的多个方面。它所涉及的活动范围极其广泛，涵盖了人类认知能力的各个层面，因此很难将其简单归类为艺术或科学，或者说它只属于其中一种。情报分析中某一部分被视为艺术还是科学，很大程度上取决于我们如何界定「艺术」与「科学」这两个概念。

本文提出的分类法将情报分析的方法论分为四种不同的功能性方法。这些方法的区别主要体现在分析方法的性质、是否涉及量化处理、所使用的数据类型以及所需的培训类型等方面。虽然每种方法都有其独特性，但它们之间的界限并不总是那么清晰。

批判性思维，根据情报方法论专家杰克·戴维斯的定义，是指将科学探究的方法和原则应用于战略情报领域的特殊情况。12 优秀的批判性思考者会深入思考：服务的对象是谁，需要解决的问题是什么，最佳的信息来源在哪里，如何构建一个有力的论点，以及如何有效地传达他们的观点。他们明白这个过程需要审视关键假设，寻找反驳证据，并考虑多种可能的解释。尽管大多数学生在学习过程中都会接触到批判性思维的技巧，但很少有教育机构提供专门的课程来系统地培养这些技能。

结构化分析是一种分析技术，它通过一系列步骤将分析者的思考过程清晰地展示出来，使得其他人能够容易地理解、审查和批评。这种方法通常需要团队合作，通过透明化的分析过程，分析者能够接触到不同的观点和意见。我们相信，结构化分析有助于减少个人分析者的认知局限、固有偏见以及各种认知偏差和直觉陷阱的影响。常用的结构化分析技术包括集群头脑风暴、远见分析、指标分析、竞争假设分析和关键假设检查。这些技术在本科和研究生课程以及情报机构的培训中都有教授，即使是没有统计学、高等数学或自然科学背景的分析者也能使用。

实证分析是指当有大量定量数据或社交媒体报告可用时，分析者运用定量方法来研究这些信息。实证数据的可量化性质与专家生成的数据有很大不同，因此用于分析的方法和问题类型也不同。计量经济学建模是实证分析的一个例子。随着社交媒体和物联网数据的爆炸性增长，复杂的算法能够识别趋势并测试假设。实证数据通过各种传感器收集，并用于分析武器系统或公众对新产品发布的反应。这种分析方法的培训通常在统计学、经济学、网络分析或自然科学的研究生教育中提供。

准定量分析是指当分析者缺乏实证数据时，使用专家生成的数据来填补分析中的空白。这种方法依赖于专家对关键变量进行评级，如高、中、低或不存在，或提供主观概率判断。专家使用特定的程序来获取这些判断，并将评级整合到一个描述特定现象的模型中，例如平民领导人对军事政变的脆弱性、政治不稳定的程度或立法辩论的可能结果。准定量分析方法包括贝叶斯推理、动态建模和模拟等。这些方法的培训通常在数学、信息科学、政治学、运筹学或商业等领域的研究生教育中提供。

这四种方法各有千秋，没有绝对的优劣之分。在不同的分析场景中，它们都是不可或缺的，共同助力我们更接近真相。在单一的分析项目中，灵活运用多种方法已成为业界的共识。例如，即便是最精细的量化分析，也难免涉及对行为动机、意图或能力的假设，这些往往需要借助批判性思维和结构化分析来深入探讨。头脑风暴则是一种有效的方法，它能帮助我们确定动态模型中的关键变量，这些变量随后将通过专家数据进行量化分析。

在这四种方法中，结构化分析相对较新，值得我们探讨它与系统 1 思维的联系。系统 1 思维是一种将专业知识与直觉判断相结合的思维方式，它主要发生在分析员的脑海中。尽管分析员可能会参考他人的意见，但最终的分析成果往往被视为个人的智慧结晶，分析员也因此对其产生强烈的归属感。然而，这种个人化的分析工作极易受到《情报分析心理学》、《战略情报的批判性思维》以及本书中所述的各种认知偏差的影响。13

结构化分析，也就是我们所说的系统 2 思维，是一种逐步进行的分析方法，它不仅适用于单个分析师，而且我们认为通过集体合作的方式能够获得更多的益处。这种分析技术通过一系列步骤，帮助具有共同兴趣的分析师们在解决分析问题时进行有效的沟通和协作。这种方法的关键在于，它能够让拥有不同专业背景和水平的参与者在分析过程的早期就接触到不同的观点、证据和心理模型，从而帮助即使是经验丰富的专家也能避免一些常见的认知偏差。通过这种结构化的集体讨论，我们还能够有效地避免群体思维，这是小型团队工作中最常见的问题之一。

当结构化分析技术被一个团队或一组人使用时，它能够促进信息的共享和团队的学习，这对于弥补团队成员在特定领域知识上的不足或弱点非常有帮助。特别是在那些需要整合多种专业知识的复杂项目中，这种方法显得尤为重要。

2.3 应对认知限制尽管直觉判断在很多情况下都非常有效，但它仍然属于大脑的系统 1 活动，这意味着它容易受到各种认知限制的影响。这些认知偏差和心理错误的可能来源包括长期的专业经验形成的固定分析思维模式、教育或培训背景、个人的成长环境、性格特征、重要的个人经历，或者是对某个决策的个人情感投入。

在本章中，我们将探讨三种不同类型的认知限制（请参见图 2.3）：

认知偏差是人们在处理信息时不可避免的思维错误。即使分析师掌握了所有构成准确观点所需的数据和证据，这些偏差也会妨碍他们准确理解现实。启发式方法是一种基于经验的技巧，它能够提供一个解决方案，尽管这个方案并不一定是最优的。启发式方法的目的是快速产生一个足够好的解决方案来应对当前的问题。然而，分析师可能会过度依赖或错误应用这些启发式方法。虽然启发式方法能够帮助分析师迅速得出答案，但这些答案有时会是错误的。直觉陷阱是认知偏差或启发式方法在实际工作中的具体表现，情报专业和其他许多领域的分析师在日常工作中常常会不自觉地陷入这些陷阱。

关于认知偏差和启发式方法如何影响一个人在多个领域中的思考，已有大量研究文献。然而，直觉陷阱作为一种新的偏差类别，是由伦道夫·菲尔森和他的教学同事首次提出的。他们在探索使用结构化分析技术来对抗认知限制的负面影响时发现了这一类别。目前，相关研究仍在进行中，旨在进一步完善和修订这十八个直觉陷阱的列表。

除了个人股权偏差之外，所有认知偏差、错误应用的启发式方法或直觉陷阱，更多时候是由于快速、无意识和直觉的系统 1 思维所导致的，而不是深思熟虑的系统 2 推理。尽管系统 1 思维常常是正确的，但它更容易受到认知偏差和心态的影响，以及知识和未来固有的不确定性。结构化分析技术作为一种系统 2 思维方式，有助于识别和克服系统 1 思维中固有的分析偏差。

自 20 世纪 70 年代初阿莫斯·特沃斯基和丹尼尔·卡尼曼提出认知偏差的概念以来，行为科学家一直在研究这些偏差对心理学、政治学、医学、经济学、商业和教育等多个领域分析和决策过程的影响。14 理查兹·休尔在 20 世纪 70 年代末和 80 年代为中央情报局（CIA）所做的工作，以及随后在 1999 年首次出版的《情报分析心理学》一书，将特沃斯基和卡尼曼的见解应用于情报分析师面临的问题。15 自该书出版以来，与美国情报界相关的其他作者（包括杰弗里·库珀和罗布·约翰斯顿）已经确定认知偏差是导致中央情报局分析失误的主要原因。16

图 2.3 认知偏差、误用启发式和直觉陷阱术语表本书是《情报分析心理学》的自然延续，后者详细阐述了影响情报分析的多种偏差和启发式。17 此后，学术文献中出现了数百种认知偏差和启发式，采用了多种术语。休尔多年前指出：「认知偏差类似于视觉错觉，即使人们完全了解其本质，错误仍然具有说服力。仅仅意识到偏差本身并不能带来更准确的感知。」18 这解释了为什么认知局限性极难克服。例如，艾米丽·普罗宁、丹尼尔·Y·林和李·罗斯在三项不同的研究中发现，人们更容易在他人身上而非自己身上察觉到认知和动机偏差的存在和运作。19 这也就解释了为何许多分析师认为自己的直觉思维（系统 1）足以应对分析任务。

情报专业分析师以及其他许多学科的分析师常常受到认知偏差、误用启发式方法和直觉陷阱的影响，这些都是公认偏差的体现。结构化分析技术帮助分析师避免、克服或至少减轻这些偏差的影响。

一个人如何感知信息受到多种因素的影响，如经验、教育、文化背景，以及这个人预期如何处理数据。我们的大脑被训练来快速处理信息，这往往导致我们错误地处理数据，或者忽视了数据的重要性，尤其是当数据不符合已建立的模式时。一些启发式方法，如战斗或逃跑的本能，或者当你闻到煤气泄漏时知道需要立即采取行动，是有帮助的。其他的则不那么有效。在解决问题时默认使用「经验法则」常常会导致固有的思维错误，因为信息被处理得太快或不正确。

认知偏差，如确认偏差或后见之明偏差，一开始就妨碍了分析思维。误用的启发式方法，如群体思维或过早封闭，在幸运的情况下，可能会导致基于非严格思维过程的正确决策。更常见的是，它们阻碍了分析过程，因为它们阻止我们考虑所有可能的范围。直觉陷阱，如投射过去的经验或过度解释小样本，是实践者在执行任务时所犯的思维错误。一个经典的例子是，当一名警探假设他或她正在处理的下一个案件将与前一个案件相似，或者一名将军准备打上一场战争而不是预见到下一场战争将不得不以不同的方式进行。

对于分析师而言，不幸的是，偏见、启发式方法和陷阱的形成既迅速又难以纠正。一旦分析师对某个议题形成固有看法，即使面对大量相反证据，也难以促使他们重新审视。分析师往往未能察觉新出现的模式或不一致的数据。更为严重的是，他们往往将异常数据视为「噪音」而忽视或排斥。

结构化分析技术有助于分析师避免、克服或至少减轻这些常见的认知局限。这些技术帮助分析师实现以下目标：

- 减少错误率。
- 避免情报和其他分析失误。
- 采用更多协作的工作方式。
- 确保责任追究。
- 使分析过程对其他分析师和决策者更加透明。

2.4 将认知局限性与结构化技术相匹配图 2.4 展示了如何将认知局限性与六大类结构化技术相匹配。

在本书中，我们提供了如何减少分析师对认知局限性的脆弱性的指导。在每类结构化分析技术的概述中，我们指出了两种认知偏差或误用的启发式方法，以及两种直觉陷阱，这些技术在该家族中最有效地对抗这些偏差（参见图 2.4）。对每种技术的描述包括关于该特定技术有助于减轻哪些偏差、启发式方法和陷阱的评论。我们认为，大多数技术以不同程度的效果对抗认知局限性，我们选择的匹配只是我们认为最有效的例证。需要进一步的研究来实证验证我们从过去十年教授这些技术和探索它们与关键认知局限性的关系中识别出的匹配。

2.5 对抗数字虚假信息

随着社交媒体平台越来越多地被用于操纵公众对政治或社会议题的看法，民主进程在美国乃至全球变得越来越脆弱。数字虚假信息的倡导者们，在很大程度上不受商业或法律约束、国际标准或道德的限制，已经变得越来越擅长利用人类普遍存在的认知局限，如确认偏误（Confirmation Bias）、群体思维（Groupthink）和情绪判断。历史可能会表明，我们严重低估了利用认知偏差、误用启发式方法和直觉陷阱来影响公众意见的容易程度。

数字虚假信息是有意误导读者的。数字虚假信息的制造者编造出引人入胜且看似连贯的叙述，通常会忽略不一致的证据并忽视基本的逻辑规则。数字欺骗者的主要目标是提供看似有说服力的错误信息，这些信息确认读者的偏见，并要么强化心理定势，要么播下对真相的冷漠或不信任。不加批判的读者往往会认为自己「找到了真相」，而实际上他们既是认知偏差、误用启发式方法和直觉陷阱的受害者，也是其传播者。

有目的的错误信息、阴谋论、欺骗和积极措施已被活动家和国家用于影响人们数十年，甚至数个世纪。由于以下原因，近年来这些对感知管理的影响似乎更加显著：

虚假信息的泛滥和数量已经达到了令人震惊的程度，这主要是因为社交媒体平台的强大传播能力。虚假信息的传播速度之快令人震惊，因为它们可以迅速在网络上「病毒式」传播，影响到数百万用户。麻省理工学院在科学杂志上的一项研究指出，虚假谣言在互联网上的传播速度是真实信息的六倍。24 人们似乎越来越倾向于寻找复杂问题的简单答案。社交网络平台通常将信息简化处理，使得信息更易于理解，但同时也失去了原有的细致和准确性。25

数字欺骗者利用社交媒体平台操纵公众认知的动机也大幅增加，原因如下：

- 几乎可以即时影响到数百万人。
- 很少有肇事者因其发布的内容受到追究。
- 肇事者可以精准定位那些最容易受影响和易于说服的人群。

另一个经常被忽视的解释数字误导信息影响加深的因素是个体对虚假信息的易感性。阴谋论的肇事者深知什么内容最有可能在其受众心中留下深刻印象。这种影响力通常是由于利用了人类普遍存在的、根深蒂固的认知偏差、误用的启发式方法和直觉陷阱。

数字虚假信息的制造者深知，操纵公众观念的最佳手段是利用人们固有的认知局限。他们能够预测一个人何时可能陷入认知偏差或错误应用启发式，从而增强其虚假信息的影响力。例如，虚假信息专家清楚地认识到，人们的观点受到其过往经历、教育背景、文化价值观以及自我认同的深刻影响，因此不同背景的人对信息的解读也会大相径庭。

此外，通过分析某人的社交媒体资料，可以更精准地识别如何包装错误信息以强化其既有观念。随着社交媒体平台和数据库的广泛应用，微观定位策略在产品营销中已显示出越来越高的效率，并在最近的政治运动中得到了广泛应用。

虚假信息制造者尤其擅长利用确认偏差 —— 即只寻求与自己观点相符的信息 —— 和生动性偏差 —— 即过分关注最引人注目的信息。他们还精通于利用错误应用的启发式，如锚定效应、群体思维和满足感。这些直觉陷阱，如情感判断、假设模式和小样本过度解读，都可能导致认知上的脆弱性。

认识到个人对数字虚假信息的脆弱性并不足以减轻威胁。需要一个更有效的策略 —— 一个涉及批判性思维策略和结构化分析技术的策略。如果人们养成习惯，评估支持某一主张的证据质量，并探究其他可信的、替代性的叙述可能如何解释所发生的事件，他们就不太可能被欺骗。以下是四种特别有效的结构化分析技术，它们有助于对抗数字虚假信息的影响：

关键假设检查。明确指出并质疑指导分析师对证据解释以及判断或结论背后推理的假设。
竞争性假设分析。评估信息与一组替代假设的一致性 / 不一致性，并拒绝那些与大量不一致数据相关的假设。
预先分析和结构化自我批评。一个系统的过程，使用头脑风暴和检查表程序来识别论点中的关键弱点，并评估关键分析判断可能如何严重错误。
