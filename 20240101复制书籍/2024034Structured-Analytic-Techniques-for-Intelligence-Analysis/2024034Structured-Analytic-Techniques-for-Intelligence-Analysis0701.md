Randolph H. Pherson, Richards J. Heuer.(2020).2024034Structured-Analytic-Techniques-for-Intelligence-Analysis3Ed.CQ Press => 0301 Choosing the Right Technique

## 0701. Diagnostic Techniques

A nalysis conducted by the intelligence, law enforcement, and business communities will never achieve the accuracy and predictability of a true science because the information with which analysts must work is typically incomplete, ambiguous, and potentially deceptive. The analytic process can, however, benefit from the lessons of science and adapt some of the elements of scientific reasoning.

The scientific process involves observing, categorizing, formulating hypotheses, and then testing those hypotheses. Generating and testing hypotheses is a core function of structured analysis. A possible explanation of the past or a judgment about the future is a hypothesis that needs to be tested by collecting and presenting evidence. This chapter focuses on several key techniques that support the Diagnostic Reasoning process, including challenging key assumptions about what the information reveals, developing Chronologies and Timelines, generating alternative hypotheses, and testing the validity of hypotheses and the quality of argumentation. Practice in using three of the techniques—Key Assumptions Check, Multiple Hypothesis Generation, and Analysis of Competing Hypotheses—will help analysts become proficient in the first three of the Five Habits of the Master Thinker (see chapter 3): challenging assumptions, generating alternative explanations, and identifying inconsistent evidence.

The generation and testing of hypotheses is a skill, and its subtleties do not come naturally. It is a form of reasoning that people can learn to use for dealing with high-stakes situations. What does come naturally is drawing on our existing body of knowledge and experience (mental model) to make an intuitive judgment. 1 In most circumstances in our daily lives, this is an efficient approach that works most of the time. For intelligence analysis, however, it is not adequate, because intelligence issues are generally so complex, and the risk and cost of error are too great. Also, the situations are often novel, so the intuitive judgment shaped by past knowledge and experience may well be wrong.

Good analysis of a complex issue must start with a set of alternative hypotheses. Another practice that the experienced analyst borrows from the scientist's toolkit involves the testing of alternative hypotheses. The truth of a hypothesis can never be proven beyond doubt by citing only evidence that is consistent with the hypothesis, because the same evidence may be and often is consistent with more than one hypothesis. Science often proceeds by refuting or disconfirming hypotheses. A hypothesis that cannot be refuted should be taken just as seriously as a hypothesis that seems to have a lot of evidence in favor of it. A single item of evidence that is shown to be inconsistent with a hypothesis can be grounds for rejecting that hypothesis. The most tenable hypothesis is often the one with the least evidence against it.

Analysts often test hypotheses by using a form of reasoning known as abduction, which differs from the two better known forms of reasoning, deduction and induction. Abductive reasoning starts with a set of facts. One then develops hypotheses that, if true, would provide the best explanation for these facts. The most tenable hypothesis is the one that best explains the facts. Because of the uncertainties inherent in intelligence analysis, conclusive proof or refutation of hypotheses is the exception rather than the rule.

Use of Diagnostic Techniques can provide a strong antidote to several cognitive biases. It can reduce the influence of Confirmation Bias by exposing analysts to new ideas and multiple permutations, and mitigate the impact of Evidence Acceptance Bias, which is accepting data as true because it helps create a more coherent story. Diagnostic Techniques also protect analysts against falling into the intuitive traps of Relying on First Impressions, Ignoring Inconsistent Evidence, and Projecting Past Experiences.

The first part of this chapter describes techniques for challenging key assumptions, establishing analytic baselines, and identifying the relationships among the key variables, drivers, or players that may influence the outcome of a situation. These and similar techniques allow analysts to imagine new and alternative explanations for their subject matter.

The second section describes three techniques for generating hypotheses. Other chapters include additional techniques for generating hypotheses, but which also have a variety of other purposes. These include Cluster Brainstorming, Nominal Group Technique, and Venn Analysis ( chapter 6 ); the Delphi Method and Classic Quadrant Crunching™ ( chapter 8 ); various forms of Foresight analysis ( chapter 9 ); and Critical Path Analysis and Decision Trees ( chapter 10 ).

This chapter concludes with a discussion of five techniques for testing hypotheses, detecting deception, and evaluating the strength of an argument. These techniques spur the analyst to become more sensitive to the quality of the data and the strength of the logic and to look for information that not only confirms but can disconfirm the hypothesis. One of these, Analysis of Competing Hypotheses (ACH), was developed by Richards J. Heuer Jr. specifically for use in intelligence analysis.

0701 诊断技术

情报、执法和商业界的分析工作，虽然难以达到纯科学研究那样的精确度和预见性，因为分析师所依赖的信息往往残缺不全、模棱两可，甚至带有误导性。然而，分析过程可以借鉴科学方法的精髓，融入科学推理的某些要素。

科学方法包括观察、分类、提出假设，进而对这些假设进行检验。在结构化分析中，提出并检验假设是至关重要的环节。对历史事件的解释或对未来趋势的预测，都需要通过搜集和呈现证据来验证其假设的正确性。本章节将探讨几种关键技术，它们有助于诊断推理过程的推进，包括质疑信息背后的关键假设、构建时间序列和时间线、提出多种可能的假设，以及验证假设的合理性和论证的严谨性。通过实践三种技术 —— 关键假设检查、多假设生成和竞争假设分析，分析师能够精通大师思考者的五个习惯中的前三项（详见第 3 章）：质疑既有假设、构思多种解释方案、识别证据中的矛盾之处。

生成和测试假设是一种需要后天学习的技能，它涉及到处理高风险情况的复杂推理。人们天生倾向于依赖已有的知识和经验（即心理模型）来做出直觉判断。在日常生活中，这种直觉判断通常是高效的，大多数情况下都能奏效。然而，在情报分析领域，这种方法就显得力不从心了，因为情报问题往往极其复杂，错误的代价和风险极高。而且，面对的往往是前所未见的新情况，基于过往知识和经验的直觉判断很可能失准。

对复杂问题的有效分析，首先要提出一系列可能的假设。经验丰富的分析师会借鉴科学家的方法，对这些假设进行测试。仅凭与假设相符的证据，无法完全证实假设的正确性，因为同样的证据可能与多个假设相符。科学研究往往通过反驳或证伪假设来取得进展。一个无法被反驳的假设，其可信度与拥有大量支持证据的假设相当。只要有一个证据与假设不符，就足以让我们对那个假设产生怀疑。最有可能正确的假设，往往是那些反对证据最少的。

分析师通常采用一种名为溯因推理的方法来检验假设，这种方法与更为人熟知的演绎和归纳推理有所不同。溯因推理首先基于一组事实，然后构建假设，这些假设如果成立，将提供对这些事实的最佳解释。最有说服力的假设是那些能够最准确解释事实的假设。在情报分析领域，由于存在不确定性，对假设的明确证明或反驳并不常见。

运用诊断技术能够有效对抗多种认知偏差。它通过引入新的观点和多种可能性，帮助分析师减少确认偏差的影响，并降低因追求故事连贯性而接受证据的偏差。此外，诊断技术还能帮助分析师避免直觉陷阱，如过分依赖第一印象、忽视矛盾证据以及过度投射个人经验。

本章首先介绍了一系列技术，用于挑战关键假设、确立分析基准，并识别可能影响局势结果的关键变量、驱动因素或参与者之间的关系。这些技术使分析师能够探索对其研究对象的新颖和替代解释。

接下来，本章介绍了三种产生假设的技术。其他章节还包含了更多用于产生假设的技术，这些技术同时也服务于其他目的。例如，集群头脑风暴、名义小组技术和维恩分析（参见第 6 章）；德尔菲法和经典象限挤压™（参见第 8 章）；以及各种前瞻性分析（参见第 9 章）和关键路径分析与决策树（参见第 10 章）。

本章最后讨论了五种测试假设、检测欺骗和评估论点强度的技术，这些技术促使分析师更加敏感于数据的质量和逻辑的强度，并寻找不仅能够证实而且能够反驳假设的信息。其中之一，竞争性假设分析法（ACH），是由理查兹·J·休尔（Richards J. Heuer Jr.）专门为情报分析开发的方法。

Overview of Techniques

Key Assumptions Check is one of the most important and frequently used techniques. Analytic judgment is always based on a combination of evidence and assumptions—or preconceptions—that influence how the evidence is interpreted. The Key Assumptions Check is a systematic effort to make explicit and question the assumptions (i.e., mental model) that guide an analyst's thinking.

Chronologies and Timelines are used to organize data on events or actions. They are used whenever it is important to understand the timing and sequence of relevant events or to identify key events and gaps.

Cross-Impact Matrix is a technique that can be used after any form of brainstorming that identifies a list of variables relevant to an analytic project. The results of the brainstorming session are put into a matrix, which is used to guide a group discussion that systematically examines how each variable influences all other variables to which it is related in a particular problem context. The group discussion is often a valuable learning experience that provides a foundation for further collaboration. Results of cross-impact discussions should be retained for future reference as a cross-check after the analysis is completed.

Multiple Hypothesis Generation can be accomplished in many ways. This book describes three techniques—Simple Hypotheses, Quadrant Hypothesis Generation, and the Multiple Hypothesis Generation. Simple Hypotheses is the easiest to use but not always the best selection. Quadrant Hypothesis Generation is used to identify a set of hypotheses when the outcome is likely to be determined by just two driving forces. Multiple Hypothesis Generation is used to identify a large set of possible hypotheses. The latter two techniques are particularly useful in identifying sets of M utually E xclusive and C omprehensively E xhaustive (MECE) hypotheses.

Diagnostic Reasoning applies hypothesis testing to the evaluation of significant new information. Such information is evaluated in the context of all plausible explanations of that information, not just in the context of the analyst's well-established mental model. The use of Diagnostic Reasoning reduces the risk of surprise, as it ensures that an analyst will have considered some alternative conclusions. Diagnostic Reasoning differs from the ACH technique in that it evaluates a single item of evidence; ACH deals with an entire issue involving multiple pieces of evidence and a more complex analytic process.

Analysis of Competing Hypotheses is the application of Karl Popper's philosophy of science to the field of intelligence analysis. 2 Popper was one of the most influential philosophers of science of the twentieth century. He is known for, among other things, his position that scientific reasoning should start with multiple hypotheses and proceed by rejecting or eliminating hypotheses, tentatively accepting only those hypotheses that cannot be refuted. This process forces an analyst to recognize the full uncertainty inherent in most analytic situations. ACH helps the analyst sort and manage relevant information to identify paths for reducing that uncertainty.

The Inconsistencies Finder™ is a simplified version of ACH that helps analysts evaluate the relative credibility of a set of hypotheses based on the amount of identified disconfirming information. It provides a quick framework for identifying inconsistent data and discovering the hypotheses that are most likely to be correct.

Deception Detection employs a set of checklists analysts can use to determine when to anticipate deception, how to determine if one is being deceived, and what to do to avoid being deceived. It is also useful for detecting the presence of Digital Disinformation or "Fake News." The possibility of deception by a foreign intelligence service, economic competitor, or other adversary organization is a distinctive type of hypothesis that can be included in any ACH analysis. Information identified through the Deception Detection technique can then be entered as relevant information in an ACH matrix.

Argument Mapping is a method that can be used to put a single hypothesis to a rigorous logical test. The structured visual representation of the arguments and evidence makes it easier to evaluate any analytic judgment. Argument Mapping is a logical follow-on to an ACH analysis. It is a detailed presentation of the arguments for and against a single hypothesis; ACH is a more general analysis of multiple hypotheses. The successful application of Argument Mapping to the hypothesis favored by the ACH analysis would increase confidence in the results of both analyses.

技术概览

关键假设检查是最重要也是最常用的技术之一。分析判断总是基于证据和假设（或先入为主的观念）的组合，这些假设影响证据的解释方式。关键假设检查是一种系统性的努力，旨在明确并挑战指导分析师思考的假设（即心理模型）。

时间线和时间轴用于组织事件或行动的数据。当理解相关事件的时间和顺序或识别关键事件和差距变得重要时，它们就会被使用。

交叉影响矩阵是一种技术，适用于任何形式的头脑风暴之后，该头脑风暴识别出与分析项目相关的变量列表。头脑风暴的结果被放入一个矩阵中，该矩阵用于指导小组讨论，系统地检查每个变量如何影响特定问题上下文中与之相关的所有其他变量。小组讨论通常是一个宝贵的学习经验，为未来的合作奠定了基础。交叉影响讨论的结果应该保留以供将来参考，并在分析完成后作为交叉检查。

多重假设生成有多种实现方法。本书介绍了三种技术 —— 简单假设、象限假设生成和多重假设生成。简单假设使用起来最简单，但并非总是最佳选择。象限假设生成用于在结果可能仅受两个主要因素影响时，提出一组假设。多重假设生成则用于提出大量可能的假设。后两种技术尤其适用于提出一组既互斥又全面覆盖所有可能性的假设（MECE）。

诊断推理是一种将假设测试应用于评估重要新信息的方法。这种方法要求在所有可能解释该信息的合理假设的背景下评估信息，而不仅仅局限于分析员已有的心智模型。通过诊断推理，分析员能够考虑多种可能的结论，从而降低对意外事件的误判风险。与竞争假设分析（ACH）不同，诊断推理侧重于评估单个证据项；而 ACH 则处理包含多个证据项和更复杂分析过程的整个问题。

竞争假设分析（ACH）是将卡尔·波普尔的科学哲学思想应用于情报分析的一种方法。波普尔是 20 世纪最具影响力的科学哲学家之一，他主张科学推理应从多个假设出发，通过排除或拒绝那些可被反驳的假设，来推进科学理论的发展。ACH 方法迫使分析员面对分析过程中固有的不确定性，并帮助他们整理和处理相关信息，以找到减少不确定性的途径。

Inconsistencies Finder™ 是一种简化版的 ACH 工具，它帮助分析师根据已识别的不一致信息量来评估一组假设的相对可信度。它提供了一个快速框架，用于识别数据中的不一致性，并找出最可能正确的假设。

欺骗检测使用一套检查清单，分析师可以用它来判断何时可能遇到欺骗行为，如何识别自己是否正遭受欺骗，以及如何采取措施避免被欺骗。这种方法还有助于检测数字虚假信息或「假新闻」的存在。外国情报机构、经济竞争对手或其他敌对组织进行欺骗的可能性是一种特殊的假设类型，可以纳入任何 ACH 分析中。通过欺骗检测技术识别的信息随后可以作为相关信息输入到 ACH 矩阵中。

论证映射是一种可以用来对单一假设进行严格逻辑测试的方法。论点和证据的结构化视觉表示使得评估任何分析判断变得更加容易。论证映射是 ACH 分析的逻辑延续。它是对单一假设支持与反对论点的详细展示；而 ACH 是对多个假设的更一般性分析。成功地将论证映射应用于 ACH 分析中偏好的假设，将增强对两种分析结果的信心，因为它提供了对假设更深入的逻辑检验。

7.1 Key Assumptions Check

Analytic judgment is always based on a combination of evidence and assumptions, or preconceptions, which influences how the evidence is interpreted. 3 The Key Assumptions Check is a systematic effort to make explicit and question the assumptions (the mental model) that guide an analyst's interpretation of evidence and reasoning about a problem. Such assumptions are usually necessary and unavoidable as a means to fill gaps in the incomplete, ambiguous, and sometimes deceptive information with which the analyst must work. They are driven by the analyst's education, training, and experience, plus the organizational context in which the analyst works.

An organization really begins to learn when its most cherished assumptions are challenged by counterassumptions. Assumptions underpinning existing policies and procedures should therefore be unearthed, and alternative policies and procedures put forward based upon counterassumptions.

— Ian I. Mitroff and Richard O. Mason, Creating a Dialectical Social Science: Concepts, Methods, and Models (1981)

The Key Assumptions Check is one of the most common techniques used by intelligence analysts because they typically need to make assumptions to fill information gaps. In the intelligence world, these assumptions are often about another country's intentions or capabilities, the way governmental processes usually work in that country, the relative strength of political forces, the trustworthiness or accuracy of key sources, the validity of previous analyses on the same subject, or the presence or absence of relevant changes in the context in which the activity is occurring. Assumptions are often difficult to identify because many sociocultural beliefs are held unconsciously or so firmly that they are assumed to be truth and not subject to challenge.

When to Use It

Any explanation of current events or estimate of future developments requires the interpretation of evidence. If the available evidence is incomplete or ambiguous, this interpretation is influenced by assumptions about how things normally work in the country or company of interest. These assumptions should be made explicit early in the analytic process.

If a Key Assumptions Check is not done at the outset of a project, it can still prove extremely valuable if done during the coordination process or before conclusions are presented or delivered. When a Key Assumptions Check is done early in the process, it is often desirable to review the assumptions again later—for example, just before or just after drafting the report. The task is to determine whether the assumptions still hold true or should be modified.

When tracking the same topic or issue over time, analysts should consider reassessing their key assumptions on a periodic basis, especially following a major new development or surprising event. If, on reflection, one or more key assumptions no longer appear to be well-founded, analysts should inform key policymakers or corporate decision makers working that target or issue that a foundational construct no longer applies or is at least doubtful.

Value Added

Preparing a written list of one's working assumptions at the beginning of any project helps the analyst do the following:

Identify the specific assumptions that underpin the basic analytic line. Achieve a better understanding of the fundamental dynamics at play. Gain a better perspective and stimulate new thinking about the issue. Discover hidden relationships and links among key factors. Identify what developments would call a key assumption into question. Avoid surprises should new information render old assumptions invalid.

A Key Assumptions Check helps analysts mitigate the impact of heuristics that, when misapplied, can impede analytic thinking, including the tendency to accept a given value of an assumption or something unknown as a proper starting point for generating an assessment (Anchoring Effect), reaching an analytic judgment before sufficient information is collected and proper analysis performed (Premature Closure), and judging the frequency of an event by the ease with which instances come to mind (Availability Heuristic). It also safeguards an analyst against several classic mental mistakes, including the tendency to overdraw conclusions when presented with only a small amount of data (Overinterpreting Small Samples), assume the same dynamic is in play when something appears to be in accord with past experiences (Projecting Past Experiences), and failing to factor something into the analysis because the analyst lacks an appropriate category or "bin" for that item of information (Lacking Sufficient Bins).

Conducting a Key Assumptions Check gives analysts a better understanding of the suppositions underlying their key judgments or conclusions. Doing so helps analysts establish how confident they should be in making their assessment and disseminating their key findings.

The Method

The process of conducting a Key Assumptions Check is relatively straightforward in concept but often challenging to put into practice. One challenge is that participating analysts must be open to the possibility that they could be wrong. It helps to involve several well-regarded analysts who are generally familiar with the topic but have no prior commitment to any set of assumptions about the issue in the process. Engaging a facilitator is also highly recommended. Keep in mind that many "key assumptions" turn out to be "key uncertainties." Randolph Pherson's extensive experience as a facilitator of analytic projects indicates that approximately one in every four key assumptions collapses on careful examination.

The following are steps in conducting a Key Assumptions Check:

Gather a small group of individuals who are working the issue along with a few "outsiders." The primary analytic unit already is working from an established mental model, so the "outsiders" are needed to bring a different perspective. Ideally, the facilitator should notify participants about the topic beforehand and ask them to bring to the meeting a list of assumptions they make about the topic. If they do not do this beforehand, start the meeting with a silent brainstorming session by asking each participant to write down several assumptions on an index card. Collect the cards and list the assumptions on a whiteboard or easel for all to see. Elicit additional assumptions. Work from the prevailing analytic line to identify additional arguments that support it. Use various devices to help prod participants' thinking:

Ask the standard journalistic questions. Who: Are we assuming that we know who all the key players are? What: Are we assuming that we know the goals of the key players? How: Are we assuming that we know how they are going to act? When: Are we assuming that conditions have not changed since our last report or that they will not change in the foreseeable future? Where: Are we assuming that we know where the real action is going to be? Why: Are we assuming that we understand the motives of the key players? Use of phrases such as "will always," "will never," or "would have to be" suggests that an idea is not being challenged. Perhaps it should be. Use of phrases such as "based on" or "generally the case" suggests the presence of a challengeable assumption. When the flow of assumptions starts to slow down, ask, "What else seems so obvious that one would not normally think about challenging it?" If no one can identify more assumptions, then there is an assumption that they do not exist, which itself is an assumption subject to challenge. After identifying a full set of assumptions, critically examine each assumption and ask,

Why am I confident that this assumption is correct? In what circumstances might this assumption be untrue? Could it have been true in the past but not any longer? How much confidence do I have that this assumption is valid? If it turns out to be invalid, how much impact would this have on the analysis? Place each assumption in one of three categories:

Basically solid (S) Correct with some caveats (C) Unsupported or questionable—the "key uncertainties" (U) Refine the list. Delete assumptions that do not hold up to scrutiny and add new ones that emerge from the discussion. If an assumption generates a lot of discussion, consider breaking it into two assumptions or rephrasing it to make the statement more explicit. Above all, emphasize those assumptions that would, if wrong, lead to changing the analytic conclusions. Consider whether key uncertainties should be converted into intelligence collection requirements or research topics.

When concluding the analysis, remember that the probability of your analytic conclusion being accurate cannot be greater than the weakest link in your chain of reasoning. Review your assumptions, assess the quality of evidence and reliability of sources, and consider the overall difficulty and complexity of the issue. Then make a rough estimate of the probability that your analytic conclusion will turn out to be wrong. Use this number to calculate the rough probability of your conclusion turning out to be accurate. For example, a three in four chance (75 percent) of being right equates to a one in four chance (25 percent) of being wrong. This focus on how and why we might be wrong is needed to offset the natural human tendency toward reluctance to admit we might be wrong.

Figure 7.1 shows apparently flawed assumptions made in the Wen Ho Lee espionage case during the 1990s and what further investigation showed about these assumptions. A Key Assumptions Check could have identified weaknesses in the case against Lee much earlier.

Relationship to Other Techniques

The Key Assumptions Check is frequently paired with other techniques because assumptions play an important role in all structured analytic efforts. It is important to get them right. For example, when an assumption is critical to an analysis, and questions remain about the validity of that assumption, it may be desirable to follow the Key Assumptions Check with a What If? Analysis. Imagine a future (or a present) in which the assumption is wrong. What could have happened to make it wrong, how could that have happened, and what are the consequences?

Figure 7.1 Key Assumptions Check: The Case of Wen Ho Lee Source: Pherson Associates, LLC, 2019.

There is a particularly noteworthy interaction between Key Assumptions Check and ACH. Key assumptions need to be included as "evidence" in an ACH matrix to ensure that the matrix is an accurate reflection of the analyst's thinking. Assumptions often emerge during a discussion of relevant information while filling out an ACH matrix. This happens when an analyst assesses the consistency or inconsistency of an item of evidence with a hypothesis and concludes that the designation is dependent upon something else—usually an assumption. Classic Quadrant Crunching™ ( chapter 8 ) and Simple Scenarios, the Cone of Plausibility, and Reversing Assumptions ( chapter 9 ) all use assumptions and their opposites to generate multiple explanations or outcomes.

Origins of This Technique

Although assumptions have been a topic of analytic concern for a long time, the idea of developing a specific analytic technique to focus on assumptions did not occur until the late 1990s. The discussion of Key Assumptions Check in this book is from Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019).

7.1 关键假设检查分析判断的形成往往依赖于证据与假设或先入之见的结合，这些因素共同塑造了分析师对证据的解读及其对问题的推理方式。关键假设检查是一种系统性的方法，旨在揭示并挑战那些指导分析师理解证据和推理过程的内在假设（即心理模型）。这些假设在分析师处理不完整、模糊甚至带有误导性的信息时显得尤为必要和不可避免。它们源自分析师的教育背景、专业训练、实践经验，以及其所处的组织环境。

一个组织只有在面对挑战其核心假设的对立观点时，才能真正实现学习与成长。因此，揭示并审视支撑现有政策和程序的假设至关重要，同时基于对立假设提出新的政策和程序也是必要的。

— Ian I. Mitroff 和 Richard O. Mason，《创造辩证社会科学：概念、方法和模型》（1981）

关键假设检查是情报分析师常用的技术之一，因为在情报分析中，分析师经常需要基于假设来填补信息上的空白。在情报领域，这些假设可能涉及其他国家的意图或能力、该国政府运作的常规方式、政治力量的相对强弱、关键信息来源的可靠性或准确性、以往对同一主题分析的有效性，以及活动发生环境中相关变化的存在与否。识别这些假设往往颇具挑战，因为许多社会文化信仰可能被无意识地接受，或者被视为不容置疑的真理。

何时使用

对于当前事件的任何解释或未来发展的估计都需要基于证据的解读。如果证据不完整或模糊，解读过程中会受到关于该国或公司通常运作方式的假设的影响。这些假设应在分析过程的早期明确提出。

如果在项目开始时未进行关键假设检查，那么在协调过程中或在结论提出或交付之前进行，仍然极其有价值。在分析过程早期进行关键假设检查后，通常希望在报告起草前后再次审查这些假设。此时，任务是确定这些假设是否仍然有效，或者是否需要进行修改。

当随着时间的推移跟踪同一主题或问题时，分析人员应考虑定期重新评估他们的关键假设，特别是在发生重大新发展或意外事件之后。如果经过反思，发现一个或多个关键假设不再成立，分析人员应通知在该目标或问题上工作的关键政策制定者或企业决策者，指出一个基础构建不再适用或至少是可疑的。

增值在任何项目的开始准备一份书面工作假设列表，有助于分析人员：

- 明确支撑基本分析线的具体假设。
- 更好地理解正在发挥作用的基本动态。
- 获得更好的视角并激发对问题的新的思考。
- 发现关键因素之间的隐藏关系和联系。
- 确定哪些发展会质疑一个关键假设。
- 避免意外，当新信息使旧假设无效时。

进行关键假设检查有助于分析师减轻启发式方法误用对分析思维的影响，包括倾向于将某个假设值或未知事物视为评估的起点（锚定效应），在未充分收集信息和进行分析之前就急于做出判断（过早封闭），以及根据回忆实例的难易程度来估计事件发生的频率（可用性启发式）。此外，它还能帮助分析师避免几种常见的心理误区，如在数据有限时过度解读（过度解释小样本），错误地认为当前情况与过去经验中的动态相同（投射过去的经验），以及因缺乏合适的信息分类而未能将重要信息纳入分析（缺乏足够的分类）。

通过进行关键假设检查，分析师能够更深入地理解支撑其关键判断或结论的假设。这有助于分析师确定他们对于自己的评估和传播关键发现的信心程度。

方法

进行关键假设检查的过程在概念上看似简单，但在实际操作中却常常面临挑战。其中一个挑战是，参与的分析师必须能够接受自己的假设可能是错误的。为了确保检查的有效性，建议邀请几位在该领域有广泛知识但未对特定假设有预设立场的知名分析师参与。此外，聘请一位经验丰富的促进者来引导整个过程也是非常重要的。需要注意的是，许多被视为「关键假设」的点，在深入分析后往往变成了「关键不确定性」。根据兰多夫·费舍尔作为分析项目促进者的丰富经验，大约有四分之一的关键假设在经过仔细审查后会被推翻。

进行关键假设检查的步骤如下：

- 组织一个由正在处理该问题的分析师和一些「局外人」组成的小组。由于主要分析团队可能已经形成了一套固定的思维模式，因此「局外人」的加入可以带来新的视角。理想情况下，促进者应提前通知参与者会议的主题，并要求他们准备一份关于该主题的假设清单。如果参与者未能提前准备，可以在会议开始时进行一次无声的头脑风暴，让每位参与者在索引卡上写下他们的假设。随后，收集这些卡片，并将假设列在白板或挂图上，供所有人共同审视。鼓励参与者提出更多的假设。从当前主流的分析观点出发，寻找支持这些观点的额外论据。使用各种启发式工具来激发参与者的思考：

未找到意译内容

基本上，我们可以将假设分为三类：坚固的（S）、有条件的正确（C）、以及未被证实或存在疑问的 —— 即「关键的不确定性」（U）。我们需要对这个假设列表进行细化。删除那些经不起仔细审查的假设，并根据讨论中出现的新信息添加新的假设。如果某个假设引发了广泛的讨论，我们可以考虑将其拆分为两个更具体的假设，或者重新表述以使假设的含义更加清晰。最重要的是，我们需要特别关注那些如果错误，将直接影响分析结论的假设。同时，我们也可以考虑将这些关键的不确定性转化为情报收集的具体要求或研究的重点。

在分析结束时，我们必须认识到，我们的分析结论的准确性概率不可能高于我们推理链条中最薄弱的一环。因此，我们需要回顾所有的假设，评估证据的质量和来源的可靠性，并全面考虑问题的复杂性和难度。在此基础上，我们可以对分析结论可能出错的概率进行一个大致的估计。然后，我们可以用这个估计来计算我们的结论最终准确的粗略概率。例如，如果我们有 75% 的把握认为结论是正确的，那么也就意味着我们有 25% 的可能性是错误的。这种对可能出错的关注，是为了对抗人们通常不愿意承认自己可能犯错的自然倾向。

图 7.1 展示了在 20 世纪 90 年代的文·何·李间谍案中，一些明显错误的假设，以及通过进一步调查揭示的这些假设的真实情况。如果在案件早期进行关键假设检查，可能就能更早地发现针对李的指控中的弱点。

与其他技术的关联

关键假设检查常与其他分析方法结合使用，因为假设在所有结构化分析中都至关重要。正确识别这些假设是分析成功的关键。例如，当一个假设对分析结果至关重要，且其有效性存疑时，紧随关键假设检查之后进行「如果假设错误会怎样？」的分析是有益的。我们可以设想一个未来（或当前）情境，其中假设不成立。是什么因素可能导致假设错误？这些因素如何影响假设？以及可能带来的后果是什么？

图 7.1 关键假设检查：文浩李案例来源：Pherson Associates, LLC, 2019.

关键假设检查与分析假设法（ACH）之间有着特别重要的互动。在 ACH 矩阵中，关键假设应被视为「证据」的一部分，以确保矩阵准确反映分析师的思考过程。在构建 ACH 矩阵时，讨论相关信息的过程中往往会浮现出新的假设。这种情况发生在分析师评估证据与假设之间的一致性或不一致性时，意识到这种评估依赖于其他因素 —— 通常是一个或多个假设。经典四象限挤压™（第 8 章）和简单场景、可能性锥体以及反转假设（第 9 章）等方法都利用假设及其对立面来探索多种可能的解释或结果。

这项技术的起源尽管假设一直是分析领域关注的焦点，但直到 20 世纪 90 年代末，才有人提出专门针对假设进行分析的技术。本书中关于关键假设检查的讨论源自伦道夫·H·弗森的《分析工具和技术手册》第 5 版（Tysons, VA：Pherson Associates, LLC, 2019）。




7.2 Chronologies and Timelines

A Chronology is a list that places events or actions in the order in which they occurred, usually in narrative or bulleted format. A Timeline is a graphic depiction of those events put in context of the time of the events and the time between events. Both are used to identify trends or relationships among the events or actions and, in the case of a Timeline, among the events and actions as well as other developments in the context of the overarching intelligence problem.

When to Use It

Chronologies and Timelines aid in organizing events or actions. The techniques are useful whenever analysts need to understand the timing and sequence of relevant events. They can also reveal significant events or important gaps in the available information. The events may or may not have a cause-and-effect relationship.

Chronologies and Timelines are usually developed at the onset of an analytic task to ascertain the context of the activity under review. They can be used in postmortems to break down the stream of reporting, find the causes for analytic failures, and highlight significant events after an intelligence or business surprise. Chronologies and Timelines are also useful for organizing information in a format that can be readily understood in a briefing or when presenting evidence to a jury.

Value Added

Chronologies and Timelines help analysts identify patterns and correlations among events. Analysts can use them to relate seemingly disconnected events to the big picture; to highlight or identify significant changes; or to assist in the discovery of trends, developing issues, or anomalies. They can serve as a catchall for raw data when the meaning of the data is not yet clear. Multiple-level Timelines allow analysts to track concurrent events that may affect one another.

The activities on a Timeline can lead an analyst to hypothesize the existence of previously unknown events. In other words, the series of known events may make sense only if other previously unknown events had occurred. The analyst can then look for other indicators of those missing events.

Chronologies and Timelines are useful tools analysts can use to counter the impact of cognitive biases and heuristics, including accepting data as true without assessing its credibility because it helps "make the case" (Evidence Acceptance Bias), seeing patterns in random events as systematic and part of a coherent story (Desire for Coherence and Uncertainty Reduction), and providing quick and easy answers to difficult problems (Mental Shotgun). It can also mitigate the impact of several intuitive traps, including giving too much weight to first impressions or initial data that attracts our attention at the time (Relying on First Impressions), not paying sufficient attention to the impact of the absence of information (Ignoring the Absence of Information), and discarding or ignoring information that is inconsistent with what one would expect to see (Ignoring Inconsistent Evidence).

The Method

Chronologies and Timelines are effective yet simple ways to order incoming information when processing daily message traffic. A Microsoft Word document or an Excel spreadsheet can log the results of research and marshal evidence. Tools such as the Excel drawing function or Analysts' Notebook can be helpful in drawing the Timeline. Follow these steps:

When researching the problem, ensure that the relevant information is listed with the date or order in which it occurred. It is important to properly reference the data to help uncover potential patterns or links. Be sure to distinguish between the date the event occurred and the date the report was received. Review the Chronology or Timeline by asking the following questions:

What are the temporal distances between key events? If "lengthy," what caused the delay? Are there missing pieces of data that may fill those gaps that should be collected? Was information overlooked that may have had an impact on or be related to the events? Conversely, if events seem to have happened more rapidly than expected or if some of the events do not appear to be related, is it possible that the analyst has information related to multiple event Timelines? Does the Timeline have all the critical events that are necessary for the outcome to occur? When did the information become known to the analyst or a key player? Are there information or intelligence gaps? Are there any points along the Timeline when the target is particularly vulnerable to the collection of intelligence or information or countermeasures? What events outside this Timeline could have influenced the activities? If preparing a Timeline, synopsize the data along a horizontal or vertical line. Use the space on both sides of the line to highlight important analytic points. For example, place facts above the line and points of analysis or commentary below the line. Alternatively, contrast the activities of different groups, organizations, or streams of information by placement above or below the line. If multiple actors are involved, you can use multiple lines, showing how and where they converge. For example, multiple lines could be used to show (1) the target's activities, (2) open source reporting about the events, (3) supplemental classified or proprietary information, and (4) analytic observations or commentary. Look for relationships and patterns in the data connecting persons, places, organizations, and other activities. Identify gaps or unexplained time periods, and consider the implications of the absence of evidence. Prepare a summary chart detailing key events and key analytic points in an annotated Timeline.

Potential Pitfalls

In using Timelines, analysts may assume, incorrectly, that events following earlier events were caused by the earlier events. Also, the value of this technique may be reduced if the analyst lacks imagination in identifying contextual events that relate to the information in the Chronology or Timeline.

Description Figure 7.2 Timeline Estimate of Missile Launch Date Source: Pherson Associates, LLC, 2019. Note: A TEL is a transporter, erector, and launcher for missiles.

Example

A team of analysts working on strategic missile forces knows what steps are necessary to prepare for and launch a nuclear missile. (See Figure 7.2 .) The analysts have been monitoring a country they believe is close to testing a new variant of its medium-range surface-to-surface ballistic missile. They have seen the initial steps of a test launch in mid-February and decide to initiate a concentrated watch of the primary and secondary test launch facilities. Observed and expected activities are placed into a Timeline to gauge the potential dates of a test launch. The analysts can thus estimate when a possible missile launch may occur and make decision makers aware of indicators of possible activity.

Origins of This Technique

Chronologies and Timelines are well-established techniques used in many fields. The information here is from M. Jones, "Sorting, Chronologies, and Timelines," The Thinker's Toolkit (New York: Three Rivers Press, 1998), chapter 6 ; and from Pherson Associates training materials.


7.2 编年史与时间线编年史是一系列按照事件或行动发生顺序排列的记录，通常采用叙述或项目符号列表的形式。时间线则是以图形方式展示这些事件，将其置于历史背景中，并标明事件之间的时间间隔。这两种工具都用于揭示事件或行动之间的趋势和联系，而时间线更进一步，将这些事件与其他相关发展联系起来，为更广泛的情报问题提供背景。

何时使用编年史和时间线是组织和理解事件顺序的有效工具。当分析师需要梳理事件的时间顺序时，这些工具尤为重要。它们不仅能够揭示关键事件，还能指出信息中的缺失部分，这些事件之间可能存在因果关系，也可能没有。

在分析任务初期，编年史和时间线常被用来构建事件的背景框架。在事后分析中，它们有助于剖析情报报告的流程，找出分析失误的原因，并在情报或商业领域的意外事件发生后，凸显关键事件的重要性。此外，它们在准备简报或向陪审团展示证据时，能够以清晰易懂的方式组织信息。

增加的价值编年史和时间线是分析师识别事件间模式和关联的有力工具。通过它们，分析师能够将零散的事件与整体情境相联系，突出显示或识别重大变化，以及辅助发现趋势、新兴问题或异常现象。当数据的含义尚不明确时，它们可以作为收集和整理原始数据的工具。多层次时间线使分析师能够追踪并分析可能相互影响的并发事件。

时间线上的活动可能会启发分析师推测出之前未被发现的事件。简而言之，已知事件的顺序只有在其他未被记录的事件发生时才显得合理。随后，分析师可以寻找这些遗漏事件的其他线索。

年代记和时间线是分析师用来减轻认知偏差和启发式影响的实用工具，这些偏差包括未经核实就接受数据为真，因为这有助于「构建论点」（证据接受偏差），在随机事件中寻找模式，将其视为有系统的，并融入连贯的故事中（对连贯性和不确定性减少的追求），以及为复杂问题提供快速简单的解答（心理散弹枪）。它还能减少几种直觉陷阱的影响，例如过分重视第一印象或最初引起注意的数据（依赖第一印象），不充分考虑信息缺失的影响（忽视信息缺失），以及忽略与预期不符的信息（忽视不一致证据）。

方法年代记和时间线是整理日常消息流量中接收信息时的有效且简单的方法。可以使用 Microsoft Word 文档或 Excel 电子表格来记录研究结果并整理证据。Excel 的绘图功能或 Analysts' Notebook 等工具可以帮助绘制时间线。按照以下步骤操作：

在研究问题时，确保将相关信息按其发生的日期或顺序列出。正确引用数据以帮助揭示潜在的模式或链接非常重要。要特别注意区分事件发生的日期和报告收到的日期。通过询问以下问题来检查年代记或时间线：

未找到意译内容

在使用时间线分析时，分析人员有时会错误地假设，后续事件是由先前事件引起的。此外，如果分析人员在识别与时间线或年表信息相关的背景事件时缺乏创造性思维，那么这种分析方法的价值可能会大打折扣。

图 7.2 展示了导弹发射日期的时间线估计，该图由 Pherson Associates, LLC 于 2019 年提供。特别指出，TEL 指的是导弹的运输、竖立和发射装置。

举例来说，一个分析团队专注于战略导弹部队的研究，他们熟知核导弹发射的准备流程。（请参阅图 7.2。）这个团队一直在密切关注一个国家，他们推测该国即将对其中程地对地弹道导弹进行新变种的测试。在 2 月中旬，他们观察到了测试发射的初步迹象，并决定加强对主要和次要测试发射设施的监控。他们将观察到的和预期的活动整合到一个时间线中，以此来预测可能的测试发射日期。通过这种方式，分析人员能够预估导弹发射的可能时间，并向决策者提供可能活动的预警信号。

本文提到的技术信息源自 M. Jones 的著作《思考者的工具包》（纽约：Three Rivers Press，1998），特别是第 6 章中关于「排序、年表和时间线」的内容；以及 Pherson Associates 提供的相关培训材料。


7.3 Cross-Impact Matrix

The Cross-Impact Matrix helps analysts deal with complex problems when "everything is related to everything else." By using this technique, analysts and decision makers can systematically examine how each factor in a context influences all other factors to which it appears related.

When to Use It

The Cross-Impact Matrix is useful early in a project when a group is still in a learning mode trying to sort out a complex situation. Whenever a brainstorming session or other meeting is held to identify all the variables, drivers, or players that may influence the outcome of a situation, the next logical step is to use a Cross-Impact Matrix to examine the interrelationships among each of these variables. A group discussion of how each pair of variables interacts can be an enlightening learning experience and a good basis on which to build ongoing collaboration. How far one goes in completing the matrix and producing a description of the effects associated with each variable may vary depending upon the nature and significance of the project. At times, just the discussion is adequate.

Analysis of cross-impacts is useful when the following occurs:

A situation is in flux, and analysts need to understand all the factors that might influence the outcome. This requires understanding how all the factors relate to one another, and how they might influence one another. A situation is stable, and analysts need to identify and monitor all the factors that could upset that stability. This, too, requires understanding how the various factors might interact to influence one another. A significant event has just occurred, and analysts need to understand the implications of the event. What other significant forces are influenced by the event, and what are the implications of this influence?

Value Added

When analysts are estimating or forecasting future events, they consider the dominant forces and potential future events that might influence an outcome. They then weigh the relative influence or likelihood of these forces or events, often considering them individually without regard to potentially important interactions. The Cross-Impact Matrix provides a context for the discussion of these interactions. This discussion often reveals that variables or issues once believed to be simple and independent are interrelated. The sharing of information during a discussion of each potential cross-impact can provide an invaluable learning experience. For this reason alone, the Cross-Impact Matrix is a useful tool that can be applied at some point in almost any study that seeks to explain current events or forecast future outcomes.

The Cross-Impact Matrix provides a structure for managing the complexity that makes most analysis so difficult. It requires that analysts clearly articulate all assumptions about the relationships among variables. Doing so helps analysts defend or critique their conclusions by tracing the analytical argument back through a path of underlying premises.

Use of the Cross-Impact Matrix is particularly effective in helping analysts avoid being influenced by heuristics such as stopping the search for a cause when a seemingly satisfactory answer is found (Premature Closure), selecting the first answer that appears "good enough" (Satisficing), and seeing patterns in random events as systematic and part of a coherent world (Desire for Coherence and Uncertainty Reduction). It can also provide a powerful antidote to several intuitive pitfalls, including overinterpreting conclusions from a small sample of data (Overinterpreting Small Samples), giving too much weight to first impressions or initial data that appears important at the time (Relying on First Impressions), and continuing to hold to a judgment when confronted with additional or contradictory evidence (Rejecting Evidence).

The Method

Assemble a group of analysts knowledgeable on various aspects of the subject. The group brainstorms a list of variables or events that would likely have some effect on the issue being studied. The project coordinator then creates a matrix and puts the list of variables or events down the left side of the matrix and the same variables or events across the top.

The group then fills out the matrix, considering, and then recording, the relationship between each variable or event and every other variable or event. For example, does the presence of Variable 1 increase or diminish the influence of Variables 2, 3, 4, and so on? Or does the occurrence of Event 1 increase or decrease the likelihood of Events 2, 3, 4, and so forth? If one variable does affect the other, the positive or negative magnitude of this effect can be recorded in the matrix by entering a large or small + or a large or small – in the appropriate cell (or by making no marking at all if there is no significant effect). The terminology used to describe the relationship between each pair of variables or events is based on whether it is "enhancing," "inhibiting," or "unrelated."

The matrix shown in Figure 7.3 has six variables, with thirty possible interactions. Note that the relationship between each pair of variables is assessed twice, as the relationship may not be symmetric. That is, the influence of Variable 1 on Variable 2 may not be the same as the impact of Variable 2 on Variable 1. It is not unusual for a Cross-Impact Matrix to have substantially more than thirty possible interactions, in which case careful consideration of each interaction can be time-consuming.

Description Figure 7.3 Cross-Impact Matrix

Analysts should use the Cross-Impact technique to focus on significant interactions between variables or events that may have been overlooked, or combinations of variables that might reinforce one another. Combinations of variables that reinforce one another can lead to surprisingly rapid changes in a predictable direction. On the other hand, recognizing that there is a relationship among variables and the direction of each relationship may be sufficient for some problems.

The depth of discussion and the method used for recording the results are discretionary. Each depends upon how much you are learning from the discussion, which will vary from one application of this matrix to another. If the group discussion of the likelihood of these variables or events and their relationships to one another is a productive learning experience, keep it going. If key relationships are identified that are likely to influence the analytic judgment, fill in all cells in the matrix and take good notes. If the group does not seem to be learning much, cut the discussion short.

As a collaborative effort, team members can conduct their discussion—and periodically review—their key findings online. As time permits, analysts can enter new information or edit previously entered information about the interaction between each pair of variables. This record will serve as a point of reference or a memory jogger throughout the project.

Relationship to Other Techniques

Matrices as a generic technique with many types of applications are discussed in chapter 5 . The use of a Cross-Impact Matrix as described here frequently follows some form of brainstorming at the start of an analytic project. Elicit the assistance of other knowledgeable analysts in exploring all the relationships among the relevant factors identified in the brainstorming session. Analysts can build on the discussion of the Cross-Impact Matrix by developing a visual Mind Map or Concept Map of all the relationships.

See also the discussion of the Complexity Manager technique in chapter 10 . An integral part of the Complexity Manager technique is a form of Cross-Impact Analysis that takes the analysis a step further toward an informed conclusion.

Origins of This Technique

The Cross-Impact Matrix technique was developed in the 1960s as one element of a quantitative futures analysis methodology called Cross-Impact Analysis. Richards J. Heuer Jr. became familiar with it when the CIA was testing the Cross-Impact Analysis methodology. He started using it as an intelligence analysis technique, as described here, more than forty years ago. For simple instructions for using the Cross-Impact Matrix and printable templates, go to http://discoveryoursolutions.com/toolkit/cross_impact_matrix.html.

7.3 交叉影响矩阵交叉影响矩阵是一种工具，它帮助分析师在面对「万物互联」的复杂问题时，能够系统地分析每个因素如何影响其他与之相关的因素。

何时使用在项目初期，当团队还在学习如何应对复杂情况时，交叉影响矩阵尤为有用。在识别所有可能影响结果的变量、驱动因素或参与者的头脑风暴会议或其他讨论之后，使用交叉影响矩阵来探究这些变量之间的相互关系是合乎逻辑的下一步。通过讨论每对变量之间的相互作用，团队可以获得深刻的见解，并为持续的合作奠定坚实的基础。至于矩阵的完成程度以及对每个变量影响的具体描述，这取决于项目的特性和重要性。有时候，仅仅进行讨论就已经足够。

交叉影响的分析在以下情况中是有用的：

- 当情况不断变化，分析师需要全面理解可能影响结果的所有因素及其相互关系时。
- 当情况稳定，但需要识别并监控可能破坏稳定性的因素及其相互作用时。
- 当重大事件发生后，分析师需要评估该事件对其他重要力量的影响及其潜在后果时。

增值

分析师在预测未来事件时，会考虑主导力量和可能影响结果的未来事件，并评估这些力量或事件的相对影响力或可能性。通常，他们将这些因素单独考虑，忽略了它们之间可能存在的重要相互作用。交叉影响矩阵为此类相互作用的讨论提供了一个平台。通过这种讨论，我们常常发现，原本看似简单和独立的变量或问题实际上是相互关联的。在讨论每个潜在的交叉影响时，信息的共享能够带来宝贵的学习机会。因此，交叉影响矩阵是一个实用的工具，几乎可以在任何旨在解释当前事件或预测未来结果的研究中使用。

交叉影响矩阵提供了一个结构，帮助管理分析中遇到的复杂性。它要求分析师明确表达所有关于变量之间关系的假设。这样做有助于分析师通过追溯分析论点背后的基本前提来捍卫或批评他们的结论。

使用交叉影响矩阵特别有助于帮助分析师避免受到启发式偏差的影响，例如在找到一个看似满意的答案后就停止寻找原因（即过早闭合），或者选择第一个看起来「足够好」的答案（即满足性），以及将随机事件视为系统性的并作为连贯世界的一部分（即对连贯性和不确定性减少的渴望）。这种方法还可以提供对几种直觉陷阱的有力补救，包括对小样本数据过度解释结论（即过度解释小样本），给予第一印象或最初看似重要的数据过多权重（即依赖第一印象），以及面对额外或矛盾证据时仍然坚持判断（即拒绝证据）。

方法如下：

召集一组对主题各个方面有知识的分析师。该组进行头脑风暴，列出可能对正在研究的问题产生一些影响的变量或事件。然后，项目协调员创建一个矩阵，将这些变量或事件列表放在矩阵的左侧，并将相同的变量或事件横跨顶部。

小组接着构建矩阵，深入分析并详细记录每个变量或事件与其他所有变量或事件之间的相互作用。例如，变量 1 的存在是否会增强或削弱变量 2、3、4 等的影响？或者事件 1 的发生是否会提高或降低事件 2、3、4 等发生的可能性？如果一个变量确实对另一个变量产生影响，这种影响的正负强度可以通过在矩阵的相应单元格中标注大小不同的加号或减号来体现（如果没有显著影响，则留空）。描述每对变量或事件之间关系的术语包括「增强」、「抑制」或「无关」。

图 7.3 展示了一个包含六个变量、存在三十种潜在相互作用的交叉影响矩阵。值得注意的是，每对变量之间的关系被评估两次，因为这种关系可能不是对等的。也就是说，变量 1 对变量 2 的影响可能与变量 2 对变量 1 的影响不同。在实际应用中，交叉影响矩阵可能包含数百种甚至更多的相互作用，因此仔细分析每一种相互作用可能是一项耗时的任务。

描述图 7.3 交叉影响矩阵分析师应当运用交叉影响技术，以识别那些可能被忽略的变量或事件之间的关键相互作用，或是那些可能相互增强的变量组合。相互增强的变量组合可能导致在可预测方向上的快速且显著的变化。另一方面，仅仅识别变量之间的关系及其影响方向，对于解决某些问题已经足够。

讨论的深度和记录结果的方式取决于具体情况。这取决于你在讨论中学到了多少，每次应用矩阵时都可能不同。如果集体讨论这些变量或事件的可能性及其相互关系是一个有益的学习过程，那么就继续深入讨论。如果发现了可能影响分析判断的重要关系，那么就详细记录在矩阵中，并做好笔记。如果小组的讨论收获不大，那么就及时结束讨论。

作为团队合作的一部分，成员们可以在网上进行讨论，并定期回顾他们的主要发现。在时间允许的情况下，分析师可以添加新的信息或修改之前关于每对变量相互作用的信息。这个记录将成为项目进行中的一个重要参考，帮助大家回忆和回顾。

与其他技术的联系矩阵作为一种多用途的技术，在第 5 章中有所讨论。这里描述的交叉影响矩阵通常在分析项目开始时通过头脑风暴来引入。在探讨头脑风暴中确定的相关因素之间的关系时，可以邀请其他经验丰富的分析师参与。分析师可以通过创建一个视觉化的思维导图或概念图来进一步发展交叉影响矩阵的讨论，展示所有关系的网络。

请参阅第 10 章中关于复杂性管理器技术的讨论。复杂性管理器技术中的一个关键部分是一种形式的交叉影响分析，它帮助分析更接近一个基于事实的结论。

这项技术的起源

Cross-Impact Matrix 技术是在 1960 年代作为 Cross-Impact Analysis 这一定量未来分析方法论的一个组成部分而开发的。Richards J. Heuer Jr. 在中央情报局测试 Cross-Impact Analysis 方法论时熟悉了这项技术，并在四十多年前就开始将其应用于情报分析领域。关于如何使用 Cross-Impact Matrix 的简单说明和可打印模板，您可以访问 http://discoveryoursolutions.com/toolkit/cross_impact_matrix.html 获取更多信息。



7.4 Multiple Hypothesis Generation

In broad terms, a hypothesis is a potential explanation or conclusion that is to be tested by collecting and analyzing evidence. It is a declarative statement that has not been established as true—an "educated guess" based on observation to be supported or refuted by more observation or through experimentation.

A good hypothesis should satisfy the following criteria represented by the mnemonic STOP:

S tatement, not a question. T estable and falsifiable. O bservation—and knowledge-based. P redicts anticipated results clearly.

Hypothesis Generation should be an integral part of any rigorous analytic process because it helps the analyst think broadly and creatively about a range of possibilities and avoid being surprised when common wisdom turns out to be wrong. The goal is to develop a list of hypotheses that can be scrutinized and tested over time against existing relevant information as well as new data that may become available in the future. Analysts should strive to make the hypotheses mutually exclusive and the list as comprehensively exhaustive as possible—thereby satisfying the imperative that hypotheses should be M utually E xclusive and C omprehensively E xhaustive (MECE).

There are many techniques used to generate hypotheses, including techniques discussed elsewhere in this book, such as Venn Analysis, Cluster Brainstorming, several forms of Foresight analysis, Classic Quadrant Crunching™, Starbursting, Delphi Method, and Decision Trees. This section discusses techniques developed specifically for hypothesis generation and then presents the method for three different techniques: Simple Hypotheses, Quadrant Hypothesis Generation, and the Multiple Hypotheses Generator ® .

When to Use It

Gaining confidence in a hypothesis is not a function solely of accumulating evidence in its favor but in showing that situations that could establish its falsity do not, in fact, happen. Analysts should develop multiple hypotheses at the start of a project when the following occurs:

the importance of the subject matter requires a systematic analysis of all alternatives, many factors or variables are involved in the analysis, a high level of uncertainty exists about the outcome, analysts or decision makers hold competing views.

Simple Hypotheses is often used to broaden the spectrum of plausible hypotheses. It utilizes Cluster Brainstorming to create potential hypotheses based on affinity groups. Quadrant Hypothesis Generation works best when the problem has two key drivers. In these circumstances, a 2-×-2 matrix is adequate for creating hypotheses that reflect the situations posited in each quadrant. The Multiple Hypotheses Generator ® is particularly helpful when there is a reigning lead hypothesis.

Value Added

Multiple Hypothesis Generation provides a structured way to generate a comprehensive set of mutually exclusive hypotheses. This can increase confidence that an important hypothesis has not been overlooked. It can also help reduce cognitive biases, such as seeking only the information that is consistent with the lead hypothesis (Confirmation Bias), accepting a given value of something or a lead hypothesis as a proper—or the only—starting point for conducting an analysis (Anchoring Effect), stopping the search for a cause when a seemingly satisfactory answer is found before sufficient information and proper analysis can be performed (Premature Closure), and seeing patterns in random events as systematic and part of a coherent story (Desire for Coherence and Uncertainty Reduction). When the techniques are used properly, choosing a lead hypothesis becomes much less critical than making sure that analysts have considered all possible explanations.

The techniques are particularly useful in helping intelligence analysts overcome some classic intuitive traps, such as the following:

Assuming a Single Solution. Most analysts quickly develop an initial lead hypothesis to explain the topic at hand and continue to test the initial hypothesis as new information appears. A good analyst will simultaneously consider a few alternatives. This helps ensure that no diagnostic information is ignored because it does not support the lead hypothesis. For example, when individuals move large amounts of money from China to other countries, financial analysts are likely to suspect that ill-begotten monies are being laundered. On some occasions, however, the funds could have been obtained through legitimate means; this alternative hypothesis should be in play until it can be disproven by the facts of the case. Overinterpreting Small Samples. Analysts frequently are pressed to "make a call" when there is insufficient data to support the assessment. In such cases, a preferred strategy is to offer several possible alternatives. The U.S. Intelligence Community—and the world as a whole—would have been better served if the National Intelligence Council in its Iraq WMD National Intelligence Estimate had proffered three (and not just the first two) hypotheses that (1) Iraq had a substantial WMD program and the intelligence community had not yet found the evidence, (2) Iraq had a more modest program but could readily accelerate production in areas that had fallen fallow, or (3) Iraq had no WMD program and reporting to the contrary was deception. Projecting Past Experiences. When under pressure, analysts can select a hypothesis primarily because it avoids a previous error or replicates a past success. A prime example of this was the desire not to repeat the mistake of underestimating Saddam Hussein's WMD capabilities in the run-up to the second U.S. war with Iraq. Relying on First Impressions. When pressed for time, analysts can also fall into the trap of giving too much weight to first impressions or initial data that attracts their attention at the time. Analysts are especially susceptible to this bias if they have recently visited a country or have viewed a particularly vivid or disturbing video.

7.4.1 The Method: Simple Hypotheses

To use the Simple Hypotheses method, define the problem and determine how the hypotheses will be used at the beginning of the project. Hypotheses can be applied several ways: (1) in an Analysis of Competing Hypotheses, (2) in some other hypothesis-testing project, (3) as a basis for developing scenarios, or (4) as a means to draw attention to particularly positive or worrisome outcomes that might arise. Figure 7.4.1 illustrates the process.

Gather together a diverse group to review the available information and explanations for the issue, activity, or behavior that you want to evaluate. In forming this diverse group, consider including different types of expertise for different aspects of the problem, cultural expertise about the geographic area involved, different perspectives from various stakeholders, and different styles of thinking (left brain/right brain, male/female). Then do the following:

Ask each member of the group to write down on an index card up to three alternative explanations or hypotheses. Prompt creative thinking by using the following:

Applying theory. Drawing from the study of many examples of the same phenomenon.

Description Figure 7.4.1 Simple Hypotheses Source: Globalytica, LLC, 2019. Comparison with historical analogies. Comparing current events to historical precedents. Situational logic. Representing all the known facts and an understanding of the underlying forces at work at the given time and place. Collect the cards and display the results on a whiteboard. Consolidate the list to avoid any duplication. Employ additional individual and group brainstorming techniques, such as Cluster Brainstorming, to identify key forces and factors. Aggregate the hypotheses into affinity groups and label each group. Use problem restatement and consideration of the opposite to develop new ideas. Update the list of alternative hypotheses. If the hypotheses will be used in Analysis of Competing Hypotheses, strive to keep them mutually exclusive—that is, if one hypothesis is true, all others must be false. Have the group clarify each hypothesis by asking the journalist's classic list of questions: Who, What, How, When, Where, and Why? Select the most promising hypotheses for further exploration.

7.4.2 The Method: Quadrant Hypothesis Generation

Use the four-quadrant technique to identify a basic set of hypotheses when two key driving forces are likely to determine the outcome of an issue. The technique identifies four potential scenarios that represent the extreme conditions for each of the two major drivers. It spans the logical possibilities inherent in the relationship and interaction of the two driving forces, thereby generating options that analysts otherwise may overlook.

Quadrant Hypothesis Generation is easier and quicker to use than the Multiple Hypotheses Generator ® , but it is limited to cases in which the outcome of a situation will be determined by two major driving forces—and it depends on the correct identification of these forces. The technique is less effective when more than two major drivers are present or when analysts differ over which forces constitute the two major drivers.

The steps for using Quadrant Hypothesis Generation follow:

Identify two main drivers by using techniques such as Cluster Brainstorming or by surveying subject-matter experts. A discussion to identify the two main drivers can be a useful exercise. Construct a 2-×-2 matrix using the two drivers. Think of each driver as a continuum from one extreme to the other. Write the extremes of each of the drivers at the end of the vertical and horizontal axes. Fill in each quadrant with the details of what the end state would be if shaped by the two extremes of the drivers. Develop signposts or indicators that show whether events are moving toward one of the hypotheses. Use the signposts or indicators of change to develop intelligence collection strategies or research priorities to determine the direction in which events are moving.

Description Figure 7.4.2 Quadrant Hypothesis Generation: Four Hypotheses on the Future of Iraq

Figure 7.4.2 shows an example of a Quadrant Hypothesis Generation chart. In this case, analysts have been tasked with developing a paper to project possible futures for Iraq, focusing on the potential end state of the government. The analysts have identified and agreed upon the two key drivers in the future of the government: the level of centralization of the federal government and the degree of religious control of that government. They develop their quadrant chart and lay out the four logical hypotheses based on their decisions.

The four hypotheses derived from the quadrant chart can be stated as follows:

The final state of the Iraq government will be a centralized state and a secularized society. The final state of the Iraq government will be a centralized state and a religious society. The final state of the Iraq government will be a decentralized state and a secularized society. The final state of the Iraq government will be a decentralized state and a religious society.

7.4.3 The Method: Multiple Hypotheses Generator ®

The Multiple Hypotheses Generator ® is a technique for developing multiple alternatives for explaining an issue, activity, or behavior. Analysts often can brainstorm a useful set of hypotheses without such a tool, but the Multiple Hypotheses Generator ® may give greater confidence than other techniques that analysts have not overlooked a critical alternative or outlier. Analysts should employ the Multiple Hypotheses Generator ® to ensure that they have considered a broad array of potential hypotheses. In some cases, they may have considerable data and want to ensure that they have generated a set of plausible explanations consistent with all the data at hand. Alternatively, they may have been presented with a hypothesis that seems to explain the phenomenon at hand and been asked to assess its validity. The technique helps analysts rank alternative hypotheses from the most to least credible, focusing on those at the top of the list as those deemed most worthy of attention.

To use this method:

Gather a diverse group to define the issue, activity, or behavior under study. Often, it is useful to ask questions in the following ways:

What variations could be developed to challenge the lead hypothesis that . . .? What are the possible permutations that would flip the assumptions contained in the lead hypothesis that . . .? Identify the Who, What, and Why for the lead hypothesis. Then generate plausible alternatives for each relevant key component. Review the lists of alternatives for each of the key components; strive to keep the alternatives on each list mutually exclusive. Generate a list of all possible permutations, as shown in Figure 7.4.3 .

Figure 7.4.3 Multiple Hypotheses Generator ® : Generating Permutations Source: Globalytica, LLC, 2019. Discard any permutation that simply makes no sense. Evaluate the credibility of the remaining permutations by challenging the key assumptions of each component. Some of these assumptions may be testable themselves. Assign a "credibility score" to each permutation using a 1-to-5-point scale where 1 is low credibility and 5 is high credibility. Re-sort the remaining permutations, listing them from most credible to least credible. Restate the permutations as hypotheses, ensuring that each meets the criteria of a good hypothesis. Select from the top of the list those hypotheses most deserving of attention.

Potential Pitfalls

The value of this technique is limited to the ability of analysts to generate a robust set of alternative explanations. If group dynamics are flawed, the outcomes will be flawed. Whether the correct hypothesis will emerge from this process and analysts identify it as such cannot be guaranteed, but the prospect of the correct hypothesis being included in the set of hypotheses under consideration is greatly increased.

Relationship to Other Techniques

The product of any Foresight analysis process can be thought of as a set of alternative hypotheses. Quadrant Hypothesis Generation is a specific application of the generic method called Morphological Analysis, described in chapter 9 . Alternative Futures Analysis uses a similar quadrant chart approach to define four potential outcomes, and Multiple Scenarios Generation uses the approach to define multiple sets of four outcomes. Both of these techniques are also described in chapter 9 .

Origins of This Technique

The generation and testing of hypotheses is a key element of scientific reasoning. The Simple Hypotheses approach and Quadrant Hypothesis Generation are described in the Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019) and Pherson Associates training materials. The description of the Multiple Hypotheses Generator ® can be found in the fourth edition of the Handbook of Analytic Tools and Techniques (Reston, VA: Pherson Associates, LLC, 2015).

7.4 多重假设生成在广义上，假设是一种可能的解释或结论，它需要通过收集和分析证据来进行检验。它是一个尚未被证实的陈述性语句 —— 基于观察的「有根据的猜测」，旨在通过进一步的观察或实验来验证其正确性或错误性。

一个好的假设应当满足由助记符 STOP 所代表的以下标准：

S：作为陈述，而非问题。T：既可证伪又稳定。O：基于观察和已有知识。P：明确预测可能的结果。

假设生成是任何严格分析过程中不可或缺的一部分，它帮助分析员广泛而创造性地探索各种可能性，避免在常识被证明错误时感到意外。其目标在于构建一组假设，这些假设能够与现有的相关信息以及未来可能出现的新数据进行持续的审查和测试。分析员应当致力于确保这些假设之间互不重叠，且尽可能全面覆盖所有可能性，以满足假设应互斥且全面穷尽（MECE）的原则。

生成假设的技术多种多样，包括本书其他部分讨论的技术，如维恩分析、集群头脑风暴、多种形式的远见分析、经典象限压缩™、星爆法、德尔菲法和决策树等。本节将探讨专门用于假设生成的技术，并介绍三种不同的技术方法：简单假设、象限假设生成和多重假设生成器 ®。

何时使用它

未找到意译内容

这些技术特别有助于帮助情报分析人员克服一些经典的直觉陷阱，例如以下几种：

避免单一假设的陷阱。分析师在面对问题时，往往会迅速形成一个初步的主导假设，并随着新信息的获取不断验证这一假设。然而，优秀的分析师会同时考虑多个可能的解释，以确保不会因为信息与主导假设不符而被忽略。例如，当有人将大量资金从中国转移到其他国家时，金融分析师可能会首先怀疑这是洗钱行为。但也有可能这些资金是通过合法途径获得的，因此这一替代假设应当被保留，直到有确凿证据证明其不成立。

警惕小样本的过度解读。在数据不足的情况下，分析师常常面临做出判断的压力。在这种情况下，提供多个可能的解释是更为明智的做法。例如，美国情报界在评估伊拉克是否拥有大规模杀伤性武器时，如果能够提出三种不同的假设，而不是仅仅两种，那么将更有助于全面理解情况：（1）伊拉克拥有大规模杀伤性武器计划，但情报界尚未找到证据；（2）伊拉克的计划规模较小，但有能力在短时间内加速生产；或者（3）伊拉克根本没有大规模杀伤性武器计划，之前的报告是误导。

反思过去的经验。在压力之下，分析师可能会倾向于选择一个假设，仅仅因为它避免了过去的错误或是重复了以往的成功。例如，在第二次伊拉克战争前夕，美国情报界为了避免重蹈低估萨达姆·侯赛因大规模杀伤性武器能力的覆辙，可能会过于倾向于某些假设。

注意第一印象的影响。在时间紧迫的情况下，分析师可能会过分依赖最初的信息或印象，尤其是当这些信息特别引人注目或令人印象深刻时。例如，如果分析师最近访问了一个国家或观看了一个特别生动或令人不安的视频，他们可能会受到这些第一手资料的强烈影响。

7.4.1 方法：简单假设为了运用简单假设方法，项目伊始便需明确问题，并规划这些假设的应用方式。假设的应用途径多样：(1) 在竞争假设分析中发挥作用，(2) 在其他假设检验项目中扮演角色，(3) 作为构建情景的基石，或者 (4) 作为提醒我们关注可能出现的特别积极或令人担忧结果的工具。图 7.4.1 清晰地描绘了这一流程。

组建一个多元化的团队，成员们将共同审视与问题相关的信息和解释，无论是涉及的活动还是行为，都是我们评估的对象。在构建这个多元化的团队时，我们应考虑吸纳不同领域的专业知识，包括对相关地理区域文化的深入了解，不同利益相关者的视角，以及多样化的思维模式（如左脑逻辑思维与右脑创造性思维，或不同性别的思维差异）。接下来，我们应采取以下步骤：

请每位团队成员在一张索引卡上，尽可能地提出最多三个不同的解释或假设。为了激发创造性思维，我们可以采取以下方法：

- 应用理论：借鉴对同一现象众多案例的研究成果。

图 7.4.1 描述了简单假设的来源，由 Globalytica, LLC 在 2019 年提供。这种方法通过将当前事件与历史上的类似情况进行对比，来分析和理解当前情境。它基于所有已知的事实，并考虑了特定时间和地点下潜在力量的作用。首先，我们收集相关信息并将其展示在白板上，然后整理这些信息以避免重复。接下来，我们运用集群头脑风暴等个人和团队创意技巧，来识别影响事件的关键力量和因素。我们将这些假设分组，并为每个组别命名。通过重新表述问题和考虑相反的情况，我们能够产生新的想法，并更新我们的假设列表。在进行竞争性假设分析时，我们确保每个假设都是互斥的，即如果一个假设成立，其他假设则必须不成立。我们通过提出记者常用的「六何」问题（何人、何事、如何、何时、何地、为何）来进一步澄清每个假设。最后，我们挑选出最有潜力的假设进行深入研究。

7.4.2 方法：四象限假设生成当问题的结果可能由两个关键驱动因素决定时，我们可以使用四象限技术来生成一组基本的假设。这种方法通过识别四种极端情景，每种情景代表两个主要驱动因素的一种极端条件，来探索所有逻辑上的可能性。这样，我们就能够考虑到两个驱动因素之间相互作用的所有可能情况，从而产生分析师可能忽视的选项。

Quadrant Hypothesis Generation 相较于 Multiple Hypotheses Generator®，更易于使用且操作更快捷，但它仅适用于结果由两个主要驱动力决定的情况，并且正确识别这些驱动力至关重要。当存在两个以上的主要驱动因素，或者分析人员对哪些力量构成两个主要驱动因素意见不一时，该技术的有效性会降低。

使用 Quadrant Hypothesis Generation 的步骤如下：

首先，通过 Cluster Brainstorming 等技术或咨询领域专家，识别出两个主要驱动因素。进行讨论以明确这两个关键驱动因素，这本身就是一个有益的过程。接着，构建一个 2×2 矩阵，将每个驱动因素视为一个从一端到另一端的连续体。在矩阵的垂直和水平轴上标出每个驱动因素的两个极端。然后，在每个象限内详细描述如果受到这两个驱动因素极端影响，最终状态将会如何。接下来，制定迹象或指标，以显示事件是否正朝着某个假设发展。最后，利用这些迹象或指标的变化，制定情报收集策略或研究重点，以追踪事件的发展方向。

图 7.4.2 描述了 Quadrant Hypothesis Generation 的一个应用实例：关于伊拉克未来的四个假设。

在图 7.4.2 中，展示了一个 Quadrant Hypothesis Generation 图表的示例。分析人员被要求撰写一份文件，预测伊拉克的未来，特别关注政府的潜在最终状态。分析人员已经确定了并一致同意影响政府未来的两个关键驱动因素：联邦政府的集中化程度和政府的宗教控制程度。他们根据这些驱动因素构建了象限图，并基于此提出了四个逻辑假设。

从象限图中得出的四个假设可以表述如下：

7.4.3 方法：多假设生成器 ®

多假设生成器 ® 是一种技术，它帮助分析师创造出多种可能的解释来分析一个问题、活动或行为。虽然分析师通常可以通过集思广益来形成一系列假设，但使用多假设生成器 ® 可以更有信心地确保没有遗漏重要的替代观点或异常情况。分析师应利用这一工具来确保他们已经考虑了各种可能的假设。在某些情况下，当分析师拥有大量数据时，他们希望确保已经找到了与所有数据相符的合理解释。或者，当面对一个看似能够解释当前现象的假设时，分析师可能需要评估其有效性。这种方法有助于分析师将不同的假设按照可信度从高到低排序，重点关注那些位于列表顶端、被认为最值得深入研究的假设。

要使用这个方法：

1. 召集一个由不同背景成员组成的团队，共同定义研究的问题、活动或行为。通常，通过以下方式提问会很有帮助：

如何开发新的变体来挑战现有的主导假设，即...？有哪些可能的变异能够颠覆主导假设中的基本假设，即...？首先，我们需要明确主导假设中的关键要素：参与者、内容和原因。然后，为每个关键要素提出可能的替代方案。在审查这些替代方案时，应确保每个列表中的选项都是互斥的。通过这种方式，我们可以生成所有可能的变异组合，如图 7.4.3 所示。

图 7.4.3 展示了多假设生成器 ® 如何生成变异组合，该图表来源于 Globalytica, LLC, 2019。我们需要排除那些不合逻辑的变异组合。对于剩余的组合，我们通过检验每个要素的关键假设来评估其可信度。有些假设本身是可以通过实验验证的。我们采用 1 到 5 分的评分体系为每个变异组合打分，1 分代表低可信度，5 分代表高可信度。然后，我们将这些组合按照可信度从高到低重新排序。接下来，我们将这些变异组合转化为假设，并确保每个假设都满足良好的假设标准。最后，我们从列表的顶部选择那些最值得进一步研究的假设。

潜在的陷阱在于，这项技术的有效性取决于分析师能否提出一组全面的替代解释。如果团队合作存在问题，那么结果也可能存在偏差。虽然不能保证正确的假设一定会从这个过程中被识别出来，但这种方法大大增加了正确假设被包含在考虑范围内的可能性。

与其他技术的关系方面，这项技术可以与其他分析方法结合使用，以提高分析的全面性和准确性。

任何前瞻性分析过程的成果都可以被看作是一系列可能的假设。四象限假设生成法是形态分析法的一种具体应用，这在第 9 章中有详细介绍。替代未来分析使用类似的方法，通过四象限图来描绘四种可能的未来情景，而多场景生成法则通过这种方法来构建多组四种不同的未来情景。这两种技术同样在第 9 章中被详细阐述。

这项技术的起源假设的提出和验证是科学推理的核心部分。简单假设方法和四象限假设生成法在《分析工具和技术手册》第五版（Tysons, VA：Pherson Associates, LLC, 2019）以及 Pherson Associates 的培训资料中有所描述。而多假设生成器 ® 的详细描述则可以在第四版《分析工具和技术手册》（Reston, VA：Pherson Associates, LLC, 2015）中找到。



7.5 Diagnostic Reasoning

Diagnostic Reasoning is the application of hypothesis testing to a new development, a single new item of information or intelligence, or the reliability of a source. It differs from Analysis of Competing Hypotheses (ACH) in that it is used to evaluate a single item of relevant information or a single source; ACH deals with an entire range of hypotheses and multiple items of relevant information.

When to Use It

Analysts should use Diagnostic Reasoning if they find themselves making a snap intuitive judgment while assessing the meaning of a new development, the significance of a new report, or the reliability of a stream of reporting from a new source. Often, much of the information used to support one's lead hypothesis turns out to be consistent with alternative hypotheses as well. In such cases, the new information should not—and cannot—be used as evidence to support the prevailing view or lead hypothesis.

The technique also helps reduce the chances of being caught by surprise. It ensures that the analyst or decision maker will have given at least some consideration to alternative explanations. The technique is especially important to use when an analyst—or decision maker—is looking for evidence to confirm an existing mental model or policy position. It helps the analyst assess whether the same information is consistent with other reasonable conclusions or with alternative hypotheses.

Value Added

The value of Diagnostic Reasoning is that it helps analysts balance their natural tendency to interpret new information as consistent with their existing understanding of what is happening—that is, the analyst's mental model. The technique prompts analysts to ask themselves whether this same information is consistent with other reasonable conclusions or alternative hypotheses. It is a common experience to discover that much of the information supporting belief in the most likely conclusion is of limited value because that same information is consistent with alternative conclusions. One needs to evaluate new information in the context of all possible explanations of that information, not just in the context of a well-established mental model.

The Diagnostic Reasoning technique helps the analyst identify the information that is essential to support a hypothesis and avoid the mistake of focusing attention on one vivid scenario or explanation while ignoring other possibilities or alternative hypotheses (Vividness Bias). When evaluating evidence, analysts tend to assimilate new information into what they currently perceive. Diagnostic Reasoning protects them from the traps of seeking only the information that is consistent with the lead hypothesis (Confirmation Bias) and selecting the first answer that appears "good enough" (Satisficing).

Experience can handicap experts because they often hold tightly to timeworn models—and a fresh perspective can be helpful. Diagnostic Reasoning helps analysts avoid the intuitive trap of assuming the same dynamic is in play when something seems to accord with an analyst's past experiences (Projecting Past Experiences). It also helps analysts counter the pitfall of continuing to hold to an analytic judgment when confronted with a mounting list of evidence that contradicts the initial conclusion (Rejecting Evidence) and dismissing information at first glance without considering all possible alternatives (Ignoring Inconsistent Evidence).

The Method

Diagnostic Reasoning is a process that focuses on trying to refute alternative judgments rather than confirming what you already believe to be true. Here are the steps to follow:

When you receive a potentially significant item of information, make a mental note of what it seems to mean (i.e., an explanation of why something happened or what it portends for the future). Make a quick, intuitive judgment based on your current mental model. Define the focal question. For example, Diagnostic Reasoning brainstorming sessions often begin with questions like

Are there alternative explanations for the lead hypothesis (defined as . . .) that would also be consistent with the new information, new development, or new source of reporting? Is there a reason other than the lead hypothesis that . . .? Brainstorm, either alone or in a small group, the alternative judgments that another analyst with a different perspective might reasonably deem to have a chance of being accurate. Make a list of these alternatives. For each alternative, ask the following question: If this alternative were true or accurate, how likely is it that I would have seen, but possibly ignored, information that was consistent with this alternative explanation? Make a tentative judgment based on consideration of these alternatives. If the new information is equally likely with each of the alternatives, the information has no diagnostic value and can be ignored. If the information is clearly inconsistent with one or more alternatives, those alternatives might be ruled out. Following this mode of thinking for each of the alternatives, decide which alternatives need further attention and which can be dropped from consideration or put aside until new information surfaces. Proceed by seeking additional evidence to refute the remaining alternatives rather than to confirm them.

Potential Pitfalls

When new information is received, analysts need to validate that the new information is accurate and not deceptive or intentionally misleading. It is also possible that none of the key information turns out to be diagnostic, or that all relevant information will not come to light.

Relationship to Other Techniques

Diagnostic Reasoning is an integral part of two other techniques: Analysis of Competing Hypotheses and Indicators Validation and Evaluation ( chapter 9 ). It is presented here as a separate technique to show that its use is not limited to those two techniques. It is a fundamental form of critical reasoning that should be widely used in intelligence analysis.

Origins of This Technique

Diagnostic Reasoning has been the principal method for medical problem solving for many years. For information on the role of Diagnostic Reasoning in the medical world, see the following publications: Albert S. Elstein, "Thinking about Diagnostic Thinking: A Thirty-Year Perspective," Advances in Health Science Education, published online by Springer Science+Business Media, August 11, 2009; and Pat Croskerry, "A Universal Model of Diagnostic Reasoning," Academic Medicine 84, no. 8 (August 2009).

7.5 诊断推理诊断推理是一种将假设检验应用于新出现的情况、单一的新信息或情报，以及信息来源可靠性的方法。与竞争假设分析（ACH）不同，诊断推理专注于评估单个相关信息或单个来源，而 ACH 则涉及多个假设和多个信息项的综合分析。

何时使用当分析师在评估新事件的意义、新报告的价值或新信息来源的可信度时，如果发现自己正在做出快速直觉判断，就应该运用诊断推理。通常情况下，支持主导假设的信息往往也能与替代假设相吻合。因此，在这种情况下，新信息不应被视为支持主流观点或主导假设的证据。

诊断推理技术有助于降低被意外情况所困扰的风险。它确保分析师或决策者在决策过程中至少会考虑其他可能的解释。当分析师或决策者试图寻找证据以证实其现有的心理模型或政策立场时，使用这一技术尤为重要。它帮助分析师判断相同的信息是否与其他合理的结论或替代假设相一致。

增值

诊断推理的价值在于它帮助分析师平衡他们自然倾向于将新信息解释为与他们对正在发生的事情的现有理解一致的倾向 —— 即分析师的心智模型。该技术促使分析师自问，同样的信息是否与其他合理的结论或替代假设一致。发现支持最可能结论的大部分信息的价值有限是很常见的，因为这些信息与替代结论一致。人们需要在所有可能的解释信息的背景下评估新信息，而不仅仅是在一个已经建立的心智模型的背景下。

诊断推理技术帮助分析师识别支持假设的必要信息，并避免将注意力集中在一种生动的场景或解释上而忽视其他可能性或替代假设的错误（生动性偏差）。在评估证据时，分析师倾向于将新信息融入他们当前的感知中。诊断推理保护他们免受只寻求与主导假设一致的信息的陷阱（确认偏差）和选择第一个看似「足够好」的答案的陷阱（满足性）。

经验可能会阻碍专家，因为他们经常紧握着过时的模型 —— 而新鲜的视角可能会有所帮助。诊断推理帮助分析师避免直觉陷阱，即当某事似乎与分析师的过去经验相符时，假设相同的动态正在起作用（投射过去经验）。它还帮助分析师克服面对越来越多的证据与初始结论相矛盾时继续坚持分析判断的陷阱（拒绝证据），以及在初次审视时没有考虑所有可能的替代方案就驳回信息的陷阱（忽视不一致的证据）。

方法诊断推理是一种思维过程，它强调质疑而非确认已有的信念。以下是实施诊断推理的步骤：

当你遇到一个可能重要的信息时，先在脑海中形成一个初步的理解（即，对事件发生的原因或其对未来的影响进行解释）。基于你现有的认知框架，迅速做出一个直觉性的判断。明确你的核心问题。例如，在诊断推理的头脑风暴中，我们常常从以下问题开始：

对于主要假设（定义为...），是否存在其他解释，这些解释同样能够与新获得的信息、新出现的情况或新来源的报道相吻合？除了主要假设，是否还有其他可能的原因...？独自或与团队成员一起，集思广益，探讨其他分析师可能认为有合理性的不同观点的替代判断。将这些替代方案一一列出。对于每一个替代方案，思考以下问题：如果这个替代方案成立，我有多大可能已经接触到，但未予以重视的与该解释相符的信息？基于对这些替代方案的全面考量，做出一个初步的判断。如果新信息对所有替代方案的可能性相同，那么这个信息就没有诊断价值，可以不予考虑。如果信息明显与某些替代方案不符，那么这些方案可能需要被排除。对每个替代方案进行这样的分析后，决定哪些需要进一步探讨，哪些可以暂时搁置，等待新信息的揭示。接下来，重点寻找能够反驳剩余替代方案的证据，而不是试图证实它们。

潜在陷阱

当接收到新信息时，分析师必须确认这些信息的真实性，排除任何可能的欺骗或误导。同时，我们也要意识到，并非所有关键信息都具有诊断价值，有时甚至所有相关信息都无法完全揭示。

诊断推理与其他技术的联系诊断推理是竞争假设分析和指标验证与评估这两种技术的核心要素（详见第 9 章）。尽管如此，我们将其单独列出，以强调它在其他领域同样适用。诊断推理是一种基础的批判性思维方式，应在情报分析中得到广泛应用。

这项技术的历史渊源多年来，诊断推理一直是医学领域解决问题的主要方法。若想了解诊断推理在医学中的应用，可以参考以下文献：Albert S. Elstein 的《关于诊断思考的思考：三十年的视角》，发表于《健康科学教育进展》，由 Springer Science+Business Media 在线出版，2009 年 8 月 11 日；以及 Pat Croskerry 的《诊断推理的通用模型》，发表于《学术医学》第 84 卷第 8 期（2009 年 8 月）。



7.6 Analysis of Competing Hypotheses

ACH is an analytic process that identifies a complete set of alternative hypotheses, systematically evaluates data that are consistent or inconsistent with each hypothesis, and proceeds by rejecting hypotheses rather than trying to confirm what appears to be the most likely hypothesis. The process of rejecting rather than confirming hypotheses applies to intelligence analysis the scientific principles advocated by Karl Popper, one of the most influential philosophers of science of the twentieth century. 4

ACH starts with the identification of a set of mutually exclusive alternative explanations or outcomes called hypotheses. The analyst assesses the consistency or inconsistency of each item of relevant information with each hypothesis, and then selects the hypothesis that best fits the relevant information. The scientific principle behind this technique is to proceed by trying to refute as many reasonable hypotheses as possible rather than to confirm what initially appears to be the most likely hypothesis. The most likely hypothesis is then the one with the least amount of inconsistent information—not the one with an abundance of supporting relevant information.

When to Use It

ACH is appropriate for almost any analysis where there are alternative explanations for what has happened, is happening, or is likely to happen. Use it when the judgment or decision is so important that you cannot afford to be wrong or when you need a systematic approach to avoid being surprised by an unforeseen outcome. ACH is particularly appropriate when dealing with controversial issues and when analysts need to leave an audit trail to show what relevant information they considered and how they arrived at their analysis. If other analysts and decision makers disagree with the analysts' conclusions, an ACH matrix can help identify the precise area of disagreement. Subsequent discussion can then focus on the most important substantive differences.

ACH is most effective when there is a robust flow of data to absorb and evaluate. It is well suited for addressing questions about technical issues in the chemical, biological, radiological, and nuclear arenas, such as, "For which weapons' system is this part most likely being imported?" or, "Which type of missile system is Country X importing or developing?" The technique is useful for managing criminal investigations and determining which line of analysis is correct. ACH is particularly helpful when an analyst must deal with the potential for denial and deception, as it was initially developed for that purpose.

The technique can be used by a single analyst but is most effective with a small team that can challenge team members' evaluations of the relevant information. It structures and facilitates the exchange of information and ideas with colleagues in other offices or agencies.

An ACH analysis requires a modest commitment of time; it may take a day or more to build the ACH matrix. Once all the relevant information has been collected, it may take several hours to work through all the stages of the analytic process before writing up the conclusions. Usually a facilitator or a colleague previously schooled in the use of the technique helps guide analysts through the process, especially if it is the first time they have used the methodology.

Value Added

Analysts are commonly required to work with incomplete, ambiguous, anomalous, and sometimes deceptive data. In addition, strict time constraints and the need to "make a call" often conspire with natural human cognitive biases to cause inaccurate or incomplete judgments. If the analyst is already generally knowledgeable on the topic, a common procedure is to develop a favored hypothesis and then search for relevant information to confirm it. This is called Satisficing or going with the first answer that seems to be supported by the evidence.

Satisficing is efficient because it saves time and often works. However, Confirmation Bias, which impels an analyst to look only for information that is consistent with the favored or lead hypothesis or widely accepted school of thought, is often at work in the background, as the analyst has made no investment in protection against surprise. Satisficing allows analysts to accept data as true without assessing its credibility or questioning fundamental assumptions because it helps create a more coherent story (Evidence Acceptance Bias). If engaged in Satisficing, analysts often bypass the analysis of alternative explanations or outcomes, which should be fundamental to any complete analysis. As a result, Satisficing fails to distinguish that much of the relevant information seemingly supportive of the favored hypothesis is also consistent with one or more alternative hypotheses. It often fails to recognize the importance of what is missing (i.e., what should be observable if a given hypothesis is true but is not there).

ACH improves the analyst's chances of overcoming these challenges by requiring analysts to identify and then try to refute as many reasonable hypotheses as possible using the full range of data, assumptions, and gaps that are pertinent to the problem at hand. The method for analyzing competing hypotheses takes time and attention in the initial stages, but it pays big dividends in the end. When analysts are first exposed to ACH and say they find it useful, it is because the simple focus on identifying alternative hypotheses and how they might be disproved prompts analysts to think seriously about evidence, explanations, or outcomes in ways that had not previously occurred to them.

The ACH process requires the analyst to assemble the collected information and organize it in a useful way, so that it can be readily retrieved for use in the analysis. This is done by creating a matrix with relevant information down the left side and hypotheses across the top. Each item of relevant information is then evaluated as to whether it is consistent or inconsistent with each hypothesis. The results are then used to assess the evidentiary and logical support for and against each hypothesis. This can be done manually, but it is much easier and better to use an Excel spreadsheet or ACH software designed for this purpose. Various ACH software applications can be used to sort and analyze the data by type of source and date of information, as well as by degree of support for or against each hypothesis.

ACH helps analysts produce a better analytic product by

Maintaining a record of the relevant information and tracking how that information relates to each hypothesis. Capturing the analysts' key assumptions when the analyst is coding the data and recording what additional information is needed or what collection requirements are needed. Enabling analysts to present conclusions in a way that is organized and transparent as it documents how conclusions were reached. Providing a foundation for identifying indicators that can then be monitored and validated to determine the direction in which events are heading. Leaving a clear audit trail as to how the analysis was done, the conclusions reached, and how individual analysts may have differed in their assumptions or judgments.

ACH Software

ACH started as a manual method at the CIA in the mid-1980s. The first professionally developed and tested ACH software was created in 2005 by the P alo A lto R esearch C enter (PARC), with federal government funding and technical assistance from Richards J. Heuer Jr. and Randolph Pherson. Randolph Pherson managed its introduction into the U.S. Intelligence Community. The PARC version, though designed for use by an individual analyst, was commonly used by a co-located team of analysts. Members of such groups reported,

The technique helped them gain a better understanding of the differences of opinion with other analysts or between analytic offices. Review of the ACH matrix provided a systematic basis for identification and discussion of differences between participating analysts. Reference to the matrix helped depersonalize the argumentation when there were differences of opinion.

A collaborative version of ACH called Te@mACH ® was developed under the direction of Randolph Pherson for Globalytica, LLC, in 2010. It has most of the functions of the PARC ACH tool but allows analysts in different locations to work on the same problem simultaneously. They can propose hypotheses and enter data on the matrix from multiple locations, but they must agree to work from the same set of hypotheses and the same set of relevant information. The software allows them to chat electronically about one another's assessments and assumptions, to compare their analysis with that of their colleagues, and to learn what the group consensus was for the overall problem solution.

Other government agencies, research centers, and academic institutions have developed versions of ACH. One version called Structured Analysis of Competing Hypotheses, developed for instruction at Mercyhurst College, builds on ACH by requiring deeper analysis at some points.

The use of collaborative ACH tools ensures that all analysts are working from the same database of evidence, arguments, and assumptions, and that each member of the team has had an opportunity to express his or her view on how that information relates to the likelihood of each hypothesis. Such tools can be used both synchronously and asynchronously and include functions such as a survey method to enter data that protects against bias, the ability to record key assumptions and collection requirements, and a filtering function that allows analysts to see how each person rated the relevant information. 5

The Method

To retain five or seven hypotheses in working memory and note how each item of information fits into each hypothesis is beyond the capabilities of most analysts. It takes far greater mental agility than the common practice of seeking evidence to support a single hypothesis already believed to be the most likely answer. The following nine-step process is at the heart of ACH and can be done without software.

Identify all possible hypotheses that should be considered. Hypotheses should be mutually exclusive; that is, if one hypothesis is true, all others must be false. The list of hypotheses should include a deception hypothesis, if that is appropriate. For each hypothesis, develop a brief scenario or "story" that explains how it might be true. Analysts should strive to create as comprehensive list of hypotheses as possible. Make a list of significant relevant information , which means everything that would help analysts evaluate the hypotheses, including evidence, assumptions, and the absence of things one would expect to see if a hypothesis were true. It is important to include assumptions as well as factual evidence, because the matrix is intended to be an accurate reflection of the analyst's thinking about the topic. If the analyst's thinking is driven by assumptions rather than hard facts, this needs to become apparent so that the assumptions can be challenged. A classic example of absence of evidence is the Sherlock Holmes story of the dog barking in the night. The failure of the dog to bark was persuasive evidence that the guilty party was not an outsider but an insider whom the dog knew. Create a matrix and analyze the diagnosticity of the information. Create a matrix with all hypotheses across the top and all items of relevant information down the left side. See Figure 7.6a for an example. Analyze the "diagnosticity" of the evidence and arguments to identify which points are most influential in judging the relative likelihood of the hypotheses. Ask, "Is this input Consistent with the hypothesis, is it Inconsistent with the hypothesis, or is it Not Applicable or not relevant?" This can be done by either filling in each cell of the matrix row-by-row or by randomly selecting cells in the matrix for analysts to rate. If it is Consistent, put a "C" in the appropriate matrix box; if it is Inconsistent, put an "I"; if it is Not Applicable to that hypothesis, put an "NA." If a specific item of evidence, argument, or assumption is particularly compelling, put two "C's" in the box; if it strongly undercuts the hypothesis, put two "I's."

When you are asking if an input is Consistent or Inconsistent with a specific hypothesis, a common response is, "It all depends on . . ." That means the rating for the hypothesis is likely based on an assumption. You should record all such assumptions when filling out the matrix. After completing the matrix, look for any pattern in those assumptions, such as the same assumption being made when ranking multiple items of information. After the relevant information has been sorted for diagnosticity, note how many of the highly diagnostic Inconsistency ratings are based on assumptions. Consider how much confidence you should have in those assumptions and then adjust the confidence in the ACH Inconsistency Scores accordingly.

Review where analysts differ in their assessments and decide if the ratings need to be adjusted (see Figure 7.6b ). Often, differences in how analysts rate an item of information can be traced back to different assumptions about the hypotheses when doing the ratings. Refine the matrix by reconsidering the hypotheses. Does it make sense to combine two hypotheses into one, or to add a new hypothesis that was not considered at the start? If a new hypothesis is added, go back and evaluate all the relevant information for this hypothesis. Additional relevant information can be added at any time.

Figure 7.6A Creating an ACH Matrix

Description Figure 7.6B Evaluating Levels of Disagreement in ACH Draw tentative conclusions about the relative likelihood of each hypothesis, basing your conclusions on an analysis regarding the diagnosticity of each item of relevant information. Proceed by trying to refute hypotheses rather than confirm them. Add up the number of Inconsistency ratings for each hypothesis and note the Inconsistency Score for each hypothesis. As a first cut, examine the total number of "I" and "II" ratings for each hypothesis. The hypothesis with the most Inconsistent ratings is the least likely to be true and the hypothesis or hypotheses with the lowest Inconsistency Score(s) is tentatively the most likely hypothesis. The Inconsistency Scores are broad generalizations, not precise calculations. ACH is a tool designed to help the analyst make a judgment, but not to actually make the judgment for the analyst. This process is likely to produce correct estimates more frequently than less systematic or rigorous approaches, but the scoring system does not eliminate the need for analysts to use their own good judgment. The "Potential Pitfalls" section below identifies several occasions when analysts need to override the Inconsistency Scores. Analyze the sensitivity of your tentative conclusion to see how dependent it is on a few critical items of information. For example, look for evidence that has a "C" for the lead hypothesis but an "I" for all other hypotheses. Evaluate the importance and credibility of those reports, arguments, or assumptions that garnered a "C." Consider the consequences for the analysis if that item of relevant information were wrong or misleading or subject to a different interpretation. If all the evidence earns a "C" for each hypothesis, then the evidence is not diagnostic. If a different interpretation of any of the data would cause a change in the overall conclusion, go back and double-check the accuracy of your interpretation. Report the conclusions. Consider the relative likelihood of all the hypotheses, not just the most likely one. State which items of relevant information were the most diagnostic, and how compelling a case they make in identifying the most likely hypothesis. Identify indicators or milestones for future observation. Generate two lists: one focusing on future events or what additional research might uncover that would substantiate the analytic judgment, and a second that would suggest the analytic judgment is less likely to be correct or that the situation has changed. Validate the indicators and monitor both lists on a regular basis, remaining alert to whether new information strengthens or weakens your case.

Potential Pitfalls

A word of caution: ACH only works when all participating analysts approach an issue with a relatively open mind. An analyst already committed to a "right answer" will often find a way to interpret relevant information to align with or make consistent with the preexisting belief. In other words, as an antidote to Confirmation Bias, ACH is like a flu shot. Getting the flu shot will usually keep you from getting the flu, but it won't make you well if you already have the flu.

The Inconsistency Scores generated for each hypothesis are not the product of a magic formula that tells you which hypothesis to believe. The ACH software takes you through a systematic analytic process, and the Inconsistency Score calculation that emerges is only as accurate as your selection and evaluation of the relevant information.

Because it is more difficult to refute hypotheses than to find information that confirms a favored hypothesis, the generation and testing of alternative hypotheses will often increase rather than reduce the analyst's level of uncertainty. Such uncertainty is frustrating, but it is usually an accurate reflection of the true situation. The ACH procedure has the offsetting advantage of focusing attention on the few items of critical information that cause the uncertainty or, if they were available, would alleviate it. ACH can guide future collection, research, and analysis to resolve the uncertainty and produce a more accurate judgment.

Analysts should be aware of five circumstances that can cause a divergence between an analyst's own beliefs and the Inconsistency Scores. In the first two circumstances described in the following list, the Inconsistency Scores seem to be wrong when they are correct. In the next three circumstances, the Inconsistency Scores may seem correct when they are wrong. Analysts need to recognize these circumstances, understand the problem, and adjust accordingly.

Assumptions or logical deductions omitted. If the scores in the matrix do not support what you believe is the most likely hypothesis, the matrix may be incomplete. Your thinking may be influenced by assumptions or logical deductions not included in the list of relevant information or arguments. If so, they should be added so the matrix fully reflects everything that influences your judgment on this issue. It is important for all analysts to recognize the role that unstated or unquestioned (and sometimes unrecognized) assumptions play in their analysis. In political or military analysis, for example, conclusions may be driven by assumptions about another country's capabilities or intentions. A principal goal of the ACH process is to identify those factors that drive the analyst's thinking on an issue so that these factors can be questioned and, if appropriate, changed. Insufficient attention to less likely hypotheses. If you think the scoring gives undue credibility to one or more of the less likely hypotheses, it may be because you have not assembled the relevant information needed to refute them. You may have devoted insufficient attention to obtaining such relevant information, or the relevant information may simply not be there. If you cannot find evidence to refute a hypothesis, it may be necessary to adjust your thinking and recognize that the uncertainty is greater than you had originally thought. Definitive relevant information. There are occasions when intelligence collectors obtain information from a trusted and well-placed inside source. The ACH analysis can label the information as having high credibility, but this is probably not enough to reflect the conclusiveness of such relevant information and the impact it should have on an analyst's thinking. In other words, in some circumstances, one or two highly authoritative reports from a trusted source in a position to know may support one hypothesis so strongly that they refute all other hypotheses regardless of what other less reliable or less definitive relevant information may show. Unbalanced set of evidence. Evidence and arguments must be representative of the entire problem. If there is considerable evidence on a related but peripheral issue and comparatively few items of evidence on the core issue, the Inconsistency Score may be misleading. Diminishing returns. As evidence accumulates, each new item of Inconsistent relevant information or argument has less impact on the Inconsistency Scores than does the earlier relevant information. For example, the impact of any single item is less when there are fifty items than when there are only ten items. To understand this, consider what happens when you calculate the average of fifty numbers. Each number has equal weight; adding a fifty-first number will have less impact on the average than if you start with only ten numbers and add one more. Stated differently, the accumulation of relevant information over time slows down the rate at which the Inconsistency Score changes in response to new relevant information. Therefore, the numbers may not reflect the actual amount of change in the situation you are analyzing. When you are evaluating change over time, it is desirable to delete the older relevant information periodically, or to partition the relevant information and analyze the older and newer relevant information separately.

Some other caveats when using ACH include the following:

The possibility that none of the relevant information identified is diagnostic. Not all relevant information is identified. Some of the relevant information is inaccurate, deceptive, or misleading. The ratings are subjective and therefore subject to human error. When the analysis is performed by a group, the outcome can be biased by Groupthink or the absence of healthy group dynamics.

Relationship to Other Techniques

ACH is often used in conjunction with other techniques. For example, Cluster Brainstorming, Nominal Group Technique, Multiple Hypothesis Generation, or the Delphi Method can identify hypotheses or relevant information for inclusion in the ACH analysis. They can also help analysts evaluate the significance of relevant information. Deception Detection may identify an opponent's motive, opportunity, or means to conduct deception or to identify past deception practices; information about these factors should be included in the list of ACH-relevant information. The Diagnostic Reasoning technique is incorporated within the ACH method. The final step in the ACH method identifies Indicators for monitoring future developments.

The ACH matrix is intended to reflect all relevant information and arguments that affect one's thinking about a designated set of hypotheses. That means it should also include assumptions identified by a Key Assumptions Check, discussed earlier in this chapter. Conversely, rating the consistency of an item of relevant information with a specific hypothesis is often based on an assumption. When rating the consistency of relevant information in an ACH matrix, the analyst should ask, "If this hypothesis is true, would I see this item of relevant information?" A common thought in response to this question is, "It all depends on. . . ." This means that, however the consistency of that item of relevant information is rated, that rating is likely based on an assumption—whatever assumption the rating "depends on." These assumptions should be recorded in the matrix and then considered in the context of a Key Assumptions Check.

The Delphi Method (chapter 8) can double-check the conclusions of an ACH analysis. In this process, outside experts are asked separately to assess the probability of the same set of hypotheses and to explain the rationale for their conclusions. If the two different groups of analysts using different methods arrive at the same conclusion, confidence in the conclusion increases. If they disagree, their lack of agreement is also useful, as one can then seek to understand the rationale for the different judgments.

ACH and Argument Mapping (described later in this chapter) are both used on the same types of complex analytic problems. They are both systematic methods for organizing relevant information, but they work in fundamentally different ways and are best used at different stages in the analytic process. ACH is used during an early stage to analyze a range of hypotheses to determine which is most consistent with the broad body of relevant information. At a later stage, when the focus is on developing, evaluating, or presenting the case for a specific conclusion, Argument Mapping is the appropriate method. Each method has strengths and weaknesses, and the optimal solution is to use both.

Origins of This Technique

Richards Heuer originally developed the ACH technique at the CIA in the mid-1980s as one part of a methodology for analyzing the presence or absence of Soviet deception. It was described publicly in his book, Psychology of Intelligence Analysis , first published in 1999; 6 Heuer and Randolph Pherson helped the Palo Alto Research Center gain funding from the federal government during 2004 and 2005 to produce the first professionally developed ACH software. Randolph Pherson managed its introduction into the U.S. Intelligence Community. Globalytica, LLC, with Pherson's assistance, subsequently developed a collaborative version of the software called Te@mACH ® . An example of an Analysis of Competing Hypotheses can be found at https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/books-and-monographs/psychology-of-intelligence-analysis/art11.html.

7.6 竞争性假设分析 (ACH)

ACH 是一种分析方法，它首先列出所有可能的假设，然后系统地检查每一条相关数据与这些假设的一致性或矛盾性。这种方法遵循卡尔·波普尔（Karl Popper）的科学哲学，他是二十世纪最有影响力的科学哲学家之一，强调通过反驳假设来推进科学认识。4

在 ACH 中，分析员首先确定一组互斥的假设，即对事件的不同解释或预测。然后，分析员评估每一项数据与每个假设的匹配程度，最终选择与数据最吻合的假设。这种方法的核心在于，不是寻找证据来支持最可能的假设，而是通过排除不合理的假设来找到最可能的答案。最可能的假设是那些与数据矛盾最少的假设，而不是拥有最多支持证据的假设。

何时使用 ACH

ACH 适用于几乎所有需要对事件的不同解释进行分析的场合。当你面临重要的判断或决策，不能容忍错误时，或者需要一个系统的方法来避免意外结果时，ACH 是一个很好的选择。特别是在处理争议性问题时，以及当分析员需要记录他们考虑了哪些信息以及如何得出结论时，ACH 尤为适用。如果其他分析员或决策者对结论有异议，ACH 可以帮助明确分歧点，使后续讨论能够集中在最关键的实质性差异上。

竞争假设分析（ACH）是一种在数据丰富且需要深入评估时特别有效的分析方法。它擅长解决涉及化学、生物、放射性和核技术的问题，例如帮助我们了解某个部件最可能用于哪种武器系统，或者揭示某个国家正在进口或开发哪种类型的导弹系统。这种方法对于指导刑事调查和确定分析方向至关重要，尤其是在面对可能的否认和欺骗时，因为 ACH 最初就是为了应对这些挑战而设计的。

虽然单个分析师可以使用 ACH，但当一个小团队共同工作时，它的效果最佳。团队成员可以相互挑战，对收集到的信息进行深入评估，这有助于促进与其他部门或机构同事之间的信息交流和思想碰撞。

进行 ACH 分析需要一定的时间投入，构建分析矩阵可能需要一天或更长时间。一旦所有相关信息收集完毕，分析师可能需要花费数小时来完成整个分析过程，并最终得出结论。通常，一个经验丰富的指导者或熟悉该技术的同事会帮助新手分析师顺利完成这一过程。

在实际操作中，分析师往往面临着处理不完整、模糊、异常甚至欺骗性数据的情况。时间压力和人类固有的认知偏见可能导致分析师做出不准确或不全面的判断。如果分析师对某个主题已有初步了解，他们可能会倾向于发展一个偏好的假设，并寻找证据来支持它，这种做法被称为「满足性」，即接受第一个看似合理的答案。在这种情况下，ACH 分析方法的价值在于它能够帮助分析师更全面、客观地评估所有可能的假设，从而做出更准确的判断。

满足性是一种高效的行为方式，它通过节省时间来提高效率，但这种做法往往伴随着确认偏误的问题。确认偏误是指分析师倾向于只关注那些支持他们偏好的假设或普遍接受的观点的信息，而忽视了可能出现的意外情况。这种倾向导致分析师在接受信息时，往往不会对其真实性进行深入评估，也不会质疑自己的基本假设，从而形成了一个看似连贯但可能存在偏差的故事（这种倾向被称为证据接受偏误）。满足性的做法使得分析师忽略了探索其他可能的解释或结果，而这些探索本应是完整分析不可或缺的一部分。结果是，满足性未能意识到，那些看似支持他们偏好的假设的信息，实际上也可能与其他合理的假设相符。更重要的是，满足性往往忽视了那些本应出现但实际缺失的信息的重要性。

竞争性假设分析（ACH）是一种方法，它要求分析师不仅要识别出所有可能的合理假设，还要尝试通过全面分析相关数据、假设和信息缺口来反驳这些假设。虽然 ACH 在开始时需要投入较多的时间和精力，但最终它能带来显著的好处。当分析师初次接触 ACH 并发现其价值时，这是因为 ACH 鼓励他们去思考如何通过证据来反驳不同的假设，这种思考方式能够激发他们以全新的视角审视问题，从而更深入地理解证据、解释和可能的结果。

ACH 过程要求分析师将收集的信息进行整理，并以一种有用的方式组织起来，以便在分析中可以方便地检索和使用。这通常通过创建一个矩阵来实现，矩阵的左侧列出相关信息，顶部列出各种假设。然后，对每一项相关信息进行评估，判断它与每个假设是一致还是不一致。结果随后被用来评估每个假设的证据和逻辑支持程度。虽然可以手动完成，但使用 Excel 电子表格或专为这一目的设计的 ACH 软件会更加简便和高效。各种 ACH 软件应用程序可以用来按信息来源类型、信息日期以及对每个假设的支持或反对程度来排序和分析数据。

ACH 帮助分析师通过以下方式生产出更好的分析产品：

- 保持相关信息的记录，并跟踪这些信息如何与每个假设相关联。
- 在分析师编码数据时捕捉分析师的关键假设，并记录需要额外信息或收集需求的内容。
- 使分析师能够以一种有组织和透明的方式呈现结论，因为它记录了结论是如何得出的。
- 提供一个基础，用于识别可以监控和验证的指标，以确定事件的发展方向。
- 留下清晰的审计轨迹，说明分析是如何进行的，结论是如何得出的，以及个别分析师在他们的假设或判断上可能存在的差异。

ACH 软件

ACH，即分析性竞争假设，最初在 20 世纪 80 年代中期作为中央情报局（CIA）内部的一种手动分析技术被采用。首个专业开发并经过测试的 ACH 软件是在 2005 年由帕洛阿尔托研究中心（PARC）开发的，该项目得到了美国联邦政府的资金支持，并由理查兹·J·霍尔（Richards J. Heuer Jr.）和兰多夫·费尔森（Randolph Pherson）提供技术指导。兰多夫·费尔森负责将这一技术引入美国情报界。尽管 PARC 版本的 ACH 是为单个分析师设计的，但实际上它经常被同一地点的分析师团队所采用。这些团队成员表示，

ACH 技术帮助他们更清晰地认识到与其他分析师或不同分析部门之间的意见差异。通过对 ACH 矩阵的审查，他们能够系统地识别和讨论这些差异。在意见分歧时，参考矩阵有助于将讨论从个人层面提升到更为客观的分析层面。

2010 年，兰多夫·费尔森为 Globalytica, LLC 开发了一个名为 Te@mACH® 的协作版 ACH。这个版本保留了 PARC ACH 工具的大部分功能，但特别允许不同地点的分析师实时协作处理同一问题。他们可以共同提出假设，并在共享的矩阵上输入数据，前提是他们必须基于相同的假设框架和共享的信息资源进行工作。该软件还支持他们通过电子交流方式讨论各自的评估和假设，比较个人分析与团队分析，并了解团队对于问题解决方案的共识。

此外，其他政府机构、研究机构和学术机构也开发了自己的 ACH 版本。例如，梅希亚堡学院开发了一个名为结构化竞争假设分析的版本，它在 ACH 的基础上增加了对某些分析环节的深入要求。

通过使用协作式分析判断（ACH）工具，所有分析师可以共享同一个包含证据、论点和假设的数据库，确保团队中的每位成员都有机会表达他们对信息与各个假设之间关联性的看法。这些工具支持同步和异步工作模式，并提供调查方法来输入数据以减少偏见，记录关键假设和收集需求，以及过滤功能，使分析师能够查看每个人对相关信息的评估。

方法在记忆中同时保留五个或七个假设，并分析每条信息如何与这些假设相匹配，这对大多数分析师来说是一项挑战。这要求分析师具备比仅仅寻找证据支持一个已认定的最可能假设更为灵活的思维方式。以下是 ACH 的核心九步流程，即使没有软件支持，也可以手动执行。

未找到意译内容

在询问某一信息是否与特定假设一致或不一致时，一个常见的回答是：「这取决于……」这意味着对假设的评价很可能基于某个假设。在填写矩阵时，应当记录下所有这样的假设。完成矩阵后，寻找这些假设中的任何模式，例如在评估多个信息项时是否重复使用了相同的假设。在相关信息已按诊断性排序后，注意有多少高度诊断性的不一致评级是基于假设的。考虑对这些假设的信心程度，然后相应地调整 ACH 不一致分数的信心。

审查分析人员在评估上的不同意见，并决定是否需要调整评级（参见图 7.6b）。通常，分析人员对信息项评级的差异可以追溯到他们在评级时对假设的不同假设。通过重新考虑假设来优化矩阵。将两个假设合并为一个，或者添加一个最初未考虑的新假设是否有意义？如果添加了新假设，需要回溯并重新评估所有与此新假设相关的信息。可以在任何时候添加额外的相关信息。

图 7.6A 创建 ACH 矩阵

描述图 7.6B：评估 ACH（假设冲突分析）中各假设的不一致性水平。基于对每项相关信息的诊断性分析，初步判断各假设的可能性。采用反驳而非证实假设的方法。计算每个假设的不一致性评分，即不一致性评级的总数。首先，统计每个假设的「I」和「II」评级的总数。不一致性评级最多的假设最不可能成立，而不一致性评分最低的假设或假设群则初步被认为是最可能的。不一致性评分是粗略的估计，不是精确的计算。ACH 是一个辅助分析师做出判断的工具，而非代替分析师的判断。这一过程可能比其他非系统性或不严格的方法更频繁地得出正确估计，但不一致性评分并不免除分析师运用自身判断的必要。下文的「潜在陷阱」部分指出了在某些情况下分析师需要忽略不一致性评分。分析你的初步结论对关键信息的依赖程度，以评估其敏感性。例如，寻找对主要假设有「C」评级但对其他所有假设有「I」评级的证据。评估那些获得「C」评级的报告、论点或假设的重要性和可信度。考虑如果相关信息是错误的、误导性的或有不同解释，对分析的潜在影响。如果所有证据对每个假设都获得「C」评级，则表明证据不具备诊断性。如果对数据的另一种解释会改变整体结论，应重新检查你的解释的准确性。报告结论时，考虑所有假设的相对可能性，而不仅仅是可能性最大的一个。指出哪些相关信息最具诊断性，并说明它们如何支持最可能的假设。确定未来观察的指标或里程碑。创建两个列表：一个关注未来事件或额外研究可能揭示的内容，以证实分析判断；另一个则关注可能表明分析判断不准确或情况已改变的事件。验证这些指标，并定期监控这两个列表，以保持对新信息是否加强或削弱你的案例的警觉。

潜在的陷阱提醒一句：ACH（分析层次处理）只有在所有参与分析的分析师都以相对开放的心态对待问题时才有效。如果分析师已经对某个「正确答案」有了坚定的信念，他们往往会找到一种方法来解释相关信息，使其与先前的信念相符。换句话说，ACH 作为对抗确认偏误的工具，其作用类似于流感疫苗。流感疫苗通常能预防流感，但如果你已经感染了流感，它并不能治愈你。

为每个假设生成的矛盾分数并不是一个神奇的公式，它不会直接告诉你应该相信哪个假设。ACH 软件通过一个系统的分析过程来帮助你，而矛盾分数的计算准确性完全取决于你选择和评估相关信息的能力。

由于反驳假设比找到支持假设的信息更为困难，因此生成和测试替代假设的过程可能会增加分析师的不确定性，而不是减少。这种不确定性虽然令人沮丧，但它通常是对实际情况的真实反映。ACH 程序的一个优势在于，它能够帮助分析师集中注意力于那些导致不确定性的关键信息，或者如果这些信息可用，它们能够减少这种不确定性。ACH 可以指导未来的信息收集、研究和分析工作，以解决不确定性问题，并得出更准确的判断。

分析师应该意识到可能导致他们自己的信念与矛盾分数之间出现分歧的五种情况。在前两种情况下，矛盾分数看似错误，但实际上是正确的。而在接下来的三种情况下，矛盾分数可能看似正确，但实际上是错误的。分析师需要识别这些情况，理解其中的问题，并做出相应的调整。

假设或逻辑推断可能未被考虑。如果矩阵中的分数与你的最可能假设不符，矩阵可能缺少关键信息。你的思考可能受到未在列表中明确提出的假设或逻辑推断的影响。因此，应将这些因素纳入矩阵，以全面反映影响你判断的所有要素。在政治或军事分析中，分析师的结论往往基于对其他国家能力或意图的假设。ACH 过程旨在揭示影响分析师思考的因素，以便这些因素可以被质疑和调整。对不太可能的假设关注不足。如果你认为某个不太可能的假设被过分重视，可能是因为缺乏反驳它们的相关信息。你可能未充分搜集这些信息，或者这些信息根本不存在。如果无法找到反驳假设的证据，你可能需要重新评估不确定性。决定性的相关信息。有时，情报收集者会从可靠的内部来源获得高可信度信息。尽管 ACH 分析可以标记这些信息为高可信度，但这可能不足以体现这些信息对分析师思考的决定性影响。在某些情况下，一个或两个来自可信来源的权威报告可能强烈支持一个假设，以至于它们否定了所有其他假设，无论其他信息如何。证据集不平衡。证据和论点必须全面代表问题。如果在一个边缘问题上证据过多，而在核心问题上证据不足，不一致分数可能会误导分析。回报递减。随着证据的积累，每条新证据对不一致分数的影响逐渐减小。例如，当有五十项证据时，新增一项对平均值的影响小于只有十项时。这意味着，随着时间的推移，新证据对不一致分数的影响减弱。因此，在评估随时间的变化时，定期删除旧信息或分别分析新旧信息是有益的。

在使用 ACH（分析性思维与推理）时，需要注意以下几点：

- 并非所有被发现的信息都具有诊断价值，即能够明确指向某个结论。
- 我们可能遗漏了一些关键的相关信息。
- 有些信息可能是不准确、带有欺骗性或误导性的。
- 由于评级过程依赖于个人判断，因此可能存在人为误差。
- 如果分析工作由团队完成，可能会受到群体思维的影响，或者因为团队内部缺乏良好的沟通和协作而导致偏差。

ACH 常常与其他分析技术结合使用，例如：

- 集群头脑风暴、名义小组技术、多假设生成或德尔菲方法等，这些方法可以帮助我们提出假设或收集相关信息，并评估这些信息的重要性。
- 欺骗检测技术可以帮助我们了解对手可能的欺骗动机、机会和手段，以及他们过去的欺骗行为，这些信息对于 ACH 分析至关重要。
- 诊断推理技术是 ACH 方法的一部分，它帮助我们进行逻辑推理。
- ACH 方法的最后一步是确定指标，这些指标将用于监测和预测未来的发展趋势。

未找到意译内容

ACH（分析竞争假设）和论证映射是两种用于解决复杂分析问题的方法。它们都旨在系统化地组织相关信息，但它们的工作原理截然不同，并且适用于分析过程的不同阶段。ACH 通常用于分析过程的早期阶段，通过对一系列假设进行分析，来确定哪个假设与大量相关信息最为吻合。而当分析进入后期阶段，重点转向构建、评估或展示对特定结论的支持时，论证映射则成为更合适的方法。每种方法都有其独特的优势和局限性，最佳实践是结合使用这两种方法。

这项技术的起源可以追溯到 Richards Heuer 在 1980 年代中期为中央情报局（CIA）开发 ACH 技术的时候，当时它是作为分析苏联是否进行欺骗的方法论的一部分。Heuer 在他的著作《情报分析心理学》中首次公开了这一技术，该书于 1999 年首次出版。Heuer 与 Randolph Pherson 合作，帮助帕洛阿尔托研究中心在 2004 年和 2005 年获得了联邦政府的资金支持，用于开发首个专业级的 ACH 软件。Pherson 还负责将这一技术引入美国情报界。随后，在 Pherson 的协助下，Globalytica, LLC 开发了一个名为 Te@mACH® 的协作版软件。如果您想查看分析竞争假设的一个实例，可以访问中央情报局的官方网站：https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/books-and-monographs/psychology-of-intelligence-analysis/art11.html






7.7 Inconsistencies Finder™

The Inconsistencies Finder™ is a simpler version of Analysis of Competing Hypotheses that focuses attention on relevant information that is inconsistent with a hypothesis, helping to disconfirm its validity.

When to Use It

The Inconsistencies Finder™ can be used whenever a set of alternative hypotheses exists, or has recently been identified, and analysts need to do the following:

Carefully weigh the credibility of multiple explanations, or alternative hypotheses, explaining what has happened, is happening, or is likely to happen. Evaluate the validity of a large amount of data as it relates to each hypothesis. Challenge their current interpretation of the evidence (or, alternatively, the interpretation of others). Create an audit trail.

Value Added

The process of systematically reviewing the relevant information and identifying which information or evidence is inconsistent with each hypothesis helps analysts do the following:

Identify the most diagnostic information. Focus on the disconfirming evidence. Dismiss those hypotheses with compelling inconsistent information. Flag areas of agreement and disagreement. Highlight the potential for disinformation or deception.

Instead of building a case to justify a preferred solution or answer, the Inconsistencies Finder™ helps analysts easily dismiss those hypotheses with compelling inconsistent information and focus attention on those with the least disconfirming information. An analytic case can then be built that supports this most likely hypothesis—or hypotheses.

The technique is not an answer generator. It should be viewed as a thinking tool that helps you frame a problem more efficiently. Unlike ACH, the technique does not help analysts identify the most diagnostic information for making their case.

The Inconsistencies Finder™ aids the production of high-quality analysis in much the same way ACH mitigates cognitive biases and intuitive traps by helping analysts do the following:

Avoid leaping to conclusions. Move beyond "first impressions." Challenge preconceived ideas. Uncover unknowns and uncertainties.

The Method

Create a matrix with all the hypotheses under consideration listed in separate columns along the top of the matrix. Make a list of all the relevant information (including significant evidence, arguments, assumptions, and the absence of things) that would be helpful in evaluating the given set of hypotheses. Put each piece of information in a separate row down the left side of the matrix. Working in small teams, analyze each item for consistency/inconsistency against the given hypotheses. Review each piece of information against each hypothesis. Analysts can move across the matrix row by row to evaluate each hypothesis against all the relevant information moving from column to column.

Place an "I" in the box that rates each item against each hypothesis if you would not expect to see that item of information if the hypothesis were true. Place a "II" in the box if the presence of the information makes a compelling case that the hypothesis cannot be true. For example, if a suspect had an unassailable alibi proving he or she was at a different location at the time a crime was committed, then he or she could not be the perpetrator. Add up all the "I's" (Inconsistent ratings) in each hypothesis column. Assign one point to each "I" and two points to each "II." Rank order the credibility of the hypotheses based on the total number of points or "I's" that each hypothesis receives. The higher the score, the less likely the hypothesis. Assess if the "I's" noted in each column make a compelling case to dismiss that hypothesis. Work your way through the "I's" beginning with the hypothesis with the most "I's" to the hypothesis with the fewest or no "I's." Identify the hypothesis(es) with the least Inconsistent information and make a case for that hypothesis(es) being true.

7.8 Deception Detection

Deception is an action intended by an adversary to influence the perceptions, decisions, or actions of another to the advantage of the deceiver. Deception Detection uses a set of checklists to help analysts determine when to look for deception, discover whether deception actually is present, and figure out what to do to avoid being deceived. As Richards J. Heuer Jr. has argued, "The accurate perception of deception in counterintelligence analysis is extraordinarily difficult. If deception is done well, the analyst should not expect to see any evidence of it. If, on the other hand, deception is expected, the analyst often will find evidence of deception even when it is not there." 7

When to Use It

Analysts should be concerned about the possibility of deception when the following occurs:

The analysis hinges on a single critical piece of information or reporting. Key information is received at a critical time—that is, when either the recipient or the potential deceiver has a great deal to gain or to lose. Accepting new information would cause the recipient to expend or divert significant resources. Accepting new information would require the analyst to alter a key assumption or key judgment. The potential deceiver may have a feedback channel that illuminates whether and how the deception information is being processed and to what effect. Information is received from a source whose bona fides are questionable. The potential deceiver has a history of conducting deception.

Value Added

Most intelligence analysts know not to assume that everything that arrives in their inbox is valid, but few know how to factor such concerns effectively into their daily work practices. Considering the deception hypothesis puts a major cognitive burden on the analyst. If an analyst accepts the possibility that some of the information received may be deceptive, then all evidence is open to question and no valid inferences can be drawn from the reporting. This fundamental dilemma can paralyze analysis unless the analyst uses practical tools to determine when it is appropriate to worry about deception, how best to detect deception in the reporting, and what to do in the future to guard against being deceived.

It is very hard to deal with deception when you are really just trying to get a sense of what is going on, and there is so much noise in the system, so much overload, and so much ambiguity. When you layer deception schemes on top of that, it erodes your ability to act.

—Robert Jervis, "Signaling and Perception in the Information Age," in The Information Revolution and National Security (August 2000)

The measure of a good deception operation is how well it exploits the cognitive biases of its target audience. The deceiver's strategy usually is to provide some intelligence or information of value to the person being deceived in the hope that he or she will conclude the "take" is good enough and should be disseminated. As additional information is collected, the Satisficing bias is reinforced and the recipient's confidence in the information or the source usually grows, further blinding the recipient to the possibility that he or she is falling prey to deception. The deceiver knows that the information being provided is highly valued, although over time some people will begin to question the bona fides of the source. Often, this puts the person who developed the source or acquired the information on the defensive, and the natural reaction is to reject any and all criticism. This cycle is usually broken only by applying structured techniques such as Deception Detection to force a critical examination of the true quality of the information and the potential for deception.

Deception Detection is a useful tool analysts can employ to avoid cognitive biases and heuristics, such as seeking only the information that is consistent with the lead hypothesis (Confirmation Bias), accepting data as true without assessing its credibility because it helps "make the case" (Evidence Acceptance Bias), and judging the frequency of an event by the ease with which instances come to mind (Availability Heuristic). It also safeguards an analyst against several classic mental mistakes, including giving too much weight to first impressions or initial data that appears important at the time (Relying on First Impressions), assuming the same dynamic is in play when something appears to be in accord with past experiences (Projecting Past Experiences), and accepting or rejecting everything someone says because the analyst strongly likes or dislikes the person (Judging by Emotion).

The Method

Analysts should routinely consider the possibility that opponents or competitors are attempting to mislead them or hide important information. The possibility of deception cannot be rejected simply because there is no evidence of it; if the deception is well done, one should not expect to see evidence of it. Some circumstances in which deception is most likely to occur are listed in the "When to Use It" section. When such circumstances occur, the analyst, or preferably a small group of analysts, should assess the situation using four checklists that are commonly referred to by their acronyms: MOM, POP, MOSES, and EVE (see box on pp. 173–174).

Analysts have also found the following "rules of the road" helpful in anticipating the possibility of deception and dealing with it: 8

Avoid overreliance on a single source of information. Seek and heed the opinions of those closest to the reporting. Be suspicious of human sources or human subsources who have not been seen or when it is unclear how or from whom they obtained the information. Do not rely exclusively on what someone says (verbal intelligence); always look for material evidence (documents, pictures, an address, a phone number, or some other form of concrete, verifiable information). Be suspicious of information that plays strongly to your own known biases and preferences. Look for a pattern of a source's reporting that initially appears to be correct but later and repeatedly turns out to be wrong, with the source invariably offering seemingly plausible, albeit weak, explanations to justify or substantiate the reporting. At the onset of a project, generate and evaluate a full set of plausible hypotheses, including a deception hypothesis, if appropriate. Know the limitations as well as the capabilities of the potential deceiver.

Relationship to Other Techniques

Analysts can combine Deception Detection with Analysis of Competing Hypotheses to assess the possibility of deception. The analyst explicitly includes deception as one of the hypotheses to be analyzed, and information identified through the MOM, POP, MOSES, and EVE checklists is included as evidence in the ACH analysis.

Origins of This Technique

Deception—and efforts to detect it—has always been an integral part of international relations. An excellent book on this subject is Michael Bennett and Edward Waltz, Counterdeception Principles and Applications for National Security (Boston: Artech House, 2007). The description of Deception Detection in this book was previously published in Randolph H. Pherson, Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019). A concrete example of Deception Detection at work can be found at https://www.apa.org/monitor/2016/03/deception .

Deception Detection Checklists

Motive, Opportunity, and Means (MOM)

Motive: What are the goals and motives of the potential deceiver? Channels: What means are available to the potential deceiver to feed information to us? Risks: What consequences would the adversary suffer if such a deception were revealed? Costs: Would the potential deceiver need to sacrifice sensitive information to establish the credibility of the deception channel? Feedback: Does the potential deceiver have a feedback mechanism to monitor the impact of the deception operation?

Past Opposition Practices (POP)

Does the adversary have a history of engaging in deception? Does the current circumstance fit the pattern of past deceptions? If not, are there other historical precedents? If not, are there changed circumstances that would explain using this form of deception at this time?

Manipulability of Sources (MOSES)

Is the source vulnerable to control or manipulation by the potential deceiver? What is the basis for judging the source to be reliable? Does the source have direct access or only indirect access to the information? How good is the source's track record of reporting?

Evaluation of Evidence (EVE)

How accurate is the source's reporting? Has the whole chain of evidence, including translations, been checked? Does the critical evidence check out? Remember, the subsource can be more critical than the source. Does evidence from one source of reporting (e.g., human intelligence) conflict with that coming from another source (e.g., signals intelligence or open-source reporting)? Do other sources of information provide corroborating evidence? Is the absence of evidence one would expect to see noteworthy?

7.9 Argument Mapping

Argument Mapping is a technique that tests a single hypothesis through logical reasoning. An Argument Map starts with a single hypothesis or tentative analytic judgment and then graphically separates the claims and evidence to help break down complex issues and communicate the reasoning behind a conclusion. It is a type of tree diagram that starts with the conclusion or lead hypothesis, and then branches out to reasons, evidence, and finally assumptions. The process of creating the Argument Map helps identify key assumptions and gaps in logic.

An Argument Map makes it easier for both the analysts and the recipients of the analysis to clarify and organize their thoughts and evaluate the soundness of any conclusion. It shows the logical relationships between various thoughts in a systematic way and allows one to assess quickly in a visual way the strength of the overall argument. The technique also helps the analysts and recipients of the report to focus on key issues and arguments rather than focusing too much attention on minor points.

When to Use It

When making an intuitive judgment, use Argument Mapping to test your own reasoning. Creating a visual map of your reasoning and the evidence that supports this reasoning helps you better understand the strengths, weaknesses, and gaps in your argument. It is best to use this technique before you write your product to ensure the quality of the argument and refine it if necessary.

Argument Mapping and Analysis of Competing Hypotheses (ACH) are complementary techniques that work well either separately or together. Argument Mapping is a detailed presentation of the argument for a single hypothesis; ACH is a more general analysis of multiple hypotheses. The ideal is to use both, as follows:

Before you generate an Argument Map, using ACH can be helpful way to take a closer look at the viability of alternative hypotheses. After looking at alternative hypotheses, you can then select the best one to map. After you have identified a favored hypothesis through ACH analysis, Argument Mapping helps check and present the rationale for this hypothesis.

Value Added

An Argument Map organizes one's thinking by showing the logical relationships between the various thoughts, both pro and con. An Argument Map also helps the analyst recognize assumptions and identify gaps in the available knowledge. The visualization of these relationships makes it easier to think about a complex issue and serves as a guide for clearly presenting to others the rationale for the conclusions. Having this rationale available in a visual form helps both the analyst and recipients of the report focus on the key points rather than meandering aimlessly or going off on irrelevant tangents.

When used collaboratively, Argument Mapping helps ensure that a variety of views are expressed and considered, helping mitigate the influence of Groupthink. The visual representation of an argument also makes it easier to recognize weaknesses in opposing arguments. It pinpoints the location of any disagreement, serves as an objective basis for mediating a disagreement, and mitigates against seeking quick and easy answers to difficult problems (Mental Shotgun).

An Argument Map is an ideal tool for dealing with issues of cause and effect—and for avoiding the trap that correlation implies causation (Confusing Causality and Correlation). By laying out all the arguments for and against a lead hypothesis—and all the supporting evidence and logic—it is easy to evaluate the soundness of the overall argument.

The process also helps analysts counter the intuitive traps of Ignoring Base Rate Probabilities by encouraging the analyst to seek out and record all the relevant facts that support each supposition. Similarly, the focus on seeking out and recording all data that support or rebut the key points of the argument makes it difficult for the analyst to overdraw conclusions from a small sample of data (Overinterpreting Small Samples) or to continue to hold to an analytic judgment when confronted with a mounting list of evidence that contradicts the initial conclusion (Rejecting Evidence).

The Method

An Argument Map starts with a hypothesis—a single-sentence statement, judgment, or claim about which the analyst can, in subsequent statements, present general arguments and detailed evidence, both pro and con. Boxes with arguments are arrayed hierarchically below this statement; these boxes are connected with arrows. The arrows signify that a statement in one box is a reason to believe, or not to believe, the statement in the box to which the arrow is pointing. Different types of boxes serve different functions in the reasoning process, and boxes use some combination of color-coding, icons, shapes, and labels so that one can quickly distinguish arguments supporting a hypothesis from arguments opposing it. Figure 7.9 is a simple example of Argument Mapping, showing some of the arguments bearing on the assessment that North Korea has nuclear weapons.

These are the specific steps involved in constructing a generic Argument Map:

Write down the lead hypothesis—a single-sentence statement, judgment, or claim at the top of the argument tree. Draw a set of boxes below this initial box and list the key reasons why the statement is true along with the key objections to the statement. Use green lines to link the reasons to the primary claim or other conclusions they support. Use green lines to connect evidence that supports the key reason. ( Hint: State the reason and then ask yourself, "Because?" The answer should be the evidence you are seeking.) Identify any counterevidence that is inconsistent with the reason. Use red lines to link the counterevidence to the reasons they contradict. Identify any objections or challenges to the primary claim or key conclusions. Use red lines to connect the objections to the primary claim or key conclusions. Identify any counterevidence that supports the objections or challenges. Use red lines to link the counterevidence to the objections or challenges it supports. Specify rebuttals, if any, with orange lines. An objection, challenge, or counterevidence that does not have an orange-line rebuttal suggests a flaw in the argument. Evaluate the argument for clarity and completeness, ensuring that red-lined opposing claims and evidence have orange-line rebuttals. If all the reasons can be rebutted, then the argument is without merit.

Potential Pitfalls

Argument Mapping is a challenging skill. Training and practice are required to use the technique properly and to gain its benefits. Detailed instructions for effective use of this technique are available at the website listed below under "Origins of This Technique." Assistance by someone experienced in using the technique is necessary for first-time users. Commercial software and freeware are available for various types of Argument Mapping. In the absence of software, using a self-stick note to represent each box in an Argument Map drawn on a whiteboard can be helpful, as it is easy to move the self-stick notes around as the map evolves and changes.

Origins of This Technique

The use of Argument Mapping goes back to the early nineteenth century. In the early twentieth century, John Henry Wigmore pioneered its use for legal argumentation. The availability of computers to create and modify Argument Maps in the later twentieth century prompted broader interest in Argument Mapping in Australia for use in a variety of analytic domains. The short description here is based on material in the Austhink website: http://www.austhink.com/critical/pages/argument_mapping.html .

Description Figure 7.9 Argument Mapping: Does North Korea Have Nuclear Weapons? Source: Diagram produced using the bCisive Argument Mapping software from Austhink, www.austhink.com .

Notes

1. See the discussion in chapter 2 contrasting the characteristics of System 1, or intuitive thinking, with System 2, or analytic thinking.

2. Karl Popper, The Logic of Science (New York: Basic Books, 1959).

3. Stuart K. Card, "The Science of Analytical Reasoning," in Illuminating the Path: The Research and Development Agenda for Visual Analytics , eds. James J. Thomas and Kristin A. Cook (Richland, WA: National Visualization and Analytics Center, Pacific Northwest National Laboratory, 2005), https://pdfs.semanticscholar.org/e6d0/612d677199464af131c16ab0fa657d6954f2.pdf

4. See Popper, The Logic of Science .

5. A more detailed description of Te@mACH ® can be found on the Software tab at http://www.globalytica.com . The software is in the process of being rehosted in 2019.

6. Richards J. Heuer Jr., Psychology of Intelligence Analysis (Washington, DC: CIA Center for the Study of Intelligence, 1999; reprinted by Pherson Associates, LLC, Reston, VA, 2007).

7. Richards J. Heuer Jr., "Cognitive Factors in Deception and Counterdeception," in Strategic Military Deception , eds. Donald C. Daniel and Katherine L. Herbig (New York: Pergamon Press, 1982).

8. Heuer, "Cognitive Factors in Deception and Counterdeception"; Michael I. Handel, "Strategic and Operational Deception in Historical Perspective," in Strategic and Operational Deception in the Second World War , ed. Michael I. Handel (London: Frank Cass, 1987).

Descriptions of Images and Figures

Back to Figure

Data from the timeline are as follows. February 7: Range instrumentation radar first active. February 12: Airframes observed on ground transport. February 13: TELs observed at suspected launch site. February 16: Transporters observed at launch site. February 24: Telemetry first active. February 28: Military establishes communication links. March 2: Missiles observed on training pads. March 11: Propellant handling activity observed. March 13: Azimuth markers observed on launch pads. March 18: Transporters moved to launch area. March 23: Airframe revealed. April 1: Propellant loading underway. April 3: Navigational closure area announced, and TEL and equipment transloading. April 5: Military assets deployed to support launch. April 6: Missiles launched.

Back to Figure

The cells in each row show the impact of the variable represented by that row on each of the variables listed across the top of the matrix. The cells in each column show the impact of each variable listed down the left side of the matrix on the variable represented by the column.

Variables 2 and 4 in the cross-impact matrix have the greatest effect on the other variables, while variable 6 has the most negative effect.

| - | Variable 1 | Variable 2 | Variable 3 | Variable 4 | Variable 5 | Variable 6 |
| --- | --- | --- | --- | --- | --- | --- |
| Variable 1 | Nil | Neutral | Positive | Neutral | Strong negative | Neutral |
| Variable 2 | Neutral | Nil | Negative | Strong positive | Positive | Positive |
| Variable 3 | Strong positive | Negative | Nil | Positive | Neutral | Negative |
| Variable 4 | Neutral | Strong positive | Neutral | Nil | Positive | Negative |
| Variable 5 | Strong negative | Positive | Neutral | Positive | Nil | Neutral |
| Variable 6 | Negative | Positive | Strong negative | Negative | Negative | Nil |

Back to Figure

Idea is generated by a group, who performs structured brainstorming to produce 1 to 3 alternative hypotheses. A list of possible alternative hypotheses leads to idea evaluation and consolidation, such as formation of affinity groups 1 through 4, and their related hypotheses. The final list consists of hypotheses. Text for the group reads, "Is the group sufficiently diverse?" Text for structured brainstorming reads, "Prompt creativity by using situational logic, historical analogies, and theory." Text for the list of possible hypotheses reads, "Does this initial list take into account all the key forces and factors?" Text for the affinity group reads, "Create groups of similar hypotheses. Ask if the opposite could be true to generate new ideas." Text for the hypotheses list reads, "Are the hypotheses mutually exclusive? Is the list comprehensive? Did you clarify each hypothesis by asking who, what, how, when, where, and why?"

Back to Figure

The illustration shows a quadrant. The top side is labeled centralized; the right side is labeled religious; the bottom side is labeled decentralized; and the left side is labeled secularized. H1: Centralized state and secularized society. H2: Centralized state and religious society. H3: Decentralized state and secularized society. H4: Decentralized state and religious society.

Back to Figure

The matrix lists relevant information and hypothesis, buttons for rating credibility, and a column for listing notes, assumptions, and credibility justification. At the top of the matrix, a color legend shows the level of disagreement. The column consists of a tool for reordering hypotheses from most to least likely. The row consists of a tool for moving the most discriminating information to the top of the matrix. The cells consists of options for access chat and viewing analyst ratings. The number of inconsistencies in the hypotheses is also displayed.

Back to Figure

The contention is that North Korea has nuclear weapons. The objection to this is that North Korea does not have technical capacity to produce enough weapons-grade fissile material. A rebuttal to this is that North Korea was provided key information and technology by Pakistan around 1997. The reasoning to the contention is that North Korea has exploded nuclear weapons in tests. The evidence to this is that North Korea claimed to have exploded test weapons in 2006 and 2009, and that there are seismological evidence of powerful explosions.