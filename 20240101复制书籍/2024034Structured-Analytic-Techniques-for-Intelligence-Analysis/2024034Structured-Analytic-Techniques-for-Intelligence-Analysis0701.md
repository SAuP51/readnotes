Randolph H. Pherson, Richards J. Heuer.(2020).2024034Structured-Analytic-Techniques-for-Intelligence-Analysis3Ed.CQ Press => 0301 Choosing the Right Technique

## 0701. Diagnostic Techniques

A nalysis conducted by the intelligence, law enforcement, and business communities will never achieve the accuracy and predictability of a true science because the information with which analysts must work is typically incomplete, ambiguous, and potentially deceptive. The analytic process can, however, benefit from the lessons of science and adapt some of the elements of scientific reasoning.

The scientific process involves observing, categorizing, formulating hypotheses, and then testing those hypotheses. Generating and testing hypotheses is a core function of structured analysis. A possible explanation of the past or a judgment about the future is a hypothesis that needs to be tested by collecting and presenting evidence. This chapter focuses on several key techniques that support the Diagnostic Reasoning process, including challenging key assumptions about what the information reveals, developing Chronologies and Timelines, generating alternative hypotheses, and testing the validity of hypotheses and the quality of argumentation. Practice in using three of the techniques—Key Assumptions Check, Multiple Hypothesis Generation, and Analysis of Competing Hypotheses—will help analysts become proficient in the first three of the Five Habits of the Master Thinker (see chapter 3): challenging assumptions, generating alternative explanations, and identifying inconsistent evidence.

The generation and testing of hypotheses is a skill, and its subtleties do not come naturally. It is a form of reasoning that people can learn to use for dealing with high-stakes situations. What does come naturally is drawing on our existing body of knowledge and experience (mental model) to make an intuitive judgment. 1 In most circumstances in our daily lives, this is an efficient approach that works most of the time. For intelligence analysis, however, it is not adequate, because intelligence issues are generally so complex, and the risk and cost of error are too great. Also, the situations are often novel, so the intuitive judgment shaped by past knowledge and experience may well be wrong.

Good analysis of a complex issue must start with a set of alternative hypotheses. Another practice that the experienced analyst borrows from the scientist's toolkit involves the testing of alternative hypotheses. The truth of a hypothesis can never be proven beyond doubt by citing only evidence that is consistent with the hypothesis, because the same evidence may be and often is consistent with more than one hypothesis. Science often proceeds by refuting or disconfirming hypotheses. A hypothesis that cannot be refuted should be taken just as seriously as a hypothesis that seems to have a lot of evidence in favor of it. A single item of evidence that is shown to be inconsistent with a hypothesis can be grounds for rejecting that hypothesis. The most tenable hypothesis is often the one with the least evidence against it.

Analysts often test hypotheses by using a form of reasoning known as abduction, which differs from the two better known forms of reasoning, deduction and induction. Abductive reasoning starts with a set of facts. One then develops hypotheses that, if true, would provide the best explanation for these facts. The most tenable hypothesis is the one that best explains the facts. Because of the uncertainties inherent in intelligence analysis, conclusive proof or refutation of hypotheses is the exception rather than the rule.

Use of Diagnostic Techniques can provide a strong antidote to several cognitive biases. It can reduce the influence of Confirmation Bias by exposing analysts to new ideas and multiple permutations, and mitigate the impact of Evidence Acceptance Bias, which is accepting data as true because it helps create a more coherent story. Diagnostic Techniques also protect analysts against falling into the intuitive traps of Relying on First Impressions, Ignoring Inconsistent Evidence, and Projecting Past Experiences.

The first part of this chapter describes techniques for challenging key assumptions, establishing analytic baselines, and identifying the relationships among the key variables, drivers, or players that may influence the outcome of a situation. These and similar techniques allow analysts to imagine new and alternative explanations for their subject matter.

The second section describes three techniques for generating hypotheses. Other chapters include additional techniques for generating hypotheses, but which also have a variety of other purposes. These include Cluster Brainstorming, Nominal Group Technique, and Venn Analysis ( chapter 6 ); the Delphi Method and Classic Quadrant Crunching™ ( chapter 8 ); various forms of Foresight analysis ( chapter 9 ); and Critical Path Analysis and Decision Trees (chapter 10).

This chapter concludes with a discussion of five techniques for testing hypotheses, detecting deception, and evaluating the strength of an argument. These techniques spur the analyst to become more sensitive to the quality of the data and the strength of the logic and to look for information that not only confirms but can disconfirm the hypothesis. One of these, Analysis of Competing Hypotheses (ACH), was developed by Richards J. Heuer Jr. specifically for use in intelligence analysis.

诊断技术

情报、执法和商业领域的分析，永远无法达到像科学那样的高准确性和可预测性，原因在于分析师处理的信息往往是不完整的、模糊的，甚至可能是误导性的。然而，分析过程可以借鉴科学的方法，采用一些科学推理的元素。

科学方法包括观察、分类、提出假设和测试假设。生成和检验假设是结构化分析的核心功能。对过去的可能解释或对未来的预测就是一种假设，需要通过收集和展示证据来验证。本章将介绍几种关键技术，这些技术有助于诊断推理过程，包括质疑信息中的关键假设、制定年表和时间轴、生成替代假设，以及检验假设的有效性和论证的质量。通过练习三种技术 —— 关键假设检查（Key Assumptions Check)、多假设生成（Multiple Hypothesis Generation）和竞争假设分析（Analysis of Competing Hypotheses) —— 分析师可以熟练掌握思考者的五个习惯（见第 3 章）的前三个：质疑假设、生成替代解释和识别不一致的证据。

生成和测试假设是一门需要掌握的技能，其微妙之处并非与生俱来。人们可以通过学习这种推理方式来应对高风险的情境。我们天生更擅长的是利用已有的知识和经验（心理模型）来进行直觉判断。在日常生活中，这种方法通常高效且有效。然而，在情报分析中，这种方法并不够用，因为情报问题通常非常复杂，错误的风险和代价太高。此外，这些情况往往是新的，因此基于过去知识和经验的直觉判断可能会出错。

要对复杂问题进行有效分析，必须从多种备选假设入手。经验丰富的分析师还会借鉴科学家的方法，测试这些备选假设。仅引用与假设一致的证据，无法毫无疑问地证明假设的真实性，因为相同的证据往往可以支持多个假设。科学的进步通常通过反驳或否定假设来实现。一个无法被反驳的假设应与那些有大量证据支持的假设同等对待。即使只有一条证据与假设不符，也可能足以推翻这个假设。而相对最可行的假设往往是反对证据最少的那个。

分析师常用一种称为溯因推理的方式来测试假设，这种推理不同于更常见的演绎和归纳推理。溯因推理从一系列事实出发，然后提出假设，如果这些假设成立，它们将能最好地解释这些事实。最可信的假设就是那个最能解释事实的假设。由于情报分析中存在固有的不确定性，确凿地证明或反驳某个假设往往是例外而非常态。

诊断技术可以有效对抗多种认知偏见。它通过让分析师接触新观点和多种可能性，减少确认偏见的影响，并缓解证据接受偏见，即因为数据有助于构建更连贯的故事而接受其为真。诊断技术还可以防止分析师陷入依赖第一印象、忽视矛盾证据和依赖过去经验的直觉陷阱。

本章的第一部分介绍了挑战关键假设、建立分析基线以及识别可能影响结果的关键变量、驱动因素或参与者之间关系的技术。这些技术及类似方法使分析师能够构想新的和替代的解释。

第二部分介绍了三种生成假设的技术。其他章节还包括了其他生成假设的技术，但这些技术也有多种其他用途。这些技术包括集群头脑风暴、名义群体技术和文氏分析（第 6 章）；德尔菲法和经典象限分析™（第 8 章）；各种形式的前瞻性分析（第 9 章）；以及关键路径分析和决策树（第 10 章）。

本章总结了五种用于检验假设、检测欺骗和评估论证强度的技术。这些技术可以帮助分析师更加关注数据质量和逻辑的严密性，并寻找不仅能支持假设、也能推翻假设的信息。其中之一是竞争假设分析（Analysis of Competing Hypotheses，ACH)，由 Richards J. Heuer Jr. 专为情报分析开发。

Overview of Techniques

Key Assumptions Check is one of the most important and frequently used techniques. Analytic judgment is always based on a combination of evidence and assumptions—or preconceptions—that influence how the evidence is interpreted. The Key Assumptions Check is a systematic effort to make explicit and question the assumptions (i.e., mental model) that guide an analyst's thinking.

Chronologies and Timelines are used to organize data on events or actions. They are used whenever it is important to understand the timing and sequence of relevant events or to identify key events and gaps.

Cross-Impact Matrix is a technique that can be used after any form of brainstorming that identifies a list of variables relevant to an analytic project. The results of the brainstorming session are put into a matrix, which is used to guide a group discussion that systematically examines how each variable influences all other variables to which it is related in a particular problem context. The group discussion is often a valuable learning experience that provides a foundation for further collaboration. Results of cross-impact discussions should be retained for future reference as a cross-check after the analysis is completed.

Multiple Hypothesis Generation can be accomplished in many ways. This book describes three techniques—Simple Hypotheses, Quadrant Hypothesis Generation, and the Multiple Hypothesis Generation. Simple Hypotheses is the easiest to use but not always the best selection. Quadrant Hypothesis Generation is used to identify a set of hypotheses when the outcome is likely to be determined by just two driving forces. Multiple Hypothesis Generation is used to identify a large set of possible hypotheses. The latter two techniques are particularly useful in identifying sets of M utually E xclusive and C omprehensively E xhaustive (MECE) hypotheses.

Diagnostic Reasoning applies hypothesis testing to the evaluation of significant new information. Such information is evaluated in the context of all plausible explanations of that information, not just in the context of the analyst's well-established mental model. The use of Diagnostic Reasoning reduces the risk of surprise, as it ensures that an analyst will have considered some alternative conclusions. Diagnostic Reasoning differs from the ACH technique in that it evaluates a single item of evidence; ACH deals with an entire issue involving multiple pieces of evidence and a more complex analytic process.

Analysis of Competing Hypotheses is the application of Karl Popper's philosophy of science to the field of intelligence analysis. 2 Popper was one of the most influential philosophers of science of the twentieth century. He is known for, among other things, his position that scientific reasoning should start with multiple hypotheses and proceed by rejecting or eliminating hypotheses, tentatively accepting only those hypotheses that cannot be refuted. This process forces an analyst to recognize the full uncertainty inherent in most analytic situations. ACH helps the analyst sort and manage relevant information to identify paths for reducing that uncertainty.

The Inconsistencies Finder™ is a simplified version of ACH that helps analysts evaluate the relative credibility of a set of hypotheses based on the amount of identified disconfirming information. It provides a quick framework for identifying inconsistent data and discovering the hypotheses that are most likely to be correct.

Deception Detection employs a set of checklists analysts can use to determine when to anticipate deception, how to determine if one is being deceived, and what to do to avoid being deceived. It is also useful for detecting the presence of Digital Disinformation or "Fake News." The possibility of deception by a foreign intelligence service, economic competitor, or other adversary organization is a distinctive type of hypothesis that can be included in any ACH analysis. Information identified through the Deception Detection technique can then be entered as relevant information in an ACH matrix.

Argument Mapping is a method that can be used to put a single hypothesis to a rigorous logical test. The structured visual representation of the arguments and evidence makes it easier to evaluate any analytic judgment. Argument Mapping is a logical follow-on to an ACH analysis. It is a detailed presentation of the arguments for and against a single hypothesis; ACH is a more general analysis of multiple hypotheses. The successful application of Argument Mapping to the hypothesis favored by the ACH analysis would increase confidence in the results of both analyses.

技术概述

关键假设检查是最重要且最常用的技术之一。分析判断总是基于证据和假设（或先入之见）的结合，而这些假设会影响证据的解读。关键假设检查是一种系统化的方法，旨在明确并质疑指导分析师思维的假设（即心理模型）。

年表和时间线用于整理事件或行动的数据。当需要了解相关事件的时间顺序或识别关键事件和空白时，它们非常有用。

交叉影响矩阵是一种用于头脑风暴后的技术，这些头脑风暴会列出与分析项目相关的变量清单。头脑风暴的结果被放入矩阵中，矩阵用于指导小组讨论，系统地检查每个变量如何影响与特定问题情境相关的其他变量。小组讨论通常是一个宝贵的学习过程，为进一步的合作奠定基础。交叉影响讨论的结果应保留以供将来参考，作为分析完成后的交叉检查。

多假设生成可以通过多种方法实现。本书介绍了三种技术 —— 简单假设、象限假设生成和多假设生成。简单假设最为容易使用，但并非总是最佳选择。象限假设生成适用于当结果可能由两个主要因素决定时，用于识别一组假设。多假设生成则用于识别大量可能的假设。后两种技术特别适合识别互斥且穷尽（MECE）的假设集。

诊断推理将假设检验应用于评估重要的新信息。这些信息会在所有合理解释的背景下进行评估，而不仅仅是分析人员已建立的心理模型。使用诊断推理可以降低意外的风险，因为它确保分析人员会考虑一些替代结论。诊断推理与 ACH 技术不同，前者评估单一证据项，而 ACH 处理涉及多个证据项和更复杂的分析过程的整个问题。

竞争假设分析是将卡尔·波普尔的科学哲学应用于情报分析领域。波普尔是二十世纪最有影响力的科学哲学家之一。他认为科学推理应该从多个假设开始，然后通过拒绝或消除假设，暂时接受那些无法被驳斥的假设。这一过程迫使分析人员认识到大多数分析情境中固有的不确定性。ACH 帮助分析人员整理和管理相关信息，以识别减少这种不确定性的路径。

Inconsistencies Finder™ 是 ACH 的简化版本，帮助分析人员根据发现的否定信息数量来评估一组假设的相对可信度。它提供了一个快速框架，用于识别不一致的数据并找出最有可能正确的假设。

Deception Detection 使用一组检查表，帮助分析人员判断何时可能遭遇欺骗，如何确认是否被欺骗，以及如何避免被欺骗。它对于检测数字虚假信息或「假新闻」也非常有用。由外国情报机构、经济竞争对手或其他敌对组织进行欺骗的可能性是一种可以包含在任何 ACH 分析中的独特假设。通过 Deception Detection 技术识别的信息可以作为相关信息输入到 ACH 矩阵中。

Argument Mapping 是一种对单一假设进行严格逻辑测试的方法。通过对论点和证据进行结构化的视觉呈现，评估任何分析判断变得更为容易。Argument Mapping 是 ACH 分析的逻辑延续。它详细展示了对单一假设的支持和反对论点，而 ACH 是对多个假设的更全面分析。成功将 Argument Mapping 应用于 ACH 分析所支持的假设，将增加对两种分析结果的信心。

### 7.1 Key Assumptions Check

Analytic judgment is always based on a combination of evidence and assumptions, or preconceptions, which influences how the evidence is interpreted. 3 The Key Assumptions Check is a systematic effort to make explicit and question the assumptions (the mental model) that guide an analyst's interpretation of evidence and reasoning about a problem. Such assumptions are usually necessary and unavoidable as a means to fill gaps in the incomplete, ambiguous, and sometimes deceptive information with which the analyst must work. They are driven by the analyst's education, training, and experience, plus the organizational context in which the analyst works.

An organization really begins to learn when its most cherished assumptions are challenged by counterassumptions. Assumptions underpinning existing policies and procedures should therefore be unearthed, and alternative policies and procedures put forward based upon counterassumptions.

— Ian I. Mitroff and Richard O. Mason, Creating a Dialectical Social Science: Concepts, Methods, and Models (1981)

The Key Assumptions Check is one of the most common techniques used by intelligence analysts because they typically need to make assumptions to fill information gaps. In the intelligence world, these assumptions are often about another country's intentions or capabilities, the way governmental processes usually work in that country, the relative strength of political forces, the trustworthiness or accuracy of key sources, the validity of previous analyses on the same subject, or the presence or absence of relevant changes in the context in which the activity is occurring. Assumptions are often difficult to identify because many sociocultural beliefs are held unconsciously or so firmly that they are assumed to be truth and not subject to challenge.

When to Use It

Any explanation of current events or estimate of future developments requires the interpretation of evidence. If the available evidence is incomplete or ambiguous, this interpretation is influenced by assumptions about how things normally work in the country or company of interest. These assumptions should be made explicit early in the analytic process.

If a Key Assumptions Check is not done at the outset of a project, it can still prove extremely valuable if done during the coordination process or before conclusions are presented or delivered. When a Key Assumptions Check is done early in the process, it is often desirable to review the assumptions again later—for example, just before or just after drafting the report. The task is to determine whether the assumptions still hold true or should be modified.

When tracking the same topic or issue over time, analysts should consider reassessing their key assumptions on a periodic basis, especially following a major new development or surprising event. If, on reflection, one or more key assumptions no longer appear to be well-founded, analysts should inform key policymakers or corporate decision makers working that target or issue that a foundational construct no longer applies or is at least doubtful.

Value Added

Preparing a written list of one's working assumptions at the beginning of any project helps the analyst do the following:

Identify the specific assumptions that underpin the basic analytic line. Achieve a better understanding of the fundamental dynamics at play. Gain a better perspective and stimulate new thinking about the issue. Discover hidden relationships and links among key factors. Identify what developments would call a key assumption into question. Avoid surprises should new information render old assumptions invalid.

A Key Assumptions Check helps analysts mitigate the impact of heuristics that, when misapplied, can impede analytic thinking, including the tendency to accept a given value of an assumption or something unknown as a proper starting point for generating an assessment (Anchoring Effect), reaching an analytic judgment before sufficient information is collected and proper analysis performed (Premature Closure), and judging the frequency of an event by the ease with which instances come to mind (Availability Heuristic). It also safeguards an analyst against several classic mental mistakes, including the tendency to overdraw conclusions when presented with only a small amount of data (Overinterpreting Small Samples), assume the same dynamic is in play when something appears to be in accord with past experiences (Projecting Past Experiences), and failing to factor something into the analysis because the analyst lacks an appropriate category or "bin" for that item of information (Lacking Sufficient Bins).

Conducting a Key Assumptions Check gives analysts a better understanding of the suppositions underlying their key judgments or conclusions. Doing so helps analysts establish how confident they should be in making their assessment and disseminating their key findings.

The Method

The process of conducting a Key Assumptions Check is relatively straightforward in concept but often challenging to put into practice. One challenge is that participating analysts must be open to the possibility that they could be wrong. It helps to involve several well-regarded analysts who are generally familiar with the topic but have no prior commitment to any set of assumptions about the issue in the process. Engaging a facilitator is also highly recommended. Keep in mind that many "key assumptions" turn out to be "key uncertainties." Randolph Pherson's extensive experience as a facilitator of analytic projects indicates that approximately one in every four key assumptions collapses on careful examination.

The following are steps in conducting a Key Assumptions Check:

Gather a small group of individuals who are working the issue along with a few "outsiders." The primary analytic unit already is working from an established mental model, so the "outsiders" are needed to bring a different perspective. Ideally, the facilitator should notify participants about the topic beforehand and ask them to bring to the meeting a list of assumptions they make about the topic. If they do not do this beforehand, start the meeting with a silent brainstorming session by asking each participant to write down several assumptions on an index card. Collect the cards and list the assumptions on a whiteboard or easel for all to see. Elicit additional assumptions. Work from the prevailing analytic line to identify additional arguments that support it. Use various devices to help prod participants' thinking:

Ask the standard journalistic questions. Who: Are we assuming that we know who all the key players are? What: Are we assuming that we know the goals of the key players? How: Are we assuming that we know how they are going to act? When: Are we assuming that conditions have not changed since our last report or that they will not change in the foreseeable future? Where: Are we assuming that we know where the real action is going to be? Why: Are we assuming that we understand the motives of the key players? Use of phrases such as "will always," "will never," or "would have to be" suggests that an idea is not being challenged. Perhaps it should be. Use of phrases such as "based on" or "generally the case" suggests the presence of a challengeable assumption. When the flow of assumptions starts to slow down, ask, "What else seems so obvious that one would not normally think about challenging it?" If no one can identify more assumptions, then there is an assumption that they do not exist, which itself is an assumption subject to challenge. After identifying a full set of assumptions, critically examine each assumption and ask,

Why am I confident that this assumption is correct? In what circumstances might this assumption be untrue? Could it have been true in the past but not any longer? How much confidence do I have that this assumption is valid? If it turns out to be invalid, how much impact would this have on the analysis? Place each assumption in one of three categories:

Basically solid (S) Correct with some caveats (C) Unsupported or questionable—the "key uncertainties" (U) Refine the list. Delete assumptions that do not hold up to scrutiny and add new ones that emerge from the discussion. If an assumption generates a lot of discussion, consider breaking it into two assumptions or rephrasing it to make the statement more explicit. Above all, emphasize those assumptions that would, if wrong, lead to changing the analytic conclusions. Consider whether key uncertainties should be converted into intelligence collection requirements or research topics.

When concluding the analysis, remember that the probability of your analytic conclusion being accurate cannot be greater than the weakest link in your chain of reasoning. Review your assumptions, assess the quality of evidence and reliability of sources, and consider the overall difficulty and complexity of the issue. Then make a rough estimate of the probability that your analytic conclusion will turn out to be wrong. Use this number to calculate the rough probability of your conclusion turning out to be accurate. For example, a three in four chance (75 percent) of being right equates to a one in four chance (25 percent) of being wrong. This focus on how and why we might be wrong is needed to offset the natural human tendency toward reluctance to admit we might be wrong.

Figure 7.1 shows apparently flawed assumptions made in the Wen Ho Lee espionage case during the 1990s and what further investigation showed about these assumptions. A Key Assumptions Check could have identified weaknesses in the case against Lee much earlier.

Relationship to Other Techniques

The Key Assumptions Check is frequently paired with other techniques because assumptions play an important role in all structured analytic efforts. It is important to get them right. For example, when an assumption is critical to an analysis, and questions remain about the validity of that assumption, it may be desirable to follow the Key Assumptions Check with a What If? Analysis. Imagine a future (or a present) in which the assumption is wrong. What could have happened to make it wrong, how could that have happened, and what are the consequences?

Figure 7.1 Key Assumptions Check: The Case of Wen Ho Lee Source: Pherson Associates, LLC, 2019.

There is a particularly noteworthy interaction between Key Assumptions Check and ACH. Key assumptions need to be included as "evidence" in an ACH matrix to ensure that the matrix is an accurate reflection of the analyst's thinking. Assumptions often emerge during a discussion of relevant information while filling out an ACH matrix. This happens when an analyst assesses the consistency or inconsistency of an item of evidence with a hypothesis and concludes that the designation is dependent upon something else—usually an assumption. Classic Quadrant Crunching™ ( chapter 8 ) and Simple Scenarios, the Cone of Plausibility, and Reversing Assumptions ( chapter 9 ) all use assumptions and their opposites to generate multiple explanations or outcomes.

Origins of This Technique

Although assumptions have been a topic of analytic concern for a long time, the idea of developing a specific analytic technique to focus on assumptions did not occur until the late 1990s. The discussion of Key Assumptions Check in this book is from Randolph H. Pherson, Handbook of Analytic Tools and Techniques , 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019).

7.1 关键假设检查

分析判断总是基于证据和假设的结合，这些假设会影响对证据的解读 [3]。关键假设检查是一种系统方法，旨在明确并质疑指导分析师解读证据和推理问题的假设（即心理模型）。这些假设通常是必要的，因为它们帮助填补分析师面对的不完整、模糊甚至有时具有欺骗性的信息。分析师的教育、培训、经验以及工作环境都会影响这些假设。

当组织最珍视的假设被反假设挑战时，才真正开始学习。因此，应该揭示现有政策和程序背后的假设，并基于反假设提出替代方案。

— Ian I. Mitroff 和 Richard O. Mason，《创造对话的社会科学：概念、方法和模型》（1981）

关键假设检查是情报分析师常用的技术之一，因为他们需要通过假设来填补信息空白。在情报领域，这些假设通常涉及另一个国家的意图或能力、政府流程的运作方式、政治力量的相对强度、关键来源的可信度或准确性、以前分析的有效性或相关环境的变化。假设通常难以识别，因为许多社会文化信念是无意识的，或者被认为是不可质疑的真理。

何时使用

对当前事件的解释或对未来发展的预测都需要对证据进行分析。如果现有的证据不完整或含糊不清，那么这种分析会受到对该国或公司运作方式假设的影响。这些假设应该在分析过程的初期明确提出。

如果在项目开始时没有进行关键假设检查（Key Assumptions Check)，即使在项目协调过程中或在结论呈现前进行，仍然非常有价值。当在早期进行关键假设检查时，通常需要在后期再次审查这些假设，例如报告撰写前后。这样可以确定这些假设是否仍然有效或需要修改。

在持续跟踪同一主题或问题时，分析师应定期重新评估其关键假设，特别是在出现重大新发展或意外事件后。如果在反思后发现一个或多个关键假设不再成立，分析师应通知相关政策制定者或企业决策者，告知其基础构架已不再适用或存在疑问。

附加价值在项目开始时准备一份书面的工作假设列表，有助于分析师完成以下任务：

- 识别支撑基本分析路线的具体假设。
- 更好地理解所涉及的基本动态。
- 获得更广阔的视角，激发新的思考。
- 发现关键因素之间隐藏的关系和联系。
- 识别哪些发展会对关键假设提出质疑。
- 避免新信息使旧假设无效时感到措手不及。

关键假设检查帮助分析师减少因错误使用启发式方法而影响分析思维的风险。这些方法包括：倾向于将假设或未知事物的某个值作为评估的起点（锚定效应），在收集足够信息和进行充分分析之前就得出结论（过早结论），以及通过事件容易被想起的程度来判断其频率（可得性启发）。此外，它还防止分析师犯一些经典的心理错误，例如在数据量少的情况下过度解读（过度解释小样本），将目前情况与过去经验相投射（投射过去经验），以及因为缺乏合适的类别或「分类框」而忽略某些信息（缺乏足够的分类框）。

进行关键假设检查能让分析师更清晰地理解其关键判断或结论背后的假设。这帮助他们在进行评估和传播关键发现时更有信心。

方法

进行关键假设检查的过程在理论上相对简单，但在实际操作中往往颇具挑战。一个主要挑战是，参与的分析师必须愿意接受他们可能会犯错误的事实。最好能邀请一些备受尊敬的分析师，他们虽然对该主题有所了解，但并未对任何假设产生先入为主的看法。建议引入一位主持人来帮助进行检查。需要注意的是，许多「关键假设」实际上是「关键不确定性」。根据 Randolph Pherson 作为分析项目主持人的丰富经验，大约每四个关键假设中就有一个在仔细检查后会被推翻。

以下是进行关键假设检查的步骤：

首先，召集一小组处理该问题的人员和几位「外部人员」。主要的分析团队已经有了既定的思维模型，因此需要「外部人员」带来不同的视角。理想情况下，主持人应提前通知参与者讨论的主题，并要求他们在会议前准备一个假设列表。如果他们没有提前准备，可以在会议开始时让每位参与者在卡片上写下几个假设，进行无声的头脑风暴。然后，收集这些卡片并将假设列在白板或画架上，供大家讨论。引导参与者提出更多的假设，从现有的分析思路中找出支持这些假设的论据。可以使用多种方法来激发参与者的思考：

提出标准的新闻提问。谁：我们是否知道所有关键人物是谁？什么：我们是否清楚关键人物的目标是什么？如何：我们是否了解他们将如何行动？什么时候：我们是否假设自上次报告以来，条件没有改变，或者在可预见的未来也不会改变？在哪里：我们是否知道真正的行动会在哪里发生？为什么：我们是否理解关键人物的动机？

使用类似「总是会」、「永远不会」或「必须是」这样的短语，表明某个想法没有受到质疑，而实际上它可能需要被挑战。使用「基于」或「通常的情况」这样的短语，表明存在可挑战的假设。

当假设的数量开始减少时，可以问：「还有什么看起来如此显而易见，以至于通常不会想到去挑战它？」如果没人能识别出更多假设，那么就意味着我们假设这些假设不存在，而这本身也是可以挑战的假设。

在识别出所有假设后，批判性地检查每一个并问自己：

- 为什么我对这个假设的正确性感到自信？
- 在什么情况下这个假设可能是不准确的？
- 它过去可能是真的，但现在不再适用吗？
- 我对这个假设的信心有多大？
- 如果这个假设被证明是无效的，将对分析产生多大影响？

将每个假设归类到以下三类之一：

基本上可以分为三类：坚实的（S），正确但有一些注意事项的（C），以及不支持或有问题的 —— 也就是「关键不确定性」（U）。我们需要对假设列表进行细化，删除那些经不起推敲的假设，并添加讨论中出现的新假设。如果某个假设引发了大量讨论，可以考虑将其分解为两个假设或重新措辞，使其更明确。尤其要强调那些如果错误会导致分析结论改变的假设。还可以考虑将关键不确定性转化为情报收集需求或研究课题。

在结束分析时，要记住，你的分析结论的准确性取决于推理链中最薄弱环节的准确性。要审查你的假设，评估证据的质量和来源的可靠性，并考虑问题的整体难度和复杂性。然后粗略估计你的分析结论出错的概率，并用这个数字来计算结论准确的概率。比如，如果有四分之三（75%）的机会是正确的，那么就有四分之一（25%）的机会是错误的。关注我们可能出错的方式和原因，有助于克服人类不愿承认错误的自然倾向。

图 7.1 显示了 1990 年代 Wen Ho Lee 间谍案中一些明显有缺陷的假设，以及进一步调查显示的这些假设的内容。关键假设检查可以在更早阶段发现针对 Lee 的案件中的弱点。

与其他技术的关系

关键假设检查经常与其他技术结合使用，因为假设在所有结构化分析工作中都非常重要。确保假设的准确性是至关重要的。例如，当某个假设对于分析至关重要，而对其有效性仍存在疑问时，可能需要在进行关键假设检查后进行「假设如何」分析。想象一个未来（或现在）假设是错误的情况。是什么原因导致假设出错，如何发生的，以及会带来什么后果？

图 7.1 关键假设检查：温和李的案例来源：Pherson Associates, LLC, 2019。

关键假设检查与 ACH 之间存在特别值得注意的互动。关键假设需要作为「证据」包含在 ACH 矩阵中，以确保矩阵能够准确反映分析师的思维。在填写 ACH 矩阵时，假设通常会在讨论相关信息时浮现。当分析师评估某一证据与假设的一致性或不一致性时，通常会发现这种评估依赖于某个假设。经典象限压缩™（第 8 章）、简单场景、可能性锥以及假设倒置（第 9 章）都利用假设及其反面来生成多种解释或结果。

这种技术的起源虽然假设长期以来一直是分析的关注点，但直到 1990 年代后期才开发出一种专门关注假设的分析技术。本书中对关键假设检查的讨论来自 Randolph H. Pherson 的《分析工具和技术手册》第五版（弗吉尼亚州泰森：Pherson Associates, LLC, 2019）。

### 7.2 Chronologies and Timelines

A Chronology is a list that places events or actions in the order in which they occurred, usually in narrative or bulleted format. A Timeline is a graphic depiction of those events put in context of the time of the events and the time between events. Both are used to identify trends or relationships among the events or actions and, in the case of a Timeline, among the events and actions as well as other developments in the context of the overarching intelligence problem.

When to Use It

Chronologies and Timelines aid in organizing events or actions. The techniques are useful whenever analysts need to understand the timing and sequence of relevant events. They can also reveal significant events or important gaps in the available information. The events may or may not have a cause-and-effect relationship.

Chronologies and Timelines are usually developed at the onset of an analytic task to ascertain the context of the activity under review. They can be used in postmortems to break down the stream of reporting, find the causes for analytic failures, and highlight significant events after an intelligence or business surprise. Chronologies and Timelines are also useful for organizing information in a format that can be readily understood in a briefing or when presenting evidence to a jury.

Value Added

Chronologies and Timelines help analysts identify patterns and correlations among events. Analysts can use them to relate seemingly disconnected events to the big picture; to highlight or identify significant changes; or to assist in the discovery of trends, developing issues, or anomalies. They can serve as a catchall for raw data when the meaning of the data is not yet clear. Multiple-level Timelines allow analysts to track concurrent events that may affect one another.

The activities on a Timeline can lead an analyst to hypothesize the existence of previously unknown events. In other words, the series of known events may make sense only if other previously unknown events had occurred. The analyst can then look for other indicators of those missing events.

Chronologies and Timelines are useful tools analysts can use to counter the impact of cognitive biases and heuristics, including accepting data as true without assessing its credibility because it helps "make the case" (Evidence Acceptance Bias), seeing patterns in random events as systematic and part of a coherent story (Desire for Coherence and Uncertainty Reduction), and providing quick and easy answers to difficult problems (Mental Shotgun). It can also mitigate the impact of several intuitive traps, including giving too much weight to first impressions or initial data that attracts our attention at the time (Relying on First Impressions), not paying sufficient attention to the impact of the absence of information (Ignoring the Absence of Information), and discarding or ignoring information that is inconsistent with what one would expect to see (Ignoring Inconsistent Evidence).

The Method

Chronologies and Timelines are effective yet simple ways to order incoming information when processing daily message traffic. A Microsoft Word document or an Excel spreadsheet can log the results of research and marshal evidence. Tools such as the Excel drawing function or Analysts' Notebook can be helpful in drawing the Timeline. Follow these steps:

When researching the problem, ensure that the relevant information is listed with the date or order in which it occurred. It is important to properly reference the data to help uncover potential patterns or links. Be sure to distinguish between the date the event occurred and the date the report was received. Review the Chronology or Timeline by asking the following questions:

What are the temporal distances between key events? If "lengthy," what caused the delay? Are there missing pieces of data that may fill those gaps that should be collected? Was information overlooked that may have had an impact on or be related to the events? Conversely, if events seem to have happened more rapidly than expected or if some of the events do not appear to be related, is it possible that the analyst has information related to multiple event Timelines? Does the Timeline have all the critical events that are necessary for the outcome to occur? When did the information become known to the analyst or a key player? Are there information or intelligence gaps? Are there any points along the Timeline when the target is particularly vulnerable to the collection of intelligence or information or countermeasures? What events outside this Timeline could have influenced the activities? If preparing a Timeline, synopsize the data along a horizontal or vertical line. Use the space on both sides of the line to highlight important analytic points. For example, place facts above the line and points of analysis or commentary below the line. Alternatively, contrast the activities of different groups, organizations, or streams of information by placement above or below the line. If multiple actors are involved, you can use multiple lines, showing how and where they converge. For example, multiple lines could be used to show (1) the target's activities, (2) open source reporting about the events, (3) supplemental classified or proprietary information, and (4) analytic observations or commentary. Look for relationships and patterns in the data connecting persons, places, organizations, and other activities. Identify gaps or unexplained time periods, and consider the implications of the absence of evidence. Prepare a summary chart detailing key events and key analytic points in an annotated Timeline.

Potential Pitfalls

In using Timelines, analysts may assume, incorrectly, that events following earlier events were caused by the earlier events. Also, the value of this technique may be reduced if the analyst lacks imagination in identifying contextual events that relate to the information in the Chronology or Timeline.

Description Figure 7.2 Timeline Estimate of Missile Launch Date Source: Pherson Associates, LLC, 2019. Note: A TEL is a transporter, erector, and launcher for missiles.

Example

A team of analysts working on strategic missile forces knows what steps are necessary to prepare for and launch a nuclear missile. (See Figure 7.2 .) The analysts have been monitoring a country they believe is close to testing a new variant of its medium-range surface-to-surface ballistic missile. They have seen the initial steps of a test launch in mid-February and decide to initiate a concentrated watch of the primary and secondary test launch facilities. Observed and expected activities are placed into a Timeline to gauge the potential dates of a test launch. The analysts can thus estimate when a possible missile launch may occur and make decision makers aware of indicators of possible activity.

Origins of This Technique

Chronologies and Timelines are well-established techniques used in many fields. The information here is from M. Jones, "Sorting, Chronologies, and Timelines," The Thinker's Toolkit (New York: Three Rivers Press, 1998), chapter 6 ; and from Pherson Associates training materials.

7.2 时间表与时间线

时间表是一种按事件或行动发生顺序排列的列表，通常以叙述或项目符号的形式展示。时间线则是这些事件的图形表示，展示了事件发生的时间和事件之间的时间间隔。两者都用于识别事件或行动之间的趋势或关系，而时间线还可以揭示事件和行动在整体情报问题背景下的其他发展之间的关系。

使用时机时间表和时间线有助于组织事件或行动。当分析人员需要了解相关事件的时间和顺序时，这些工具非常有用。它们还可以揭示重大事件或信息中的重要缺失。这些事件可能存在或不存在因果关系。

时间表和时间线通常在分析任务开始时创建，以确定所研究活动的背景。它们可以用于事后分析，分解报告流，找出分析失败的原因，并在情报或商业意外之后突出重大事件。时间表和时间线还可以将信息组织成易于在简报中理解或在向陪审团展示证据时使用的格式。

附加价值时间表和时间线帮助分析人员识别事件之间的模式和关联。分析人员可以使用它们将看似无关的事件与整体情况联系起来；突出或识别重大变化；或帮助发现趋势、发展中的问题或异常。它们可以作为原始数据的汇总，当数据的意义尚不清楚时使用。多层次的时间线允许分析人员跟踪可能相互影响的并发事件。

时间轴上的活动可能会让分析人员推测以前未曾发现的事件。换句话说，已知事件的发生往往意味着可能有一些我们还不知道的事件发生过。于是，分析人员就会去寻找这些未知事件的线索。

时间顺序和时间轴是分析人员用来对抗认知偏见和启发法的有力工具。这些偏见和启发法包括：因为数据有助于证明某个观点而盲目接受数据为真（证据接受偏见）；在随机事件中看出系统性模式并将其视作一个连贯的故事（渴望连贯性和减少不确定性）；以及为复杂问题提供快速和简单的答案（心智霰弹枪）。时间轴还能减轻几种直觉陷阱的影响，包括：过度依赖第一印象或最初吸引我们注意的数据（依赖第一印象）；不重视信息缺失的影响（忽视信息缺失）；以及忽视与预期不一致的信息（忽视不一致证据）。

方法时间顺序和时间轴是处理日常信息流时既简单又有效的整理方法。你可以使用 Microsoft Word 文档或 Excel 电子表格来记录研究结果和整理证据。像 Excel 绘图功能或 Analysts' Notebook 这样的工具对绘制时间轴很有帮助。请按照以下步骤操作：

在进行研究时，确保将相关信息按其发生日期或顺序列出。正确引用数据以帮助发现潜在模式或关联是非常重要的。一定要区分事件发生的日期和收到报告的日期。可以通过以下问题来审查时间顺序或时间轴：

关键事件之间的时间间隔是多少？如果时间间隔很长，是什么原因导致的延迟？是否存在需要收集的缺失数据来填补这些空白？是否有被忽略的信息可能影响事件或与事件有关？相反，如果事件发生速度比预期快，或者某些事件似乎没有关联，是否可能分析师掌握了与多个事件时间线相关的信息？时间线是否包含所有导致结果发生的关键事件？分析师或关键人物何时得知这些信息？是否存在信息或情报的空白？在时间线的某些点上，目标是否特别容易受到情报或信息收集或反制措施的影响？时间线之外的事件是否可能影响活动？如果需要准备时间线，请沿水平或垂直方向总结数据。利用线两侧的空间突出重要的分析点。例如，将事实放在线上方，将分析或评论点放在线下方。或者，通过线上或线下位置对比不同团体、组织或信息流的活动。如果涉及多个行为者，可以使用多条线，显示它们如何以及在哪里交汇。例如，可以用多条线分别表示（1）目标的活动，(2）关于事件的公开报道，(3）补充的机密或专有信息，以及（4）分析观察或评论。寻找连接人员、地点、组织和其他活动的数据中的关系和模式。识别差距或无法解释的时间段，并考虑证据缺失的影响。准备一张详细说明关键事件和关键分析点的注释时间线图。

潜在的陷阱

在使用时间线时，分析师可能会错误地认为后续事件是由之前的事件引起的。如果分析师在识别时间顺序或时间线中的背景事件时缺乏想象力，这种技术的有效性可能会降低。

图 7.2 导弹发射日期估计的时间线来源：Pherson Associates, LLC, 2019。注意：TEL 是指导弹的运输、竖立和发射器。

示例一个研究战略导弹部队的分析团队清楚地知道准备和发射核导弹的步骤。（见图 7.2。）他们一直在监视一个可能接近测试其中程地对地弹道导弹新变种的国家。分析师在二月中旬观察到了测试发射的初步步骤，并决定对主要和次要测试发射设施进行重点监视。将观察到的和预期的活动放入时间线中，以评估可能的测试发射日期。通过这种方式，分析师可以估算可能的导弹发射时间，并提醒决策者注意可能的活动迹象。

这种技术的起源时间顺序和时间线是许多领域中广泛使用的技术。这些信息来自 M. Jones 的《排序、时间顺序和时间线》，《思想者的工具箱》（纽约：三河出版社，1998）第 6 章；以及 Pherson Associates 的培训材料。

### 7.3 Cross-Impact Matrix

The Cross-Impact Matrix helps analysts deal with complex problems when "everything is related to everything else." By using this technique, analysts and decision makers can systematically examine how each factor in a context influences all other factors to which it appears related.

When to Use It

The Cross-Impact Matrix is useful early in a project when a group is still in a learning mode trying to sort out a complex situation. Whenever a brainstorming session or other meeting is held to identify all the variables, drivers, or players that may influence the outcome of a situation, the next logical step is to use a Cross-Impact Matrix to examine the interrelationships among each of these variables. A group discussion of how each pair of variables interacts can be an enlightening learning experience and a good basis on which to build ongoing collaboration. How far one goes in completing the matrix and producing a description of the effects associated with each variable may vary depending upon the nature and significance of the project. At times, just the discussion is adequate.

Analysis of cross-impacts is useful when the following occurs:

A situation is in flux, and analysts need to understand all the factors that might influence the outcome. This requires understanding how all the factors relate to one another, and how they might influence one another. A situation is stable, and analysts need to identify and monitor all the factors that could upset that stability. This, too, requires understanding how the various factors might interact to influence one another. A significant event has just occurred, and analysts need to understand the implications of the event. What other significant forces are influenced by the event, and what are the implications of this influence?

Value Added

When analysts are estimating or forecasting future events, they consider the dominant forces and potential future events that might influence an outcome. They then weigh the relative influence or likelihood of these forces or events, often considering them individually without regard to potentially important interactions. The Cross-Impact Matrix provides a context for the discussion of these interactions. This discussion often reveals that variables or issues once believed to be simple and independent are interrelated. The sharing of information during a discussion of each potential cross-impact can provide an invaluable learning experience. For this reason alone, the Cross-Impact Matrix is a useful tool that can be applied at some point in almost any study that seeks to explain current events or forecast future outcomes.

The Cross-Impact Matrix provides a structure for managing the complexity that makes most analysis so difficult. It requires that analysts clearly articulate all assumptions about the relationships among variables. Doing so helps analysts defend or critique their conclusions by tracing the analytical argument back through a path of underlying premises.

Use of the Cross-Impact Matrix is particularly effective in helping analysts avoid being influenced by heuristics such as stopping the search for a cause when a seemingly satisfactory answer is found (Premature Closure), selecting the first answer that appears "good enough" (Satisficing), and seeing patterns in random events as systematic and part of a coherent world (Desire for Coherence and Uncertainty Reduction). It can also provide a powerful antidote to several intuitive pitfalls, including overinterpreting conclusions from a small sample of data (Overinterpreting Small Samples), giving too much weight to first impressions or initial data that appears important at the time (Relying on First Impressions), and continuing to hold to a judgment when confronted with additional or contradictory evidence (Rejecting Evidence).

The Method

Assemble a group of analysts knowledgeable on various aspects of the subject. The group brainstorms a list of variables or events that would likely have some effect on the issue being studied. The project coordinator then creates a matrix and puts the list of variables or events down the left side of the matrix and the same variables or events across the top.

The group then fills out the matrix, considering, and then recording, the relationship between each variable or event and every other variable or event. For example, does the presence of Variable 1 increase or diminish the influence of Variables 2, 3, 4, and so on? Or does the occurrence of Event 1 increase or decrease the likelihood of Events 2, 3, 4, and so forth? If one variable does affect the other, the positive or negative magnitude of this effect can be recorded in the matrix by entering a large or small + or a large or small – in the appropriate cell (or by making no marking at all if there is no significant effect). The terminology used to describe the relationship between each pair of variables or events is based on whether it is "enhancing," "inhibiting," or "unrelated."

The matrix shown in Figure 7.3 has six variables, with thirty possible interactions. Note that the relationship between each pair of variables is assessed twice, as the relationship may not be symmetric. That is, the influence of Variable 1 on Variable 2 may not be the same as the impact of Variable 2 on Variable 1. It is not unusual for a Cross-Impact Matrix to have substantially more than thirty possible interactions, in which case careful consideration of each interaction can be time-consuming.

Description Figure 7.3 Cross-Impact Matrix

Analysts should use the Cross-Impact technique to focus on significant interactions between variables or events that may have been overlooked, or combinations of variables that might reinforce one another. Combinations of variables that reinforce one another can lead to surprisingly rapid changes in a predictable direction. On the other hand, recognizing that there is a relationship among variables and the direction of each relationship may be sufficient for some problems.

The depth of discussion and the method used for recording the results are discretionary. Each depends upon how much you are learning from the discussion, which will vary from one application of this matrix to another. If the group discussion of the likelihood of these variables or events and their relationships to one another is a productive learning experience, keep it going. If key relationships are identified that are likely to influence the analytic judgment, fill in all cells in the matrix and take good notes. If the group does not seem to be learning much, cut the discussion short.

As a collaborative effort, team members can conduct their discussion—and periodically review—their key findings online. As time permits, analysts can enter new information or edit previously entered information about the interaction between each pair of variables. This record will serve as a point of reference or a memory jogger throughout the project.

Relationship to Other Techniques

Matrices as a generic technique with many types of applications are discussed in chapter 5 . The use of a Cross-Impact Matrix as described here frequently follows some form of brainstorming at the start of an analytic project. Elicit the assistance of other knowledgeable analysts in exploring all the relationships among the relevant factors identified in the brainstorming session. Analysts can build on the discussion of the Cross-Impact Matrix by developing a visual Mind Map or Concept Map of all the relationships.

See also the discussion of the Complexity Manager technique in chapter 10 . An integral part of the Complexity Manager technique is a form of Cross-Impact Analysis that takes the analysis a step further toward an informed conclusion.

Origins of This Technique

The Cross-Impact Matrix technique was developed in the 1960s as one element of a quantitative futures analysis methodology called Cross-Impact Analysis. Richards J. Heuer Jr. became familiar with it when the CIA was testing the Cross-Impact Analysis methodology. He started using it as an intelligence analysis technique, as described here, more than forty years ago. For simple instructions for using the Cross-Impact Matrix and printable templates, go to http://discoveryoursolutions.com/toolkit/cross_impact_matrix.html.

7.3 交叉影响矩阵

交叉影响矩阵是一种帮助分析师处理复杂问题的工具，特别是在所有因素都相互关联的情况下。通过这种方法，分析师和决策者可以系统地检查每个因素如何影响其他相关因素。

使用时机在项目初期，当团队还在摸索和理解复杂情况时，交叉影响矩阵非常有用。比如，在头脑风暴或其他会议中，团队识别出可能影响结果的所有变量、驱动因素或参与者后，接下来就可以使用交叉影响矩阵来分析这些变量之间的相互关系。讨论每对变量如何相互作用的过程，不仅能让团队成员学到很多，还能为后续的合作打下良好基础。需要完成矩阵的程度和详细描述每个变量影响的必要性，取决于项目的重要性和复杂程度。有时，仅仅是讨论这些关系就已足够。

交叉影响分析在以下情况下特别有用：

当情况在变化时，分析师需要了解所有可能影响结果的因素。这需要理解所有因素之间的关系及其相互影响。当情况保持稳定时，分析师需要识别和监控可能破坏稳定的因素。这也需要理解各种因素如何相互作用以影响彼此。当发生重大事件后，分析师需要理解事件的影响。有哪些其他重要因素受到了影响？这些影响意味着什么？

附加值

当分析师在估算或预测未来事件时，他们会考虑主要因素和可能影响结果的潜在事件。他们会权衡这些因素或事件的影响或可能性，通常单独考虑，而不顾及潜在的重要互动。交叉影响矩阵为讨论这些互动提供了一个框架。通过这种讨论，通常可以发现原本认为简单和独立的变量或问题实际上是相互关联的。在讨论每个潜在的交叉影响时，共享信息可以带来宝贵的学习经验。因此，交叉影响矩阵在几乎所有试图解释当前事件或预测未来结果的研究中都是一个有用的工具。

交叉影响矩阵为处理复杂性提供了结构，这也是为什么大多数分析如此困难。它要求分析师清晰地表达关于变量之间关系的所有假设。这有助于分析师通过回溯分析路径来捍卫或评估他们的结论。

使用交叉影响矩阵（Cross-Impact Matrix）可以有效帮助分析人员避免一些常见的思维偏误。比如，当找到一个看似满意的答案时，不会过早停止寻找原因（过早结束）；不会选择第一个看起来「足够好」的答案（满意化）；也不会将随机事件误认为是系统性模式，认为它们是一个连贯世界的一部分（追求连贯性和减少不确定性）。此外，它还能有效防止几种直觉陷阱，包括从小样本数据中得出过度结论（过度解读小样本）、过于依赖第一印象或初始数据（依赖第一印象），以及面对额外或矛盾证据时仍坚持原有判断（拒绝证据）。

方法首先，召集一组对该主题各方面都有所了解的分析人员。小组成员进行头脑风暴，列出可能对研究问题产生影响的变量或事件。然后，项目协调员创建一个矩阵，将这些变量或事件的列表放在矩阵的左侧，并将相同的变量或事件放在顶部。

然后小组填写矩阵，考虑并记录变量或事件之间的关系。例如，变量 1 的存在是否会增加或减少变量 2、3、4 等的影响？或者事件 1 的发生是否会增加或减少事件 2、3、4 等的可能性？如果一个变量确实影响了另一个变量，可以通过在相应的单元格中输入大 +、小 +、大 – 或小 – 来记录这种正面或负面的影响（如果没有显著影响，则不做任何标记）。描述每对变量或事件关系的术语基于它们是「增强的」、「抑制的」还是「无关的」。

图 7.3 显示的矩阵包含六个变量，有三十种可能的交互。注意，每对变量之间的关系被评估了两次，因为这种关系可能不是对称的。也就是说，变量 1 对变量 2 的影响可能与变量 2 对变量 1 的影响不同。对于交叉影响矩阵来说，超过三十个可能的交互并不罕见，这种情况下，对每个交互进行仔细考虑可能会非常耗时。

图 7.3 交叉影响矩阵描述分析师应使用交叉影响技术来关注可能被忽视的变量或事件之间的重要交互，或者可能相互强化的变量组合。相互强化的变量组合可能会导致可预测方向的快速变化。另一方面，认识到变量之间的关系及其方向对于某些问题来说可能已经足够。

讨论的深度和记录结果的方法可以灵活掌握。这取决于你从讨论中获得的知识量，这在不同应用场景下会有所不同。如果小组讨论这些变量或事件的可能性及其相互关系是一个有成效的学习过程，可以继续讨论。如果确定了可能影响分析判断的关键关系，请填写矩阵中的所有单元格并做好记录。如果小组讨论没有产生太多新见解，可以缩短讨论时间。

团队成员可以在线进行协作讨论，并定期回顾他们的关键发现。时间允许时，分析师可以输入新信息或编辑之前记录的关于每对变量之间相互作用的信息。这些记录将在整个项目中作为参考或提醒。

与其他技术的关系第 5 章讨论了矩阵作为一种通用技术的多种应用类型。这里描述的交叉影响矩阵的使用通常在分析项目开始时进行头脑风暴之后。可以借助其他有经验的分析师来探索头脑风暴会议中确定的相关因素之间的关系。分析师可以通过开发一个所有关系的视觉思维导图或概念图来扩展对交叉影响矩阵的讨论。

另见第 10 章中关于复杂性管理技术的讨论。复杂性管理技术的一个重要部分是交叉影响分析，它将分析进一步推向一个知情的结论。

这种技术的起源

Cross-Impact Matrix 技术开发于 1960 年代，是一种称为 Cross-Impact Analysis 的定量未来分析方法的一部分。Richards J. Heuer Jr. 在 CIA 测试 Cross-Impact Analysis 方法时，熟悉了这项技术。从四十多年前开始，他就将其作为情报分析技术使用，正如这里描述的那样。有关使用 Cross-Impact Matrix 的简单说明和可打印模板，请访问 http://discoveryoursolutions.com/toolkit/cross_impact_matrix.html。

### 7.4 Multiple Hypothesis Generation

In broad terms, a hypothesis is a potential explanation or conclusion that is to be tested by collecting and analyzing evidence. It is a declarative statement that has not been established as true—an "educated guess" based on observation to be supported or refuted by more observation or through experimentation.

A good hypothesis should satisfy the following criteria represented by the mnemonic STOP:

S tatement, not a question. T estable and falsifiable. O bservation—and knowledge-based. P redicts anticipated results clearly.

Hypothesis Generation should be an integral part of any rigorous analytic process because it helps the analyst think broadly and creatively about a range of possibilities and avoid being surprised when common wisdom turns out to be wrong. The goal is to develop a list of hypotheses that can be scrutinized and tested over time against existing relevant information as well as new data that may become available in the future. Analysts should strive to make the hypotheses mutually exclusive and the list as comprehensively exhaustive as possible—thereby satisfying the imperative that hypotheses should be M utually E xclusive and C omprehensively E xhaustive (MECE).

There are many techniques used to generate hypotheses, including techniques discussed elsewhere in this book, such as Venn Analysis, Cluster Brainstorming, several forms of Foresight analysis, Classic Quadrant Crunching™, Starbursting, Delphi Method, and Decision Trees. This section discusses techniques developed specifically for hypothesis generation and then presents the method for three different techniques: Simple Hypotheses, Quadrant Hypothesis Generation, and the Multiple Hypotheses Generator ® .

When to Use It

Gaining confidence in a hypothesis is not a function solely of accumulating evidence in its favor but in showing that situations that could establish its falsity do not, in fact, happen. Analysts should develop multiple hypotheses at the start of a project when the following occurs:

the importance of the subject matter requires a systematic analysis of all alternatives, many factors or variables are involved in the analysis, a high level of uncertainty exists about the outcome, analysts or decision makers hold competing views.

Simple Hypotheses is often used to broaden the spectrum of plausible hypotheses. It utilizes Cluster Brainstorming to create potential hypotheses based on affinity groups. Quadrant Hypothesis Generation works best when the problem has two key drivers. In these circumstances, a 2-×-2 matrix is adequate for creating hypotheses that reflect the situations posited in each quadrant. The Multiple Hypotheses Generator ® is particularly helpful when there is a reigning lead hypothesis.

Value Added

Multiple Hypothesis Generation provides a structured way to generate a comprehensive set of mutually exclusive hypotheses. This can increase confidence that an important hypothesis has not been overlooked. It can also help reduce cognitive biases, such as seeking only the information that is consistent with the lead hypothesis (Confirmation Bias), accepting a given value of something or a lead hypothesis as a proper—or the only—starting point for conducting an analysis (Anchoring Effect), stopping the search for a cause when a seemingly satisfactory answer is found before sufficient information and proper analysis can be performed (Premature Closure), and seeing patterns in random events as systematic and part of a coherent story (Desire for Coherence and Uncertainty Reduction). When the techniques are used properly, choosing a lead hypothesis becomes much less critical than making sure that analysts have considered all possible explanations.

The techniques are particularly useful in helping intelligence analysts overcome some classic intuitive traps, such as the following:

Assuming a Single Solution. Most analysts quickly develop an initial lead hypothesis to explain the topic at hand and continue to test the initial hypothesis as new information appears. A good analyst will simultaneously consider a few alternatives. This helps ensure that no diagnostic information is ignored because it does not support the lead hypothesis. For example, when individuals move large amounts of money from China to other countries, financial analysts are likely to suspect that ill-begotten monies are being laundered. On some occasions, however, the funds could have been obtained through legitimate means; this alternative hypothesis should be in play until it can be disproven by the facts of the case. Overinterpreting Small Samples. Analysts frequently are pressed to "make a call" when there is insufficient data to support the assessment. In such cases, a preferred strategy is to offer several possible alternatives. The U.S. Intelligence Community—and the world as a whole—would have been better served if the National Intelligence Council in its Iraq WMD National Intelligence Estimate had proffered three (and not just the first two) hypotheses that (1) Iraq had a substantial WMD program and the intelligence community had not yet found the evidence, (2) Iraq had a more modest program but could readily accelerate production in areas that had fallen fallow, or (3) Iraq had no WMD program and reporting to the contrary was deception. Projecting Past Experiences. When under pressure, analysts can select a hypothesis primarily because it avoids a previous error or replicates a past success. A prime example of this was the desire not to repeat the mistake of underestimating Saddam Hussein's WMD capabilities in the run-up to the second U.S. war with Iraq. Relying on First Impressions. When pressed for time, analysts can also fall into the trap of giving too much weight to first impressions or initial data that attracts their attention at the time. Analysts are especially susceptible to this bias if they have recently visited a country or have viewed a particularly vivid or disturbing video.

7.4.1 The Method: Simple Hypotheses

To use the Simple Hypotheses method, define the problem and determine how the hypotheses will be used at the beginning of the project. Hypotheses can be applied several ways: (1) in an Analysis of Competing Hypotheses, (2) in some other hypothesis-testing project, (3) as a basis for developing scenarios, or (4) as a means to draw attention to particularly positive or worrisome outcomes that might arise. Figure 7.4.1 illustrates the process.

Gather together a diverse group to review the available information and explanations for the issue, activity, or behavior that you want to evaluate. In forming this diverse group, consider including different types of expertise for different aspects of the problem, cultural expertise about the geographic area involved, different perspectives from various stakeholders, and different styles of thinking (left brain/right brain, male/female). Then do the following:

Ask each member of the group to write down on an index card up to three alternative explanations or hypotheses. Prompt creative thinking by using the following:

Applying theory. Drawing from the study of many examples of the same phenomenon.

Description Figure 7.4.1 Simple Hypotheses Source: Globalytica, LLC, 2019. Comparison with historical analogies. Comparing current events to historical precedents. Situational logic. Representing all the known facts and an understanding of the underlying forces at work at the given time and place. Collect the cards and display the results on a whiteboard. Consolidate the list to avoid any duplication. Employ additional individual and group brainstorming techniques, such as Cluster Brainstorming, to identify key forces and factors. Aggregate the hypotheses into affinity groups and label each group. Use problem restatement and consideration of the opposite to develop new ideas. Update the list of alternative hypotheses. If the hypotheses will be used in Analysis of Competing Hypotheses, strive to keep them mutually exclusive—that is, if one hypothesis is true, all others must be false. Have the group clarify each hypothesis by asking the journalist's classic list of questions: Who, What, How, When, Where, and Why? Select the most promising hypotheses for further exploration.

7.4.2 The Method: Quadrant Hypothesis Generation

Use the four-quadrant technique to identify a basic set of hypotheses when two key driving forces are likely to determine the outcome of an issue. The technique identifies four potential scenarios that represent the extreme conditions for each of the two major drivers. It spans the logical possibilities inherent in the relationship and interaction of the two driving forces, thereby generating options that analysts otherwise may overlook.

Quadrant Hypothesis Generation is easier and quicker to use than the Multiple Hypotheses Generator ® , but it is limited to cases in which the outcome of a situation will be determined by two major driving forces—and it depends on the correct identification of these forces. The technique is less effective when more than two major drivers are present or when analysts differ over which forces constitute the two major drivers.

The steps for using Quadrant Hypothesis Generation follow:

Identify two main drivers by using techniques such as Cluster Brainstorming or by surveying subject-matter experts. A discussion to identify the two main drivers can be a useful exercise. Construct a 2-×-2 matrix using the two drivers. Think of each driver as a continuum from one extreme to the other. Write the extremes of each of the drivers at the end of the vertical and horizontal axes. Fill in each quadrant with the details of what the end state would be if shaped by the two extremes of the drivers. Develop signposts or indicators that show whether events are moving toward one of the hypotheses. Use the signposts or indicators of change to develop intelligence collection strategies or research priorities to determine the direction in which events are moving.

Description Figure 7.4.2 Quadrant Hypothesis Generation: Four Hypotheses on the Future of Iraq

Figure 7.4.2 shows an example of a Quadrant Hypothesis Generation chart. In this case, analysts have been tasked with developing a paper to project possible futures for Iraq, focusing on the potential end state of the government. The analysts have identified and agreed upon the two key drivers in the future of the government: the level of centralization of the federal government and the degree of religious control of that government. They develop their quadrant chart and lay out the four logical hypotheses based on their decisions.

The four hypotheses derived from the quadrant chart can be stated as follows:

The final state of the Iraq government will be a centralized state and a secularized society. The final state of the Iraq government will be a centralized state and a religious society. The final state of the Iraq government will be a decentralized state and a secularized society. The final state of the Iraq government will be a decentralized state and a religious society.

7.4.3 The Method: Multiple Hypotheses Generator ®

The Multiple Hypotheses Generator ® is a technique for developing multiple alternatives for explaining an issue, activity, or behavior. Analysts often can brainstorm a useful set of hypotheses without such a tool, but the Multiple Hypotheses Generator ® may give greater confidence than other techniques that analysts have not overlooked a critical alternative or outlier. Analysts should employ the Multiple Hypotheses Generator ® to ensure that they have considered a broad array of potential hypotheses. In some cases, they may have considerable data and want to ensure that they have generated a set of plausible explanations consistent with all the data at hand. Alternatively, they may have been presented with a hypothesis that seems to explain the phenomenon at hand and been asked to assess its validity. The technique helps analysts rank alternative hypotheses from the most to least credible, focusing on those at the top of the list as those deemed most worthy of attention.

To use this method:

Gather a diverse group to define the issue, activity, or behavior under study. Often, it is useful to ask questions in the following ways:

What variations could be developed to challenge the lead hypothesis that . . .? What are the possible permutations that would flip the assumptions contained in the lead hypothesis that . . .? Identify the Who, What, and Why for the lead hypothesis. Then generate plausible alternatives for each relevant key component. Review the lists of alternatives for each of the key components; strive to keep the alternatives on each list mutually exclusive. Generate a list of all possible permutations, as shown in Figure 7.4.3 .

Figure 7.4.3 Multiple Hypotheses Generator ® : Generating Permutations Source: Globalytica, LLC, 2019. Discard any permutation that simply makes no sense. Evaluate the credibility of the remaining permutations by challenging the key assumptions of each component. Some of these assumptions may be testable themselves. Assign a "credibility score" to each permutation using a 1-to-5-point scale where 1 is low credibility and 5 is high credibility. Re-sort the remaining permutations, listing them from most credible to least credible. Restate the permutations as hypotheses, ensuring that each meets the criteria of a good hypothesis. Select from the top of the list those hypotheses most deserving of attention.

Potential Pitfalls

The value of this technique is limited to the ability of analysts to generate a robust set of alternative explanations. If group dynamics are flawed, the outcomes will be flawed. Whether the correct hypothesis will emerge from this process and analysts identify it as such cannot be guaranteed, but the prospect of the correct hypothesis being included in the set of hypotheses under consideration is greatly increased.

Relationship to Other Techniques

The product of any Foresight analysis process can be thought of as a set of alternative hypotheses. Quadrant Hypothesis Generation is a specific application of the generic method called Morphological Analysis, described in chapter 9 . Alternative Futures Analysis uses a similar quadrant chart approach to define four potential outcomes, and Multiple Scenarios Generation uses the approach to define multiple sets of four outcomes. Both of these techniques are also described in chapter 9 .

Origins of This Technique

The generation and testing of hypotheses is a key element of scientific reasoning. The Simple Hypotheses approach and Quadrant Hypothesis Generation are described in the Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019) and Pherson Associates training materials. The description of the Multiple Hypotheses Generator ® can be found in the fourth edition of the Handbook of Analytic Tools and Techniques (Reston, VA: Pherson Associates, LLC, 2015).

7.4 多重假设生成

假设，简单来说，是一种需要通过收集和分析证据来验证的潜在解释或结论。它是一种尚未被证实的陈述，可以看作是基于观察的「有根据的猜测」，需要通过进一步的观察或实验来支持或反驳。

一个好的假设应该满足以下标准，这些标准可以用缩略词 STOP 来表示：

S 表示声明，而不是问题。T 表示可测试和可证伪。O 表示基于观察和知识。P 表示清晰预测预期结果。

假设生成应该是任何严谨分析过程中的重要环节，因为它帮助分析人员广泛而有创意地思考各种可能性，避免在常识被证明错误时感到意外。目标是制定出一份可以随着时间推移根据现有相关信息以及未来可能获取的新数据进行审查和测试的假设列表。分析人员应努力使假设互相排斥，并使列表尽可能全面，以满足假设应该是互斥和全面穷尽（MECE）的要求。

有许多技术可以用来生成假设，包括本书其他部分讨论的技术，如韦恩分析、集群头脑风暴、前瞻分析的多种形式、经典象限压缩 ™、星爆法、德尔菲法和决策树。本节将讨论专门用于假设生成的技术，并介绍三种不同的生成方法：简单假设、象限假设生成和多重假设生成器 ®。

使用时机

获得对某个假设的信心不仅仅是通过积累支持该假设的证据，还需要证明那些可能推翻该假设的情况实际上并未发生。当以下情况出现时，分析人员应在项目初期提出多个假设：

- 该主题的重要性需要对所有备选方案进行系统的分析
- 分析涉及许多因素或变量
- 对结果存在高度的不确定性
- 分析人员或决策者对问题有不同的看法简单假设常用来扩大可能的假设范围。它通过集群头脑风暴方法，根据相似性小组创建潜在假设。当问题有两个关键驱动因素时，象限假设生成方法效果最佳。在这种情况下，使用一个 2×2 矩阵就足以创建反映每个象限情况的假设。当存在一个主导假设时，多重假设生成器 ® 特别有用。

附加值多重假设生成提供了一种结构化的方法，能够生成一组相互排斥且全面的假设。这可以增加对某个重要假设未被忽略的信心。它还可以帮助减少认知偏见，例如只寻找与主导假设一致的信息（确认偏差），接受某个事物的特定值或主导假设作为分析的唯一起点（锚定效应），在找到一个看似满意的答案之前停止寻找原因（过早终止），以及在随机事件中看到系统性和连贯故事的一部分（对连贯性和减少不确定性的渴望）。当这些技术被正确使用时，选择一个主导假设变得不那么重要，而更重要的是确保分析人员已经考虑了所有可能的解释。

这些技术对于情报分析员来说特别有用，可以帮助他们克服一些经典的直觉陷阱，例如以下几点：

假设只有一种解决方案。大多数分析师会迅速提出一个初步假设来解释当前的问题，并在新的信息出现时继续验证这一初步假设。优秀的分析师会同时考虑几种不同的假设，以确保不会因为某个假设不被支持而忽略任何诊断信息。例如，当个人将大量资金从中国转移到其他国家时，金融分析师可能会怀疑这些资金是通过非法手段获得的。然而，有时这些资金可能是通过合法手段获得的；在案件的事实证明这一点之前，这一替代假设应当被考虑。

过度解读小样本数据。分析师经常在数据不足以支持评估时被迫「做出判断」。此时，首选策略是提供几种可能的假设。如果国家情报委员会在其伊拉克大规模杀伤性武器国家情报评估中提出三种（而不仅仅是前两种）假设，美国情报界 —— 以及全世界 —— 将会受到更好的服务：（1）伊拉克有一个庞大的大规模杀伤性武器计划，而情报界尚未找到证据，(2）伊拉克有一个较小的计划，但可以很容易地加速那些已经荒废的领域的生产，或者（3）伊拉克没有大规模杀伤性武器计划，反对的报告是欺骗。

利用过去的经验。在压力很大时，分析师可能会选择一个假设，主要是因为它可以避免先前的错误或复制过去的成功。一个主要的例子是在第二次美伊战争前夕，不希望重复低估萨达姆·侯赛因的大规模杀伤性武器能力的错误。

依赖于第一印象。当时间紧迫时，分析师也可能陷入过分重视第一印象或当时吸引其注意的初步数据的陷阱。如果分析师最近访问了某个国家或观看了一段特别生动或令人不安的视频，他们尤其容易受到这种偏见的影响。

7.4.1 方法：简单假设在项目开始时，使用简单假设方法需要先定义问题，并确定将如何使用这些假设。假设可以通过以下几种方式应用：（1）进行竞争假设分析，（2）在其他假设测试项目中使用，（3）作为开发场景的基础，或（4）用于突出可能出现的特别积极或令人担忧的结果。图 7.4.1 展示了这一过程。

首先，召集一个多样化的小组，来审查与所评估问题、活动或行为相关的可用信息和解释。组成这个小组时，要考虑包括不同领域的专家，以便全面应对问题的各个方面；涉及区域的文化专家；不同利益相关者的多种观点；以及不同的思维方式（如左脑 / 右脑，男性 / 女性）。然后，按照以下步骤操作：

请小组成员每人在卡片上写下最多三种可替代的解释或假设。可以通过以下方法激发创造性思维：

- 应用理论：借鉴对同类现象的众多研究。

描述图 7.4.1 简单假设来源：Globalytica, LLC, 2019。对比当前事件与历史先例。通过情境逻辑，展示所有已知事实以及对特定时间和地点的潜在力量的理解。收集卡片并在白板上展示结果。合并列表以避免重复。使用额外的个人和小组头脑风暴技术，例如聚类头脑风暴，以识别关键力量和因素。将假设聚类成相似组并标记每个组。通过重新表述问题和考虑相反情况来产生新想法。更新替代假设列表。如果这些假设用于竞争假设分析，确保它们互相排斥，即一个假设为真时，其他假设必须为假。通过提出记者经典的「谁，什么，如何，何时，何地，为什么」问题，让小组澄清每个假设。选择最有潜力的假设进行进一步探索。

7.4.2 方法：象限假设生成当两个关键驱动因素可能决定问题的结果时，使用四象限技术来识别一组基本假设。该技术确定了四种可能情景，分别代表两个主要驱动因素的极端情况。它涵盖了两个驱动因素关系和相互作用中的所有逻辑可能性，从而生成分析人员可能忽略的选项。

Quadrant 假设生成方法比 Multiple Hypotheses Generator ® 使用起来更简单、更快捷，但它只适用于结果由两个主要驱动力决定的情况，并且依赖于正确识别这些驱动力。当存在两个以上的主要驱动因素或分析人员对哪些因素是主要驱动力有不同意见时，这种方法的效果会下降。

使用 Quadrant 假设生成方法的步骤如下：

1. 使用 Cluster Brainstorming 等技术或通过调查领域专家来识别两个主要驱动因素。讨论确定这两个主要驱动因素是一个有益的过程。
2. 使用这两个驱动因素构建一个 2×2 矩阵。将每个驱动因素视为从一个极端到另一个极端的连续体。在垂直和水平轴的末端写下每个驱动因素的极端。
3. 填写每个象限，描述在两个驱动因素的极端影响下可能出现的情况。
4. 设立标志或指标，判断事件是否朝着某一个假设发展。
5. 使用这些标志或变化指标来制定情报收集策略或研究重点，确定事件的发展方向。

描述图 7.4.2 Quadrant Hypothesis Generation：四个关于伊拉克未来的假设图 7.4.2 显示了一个 Quadrant 假设生成图表的示例。在这个案例中，分析人员被要求撰写一份关于伊拉克未来可能情况的报告，重点关注政府的潜在最终状态。分析人员识别并确定了政府未来的两个关键驱动因素：联邦政府的集中化程度和政府的宗教控制程度。他们构建了象限图表，并基于这些决定列出了四个逻辑假设。

从象限图中得出的四个假设如下：

伊拉克政府的最终形态可能是以下几种之一：中央集权且世俗化、中央集权且宗教化、分权且世俗化、分权且宗教化。

7.4.3 方法：多重假设生成器 ®

多重假设生成器 ® 是一种用于开发多种解释问题、活动或行为的替代方案的技术。尽管分析师通常无需这种工具也能头脑风暴出有用的假设，但使用多重假设生成器 ® 能确保不遗漏任何关键的替代方案或异常情况。分析师应该使用该工具来考虑广泛的潜在假设。有时，他们可能拥有大量数据，并希望生成一组与所有数据一致的合理解释。或者，他们可能已经有了一个假设，并需要评估其有效性。该技术帮助分析师按可信度对假设进行排序，重点关注那些最可信的。

使用该方法时：

召集一个多元化的小组来定义所研究的问题、活动或行为。通常，可以用以下方式提问：

可以开发哪些变体来挑战现有假设……？有哪些可能的排列方式可以推翻现有假设中的前提……？首先明确现有假设的「谁、什么、为什么」。然后为每个相关的关键部分生成合理的替代方案。查看每个关键部分的替代方案列表；确保每个列表上的替代方案彼此独立。生成所有可能的排列列表，如图 7.4.3 所示。

图 7.4.3 多假设生成器 ® ：生成排列来源：Globalytica, LLC, 2019。丢弃任何不合理的排列。通过质疑每个部分的关键假设来评估剩余排列的可信度。这些假设中的一些可能是可以测试的。使用 1 到 5 分的评分标准为每个排列分配「可信度分数」，其中 1 表示低可信度，5 表示高可信度。重新排列剩余的排列，从最可信到最不可信。将排列重新表达为假设，确保每个假设都符合良好假设的标准。从列表顶部选择最值得关注的假设。

潜在的问题这种技术的价值取决于分析师生成一组强大替代解释的能力。如果团队合作不良，结果也会受到影响。虽然不能保证正确的假设一定会从这个过程中浮现并被识别，但这种方法能大大增加正确假设被包含在考虑范围内的可能性。

与其他技术的关系

任何前瞻分析过程的结果都可以视为一组替代假设。象限假设生成是形态分析（Morphological Analysis）这一通用方法的具体应用，如第 9 章所述。替代未来分析（Alternative Futures Analysis）使用类似的象限图方法来定义四种潜在的结果，而多场景生成（Multiple Scenarios Generation）使用该方法来定义多个四种结果的集合。这两种技术也在第 9 章中有详细描述。

这种技术的起源生成和测试假设是科学推理的关键要素。简单假设方法和象限假设生成在《分析工具和技术手册》 第五版（弗吉尼亚州泰森斯：Pherson Associates, LLC, 2019）和 Pherson Associates 的培训材料中有详细描述。多假设生成器 ® 的描述可以在《分析工具和技术手册》 第四版（弗吉尼亚州雷斯顿：Pherson Associates, LLC, 2015）中找到。

### 7.5 Diagnostic Reasoning

Diagnostic Reasoning is the application of hypothesis testing to a new development, a single new item of information or intelligence, or the reliability of a source. It differs from Analysis of Competing Hypotheses (ACH) in that it is used to evaluate a single item of relevant information or a single source; ACH deals with an entire range of hypotheses and multiple items of relevant information.

When to Use It

Analysts should use Diagnostic Reasoning if they find themselves making a snap intuitive judgment while assessing the meaning of a new development, the significance of a new report, or the reliability of a stream of reporting from a new source. Often, much of the information used to support one's lead hypothesis turns out to be consistent with alternative hypotheses as well. In such cases, the new information should not—and cannot—be used as evidence to support the prevailing view or lead hypothesis.

The technique also helps reduce the chances of being caught by surprise. It ensures that the analyst or decision maker will have given at least some consideration to alternative explanations. The technique is especially important to use when an analyst—or decision maker—is looking for evidence to confirm an existing mental model or policy position. It helps the analyst assess whether the same information is consistent with other reasonable conclusions or with alternative hypotheses.

Value Added

The value of Diagnostic Reasoning is that it helps analysts balance their natural tendency to interpret new information as consistent with their existing understanding of what is happening—that is, the analyst's mental model. The technique prompts analysts to ask themselves whether this same information is consistent with other reasonable conclusions or alternative hypotheses. It is a common experience to discover that much of the information supporting belief in the most likely conclusion is of limited value because that same information is consistent with alternative conclusions. One needs to evaluate new information in the context of all possible explanations of that information, not just in the context of a well-established mental model.

The Diagnostic Reasoning technique helps the analyst identify the information that is essential to support a hypothesis and avoid the mistake of focusing attention on one vivid scenario or explanation while ignoring other possibilities or alternative hypotheses (Vividness Bias). When evaluating evidence, analysts tend to assimilate new information into what they currently perceive. Diagnostic Reasoning protects them from the traps of seeking only the information that is consistent with the lead hypothesis (Confirmation Bias) and selecting the first answer that appears "good enough" (Satisficing).

Experience can handicap experts because they often hold tightly to timeworn models—and a fresh perspective can be helpful. Diagnostic Reasoning helps analysts avoid the intuitive trap of assuming the same dynamic is in play when something seems to accord with an analyst's past experiences (Projecting Past Experiences). It also helps analysts counter the pitfall of continuing to hold to an analytic judgment when confronted with a mounting list of evidence that contradicts the initial conclusion (Rejecting Evidence) and dismissing information at first glance without considering all possible alternatives (Ignoring Inconsistent Evidence).

The Method

Diagnostic Reasoning is a process that focuses on trying to refute alternative judgments rather than confirming what you already believe to be true. Here are the steps to follow:

When you receive a potentially significant item of information, make a mental note of what it seems to mean (i.e., an explanation of why something happened or what it portends for the future). Make a quick, intuitive judgment based on your current mental model. Define the focal question. For example, Diagnostic Reasoning brainstorming sessions often begin with questions like

Are there alternative explanations for the lead hypothesis (defined as . . .) that would also be consistent with the new information, new development, or new source of reporting? Is there a reason other than the lead hypothesis that . . .? Brainstorm, either alone or in a small group, the alternative judgments that another analyst with a different perspective might reasonably deem to have a chance of being accurate. Make a list of these alternatives. For each alternative, ask the following question: If this alternative were true or accurate, how likely is it that I would have seen, but possibly ignored, information that was consistent with this alternative explanation? Make a tentative judgment based on consideration of these alternatives. If the new information is equally likely with each of the alternatives, the information has no diagnostic value and can be ignored. If the information is clearly inconsistent with one or more alternatives, those alternatives might be ruled out. Following this mode of thinking for each of the alternatives, decide which alternatives need further attention and which can be dropped from consideration or put aside until new information surfaces. Proceed by seeking additional evidence to refute the remaining alternatives rather than to confirm them.

Potential Pitfalls

When new information is received, analysts need to validate that the new information is accurate and not deceptive or intentionally misleading. It is also possible that none of the key information turns out to be diagnostic, or that all relevant information will not come to light.

Relationship to Other Techniques

Diagnostic Reasoning is an integral part of two other techniques: Analysis of Competing Hypotheses and Indicators Validation and Evaluation ( chapter 9 ). It is presented here as a separate technique to show that its use is not limited to those two techniques. It is a fundamental form of critical reasoning that should be widely used in intelligence analysis.

Origins of This Technique

Diagnostic Reasoning has been the principal method for medical problem solving for many years. For information on the role of Diagnostic Reasoning in the medical world, see the following publications: Albert S. Elstein, "Thinking about Diagnostic Thinking: A Thirty-Year Perspective," Advances in Health Science Education, published online by Springer Science+Business Media, August 11, 2009; and Pat Croskerry, "A Universal Model of Diagnostic Reasoning," Academic Medicine 84, no. 8 (August 2009).

7.5 诊断推理

诊断推理是指应用假设检验来评估一个新发展的单个信息、新情报，或来源的可靠性。它与竞争假设分析（ACH）不同，诊断推理专注于评估单一的相关信息或来源，而 ACH 则处理多个假设和相关信息。

使用时机当分析人员在评估新发展的意义、新报告的重要性或新来源的可靠性时，如果发现自己做出了快速的直觉判断，这时应考虑使用诊断推理。通常情况下，支持主要假设的信息也可能与其他假设一致。在这种情况下，新信息不能作为支持现有观点或主要假设的证据。

这种技术有助于减少意外情况的发生。它确保分析人员或决策者能够考虑到替代解释。尤其是在寻找证据来确认现有心理模型或政策立场时，这种方法显得尤为重要。它帮助分析人员评估相同的信息是否也支持其他合理的结论或假设。

附加价值

诊断推理的价值在于，它帮助分析员平衡自然倾向，将新信息解释为与现有理解一致的倾向，即分析员的心理模型。该技术促使分析员自问，这些信息是否也适用于其他合理的结论或替代假设。常见的情况是，许多支持最可能结论的信息实际上价值有限，因为它们同样可以支持其他结论。评估新信息时，需要考虑所有可能的解释，而不仅仅是现有的心理模型。

诊断推理技术帮助分析员识别支持假设的关键信息，避免只关注一个生动的场景或解释而忽略其他可能性或替代假设（生动性偏见）。在评估证据时，分析员往往会将新信息纳入现有认知中。诊断推理技术可以保护他们不陷入只寻找支持主要假设的信息（确认偏见）或选择第一个看起来「足够好」答案（满意）的陷阱。

经验有时会限制专家，因为他们通常坚持陈旧的模型，而新视角可能带来帮助。诊断推理帮助分析员避免在某些情况看似符合过去经验时，直觉上假设相同动态在起作用的陷阱（投射过去经验）。它还帮助分析员对抗在面对越来越多的反证时，继续坚持初始结论（拒绝证据）和在第一眼看到信息时不考虑所有可能替代方案而忽略信息（忽略不一致证据）的陷阱。

方法诊断推理是一种侧重于驳斥替代判断而不是确认已有信念的过程。以下是具体步骤：

当你收到一条可能重要的信息时，首先记下它的含义（即为什么发生某事或对未来的预示）。根据你当前的心理模型做一个快速的直觉判断。确定焦点问题。例如，诊断推理的头脑风暴会议通常从以下问题开始：

是否有其他解释可以替代主要假设（定义为……）并且也与新信息、新发展或新的报告来源一致？主要假设以外是否还有其他原因……？可以独自或在小组内头脑风暴，找出其他分析师从不同角度可能认为有合理性的替代判断，并列出这些替代方案。对于每个替代方案，问自己：如果这个替代方案是真实的，我有多大可能已经看到但忽略了与之相关的信息？根据这些替代方案做出初步判断。如果新信息在所有替代方案中都同样可能，那么该信息没有诊断价值，可以忽略。如果信息显然与一个或多个替代方案不一致，则可以排除这些替代方案。按照这种思路对每个替代方案进行分析，决定哪些需要进一步关注，哪些可以暂时忽略。接下来，通过寻找更多证据来驳斥剩余的替代方案，而不是确认它们。

潜在的陷阱

当分析师接收到新信息时，首先需要验证这些信息的准确性，并确保其没有欺骗性或故意误导的成分。也有可能所有关键信息都不具有诊断价值，或者重要信息没有全部显现出来。

与其他技术的关系诊断推理是竞争假设分析和指标验证与评估（第九章）的重要组成部分。尽管在这些技术中有广泛应用，但它作为一种独立的技术被单独介绍，目的是强调其在情报分析中的基础性和广泛应用。

该技术的起源多年来，诊断推理一直是解决医学问题的主要方法。关于诊断推理在医学领域的应用，可以参考以下文献：Albert S. Elstein 的《Thinking about Diagnostic Thinking：A Thirty-Year Perspective》，发表于 Springer Science+Business Media 的《Advances in Health Science Education》，2009 年 8 月 11 日在线出版；以及 Pat Croskerry 的《A Universal Model of Diagnostic Reasoning》，发表于《Academic Medicine》，2009 年 8 月，第 84 卷第 8 期。

### 7.6 Analysis of Competing Hypotheses

ACH is an analytic process that identifies a complete set of alternative hypotheses, systematically evaluates data that are consistent or inconsistent with each hypothesis, and proceeds by rejecting hypotheses rather than trying to confirm what appears to be the most likely hypothesis. The process of rejecting rather than confirming hypotheses applies to intelligence analysis the scientific principles advocated by Karl Popper, one of the most influential philosophers of science of the twentieth century. 4

ACH starts with the identification of a set of mutually exclusive alternative explanations or outcomes called hypotheses. The analyst assesses the consistency or inconsistency of each item of relevant information with each hypothesis, and then selects the hypothesis that best fits the relevant information. The scientific principle behind this technique is to proceed by trying to refute as many reasonable hypotheses as possible rather than to confirm what initially appears to be the most likely hypothesis. The most likely hypothesis is then the one with the least amount of inconsistent information—not the one with an abundance of supporting relevant information.

7.6 竞争性假设分析

竞争性假设分析（ACH）是一种分析方法，旨在识别一整套备选假设，并系统地评估每个假设与数据的一致性或不一致性。该方法通过排除假设来进行分析，而不是试图确认看起来最可能的假设。这种方法借鉴了 20 世纪著名科学哲学家卡尔·波普尔的科学原则，应用于情报分析领域。

ACH 的第一步是识别一组互斥的备选解释或结果，称为假设。分析师需评估每项相关信息与每个假设的一致性或不一致性，然后选择最符合这些信息的假设。这种技术的核心原则是尽可能反驳多个合理假设，而不是确认最初看起来最可能的假设。最终，最可能的假设是那些与之不一致的信息最少的假设，而不是拥有大量支持信息的假设。

When to Use It

ACH is appropriate for almost any analysis where there are alternative explanations for what has happened, is happening, or is likely to happen. Use it when the judgment or decision is so important that you cannot afford to be wrong or when you need a systematic approach to avoid being surprised by an unforeseen outcome. ACH is particularly appropriate when dealing with controversial issues and when analysts need to leave an audit trail to show what relevant information they considered and how they arrived at their analysis. If other analysts and decision makers disagree with the analysts' conclusions, an ACH matrix can help identify the precise area of disagreement. Subsequent discussion can then focus on the most important substantive differences.

ACH is most effective when there is a robust flow of data to absorb and evaluate. It is well suited for addressing questions about technical issues in the chemical, biological, radiological, and nuclear arenas, such as, "For which weapons' system is this part most likely being imported?" or, "Which type of missile system is Country X importing or developing?" The technique is useful for managing criminal investigations and determining which line of analysis is correct. ACH is particularly helpful when an analyst must deal with the potential for denial and deception, as it was initially developed for that purpose.

The technique can be used by a single analyst but is most effective with a small team that can challenge team members' evaluations of the relevant information. It structures and facilitates the exchange of information and ideas with colleagues in other offices or agencies.

An ACH analysis requires a modest commitment of time; it may take a day or more to build the ACH matrix. Once all the relevant information has been collected, it may take several hours to work through all the stages of the analytic process before writing up the conclusions. Usually a facilitator or a colleague previously schooled in the use of the technique helps guide analysts through the process, especially if it is the first time they have used the methodology.

什么时候使用它

ACH（分析对比假设）适用于几乎所有有多个解释的分析场景，无论是已经发生、正在发生，还是可能发生的情况。当判断或决策非常重要，不能有任何错误，或者需要一种系统的方法来避免意外结果时，建议使用 ACH。特别是在处理有争议的问题时，ACH 非常有用，因为它可以提供一条清晰的审计轨迹，展示分析师考虑了哪些相关信息以及如何得出结论。如果其他分析师和决策者不同意某分析师的结论，ACH 矩阵可以帮助找出具体的分歧点，使后续讨论更加聚焦于关键差异。

当需要处理大量数据时，ACH 效果最佳。它特别适用于化学、生物、放射和核领域的技术问题。例如，你可以用它来判断某个部件最有可能被用于哪个武器系统，或者某国正在进口或开发哪种类型的导弹系统。该技术在刑事调查中也非常有帮助，能够帮助确定正确的分析方向。ACH 最初是为应对否认和欺骗开发的，因此在这类情况下尤其有效。

ACH 可以由单个分析师使用，但在小团队中效果更好，因为团队成员可以互相挑战对信息的评估结果。这样可以更好地结构化和促进与其他办公室或机构同事的信息和想法交流。

进行 ACH（分析竞争假设）需要投入适当的时间；构建 ACH 矩阵可能需要一天或更长时间。一旦收集到所有相关信息，可能需要几个小时来完成整个分析过程，然后再写出结论。通常，一个熟悉该技术的主持人或同事会帮助分析师完成整个过程，尤其是当他们第一次使用这种方法时。

Value Added

Analysts are commonly required to work with incomplete, ambiguous, anomalous, and sometimes deceptive data. In addition, strict time constraints and the need to "make a call" often conspire with natural human cognitive biases to cause inaccurate or incomplete judgments. If the analyst is already generally knowledgeable on the topic, a common procedure is to develop a favored hypothesis and then search for relevant information to confirm it. This is called Satisficing or going with the first answer that seems to be supported by the evidence.

Satisficing is efficient because it saves time and often works. However, Confirmation Bias, which impels an analyst to look only for information that is consistent with the favored or lead hypothesis or widely accepted school of thought, is often at work in the background, as the analyst has made no investment in protection against surprise. Satisficing allows analysts to accept data as true without assessing its credibility or questioning fundamental assumptions because it helps create a more coherent story (Evidence Acceptance Bias). If engaged in Satisficing, analysts often bypass the analysis of alternative explanations or outcomes, which should be fundamental to any complete analysis. As a result, Satisficing fails to distinguish that much of the relevant information seemingly supportive of the favored hypothesis is also consistent with one or more alternative hypotheses. It often fails to recognize the importance of what is missing (i.e., what should be observable if a given hypothesis is true but is not there).

ACH improves the analyst's chances of overcoming these challenges by requiring analysts to identify and then try to refute as many reasonable hypotheses as possible using the full range of data, assumptions, and gaps that are pertinent to the problem at hand. The method for analyzing competing hypotheses takes time and attention in the initial stages, but it pays big dividends in the end. When analysts are first exposed to ACH and say they find it useful, it is because the simple focus on identifying alternative hypotheses and how they might be disproved prompts analysts to think seriously about evidence, explanations, or outcomes in ways that had not previously occurred to them.

The ACH process requires the analyst to assemble the collected information and organize it in a useful way, so that it can be readily retrieved for use in the analysis. This is done by creating a matrix with relevant information down the left side and hypotheses across the top. Each item of relevant information is then evaluated as to whether it is consistent or inconsistent with each hypothesis. The results are then used to assess the evidentiary and logical support for and against each hypothesis. This can be done manually, but it is much easier and better to use an Excel spreadsheet or ACH software designed for this purpose. Various ACH software applications can be used to sort and analyze the data by type of source and date of information, as well as by degree of support for or against each hypothesis.

ACH helps analysts produce a better analytic product by:

- Maintaining a record of the relevant information and tracking how that information relates to each hypothesis. 

- Capturing the analysts' key assumptions when the analyst is coding the data and recording what additional information is needed or what collection requirements are needed. 

- Enabling analysts to present conclusions in a way that is organized and transparent as it documents how conclusions were reached. 

- Providing a foundation for identifying indicators that can then be monitored and validated to determine the direction in which events are heading. 

- Leaving a clear audit trail as to how the analysis was done, the conclusions reached, and how individual analysts may have differed in their assumptions or judgments.

增值

分析师通常需要处理不完整、模糊、异常，甚至有时是欺骗性的数据。此外，严格的时间限制和需要「做出决定」常常与人类固有的认知偏见共同作用，导致不准确或不完整的判断。如果分析师已经对该主题有基本了解，常见的做法是提出一个偏好的假设，然后寻找相关信息来证实它。这种做法被称为「满意」或选择第一个似乎有证据支持的答案。

满意化是一种高效的方法，因为它节省时间且通常有效。然而，确认偏误（Confirmation Bias）促使分析师只寻找与其偏好或主要假设或广泛接受的学派一致的信息，这通常在背景中起作用，因为分析师没有在防止意外方面进行投资。满意化允许分析师接受数据为真，而不评估其可信性或质疑基本假设，因为它有助于创建一个更连贯的故事（证据接受偏误，Evidence Acceptance Bias)。如果使用满意化，分析师通常会跳过对替代解释或结果的分析，这应该是任何完整分析的基础。因此，满意化未能区分许多看似支持偏好假设的相关信息也与一个或多个替代假设一致。它经常未能认识到缺失信息的重要性（即，如果给定假设为真但不存在的内容应该是可观察的）。

ACH 通过要求分析师识别并尝试使用所有与手头问题相关的数据、假设和空白来反驳尽可能多的合理假设，从而改善分析师克服这些挑战的机会。分析竞争假设的方法在初期阶段需要时间和注意力，但最终会带来丰厚的回报。当分析师首次接触 ACH 并表示其有用时，这是因为简单地关注识别替代假设及其可能被驳斥的方式，促使分析师认真思考以前没有想到的证据、解释或结果。

ACH 过程要求分析人员收集并整理信息，以便在分析时能方便地检索和使用。具体方法是创建一个矩阵，左侧列出相关信息，顶部列出假设。然后，评估每条信息是否与各个假设一致或不一致。通过这些结果可以评估支持和反对每个假设的证据和逻辑基础。虽然可以手动进行，但使用 Excel 电子表格或专门的 ACH 软件会更简单高效。这些软件可以根据信息来源、日期以及对假设的支持程度对数据进行分类和分析。

ACH 有助于分析人员生成更好的分析产品，具体方式如下：

记录相关信息并追踪其与各个假设的关系。

在编码数据时捕捉分析人员的关键假设，并记录所需的其他信息或收集需求。

使分析人员能以条理清晰、透明的方式呈现结论，并记录得出结论的过程。

提供基础，用于识别可以监控和验证的指标，以便判断事件的发展方向。

留下清晰的审计记录，展示分析过程、结论以及分析人员在假设或判断上的不同之处。

ACH Software

ACH started as a manual method at the CIA in the mid-1980s. The first professionally developed and tested ACH software was created in 2005 by the P alo A lto R esearch C enter (PARC), with federal government funding and technical assistance from Richards J. Heuer Jr. and Randolph Pherson. Randolph Pherson managed its introduction into the U.S. Intelligence Community. The PARC version, though designed for use by an individual analyst, was commonly used by a co-located team of analysts. Members of such groups reported,

- The technique helped them gain a better understanding of the differences of opinion with other analysts or between analytic offices. 

- Review of the ACH matrix provided a systematic basis for identification and discussion of differences between participating analysts. 

- Reference to the matrix helped depersonalize the argumentation when there were differences of opinion.

A collaborative version of ACH called Te@mACH ® was developed under the direction of Randolph Pherson for Globalytica, LLC, in 2010. It has most of the functions of the PARC ACH tool but allows analysts in different locations to work on the same problem simultaneously. They can propose hypotheses and enter data on the matrix from multiple locations, but they must agree to work from the same set of hypotheses and the same set of relevant information. The software allows them to chat electronically about one another's assessments and assumptions, to compare their analysis with that of their colleagues, and to learn what the group consensus was for the overall problem solution.

Other government agencies, research centers, and academic institutions have developed versions of ACH. One version called Structured Analysis of Competing Hypotheses, developed for instruction at Mercyhurst College, builds on ACH by requiring deeper analysis at some points.

The use of collaborative ACH tools ensures that all analysts are working from the same database of evidence, arguments, and assumptions, and that each member of the team has had an opportunity to express his or her view on how that information relates to the likelihood of each hypothesis. Such tools can be used both synchronously and asynchronously and include functions such as a survey method to enter data that protects against bias, the ability to record key assumptions and collection requirements, and a filtering function that allows analysts to see how each person rated the relevant information. 5

ACH 软件

ACH 最早在 20 世纪 80 年代中期由 CIA 手动操作。第一个专业开发和测试的 ACH 软件是由 P alo A lto R esearch C enter（PARC）于 2005 年创建，并得到了联邦政府的资助和 Richards J. Heuer Jr. 以及 Randolph Pherson 的技术支持。Randolph Pherson 负责将其引入美国情报界。虽然 PARC 版本是为单个分析员设计的，但通常由同一地点的团队分析员共同使用。这些小组成员报告称，

该技术帮助他们更好地理解与其他分析员或分析办公室之间的意见分歧。通过审查 ACH 矩阵，他们能够系统地识别和讨论参与分析员之间的差异。参考矩阵在出现意见分歧时有助于使论证非个人化。

2010 年，Randolph Pherson 在 Globalytica, LLC 的指导下，开发了一种名为 Te@mACH ® 的协作版 ACH。它具备 PARC ACH 工具的大部分功能，但允许不同地点的分析员同时处理同一个问题。他们可以从多个地点提出假设并在矩阵上输入数据，但必须统一使用同一组假设和相关信息。该软件允许他们通过电子聊天讨论彼此的评估和假设，比较他们的分析结果，并了解小组对整体问题解决方案的共识。

其他政府机构、研究中心和学术机构也开发了 ACH 的不同版本。其中一个名为「竞争假设结构分析」的版本，专为 Mercyhurst College 的教学设计，通过在某些环节要求更深入的分析来扩展 ACH。

使用协作式的 ACH 工具可以确保所有分析员共享相同的证据、论点和假设数据库，并且每位团队成员都可以表达他或她对这些信息与每个假设可能性的看法。这些工具既可以同步使用也可以异步使用，功能包括通过调查方法输入数据以防止偏见、记录关键假设和收集需求，以及一个过滤功能，让分析员查看每个人对相关信息的评级。5

The Method

To retain five or seven hypotheses in working memory and note how each item of information fits into each hypothesis is beyond the capabilities of most analysts. It takes far greater mental agility than the common practice of seeking evidence to support a single hypothesis already believed to be the most likely answer. The following nine-step process is at the heart of ACH and can be done without software.

Identify all possible hypotheses that should be considered. Hypotheses should be mutually exclusive; that is, if one hypothesis is true, all others must be false. The list of hypotheses should include a deception hypothesis, if that is appropriate. For each hypothesis, develop a brief scenario or "story" that explains how it might be true. Analysts should strive to create as comprehensive list of hypotheses as possible. 

Make a list of significant relevant information , which means everything that would help analysts evaluate the hypotheses, including evidence, assumptions, and the absence of things one would expect to see if a hypothesis were true. It is important to include assumptions as well as factual evidence, because the matrix is intended to be an accurate reflection of the analyst's thinking about the topic. If the analyst's thinking is driven by assumptions rather than hard facts, this needs to become apparent so that the assumptions can be challenged. A classic example of absence of evidence is the Sherlock Holmes story of the dog barking in the night. The failure of the dog to bark was persuasive evidence that the guilty party was not an outsider but an insider whom the dog knew. 

Create a matrix and analyze the diagnosticity of the information. Create a matrix with all hypotheses across the top and all items of relevant information down the left side. See Figure 7.6a for an example. Analyze the "diagnosticity" of the evidence and arguments to identify which points are most influential in judging the relative likelihood of the hypotheses. Ask, "Is this input Consistent with the hypothesis, is it Inconsistent with the hypothesis, or is it Not Applicable or not relevant?" This can be done by either filling in each cell of the matrix row-by-row or by randomly selecting cells in the matrix for analysts to rate. If it is Consistent, put a "C" in the appropriate matrix box; if it is Inconsistent, put an "I"; if it is Not Applicable to that hypothesis, put an "NA." If a specific item of evidence, argument, or assumption is particularly compelling, put two "C's" in the box; if it strongly undercuts the hypothesis, put two "I's."

When you are asking if an input is Consistent or Inconsistent with a specific hypothesis, a common response is, "It all depends on . . ." That means the rating for the hypothesis is likely based on an assumption. You should record all such assumptions when filling out the matrix. After completing the matrix, look for any pattern in those assumptions, such as the same assumption being made when ranking multiple items of information. After the relevant information has been sorted for diagnosticity, note how many of the highly diagnostic Inconsistency ratings are based on assumptions. Consider how much confidence you should have in those assumptions and then adjust the confidence in the ACH Inconsistency Scores accordingly.

Review where analysts differ in their assessments and decide if the ratings need to be adjusted (see Figure 7.6b ). Often, differences in how analysts rate an item of information can be traced back to different assumptions about the hypotheses when doing the ratings. 

Refine the matrix by reconsidering the hypotheses. Does it make sense to combine two hypotheses into one, or to add a new hypothesis that was not considered at the start? If a new hypothesis is added, go back and evaluate all the relevant information for this hypothesis. Additional relevant information can be added at any time.

Figure 7.6A Creating an ACH Matrix

Description 

Figure 7.6B Evaluating Levels of Disagreement in ACH 

Draw tentative conclusions about the relative likelihood of each hypothesis, basing your conclusions on an analysis regarding the diagnosticity of each item of relevant information. Proceed by trying to refute hypotheses rather than confirm them. Add up the number of Inconsistency ratings for each hypothesis and note the Inconsistency Score for each hypothesis. As a first cut, examine the total number of "I" and "II" ratings for each hypothesis. The hypothesis with the most Inconsistent ratings is the least likely to be true and the hypothesis or hypotheses with the lowest Inconsistency Score(s) is tentatively the most likely hypothesis. 

The Inconsistency Scores are broad generalizations, not precise calculations. ACH is a tool designed to help the analyst make a judgment, but not to actually make the judgment for the analyst. This process is likely to produce correct estimates more frequently than less systematic or rigorous approaches, but the scoring system does not eliminate the need for analysts to use their own good judgment. The "Potential Pitfalls" section below identifies several occasions when analysts need to override the Inconsistency Scores. 

Analyze the sensitivity of your tentative conclusion to see how dependent it is on a few critical items of information. For example, look for evidence that has a "C" for the lead hypothesis but an "I" for all other hypotheses. Evaluate the importance and credibility of those reports, arguments, or assumptions that garnered a "C." Consider the consequences for the analysis if that item of relevant information were wrong or misleading or subject to a different interpretation. If all the evidence earns a "C" for each hypothesis, then the evidence is not diagnostic. If a different interpretation of any of the data would cause a change in the overall conclusion, go back and double-check the accuracy of your interpretation. 

Report the conclusions. Consider the relative likelihood of all the hypotheses, not just the most likely one. State which items of relevant information were the most diagnostic, and how compelling a case they make in identifying the most likely hypothesis. 

Identify indicators or milestones for future observation. Generate two lists: one focusing on future events or what additional research might uncover that would substantiate the analytic judgment, and a second that would suggest the analytic judgment is less likely to be correct or that the situation has changed. Validate the indicators and monitor both lists on a regular basis, remaining alert to whether new information strengthens or weakens your case.

方法

在工作记忆中同时保留五到七个假设并记录每条信息如何适配每个假设，对于大多数分析员来说是很困难的。这需要比通常的只寻找支持单一假设的证据的方法更高的心智能力。以下九步过程是 ACH 的核心，可以在没有软件的情况下完成。

识别所有可能的假设，这些假设应该是互斥的；也就是说，如果一个假设为真，其他所有假设必须为假。假设列表应包括欺骗假设（如果适用）。对于每个假设，简要描述一个可能的场景或「故事」来解释它可能如何成立。分析师应尽力列出尽可能全面的假设。

列出所有重要的相关信息，这包括所有有助于分析师评估假设的信息，如证据、假设，以及如果假设为真所预期看到的事物的缺失。包括假设和事实证据是很重要的，因为这个矩阵旨在准确反映分析师对主题的思考过程。如果分析师的思考是基于假设而非硬性事实，这一点需要显而易见，以便对这些假设进行挑战。

缺乏证据的经典例子是福尔摩斯故事中的夜间狗吠声。狗没有吠叫的事实是一个有力的证据，表明有罪的一方不是外人，而是狗认识的内部人员。

创建一个矩阵并分析信息的诊断性。创建一个矩阵，将所有假设放在顶部，将所有相关信息项放在左侧。参见图 7.6a 了解示例。分析证据和论点的「诊断性」以确定哪些点在判断假设的相对可能性方面最具影响力。问：「这个输入是否与假设一致，与假设不一致，还是不适用或不相关？」这可以通过逐行填写矩阵的每个单元格，或者随机选择矩阵中的单元格供分析师评分来完成。如果一致，在适当的矩阵框中放置一个「C」；如果不一致，放置一个「I」；如果不适用于该假设，放置一个「NA」。如果某个特定的证据、论点或假设特别有说服力，在框中放置两个「C」；如果它强烈削弱了假设，放置两个「I」。

当你在判断某个输入是否与特定假设一致或不一致时，一个常见的回答是「这完全取决于……」。这意味着假设的评级可能是基于某些假设。在填写矩阵时，你应该记录所有这些假设。完成矩阵后，查找这些假设中的任何模式，例如在对多个信息项进行排序时做出的相同假设。在对相关信息进行诊断性排序后，注意有多少高度诊断性的不一致评级是基于这些假设的。考虑你对这些假设的信心程度，然后相应地调整 ACH 不一致性评分中的信心。

审查分析师在评估中的差异，决定是否需要调整评级（见图 7.6b）。通常，分析师对某个信息项的不同评级可以追溯到在进行评级时对假设的不同假设。通过重新考虑假设来完善矩阵。将两个假设合并为一个，或者添加一个在开始时未考虑的新假设是否有意义？如果添加了新假设，请重新评估所有与此假设相关的信息。你可以随时添加额外的相关信息。

图 7.6A 创建 ACH 矩阵

描述图 7.6B 评估 ACH 中的分歧级别基于对相关信息的诊断分析，初步判断每个假设的相对可能性。尽量通过反驳假设而不是确认假设来进行分析。计算每个假设的「不一致」评分，并记录这些评分。首先，检查每个假设的总共的「Ⅰ」和「Ⅱ」评分。评分越多的假设越不可能为真，而评分最少的假设暂时认为最有可能为真。不一致评分是一个大致的概括，而非精确计算。ACH 是帮助分析师做出判断的工具，但最终决策依然需要分析师自身的判断。尽管这个过程比不系统或不严格的方法更可能得出正确的估计，但评分系统并不能替代分析师的判断能力。下面的「潜在陷阱」部分提到了几种需要分析师超越不一致评分的情况。

分析你的初步结论的敏感性，评估它在多大程度上依赖于一些关键信息。例如，找出对主要假设标记为「C」但对其他假设标记为「I」的证据。评估那些被标记为「C」的报告、论点或假设的重要性和可信度。如果该信息有误、具有误导性或被不同解释，对分析的影响是什么。如果所有证据对每个假设都标记为「C」，那么这些证据就不是诊断性的。如果对任何数据的不同解释会改变整体结论，请返回并仔细检查你的解释是否准确。报告结论时，要考虑所有假设的相对可能性，而不仅仅是最可能的一个。说明哪些信息最具诊断性，以及它们在确定最可能假设方面的说服力。确定用于未来观察的指标或里程碑。生成两个列表：一个列出未来事件或进一步研究可能揭示的内容，以支持分析判断；另一个列出可能表明分析判断不正确或情况发生变化的内容。验证这些指标并定期监控两个列表，保持警觉，看看新信息是否加强或削弱了你的判断。

Potential Pitfalls

A word of caution: ACH only works when all participating analysts approach an issue with a relatively open mind. An analyst already committed to a "right answer" will often find a way to interpret relevant information to align with or make consistent with the preexisting belief. In other words, as an antidote to Confirmation Bias, ACH is like a flu shot. Getting the flu shot will usually keep you from getting the flu, but it won't make you well if you already have the flu.

The Inconsistency Scores generated for each hypothesis are not the product of a magic formula that tells you which hypothesis to believe. The ACH software takes you through a systematic analytic process, and the Inconsistency Score calculation that emerges is only as accurate as your selection and evaluation of the relevant information.

Because it is more difficult to refute hypotheses than to find information that confirms a favored hypothesis, the generation and testing of alternative hypotheses will often increase rather than reduce the analyst's level of uncertainty. Such uncertainty is frustrating, but it is usually an accurate reflection of the true situation. The ACH procedure has the offsetting advantage of focusing attention on the few items of critical information that cause the uncertainty or, if they were available, would alleviate it. ACH can guide future collection, research, and analysis to resolve the uncertainty and produce a more accurate judgment.

Analysts should be aware of five circumstances that can cause a divergence between an analyst's own beliefs and the Inconsistency Scores. In the first two circumstances described in the following list, the Inconsistency Scores seem to be wrong when they are correct. In the next three circumstances, the Inconsistency Scores may seem correct when they are wrong. Analysts need to recognize these circumstances, understand the problem, and adjust accordingly.

Assumptions or logical deductions omitted. If the scores in the matrix do not support what you believe is the most likely hypothesis, the matrix may be incomplete. Your thinking may be influenced by assumptions or logical deductions not included in the list of relevant information or arguments. If so, they should be added so the matrix fully reflects everything that influences your judgment on this issue. It is important for all analysts to recognize the role that unstated or unquestioned (and sometimes unrecognized) assumptions play in their analysis. In political or military analysis, for example, conclusions may be driven by assumptions about another country's capabilities or intentions. A principal goal of the ACH process is to identify those factors that drive the analyst's thinking on an issue so that these factors can be questioned and, if appropriate, changed. 

Insufficient attention to less likely hypotheses. If you think the scoring gives undue credibility to one or more of the less likely hypotheses, it may be because you have not assembled the relevant information needed to refute them. You may have devoted insufficient attention to obtaining such relevant information, or the relevant information may simply not be there. If you cannot find evidence to refute a hypothesis, it may be necessary to adjust your thinking and recognize that the uncertainty is greater than you had originally thought. 

Definitive relevant information. There are occasions when intelligence collectors obtain information from a trusted and well-placed inside source. The ACH analysis can label the information as having high credibility, but this is probably not enough to reflect the conclusiveness of such relevant information and the impact it should have on an analyst's thinking. In other words, in some circumstances, one or two highly authoritative reports from a trusted source in a position to know may support one hypothesis so strongly that they refute all other hypotheses regardless of what other less reliable or less definitive relevant information may show. 

Unbalanced set of evidence. Evidence and arguments must be representative of the entire problem. If there is considerable evidence on a related but peripheral issue and comparatively few items of evidence on the core issue, the Inconsistency Score may be misleading. 

Diminishing returns. As evidence accumulates, each new item of Inconsistent relevant information or argument has less impact on the Inconsistency Scores than does the earlier relevant information. For example, the impact of any single item is less when there are fifty items than when there are only ten items. To understand this, consider what happens when you calculate the average of fifty numbers. Each number has equal weight; adding a fifty-first number will have less impact on the average than if you start with only ten numbers and add one more. Stated differently, the accumulation of relevant information over time slows down the rate at which the Inconsistency Score changes in response to new relevant information. Therefore, the numbers may not reflect the actual amount of change in the situation you are analyzing. When you are evaluating change over time, it is desirable to delete the older relevant information periodically, or to partition the relevant information and analyze the older and newer relevant information separately.

Some other caveats when using ACH include the following:

The possibility that none of the relevant information identified is diagnostic. 

Not all relevant information is identified. 

Some of the relevant information is inaccurate, deceptive, or misleading. 

The ratings are subjective and therefore subject to human error. 

When the analysis is performed by a group, the outcome can be biased by Groupthink or the absence of healthy group dynamics.

潜在的陷阱

需要注意的是，ACH 只有在所有参与的分析师都保持相对开放的心态时才有效。如果某个分析师已经认定了一个「正确答案」，他往往会倾向于解释相关信息，使其符合自己的先前信念。换句话说，ACH 是对抗确认偏差（Confirmation Bias）的方法，就像流感疫苗一样。接种流感疫苗通常可以预防流感，但如果你已经感染了流感，它并不能治愈你。

为每个假设生成的不一致性分数并不是一种神奇的公式来告诉你应该相信哪个假设。ACH 软件会引导你进行一个系统的分析过程，所生成的不一致性分数的准确性取决于你选择和评估相关信息的准确性。

由于反驳一个假设比找到支持某个假设的信息更困难，生成和测试替代假设通常会增加而不是减少分析师的不确定性。这种不确定性虽然令人沮丧，但通常是对真实情况的准确反映。ACH 程序的优势在于，它可以将注意力集中在那些导致不确定或能够缓解不确定性的关键信息上。ACH 可以指导未来的收集、研究和分析，以解决不确定性并做出更准确的判断。

分析师应注意五种可能导致其个人信念与不一致性分数之间出现差异的情况。在以下列表中，前两种情况下的不一致性分数实际上是正确的，但看起来像是错误的。而后三种情况下的不一致性分数可能看起来正确，但实际上是错误的。分析师需要识别这些情况，理解问题，并进行相应调整。

假设或逻辑推理可能被遗漏。如果矩阵中的评分不支持你认为最有可能的假设，那么可能是矩阵不完整。你的思维可能受到了未包含在相关信息或论点中的假设或推理的影响。如果是这样，应该将它们添加进来，以便矩阵充分反映所有影响你判断的因素。所有分析师都应意识到，未明确陈述或质疑的假设可能会影响他们的分析。在政治或军事分析中，结论可能会基于对其他国家能力或意图的假设。ACH 过程的主要目标是识别那些影响分析师思维的因素，以便对这些因素进行质疑，并在必要时进行调整。

对不太可能的假设关注不足。如果你认为评分给了一些不太可能的假设过高的可信度，可能是因为你没有收集到足够驳斥这些假设的信息。你可能没有足够关注获取这些信息，或者这些信息可能本来就不存在。如果你找不到反驳某个假设的证据，可能需要调整你的思维，并认识到不确定性比你原先想象的更大。

确定的相关信息。有时，情报员会从一个可靠且有内部消息来源的人那里获得信息。ACH 分析可以将该信息标记为高可信度，但这可能不足以完全反映这些信息的结论性及其对分析师思维的影响。换句话说，在某些情况下，来自一个知情且可信消息来源的一两个高权威性报告可能会如此强烈地支持一个假设，以至于驳斥了所有其他假设，不论其他较不可靠的信息显示什么。

不平衡的证据集合。证据和论据必须全面代表整个问题。如果在一个相关但边缘的问题上有大量证据，而在核心问题上证据较少，那么不一致性得分可能会产生误导。

边际收益递减。随着证据的累积，每一个新的不一致信息或论据对不一致性得分的影响都会变小。例如，当有五十个项目时，任何一个单独项目的影响比只有十个项目时要小。要理解这一点，可以想象当你计算五十个数字的平均值时，每个数字都有同等的权重；添加第 51 个数字对平均值的影响将比从十个数字开始再添加一个要小。换句话说，随着时间的推移，相关信息的累积会减缓不一致性得分对新增信息的反应速度。因此，这些数字可能无法完全反映你正在分析的情况的实际变化。当你在评估随时间的变化时，最好定期删除旧的信息，或者将信息分区，分别分析旧的和新的信息。

使用 ACH 进行分析时，还需要注意以下几点：

可能没有任何相关信息能够被确定为诊断信息。并不是所有相关信息都能被识别出来。一些相关信息可能是不准确的、具有欺骗性的或误导性的。评级具有主观性，因此可能会有误差。当小组进行分析时，结果可能会受到群体思维的影响，或者因为缺乏健康的群体动态而产生偏差。

Relationship to Other Techniques

ACH is often used in conjunction with other techniques. For example, Cluster Brainstorming, Nominal Group Technique, Multiple Hypothesis Generation, or the Delphi Method can identify hypotheses or relevant information for inclusion in the ACH analysis. They can also help analysts evaluate the significance of relevant information. Deception Detection may identify an opponent's motive, opportunity, or means to conduct deception or to identify past deception practices; information about these factors should be included in the list of ACH-relevant information. The Diagnostic Reasoning technique is incorporated within the ACH method. The final step in the ACH method identifies Indicators for monitoring future developments.

The ACH matrix is intended to reflect all relevant information and arguments that affect one's thinking about a designated set of hypotheses. That means it should also include assumptions identified by a Key Assumptions Check, discussed earlier in this chapter. Conversely, rating the consistency of an item of relevant information with a specific hypothesis is often based on an assumption. When rating the consistency of relevant information in an ACH matrix, the analyst should ask, "If this hypothesis is true, would I see this item of relevant information?" A common thought in response to this question is, "It all depends on. . . ." This means that, however the consistency of that item of relevant information is rated, that rating is likely based on an assumption—whatever assumption the rating "depends on." These assumptions should be recorded in the matrix and then considered in the context of a Key Assumptions Check.

The Delphi Method (chapter 8) can double-check the conclusions of an ACH analysis. In this process, outside experts are asked separately to assess the probability of the same set of hypotheses and to explain the rationale for their conclusions. If the two different groups of analysts using different methods arrive at the same conclusion, confidence in the conclusion increases. If they disagree, their lack of agreement is also useful, as one can then seek to understand the rationale for the different judgments.

ACH and Argument Mapping (described later in this chapter) are both used on the same types of complex analytic problems. They are both systematic methods for organizing relevant information, but they work in fundamentally different ways and are best used at different stages in the analytic process. ACH is used during an early stage to analyze a range of hypotheses to determine which is most consistent with the broad body of relevant information. At a later stage, when the focus is on developing, evaluating, or presenting the case for a specific conclusion, Argument Mapping is the appropriate method. Each method has strengths and weaknesses, and the optimal solution is to use both.

Origins of This Technique

Richards Heuer originally developed the ACH technique at the CIA in the mid-1980s as one part of a methodology for analyzing the presence or absence of Soviet deception. It was described publicly in his book, Psychology of Intelligence Analysis , first published in 1999; 6 Heuer and Randolph Pherson helped the Palo Alto Research Center gain funding from the federal government during 2004 and 2005 to produce the first professionally developed ACH software. Randolph Pherson managed its introduction into the U.S. Intelligence Community. Globalytica, LLC, with Pherson's assistance, subsequently developed a collaborative version of the software called Te@mACH ® . An example of an Analysis of Competing Hypotheses can be found at https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/books-and-monographs/psychology-of-intelligence-analysis/art11.html.

与其他技术的结合

ACH 通常与其他技术结合使用。例如，集群头脑风暴、名义小组技术、多假设生成或德尔菲法可以识别要包含在 ACH 分析中的假设或相关信息。这些方法还可以帮助分析师评估相关信息的重要性。欺骗检测可以识别对手进行欺骗的动机、机会或手段，或识别过去的欺骗行为；这些因素的信息应包含在 ACH 相关信息列表中。诊断推理技术已经被纳入 ACH 方法中。ACH 方法的最后一步是确定用于监控未来发展的指标。

ACH 矩阵旨在汇总所有与指定假设集有关的关键信息和论点。这也包括在本章前面讨论的关键假设检查中识别出来的假设。相反，评估某条相关信息与特定假设的一致性通常是基于某个假设。在评估 ACH 矩阵中的相关信息时，分析师应自问：「如果这个假设是真的，我会看到这条相关信息吗？」常见的回答是，「这取决于……」也就是说，无论这条信息的一致性如何评价，评价的依据通常是某个假设 —— 即评价「取决于」的假设。这些假设应记录在矩阵中，并在关键假设检查的背景下加以考虑。

德尔菲法（第 8 章）可以用于复核 ACH 分析的结论。在这个过程中，外部专家分别评估同一组假设的概率，并解释他们的结论理由。如果使用不同方法的两个分析小组得出了相同的结论，那么对结论的信心就会增加。如果他们的结论不同，这种分歧也是有价值的，因为可以进一步理解不同判断背后的原因。

ACH 和 Argument Mapping（在本章后面介绍）都用于处理复杂的分析问题。这两种方法都是系统化地组织相关信息，但它们的工作方式有根本区别，并且适用于分析过程的不同阶段。ACH 通常在早期阶段使用，通过分析多个假设来确定哪个最符合大量相关信息。而在后期，当需要开发、评估或展示具体结论时，Argument Mapping 是更合适的方法。每种方法都有各自的优缺点，最佳的解决方案是结合使用。

这种技术的起源

Richards Heuer 在 1980 年代中期于 CIA 首次开发了 ACH 技术，作为分析苏联欺骗存在与否的一部分。这项技术首次在他 1999 年出版的书《心理学情报分析》中被公开描述 [6]。Heuer 和 Randolph Pherson 还帮助 Palo Alto 研究中心在 2004 年和 2005 年期间获得了联邦政府的资助，开发了第一个专业的 ACH 软件。Randolph Pherson 负责将其引入美国情报界。随后，Globalytica, LLC 在 Pherson 的协助下开发了名为 Te@mACH ® 的协作版软件。可以在 https://www.cia.gov/library/center-for-the-study-of-intelligence/csi-publications/books-and-monographs/psychology-of-intelligence-analysis/art11.html 找到一个竞争假设分析的示例。

### 7.7 Inconsistencies Finder™

The Inconsistencies Finder™ is a simpler version of Analysis of Competing Hypotheses that focuses attention on relevant information that is inconsistent with a hypothesis, helping to disconfirm its validity.

When to Use It

The Inconsistencies Finder™ can be used whenever a set of alternative hypotheses exists, or has recently been identified, and analysts need to do the following:

Carefully weigh the credibility of multiple explanations, or alternative hypotheses, explaining what has happened, is happening, or is likely to happen. Evaluate the validity of a large amount of data as it relates to each hypothesis. Challenge their current interpretation of the evidence (or, alternatively, the interpretation of others). Create an audit trail.

Value Added

The process of systematically reviewing the relevant information and identifying which information or evidence is inconsistent with each hypothesis helps analysts do the following:

Identify the most diagnostic information. Focus on the disconfirming evidence. Dismiss those hypotheses with compelling inconsistent information. Flag areas of agreement and disagreement. Highlight the potential for disinformation or deception.

Instead of building a case to justify a preferred solution or answer, the Inconsistencies Finder™ helps analysts easily dismiss those hypotheses with compelling inconsistent information and focus attention on those with the least disconfirming information. An analytic case can then be built that supports this most likely hypothesis—or hypotheses.

The technique is not an answer generator. It should be viewed as a thinking tool that helps you frame a problem more efficiently. Unlike ACH, the technique does not help analysts identify the most diagnostic information for making their case.

The Inconsistencies Finder™ aids the production of high-quality analysis in much the same way ACH mitigates cognitive biases and intuitive traps by helping analysts do the following:

Avoid leaping to conclusions. Move beyond "first impressions." Challenge preconceived ideas. Uncover unknowns and uncertainties.

The Method

Create a matrix with all the hypotheses under consideration listed in separate columns along the top of the matrix. Make a list of all the relevant information (including significant evidence, arguments, assumptions, and the absence of things) that would be helpful in evaluating the given set of hypotheses. Put each piece of information in a separate row down the left side of the matrix. Working in small teams, analyze each item for consistency/inconsistency against the given hypotheses. Review each piece of information against each hypothesis. Analysts can move across the matrix row by row to evaluate each hypothesis against all the relevant information moving from column to column.

Place an "I" in the box that rates each item against each hypothesis if you would not expect to see that item of information if the hypothesis were true. Place a "II" in the box if the presence of the information makes a compelling case that the hypothesis cannot be true. For example, if a suspect had an unassailable alibi proving he or she was at a different location at the time a crime was committed, then he or she could not be the perpetrator. Add up all the "I's" (Inconsistent ratings) in each hypothesis column. Assign one point to each "I" and two points to each "II." Rank order the credibility of the hypotheses based on the total number of points or "I's" that each hypothesis receives. The higher the score, the less likely the hypothesis. Assess if the "I's" noted in each column make a compelling case to dismiss that hypothesis. Work your way through the "I's" beginning with the hypothesis with the most "I's" to the hypothesis with the fewest or no "I's." Identify the hypothesis(es) with the least Inconsistent information and make a case for that hypothesis(es) being true.

Inconsistencies Finder™

Inconsistencies Finder™ 是竞争性假设分析（Analysis of Competing Hypotheses）的简化版本，专注于发现与假设不一致的相关信息，从而帮助否定假设的有效性。

使用场景

Inconsistencies Finder™ 可用于存在或刚刚识别出一组替代假设的情况，分析师需要做以下几件事：

- 仔细评估多种解释或替代假设的可信度，以解释已经发生、正在发生或可能发生的事件。
- 评估大量数据与每个假设的相关性。
- 挑战当前对证据的解释（或他人的解释）。
- 创建审计跟踪。

价值体现系统地审查相关信息并确定哪些信息或证据与每个假设不一致，有助于分析师做到以下几点：

- 识别最具诊断性的信息。
- 专注于否定性证据。
- 排除那些具有明显不一致信息的假设。
- 标记一致和不一致的部分。
- 突出错误信息或欺骗的可能性。

与建立一个支持首选解决方案或答案的案例不同，Inconsistencies Finder™ 帮助分析师轻松排除那些具有明显不一致信息的假设，并专注于那些具有最少否定信息的假设。然后，可以构建一个支持这种最可能假设的分析案例。

该技术不是答案生成器，而应被视为一种帮助更有效地框定问题的思维工具。与 ACH 不同，该技术不帮助分析师识别最具诊断性的信息以支持他们的案例。

Inconsistencies Finder™ 通过帮助分析师做到以下这些，与 ACH 一样，在很大程度上帮助制作高质量的分析，从而减轻认知偏见和直觉陷阱：

避免急于下结论。不要仅凭「第一印象」就做判断。要质疑已有的想法，探索未知和不确定性。

方法首先，创建一个矩阵，在矩阵顶部的各列列出所有待考虑的假设。在矩阵的左侧列出所有相关信息（包括重要的证据、论点、假设和缺失的内容），这些信息有助于评估这些假设。然后，分成小组，分析每条信息在每个假设下的一致性或不一致性。逐行审查每条信息与每个假设的关系。

如果某条信息在假设为真时不应出现，则在相应的框中标记「I」。如果某条信息的存在证明假设不可能为真，则标记「II」。例如，如果嫌疑人有无懈可击的证据证明在犯罪发生时不在现场，那么他或她就不可能是犯罪者。将每个假设列中的所有「I」（不一致评分）加起来。每个「I」记一分，每个「II」记两分。根据总分或每个假设获得的「I」的数量，对假设的可信度进行排序。分数越高，假设成立的可能性越小。通过评估每列中的「I」数量，判断是否有足够的理由排除该假设。从「I」最多的假设开始，逐步分析到「I」最少或没有「I」的假设。最后，确定信息不一致最少的假设，并为其真实性提供依据。

### 7.8 Deception Detection

Deception is an action intended by an adversary to influence the perceptions, decisions, or actions of another to the advantage of the deceiver. Deception Detection uses a set of checklists to help analysts determine when to look for deception, discover whether deception actually is present, and figure out what to do to avoid being deceived. As Richards J. Heuer Jr. has argued, "The accurate perception of deception in counterintelligence analysis is extraordinarily difficult. If deception is done well, the analyst should not expect to see any evidence of it. If, on the other hand, deception is expected, the analyst often will find evidence of deception even when it is not there." 7

When to Use It

Analysts should be concerned about the possibility of deception when the following occurs:

The analysis hinges on a single critical piece of information or reporting. Key information is received at a critical time—that is, when either the recipient or the potential deceiver has a great deal to gain or to lose. Accepting new information would cause the recipient to expend or divert significant resources. Accepting new information would require the analyst to alter a key assumption or key judgment. The potential deceiver may have a feedback channel that illuminates whether and how the deception information is being processed and to what effect. Information is received from a source whose bona fides are questionable. The potential deceiver has a history of conducting deception.

Value Added

Most intelligence analysts know not to assume that everything that arrives in their inbox is valid, but few know how to factor such concerns effectively into their daily work practices. Considering the deception hypothesis puts a major cognitive burden on the analyst. If an analyst accepts the possibility that some of the information received may be deceptive, then all evidence is open to question and no valid inferences can be drawn from the reporting. This fundamental dilemma can paralyze analysis unless the analyst uses practical tools to determine when it is appropriate to worry about deception, how best to detect deception in the reporting, and what to do in the future to guard against being deceived.

It is very hard to deal with deception when you are really just trying to get a sense of what is going on, and there is so much noise in the system, so much overload, and so much ambiguity. When you layer deception schemes on top of that, it erodes your ability to act.

—Robert Jervis, "Signaling and Perception in the Information Age," in The Information Revolution and National Security (August 2000)

The measure of a good deception operation is how well it exploits the cognitive biases of its target audience. The deceiver's strategy usually is to provide some intelligence or information of value to the person being deceived in the hope that he or she will conclude the "take" is good enough and should be disseminated. As additional information is collected, the Satisficing bias is reinforced and the recipient's confidence in the information or the source usually grows, further blinding the recipient to the possibility that he or she is falling prey to deception. The deceiver knows that the information being provided is highly valued, although over time some people will begin to question the bona fides of the source. Often, this puts the person who developed the source or acquired the information on the defensive, and the natural reaction is to reject any and all criticism. This cycle is usually broken only by applying structured techniques such as Deception Detection to force a critical examination of the true quality of the information and the potential for deception.

Deception Detection is a useful tool analysts can employ to avoid cognitive biases and heuristics, such as seeking only the information that is consistent with the lead hypothesis (Confirmation Bias), accepting data as true without assessing its credibility because it helps "make the case" (Evidence Acceptance Bias), and judging the frequency of an event by the ease with which instances come to mind (Availability Heuristic). It also safeguards an analyst against several classic mental mistakes, including giving too much weight to first impressions or initial data that appears important at the time (Relying on First Impressions), assuming the same dynamic is in play when something appears to be in accord with past experiences (Projecting Past Experiences), and accepting or rejecting everything someone says because the analyst strongly likes or dislikes the person (Judging by Emotion).

The Method

Analysts should routinely consider the possibility that opponents or competitors are attempting to mislead them or hide important information. The possibility of deception cannot be rejected simply because there is no evidence of it; if the deception is well done, one should not expect to see evidence of it. Some circumstances in which deception is most likely to occur are listed in the "When to Use It" section. When such circumstances occur, the analyst, or preferably a small group of analysts, should assess the situation using four checklists that are commonly referred to by their acronyms: MOM, POP, MOSES, and EVE (see box on pp. 173–174).

Analysts have also found the following "rules of the road" helpful in anticipating the possibility of deception and dealing with it: 8

Avoid overreliance on a single source of information. Seek and heed the opinions of those closest to the reporting. Be suspicious of human sources or human subsources who have not been seen or when it is unclear how or from whom they obtained the information. Do not rely exclusively on what someone says (verbal intelligence); always look for material evidence (documents, pictures, an address, a phone number, or some other form of concrete, verifiable information). Be suspicious of information that plays strongly to your own known biases and preferences. Look for a pattern of a source's reporting that initially appears to be correct but later and repeatedly turns out to be wrong, with the source invariably offering seemingly plausible, albeit weak, explanations to justify or substantiate the reporting. At the onset of a project, generate and evaluate a full set of plausible hypotheses, including a deception hypothesis, if appropriate. Know the limitations as well as the capabilities of the potential deceiver.

Relationship to Other Techniques

Analysts can combine Deception Detection with Analysis of Competing Hypotheses to assess the possibility of deception. The analyst explicitly includes deception as one of the hypotheses to be analyzed, and information identified through the MOM, POP, MOSES, and EVE checklists is included as evidence in the ACH analysis.

Origins of This Technique

Deception—and efforts to detect it—has always been an integral part of international relations. An excellent book on this subject is Michael Bennett and Edward Waltz, Counterdeception Principles and Applications for National Security (Boston: Artech House, 2007). The description of Deception Detection in this book was previously published in Randolph H. Pherson, Handbook of Analytic Tools and Techniques, 5th ed. (Tysons, VA: Pherson Associates, LLC, 2019). A concrete example of Deception Detection at work can be found at https://www.apa.org/monitor/2016/03/deception .

Deception Detection Checklists

Motive, Opportunity, and Means (MOM)

Motive: What are the goals and motives of the potential deceiver? Channels: What means are available to the potential deceiver to feed information to us? Risks: What consequences would the adversary suffer if such a deception were revealed? Costs: Would the potential deceiver need to sacrifice sensitive information to establish the credibility of the deception channel? Feedback: Does the potential deceiver have a feedback mechanism to monitor the impact of the deception operation?

Past Opposition Practices (POP)

Does the adversary have a history of engaging in deception? Does the current circumstance fit the pattern of past deceptions? If not, are there other historical precedents? If not, are there changed circumstances that would explain using this form of deception at this time?

Manipulability of Sources (MOSES)

Is the source vulnerable to control or manipulation by the potential deceiver? What is the basis for judging the source to be reliable? Does the source have direct access or only indirect access to the information? How good is the source's track record of reporting?

Evaluation of Evidence (EVE)

How accurate is the source's reporting? Has the whole chain of evidence, including translations, been checked? Does the critical evidence check out? Remember, the subsource can be more critical than the source. Does evidence from one source of reporting (e.g., human intelligence) conflict with that coming from another source (e.g., signals intelligence or open-source reporting)? Do other sources of information provide corroborating evidence? Is the absence of evidence one would expect to see noteworthy?

7.8 欺骗检测

欺骗是指对手通过某种行为，企图影响另一方的认知、决策或行动，以获取自身的利益。欺骗检测则通过一系列清单，协助分析人员判断何时需要警惕欺骗，确认是否存在欺骗，并采取措施避免上当受骗。正如 Richards J. Heuer Jr. 所言，「在反间谍分析中，准确识别欺骗是极其困难的。如果欺骗手段高明，分析人员不应期望能找到任何证据。相反，如果预期存在欺骗，分析人员往往会看到欺骗的迹象，即便这些迹象并不存在。」[7]

何时使用当满足以下情况时，分析人员应警惕欺骗的可能性：

- 分析依赖于单一的关键信息或报告。
- 关键信息在关键时刻到达，即接收者或潜在欺骗者在此时有大量利害关系。
- 接受新信息会导致接收者花费或重新分配大量资源。
- 接受新信息会要求分析人员改变关键假设或关键判断。
- 潜在欺骗者可能通过某种反馈渠道，了解欺骗信息是否以及如何被处理，并评估其效果。
- 信息来自一个可信度存疑的来源。
- 潜在的欺骗者有过欺骗行为的历史。

附加价值

大多数情报分析员都知道不能假定收件箱中的所有信息都是可信的，但很少有人知道如何在日常工作中有效地处理这些担忧。考虑到欺骗的可能性，会给分析员带来很大的认知压力。如果分析员认为收到的信息可能存在欺骗，那么所有证据都可能被质疑，从而无法得出有效的结论。除非分析员能使用一些实用的工具，否则这种基本的困境会使分析陷入瘫痪。这些工具可以帮助他们判断何时需要关注欺骗、如何检测报告中的欺骗，以及如何在未来防止被欺骗。

当你试图了解实际情况时，处理欺骗是非常困难的，因为系统中充斥着大量噪音、信息过载和模糊性。如果再加上欺骗计划，这会进一步削弱你的行动能力。

——Robert Jervis，《信息时代的信号和感知》，载于《信息革命与国家安全》（2000 年 8 月）

衡量欺骗操作是否成功的标准在于它能多大程度上利用目标受众的认知偏差。欺骗者通常会向目标提供一些有价值的信息，希望目标认为这些「情报」足够可靠，值得传播。随着更多信息的获取，满意性偏差（Satisficing bias）会被强化，目标对信息或其来源的信任度会增加，从而忽视自己可能被欺骗的风险。尽管随着时间的推移，有些人会开始质疑信息来源的真实性，但这通常会使获取信息的人产生防御心理，拒绝一切批评。这个循环通常只能通过使用诸如欺骗检测（Deception Detection）等结构化技术来打破，以便对信息的真实性和欺骗的可能性进行深入审查。

欺骗检测是一种有用的工具，分析人员可以利用它来避免认知偏差和启发式思维，例如只寻找支持主要假设的信息（确认偏差），接受数据为真而不评估其可信性，因为它有助于「证明结论」（证据接受偏差），以及根据容易联想到的实例判断事件频率（可用性启发法）。它还可以防止分析人员犯一些经典的心理错误，例如过分依赖第一印象或最初看起来重要的数据（依赖第一印象），假设与过去经验一致的情况依然适用（投射过去的经验），以及因为个人喜好而完全接受或拒绝某人的所有观点（凭情绪判断）。

方法

分析师应该经常考虑到对手或竞争者可能在试图误导他们或隐藏重要信息。不能仅仅因为没有证据就排除欺骗的可能性，如果欺骗做得好，不应该期待看到其证据。在「何时使用」部分列出了一些最可能发生欺骗的情况。当出现这种情况时，分析师或最好是一个小组的分析师，应使用四个常见的清单来评估情况，这些清单通常用其首字母缩写来引用：MOM，POP，MOSES，和 EVE（见第 173-174 页的方框）。

分析师还发现以下「指导原则」对预见和处理欺骗非常有帮助：

避免过度依赖单一信息来源。寻求并听取那些最接近报告的人的意见。对未见过的或不清楚他们如何或从何处获得信息的人类来源或人类子来源持怀疑态度。不要只依赖某人的话（口头情报）；始终寻找物质证据（文件、图片、地址、电话号码或其他形式的具体、可验证的信息）。对那些强烈迎合你已知的偏见和偏好的信息持怀疑态度。寻找一个来源的报告模式，该模式最初似乎是正确的，但后来和反复被证明是错误的，并且该来源总是提供看似合理但薄弱的解释来证明或证实其报告。在项目开始时，生成并评估一整套合理的假设，包括欺骗假设（如果适用）。了解潜在欺骗者的局限性以及能力。

与其他技术的关系

分析师可以将欺骗检测与竞争假设分析相结合，以评估欺骗的可能性。分析师明确将欺骗作为假设之一进行分析，并将通过 MOM、POP、MOSES 和 EVE 检查表识别的信息作为 ACH 分析中的证据。

这种技术的起源欺骗以及检测欺骗的努力一直是国际关系的重要组成部分。关于这个主题，有一本优秀的书籍 ——Michael Bennett 和 Edward Waltz 所著的《反欺骗原理与国家安全应用》(波士顿：Artech House, 2007)。本书中关于欺骗检测的描述曾在 Randolph H. Pherson 所著的《分析工具和技术手册》第五版（Tysons, VA：Pherson Associates, LLC, 2019）中发表。一个欺骗检测实际应用的具体例子可以在 https://www.apa.org/monitor/2016/03/deception 找到。

欺骗检测检查表动机、机会和手段（MOM)

动机：潜在欺骗者的目标和动机是什么？渠道：潜在欺骗者通过哪些手段向我们传递信息？风险：如果这种欺骗被揭穿，对手将面临什么后果？成本：潜在欺骗者是否需要付出敏感信息的代价来建立欺骗渠道的可信度？反馈：潜在欺骗者是否有反馈机制来监控欺骗操作的影响？

过去的对手行为（POP)

对手是否有从事欺骗的历史记录？当前情况是否符合过去欺骗行为的模式？如果不符合，是否存在其他历史先例？如果没有，是否有特殊变化可以解释为什么此时采用这种形式的欺骗？

来源操控性（MOSES)

源头是否容易被潜在的欺骗者控制或操纵？我们如何判断源头的可靠性？源头是直接获取信息，还是通过间接途径？源头过去的报告记录如何？

证据评估（EVE)

源头的报告有多准确？整个证据链（包括翻译）是否已经检查过？关键证据是否核实无误？我们需要记住，次要来源的可靠性有时比主要来源更重要。是否有来自不同报告源（如人类情报与信号情报或公开来源报告）之间的证据冲突？其他信息来源是否提供了相应的佐证？预期中的证据缺失是否值得关注？

### 7.9 Argument Mapping

Argument Mapping is a technique that tests a single hypothesis through logical reasoning. An Argument Map starts with a single hypothesis or tentative analytic judgment and then graphically separates the claims and evidence to help break down complex issues and communicate the reasoning behind a conclusion. It is a type of tree diagram that starts with the conclusion or lead hypothesis, and then branches out to reasons, evidence, and finally assumptions. The process of creating the Argument Map helps identify key assumptions and gaps in logic.

An Argument Map makes it easier for both the analysts and the recipients of the analysis to clarify and organize their thoughts and evaluate the soundness of any conclusion. It shows the logical relationships between various thoughts in a systematic way and allows one to assess quickly in a visual way the strength of the overall argument. The technique also helps the analysts and recipients of the report to focus on key issues and arguments rather than focusing too much attention on minor points.

When to Use It

When making an intuitive judgment, use Argument Mapping to test your own reasoning. Creating a visual map of your reasoning and the evidence that supports this reasoning helps you better understand the strengths, weaknesses, and gaps in your argument. It is best to use this technique before you write your product to ensure the quality of the argument and refine it if necessary.

Argument Mapping and Analysis of Competing Hypotheses (ACH) are complementary techniques that work well either separately or together. Argument Mapping is a detailed presentation of the argument for a single hypothesis; ACH is a more general analysis of multiple hypotheses. The ideal is to use both, as follows:

Before you generate an Argument Map, using ACH can be helpful way to take a closer look at the viability of alternative hypotheses. After looking at alternative hypotheses, you can then select the best one to map. After you have identified a favored hypothesis through ACH analysis, Argument Mapping helps check and present the rationale for this hypothesis.

Value Added

An Argument Map organizes one's thinking by showing the logical relationships between the various thoughts, both pro and con. An Argument Map also helps the analyst recognize assumptions and identify gaps in the available knowledge. The visualization of these relationships makes it easier to think about a complex issue and serves as a guide for clearly presenting to others the rationale for the conclusions. Having this rationale available in a visual form helps both the analyst and recipients of the report focus on the key points rather than meandering aimlessly or going off on irrelevant tangents.

When used collaboratively, Argument Mapping helps ensure that a variety of views are expressed and considered, helping mitigate the influence of Groupthink. The visual representation of an argument also makes it easier to recognize weaknesses in opposing arguments. It pinpoints the location of any disagreement, serves as an objective basis for mediating a disagreement, and mitigates against seeking quick and easy answers to difficult problems (Mental Shotgun).

An Argument Map is an ideal tool for dealing with issues of cause and effect—and for avoiding the trap that correlation implies causation (Confusing Causality and Correlation). By laying out all the arguments for and against a lead hypothesis—and all the supporting evidence and logic—it is easy to evaluate the soundness of the overall argument.

The process also helps analysts counter the intuitive traps of Ignoring Base Rate Probabilities by encouraging the analyst to seek out and record all the relevant facts that support each supposition. Similarly, the focus on seeking out and recording all data that support or rebut the key points of the argument makes it difficult for the analyst to overdraw conclusions from a small sample of data (Overinterpreting Small Samples) or to continue to hold to an analytic judgment when confronted with a mounting list of evidence that contradicts the initial conclusion (Rejecting Evidence).

The Method

An Argument Map starts with a hypothesis—a single-sentence statement, judgment, or claim about which the analyst can, in subsequent statements, present general arguments and detailed evidence, both pro and con. Boxes with arguments are arrayed hierarchically below this statement; these boxes are connected with arrows. The arrows signify that a statement in one box is a reason to believe, or not to believe, the statement in the box to which the arrow is pointing. Different types of boxes serve different functions in the reasoning process, and boxes use some combination of color-coding, icons, shapes, and labels so that one can quickly distinguish arguments supporting a hypothesis from arguments opposing it. Figure 7.9 is a simple example of Argument Mapping, showing some of the arguments bearing on the assessment that North Korea has nuclear weapons.

These are the specific steps involved in constructing a generic Argument Map:

Write down the lead hypothesis—a single-sentence statement, judgment, or claim at the top of the argument tree. Draw a set of boxes below this initial box and list the key reasons why the statement is true along with the key objections to the statement. Use green lines to link the reasons to the primary claim or other conclusions they support. Use green lines to connect evidence that supports the key reason. ( Hint: State the reason and then ask yourself, "Because?" The answer should be the evidence you are seeking.) Identify any counterevidence that is inconsistent with the reason. Use red lines to link the counterevidence to the reasons they contradict. Identify any objections or challenges to the primary claim or key conclusions. Use red lines to connect the objections to the primary claim or key conclusions. Identify any counterevidence that supports the objections or challenges. Use red lines to link the counterevidence to the objections or challenges it supports. Specify rebuttals, if any, with orange lines. An objection, challenge, or counterevidence that does not have an orange-line rebuttal suggests a flaw in the argument. Evaluate the argument for clarity and completeness, ensuring that red-lined opposing claims and evidence have orange-line rebuttals. If all the reasons can be rebutted, then the argument is without merit.

Potential Pitfalls

Argument Mapping is a challenging skill. Training and practice are required to use the technique properly and to gain its benefits. Detailed instructions for effective use of this technique are available at the website listed below under "Origins of This Technique." Assistance by someone experienced in using the technique is necessary for first-time users. Commercial software and freeware are available for various types of Argument Mapping. In the absence of software, using a self-stick note to represent each box in an Argument Map drawn on a whiteboard can be helpful, as it is easy to move the self-stick notes around as the map evolves and changes.

Origins of This Technique

The use of Argument Mapping goes back to the early nineteenth century. In the early twentieth century, John Henry Wigmore pioneered its use for legal argumentation. The availability of computers to create and modify Argument Maps in the later twentieth century prompted broader interest in Argument Mapping in Australia for use in a variety of analytic domains. The short description here is based on material in the Austhink website: http://www.austhink.com/critical/pages/argument_mapping.html .

Description Figure 7.9 Argument Mapping: Does North Korea Have Nuclear Weapons? Source: Diagram produced using the bCisive Argument Mapping software from Austhink, www.austhink.com.

7.9 论证图

论证图是一种通过逻辑推理验证单一假设的方法。论证图从一个假设或初步分析判断开始，然后通过图形方式分离出相关的声明和证据，帮助分解复杂问题，并展示结论背后的推理过程。论证图是一种树形图，从结论或主要假设出发，然后分支到理由、证据，最后是基础假设。创建论证图的过程有助于发现关键假设和逻辑漏洞。

论证图可以帮助分析员和报告的接收者更清晰地组织和表达他们的思路，并评估结论的合理性。它以系统的方式展示各个观点之间的逻辑关系，使人们能够快速、直观地评估整体论证的强度。这种方法还使分析员和报告接收者能够将注意力集中在主要问题和论点上，而不是次要细节上。

何时使用

在做直观判断时，可以使用论证图（Argument Mapping）来检验自己的推理过程。通过创建一个可视化的图表，展示推理过程及其支撑证据，可以帮助你更好地理解论点的优缺点和存在的漏洞。最好在撰写报告之前使用这一技术，以确保论点的质量，并在必要时进行改进。

论证图和竞争假设分析（Analysis of Competing Hypotheses, ACH）是互补的技术，可以单独使用，也可以结合使用。论证图详细展示了单一假设的推理过程；ACH 则是对多种假设的综合分析。理想的做法是同时使用这两种技术，如下所示：

在生成论证图之前，使用 ACH 可以更仔细地评估各种替代假设的可行性。审视替代假设之后，可以选择最优的假设进行图示。在通过 ACH 分析确定了一个偏好的假设之后，论证图可以帮助检查和展示这一假设的推理依据。

价值所在论证图通过展示各种观点之间的逻辑关系来组织思维，包括支持和反对的观点。它还可以帮助分析师识别假设并发现现有知识中的漏洞。可视化这些关系可以更容易地思考复杂问题，并为清晰地向他人展示结论的依据提供指导。将这些依据以可视化形式展示，有助于分析师和报告的读者集中注意力在关键点上，而不是漫无目的地讨论或偏离主题。

在协作使用时，论证图（Argument Mapping）有助于确保多种观点得以表达和考虑，从而减轻群体思维（Groupthink）的影响。论证图的视觉化表示还使得发现反对观点中的弱点变得更容易。它能够明确指出分歧的位置，作为调解分歧的客观依据，并能避免对复杂问题寻求快速而简单的答案（Mental Shotgun）。

论证图是处理因果关系问题的理想工具，同时还能避免将相关性误认为因果关系的陷阱（混淆因果关系和相关性）。通过列出支持和反对某个主要假设的所有论点，以及所有相关的证据和逻辑，可以轻松评估整个论证的合理性。

这一过程还通过鼓励分析师寻找并记录所有支持每个假设的相关事实，帮助他们对抗忽视基准概率的直觉陷阱（忽视基准概率）。同样，专注于寻找和记录所有支持或反驳关键论点的数据，使得分析师难以基于小样本数据得出过度结论（过度解释小样本），或者在面对越来越多的反对证据时坚持原有的分析判断（拒绝证据）。

该方法

论证图（Argument Map）是从一个假设开始的。这是一个单句的陈述、判断或主张，分析师可以在后续的陈述中提出支持和反对的总体论点和详细证据。带有论点的框按照层次排列在这一陈述的下方，并通过箭头连接。箭头表示一个框中的陈述是支持或反对箭头所指向的框中陈述的理由。不同类型的框在推理过程中有不同的作用，这些框通过颜色编码、图标、形状和标签的组合来区分支持假设的论点和反对假设的论点。图 7.9 是一个简单的论证图示例，展示了一些关于评估朝鲜是否拥有核武器的论点。

构建通用论证图的具体步骤如下：

写下主要假设，即在论证树顶端的一个单句陈述、判断或主张。在这个初始框下画出一组框，列出支持该陈述的主要原因和反对意见。用绿色线条将这些原因与主要假设或它们支持的其他结论连接。用绿色线条连接支持这些原因的证据（提示：陈述原因，然后问自己「为什么？」答案就是你要找的证据）。找出任何与原因不一致的反证据。用红色线条将反证据与它们所矛盾的原因连接。找出任何对主要假设或主要结论的反对意见或挑战。用红色线条将反对意见与主要假设或主要结论连接。找出支持这些反对意见或挑战的反证据。用红色线条将反证据与它支持的反对意见或挑战连接。用橙色线条标出任何反驳。如果某个反对意见、挑战或反证据没有橙线反驳，表明论证存在缺陷。评估论证的清晰度和完整性，确保红线标出的反对主张和证据有橙线反驳。如果所有原因都可以反驳，那么该论证是没有根据的。

潜在的陷阱

Argument Mapping（论证图谱）是一项需要挑战的技能。需要通过培训和练习才能正确掌握并享受到它带来的好处。关于如何有效使用这种技术的详细说明，可以在「该技术的起源」部分列出的网站中找到。对于第一次使用的人来说，寻求有经验者的帮助是非常必要的。市面上有各种商业软件和免费软件可供选择，用于不同类型的 Argument Mapping。如果没有软件，可以使用便签纸代表 Argument Map（论证图谱）中的各个框，并将其贴在白板上，这样在图谱演变和变化时，可以方便地移动便签纸。

该技术的起源

Argument Mapping（论证图谱）的使用可以追溯到 19 世纪初。在 20 世纪初，John Henry Wigmore 首次将其用于法律论证。到了 20 世纪后期，计算机的普及使得创建和修改 Argument Map 变得更加方便，这促使澳大利亚在各种分析领域中广泛应用 Argument Mapping。这里简要描述基于 Austhink 网站上的材料：http://www.austhink.com/critical/pages/argument_mapping.html 。

描述图 7.9 Argument Mapping：朝鲜是否拥有核武器？来源：由 Austhink 的 bCisive Argument Mapping 软件制作的图表，www.austhink.com。

### Notes

1. See the discussion in chapter 2 contrasting the characteristics of System 1, or intuitive thinking, with System 2, or analytic thinking.

2. Karl Popper, The Logic of Science (New York: Basic Books, 1959).

3. Stuart K. Card, "The Science of Analytical Reasoning," in Illuminating the Path: The Research and Development Agenda for Visual Analytics , eds. James J. Thomas and Kristin A. Cook (Richland, WA: National Visualization and Analytics Center, Pacific Northwest National Laboratory, 2005), https://pdfs.semanticscholar.org/e6d0/612d677199464af131c16ab0fa657d6954f2.pdf

4. See Popper, The Logic of Science .

5. A more detailed description of Te@mACH ® can be found on the Software tab at http://www.globalytica.com . The software is in the process of being rehosted in 2019.

6. Richards J. Heuer Jr., Psychology of Intelligence Analysis (Washington, DC: CIA Center for the Study of Intelligence, 1999; reprinted by Pherson Associates, LLC, Reston, VA, 2007).

7. Richards J. Heuer Jr., "Cognitive Factors in Deception and Counterdeception," in Strategic Military Deception , eds. Donald C. Daniel and Katherine L. Herbig (New York: Pergamon Press, 1982).

8. Heuer, "Cognitive Factors in Deception and Counterdeception"; Michael I. Handel, "Strategic and Operational Deception in Historical Perspective," in Strategic and Operational Deception in the Second World War , ed. Michael I. Handel (London: Frank Cass, 1987).

注释

1. 参见第 2 章关于 System 1（直觉思维）与 System 2（分析性思维）特征的讨论。

2. Karl Popper，《科学的逻辑》（纽约：Basic Books，1959 年）。

3. Stuart K. Card，「分析推理的科学」，收录于 Illuminating the Path：The Research and Development Agenda for Visual Analytics ，编者 James J. Thomas 和 Kristin A. Cook（Richland, WA：国家可视化与分析中心，太平洋西北国家实验室，2005 年），https://pdfs.semanticscholar.org/e6d0/612d677199464af131c16ab0fa657d6954f2.pdf

4. 参见 Popper，《科学的逻辑》。

5. 有关 Te@mACH ® 的更详细描述可以在 http://www.globalytica.com 的软件栏目中找到。这款软件计划在 2019 年重新托管。

6. Richards J. Heuer Jr.，《情报分析的心理学》(华盛顿特区：CIA 情报研究中心，1999 年；由 Pherson Associates, LLC 重印，弗吉尼亚州雷斯顿，2007 年)。

7. Richards J. Heuer Jr.，"欺骗与反欺骗中的认知因素"，见《战略军事欺骗》，编者 Donald C. Daniel 和 Katherine L. Herbig（纽约：Pergamon Press, 1982)。

8. Heuer，"欺骗与反欺骗中的认知因素"；Michael I. Handel，"历史视角下的战略与操作性欺骗"，见《二战中的战略与操作性欺骗》，编者 Michael I. Handel（伦敦：Frank Cass, 1987)。

Descriptions of Images and Figures

Back to Figure

Data from the timeline are as follows. February 7: Range instrumentation radar first active. February 12: Airframes observed on ground transport. February 13: TELs observed at suspected launch site. February 16: Transporters observed at launch site. February 24: Telemetry first active. February 28: Military establishes communication links. March 2: Missiles observed on training pads. March 11: Propellant handling activity observed. March 13: Azimuth markers observed on launch pads. March 18: Transporters moved to launch area. March 23: Airframe revealed. April 1: Propellant loading underway. April 3: Navigational closure area announced, and TEL and equipment transloading. April 5: Military assets deployed to support launch. April 6: Missiles launched.

Back to Figure

The cells in each row show the impact of the variable represented by that row on each of the variables listed across the top of the matrix. The cells in each column show the impact of each variable listed down the left side of the matrix on the variable represented by the column.

Variables 2 and 4 in the cross-impact matrix have the greatest effect on the other variables, while variable 6 has the most negative effect.

| - | Variable 1 | Variable 2 | Variable 3 | Variable 4 | Variable 5 | Variable 6 |
| --- | --- | --- | --- | --- | --- | --- |
| Variable 1 | Nil | Neutral | Positive | Neutral | Strong negative | Neutral |
| Variable 2 | Neutral | Nil | Negative | Strong positive | Positive | Positive |
| Variable 3 | Strong positive | Negative | Nil | Positive | Neutral | Negative |
| Variable 4 | Neutral | Strong positive | Neutral | Nil | Positive | Negative |
| Variable 5 | Strong negative | Positive | Neutral | Positive | Nil | Neutral |
| Variable 6 | Negative | Positive | Strong negative | Negative | Negative | Nil |

Back to Figure

Idea is generated by a group, who performs structured brainstorming to produce 1 to 3 alternative hypotheses. A list of possible alternative hypotheses leads to idea evaluation and consolidation, such as formation of affinity groups 1 through 4, and their related hypotheses. The final list consists of hypotheses. Text for the group reads, "Is the group sufficiently diverse?" Text for structured brainstorming reads, "Prompt creativity by using situational logic, historical analogies, and theory." Text for the list of possible hypotheses reads, "Does this initial list take into account all the key forces and factors?" Text for the affinity group reads, "Create groups of similar hypotheses. Ask if the opposite could be true to generate new ideas." Text for the hypotheses list reads, "Are the hypotheses mutually exclusive? Is the list comprehensive? Did you clarify each hypothesis by asking who, what, how, when, where, and why?"

Back to Figure

The illustration shows a quadrant. The top side is labeled centralized; the right side is labeled religious; the bottom side is labeled decentralized; and the left side is labeled secularized. H1: Centralized state and secularized society. H2: Centralized state and religious society. H3: Decentralized state and secularized society. H4: Decentralized state and religious society.

Back to Figure

The matrix lists relevant information and hypothesis, buttons for rating credibility, and a column for listing notes, assumptions, and credibility justification. At the top of the matrix, a color legend shows the level of disagreement. The column consists of a tool for reordering hypotheses from most to least likely. The row consists of a tool for moving the most discriminating information to the top of the matrix. The cells consists of options for access chat and viewing analyst ratings. The number of inconsistencies in the hypotheses is also displayed.

Back to Figure

The contention is that North Korea has nuclear weapons. The objection to this is that North Korea does not have technical capacity to produce enough weapons-grade fissile material. A rebuttal to this is that North Korea was provided key information and technology by Pakistan around 1997. The reasoning to the contention is that North Korea has exploded nuclear weapons in tests. The evidence to this is that North Korea claimed to have exploded test weapons in 2006 and 2009, and that there are seismological evidence of powerful explosions.

图像和图表的描述回到图表时间线中的数据如下。2 月 7 日：射程测量雷达首次启用。2 月 12 日：观察到机身在地面运输。2 月 13 日：在疑似发射地点观察到 TEL（运输 / 起竖 / 发射装置）。2 月 16 日：在发射地点观察到运输车。2 月 24 日：遥测系统首次启用。2 月 28 日：军方建立了通信链接。3 月 2 日：在训练场上观察到导弹。3 月 11 日：观察到推进剂处理活动。3 月 13 日：在发射台上观察到方位标记。3 月 18 日：运输车移至发射区域。3 月 23 日：揭示了机身。4 月 1 日：推进剂装载进行中。4 月 3 日：宣布导航关闭区域，并重新装载 TEL 和设备。4 月 5 日：部署军事资产以支持发射。4 月 6 日：导弹发射。

回到图表每行中的单元格显示该行代表的变量对矩阵顶部列出的每个变量的影响。每列中的单元格显示左侧列出的每个变量对该列代表的变量的影响。

变量 2 和 4 在交叉影响矩阵中对其他变量影响最大，而变量 6 负面影响最大。

| - | 变量 1 | 变量 2 | 变量 3 | 变量 4 | 变量 5 | 变量 6 |
| --- | --- | --- | --- | --- | --- | --- |
| 变量 1 | 无影响 | 中性 | 正向 | 中性 | 强负面 | 中性 |
| 变量 2 | 中性 | 无影响 | 负向 | 强正向 | 正向 | 正向 |
| 变量 3 | 强正向 | 负向 | 无影响 | 正向 | 中性 | 负向 |
| 变量 4 | 中性 | 强正向 | 中性 | 无影响 | 正向 | 负向 |
| 变量 5 | 强负面 | 正向 | 中性 | 正向 | 无影响 | 中性 |
| 变量 6 | 负向 | 正向 | 强负面 | 负向 | 负向 | 无影响 |

如图一个小组通过结构化的头脑风暴产生 1 到 3 个替代假设。可能的替代假设列表引导了思想评估和整合，例如形成 1 到 4 的亲和组及其相关假设。最终列表由这些假设组成。小组的提示为，「小组是否足够多样化？」结构化头脑风暴的提示为，「通过情境逻辑、历史类比和理论来激发创造力。」可能假设列表的提示为，「这个初始列表是否考虑了所有关键力量和因素？」亲和组的提示为，「创建相似假设的小组。问一下相反的情况是否也可能成立，以生成新想法。」假设列表的提示为，「这些假设是否相互排斥？列表是否全面？你是否通过问谁、什么、如何、何时、何地和为什么来澄清每个假设？」

如图

图示展示了一个象限图。顶部标记为「集中化」；右侧标记为「宗教化」；底部标记为「去中心化」；左侧标记为「世俗化」。H1：集中化的国家和世俗化的社会。H2：集中化的国家和宗教化的社会。H3：去中心化的国家和世俗化的社会。H4：去中心化的国家和宗教化的社会。

矩阵列出了相关信息和假设，还有用于评级可信度的按钮和记录备注、假设以及可信度理由的列。在矩阵顶部，有一个显示分歧程度的颜色图例。列中包含一个用于按可能性排序假设的工具。行中有一个用于将最具区分度的信息移动到矩阵顶部的工具。单元格中有访问聊天和查看分析师评级的选项。假设中的不一致数量也显示出来。

争论点是关于朝鲜是否拥有核武器。反对意见是朝鲜没有生产足够武器级裂变材料的技术能力。对此的反驳是朝鲜在 1997 年左右从巴基斯坦获得了关键信息和技术。支持这一争论点的推理是朝鲜在测试中引爆了核武器。证据是朝鲜声称在 2006 年和 2009 年的测试中引爆了核武器，并且有强烈爆炸的地震学证据。