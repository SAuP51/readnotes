# 2019065利用Python进行数据分析R00

## 记忆时间


## 模板

### 1. 逻辑脉络

用自己的话总结主题，梳理逻辑脉络，也就是这本书整个地图里这一章所在的节点。

### 2. 摘录及评论

## 序

时过境迁，从本书英文版第 1 版 2012 年出版至今，已经过去了 6 年。这 6 年中，Python 的主流版本从 2.7 升级到了 3.6。无论是否情愿，大部分 Pythoner 都不得不学会适应新版本；而 pandas 则从 0.1.0 版本送代到如今的 0.22.0 版本。版本号的持续増加意味着新技术、新特性的不断丰富。

本书英文版的副书名是「Data Wrangling with Pandas, Numpy, and Ipython」，其中 Wrangling 是一个很难直译的词汇，它的原意是争执、争论，但在书中它描述的是将数据进行规整、处理的意思。希望读者读完本书后，可以使用好 pandas、Numpy 和 python 这些工具，更好地完成数据处理、分析的学习和工作。

## 03. 内建数据结构、函数及文件

### 1. 逻辑脉络

清楚 python 的内建数据结构有哪些（list/dict/tuple/set）；

### 2. 摘录及评论

本章将讨论贯穿本书所要使用的 Python 语言内建功能。由于像 pandas 和 Numpy 这类附加库提供了在大数据集上的高级计算功能，所以它们被设计为与 Python 内建数据操作工具协同使用。

我们将开始介绍 Python 的常用数据结构：元组、列表、字典和集合。然后我们会讨论如何创建可复用的 Python 函数。我们将介绍 Python 文件对象的机制以及如何与你的本地硬盘进行交互。

与元组不同，列表的长度是可变的，它所包含的内容也是可以修改的。你可以使用中括号 [] 或者 list 类型函数来定义列表：

列表与元组非常相似（尽管元组不可修改），它们的很多函数用法是相似的。

list 函数在数据处理中常用于将迭代器或者生成器转化为列表：

insert 与 append 相比，计算代价更高。因为子序列元素不得不在内部移动为新元素提供空间。如果你想要在序列的头部和尾部都插入元素，那你应该探索下 collections.deque，它是一个双端队列，可以满足头尾部都增加的要求。

insert 的反操作是 pop，该操作会将特定位置的元素移除并返回：

如果不考虑性能，通过使用 append 和 remove，你可以将 Python 的列表用作一种完全合适的「多集合」数据结构。

与字典、集合（后面会介绍）相比，检查列表中是否包含一个值是非常缓慢的。这是因为 Python 在列表中进行了线性逐个扫描，而在字典和集合中 Python 是同时检查所有元素的（基于哈希表）。

请注意通过添加内容来连接列表是一种相对高代价的操作，这是因为连接过程中创建了新列表，并且还要复制对象。使用 extend 将元素添加到已经存在的列表是更好的方式，尤其是在你需要构建一个大型列表时：

你可以调用列表的 sort 方法对列表进行内部排序（无须新建一个对象）：

sort 有一些选项偶尔会派上用场。其中一项是传递一个二级排序 key —— 一个用于生成排序值的函数。例如，我们可以通过字符串的长度进行排序：

下面，我们会讨论 sorted 方法，该方法可以针对通用序列产生一个排序后的拷贝。

内建的 bisect 模块实现了二分搜索和已排序列表的插值。bisect.bisect 会找到元素应当被插入的位置，并保持序列排序，而 bisect.insort 将元素插入到相应位置：

使用切片符号可以对大多数序列类型选取其子集，它的基本形式是将 start:stop 传入到索引符号 [ ] 中：

由于起始位置 start 的索引是包含的，而结束位置 stop 的索引并不包含，因此元素的数量是 stop-start。

start 和 stop 是可以省略的，如果省略的话会默认传入序列的起始位置或结束位置：

负索引可以从序列的尾部进行索引：

步进值 step 可以在第二个冒号后面使用，意思是每隔多少个数取一个值：

Python 有很多有用的序列函数，你应当熟悉并择机使用。

我们经常需要在遍历一个序列的同时追踪当前元素的索引。一种自行实现的方法像下面的示例：

由于这种场景很常见，所以 Python 内建了 enumerate 函数，返回了（i, value）元组的序列，其中 value 是元素的值，i 是元素的索引：

当你需要对数据建立索引时，一种有效的模式就是使用 enumerate 构造一个字典，将序列值（假设是唯一的）映射到索引位置上：

zip 将列表、元组或其他序列的元素配对，新建一个元组构成的列表。

zip 可以处理任意长度的序列，它生成列表长度由最短的序列決定。

zip 的常用场景为同时遍历多个序列，有时候会和 enumerate 同时使用。

给定一个已「配对」的序列时，zip 函数有一种机智的方式去「拆分」序列。这种方式的另一种思路就是将行的列表转换为列的列表。语法看上去略显魔幻：





## 04. NumPy基础：数组和矢量计算

### 1. 逻辑脉络


### 2. 摘录及评论

NumPy（Numerical Python 的简称）是 Python 数值计算最重要的基础包。大多数提供科学计算的包都是用 NumPy 的数组作为构建基础。

NumPy 的部分功能如下：

1. ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。

2. 用于对整组数据进行快速运算的标准数学函数（无需编写循环）。

3. 用于读写磁盘数据的工具以及用于操作内存映射文件的工具。

4. 线性代数、随机数生成以及傅里叶变换功能。

5. 用于集成由 C、C++、Fortran 等语言编写的代码的 C 语言 API。

由于 NumPy 提供了一个简单易用的 C 语言 API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以 NumPy 数组的形式将数据返回给 Python。这个功能使 Python 成为一种包装 C/C++/Fortran 历史代码库的选择，并使被包装库拥有一个动态的、易用的接口。

NumPy 本身并没有提供多么高级的数据分析功能，理解 NumPy 数组以及面向数组的计算将有助于你更加高效地使用诸如 pandas 之类的工具。因为 NumPy 是一个很大的题目，我会在附录 A 中介绍更多 NumPy 高级功能，比如广播。

对于大部分数据分析应用而言，我最关注的功能主要集中在：

1. 用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算。

2. 常用的数组算法，如排序、唯一化、集合运算等。

3. 高效的描述统计和数据聚合/摘要运算。

4. 用于异构数据集的合并/连接运算的数据对齐和关系型数据运算。

5. 将条件逻辑表述为数组表达式（而不是带有 if-elif-else 分支的循环）。

6. 数据的分组运算（聚合、转换、函数应用等）。

虽然 NumPy 提供了通用的数值数据处理的计算基础，但大多数读者可能还是想将 pandas 作为统计和分析工作的基础，尤其是处理表格数据时。pandas 还提供了一些 NumPy 所没有的更加领域特定的功能，如时间序列处理等。

笔记：Python 的面向数组计算可以追溯到 1995 年，Jim Hugunin 创建了 Numeric 库。接下来的 10 年，许多科学编程社区纷纷开始使用 Python 的数组编程，但是进入 21 世纪，库的生态系统变得碎片化了。2005 年，Travis Oliphant 从 Numeric 和 Numarray 项目整了出了 NumPy 项目，进而所有社区都集合到了这个框架下。

NumPy 之于数值计算特别重要的原因之一，是因为它可以高效处理大数组的数据。这是因为：

1. NumPy 是在一个连续的内存块中存储数据，独立于其他 Python 内置对象。NumPy 的 C 语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起 Python 的内置序列，NumPy 数组使用的内存更少。

2. NumPy 可以在整个数组上执行复杂的计算，而不需要 Python 的 for 循环。

基于 NumPy 的算法要比纯 Python 快 10 到 100 倍（甚至更快），并且使用的内存更少。

NumPy 最重要的一个特点就是其 N 维数组对象（即 ndarray），该对象是一个快速而灵活的大数据集容器。你可以利用这种数组对整块数据执行一些数学运算，其语法跟标量元素之间的运算一样。

要明白 Python 是如何利用与标量值类似的语法进行批次计算，我先引入 NumPy，然后生成一个包含随机数据的小数组：

笔记：在本章及全书中，我会使用标准的 NumPy 惯用法 import numpy as np。你当然也可以在代码中使用 from numpy import *，但不建议这么做。numpy 的命名空间很大，包含许多函数，其中一些的名字与 Python 的内置函数重名（比如 min 和 max）。

ndarray 是一个通用的同构数据多维容器，也就是说，其中的所有元素必须是相同类型的。每个数组都有一个 shape（一个表示各维度大小的元组）和一个 dtype（一个用于说明数组数据类型的对象）：

1『shape 和 dtype 是多维数组对象里的属性。比如 data.shape 返回的是数组各个维度的大小，比如是 (2, 3)；data.dtype 返回的是多维数组数据类型，比如是 dtype('float64')。』

本章将会介绍 NumPy 数组的基本用法，这对于本书后面各章的理解基本够用。虽然大多数数据分析工作不需要深入理解 NumPy，但是精通面向数组的编程和思维方式是成为 Python 科学计算牛人的一大关键步骤。

笔记：当你在本书中看到「数组」、「NumPy 数组」、「ndarray」时，基本上都指的是同一样东西，即 ndarray 对象。

创建数组最简单的办法就是使用 array 函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的 NumPy 数组。以一个列表的转换为例：

嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组：

因为 data2 是列表的列表，NumPy 数组 arr2 的两个维度的 shape 是从 data2 引入的。可以用属性 ndim 和 shape 验证：

除非特别说明（稍后将会详细介绍），np.array 会尝试为新建的这个数组推断出一个较为合适的数据类型。数据类型保存在一个特殊的 dtype 对象中。

除 np.array 之外，还有一些函数也可以新建数组。比如，zeros 和 ones 分别可以创建指定长度或形状的全 0 或全 1 数组。empty 可以创建一个没有任何具体值的数组。要用这些方法创建多维数组，只需传入一个表示形状的元组即可：

注意：认为 np.empty 会返回全 0 数组的想法是不安全的。很多情况下（如前所示），它返回的都是一些未初始化的垃圾值。

arange 是 Python 内置函数 range 的数组版：

表 4-1 列出了一些数组创建函数。由于 NumPy 关注的是数值计算，因此，如果没有特别指定，数据类型基本都是 float64（浮点数）。



## 05. pandas 入门

### 1. 逻辑脉络

pandas 入门概念：基于 numpy 数组构建的；专门处理表格和混杂数据设计；Series 数据结构和 DataFrame 数据结构；

### 2. 摘录及评论

pandas 是本书后续内容的首选库。它含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具。pandas 经常和其它工具一同使用，如数值计算工具 NumPy 和 SciPy，分析库 statsmodels 和 scikit-learn，和数据可视化库 matplotlib。pandas 是基于 NumPy 数组构建的，特别是基于数组的函数和不使用 for 循环的数据处理。虽然 pandas 采用了大量的 NumPy 编码风格，但二者最大的不同是 pandas 是专门为处理表格和混杂数据设计的。而 NumPy 更适合处理统一的数值数组数据。

要使用 pandas，你首先就得熟悉它的两个主要数据结构：Series 和 DataFrame。虽然它们并不能解决所有问题，但它们为大多数应用提供了一种可靠的、易于使用的基础。

Series 是一种类似于一维数组的对象，它由一组数据（各种 NumPy 数据类型）以及一组与之相关的数据标签（即索引）组成。Series 的字符串表现形式为：索引在左边，值在右边。由于我们没有为数据指定索引，于是会自动创建一个 0 到 N-1（N 为数据的长度）的整数型索引。你可以通过 Series 的 values 和 index 属性获取其数组表示形式和索引对象：

使用 NumPy 函数或类似 NumPy 的运算（如根据布尔型数组进行过滤、标量乘法、应用数学函数等）都会保留索引值的链接：

还可以将 Series 看成是一个定长的有序字典，因为它是索引值到数据值的一个映射。它可以用在许多原本需要字典参数的函数中：

如果数据被存放在一个 Python 字典中，也可以直接通过这个字典来创建 Series：

```
In [26]: sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000} 
In [27]: obj3 = pd.Series(sdata) 
```

如果只传入一个字典，则结果 Series 中的索引就是原字典的键（有序排列）。你可以传入排好序的字典的键以改变顺序：

在这个例子中，sdata 中跟 states 索引相匹配的那 3 个值会被找出来并放到相应的位置上，但由于 "California" 所对应的 sdata 值找不到，所以其结果就为 NaN（即「非数字」（not a number），在 pandas 中，它用于表示缺失或 NA 值）。因为 ‘Utah’ 不在 states 中，它被从结果中除去。我将持续使用缺失（missing）或 NA 表示缺失数据。pandas 的 isnull 和 notnull 函数可用于检测缺失数据：

对于许多应用而言，Series 最重要的一个功能是，它会根据运算的索引标签自动对齐数据：

1『两个字典合并后自动剔除重复的元素。』

数据对齐功能将在后面详细讲解。如果你使用过数据库，你可以认为是类似 join 的操作。Series 对象本身及其索引都有一个 name 属性，该属性跟 pandas 其他的关键功能关系非常密切：

Series 的索引可以通过赋值的方式就地修改：

DataFrame 是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共用同一个索引）。DataFrame 中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。有关 DataFrame 内部的技术细节远远超出了本书所讨论的范围。

笔记：虽然 DataFrame 是以二维结构保存数据的，但你仍然可以轻松地将其表示为更高维度的数据（层次化索引的表格型结构，这是 pandas 中许多高级数据处理功能的关键要素，我们会在第 8 章讨论这个问题）。

建 DataFrame 的办法有很多，最常用的一种是直接传入一个由等长列表或 NumPy 数组组成的字典：

结果 DataFrame 会自动加上索引（跟 Series 一样），且全部列会被有序排列：

如果你使用的是 Jupyter notebook，pandas DataFrame 对象会以对浏览器友好的 HTML 表格的方式呈现。对于特别大的 DataFrame，head 方法会选取前五行：

如果指定了列序列，则 DataFrame 的列就会按照指定顺序进行排列：

1『这里展现的数据形式，跟 pdms 三维抽出来的材料数据是一样的。如何把材料数据转化为一个 DataFrame 表格型的数据结构即为下一步的动作。』

如果传入的列在数据中找不到，就会在结果中产生缺失值：

通过类似字典标记的方式或属性的方式，可以将 DataFrame 的列获取为一个 Series：

笔记：IPython 提供了类似属性的访问（即 frame2.year）和 tab 补全。

frame2 [column] 适用于任何列的名，但是 frame2.column 只有在列名是一个合理的 Python 变量名时才适用。注意，返回的 Series 拥有原 DataFrame 相同的索引，且其 name 属性也已经被相应地设置好了。行也可以通过位置或名称的方式进行获取，比如用 loc 属性（稍后将对此进行详细讲解）：

列可以通过赋值的方式进行修改。例如，我们可以给那个空的 "debt" 列赋上一个标量值或一组值：

将列表或数组赋值给某个列时，其长度必须跟 DataFrame 的长度相匹配。如果赋值的是一个 Series，就会精确匹配 DataFrame 的索引，所有的空位都将被填上缺失值：

如果被赋值的列并不存在，则会生成一个新的列。del 关键字可以像在字典中那样对 DataFrame 删除列。作为 del 的例子，我先添加一个新的布尔值的列，state 是否为 'Ohio'：

注意：不能用 frame2.eastern 创建新的列。del 方法可以用来删除这列：

注意：通过索引方式返回的列只是相应数据的视图而已，并不是副本。因此，对返回的 Series 所做的任何就地修改全都会反映到源 DataFrame 上。通过 Series 的 copy 方法即可指定复制列。另一种常见的数据形式是嵌套字典：

如果嵌套字典传给 DataFrame，pandas 就会被解释为：外层字典的键作为列，内层键则作为行索引：

你也可以使用类似 NumPy 数组的方法，对 DataFrame 进行转置（交换行和列）：

内层字典的键会被合并、排序以形成最终的索引。如果明确指定了索引，则不会这样：

如果设置了 DataFrame 的 index 和 columns 的 name 属性，则这些信息也会被显示出来：

跟 Series 一样，values 属性也会以二维 ndarray 的形式返回 DataFrame 中的数据：

pandas 的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建 Series 或 DataFrame 时，所用到的任何数组或其他序列的标签都会被转换成一个 Index：

Index 对象是不可变的，因此用户不能对其进行修改；不可变可以使 Index 对象在多个数据结构之间安全共享：

注意：虽然用户不需要经常使用 Index 的功能，但是因为一些操作会生成包含被索引化的数据，理解它们的工作原理是很重要的。除了类似于数组，Index 的功能也类似一个固定大小的集合：

1『Index 是 pandas 模块里的一个方法。』

与 python 的集合不同，pandas 的 Index 可以包含重复的标签：

根据重复标签进行筛选，会选取所有重复标签对应的数据。每个索引都有一些集合逻辑的方法和属性，这些方法和属性解决了关于它所包含的数据的其他常见问题。表 5-2 中总结了这些方法和属性中常用的一部分。

将介绍操作 Series 和 DataFrame 中的数据的基本手段。后续章节将更加深入地挖掘 pandas 在数据分析和处理方面的功能。本书不是 pandas 库的详尽文档，主要关注的是最重要的功能，那些不大常用的内容（也就是那些更深奥的内容）就交给你自己去摸索吧。

pandas 对象的一个重要方法是 reindex，其作用是创建一个新对象，它的数据符合新的索引。看下面的例子：

对于时间序列这样的有序数据，重新索引时可能需要做一些插值处理。method 选项即可达到此目的，例如，使用 ffill 可以实现前向值填充：

借助 DataFrame，reindex 可以修改（行）索引和列。只传递一个序列时，会重新索引结果的行：

列可以用 columns 关键字重新索引。表 5-3 列出了 reindex 函数的各参数及说明。

如果你已经拥有索引数组或不含条目的列表，在轴向上删除一个或更多的条目就非常容易，但这样需要一些数据操作和集合逻辑，drop 方法会返回一个含有指示值或轴向上删除值的新对象：

1『drop() 方法删除数据结构里任意轴线上的数据，一行或一列，多行或多列。』

用标签序列调用 drop 会从行标签（axis 0）删除值：

通过传递 axis=1 或 axis='columns' 可以删除列的值：

许多函数，如 drop，会修改 Series 或 DataFrame 的大小或形状，可以就地修改对象，不会返回新的对象：

小心使用 inplace，它会销毁所有被删除的数据。

1『inplace 是 drop() 方法的一个形参。』

Series 索引（obj [...]）的工作方式类似于 NumPy 数组的索引，只不过 Series 的索引值不只是整数。下面是几个例子：

利用标签的切片运算与普通的 Python 切片运算不同，其末端是包含的：

用切片可以对 Series 的相应部分进行设置：1『赋值设置。』

用一个值或序列对 DataFrame 进行索引其实就是获取一个或多个列：

这种索引方式有几个特殊的情况。首先通过切片或布尔型数组选取数据：

选取行的语法 data [:2] 十分方便。向 [ ] 传递单一的元素或列表，就可选择列。另一种用法是通过布尔型 DataFrame（比如下面这个由标量比较运算得出的）进行索引；这使得 DataFrame 的语法与 NumPy 二维数组的语法很像。

对于 DataFrame 的行的标签索引，我引入了特殊的标签运算符 loc 和 iloc。它们可以让你用类似 NumPy 的标记，使用轴标签（loc）或整数索引（iloc），从 DataFrame 选择行和列的子集。作为一个初步示例，让我们通过标签选择一行和多列：

这两个索引函数也适用于一个标签或多个标签的切片：

所以，在 pandas 中，有多个方法可以选取和重新组合数据。对于 DataFrame，表 5-4 进行了总结。后面会看到，还有更多的方法进行层级化索引。

笔记：在一开始设计 pandas 时，我觉得用 frame [:, col] 选取列过于繁琐（也容易出错），因为列的选择是非常常见的操作。我做了些取舍，将花式索引的功能（标签和整数）放到了 ix 运算符中。在实践中，这会导致许多边缘情况，数据的轴标签是整数，所以 pandas 团队决定创造 loc 和 iloc 运算符分别处理严格基于标签和整数的索引。ix 运算符仍然可用，但并不推荐。

处理整数索引的 pandas 对象常常难住新手，因为它与 Python 内置的列表和元组的索引语法不同。为了进行统一，如果轴索引含有整数，数据选取总会使用标签。为了更准确，请使用 loc（标签）或 iloc（整数）：

pandas 最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。看一个简单的例子：

没有交叠的标签位置上，内部数据对齐会产生缺失值。缺失值会在后续的算术操作上产生影响。在 DataFrame 的示例中，行和列上都会执行对齐：

将这些对象加在一起，返回一个 DataFrame，它的索引、列是每个 DataFrame 的索引、列的并集：

因为 'c' 和 'e' 列均不在两个 DataFrame 对象中，在结果中以缺省值呈现。行也是同样。如果 DataFrame 对象相加，没有共用的列或行标签，结果都会是空：








## 06. 数据加载、存储与文件格式

### 1. 逻辑脉络


### 2. 摘录及评论

访问数据是使用本书所介绍的这些工具的第一步。我会着重介绍 pandas 的数据输入与输出，虽然别的库中也有不少以此为目的的工具。输入输出通常可以划分为几个大类：读取文本文件和其他更高效的磁盘存储格式，加载数据库中的数据，利用 Web API 操作网络资源。

pandas 提供了一些用于将表格型数据读取为 DataFrame 对象的函数。表 6-1 对它们进行了总结，其中 read_csv 和 read_table 可能会是你今后用得最多的。

我将大致介绍一下这些函数在将文本数据转换为 DataFrame 时所用到的一些技术。这些函数的选项可以划分为以下几个大类：

1、索引：将一个或多个列当做返回的 DataFrame 处理，以及是否从文件、用户获取列名。

2、类型推断和数据转换：包括用户定义值的转换、和自定义的缺失值标记列表等。

3、日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。

4、迭代：支持对大文件进行逐块迭代。

5、不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西（比如由成千上万个逗号隔开的数值数据）。

因为工作中实际碰到的数据可能十分混乱，一些数据加载函数（尤其是 read_csv）的选项逐渐变得复杂起来。面对不同的参数，感到头痛很正常（read_csv 有超过 50 个参数）。pandas 文档有这些参数的例子，如果你感到阅读某个文件很难，可以通过相似的足够多的例子找到正确的参数。其中一些函数，比如 pandas.read_csv，有类型推断功能，因为列数据的类型不属于数据类型。也就是说，你不需要指定列的类型到底是数值、整数、布尔值，还是字符串。其它的数据格式，如 HDF5、Feather 和 msgpack，会在格式中存储数据类型。

日期和其他自定义类型的处理需要多花点工夫才行。首先我们来看一个以逗号分隔的（CSV）文本文件：

笔记：这里，我用的是 Unix 的 cat shell 命令将文件的原始内容打印到屏幕上。如果你用的是 Windows，你可以使用 type 达到同样的效果。

由于该文件以逗号分隔，所以我们可以使用 read_csv 将其读入一个 DataFrame：

我们还可以使用 read_table，并指定分隔符：

并不是所有文件都有标题行。读入该文件的办法有两个。你可以让 pandas 为其分配默认的列名，也可以自己定义列名：

假设你希望将 message 列做成 DataFrame 的索引。你可以明确表示要将该列放到索引 4 的位置上，也可以通过 index_col 参数指定 "message"：

```
In [15]: names = ['a', 'b', 'c', 'd', 'message'] 
In [16]: pd.read_csv('examples/ex2.csv', names=names, index_col='message') 
```

如果希望将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表即可：

有些情况下，有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其他模式）。有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其他模式来分隔字段）。看看下面这个文本文件：

虽然可以手动对数据进行规整，这里的字段是被数量不同的空白字符间隔开的。这种情况下，你可以传递一个正则表达式作为 read_table 的分隔符。可以用正则表达式表达为 \s+，于是有：

1『用上面的正则表达式处理材料数据失败，必须好好研究正则表达式的知识。』

这些解析器函数还有许多参数可以帮助你处理各种各样的异形文件格式（表 6-2 列出了一些）。比如说，你可以用 skiprows 跳过文件的第一行、第三行和第四行：

缺失值处理是文件解析任务中的一个重要组成部分。缺失数据经常是要么没有（空字符串），要么用某个标记值表示。默认情况下，pandas 会用一组经常出现的标记值进行识别，比如 NA 及 NULL：

na_values 可以用一个列表或集合的字符串表示缺失值：

在处理很大的文件时，或找出大文件中的参数集以便于后续处理时，你可能只想读取文件的一小部分或逐块对文件进行迭代。

如果只想读取几行（避免读取整个文件），通过 nrows 进行指定即可：

要逐块读取文件，可以指定 chunksize（行数）：

read_csv 所返回的这个 TextParser 对象使你可以根据 chunksize 对文件进行逐块迭代。比如说，我们可以迭代处理 ex6.csv，将值计数聚合到 "key" 列中，如下所示：

「read_csv 返回的 TextParser 对象允许你根据 chunksize 遍历文件。例如，我们可以遍历 ex6.csv，并对 ’key’ 列聚合获得计数值：」

TextParser 还有一个 get_chunk 方法，它使你可以读取任意大小的块。












