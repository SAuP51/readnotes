# 2020006陈旸的数据分析R03.md

## 记忆时间

## 卡片

### 0101. 反常识卡——

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

#### 01. 常识

#### 02. 反常识

#### 03. 知识来源

比如提出者，如何演化成型的；书或专栏具体出现的地方。

#### 04. 例子

### 0201. 术语卡——

根据反常识，再补充三个证据——就产生三张术语卡。

例子。

### 0202. 术语卡——

### 0203. 术语卡——

### 0301. 人名卡——

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

维基百科链接：有的话。

#### 01. 出生日期

用一句话描述你对这个大牛的印象。

#### 02. 贡献及经历

#### 03. 论文及书籍

#### 04. 演讲汇总

找一个他的 TED 演讲，有的话。

### 0401. 金句卡——

最后根据他写的非常震撼的话语——产生一张金句卡。

### 0501. 行动卡——

行动卡是能够指导自己的行动的卡。

## 04. 数据分析工作篇

### 1. 逻辑脉络

1、辅助培养数据分析思维的工具：生命线视角、提问和分享。任何一段经历都可以当作生命线，横坐标为时间轴，纵坐标为重要事件（有正有负），影响力越大其绝对值越大；提问本身就是一种维度的观察。有一个好的问题，才会有好的答案。问题可以帮助我们关注事物的不同方面，而且通常是一些重要的维度，对我们全面客观地分析一件事是非常有好处的。提问题还可以让我们变被动为主动；学会分享是最快的成长。分享可以锻炼我们的逻辑性，分享过程也是对知识重新梳理的过程。另一方面也可以让我们获得别人的反馈，更容易得到正反馈的愉悦。就像我们在做机器学习训练的时候，如果训练没有结果反馈，我们就无法客观地了解对知识的掌握程度。如果能得到别人的反馈，就更容易有收获，训练的收敛速度也会越快。

2、简历是最好的工作梳理。HR 看相关项目简历其背后的逻辑是根据历史信息预估一个人相关的工作能力。实战项目过程中需要做的：1）了解每个实战项目的目标；2）理解每个算法的原理；3）跑一遍项目代码，将运行结果放到 GitHub 上；4）做项目的心得总结。简历重点体现，当时的项目目标、采用的解决方案、实现的代码以及项目过程的总结体会拿给 HR 看。

### 2. 摘录及评论

### 0401如何培养你的数据分析思维.md

今天我们做了一个有关生命线的游戏，你能了解到我们每个人、每个公司、每件事，只要有历史数据，都有可能从中发现规律，从而指导未来。所以说数据分析这件事，就好比是生命线一样闪耀着价值。而培养自己的数据化思维虽然不是一天能练就的，却是重要的事情。很多时候，我们容易被紧急的事情牵着走，毕竟紧急事情的优先级会更高。但人生差距不是在于处理多少紧急的事，而是在于做过多少重要的事。从人性的角度来看，重要不紧急的事是容易被拖延的。不过我有两个工具教你摆脱惰性，一个就是学会提问，它从提问的角度训练我们的数据化思维，让我们对事物看得更清楚，另一个就是学会分享，它从反馈的角度让我们的训练过程更加收敛，效率得到提升，也更容易获得成就感。

数据分析可以是一个职业，一份工作，也可以是一种思维方式。在专栏里，我们更多的是讲解了数据分析工具的使用。从 Python 爬虫到 Python 可视化，再到数据清洗、数据挖掘算法等，而在日常工作中，我们除了需要熟练掌握这些工具的使用外，更主要的是培养自己的数据分析思维。培养数据分析思维不仅对找一份和数据分析相关的工作有帮助，在日常生活中同样会有帮助。

1）我们做一个有关生命线的游戏。你可以把生命线看作是数据可视化，能从中发现什么规律呢？2）当你想知道事情的答案，但不知道从何处下手的时候，要怎么办呢？要学会提问。好的问题就是好的开始。遇到茫然的情况，不妨从提问开始。3）「我平时也有一些关于数据分析的思考，但是效率不高，有什么方法可以提升效率么？」分享是最快的成长，通过反向传播可以让我们更快得到收敛。4）「我也知道数据分析思维的训练很重要，但是平时工作很忙该怎么办？」

一个关于生命线的游戏。举个例子，如果你想知道自己是如何挣钱的，你可以分析自己以往挣钱的经历，也可以是赔钱的经历，把它们写在一个时间轴上，纵坐标是发生的事件，这个事件对你的影响越大，纵坐标的绝对值就越大。通过生命线的分析，我们先把这些事件按照时间的顺序记录下来，然后记录它们的影响力。实际上这些事件，影响力 y 和时间 x 就是你的生命线历史数据，画出生命线之前，你不必思考它们之间的规律是什么。画出来之后，你有 30 分钟的时间，仔细思考和分析它们之间有什么关联。

其实你能看出来，画生命线之前，我们首先需要有客观的记录数据，生命线就相当于数据可视化，更容易让我们找到规律。你可以对这些事件打上不同的标签，比如 12 岁的时候给报社投稿挣到了 180 元，26 岁做自媒体，每个月有 2 万收入等等，那么两件事都可以打上「写作」这个标签。我们之前讲过打标签是一种抽象能力。当你对这些事件逐一分析打标签的时候，就有可能从更高的维度上观察到这些事件的规律。

上面这个是关于挣钱方向的生命线游戏，有空的话你可以做一下，分析分析适合自己的挣钱模式是什么。此外还有一个生命线的游戏，你肯定不陌生，那就是简历。在面试之前，你最重要的信息就是简历。HR 会通过简历筛选符合要求的人，一般来说会根据简历来看职业经历是否具有连续性，比如说这个人做过行政，又做过销售，现在面试数据分析的工作，那么对于 HR 来说，他就没有找到职业方向。所以有些人在投递某个职位前，会特地对简历做有针对性的修改，比如重点呈现和数据分析相关的经历，其他关系不大的经历都 一一 删除，哪怕经历再丰富。不相关的经历其实就是干扰数据，这些并不是 HR 想要看到的！

除了分析挣钱、找工作以外，通过生命线做数据分析还能帮我们做什么呢？它可以分析你的感情经历、是否有偏财运等等。数据是非常重要的宝藏，只是你需要知道如何观察它，使用它。通过历史才能看到未来，如果我们不去分析这些历史，就没有办法找到未来的规律。大到国家，小到个人，都是如此。这也是为什么很多成功人士经常读书的原因之一吧。通过总结别人的成功或者失败的经验，可以启迪自己的人生道路。

提问是最好的老师。当了解数据分析的价值之后，你可能会问，学会提问和数据分析思维有什么联系？实际上提问本身就是一种维度的观察。很多人在做数据分析的时候，首先遇到的问题是没有数据怎么办？数据从哪里来？其实在找数据之前，我们应该先问自己一个问题，我要解决什么问题？要分析什么规律？比如说，你想观察自己挣钱模式的规律，或者想解决个人的情感问题，再或者，想找到一份适合自己的工作等。我们首先需要定义一个目标。

然后围绕这个目标再问自己，这些数据可能会在哪里？是通过分析自己过去的经历找，还是从网上找相关的信息？都有哪些渠道可以收集到这些信息？有一个好的问题，才会有好的答案。问题可以帮助我们关注事物的不同方面，而且通常是一些重要的维度，对我们全面客观地分析一件事是非常有好处的。

从科技进步来看，很多时候都是先有一个问题，再有无数的人前赴后继去解决它。比如世界三大数学猜想，费马猜想、四色猜想和哥德巴赫猜想。比如费马大定理是费马在 1637 年提出的，此后的 300 年间有无数数学家试图去验证它。学会提问不仅可以帮助我们对事物有更全面的认识，还可以让我们变被动为主动。要知道在职场上，大部分人的工作状态都属于被动性，比如等着领导下任务、数据分析结果没出来就怪数据不完整，质量不够好等。被动的状态往往能量很低，或者说创造性很低。只有当你主动思考，寻找答案的时候，才更可能会有有创造力的发现。

以我的学习经历为例，很多人在上学期间，基本上都是老师在课上讲，自己只是听，很少提问，信息仅仅限于单向传递。而我经常会把不懂的问题整理下来，下课的时候主动向老师提问，这样做的好处是，勤于思考，可以让知识尽量没有盲点，另外通过提问和思考的方式 ，也可以让我对这个知识掌握得更牢固。我成绩通常不错，后来保送到了清华计算机系，很多人认为我平时学习是不是很晚，其实并没有，我只是善于找学习的规律，提问思考就是最好的学习方式。它更容易让我们对一件事物建立多维度的认知。

学会分享是最快的成长。如果说培养数据思维从提问开始，那么把总结分享作为结束则是最适合不过的。把学到的知识分享给身边的朋友，可以锻炼我们的逻辑性，分享的过程也是对知识重新梳理的过程。另一方面也可以让我们获得别人的反馈，更容易得到正反馈的愉悦。就像我们在做机器学习训练的时候，如果训练没有结果反馈，我们就无法客观地了解对知识的掌握程度。如果能得到别人的反馈，就更容易有收获，训练的收敛速度也会越快。所以在某种程度上，你可以把分享的过程，理解是在测试集上做验证的过程。它会让你收获更多，成长更快。

培养数据分析思维是重要不紧急的事。你可能会说：「道理我都懂，可就是做的时候想不起来。」那是怎么回事呢？实际上，培养数据分析思维是重要不紧急的事。在工作中，我们经常会被紧急的事情占据带宽。这些紧急的事情对当下很重要，但是放长远来看重要性就很弱了。而拉开我们人生差距的，恰恰是那些重要不紧急的事情上，而不是在于我们每天处理了多少紧急的事。这点很容易理解，毕竟人都有惰性，紧急的事情来了一般都会优先处理。不过你要换一种思考方式，既然我们人生的差距不是在于做过多少紧急的事，而是在于做过多少重要的事，那么从工作的第一天开始，我就应该着重积累重要的事，即使它目前并不紧急。

这样你会发现，当你做过的重要事情越来越多的时候，紧急的事情也就越来越少了。比如你想着如何找到一份更高薪酬更适合自己工作的时候，就不用着急每个月还贷款的事情了。

### 0402求职简历中没有相关项目经验怎么办.md

在专栏的讲解过程中，很多同学都反馈过他们正在找工作，但项目经历这块是自己的软肋。我们关键要弄明白 HR 招人背后的逻辑，把相关的训练经验总结下来写在简历中，最后拆解专栏的实战项目。在这个过程中你需要：1）了解每个实战项目的目标；2）理解每个算法的原理；3）跑一遍项目代码，将运行结果放到 GitHub 上；4）做项目的心得总结。当你自己把这些内容整理出来的时候，你发现自己会更有信心。简历的完善只是表象，实际上最重要的是自己的能力也得到了提升。我在专栏里讲解了理论知识、工具方法和实战项目，希望你把专栏作为一个工具，带你走入数据科学的大门。掌握了这个工具之后，平时遇到问题的时候，你就可以用数据的视角来分析它，使用工具来做模拟，总结结果，进一步完善你的简历。另外，简历是最好的工作梳理。

上节课我讲到了如何培养数据分析思维，它是一个重要但不紧急的事。在工作求职中，你可能会遇到各种又重要又紧急的事，比如填写求职简历中的项目经验。它的重要性在于，HR 一般都会依据简历中的项目经验初步筛选候选人是否符合面试要求，紧急性在于求职找工作往往就是眼前的事，但简历中的项目经验又很难临时抱佛脚。项目经验一般没有弹性，一是一，二是二，一方面要保证真实性，是自己做过的项目，另一方面又很难在短时间内积攒这些经验。

如果没有项目经验，很多人就会感觉无从下手，这时候该怎么办呢？我自己面试过的技术人员少说也有上百人，我想以自己的经验做一些分享，在经验积累上和你分享以下三个需要注意的地方：1）我们求职找工作的时候，要理解 HR 看项目经验的逻辑是什么？2）明确要完善项目经验这个目标后，我们该如何快速定位要积累的内容，并通过实战和训练快速进行提升经验值？3）如何在项目经验中融入自己的心得体会，让你的经验显得与众不同？

HR 看相关项目简历，背后的逻辑是什么。HR 之所以要看相关的项目经验，是因为这些历史信息可以帮助他预估一个人相关的工作能力。知识不等于项目经验，即使你对知识都了解了，在实际项目过程中，还是会遇到各种问题。比如工具包安装不上、中文编码错误、画图显示不出来、算法运行过慢、数据拟合结果不好等各种问题。项目经历相当于一种训练，当你得到了更好的训练之后，数据分析的模型能力也就会越强，然后在「新公司」这个测试集中，就越有可能发挥好的效果。

做过训练和没有训练的人是完全不同的。如果你没有相关的经验，那么你现在找的这份工作就好比是训练集一样，没有一个公司会把他们的项目当做是你练手的数据集。大家都期望你是已经训练好的模型，可以马上开展新的工作，并且产生价值。所以在经验积累上，你要证明给 HR，我做过这样的项目，具备这样的能力。

1『新工作隐喻为「训练集」，贴切。』

你可能想问，项目从哪里来呢？第一个肯定是以往类似的工作经历，第二个就是自己做过类似的项目。但是在简历中呈现数据分析的项目也是需要技巧的，简历不是流水账，你需要重点把当时的项目目标、采用的解决方案、实现的代码以及项目过程的总结体会拿给 HR 看。这样，即使你没有相关的工作经历，如果你能通过专栏实战积累上面的 4 点，对 HR 来说也是有说服力的，这样总比一张白纸要强得多。要知道 HR 背后的逻辑是要通过简历证明你是已经被训练过的模型，可以上手工作了，而不是把新公司当成训练集。

1『项目的目标、采用的解决方案、实现的代码和项目总结。』

如何完善简历里的项目经历。现在我们需要简历中有更多的项目经验。如果你跟着专栏从头到尾完整学习了，在爬虫、数据可视化、数据清洗和集成、数据挖掘算法、图像识别等多个维度进行了实战训练，那么恭喜你，实际上你已经具有数据分析相关的工作经验了。这方面我来简单帮你总结下，梳理出一个项目简历的模板。但最根本的是，你需要自己跑一遍项目代码，完整了解项目目标和解决方案。只有这样，放到简历中的时候才会比较充实。

1、乳腺癌检测：采用 SVM 方法，对美国威斯康星州的乳腺癌诊断数据集进行分类，最终实现一个针对乳腺癌检测的分类器：[cystanford/breast_cancer_data: 乳腺癌检测分类数据](https://github.com/cystanford/breast_cancer_data)。

2、内容抓取：通过 Python 爬虫对豆瓣电影中的电影数据和海报等信息进行抓取：[cystanford/pachong: Python爬虫实例](https://github.com/cystanford/pachong)。

3、邮件数据分析：通过 PageRank 算法分析邮件中的人物关系图谱，并针对邮件数量较大的情况筛选出重要的人物，进行绘制：[cystanford/PageRank: PageRank算法实例-希拉里邮件PR分析](https://github.com/cystanford/PageRank)。

4、微博文档分类：采用朴素贝叶斯的方法，对微博的内容进行分类，最终实现一个简单的文档分类器：[cystanford/text_classification: 中文文档分类数据集](https://github.com/cystanford/text_classification)。

5、电影数据集关联规则挖掘：采用 Apriori 算法，分析电影数据集中的导演和演员信息，从而发现导演和演员之间的频繁项集及关联规则：[cystanford/Apriori: Apriori算法实例-挖掘电影导演的关联规则](https://github.com/cystanford/Apriori)。

6、歌词词云可视化：动态抓取指定明星的歌曲列表，保存歌词文件，去除歌词中的常用词，并对歌词进行词云展示，分析歌曲的作词风格：[cystanford/word_cloud: 词云生成](https://github.com/cystanford/word_cloud)。

7、信用卡违约率分析：针对台湾某银行信用卡的数据，构建一个分析信用卡违约率的分类器。采用 Random Forest 算法，信用卡违约率识别率在 80% 左右：[cystanford/credit_default: 信用卡违约率分析](https://github.com/cystanford/credit_default)。

8、信用卡欺诈分析：针对欧洲某银行信用卡交易数据，构建一个信用卡交易欺诈识别器。采用逻辑回归算法，通过数据可视化方式对混淆矩阵进行展示，统计模型的精确率，召回率和 F1 值，F1 值为 0.712，并绘制了精确率和召回率的曲线关系：[cystanford/credit_fraud: 信用卡欺诈分析](https://github.com/cystanford/credit_fraud)。

9、比特币走势分析：分析 2012 年 1 月 1 日到 2018 年 10 月 31 日的比特币价格数据，并采用时间序列方法，构建自回归滑动平均模型（ARMA 模型），预测未来 8 个月比特币的价格走势。预测结果表明比特币将在 8 个月内降低到 4000 美金左右，与实际比特币价格趋势吻合（实际最低降到 4000 美金以下）：[cystanford/bitcoin: 比特币走势分析](https://github.com/cystanford/bitcoin)。

不一样的项目经历和体会。上面我整理了 9 个项目简历的示例，如果认真学习专栏，并且坚持练习的话，那么不用愁相关的项目经验。如果你希望有不一样的项目经历，那么能融入自己的项目体会和总结的话，就会更好。比如分析比特币走势这一篇文章中，我还提供了沪市指数的历史数据（从 1990 年 12 月 19 日到 2019 年 2 月 28 日），你完全可以采用 ARMA 模型自己跑一遍，然后整理出相关的经历。再或者，我们对毛不易歌词进行词云分析的时候，你也可以分析其他的歌手，或者某个歌手的某张专辑的词云。模型方法是相同的，但不同的数据集出来的结果是不同的。

另外你也可以在项目实战中，融入自己的心得体会。比如在预测比特币走势这个项目中，我们对原始数据进行了降维，按月为粒度进行了统计，实际预测结果与按天进行统计的结果相差并不大，但是数据量降到了 1/30，大大提升了效率。在这个过程中，你应该能体会到数据降维的作用。在信用卡欺诈分析这个项目中，我们观察到数据集的分类样本是不平衡的，针对这种情况，我们到底该采用哪个评价标准呢？为什么采用准确率作为评价标准会有问题？有关这方面的经验总结你也可以简单做个说明，这样不光可以证明你具备这种项目的经验，也能证明针对这类的问题，你都找到了哪些规律。总之自己的心得体会和总结能给项目经验加分不少。











