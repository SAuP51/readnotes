# 2019065利用Python进行数据分析R00

## 记忆时间

## 卡片

### 0101. 主题卡——

这本书的主题核心，就是最大的反常识卡，并且注意时间脉络。

### 0201. 术语卡——广播

不同大小的数组之间的运算叫做广播（broadcasting），将在附录 A 中对其进行详细讨论。

### 0202. 术语卡——

### 0203. 术语卡——

### 0301. 人名卡——

根据这些证据和案例，找出源头和提出术语的人是谁——产生一张人名卡，并且分析他为什么牛，有哪些作品，生平经历是什么。

维基百科链接：有的话。

#### 01. 出生日期

用一句话描述你对这个大牛的印象。

#### 02. 贡献及经历

#### 03. 论文及书籍

#### 04. 演讲汇总

找一个他的 TED 演讲，有的话。

### 0401. 金句卡——

最后根据他写的非常震撼的话语——产生一张金句卡。

## 序

时过境迁，从本书英文版第 1 版 2012 年出版至今，已经过去了 6 年。这 6 年中，Python 的主流版本从 2.7 升级到了 3.6。无论是否情愿，大部分 Pythoner 都不得不学会适应新版本；而 pandas 则从 0.1.0 版本送代到如今的 0.22.0 版本。版本号的持续増加意味着新技术、新特性的不断丰富。

本书英文版的副书名是「Data Wrangling with Pandas, Numpy, and Ipython」，其中 Wrangling 是一个很难直译的词汇，它的原意是争执、争论，但在书中它描述的是将数据进行规整、处理的意思。希望读者读完本书后，可以使用好 pandas、Numpy 和 python 这些工具，更好地完成数据处理、分析的学习和工作。

## 03. 内建数据结构、函数及文件

### 1. 逻辑脉络

清楚 python 的内建数据结构有哪些（list/dict/tuple/set）。虽然扩展库如 pandas 和 Numpy 使处理大数据集很方便，但它们是和 Python 的内置数据处理工具一同使用的。

### 2. 摘录及评论

本章将讨论贯穿本书所要使用的 Python 语言内建功能。由于像 pandas 和 Numpy 这类附加库提供了在大数据集上的高级计算功能，所以它们被设计为与 Python 内建数据操作工具协同使用。我们将开始介绍 Python 的常用数据结构：元组、列表、字典和集合。然后我们会讨论如何创建可复用的 Python 函数。我们将介绍 Python 文件对象的机制以及如何与你的本地硬盘进行交互。

元组是一个固定长度，不可改变的 Python 序列对象。创建元组的最简单方式，是用逗号分隔一列值；当用复杂的表达式定义元组，最好将值放到圆括号内；用 tuple 可以将任意序列或迭代器转换成元组；可以用方括号访问元组中的元素。和 C、C++、JAVA 等语言一样，序列是从 0 开始的；元组中存储的对象可能是可变对象。一旦创建了元组，元组中的对象就不能修改了；如果元组中的某个对象是可变的，比如列表，可以在原位进行修改；可以用加号运算符将元组串联起来。元组乘以一个整数，像列表一样，会将几个元组的复制串联起来。对象本身并没有被复制，只是引用了它。

如果你想将元组赋值给类似元组的变量，Python 会试图拆分等号右边的值。即使含有元组的元组也会被拆分。使用这个功能，你可以很容易地替换变量的名字，其它语言可能是这样，但是在 Python 中，替换可以这样做；变量拆分常用来迭代元组或列表序列。另一个常见用法是从函数返回多个值；Python 最近新增了更多高级的元组拆分功能，允许从元组的开头「摘取」几个元素。它使用了特殊的语法 *rest，这也用在函数签名中以抓取任意长度列表的位置参数。rest 的部分是想要舍弃的部分，rest 的名字不重要。作为惯用写法，许多 Python 程序员会将不需要的变量使用下划线；因为元组的大小和内容不能修改，它的实例方法都很轻量。其中一个很有用的就是 count（也适用于列表），它可以统计某个值得出现频率。

1『迭代元组和列表序列，例子是看懂了，但没摸清应用点；从函数返回多个值的应用也没弄懂。』

与元组不同，列表的长度是可变的，它所包含的内容也是可以修改的。你可以使用中括号 [] 或者 list 类型函数来定义列表；列表与元组非常相似（尽管元组不可修改），它们的很多函数用法是相似的；list 函数在数据处理中常用于将迭代器或者生成器转化为列表。

添加和删除元素。可以用 append 在列表末尾添加元素。insert 可以在特定的位置插入元素，插入的序号必须在 0 和列表长度之间。insert 的反操作是 pop，该操作会将特定位置的元素移除并返回。可以用 remove 去除某个值，remove 会先寻找第一个值并除去。如果不考虑性能，通过使用 append 和 remove，你可以将 Python 的列表用作一种完全合适的「多集合」数据结构。与字典、集合（后面会介绍）相比，检查列表中是否包含一个值是非常缓慢的。这是因为 Python 在列表中进行了线性逐个扫描，而在字典和集合中 Python 是同时检查所有元素的（基于哈希表）；用 in 可以检查列表是否包含某个值，否定 in 可以再加一个 not。

『警告：insert 与 append 相比，计算代价更高。因为子序列元素不得不在内部移动为新元素提供空间。如果你想要在序列的头部和尾部都插入元素，那你应该探索下 collections.deque，它是一个双端队列，可以满足头尾部都增加的要求。』

串联和组合列表。与元组类似，可以用加号将两个列表串联起来。如果已经定义了一个列表，用 extend 方法可以追加多个元素。请注意通过添加内容来连接列表是一种相对高代价的操作，这是因为连接过程中创建了新列表，并且还要复制对象。使用 extend 将元素添加到已经存在的列表是更好的方式，尤其是在你需要构建一个大型列表时。因此 everything = [] for chunk in list_of_lists: everything.extend(chunk) 要比串联方法快：everything = [] for chunk in list_of_lists: everything = everything + chunk。

排序。你可以调用列表的 sort 方法对列表进行内部排序（无须新建一个对象）。sort 有一些选项偶尔会派上用场。其中一项是传递一个二级排序 key —— 一个用于生成排序值的函数。例如，我们可以通过字符串的长度进行排序；稍后，我们会学习 sorted 函数，该方法可以针对通用序列产生一个排序后的拷贝。

1『key 是方法 sort 的一个实参，要传递进去。b.sort(key=len)』

二分搜索和维护已排序的列表。bisect 模块支持二分查找，和向已排序的列表插入值。bisect.bisect 可以找到插入值后仍保证排序的位置，bisect.insort 是向这个位置插入值。注意：bisect 模块不会检查列表是否已排好序，进行检查的话会耗费大量计算。因此，对未排序的列表使用 bisect 不会产生错误，但结果不一定正确。

切片。用切边可以选取大多数序列类型的一部分，切片的基本形式是在方括号中使用 start:stop；切片也可以被序列赋值；切片的起始元素是包括的，不包含结束元素。因此，结果中包含的元素个数是 stop - start；start 或 stop 都可以被省略，省略之后，分别默认序列的开头和结尾；负数表明从后向前切片；需要一段时间来熟悉使用切片，尤其是当你之前学的是 R 或 MATLAB。图 3-1 展示了正整数和负整数的切片。在图中，指数标示在边缘以表明切片是在哪里开始哪里结束的；在第二个冒号后面使用 step，可以隔一个取一个元素，一个聪明的方法是使用 - 1，它可以将列表或元组颠倒过来。

序列函数。Python 有很多有用的序列函数，你应当熟悉并择机使用。

enumerate 函数。我们经常需要在遍历一个序列的同时追踪当前元素的索引。一种自行实现的方法像下面的示例。由于这种场景很常见，所以 Python 内建了 enumerate 函数，返回了（i, value）元组的序列，其中 value 是元素的值，i 是元素的索引。当你需要对数据建立索引时，一种有效的模式就是使用 enumerate 构造一个字典，将序列值（假设是唯一的）映射到索引位置上。

sorted 函数。sorted 函数可以从任意序列的元素返回一个新的排好序的列表。sorted 函数可以接受和 sort 相同的参数。

zip 函数。zip 将列表、元组或其他序列的元素配对，组合成一个元组列表；zip 可以处理任意长度的序列，它生成列表长度由最短的序列决定；zip 的常用场景为同时遍历多个序列，有时候会和 enumerate 同时使用；给定一个已「配对」的序列时，zip 函数有一种机智的方式去「拆分」序列。这种方式的另一种思路就是将行的列表转换为列的列表。语法看上去略显魔幻。

```
for i, (a, b) in enumerate(zip(seq1, seq2)): 
    print('{0}: {1}, {2}'.format(i, a, b)) 
```

```
In [96]: pitchers = [('Nolan', 'Ryan'), ('Roger', 'Clemens'), ('Schilling', 'Curt')] 
In [97]: first_names, last_names = zip(*pitchers) 
In [98]: first_names 
Out[98]: ('Nolan', 'Roger', 'Schilling') 
In [99]: last_names 
Out[99]: ('Ryan', 'Clemens', 'Curt')
```

reversed 函数。reversed 可以从后向前迭代一个序列。要记住 reversed 是一个生成器（后面详细介绍），只有实体化（即列表或 for 循环）之后才能创建翻转的序列。

字典。dict（字典）可能是Python内建数据结构中最重要的。它更为常用的名字是哈希表或者是关联数组。字典是拥有灵活尺寸的键值对集合，其中键和值都是 Python 对象。用大括号 {} 是创建字典的一种方式，在字典中用逗号将键值对分隔；你可以像访问列表或元组中的元素一样，访问、插入或设定字典中的元素；你可以用检查列表和元组是否包含某个值得方法，检查字典中是否包含某个键；可以用 del 关键字或 pop 方法（返回值得同时删除键）删除值；eys 和 values 是字典的键和值的迭代器方法。虽然键值对没有顺序，这两个方法可以用相同的顺序输出键和值；用 update 方法可以将一个字典与另一个合并。update 方法改变了字典中元素位置，因此对于任何原字典中已经存在的键，如果传给 update 方法的数据也含有相同的键，则它的值将会被覆盖。

用序列创建字典。常常，你可能想将两个序列配对组合成字典。下面是一种写法。由于字典本质上是2-元组（含有 2 个元素的元组）的集合，字典是可以接受一个2-元组的列表作为参数的。稍后我们将会讨论字典推导式，那是另一种构建字典的方法。

默认值。下面的逻辑很常见。不过字典的 get 方法和 pop 方法可以返回一个默认值，因此上述的 if-else 代码块可以被简写为；带有默认值的 get 方法会在 key 参数不是字典的键时返回 None，而 pop 会抛出异常。

    value = some_dict.get(key, default_value)

一个常见的场景是字典中的值集合通过设置，成为另一种集合，比如列表。举个例子，你可以想象一下将字词组成的列表根据首字母分类为包含列表的字典。setdefault 方法就正是干这个的。上面的 for 循环可以改写为：

    for word in words: letter = word[0] by_letter.setdefault(letter, []).append(word)

内建的集合模块有一个非常有用的类，defaultdict。这个类使得上述目的实现更为简单。想要生成符合要求的字典，你可以向字典中传入类型或能在各位置生成默认值的函数：

```
from collections import defaultdict 
by_letter = defaultdict(list) 
for word in words: 
    by_letter[word[0]].append(word)
```

1『原文中的这几段代码没有完全消化掉，多琢磨琢磨。』

有效的键类型。字典的值可以是任意 Python 对象，而键通常是不可变的标量类型（整数、浮点型、字符串）或元组（元组中的对象必须是不可变的）。这被称为「可哈希性」。可以用 hash 函数检测一个对象是否是可哈希的（可被用作字典的键）。要用列表当做键，一种方法是将列表转化为元组，只要内部元素可以被哈希，它也就可以被哈希。

集合。集合是一种无序且元素唯一的容器。你可以认为集合也像字典，但是只有键没有值。集合可以有两种创建方式：通过 set 函数或者是用字面值集与大括号的语法；集合支持合并、交集、差分和对称差等数学集合运算。考虑两个示例集合。合并是取两个集合中不重复的元素。可以用 union 方法，或者 | 运算符。交集的元素包含在两个集合中。可以用 intersection 或 & 运算符。表 3-1 列出了常用的集合方法；所有的逻辑集合运算都有对应操作，允许你用操作的结果替代操作左边的集合内容。对于大型集合，下面的代码效率更高；和字典类似，集合的元素必须是不可变的。如果想要包含列表型的元素，必须先转换为元组；你还可以检测一个集合是否是另一个集合的子集或父集；当且仅当两个集合的内容一模一样时，两个集合才相等。

列表、集合和字典的推导式。列表推导式是 Python 最受喜爱的特性之一。它允许用户方便的从一个集合过滤元素，形成列表，在传递参数的过程中还可以修改元素。形式如下：

    [expr for val in collection if condition]

它等同于下面的 for 循环；

```
result = [] 
for val in collection: 
    if condition: 
        result.append(expr)
```

filter 条件可以被忽略，只留下表达式就行。例如，给定一个字符串列表，我们可以过滤出长度在 2 及以下的字符串，并将其转换成大写：

```
In [154]: strings = ['a', 'as', 'bat', 'car', 'dove', 'python'] 
In [155]: [x.upper() for x in strings if len(x) > 2] 
Out[155]: ['BAT', 'CAR', 'DOVE', 'PYTHON']
```

用相似的方法，还可以推导集合和字典。字典的推导式如下所示：

    dict_comp = {key-expr : value-expr for value in collection if condition}

集合的推导式与列表很像，只不过用的是尖括号：

    set_comp = {expr for value in collection if condition}

与列表推导式类似，集合与字典的推导也很方便，而且使代码的读写都很容易。来看前面的字符串列表。假如我们只想要字符串的长度，用集合推导式的方法非常方便：

```
In [156]: unique_lengths = {len(x) for x in strings} 
In [157]: unique_lengths 
Out[157]: {1, 2, 3, 4, 6}
```

map 函数可以进一步简化：

```
In [158]: set(map(len, strings)) 
Out[158]: {1, 2, 3, 4, 6}
```

作为一个字典推导式的例子，我们可以创建一个字符串的查找映射表以确定它在列表中的位置：

```
In [159]: loc_mapping = {val : index for index, val in enumerate(strings)} 
In [160]: loc_mapping 
Out[160]: {'a': 0, 'as': 1, 'bat': 2, 'car': 3, 'dove': 4, 'python': 5}
```

假设我们有一个包含列表的列表，包含了一些英文名和西班牙名；你可能是从一些文件得到的这些名字，然后想按照语言进行分类。现在假设我们想用一个列表包含所有的名字，这些名字中包含两个或更多的 e。可以用 for 循环来做；可以用嵌套列表推导式的方法，将这些写在一起，如下所示：

```
In [162]: result = [name for names in all_data for name in names 
.....:     if name.count('e') >= 2] 
In [163]: result 
Out[163]: ['Steven']
```

嵌套列表推导式可能会让你有点晕头转向。列表推导式的for循环部分是根据嵌套的顺序排列的，所有的过滤条件像之前一样被放在尾部。下面的例子是将含有整数元组的列表扁平化为一个简单的整数列表：

```
In [164]: some_tuples = [(1, 2, 3), (4, 5, 6), (7, 8, 9)] 
In [165]: flattened = [x for tup in some_tuples for x in tup] 
In [166]: flattened 
Out[166]: [1, 2, 3, 4, 5, 6, 7, 8, 9]
```

记住，for 表达式的顺序是与嵌套 for 循环的顺序一样（而不是列表推导式的顺序）：

```
flattened = [] 
for tup in some_tuples:
    for x in tup: 
        flattened.append(x)
```

你当然可以嵌套多层的列表推导式，但超过两到三层之后你很可能开始疑惑这种做法是否会有利于代码可读性。嵌套推导式的语法要和列表推导式中的列表推导式区分开，列表推导式中的列表推导式也是非常有效的：


```
In [167]: [[x for x in tup] for tup in some_tuples] 
Out[167]: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
```

这段代码产生了一个列表的列表，而不是扁平化的只包含元素的列表。

函数是 Python 中最主要也是最重要的代码组织和复用手段。作为最重要的原则，如果你要重复使用相同或非常类似的代码，就需要写一个函数。通过给函数起一个名字，还可以提高代码的可读性。函数使用 def 关键字声明，用 return 关键字返回值；同时拥有多条 return 语句也是可以的。如果到达函数末尾时没有遇到任何一条 return 语句，则返回 None；函数可以有一些位置参数（positional）和一些关键字参数（keyword）。关键字参数通常用于指定默认值或可选参数。在上面的函数中，x 和 y 是位置参数，而 z 则是关键字参数。也就是说，该函数可以下面这两种方式进行调用；函数参数的主要限制在于：关键字参数必须位于位置参数（如果有的话）之后。你可以任何顺序指定关键字参数。也就是说，你不用死记硬背函数参数的顺序，只要记得它们的名字就可以了；也可以用关键字传递位置参数。前面的例子，也可以写为。

命名空间、作用域和局部函数。函数可以访问两种不同作用域中的变量：全局（global）和局部（local）。Python 有一种更科学的用于描述变量作用域的名称，即命名空间（namespace）。任何在函数中赋值的变量默认都是被分配到局部命名空间（local namespace）中的。局部命名空间是在函数被调用时创建的，函数参数会立即填入该命名空间。在函数执行完毕之后，局部命名空间就会被销毁（会有一些例外的情况，具体请参见后面介绍闭包的那一节）。看看下面这个函数；调用 func () 之后，首先会创建出空列表 a，然后添加 5 个元素，最后 a 会在该函数退出的时候被销毁。假如我们像下面这样定义 a；虽然可以在函数中对全局变量进行赋值操作，但是那些变量必须用 global 关键字声明成全局的才行。

注意：我常常建议人们不要频繁使用 global 关键字。因为全局变量一般是用于存放系统的某些状态的。如果你发现自己用了很多，那可能就说明得要来点儿面向对象编程了（即使用类）。

返回多个值。在我第一次用 Python 编程时（之前已经习惯了 Java 和 C++），最喜欢的一个功能是：函数可以返回多个值。下面是一个简单的例子；在数据分析和其他科学计算应用中，你会发现自己常常这么干。该函数其实只返回了一个对象，也就是一个元组，最后该元组会被拆包到各个结果变量中。在上面的例子中，我们还可以这样写；这里的 return_value 将会是一个含有 3 个返回值的三元元组。此外，还有一种非常具有吸引力的多值返回方式 —— 返回字典；具体用哪种技术取决于你需要做什么。

由于 Python 函数都是对象，因此，在其他语言中较难表达的一些设计思想在 Python 中就要简单很多了。假设我们有下面这样一个字符串数组，希望对其进行一些数据清理工作并执行一堆转换；不管是谁，只要处理过由用户提交的调查数据，就能明白这种乱七八糟的数据是怎么一回事。为了得到一组能用于分析工作的格式统一的字符串，需要做很多事情：去除空白符、删除各种标点符号、正确的大写格式等。做法之一是使用内建的字符串方法和正则表达式 re 模块；其实还有另外一种不错的办法，将需要在一组给定字符串上执行的所有运算做成一个列表；这种多函数模式使你能在很高的层次上轻松修改字符串的转换方式。此时的 clean_strings 也更具可复用性！还可以将函数用作其他函数的参数，比如内置的 map 函数，它用于在一组数据上应用一个函数。

匿名（lambda）函数。Python 支持一种被称为匿名的、或 lambda 函数。它仅由单条语句组成，该语句的结果就是返回值。它是通过 lambda 关键字定义的，这个关键字没有别的含义，仅仅是说「我们正在声明的是一个匿名函数」。

```
def short_function(x): 
    return x * 2 
equiv_anon = lambda x: x * 2
```

本书其余部分一般将其称为 lambda 函数。它们在数据分析工作中非常方便，因为你会发现很多数据转换函数都以函数作为参数的。直接传入 lambda 函数比编写完整函数声明要少输入很多字（也更清晰），甚至比将 lambda 函数赋值给一个变量还要少输入很多字。看看下面这个简单得有些傻的例子：

```
def apply_to_list(some_list, f): 
    return [f(x) for x in some_list] 
ints = [4, 0, 1, 5, 6] 
apply_to_list(ints, lambda x: x * 2)
```

虽然你可以直接编写 [x *2for x in ints]，但是这里我们可以非常轻松地传入一个自定义运算给 apply_to_list 函数。再来看另外一个例子。假设有一组字符串，你想要根据各字符串不同字母的数量对其进行排序；这里，我们可以传入一个 lambda 函数到列表的 sort 方法：

```
In [177]: strings = ['foo', 'card', 'bar', 'aaaa', 'abab']
In [178]: strings.sort(key=lambda x: len(set(list(x)))) 
In [179]: strings 
Out[179]: ['aaaa', 'foo', 'abab', 'bar', 'card']
```

笔记：lambda 函数之所以会被称为匿名函数，与 def 声明的函数不同，原因之一就是这种函数对象本身是没有提供名称 name 属性。

柯里化：部分参数应用。柯里化（currying）是一个有趣的计算机科学术语，它指的是通过「部分参数应用」（partial argument application）从现有函数派生出新函数的技术。例如，假设我们有一个执行两数相加的简单函数；通过这个函数，我们可以派生出一个新的只有一个参数的函数 ——add_five，它用于对其参数加 5：

    add_five = lambda y: add_numbers(5, y)

add_numbers 的第二个参数称为「柯里化的」（curried）。这里没什么特别花哨的东西，因为我们其实就只是定义了一个可以调用现有函数的新函数而已。内置的 functools 模块可以用 partial 函数将此过程简化。

生成器。能以一种一致的方式对序列进行迭代（比如列表中的对象或文件中的行），是 Python 的一个重要特点。这是通过一种叫做迭代器协议（iterator protocol，它是一种使对象可迭代的通用方式）的方式实现的，一个原生的使对象可迭代的方法。比如说，遍历一个字典，获得字典的键；当你编写 for key in some_dict 时，Python 解释器首先会尝试从 some_dict 创建一个迭代器；迭代器是一种特殊对象，它可以在诸如 for 循环之类的上下文中向 Python 解释器输送对象。大部分能接受列表之类的对象的方法也都可以接受任何可迭代对象。比如 min、max、sum 等内置方法以及 list、tuple 等类型构造器。

生成器（generator）是构造新的可迭代对象的一种简单方式。一般的函数执行之后只会返回单个值，而生成器则是以延迟的方式返回一个值序列，即每返回一个值之后暂停，直到下一个值被请求时再继续。要创建一个生成器，只需将函数中的 return 替换为 yeild 即可；调用该生成器时，没有任何代码会被立即执行；直到你从该生成器中请求元素时，它才会开始执行其代码。

生成器表达式。另一种更简洁的构造生成器的方法是使用生成器表达式（generator expression）。这是一种类似于列表、字典、集合推导式的生成器。其创建方式为，把列表推导式两端的方括号改成圆括号；它跟下面这个冗长得多的生成器是完全等价的；生成器表达式也可以取代列表推导式，作为函数参数。

```
In [191]: sum(x ** 2 for x in range(100)) 
Out[191]: 328350 
In [192]: dict((i, i **2) for i in range(5)) 
Out[192]: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}
```

itertools 模块。标准库 itertools 模块中有一组用于许多常见数据算法的生成器。例如，groupby 可以接受任何序列和一个函数。它根据函数的返回值对序列中的连续元素进行分组。下面是一个例子；表 3-2 中列出了一些我经常用到的 itertools 函数。建议参阅 Python 官方文档，进一步学习。

错误和异常处理。优雅地处理 Python 的错误和异常是构建健壮程序的重要部分。在数据分析中，许多函数函数只用于部分输入。例如，Python 的 float 函数可以将字符串转换成浮点数，但输入有误时，有 ValueError 错误；假如想优雅地处理 float 的错误，让它返回输入值。我们可以写一个函数，在 try/except 中调用 float。当 float (x) 抛出异常时，才会执行 except 的部分；你可能注意到 float 抛出的异常不仅是 ValueError。你可能只想处理 ValueError，TypeError 错误（输入不是字符串或数值）可能是合理的 bug。可以写一个异常类型；可以通过将多个异常类型写成元组的方式同时捕获多个异常（小括号是必不可少的）；某些情况下，你可能想要处理一个异常，但是你希望一部分代码无论 try 代码块是否报错都要执行。为了实现这个目的，使用 finally 关键字；这样，我们可以让 f 在程序结束后总是关闭。类似地，你可以使用 else 来执行当 try 代码块成功执行时才会执行的代码。

比标准 Python 解释器提供更多额外的上下文是 IPython 的一大进步（标准 Python 解释器不提供任何额外的上下文）。你可以使用 %xmode 命令来控制上下文的数量，可以从 Plain（普通）模式（与标准 Python 解释器一致）切换到 Verbose（复杂）模式（可以显示函数的参数值以及更多有用信息）。你将会在下一章看到如何在错误发生后进入异常堆栈（使用 %debug 或 %pdb 命令）进行交互式事后调试。

文件和操作系统。本书的代码示例大多使用诸如 pandas.read_csv 之类的高级工具将磁盘上的数据文件读入 Python 数据结构。但我们还是需要了解一些有关 Python 文件处理方面的基础知识。好在它本来就很简单，这也是 Python 在文本和文件处理方面的如此流行的原因之一。为了打开一个文件以便读写，可以使用内置的 open 函数以及一个相对或绝对的文件路径；默认情况下，文件是以只读模式（'r'）打开的。然后，我们就可以像处理列表那样来处理这个文件句柄 f 了，比如对行进行迭代；行内容会在行结尾标识（EOL）完整的情况下从文件中全部读出，所以你会经常看到一些代码，功能是将文件中的内容形成不带 EOL 的列表；如果使用 open 创建文件对象，一定要用 close 关闭它。关闭文件可以返回操作系统资源。用 with 语句可以可以更容易地清理打开的文件，这样可以在退出代码块时，自动关闭文件；如果输入 f =open (path,'w')，就会有一个新文件被创建在 examples/segismundo.txt，并覆盖掉该位置原来的任何数据。另外有一个 x 文件模式，它可以创建可写的文件，但是如果文件路径存在，就无法创建。表 3-3 列出了所有的读 / 写模式。

1『译者说的迭代其实指遍历。』

对于可读文件，一些常用的方法是 read、seek 和 tell。read 会从文件返回字符。字符的内容是由文件的编码决定的（如 UTF-8），如果是二进制模式打开的就是原始字节；read 方法通过读取的字节数来推进文件句柄的位置。tell 方法可以给出句柄当前的位置；尽管我们从文件读取了 10 个字符，位置却是 11，这是因为用默认的编码用了这么多字节才解码了这 10 个字符。你可以用 sys 模块检查默认的编码；seek 将文件位置更改为文件中的指定字节。

```
In [219]: import sys 
In [220]: sys.getdefaultencoding() 
Out[220]: 'utf-8'
```

1『sys 是 Python 的标准模块，又体会到标准模块的丰富。』

3『

编码的有关概念：对于英语我们一般不会遇到什么编码问题，因为一个英文字符在系统里占一个位置。对于中文的话，微软设置了一个编码 gbk，一个汉字在系统里占有 2 个位置，gbk 编码虽然节省空间，但只包含有常用字。对于那些生僻的字，就用 utf-8 编码，这个编码一个汉字是占有 3 个位置。如果 resquest 得到的对象直接 read() 的话，它会按一个字符占一个位置的规则去读，那么读出来的就是乱码。解决的办法是在 read() 方法里指定解码的方式。

	response.read().decode('utf-8')

read() 读出来的信息是 html 语法形式的。

』

向文件写入，可以使用文件的 write 或 writelines 方法。例如，我们可以创建一个无空行版的 prof_mod.py。

文件的字节和 Unicode。Python 文件的默认操作是「文本模式」，也就是说，你需要处理 Python 的字符串（即 Unicode）。它与「二进制模式」相对，文件模式加一个 b。我们来看上一节的文件（UTF-8 编码、包含非 ASCII 字符）；UTF-8 是长度可变的 Unicode 编码，所以当我从文件请求一定数量的字符时，Python 会从文件读取足够多（可能少至 10 或多至 40 字节）的字节进行解码。如果以「rb」模式打开文件，则读取确切的请求字节数；取决于文本的编码，你可以将字节解码为 str 对象，但只有当每个编码的 Unicode 字符都完全成形时才能这么做；文本模式下，利用 open 方法的选项参数 encoding, Python 提供了一种方便的方法将文件内容从 Unicode 编码转换为其他类型的编码。

除了二进制模式，在打开文件时使用 seek 要当心。如果文件的句柄位置恰好在一个 Unicode 符号的字节中间时，后续的读取会导致错误；如果你经常要对非 ASCII 字符文本进行数据分析，通晓 Python 的 Unicode 功能是非常重要的。更多内容，参阅 Python 官方文档。


## 06. 数据加载、存储与文件格式

### 1. 逻辑脉络


### 2. 摘录及评论

访问数据是使用本书所介绍的这些工具的第一步。我会着重介绍 pandas 的数据输入与输出，虽然别的库中也有不少以此为目的的工具。输入输出通常可以划分为几个大类：读取文本文件和其他更高效的磁盘存储格式，加载数据库中的数据，利用 Web API 操作网络资源。

pandas 提供了一些用于将表格型数据读取为 DataFrame 对象的函数。表 6-1 对它们进行了总结，其中 read_csv 和 read_table 可能会是你今后用得最多的。

我将大致介绍一下这些函数在将文本数据转换为 DataFrame 时所用到的一些技术。这些函数的选项可以划分为以下几个大类：

1、索引：将一个或多个列当做返回的 DataFrame 处理，以及是否从文件、用户获取列名。

2、类型推断和数据转换：包括用户定义值的转换、和自定义的缺失值标记列表等。

3、日期解析：包括组合功能，比如将分散在多个列中的日期时间信息组合成结果中的单个列。

4、迭代：支持对大文件进行逐块迭代。

5、不规整数据问题：跳过一些行、页脚、注释或其他一些不重要的东西（比如由成千上万个逗号隔开的数值数据）。

因为工作中实际碰到的数据可能十分混乱，一些数据加载函数（尤其是 read_csv）的选项逐渐变得复杂起来。面对不同的参数，感到头痛很正常（read_csv 有超过 50 个参数）。pandas 文档有这些参数的例子，如果你感到阅读某个文件很难，可以通过相似的足够多的例子找到正确的参数。其中一些函数，比如 pandas.read_csv，有类型推断功能，因为列数据的类型不属于数据类型。也就是说，你不需要指定列的类型到底是数值、整数、布尔值，还是字符串。其它的数据格式，如 HDF5、Feather 和 msgpack，会在格式中存储数据类型。

日期和其他自定义类型的处理需要多花点工夫才行。首先我们来看一个以逗号分隔的（CSV）文本文件：

笔记：这里，我用的是 Unix 的 cat shell 命令将文件的原始内容打印到屏幕上。如果你用的是 Windows，你可以使用 type 达到同样的效果。

由于该文件以逗号分隔，所以我们可以使用 read_csv 将其读入一个 DataFrame：

我们还可以使用 read_table，并指定分隔符：

并不是所有文件都有标题行。读入该文件的办法有两个。你可以让 pandas 为其分配默认的列名，也可以自己定义列名：

假设你希望将 message 列做成 DataFrame 的索引。你可以明确表示要将该列放到索引 4 的位置上，也可以通过 index_col 参数指定 "message"：

```
In [15]: names = ['a', 'b', 'c', 'd', 'message'] 
In [16]: pd.read_csv('examples/ex2.csv', names=names, index_col='message') 
```

如果希望将多个列做成一个层次化索引，只需传入由列编号或列名组成的列表即可：

有些情况下，有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其他模式）。有些表格可能不是用固定的分隔符去分隔字段的（比如空白符或其他模式来分隔字段）。看看下面这个文本文件：

虽然可以手动对数据进行规整，这里的字段是被数量不同的空白字符间隔开的。这种情况下，你可以传递一个正则表达式作为 read_table 的分隔符。可以用正则表达式表达为 \s+，于是有：

1『用上面的正则表达式处理材料数据失败，必须好好研究正则表达式的知识。』

这些解析器函数还有许多参数可以帮助你处理各种各样的异形文件格式（表 6-2 列出了一些）。比如说，你可以用 skiprows 跳过文件的第一行、第三行和第四行：

缺失值处理是文件解析任务中的一个重要组成部分。缺失数据经常是要么没有（空字符串），要么用某个标记值表示。默认情况下，pandas 会用一组经常出现的标记值进行识别，比如 NA 及 NULL：

na_values 可以用一个列表或集合的字符串表示缺失值：

在处理很大的文件时，或找出大文件中的参数集以便于后续处理时，你可能只想读取文件的一小部分或逐块对文件进行迭代。

如果只想读取几行（避免读取整个文件），通过 nrows 进行指定即可：

要逐块读取文件，可以指定 chunksize（行数）：

read_csv 所返回的这个 TextParser 对象使你可以根据 chunksize 对文件进行逐块迭代。比如说，我们可以迭代处理 ex6.csv，将值计数聚合到 "key" 列中，如下所示：

「read_csv 返回的 TextParser 对象允许你根据 chunksize 遍历文件。例如，我们可以遍历 ex6.csv，并对 ’key’ 列聚合获得计数值：」

TextParser 还有一个 get_chunk 方法，它使你可以读取任意大小的块。

## 04. NumPy 基础：数组和矢量计算

### 1. 逻辑脉络

NumPy 的核心是对数组（矩阵）的强大操作。

### 2. 摘录及评论

NumPy（Numerical Python 的简称）是 Python 数值计算最重要的基础包。大多数提供科学计算的包都是用 NumPy 的数组作为构建基础。NumPy 的部分功能如下：ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组；用于对整组数据进行快速运算的标准数学函数（无需编写循环）；用于读写磁盘数据的工具以及用于操作内存映射文件的工具；线性代数、随机数生成以及傅里叶变换功能；用于集成由 C、C++、Fortran 等语言编写的代码的 C 语言 API。

由于 NumPy 提供了一个简单易用的 C 语言 API，因此很容易将数据传递给由低级语言编写的外部库，外部库也能以 NumPy 数组的形式将数据返回给 Python。这个功能使 Python 成为一种包装 C/C++/Fortran 历史代码库的选择，并使被包装库拥有一个动态的、易用的接口。NumPy 本身并没有提供多么高级的数据分析功能，理解 NumPy 数组以及面向数组的计算将有助于你更加高效地使用诸如 pandas 之类的工具。因为 NumPy 是一个很大的题目，我会在附录 A 中介绍更多 NumPy 高级功能，比如广播。对于大部分数据分析应用而言，我最关注的功能主要集中在：用于数据整理和清理、子集构造和过滤、转换等快速的矢量化数组运算；常用的数组算法，如排序、唯一化、集合运算等；高效的描述统计和数据聚合/摘要运算；用于异构数据集的合并/连接运算的数据对齐和关系型数据运算；将条件逻辑表述为数组表达式（而不是带有 if-elif-else 分支的循环）；数据的分组运算（聚合、转换、函数应用等）。

虽然 NumPy 提供了通用的数值数据处理的计算基础，但大多数读者可能还是想将 pandas 作为统计和分析工作的基础，尤其是处理表格数据时。pandas 还提供了一些 NumPy 所没有的更加领域特定的功能，如时间序列处理等。

笔记：Python 的面向数组计算可以追溯到 1995 年，Jim Hugunin 创建了 Numeric 库。接下来的 10 年，许多科学编程社区纷纷开始使用 Python 的数组编程，但是进入 21 世纪，库的生态系统变得碎片化了。2005 年，Travis Oliphant 从 Numeric 和 Numarray 项目整了出了 NumPy 项目，进而所有社区都集合到了这个框架下。NumPy 之于数值计算特别重要的原因之一，是因为它可以高效处理大数组的数据。这是因为：NumPy 是在一个连续的内存块中存储数据，独立于其他 Python 内置对象。NumPy 的 C 语言编写的算法库可以操作内存，而不必进行类型检查或其它前期工作。比起 Python 的内置序列，NumPy 数组使用的内存更少；NumPy 可以在整个数组上执行复杂的计算，而不需要 Python 的 for 循环。

基于 NumPy 的算法要比纯 Python 快 10 到 100 倍（甚至更快），并且使用的内存更少。NumPy 最重要的一个特点就是其 N 维数组对象（即 ndarray），该对象是一个快速而灵活的大数据集容器。你可以利用这种数组对整块数据执行一些数学运算，其语法跟标量元素之间的运算一样。要明白 Python 是如何利用与标量值类似的语法进行批次计算，我先引入 NumPy，然后生成一个包含随机数据的小数组：

笔记：在本章及全书中，我会使用标准的 NumPy 惯用法 import numpy as np。你当然也可以在代码中使用 from numpy import *，但不建议这么做。numpy 的命名空间很大，包含许多函数，其中一些的名字与 Python 的内置函数重名（比如 min 和 max）。

ndarray 是一个通用的同构数据多维容器，也就是说，其中的所有元素必须是相同类型的。每个数组都有一个 shape（一个表示各维度大小的元组）和一个 dtype（一个用于说明数组数据类型的对象）。

1『ndarray 对象太重要了，是 numpy 的核心基础。shape 和 dtype 是多维数组对象里的属性。比如 data.shape 返回的是数组各个维度的大小，比如是 (2, 3)；data.dtype 返回的是多维数组数据类型，比如是 dtype('float64')。』

本章将会介绍 NumPy 数组的基本用法，这对于本书后面各章的理解基本够用。虽然大多数数据分析工作不需要深入理解 NumPy，但是精通面向数组的编程和思维方式是成为 Python 科学计算牛人的一大关键步骤。

笔记：当你在本书中看到「数组」、「NumPy 数组」、「ndarray」时，基本上都指的是同一样东西，即 ndarray 对象。

创建数组最简单的办法就是使用 array 函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的 NumPy 数组。以一个列表的转换为例；嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组。因为 data2 是列表的列表，NumPy 数组 arr2 的两个维度的 shape 是从 data2 引入的。可以用属性 ndim 和 shape 验证；除非特别说明（稍后将会详细介绍），np.array 会尝试为新建的这个数组推断出一个较为合适的数据类型。数据类型保存在一个特殊的 dtype 对象中。除 np.array 之外，还有一些函数也可以新建数组。比如，zeros 和 ones 分别可以创建指定长度或形状的全 0 或全 1 数组。empty 可以创建一个没有任何具体值的数组。要用这些方法创建多维数组，只需传入一个表示形状的元组即可。

想要使用 np.empty 来生成一个全 0 数组，并不安全，有些时候它可能会返回未初始化的垃圾数值。arange 是 Python 内置函数 range 的数组版；表 4-1 列出了一些数组创建函数。由于 NumPy 关注的是数值计算，因此，如果没有特别指定，数据类型基本都是 float64（浮点数）。

数据类型，即 dytpe，是一个特殊的对象，它包含了 ndarray 需要为某一种类型数据所申明的内存块信息（也称为元数据，即表示数据的数据）；dtype 是 NumPy 能够与其他系统数据灵活交互的原因。通常，其他系统提供一个硬盘或内存与数据的对应关系（直接映射到相应的机器表示），使得利用 C 或 Fortran 等底层语言读写数据变得十分方便。数据的 dtype 通常都是按照一个方式命名：类型名，比如 float 和 int，后面再接上表明每个元素位数的数字。一个标准的双精度浮点值（Python 中数据类型为 float），将使用 8 字节或 64 位。因此，这个类型在 NumPy 中称为 float64。表 4-2 将展现所有的 NumPy 所支持的数据类型。

笔记：记不住这些 NumPy 的 dtype 也没关系，新手更是如此。通常只需要知道你所处理的数据的大致类型是浮点数、复数、整数、布尔值、字符串，还是普通的 Python 对象即可。当你需要控制数据在内存和磁盘中的存储方式时（尤其是对大数据集），那就得了解如何控制存储类型。

可以通过 ndarray 的 astype 方法明确地将一个数组从一个 dtype 转换成另一个 dtype；在本例中，整数被转换成了浮点数。如果将浮点数转换成整数，则小数部分将会被截取删除；如果你有一个数组，里面的元素都是表达数字含义的字符串，也可以通过 astype 将字符串转换为数字。

在 NumPy 中，当使用 numpy.string_ 类型作字符串数据要小心，因为 NumPy 会修正它的大小或删除输入且不发出警告。pandas 在处理非数值数据时有更直观的开箱型操作；如果因为某些原因导致转换类型失败（比如字符串无法转换为 float64 位时），将会抛出一个ValueError。这里我偷懒地使用 float 来代替 np.float64，是因为 NumPy 可以使用相同别名来表征与 Python 精度相同的 Python 数据类型。你也可以使用另一个数组的 dtype 属性；也可以使用类型代码来传入数据类型。

笔记：使用 astype 时总是生成一个新的数组，即使你传入的 dtype 与之前一样。

NumPy 数组的运算。数组很重要，因为它使你不用编写循环即可对数据执行批量运算。NumPy 用户称其为向量化（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级；数组与标量的算术运算会将标量值传播到各个元素；大小相同的数组之间的比较会生成布尔值数组；不同大小的数组之间的运算叫做广播（broadcasting），将在附录 A 中对其进行详细讨论。本书的内容不需要对广播机制有多深的理解。

1『广播的定义：不同大小的数组之间的运算。』

基本的索引和切片。NumPy 数组的索引是一个内容丰富的主题，因为选取数据子集或单个元素的方式有很多。一维数组很简单。从表面上看，它们跟 Python 列表的功能差不多；如上所示，当你将一个标量值赋值给一个切片时（如 arr [5:8]=12），该值会自动传播（也就说后面将会讲到的「广播」）到整个选区。跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，视图上的任何修改都会直接反映到源数组上。作为例子，先创建一个 arr 的切片；现在，当我修稿 arr_slice 中的值，变动也会体现在原始数组 arr 中；切片 [:] 会给数组中的所有值赋值。

如果你刚开始接触 NumPy，可能会对此感到惊讶（尤其是当你曾经用过其他热衷于复制数组数据的编程语言）。由于 NumPy 的设计目的是处理大数据，所以你可以想象一下，假如 NumPy 坚持要将数据复制来复制去的话会产生何等的性能和内存问题。注意：如果你想要得到的是 ndarray 切片的一份副本而非视图，就需要明确地进行复制操作，例如 arr [5:8].copy ()。

对于高维度数组，能做的事情更多。在一个二维数组中，各索引位置上的元素不再是标量而是一维数组；因此，可以对各个元素进行递归访问，但这样需要做的事情有点多。你可以传入一个以逗号隔开的索引列表来选取单个元素。也就是说，下面两种方式是等价的；图 4-1 说明了二维数组的索引方式。轴 0 作为行，轴 1 作为列。

```
In [74]: arr2d[0][2] 
Out[74]: 3 
In [75]: arr2d[0, 2] 
Out[75]: 3
```

在多维数组中，你可以省略后续索引值，返回的对象将是降低一个维度的数组。因此在一个 2×2×3 的数组 arr3d 中。arr3d [0] 是一个 2×3 数组；标量值和数组都可以被赋值给 arr3d [0]；相似的，arr3d [1,0] 可以访问索引以 (1,0) 开头的那些值（以一维数组的形式返回）；上面的表达式可以分解为下面两步，注意在上面所有这些选取数组子集的例子中，返回的数组都是视图。

切片索引。ndarray 的切片语法跟 Python 列表这样的一维对象差不多；对于之前的二维数组 arr2d，其切片方式稍显不同。如你所见，数组沿着轴 0 进行了切片。表达式 arrzd[:2] 的含义为选择 arr2d 的前两「行」。你可以进行多组切片，与多组索引类似；像这样进行切片时，只能得到相同维数的数组视图。通过将整数索引和切片混合，可以得到低维度的切片。例如，我可以选取第二行的前两列；图 4-2 对此进行了说明。注意，「只有冒号」表示选取整个轴，因此你可以像下面这样只对高维轴进行切片；自然，对切片表达式的赋值操作也会被扩散到整个选区。

1『切片操作时，末尾索引值无效，倒数第二个才有效。比如对 arr2d 切片，arr2d[:2] 是切前 2 行，arr2d[1:3] 是切第二行到第三行；arr2d[:2, 1:] 表示行切前 2 行，列切从第 2 列到最后一列；arr2d[2, :2] 表示第二行的前两列。』

布尔型索引。来看这样一个例子，假设我们有一个用于存储数据的数组以及一个存储姓名的数组（含有重复项）。在这里，我将使用 numpy.random 中的 randn 函数生成一些正态分布的随机数据；假设每个名字都对应 data 数组中的一行，而我们想要选出对应于名字 "Bob" 的所有行。跟算术运算一样，数组的比较运算（如 ==）也是可以向量化的。因此，对 names 和字符串 "Bob" 的比较运算将会产生一个布尔型数组；这个布尔型数组可用于数组索引；布尔型数组的长度必须跟被索引的轴长度一致。此外，还可以将布尔型数组跟切片、整数（或整数序列，稍后将对此进行详细讲解）混合使用。注意：当布尔值数组的长度不正确时，布尔值选择数据的方法并不会报错，因此我建议在使用该特性的时候要小心。下面的例子，我选取了 names == 'Bob' 的行，并索引了列。

要选择除 "Bob" 以外的其他值，既可以使用不等于符号（!=），也可以通过 ～ 对条件进行否定；～ 符号可以在你想要对一个通用条件进行取反时使用；选取这三个名字中的两个需要组合应用多个布尔条件，使用 &（和）、|（或）之类的布尔算术运算符即可；通过布尔型索引选取数组中的数据，将总是创建数据的副本，即使返回一模一样的数组也是如此。

注意：Python 关键字 and 和 or 在布尔型数组中无效。要是用 & 与 |。

通过布尔型数组设置值是一种经常用到的手段。为了将 data 中的所有负值都设置为 0，我们只需；通过一维布尔数组设置整行或列的值也很简单。后面会看到，这类二维数据的操作也可以用 pandas 方便的来做。

神奇索引。神奇索引是 NumPy 中的术语，用于描述使用整数数组进行数据索引。假设我们有一个 8×4 的数组；为了选出一个符合特定顺序的子集，你可以简单地通过传递一个包含指明所需顺序的列表或数组来完成；这段代码确实达到我们的要求了！使用负数索引将会从末尾开始选取行；一次传入多个索引数组会有一点特别。它返回的是一个一维数组，其中的元素对应各个索引元组。附录 A 中会详细介绍 reshape 方法。

最终选出的是元素 (1,0)、(5,3)、(7,1) 和 (2,2)。无论数组是多少维的，神奇索引总是一维的。这个神奇索引的行为可能会跟某些用户的预期不一样（包括我在内），选取矩阵的行列子集应该是矩形区域的形式才对。下面是得到该结果的一个办法；请牢记神奇索引与切片不同，它总是将数据复制到一个新的数组中。

数组转置和轴对换。转置是重塑的一种特殊形式，它返回的是源数据的视图（不会进行任何复制操作）。数组不仅有 transpose 方法，还有一个特殊的 T 属性；在进行矩阵计算时，经常需要用到该操作，比如利用 np.dot 计算矩阵内积；对于高维数组，transpose 需要得到一个由轴编号组成的元组才能对这些轴进行转置（比较费脑子）。这里，第一个轴被换成了第二个，第二个轴被换成了第一个，最后一个轴不变。简单的转置可以使用 .T，它其实就是进行轴对换而已；ndarray 还有一个 swapaxes 方法，它需要接受一对轴编号。swapaxes 也是返回源数据的视图（不会进行任何复制操作）。

1『如何计算 2 个矩阵内积的源码。』

```
In [129]: arr = np.random.randn(6, 3) 
In [130]: arr 
Out[130]: 
array([[-0.8608, 0.5601, -1.2659], [ 0.1198, -1.0635, 0.3329], [-2.3594, -0.1995, -1.542 ], [-0.9707, -1.307 , 0.2863], [ 0.378 , -0.7539, 0.3313], [ 1.3497, 0.0699, 0.2467]]) 
In [131]: np.dot(arr.T, arr) 
Out[131]: 
array([[ 9.2291, 0.9394, 4.948 ], [ 0.9394, 3.7662, -1.3622], [ 4.948 , -1.3622, 4.3437]])
```

通用函数：快速的逐元素数组函数。通用函数，也可以称为 ufunc，是一种在 ndarray 数据中进行逐元素操作的函数。某些简单函数接收一个或多个标量数值，并产生一个或多个标量结果，而通用函数就是对这些简单函数的向量化封装。有很多 ufunc 是简单的逐元素转换，比如 sqrt 或 exp 函数；这些都是一元（unary）ufunc。另外一些（如 add 或 maximum）接受 2 个数组（因此也叫二元（binary）ufunc），并返回一个结果数组；这里，numpy.maximum 计算了 x 和 y 中元素级别最大的元素；虽然并不常见，但有些 ufunc 的确可以返回多个数组。modf 就是一个例子，它是 Python 内置函数 divmod 的矢量化版本，它会返回浮点数数组的小数和整数部分；通用函数接收一个可选参数out，允许对数组按位置操作；表 4-3 和表 4-4 分别列出了一些一元和二元 ufunc。

利用数组进行数据处理。使用 NumPy 数组可以使你利用简单的数组表达式完成多种数据操作任务，而无须写些大量循环。这种利用数组表达式来替代显式循环的方法，称为向量化。通常，向量化的数组操作会比纯 Python 的等价实现在速度上快一到两个数量级（甚至更多），这对所有种类的数值计算产生了最大的影响。附录 A 中我解释的广播机制，就是向量化计算的有效方式。作为一个简单的示例，假设我们想要对一些网格数据来计算函数 sqrt(x^2+y^2) 的值。np.meshgrid 函数接收两个一维数组，并根据两个数组的所有 (x, y) 对生成一个二维矩阵；现在，你可以用和两个坐标值同样的表达式来使用函数；作为第 9 章的先导，我用 matplotlib 创建了这个二维数组的可视化。见图 4-3。这张图是用 matplotlib 的 imshow 函数创建的。

将条件逻辑表述为数组运算。numpy.where 函数是三元表达式 x if condition else y 的向量化版本。假设我们有一个布尔数组和两个值数组；假设我们想要根据 cond 中的值选取 xarr 和 yarr 的值：当 cond 中的值为 True 时，选取 xarr 的值，否则从 yarr 中选取。列表推导式的写法应该如下所示；这有几个问题。第一，它对大数组的处理速度不是很快（因为所有工作都是由纯 Python 完成的）。第二，无法用于多维数组。若使用 np.where，则可以将该功能写得非常简洁：

```
In [170]: result = np.where(cond, xarr, yarr) 
In [171]: result 
Out[171]: array([ 1.1, 2.2, 1.3, 1.4, 2.5])
```

np.where 的第二个和第三个参数不必是数组，它们都可以是标量值。在数据分析工作中，where 通常用于根据另一个数组而产生一个新的数组。假设有一个由随机数据组成的矩阵，你希望将所有正值替换为 2，将所有负值替换为－2。若利用 np.where，则会非常简单；使用 np.where，可以将标量和数组结合起来。例如，我可用常数 2 替换 arr 中所有正的值；传递给 where 的数组大小可以不相等，甚至可以是标量值。

数学和统计方法。许多关于计算整个数组统计值或关于轴向数据的数学函数，可以作为数组类型的方法被调用。你可以使用聚合函数（通常也叫缩减函数），比如 sum、mean 和 std（标准差），既可以直接调用数组实例的方法，也可以使用顶层的 NumPy 函数。这里，我生成了一些正态分布随机数据，然后做了聚类统计；像 mean、sum 等函数可以接收一个可选参数 axis，这个参数可以用于计算给定轴向上的统计值，形成一个下降一维度的数组；这里，arr.mean (1) 是「计算行的平均值」，arr.sum (0) 是「计算每列的和」。其他如 cumsum 和 cumprod 之类的方法则不聚合，而是产生一个由中间结果组成的数组；在多维数组中，累加函数（如 cumsum）返回的是同样大小的数组，但是会根据每个低维的切片沿着标记轴计算部分聚类。表 4-5 列出了全部的基本数组统计方法。后续章节中有很多例子都会用到这些方法。

用于布尔型数组的方法。在上面这些方法中，布尔值会被强制转换为 1（True）和 0（False）。因此，sum 经常被用来对布尔型数组中的 True 值计数；另外还有两个方法 any 和 all，它们对布尔型数组非常有用。any 用于测试数组中是否存在一个或多个 True，而 all 则检查数组中所有值是否都是 True；这两个方法也能用于非布尔型数组，所有非 0 元素将会被当做 True。

排序。跟 Python 内置的列表类型一样，NumPy 数组也可以通过 sort 方法就地排序；多维数组可以在任何一个轴向上进行排序，只需将轴编号传给 sort 即可；顶级方法 np.sort 返回的是数组的已排序副本，而就地排序则会修改数组本身。计算数组分位数最简单的办法是对其进行排序，然后选取特定位置的值；更多关于 NumPy 排序方法以及诸如间接排序之类的高级技术，请参阅附录 A。在 pandas 中还可以找到一些其他跟排序有关的数据操作（比如根据一列或多列对表格型数据进行排序）。

唯一值以及其它的集合逻辑。NumPy 提供了一些针对一维 ndarray 的基本集合运算。最常用的可能要数 np.unique 了，它用于找出数组中的唯一值并返回已排序的结果；拿跟 np.unique 等价的纯 Python 代码来对比一下；另一个函数 np.in1d 用于测试一个数组中的值在另一个数组中的成员资格，返回一个布尔型数组；NumPy 中的集合函数请参见表 4-6。

用于数组的文件输入输出。NumPy 能够读写磁盘上的文本数据或二进制数据。这一小节只讨论 NumPy 的内置二进制格式，因为更多的用户会使用 pandas 或其它工具加载文本或表格数据（见第 6 章）。np.save 和 np.load 是读写磁盘数组数据的两个主要函数。默认情况下，数组是以未压缩的原始二进制格式保存在扩展名为 .npy 的文件中的；如果文件路径末尾没有扩展名 .npy，则该扩展名会被自动加上。然后就可以通过 np.load 读取磁盘上的数组；通过 np.savez 可以将多个数组保存到一个未压缩文件中，将数组以关键字参数的形式传入即可；加载 .npz 文件时，你会得到一个类似字典的对象，该对象会对各个数组进行延迟加载；如果数据压缩的很好，就可以使用 numpy.savez_compressed。

线性代数（如矩阵乘法、矩阵分解、行列式以及其他方阵数学等）是任何数组库的重要组成部分。不像某些语言（如 MATLAB），通过 * 对两个二维数组相乘得到的是一个元素级的积，而不是一个矩阵点积。因此，NumPy 提供了一个用于矩阵乘法的 dot 函数（既是一个数组方法也是 numpy 命名空间中的一个函数）；x.dot (y) 等价于 np.dot (x, y)；一个二维数组跟一个大小合适的一维数组的矩阵点积运算之后将会得到一个一维数组；@符（类似 Python 3.5）也可以用作中缀运算符，进行矩阵乘法。

numpy.linalg 中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西。它们跟 MATLAB 和 R 等语言所使用的是相同的行业标准线性代数库，如 BLAS、LAPACK、Intel MKL（Math Kernel Library，可能有，取决于你的 NumPy 版本）等。表达式 X.T.dot (X) 计算 X 和它的转置 X.T 的点积。表 4-7 中列出了一些最常用的线性代数函数。

1『这里有矩阵各种运算的函数信息。』

伪随机数生成。numpy.random 模块对 Python 内置的 random 进行了补充，增加了一些用于高效生成多种概率分布的样本值的函数。例如，你可以用 normal 来得到一个标准正态分布的 4×4 样本数组；而 Python 内置的 random 模块则只能一次生成一个样本值。从下面的测试结果中可以看出，如果需要产生大量样本值，numpy.random 快了不止一个数量级；我们说这些都是伪随机数，是因为它们都是通过算法基于随机数生成器种子，在确定性的条件下生成的。你可以用 NumPy 的 np.random.seed 更改随机数生成种子；numpy.random 的数据生成函数使用了全局的随机种子。要避免全局状态，你可以使用 numpy.random.RandomState，创建一个与其它隔离的随机数生成器；表 4-8 列出了 numpy.random 中的部分函数。在下一节中，我将给出一些利用这些函数一次性生成大量样本值的范例。

1『「2019018Python编程」里也有个随机漫步的例子，不过跟用矩阵实现相比，矩阵的源码要简洁太多。』

示例：随机漫步。我们通过模拟随机漫步来说明如何运用数组运算。先来看一个简单的随机漫步的例子：从 0 开始，步长 1 和 -1 出现的概率相等。下面是一个通过内置的 random 模块以纯 Python 的方式实现 1000 步的随机漫步；不难看出，这其实就是随机漫步中各步的累计和，可以用一个数组运算来实现。因此，我用 np.random 模块一次性随机产生 1000 个「掷硬币」结果（即两个数中任选一个），将其分别设置为 1 或 -1，然后计算累计和；有了这些数据之后，我们就可以沿着漫步路径做一些统计工作了，比如求取最大值和最小值。

现在来看一个复杂点的统计任务 —— 首次穿越时间，即随机漫步过程中第一次到达某个特定值的时间。假设我们想要知道本次随机漫步需要多久才能距离初始 0 点至少 10 步远（任一方向均可）。np.abs (walk)>=10 可以得到一个布尔型数组，它表示的是距离是否达到或超过 10，而我们想要知道的是第一个 10 或－10 的索引。可以用 argmax 来解决这个问题，它返回的是该布尔型数组第一个最大值的索引（True 就是最大值）。

注意，这里使用 argmax 并不是很高效，因为它无论如何都会对数组进行完全扫描。在本例中，只要发现了一个 True，那我们就知道它是个最大值了。

一次模拟多个随机漫步。如果你希望模拟多个随机漫步过程（比如 5000 个），只需对上面的代码做一点点修改即可生成所有的随机漫步过程。只要给 numpy.random 的函数传入一个二元元组就可以产生一个二维数组，然后我们就可以一次性计算 5000 个随机漫步过程（一行一个）的累计和了；现在，我们来计算所有随机漫步过程的最大值和最小值；得到这些数据之后，我们来计算 30 或－30 的最小穿越时间。这里稍微复杂些，因为不是 5000 个过程都到达了 30。我们可以用 any 方法来对此进行检查；然后我们利用这个布尔型数组选出那些穿越了 30（绝对值）的随机漫步（行），并调用 argmax 在轴 1 上获取穿越时间。

```
In [258]: nwalks = 5000 
In [259]: nsteps = 1000 
In [260]: draws = np.random.randint(0, 2, size=(nwalks, nsteps)) # 0 or 1 
In [261]: steps = np.where(draws > 0, 1, -1) 
In [262]: walks = steps.cumsum(1) 
In [263]: walks 
Out[263]: 
array([[ 1, 0, 1, ..., 8, 7, 8], [ 1, 0, -1, ..., 34, 33, 32], [ 1, 0, -1, ..., 4, 5, 4], ..., [ 1, 2, 1, ..., 24, 25, 26], [ 1, 2, 3, ..., 14, 13, 14], [ -1, -2, -3, ..., -24, -23, -22]])

In [264]: walks.max() 
Out[264]: 138
In [265]: walks.min() 
Out[265]: -133

In [266]: hits30 = (np.abs(walks) >= 30).any(1) 
In [267]: hits30 
Out[267]: array([False, True, False, ..., False, True, False], dtype=bool) 
In [268]: hits30.sum() # Number that hit 30 or -30 
Out[268]: 3410

In [269]: crossing_times = (np.abs(walks[hits30]) >= 30).argmax(1) 
In [270]: crossing_times.mean() 
Out[270]: 498.88973607038122
```

请尝试用其他分布方式得到漫步数据。只需使用不同的随机数生成函数即可，如 normal 用于生成指定均值和标准差的正态分布数据：

```
In [271]: steps = np.random.normal(loc=0, scale=0.25, 
.....:    size=(nwalks, nsteps))
```

## 05. pandas 入门

### 1. 逻辑脉络

pandas 入门概念：基于 numpy 数组构建的；专门处理表格和混杂数据设计；Series 数据结构和 DataFrame 数据结构；

### 2. 摘录及评论

pandas 是本书后续内容的首选库。它含有使数据清洗和分析工作变得更快更简单的数据结构和操作工具。pandas 经常和其它工具一同使用，如数值计算工具 NumPy 和 SciPy，分析库 statsmodels 和 scikit-learn，和数据可视化库 matplotlib。

pandas 是基于 NumPy 数组构建的，特别是基于数组的函数和不使用 for 循环的数据处理。虽然 pandas 采用了大量的 NumPy 编码风格，但二者最大的不同是 pandas 是专门为处理表格和混杂数据设计的。而 NumPy 更适合处理统一的数值数组数据。

1『pandas 与 numpy 的区别在于：pandas 是专门为处理表格和混杂数据，而 numPy 更适合处理统一的数值数组数据。』

自从 2010 年 pandas 开源以来，pandas 逐渐成长为一个非常大的库，应用于许多真实案例。开发者社区已经有了 800 个独立的贡献者，他们在解决日常数据问题的同时为这个项目提供贡献。在本书后续部分中，我将使用下面这样的 pandas 引入约定：

    In [1]: import pandas as pd

因此，只要你在代码中看到 pd.，就得想到这是 pandas。因为 Series 和 DataFrame 用的次数非常多，所以将其引入本地命名空间中会更方便：

    In [2]: from pandas import Series, DataFrame

要使用 pandas，你首先就得熟悉它的两个主要数据结构：Series 和 DataFrame。虽然它们并不能解决所有问题，但它们为大多数应用提供了一种可靠的、易于使用的基础。

Series 是一种类似于一维数组的对象，它由一组数据（各种 NumPy 数据类型）以及一组与之相关的数据标签（即索引）组成。Series 的字符串表现形式为：索引在左边，值在右边。由于我们没有为数据指定索引，于是会自动创建一个 0 到 N-1（N 为数据的长度）的整数型索引。你可以通过 Series 的 values 和 index 属性获取其数组表示形式和索引对象。

通常，我们希望所创建的 Series 带有一个可以对各个数据点进行标记的索引；与普通 NumPy 数组相比，你可以通过索引的方式选取 Series 中的单个或一组值。['c', 'a', 'd'] 是索引列表，即使它包含的是字符串而不是整数；使用 NumPy 函数或类似 NumPy 的运算（如根据布尔型数组进行过滤、标量乘法、应用数学函数等）都会保留索引值的链接；还可以将 Series 看成是一个定长的有序字典，因为它是索引值到数据值的一个映射。它可以用在许多原本需要字典参数的函数中；如果数据被存放在一个 Python 字典中，也可以直接通过这个字典来创建 Series：

```
In [26]: sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000} 
In [27]: obj3 = pd.Series(sdata) 
```

如果只传入一个字典，则结果 Series 中的索引就是原字典的键（有序排列）。你可以传入排好序的字典的键以改变顺序；在这个例子中，sdata 中跟 states 索引相匹配的那 3 个值会被找出来并放到相应的位置上，但由于 "California" 所对应的 sdata 值找不到，所以其结果就为 NaN（即「非数字」（not a number），在 pandas 中，它用于表示缺失或 NA 值）。因为 ‘Utah’ 不在 states 中，它被从结果中除去。我将持续使用缺失（missing）或 NA 表示缺失数据。pandas 的 isnull 和 notnull 函数可用于检测缺失数据。Series 也有类似的实例方法。我将在第 7 章详细讲解如何处理缺失数据；对于许多应用而言，Series 最重要的一个功能是，它会根据运算的索引标签自动对齐数据；数据对齐功能将在后面详细讲解。如果你使用过数据库，你可以认为是类似 join 的操作。

1『两个字典合并后自动剔除重复的元素；「自动对齐」是个关键点。』

Series 对象本身及其索引都有一个 name 属性，该属性跟 pandas 其他的关键功能关系非常密切；Series 的索引可以通过赋值的方式就地修改。

DataFrame 是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等）。DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共用同一个索引）。DataFrame 中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）。有关 DataFrame 内部的技术细节远远超出了本书所讨论的范围。

笔记：虽然 DataFrame 是以二维结构保存数据的，但你仍然可以轻松地将其表示为更高维度的数据（层次化索引的表格型结构，这是 pandas 中许多高级数据处理功能的关键要素，我们会在第 8 章讨论这个问题）。

建 DataFrame 的办法有很多，最常用的一种是直接传入一个由等长列表或 NumPy 数组组成的字典；结果 DataFrame 会自动加上索引（跟 Series 一样），且全部列会被有序排列；如果你使用的是 Jupyter notebook，pandas DataFrame 对象会以对浏览器友好的 HTML 表格的方式呈现。

2『已经在 conda 环境里面安装了 Jupyter，「conda install jupyter」，然后用命名 jupyter-notebook 启动。』

对于特别大的 DataFrame，head 方法会选取前五行；如果指定了列序列，则 DataFrame 的列就会按照指定顺序进行排列。如果传入的列在数据中找不到，就会在结果中产生缺失值；通过类似字典标记的方式或属性的方式，可以将 DataFrame 的列获取为一个 Series。

1『这里展现的数据形式，跟 pdms 三维抽出来的材料数据是一样的。如何把材料数据转化为一个 DataFrame 表格型的数据结构即为下一步的动作。』

笔记：在 IPython 中，属性型连接（比如 frame2.year）和列名的 tab 补全是非常方便的。

frame2 [column] 适用于任何列的名，但是 frame2.column 只有在列名是一个合理的 Python 变量名时才适用。注意，返回的 Series 拥有原 DataFrame 相同的索引，且其 name 属性也已经被相应地设置好了。行也可以通过位置或名称的方式进行获取，比如用 loc 属性（稍后将对此进行详细讲解）；列可以通过赋值的方式进行修改。例如，我们可以给那个空的 "debt" 列赋上一个标量值或一组值。

将列表或数组赋值给某个列时，其长度必须跟 DataFrame 的长度相匹配。如果赋值的是一个 Series，就会精确匹配 DataFrame 的索引，所有的空位都将被填上缺失值；如果被赋值的列并不存在，则会生成一个新的列。del 关键字可以像在字典中那样对 DataFrame 删除列。作为 del 的例子，我先添加一个新的布尔值的列，state 是否为 'Ohio'。

注意：不能用 frame2.eastern 创建新的列。del 方法可以用来删除这列；通过索引方式返回的列只是相应数据的视图而已，并不是副本。因此，对返回的 Series 所做的任何就地修改全都会反映到源 DataFrame 上。通过 Series 的 copy 方法即可指定复制列。

另一种常见的数据形式是嵌套字典；如果嵌套字典传给 DataFrame，pandas 就会被解释为：外层字典的键作为列，内层键则作为行索引；你也可以使用类似 NumPy 数组的方法，对 DataFrame 进行转置（交换行和列）；内层字典的键会被合并、排序以形成最终的索引。如果明确指定了索引，则不会这样；由 Series 组成的字典差不多也是一样的用法；表 5-1 列出了 DataFrame 构造函数所能接受的各种数据；如果设置了 DataFrame 的 index 和 columns 的 name 属性，则这些信息也会被显示出来；跟 Series 一样，values 属性也会以二维 ndarray 的形式返回 DataFrame 中的数据。

索引对象。pandas 的索引对象负责管理轴标签和其他元数据（比如轴名称等）。构建 Series 或 DataFrame 时，所用到的任何数组或其他序列的标签都会被转换成一个 Index；Index 对象是不可变的，因此用户不能对其进行修改；不可变可以使 Index 对象在多个数据结构之间安全共享。

注意：虽然用户不需要经常使用 Index 的功能，但是因为一些操作会生成包含被索引化的数据，理解它们的工作原理是很重要的。除了类似于数组，Index 的功能也类似一个固定大小的集合。

1『Index 是 pandas 模块里的一个方法。』

与 python 的集合不同，pandas 的 Index 可以包含重复的标签；根据重复标签进行筛选，会选取所有重复标签对应的数据。每个索引都有一些集合逻辑的方法和属性，这些方法和属性解决了关于它所包含的数据的其他常见问题。表 5-2 中总结了这些方法和属性中常用的一部分。






基本功能。将介绍操作 Series 和 DataFrame 中的数据的基本手段。后续章节将更加深入地挖掘 pandas 在数据分析和处理方面的功能。本书不是 pandas 库的详尽文档，主要关注的是最重要的功能，那些不大常用的内容（也就是那些更深奥的内容）就交给你自己去摸索吧。

重新索引。pandas 对象的一个重要方法是 reindex，其作用是创建一个新对象，它的数据符合新的索引。看下面的例子；对于时间序列这样的有序数据，重新索引时可能需要做一些插值处理。method 选项即可达到此目的，例如，使用 ffill 可以实现前向值填充；借助 DataFrame，reindex 可以修改（行）索引和列。只传递一个序列时，会重新索引结果的行；列可以用 columns 关键字重新索引。表 5-3 列出了 reindex 函数的各参数及说明。

表 5-3，indeX：新建作为索引的序列，可以是索引实例或任意其他序列型 Python 数据结构，索引使用时无须复制。

丢弃指定轴上的项。如果你已经拥有索引数组或不含条目的列表，在轴向上删除一个或更多的条目就非常容易，但这样需要一些数据操作和集合逻辑，drop 方法会返回一个含有指示值或轴向上删除值的新对象；用标签序列调用 drop 会从行标签（axis 0）删除值；通过传递 axis=1 或 axis='columns' 可以删除列的值；许多函数，如 drop，会修改 Series 或 DataFrame 的大小或形状，可以就地修改对象，不会返回新的对象；小心使用 inplace，它会销毁所有被删除的数据。

1『drop() 方法删除数据结构里任意轴线上的数据，一行或一列，多行或多列。』

1『inplace 是 drop() 方法的一个形参。』

索引、选取和过滤。Series 索引（obj [...]）的工作方式类似于 NumPy 数组的索引，只不过 Series 的索引值不只是整数。下面是几个例子；利用标签的切片运算与普通的 Python 切片运算不同，其末端是包含的；用切片可以对 Series 的相应部分进行设置；用一个值或序列对 DataFrame 进行索引其实就是获取一个或多个列；这种索引方式有几个特殊的情况。首先通过切片或布尔型数组选取数据；选取行的语法 data [:2] 十分方便。向 [ ] 传递单一的元素或列表，就可选择列。另一种用法是通过布尔型 DataFrame（比如下面这个由标量比较运算得出的）进行索引；这使得 DataFrame 的语法与 NumPy 二维数组的语法很像。

1『赋值设置。』

用 loc 和 iloc 进行选取。对于 DataFrame 的行的标签索引，我引入了特殊的标签运算符 loc 和 iloc。它们可以让你用类似 NumPy 的标记，使用轴标签（loc）或整数索引（iloc），从 DataFrame 选择行和列的子集。作为一个初步示例，让我们通过标签选择一行和多列；这两个索引函数也适用于一个标签或多个标签的切片；所以，在 pandas 中，有多个方法可以选取和重新组合数据。对于 DataFrame，表 5-4 进行了总结。后面会看到，还有更多的方法进行层级化索引。

笔记：在一开始设计 pandas 时，我觉得用 frame [:, col] 选取列过于繁琐（也容易出错），因为列的选择是非常常见的操作。我做了些取舍，将花式索引的功能（标签和整数）放到了 ix 运算符中。在实践中，这会导致许多边缘情况，数据的轴标签是整数，所以 pandas 团队决定创造 loc 和 iloc 运算符分别处理严格基于标签和整数的索引。ix 运算符仍然可用，但并不推荐。

表 5-4 DataFrame 的索引选项。df[val]：从 Dataframe 中选择单列或列序列；特殊情况的便利：布尔数组（过滤行），切片（切片行）或布尔值 Dataframe。

整数索引。处理整数索引的 pandas 对象常常难住新手，因为它与 Python 内置的列表和元组的索引语法不同。为了进行统一，如果轴索引含有整数，数据选取总会使用标签。为了更准确，请使用 loc（标签）或 iloc（整数）。

算术运算和数据对齐。pandas 最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。看一个简单的例子；它们相加就会产生；自动的数据对齐操作在不重叠的索引处引入了 NA 值。缺失值会在算术运算过程中传播。对于 DataFrame，对齐操作会同时发生在行和列上；将这些对象加在一起，返回一个 DataFrame，它的索引、列是每个 DataFrame 的索引、列的并集；因为 'c' 和 'e' 列均不在两个 DataFrame 对象中，在结果中以缺省值呈现。行也是同样。如果 DataFrame 对象相加，没有共用的列或行标签，结果都会是空。






















