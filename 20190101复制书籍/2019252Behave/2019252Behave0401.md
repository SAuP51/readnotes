
Four


			Hours to Days Before





We now take the next step back in our chronology, considering events from hours to days before a behavior occurs. To do so, we enter the realm of hormones. What are the effects of hormones on the brain and sensory systems that filled the last two chapters? How do hormones influence our best and worst behaviors?

			While this chapter examines various hormones, the most attention is paid to one inextricably tied to aggression, namely testosterone. And as the punch line, testosterone is far less relevant to aggression than usually assumed. At the other end of the spectrum, the chapter also considers a hormone with cult status for fostering warm, fuzzy prosociality, namely oxytocin. As we’ll see, it’s not quite as groovy as assumed.

			Those who are unfamiliar with hormones and endocrinology, please see the primer in appendix 2.





TESTOSTERONE’S BUM RAP


			Testosterone is secreted by the testes as the final step in the “hypothalamic/pituitary/testicular” axis; it has effects on cells throughout the body (including neurons, of course). And testosterone is everyone’s usual suspect when it comes to the hormonal causes of aggression.





Correlation and Causality


			Why is it that throughout the animal kingdom, and in every human culture, males account for most aggression and violence? Well, what about testosterone and some related hormones (collectively called “androgens,” a term that, unless otherwise noted, I will use simplistically as synonymous with “testosterone”)? In nearly all species males have more circulating testosterone than do females (who secrete small amounts of androgens from the adrenal glands). Moreover, male aggression is most prevalent when testosterone levels are highest (adolescence, and during mating season in seasonal breeders).

			Thus, testosterone and aggression are linked. Furthermore, there are particularly high levels of testosterone receptors in the amygdala, in the way station by which it projects to the rest of the brain (the bed nucleus of the stria terminalis), and in its major targets (the hypothalamus, the central gray of the midbrain, and the frontal cortex). But these are merely correlative data. Showing that testosterone causes aggression requires a “subtraction” plus a “replacement” experiment. Subtraction—castrate a male. Do levels of aggression decrease? Yes (including in humans). This shows that something coming from the testes causes aggression. Is it testosterone? Replacement—give that castrated individual replacement testosterone. Do precastration levels of aggression return? Yes (including in humans).

			Thus, testosterone causes aggression. Time to see how wrong that is.

			The first hint of a complication comes after castration, when average levels of aggression plummet in every species. But, crucially, not to zero. Well, maybe the castration wasn’t perfect, you missed some bits of testes. Or maybe enough of the minor adrenal androgens are secreted to maintain the aggression. But no—even when testosterone and androgens are completely eliminated, some aggression remains. Thus, some male aggression is testosterone independent.*

			This point is driven home by castration of some sexual offenders, a legal procedure in a few states.1 This is accomplished with “chemical castration,” administration of drugs that either inhibit testosterone production or block testosterone receptors.* Castration decreases sexual urges in the subset of sex offenders with intense, obsessive, and pathological urges. But otherwise castration doesn’t decrease recidivism rates; as stated in one meta-analysis, “hostile rapists and those who commit sex crimes motivated by power or anger are not amenable to treatment with [the antiandrogenic drugs].”

			This leads to a hugely informative point: the more experience a male had being aggressive prior to castration, the more aggression continues afterward. In other words, the less his being aggressive in the future requires testosterone and the more it’s a function of social learning.

			On to the next issue that lessens the primacy of testosterone: What do individual levels of testosterone have to do with aggression? If one person has higher testosterone levels than another, or higher levels this week than last, are they more likely to be aggressive?

			Initially the answer seemed to be yes, as studies showed correlation between individual differences in testosterone levels and levels of aggression. In a typical study, higher testosterone levels would be observed in those male prisoners with higher rates of aggression. But being aggressive stimulates testosterone secretion; no wonder more aggressive individuals had higher levels. Such studies couldn’t disentangle chickens and eggs.

			Thus, a better question is whether differences in testosterone levels among individuals predict who will be aggressive. And among birds, fish, mammals, and especially other primates, the answer is generally no. This has been studied extensively in humans, examining a variety of measures of aggression. And the answer is clear. To quote the British endocrinologist John Archer in a definitive 2006 review, “There is a weak and inconsistent association between testosterone levels and aggression in [human] adults, and . . . administration of testosterone to volunteers typically does not increase their aggression.” The brain doesn’t pay attention to fluctuations of testosterone levels within the normal range.2

			(Things differ when levels are made “supraphysiological”—higher than the body normally generates. This is the world of athletes and bodybuilders abusing high-dose testosterone-like anabolic steroids; in that situation risk of aggression does increase. Two complications: it’s not random who would choose to take these drugs, and abusers are often already predisposed toward aggression; supraphysiological levels of androgens generate anxiety and paranoia, and increased aggression may be secondary to that.)3

			Thus, aggression is typically more about social learning than about testosterone, and differing levels of testosterone generally can’t explain why some individuals are more aggressive than others. So what does testosterone actually do to behavior?





Subtleties of Testosterone Effects


			When looking at faces expressing strong emotions, we tend to make microexpressions that mimic them; testosterone decreases such empathic mimicry.*4 Moreover, testosterone makes people less adept at identifying emotions by looking at people’s eyes, and faces of strangers activate the amygdala more than familiar ones and are rated as less trustworthy.

			Testosterone also increases confidence and optimism, while decreasing fear and anxiety.5 This explains the “winner” effect in lab animals, where winning a fight increases an animal’s willingness to participate in, and its success in, another such interaction. Part of the increased success probably reflects the fact that winning stimulates testosterone secretion, which increases glucose delivery and metabolism in the animal’s muscles and makes his pheromones smell scarier. Moreover, winning increases the number of testosterone receptors in the bed nucleus of the stria terminalis (the way station through which the amygdala communicates with the rest of the brain), increasing its sensitivity to the hormone. Success in everything from athletics to chess to the stock market boosts testosterone levels.

			Confident and optimistic. Well, endless self-help books urge us to be precisely that. But testosterone makes people overconfident and overly optimistic, with bad consequences. In one study, pairs of subjects could consult each other before making individual choices in a task. Testosterone made subjects more likely to think their opinion was correct and to ignore input from their partner. Testosterone makes people cocky, egocentric, and narcissistic.6

			Testosterone boosts impulsivity and risk taking, making people do the easier thing when it’s the dumb-ass thing to do.7 Testosterone does this by decreasing activity in the prefrontal cortex and its functional coupling to the amygdala and increasing amygdaloid coupling with the thalamus—the source of that shortcut path of sensory information into the amygdala. Thus, more influence by split-second, low-accuracy inputs and less by the let’s-stop-and-think-about-this frontal cortex.

			Being fearless, overconfident, and delusionally optimistic sure feels good. No surprise, then, that testosterone can be pleasurable. Rats will work (by pressing levers) to be infused with testosterone and show “conditioned place preference,” returning to a random corner of the cage where infusions occur. “I don’t know why, but I feel good whenever I stand there.”8,9

			The underlying neurobiology fits perfectly. Dopamine is needed for place-preference conditioning to occur, and testosterone increases activity in the ventral tegmentum, the source of those mesolimbic and mesocortical dopamine projections. Moreover, conditioned place preference is induced when testosterone is infused directly into the nucleus accumbens, the ventral tegmentum’s main projection target. When a rat wins a fight, the number of testosterone receptors increases in the ventral tegmentum and accumbens, increasing sensitivity to the hormone’s feel-good effects.10

			So testosterone does subtle things to behavior. Nonetheless, this doesn’t tell us much because everything can be interpreted every which way. Testosterone increases anxiety—you feel threatened and become more reactively aggressive. Testosterone decreases anxiety—you feel cocky and overconfident, become more preemptively aggressive. Testosterone increases risk taking—“Hey, let’s gamble and invade.” Testosterone increases risk taking—“Hey, let’s gamble and make a peace offer.” Testosterone makes you feel good—“Let’s start another fight, since the last one went swell.” Testosterone makes you feel good—“Let’s all hold hands.”

			It’s a crucial unifying concept that testosterone’s effects are hugely context dependent.





Contingent Testosterone Effects


			This context dependency means that rather than causing X, testosterone amplifies the power of something else to cause X.

			A classic example comes from a 1977 study of groups of male talapoin monkeys.11 Testosterone was administered to the middle-ranking male in each group (say, rank number 3 out of five), increasing their levels of aggression. Does this mean that these guys, stoked on ’roids, started challenging numbers 1 and 2 in the hierarchy? No. They became aggressive jerks to poor numbers 4 and 5. Testosterone did not create new social patterns of aggression; it exaggerated preexisting ones.

			In human studies testosterone didn’t raise baseline activity in the amygdala; it boosted the amygdala’s response and heart-rate reactivity to angry faces (but not to happy or neutral ones). Similarly, testosterone did not make subjects more selfish and uncooperative in an economic game; it made them more punitive when provoked by being treated poorly, enhancing “vengeful reactive aggression.”12

			The context dependency also occurs on the neurobiological level, in that the hormone shortens the refractory period of neurons in the amygdala and amygdaloid targets in the hypothalamus.13 Recall that the refractory period comes in neurons after action potentials. This is when the neuron’s resting potential is hyperpolarized (i.e., when it is more negatively charged than usual), making the neuron less excitable, producing a period of silence after the action potential. Thus, shorter refractory periods mean a higher rate of action potentials. So is testosterone causing action potentials in these neurons? No. It’s causing them to fire at a faster rate if they are stimulated by something else. Similarly, testosterone increases amygdala response to angry faces, but not to other sorts. Thus, if the amygdala is already responding to some realm of social learning, testosterone ups the volume.





A Key Synthesis: The Challenge Hypothesis


			Thus, testosterone’s actions are contingent and amplifying, exacerbating preexisting tendencies toward aggression rather than creating aggression out of thin air. This picture inspired the “challenge hypothesis,” a wonderfully unifying conceptualization of testosterone’s actions.14 As proposed in 1990 by the superb behavioral endocrinologist John Wingfield of the University of California at Davis, and colleagues, the idea is that rising testosterone levels increase aggression only at the time of a challenge. Which is precisely how things work.

			The explains why basal levels of testosterone have little to do with subsequent aggression, and why increases in testosterone due to puberty, sexual stimulation, or the start of mating season don’t increase aggression either.15

			But things are different during challenges.16 Among various primates, testosterone levels rise when a dominance hierarchy first forms or undergoes reorganization. Testosterone rises in humans in both individual and team sports competition, including basketball, wrestling, tennis, rugby, and judo; there’s generally a rise in anticipation of the event and a larger one afterward, especially among winners.* Remarkably, watching your favorite team win raises testosterone levels, showing that the rise is less about muscle activity than about the psychology of dominance, identification, and self-esteem.

			Most important, the rise in testosterone after a challenge makes aggression more likely.17 Think about this. Testosterone levels rise, reaching the brain. If this occurs because someone is challenging you, you head in the direction of aggression. If an identical rise occurs because days are lengthening and mating season is approaching, you decide to fly a thousand miles to your breeding grounds. And if the same occurs because of puberty, you get stupid and giggly around that girl who plays clarinet in the band. The context dependency is remarkable.*18

			The challenge hypothesis has a second part to it. When testosterone rises after a challenge, it doesn’t prompt aggression. Instead it prompts whatever behaviors are needed to maintain status. This changes things enormously.

			Well, maybe not, since maintaining status for, say, male primates consists mostly of aggression or threats of it—from slashing your opponent to giving a “You have no idea who you’re screwing with” stare.19

			And now for some flabbergastingly important research. What happens if defending your status requires you to be nice? This was explored in a study by Christoph Eisenegger and Ernst Fehr of the University of Zurich.20 Participants played the Ultimatum Game (introduced in chapter 2), where you decide how to split money between you and another player. The other person can accept the split or reject it, in which case neither of you gets anything. Prior research had shown that when someone’s offer is rejected, they feel dissed, subordinated, especially if news of that carries into future rounds with other players. In other words, in this scenario status and reputation rest on being fair.

			And what happens when subjects were given testosterone beforehand? People made more generous offers. What the hormone makes you do depends on what counts as being studly. This requires some fancy neuroendocrine wiring that is sensitive to social learning. You couldn’t ask for a finding more counter to testosterone’s reputation.

			The study contained a slick additional finding that further separated testosterone myth from reality. As per usual, subjects got either testosterone or saline, without knowing which. Subjects who believed it was testosterone (independent of whether it actually was) made less generous offers. In other words, testosterone doesn’t necessarily make you behave in a crappy manner, but believing that it does and that you’re drowning in the stuff makes you behave in a crappy manner.

			Additional studies show that testosterone promotes prosociality in the right setting. In one, under circumstances where someone’s sense of pride rides on honesty, testosterone decreased men’s cheating in a game. In another, subjects decided how much of a sum of money they would keep and how much they would publicly contribute to a common pool shared by all the players; testosterone made most subjects more prosocial.21

			What does this mean? Testosterone makes us more willing to do what it takes to attain and maintain status. And the key point is what it takes. Engineer social circumstances right, and boosting testosterone levels during a challenge would make people compete like crazy to do the most acts of random kindness. In our world riddled with male violence, the problem isn’t that testosterone can increase levels of aggression. The problem is the frequency with which we reward aggression.





OXYTOCIN AND VASOPRESSIN: A MARKETING DREAM


			If the point of the preceding section is that testosterone has gotten a bum rap, the point of this one is that oxytocin (and the closely related vasopressin) is coasting in a Teflon presidency. According to lore, oxytocin makes organisms less aggressive, more socially attuned, trusting, and empathic. Individuals treated with oxytocin become more faithful partners and more attentive parents. It makes lab rats more charitable and better listeners, makes fruit flies sing like Joan Baez. Naturally, things are more complicated, and oxytocin has an informative dark side.





Basics


			Oxytocin and vasopressin are chemically similar hormones; the DNA sequences that constitute their genes are similar, and the two genes occur close to each other on the same chromosome. There was a single ancestral gene that, a few hundred million years ago, was accidentally “duplicated” in the genome, and the DNA sequences in the two copies of the gene drifted independently, evolving into two closely related genes (stay tuned for more in chapter 8). This gene duplication occurred as mammals were emerging; other vertebrates have only the ancestral version, called vasotocin, which is structurally between the two separate mammalian hormones.

			For twentieth-century neurobiologists, oxytocin and vasopressin were pretty boring. They were made in hypothalamic neurons that sent axons to the posterior pituitary. There they would be released into circulation, thereby attaining hormone status, and have nothing to do with the brain ever again. Oxytocin stimulated uterine contraction during labor and milk letdown afterward. Vasopressin (aka “antidiuretic hormone”) regulated water retention in the kidneys. And reflecting their similar structures, each also had mild versions of the other one’s effects. End of story.





Neurobiologists Take Notice


			Things became interesting with the discovery that those hypothalamic neurons that made oxytocin and vasopressin also sent projections throughout the brain, including the dopamine-related ventral tegmentum and nucleus accumbens, hippocampus, amygdala, and frontal cortex, all regions with ample levels of receptors for the hormones. Moreover, oxytocin and vasopressin turned out to be synthesized and secreted elsewhere in the brain. These two boring, classical peripheral hormones affected brain function and behavior. They started being called “neuropeptides”—neuroactive messengers with a peptide structure—which is a fancy way of saying they are small proteins (and, to avoid writing “oxytocin and vasopressin” endlessly, I will refer to them as neuropeptides; note though that there are other neuropeptides).

			The initial findings about their behavioral effects made sense.22 Oxytocin prepares the body of a female mammal for birth and lactation; logically, oxytocin also facilitates maternal behavior. The brain boosts oxytocin production when a female rat gives birth, thanks to a hypothalamic circuit with markedly different functions in females and males. Moreover, the ventral tegmentum increases its sensitivity to the neuropeptide by increasing levels of oxytocin receptors. Infuse oxytocin into the brain of a virgin rat, and she’ll act maternally—retrieving, grooming, and licking pups. Block the actions of oxytocin in a rodent mother,*23 and she’ll stop maternal behaviors, including nursing. Oxytocin works in the olfactory system, helping a new mom learn the smell of her offspring. Meanwhile, vasopressin has similar but milder effects.

			Soon other species were heard from. Oxytocin lets sheep learn the smell of their offspring and facilitates female monkeys grooming their offspring. Spray oxytocin up a woman’s nose (a way to get the neuropeptide past the blood-brain barrier and into the brain), and she’ll find babies to look more appealing. Moreover, women with variants of genes that produce higher levels of oxytocin or oxytocin receptors average higher levels of touching their infants and more synchronized gazing with them.

			So oxytocin is central to female mammals nursing, wanting to nurse their child, and remembering which one is their child. Males then got into the act, as vasopressin plays a role in paternal behavior. A female rodent giving birth increases vasopressin and vasopressin receptor levels throughout the body, including the brain, of the nearby father. Among monkeys, experienced fathers have more dendrites in frontal cortical neurons containing vasopressin receptors. Moreover, administering vasopressin enhances paternal behaviors. However, an ethological caveat: this occurs only in species where males are paternal (e.g., prairie voles and marmoset monkeys).24*

			Then, dozens of millions of years ago, some rodent and primate species independently evolved monogamous pair-bonding, along with the neuropeptides central to the process.25 Among marmoset and titi monkeys, which both pair-bond, oxytocin strengthens the bond, increasing a monkey’s preference for huddling with her partner over huddling with a stranger. Then there was a study that is embarrassingly similar to stereotypical human couples. Among pair-bonding tamarin monkeys, lots of grooming and physical contact predicted high oxytocin levels in female members of a pair. What predicted high levels of oxytocin in males? Lots of sex.

			Beautiful, pioneering work by Thomas Insel of the National Institute of Mental Health, Larry Young of Emory University, and Sue Carter of the University of Illinois has made a species of vole arguably the most celebrated rodent on earth.26 Most voles (e.g., montane voles) are polygamous. In contrast, prairie voles, in a salute to Garrison Keillor, form monogamous mating pairs for life. Naturally, this isn’t quite the case—while they are “social pair-bonders” with their permanent relationships, they’re not quite perfect “sexual pair-bonders,” as males might mess around on the side. Nonetheless, prairie voles pair-bond more than other voles, prompting Insel, Young, and Carter to figure out why.

			First finding: sex releases oxytocin and vasopressin in the nucleus accumbens of female and male voles, respectively. Obvious theory: prairie voles release more of the stuff during sex than do polygamous voles, causing a more rewarding buzz, encouraging the individuals to stick with their partner. But prairie voles don’t release more neuropeptides than montane voles. Instead, prairie voles have more of the pertinent receptors in the nucleus accumbens than do polygamous voles.* Moreover, male prairie voles with a variant of the vasopressin receptor gene that produced more receptors in the nucleus accumbens were stronger pair-bonders. Then the scientists conducted two tour de force studies. First they engineered the brains of male mice to express the prairie vole version of the vasopressin receptor in their brains, and they groomed and huddled more with familiar females (but not with strangers). Then the scientists engineered the brains of male montane voles to have more vasopressin receptors in the nucleus accumbens; the males became more socially affiliative with individual females.*

			What about versions of vasopressin receptor genes in other species? When compared with chimps, bonobos have a variant associated with more receptor expression and far more social bonding between females and males (although, in contrast to prairie voles, bonobos are anything but monogamous).27

			How about humans? This is tough to study, because you can’t measure these neuropeptides in tiny brain regions in humans and instead have to examine levels in the circulation, a fairly indirect measure.

			Nevertheless, these neuropeptides appear to play a role in human pair-bonding.28 For starters, circulating oxytocin levels are elevated in couples when they’ve first hooked up. Furthermore, the higher the levels, the more physical affection, the more behaviors are synchronized, the more long-lasting the relationship, and the happier interviewers rate couples to be.

			Even more interesting were studies where oxytocin (or a control spray) was administered intranasally. In one fun study, couples had to discuss one of their conflicts; oxytocin up their noses, and they’d be rated as communicating more positively and would secrete less stress hormones. Another study suggests that oxytocin unconsciously strengthens the pair-bond. Heterosexual male volunteers, with or without an oxytocin spritz, interacted with an attractive female researcher, doing some nonsense task. Among men in stable relationships, oxytocin increased their distance from the woman an average of four to six inches. Single guys, no effect. (Why didn’t oxytocin make them stand closer? The researchers indicated that they were already about as close as one could get away with.) If the experimenter was male, no effect. Moreover, oxytocin caused males in relationships to spend less time looking at pictures of attractive women. Importantly, oxytocin didn’t make men rate these women as less attractive; they were simply less interested.29

			Thus, oxytocin and vasopressin facilitate bonding between parent and child and between couples.* Now for something truly charming that evolution has cooked up recently. Sometime in the last fifty thousand years (i.e., less than 0.1 percent of the time that oxytocin has existed), the brains of humans and domesticated wolves evolved a new response to oxytocin: when a dog and its owner (but not a stranger) interact, they secrete oxytocin.30 The more of that time is spent gazing at each other, the bigger the rise. Give dogs oxytocin, and they gaze longer at their humans . . . which raises the humans’ oxytocin levels. So a hormone that evolved for mother-infant bonding plays a role in this bizarre, unprecedented form of bonding between species.

			In line with its effects on bonding, oxytocin inhibits the central amygdala, suppresses fear and anxiety, and activates the “calm, vegetative” parasympathetic nervous system. Moreover, people with an oxytocin receptor gene variant associated with more sensitive parenting also have less of a cardiovascular startle response. In the words of Sue Carter, exposure to oxytocin is “a physiological metaphor for safety.” Furthermore, oxytocin reduces aggression in rodents, and mice whose oxytocin system was silenced (by deleting the gene for oxytocin or its receptor) were abnormally aggressive.31

			Other studies showed that people rate faces as more trustworthy, and are more trusting in economic games, when given oxytocin (oxytocin had no effect when someone thought they were playing with a computer, showing that this was about social behavior).32 This increased trust was interesting. Normally, if the other player does something duplicitous in the game, subjects are less trusting in subsequent rounds; in contrast, oxytocin-treated investors didn’t modify their behavior in this way. Stated scientifically, “oxytocin inoculated betrayal aversion among investors”; stated caustically, oxytocin makes people irrational dupes; stated more angelically, oxytocin makes people turn the other cheek.

			More prosocial effects of oxytocin emerged. It made people better at detecting happy (versus angry, fearful, or neutral) faces or words with positive (versus negative) social connotations, when these were displayed briefly. Moreover, oxytocin made people more charitable. People with the version of the oxytocin receptor gene associated with more sensitive parenting were rated by observers as more prosocial (when discussing a time of personal suffering), as well as more sensitive to social approval. And the neuropeptide made people more responsive to social reinforcement, enhancing performance in a task where correct or wrong answers elicited a smile or frown, respectively (while having no effect when right and wrong answers elicited different-colored lights).33

			So oxytocin elicits prosocial behavior, and oxytocin is released when we experience prosocial behavior (being trusted in a game, receiving a warm touch, and so on). In other words, a warm and fuzzy positive feedback loop.34

			Obviously, oxytocin and vasopressin are the grooviest hormones in the universe.* Pour them into the water supply, and people will be more charitable, trusting, and empathic. We’d be better parents and would make love, not war (mostly platonic love, though, since people in relationships would give wide berths to everyone else). Best of all, we’d buy all sorts of useless crap, trusting the promotional banners in stores once oxytocin starts spraying out of the ventilation system.

			Okay, time to settle down a bit.





Prosociality Versus Sociality


			Are oxytocin and vasopressin about prosociality or social competence? Do these hormones make us see happy faces everywhere or become more interested in gathering accurate social information about faces? The latter isn’t necessarily prosocial; after all, accurate information about someone’s emotions makes them easier to manipulate.

			The Groovy Neuropeptide School supports the idea of ubiquitous prosociality.35 But the neuropeptides also foster social interest and competence. They make people look at eyes longer, increasing accuracy in reading emotions. Moreover, oxytocin enhances activity in the temporoparietal juncture (that region involved in Theory of Mind) when people do a social-recognition task. The hormone increases the accuracy of assessments of other people’s thoughts, with a gender twist—women improve at detecting kinship relations, while men improve at detecting dominance relations. In addition, oxytocin increases accuracy in remembering faces and their emotional expressions, and people with the “sensitive parenting” oxytocin receptor gene variant are particularly adept at assessing emotions. Similarly, the hormones facilitate rodents’ learning of an individual’s smell, but not nonsocial odors.

			Neuroimaging research shows that these neuropeptides are about social competence, as well as prosociality.36 For example, variants of a gene related to oxytocin signaling* are associated with differing degrees of activation of the fusiform face area when looking at faces.

			Findings like these suggest that abnormalities in these neuropeptides increase the risk of disorders of impaired sociality, namely autism spectrum disorders (ASD) (strikingly, people with ASD show blunted fusiform responses to faces).37 Remarkably, ASD has been linked to gene variants related to oxytocin and vasopressin, to nongenetic mechanisms for silencing the oxytocin receptor gene, and to lower levels of the receptor itself. Moreover, the neuropeptides improve social skills in some individuals with ASD—e.g., enhancing eye contact.

			Thus, sometimes oxytocin and vasopressin make us more prosocial, but sometimes they make us more avid and accurate social information gatherers. Nonetheless, there is a happy-face bias, since accuracy is most enhanced for positive emotions.38

			Time for more complications.





Contingent Effects of Oxytocin and Vasopressin


			Recall testosterone’s contingent effects (e.g., making a monkey more aggressive, but only toward individuals he already dominates). Naturally, these neuropeptides’ effects are also contingent.39

			One factor already mentioned is gender: oxytocin enhances different aspects of social competence in women and men. Moreover, oxytocin’s calming effects on the amygdala are more consistent in men than in women. Predictably, neurons that make these neuropeptides are regulated by both estrogen and testosterone.40

			As a really interesting contingent effect, oxytocin enhances charitability—but only in people who are already so. This mirrors testosterone’s only raising aggression in aggression-prone people. Hormones rarely act outside the context of the individual and his or her environment.41

			Finally, a fascinating study shows cultural contingencies in oxytocin’s actions.42 During stress, Americans seek emotional support (e.g., telling a friend about their problem) more readily than do East Asians. In one study oxytocin receptor gene variants were identified in American and Korean subjects. Under unstressful circumstances, neither cultural background nor receptor variant affected support-seeking behavior. During stressful periods, support seeking rose among subjects with the receptor variant associated with enhanced sensitivity to social feedback and approval—but only among the Americans (including Korean Americans). What does oxytocin do to support-seeking behavior? It depends on whether you’re stressed. And on the genetic variant of your oxytocin receptor. And on your culture. More to come in chapters 8 and 9.





And the Dark Side of These Neuropeptides


			As we saw, oxytocin (and vasopressin) decreases aggression in rodent females. Except for aggression in defense of one’s pups, which the neuropeptide increases via effects in the central amygdala (with its involvement in instinctual fear).43

			This readily fits with these neuropeptides enhancing maternalism, including snarling don’t-get-one-step-closer maternalism. Similarly, vasopressin enhances aggression in paternal prairie vole males. This finding comes with a familiar additional contingency. The more aggressive the male prairie vole, the less that aggression decreases after blocking of his vasopressin system—just as in the case of testosterone, with increased experience, aggression is maintained by social learning rather than by a hormone/neuropeptide. Moreover, vasopressin increases aggression most in male rodents who are already aggressive—yet another biological effect depending on individual and social context.44

			And now to really upend our view of these feel-good neuropeptides. For starters, back to oxytocin enhancing trust and cooperation in an economic game—but not if the other player is anonymous and in a different room. When playing against strangers, oxytocin decreases cooperation, enhances envy when luck is bad, and enhances gloating when it’s good.45

			Finally, beautiful studies by Carsten de Dreu of the University of Amsterdam showed just how unwarm and unfuzzy oxytocin can be.46 In the first, male subjects formed two teams; each subject chose how much of his money to put into a pot shared with teammates. As usual, oxytocin increased such generosity. Then participants played the Prisoner’s Dilemma with someone from the other team.* When financial stakes were high, making subjects more motivated, oxytocin made them more likely to preemptively stab the other player in the back. Thus, oxytocin makes you more prosocial to people like you (i.e., your teammates) but spontaneously lousy to Others who are a threat. As emphasized by De Dreu, perhaps oxytocin evolved to enhance social competence to make us better at identifying who is an Us.

			In De Dreu’s second study, Dutch student subjects took the Implicit Association Test of unconscious bias.* And oxytocin exaggerated biases against two out-groups, namely Middle Easterners and Germans.47

			Then came the study’s truly revealing second part. Subjects had to decide whether it was okay to kill one person in order to save five. In the scenario the potential sacrificial lamb’s name was either stereotypically Dutch (Dirk or Peter), German (Markus or Helmut), or Middle Eastern (Ahmed or Youssef); the five people in danger were unnamed. Remarkably, oxytocin made subjects less likely to sacrifice good ol’ Dirk or Peter, rather than Helmut or Ahmed.

			Oxytocin, the luv hormone, makes us more prosocial to Us and worse to everyone else. That’s not generic prosociality. That’s ethnocentrism and xenophobia. In other words, the actions of these neuropeptides depend dramatically on context—who you are, your environment, and who that person is. As we will see in chapter 8, the same applies to the regulation of genes relevant to these neuropeptides.





THE ENDOCRINOLOGY OF AGGRESSION IN FEMALES


			Help!

			This topic confuses me. Here’s why:


This is a domain where the ratios of two hormones can matter more than their absolute levels, where the brain responds the same way to (a) two units of estrogen plus one unit of progesterone and (b) two gazillion units of estrogen plus one gazillion units of progesterone. This requires some complex neurobiology.

				Hormone levels are extremely dynamic, with hundredfold changes in some within hours—no male’s testes ever had to navigate the endocrinology of ovulation or childbirth. Among other things, re-creating such endocrine fluctuations in lab animals is tough.

				There’s dizzying variability across species. Some breed year-round, others only in particular seasons; nursing inhibits ovulation in some, stimulates it in others.

				Progesterone rarely works in the brain as itself. Instead it’s usually converted into various “neurosteroids” with differing actions in different brain regions. And “estrogen” describes a soup of related hormones, none of which work identically.

				Finally, one must debunk the myth that females are always nice and affiliative (unless, of course, they’re aggressively protecting their babies, which is cool and inspirational).





Maternal Aggression


			Levels of aggression rise in rodents during pregnancy, peaking around parturition.*48 Appropriately, the highest levels occur in species and breeds with the greatest threat of infanticide.49

			During late pregnancy, estrogen and progesterone increase maternal aggression by increasing oxytocin release in certain brain regions, bringing us back to oxytocin promoting maternal aggression.50

			Two complications illustrate some endocrine principles.* Estrogen contributes to maternal aggression. But estrogen can also reduce aggression and enhance empathy and emotional recognition. It turns out there are two different types of receptors for estrogen in the brain, mediating these opposing effects and with their levels independently regulated. Thus, same hormone, same levels, different outcome if the brain is set up to respond differently.51

			The other complication: As noted, progesterone, working with estrogen, promotes maternal aggression. However, on its own it decreases aggression and anxiety. Same hormone, same levels, diametrically opposite outcomes depending on the presence of a second hormone.52

			Progesterone decreases anxiety through a thoroughly cool route. When it enters neurons, it is converted to another steroid;* this binds to GABA receptors, making them more sensitive to the inhibitory effects of GABA, thereby calming the brain. Thus, direct cross-talk between hormones and neurotransmitters.





Bare-Knuckled Female Aggression


			The traditional view is that other than maternal aggression, any female-female competition is passive, covert. As noted by the pioneering primatologist Sarah Blaffer Hrdy of the University of California at Davis, before the 1970s hardly anyone even researched competition among females.53

			Nevertheless, there is plenty of female-female aggression. This is often dismissed with a psychopathology argument—if, say, a female chimp is murderous, it’s because, well, she’s crazy. Or female aggression is viewed as endocrine “spillover.”54 Females synthesize small amounts of androgens in the adrenals and ovaries; in the spillover view, the process of synthesizing “real” female steroid hormones is somewhat sloppy, and some androgenic steroids are inadvertently produced; since evolution is lazy and hasn’t eliminated androgen receptors in female brains, there’s some androgen-driven aggression.

			These views are wrong for a number of reasons.

			Female brains don’t contain androgen receptors simply because they come from a similar blueprint as male brains. Instead, androgen receptors are distributed differently in the brains of females and males, with higher levels in some regions in females. There has been active selection for androgen effects in females.55

			Even more important, female aggression makes sense—females can increase their evolutionary fitness with strategic, instrumental aggression.56 Depending on the species, females compete aggressively for resources (e.g., food or nesting places), harass lower-ranking reproductive competitors into stress-induced infertility, or kill each other’s infants (as in chimps). And in the bird and (rare) primate species where males are actually paternal, females compete aggressively for such princes.

			Remarkably, there are even species—primates (bonobos, lemurs, marmosets, and tamarins), rock hyraxes, and rodents (the California mouse, Syrian golden hamsters, and naked mole rats)—where females are socially dominant and more aggressive (and often more muscular) than males.57 The most celebrated example of a sex-reversal system is the spotted hyena, shown by Laurence Frank of UC Berkeley and colleagues.* Among typical social carnivores (e.g., lions), females do most of the hunting, after which males show up and eat first. Among hyenas it’s the socially subordinate males who hunt; they are then booted off the kill by females so that the kids eat first. Get this: In many mammals erections are a sign of dominance, of a guy strutting his stuff. Among hyenas it’s reversed—when a female is about to terrorize a male, he gets an erection. (“Please don’t hurt me! Look, I’m just a nonthreatening male.”)*

			What explains female competitive aggression (in sex-reversal species or “normal” animals)? Those androgens in females are obvious suspects, and in some sex-reversal species females have androgen levels that equal or even trump those in males.58 Among hyenas, where this occurs, spending fetal life awash in Mom’s plentiful androgens produces a “pseudo-hermaphrodite”*—female hyenas have a fake scrotal sack, no external vagina, and a clitoris that is as large as a penis and gets erect as well.* Moreover, some of the sex differences in the brain seen in most mammals don’t occur in hyenas or naked mole rats, reflecting their fetal androgenization.

			This suggests that elevated female aggression in sex-reversal species arises from the elevated androgen exposure and, by extension, that the diminished aggression among females of other species comes from their low androgen levels.

			But complications emerge. For starters, there are species (e.g., Brazilian guinea pigs) where females have high androgen levels but aren’t particularly aggressive or dominant toward males. Conversely, there are sex-reversal bird species without elevated androgen levels in females. Moreover, as with males, individual levels of androgens in females, whether in conventional or sex-reversal species, do not predict individual levels of aggression. And most broadly, androgen levels don’t tend to rise around periods of female aggression.59

			This makes sense. Female aggression is mostly related to reproduction and infant survival—maternal aggression, obviously, but also female competition for mates, nesting places, and much-needed food during pregnancy or lactation. Androgens disrupt aspects of reproduction and maternal behavior in females. As emphasized by Hrdy, females must balance the proaggression advantages of androgens with their antireproductive disadvantages. Ideally, then, androgens in females should affect the “aggression” parts of the brain but not the “reproduction/maternalism” parts. Which is precisely what has evolved, as it turns out.*60





Perimenstrual Aggression and Irritability


			Inevitably we turn to premenstrual syndrome (PMS)*—the symptoms of negative mood and irritability that come around the time of menstruation (along with the bloating of water retention, cramps, acne . . .). There’s a lot of baggage and misconceptions about PMS (along with PMDD—premenstrual dysphoric disorder, where symptoms are severe enough to impair normal functioning; it effects 2 to 5 percent of women).61

			The topic is mired in two controversies—what causes PMS/PMDD, and how is it relevant to aggression? The first is a doozy. Is PMS/PMDD a biological disease or a social construct?

			In the extreme “It’s just a social construct” school, PMS is entirely culture specific, meaning it occurs only in certain societies. Margaret Mead started this by asserting in 1928 in Coming of Age in Samoa that Samoan women don’t have mood or behavioral changes when menstruating. Since the Samoans were enshrined by Mead as the coolest, most peaceful and sexually free primates east of bonobos, this started trendy anthropological claims that women in other hip, minimal-clothing cultures had no PMS either.* And naturally, cultures with rampant PMS (e.g., American primates) were anti-Samoans, where symptoms arose from mistreatment and sexual repression of women. This view even had room for a socioeconomic critique, with howlers like “PMS [is] a mode for the expression of women’s anger resulting from her oppressed position in American capitalist society.”*62

			An offshoot of this view is the idea that in such repressive societies, it’s the most repressed women who have the worst PMS. Thus, depending on the paper, women with bad PMS must be anxious, depressed, neurotic, hypochondriacal, sexually repressed, toadies of religious repression, or more compliant with gender stereotypes and must respond to challenge by withdrawing, rather than by tackling things head on. In other words, not a single cool Samoan among them.

			Fortunately, this has mostly subsided. Numerous studies show normal shifts in the brain and behavior over the course of the reproductive cycle, with as many behavioral correlates of ovulation as of menses.*63 PMS, then, is simply a disruptively extreme version of those shifts. While PMS is real, symptoms vary by culture. For example, perimenstrual women in China report less negative affect than do Western women (raising the issue of whether they experience less and/or report less). Given the more than one hundred symptoms linked to PMS, it’s not surprising if different symptoms predominate in different populations.

			As strong evidence that perimenstrual mood and behavioral changes are biological, they occur in other primates.64 Both female baboons and female vervet monkeys become more aggressive and less social before their menses (without, to my knowledge, having issues with American capitalism). Interestingly, the baboon study showed increased aggressiveness only in dominant females; presumably, subordinate females simply couldn’t express increased aggressiveness.

			All these findings suggest that the mood and behavioral shifts are biologically based. What is a social construct is medicalizing and pathologizing these shifts as “symptoms,” a “syndrome,” or “disorder.”

			Thus, what is the underlying biology? A leading theory points to the plunging levels of progesterone as menses approaches and thus the loss of its anxiolytic and sedating effects. In this view, PMS arises from too extreme of a decline. However, there’s not much actual support for this idea.

			Another theory, backed by some evidence, concerns the hormone beta-endorphin, famed for being secreted during exercise and inducing a gauzy, euphoric “runner’s high.” In this model PMS is about abnormally low levels of beta-endorphin. There are plenty more theories but very little certainty.

			Now for the question of how much PMS is associated with aggression. In the 1960s, studies by Katharina Dalton, who coined the term “premenstrual syndrome” in 1953, reported that female criminals committed their crimes disproportionately during their perimenstrual period (which may tell less about committing a crime than about getting caught).65 Other studies of a boarding school showed a disproportionate share of “bad marks” for behavioral offenses going to perimenstrual students. However, the prison studies didn’t distinguish between violent and nonviolent crimes, and the school study didn’t distinguish between aggressive acts and infractions like tardiness. Collectively, there is little evidence that women tend toward aggression around their menses or that violent women are more likely to have committed their acts around their menses.

			Nevertheless, defense pleas of PMS-related “diminished responsibility” have been successful in courtrooms.66 A notable 1980 case concerned Sandie Craddock, who murdered a coworker and had a long rap sheet with more than thirty convictions for theft, arson, and assault. Incongruously but fortuitously, Craddock was a meticulous diarist, having years of records of not just when she was having her period but also when she was out about town on a criminal spree. Her criminal acts and times of menses matched so closely that she was put on probation plus progesterone treatment. And making the case stranger, Craddock’s doctor later reduced her progesterone dose; by her next period, she had been arrested for attempting to knife someone. Probation again, plus a wee bit more progesterone.

			These studies suggest that a small number of women do show perimenstrual behavior that qualifies as psychotic and should be mitigating in a courtroom.* Nevertheless, normal garden-variety perimenstrual shifts in mood and behavior are not particularly associated with increased aggression.





STRESS AND IMPRUDENT BRAIN FUNCTION


			The time before some of our most important, consequential behaviors can be filled with stress. Which is too bad, since stress influences the decisions we make, rarely for the better.





The Basic Dichotomy of the Acute and the Chronic Stress Response


			We begin with a long-forgotten term from ninth-grade biology. Remember “homeostasis”? It means having an ideal body temperature, heart rate, glucose level, and so on. A “stressor” is anything that disrupts homeostatic balance—say, being chased by a lion if you’re a zebra, or chasing after a zebra if you’re a hungry lion. The stress response is the array of neural and endocrine changes that occur in that zebra or lion, designed to get them through that crisis and reestablish homeostasis.*67

			Critical events in the brain mediate the start of the stress response. (Warning: the next two paragraphs are technical and not essential.) The sight of the lion activates the amygdala; amygdaloid neurons stimulate brain-stem neurons, which then inhibit the parasympathetic nervous system and mobilize the sympathetic nervous system, releasing epinephrine and norepinephrine throughout the body.

			The amygdala also mediates the other main branch of the stress response, activating the paraventricular nucleus (PVN) in the hypothalamus. And the PVN sends projections to the base of the hypothalamus, where it secretes corticotropin-releasing hormone (CRH); this triggers the pituitary to release adrenocorticotropic hormone (ACTH), which stimulates glucocorticoid secretion from the adrenals.

			Glucocorticoids plus the sympathetic nervous system enable an organism to survive a physical stressor by activating the classical “fight or flight” response. Whether you are that zebra or that lion, you’ll need energy for your muscles, and the stress response rapidly mobilizes energy into circulation from storage sites in your body. Furthermore, heart rate and blood pressure increase, delivering that circulating energy to exercising muscles faster. Moreover, during stress, long-term building projects—growth, tissue repair, and reproduction—are postponed until after the crisis; after all, if a lion is chasing you, you have better things to do with your energy than, say, thicken your uterine walls. Beta-endorphin is secreted, the immune system is stimulated, and blood clotting is enhanced, all useful following painful injury. Moreover, glucocorticoids reach the brain, rapidly enhancing aspects of cognition and sensory acuity.

			This is wonderfully adaptive for the zebra or lion; try sprinting without epinephrine and glucocorticoids, and you’ll soon be dead. Reflecting its importance, this basic stress response is ancient physiology, found in mammals, birds, fish, and reptiles.

			What is not ancient is how stress works in smart, socially sophisticated, recently evolved primates. For primates the definition of a stressor expands beyond merely a physical challenge to homeostasis. In addition, it includes thinking you’re going to be thrown out of homeostasis. An anticipatory stress response is adaptive if there really is a physical challenge coming. However, if you’re constantly but incorrectly convinced that you’re about to be thrown out of balance, you’re being an anxious, neurotic, paranoid, or hostile primate who is psychologically stressed. And the stress response did not evolve for dealing with this recent mammalian innovation.

			Mobilizing energy while sprinting for your life helps save you. Do the same thing chronically because of a stressful thirty-year mortgage, and you’re at risk for various metabolic problems, including adult-onset diabetes. Likewise with blood pressure: increase it to sprint across the savanna—good thing. Increase it because of chronic psychological stress, and you’ve got stress-induced hypertension. Chronically impair growth and tissue repair, and you’ll pay the price. Ditto for chronically inhibiting reproductive physiology; you’ll disrupt ovulatory cycles in women and cause plummeting erections and testosterone levels in men. Finally, while the acute stress response involves enhanced immunity, chronic stress suppresses immunity, increasing vulnerability to some infectious diseases.*

			We have a dichotomy—if you’re stressed like a normal mammal in an acute physical crisis, the stress response is lifesaving. But if instead you chronically activate the stress response for reasons of psychological stress, your health suffers. It is a rare human who sickens because they can’t activate the stress response when it is needed. Instead, we get sick from activating the stress response too often, too long, and for purely psychological reasons. Crucially, the beneficial effects of the stress response for sprinting zebras and lions play out over the course of seconds to minutes. But once you take stress to the time course of this chapter (henceforth referred to as “sustained” stress), you’ll be dealing with adverse consequences. Including some unwelcome effects on the behaviors that fill this book.





A Brief Digression: Stress That We Love


			Either running from a lion or dealing with years of traffic jams is a drag. Which contrasts with stress that we love.68

			We love stress that is mild and transient and occurs in a benevolent context. The stressful menace of a roller-coaster ride is that it will make us queasy, not that it will decapitate us; it lasts for three minutes, not three days. We love that kind of stress, clamor for it, pay to experience it. What do we call that optimal amount of stress? Being engaged, engrossed, and challenged. Being stimulated. Playing. The core of psychological stress is loss of control and predictability. But in benevolent settings we happily relinquish control and predictability to be challenged by the unexpected—a dip in the roller-coaster tracks, a plot twist, a difficult line drive heading our way, an opponent’s unexpected chess move. Surprise me—this is fun.

			This brings up a key concept, namely the inverted U. The complete absence of stress is aversively boring. Moderate, transient stress is wonderful—various aspects of brain function are enhanced; glucocorticoid levels in that range enhance dopamine release; rats work at pressing levers in order to be infused with just the right amount of glucocorticoids. And as stress becomes more severe and prolonged, those good effects disappear (with, of course, dramatic individual differences as to where the transition from stress as stimulatory to overstimulatory occurs; one person’s nightmare is another’s hobby).*

			 				 				Visit bit.ly/2ngw6bq for a larger version of this graph.



			We love the right amount of stress, would wither without it. But back now to sustained stress and the right side of the inverted U.





Sustained Stress and the Neurobiology of Fear


			For starters, sustained stress makes people implicitly (i.e., not consciously) look more at angry faces. Moreover, during stress, that sensory shortcut from the thalamus to the amygdala becomes more active, with more excitable synapses; we know the resulting trade-off between speed and accuracy. Compounding things further, glucocorticoids decrease activation of the (cognitive) medial PFC during processing of emotional faces. Collectively, stress or glucocorticoid administration decreases accuracy when rapidly assessing emotions of faces.69

			Meanwhile, during stress things aren’t going great in the amygdala. The region is highly sensitive to glucocorticoids, with lots of glucocorticoid receptors; stress and glucocorticoids increase excitability of amygdaloid neurons,* particularly in the basolateral amygdala (the BLA), with its role in learning fear. Thus, this is another contingent hormone action—glucocorticoids don’t cause action potentials in amygdaloid neurons, don’t invent excitation. Instead they amplify preexisting excitation. Stress and glucocorticoids also increase levels of CRH in the BLA, and of a growth factor that builds new dendrites and synapses (brain-derived neurotrophic factor, or BDNF).70

			Recall from chapter 2 how during a fearful situation the amygdala recruits the hippocampus into remembering contextual information about the event (e.g., the amygdala remembers the thief’s knife, whereas the hippocampus remembers where the robbery occurred).71 Stress strengthens this recruitment, making the hippocampus a temporary fear-laden suburb of the amygdala. Thanks to these glucocorticoid actions in the amygdala,* stress makes it easier to learn a fear association and to consolidate it into a long-term memory.

			This sets us up for a positive feedback loop. As noted, with the onset of stress, the amygdala indirectly activates the glucocorticoid stress response. And in turn glucocorticoids increase amygdala excitability.

			Stress also makes it harder to unlearn fear, to “extinguish” a conditioned fear association. This involves the prefrontal cortex, which causes fear extinction by inhibiting the BLA (as covered in chapter 2); stress weakens the PFC’s hold over the amygdala.72

			Recall what fear extinction is about. You’ve learned to fearfully associate a light with a shock, but today the light keeps coming on with no shock. Extinction is not passively forgetting that light equals shock. It is the BLA actively learning that light no longer equals shock. Thus stress facilitates learning fear associations but impairs learning fear extinction.





Sustained Stress, Executive Function, and Judgment


			Stress compromises other aspects of frontal cortical function. Working memory is disrupted; in one study, prolonged administration of high glucocorticoid levels to healthy subjects impaired working memory into the range seen after frontal cortical damage. Glucocorticoids accomplish this by enhancing norepinephrine signaling in the PFC so much that, instead of causing aroused focus, it induces chicken-with-its-head-cut-off cognitive tumult, and by enhancing disruptive signaling from the amygdala to the PFC. Stress also desynchronizes activation in different frontocortical regions, which impairs the ability to shift attention between tasks.73

			These stress effects on frontal function also make us perseverative—in a rut, set in our ways, running on automatic, being habitual. We all know this—what do we typically do during a stressful time when something isn’t working? The same thing again, many more times, faster and more intensely—it becomes unimaginable that the usual isn’t working. This is precisely where the frontal cortex makes you do the harder but more correct thing—recognize that it’s time for a change. Except for a stressed frontal cortex, or one that’s been exposed to a lot of glucocorticoids. In rats, monkeys, and humans, stress weakens frontal connections with the hippocampus—essential for incorporating the new information that should prompt shifting to a new strategy—while strengthening frontal connections with more habitual brain circuits.74

			Finally, the decreased frontal function and increased amygdaloid function during stress alter risk-taking behavior. For example, the stress of sleep deprivation or of public speaking, or the administration of high glucocorticoid levels, shifts people from protecting against losses to seeking bigger gains when gambling. This involves an interesting gender difference—in general, major stressors make people of both genders more risk taking. But moderate stressors bias men toward, and women away from, risk taking. In the absence of stress, men tend toward more risk taking than women; thus, once again, hormones enhance a preexisting tendency.75

			Whether one becomes irrationally risk taking (failing to shift strategy in response to a declining reward rate) or risk averse (failing to respond to the opposite), one is incorporating new information poorly. Stated most broadly, sustained stress impairs risk assessment.76





Sustained Stress and Pro- and Antisociality


			During sustained stress, the amygdala processes emotional sensory information more rapidly and less accurately, dominates hippocampal function, and disrupts frontocortical function; we’re more fearful, our thinking is muddled, and we assess risks poorly and act impulsively out of habit, rather than incorporating new data.77 This is a prescription for rapid, reactive aggression; stress and acute administration of glucocorticoids increase such aggression in both rodents and humans. We have two familiar qualifications: (a) rather than creating aggression, stress and glucocorticoids increase sensitivity to social triggers of aggression; (b) this occurs most readily in individuals already predisposed toward aggression. As we will see in the next chapter, stress over the course of weeks to months produces a less nuanced picture.

			There’s an additional depressing reason why stress fosters aggression—because it reduces stress. Shock a rat and its glucocorticoid levels and blood pressure rise; with enough shocks, it’s at risk for a “stress” ulcer. Various things can buffer the rat during shocks—running on a running wheel, eating, gnawing on wood in frustration. But a particularly effective buffer is for the rat to bite another rat. Stress-induced (aka frustration-induced) displacement aggression is ubiquitous in various species. Among baboons, for example, nearly half of aggression is this type—a high-ranking male loses a fight and chases a subadult male, who promptly bites a female, who then lunges at an infant. My research shows that within the same dominance rank, the more a baboon tends to displace aggression after losing a fight, the lower his glucocorticoid levels.78

			Humans excel at stress-induced displacement aggression—consider how economic downturns increase rates of spousal and child abuse. Or consider a study of family violence and pro football. If the local team unexpectedly loses, spousal/partner violence by men increases 10 percent soon afterward (with no increase when the team won or was expected to lose). And as the stakes get higher, the pattern is exacerbated: a 13 percent increase after upsets when the team was in playoff contention, a 20 percent increase when the upset is by a rival.79

			Little is known concerning the neurobiology of displacement aggression blunting the stress response. I’d guess that lashing out activates dopaminergic reward pathways, a surefire way to inhibit CRH release.*80 Far too often, giving an ulcer helps avoid getting one.

			More bad news: stress biases us toward selfishness. In one study subjects answered questions about moral decision-making scenarios after either a social stressor or a neutral situation.* Some scenarios were of low emotional intensity (“In the supermarket you wait at the meat counter and an elderly man pushes to the front. Would you complain?”), others high intensity (“You meet the love of your life, but you are married and have children. Would you leave your family?”). Stress made people give more egoistic answers about emotionally intense moral decisions (but not milder ones); the more glucocorticoid levels rose, the more egoistic the answers. Moreover, in the same paradigm, stress lessened how altruistic people claimed they’d be concerning personal (but not impersonal) moral decisions.81

			We have another contingent endocrine effect: stress makes people more egoistic, but only in the most emotionally intense and personal circumstances.* This resembles another circumstance of poor frontal function—recall from chapter 2 how individuals with frontal cortical damage make reasonable judgments about someone else’s issues, but the more personal and emotionally potent the issue, the more they are impaired.

			Feeling better by abusing someone innocent, or thinking more about your own needs, is not compatible with feeling empathy. Does stress decrease empathy? Seemingly yes, in both mice and humans. A remarkable 2006 paper in Science by Jeffrey Mogil of McGill University showed the rudiments of mouse empathy—a mouse’s pain threshold is lowered when it is near another mouse in pain, but only if the other mouse is its cagemate.82

			This prompted a follow-up study that I did with Mogil’s group involving the same paradigm. The presence of a strange mouse triggers a stress response. But when glucocorticoid secretion is temporarily blocked, mice show the same “pain empathy” for a strange mouse as for a cagemate. In other words, to personify mice, glucocorticoids narrow who counts as enough of an “Us” to evoke empathy. Likewise in humans—pain empathy was not evoked for a stranger unless glucocorticoid secretion was blocked (either after administration of a short-acting drug or after the subject and stranger interacted socially). Recall from chapter 2 the involvement of the anterior cingulate cortex in pain empathy. I bet that glucocorticoids do some disabling, atrophying things to neurons there.

			Thus, sustained stress has some pretty unappealing behavioral effects. Nonetheless there are circumstances where stress brings out the magnificent best in some people. Work by Shelley Taylor of UCLA shows that “fight or flight” is the typical response to stress in males, and naturally, the stress literature is predominantly studies of males by males.83 Things often differ in females. Showing that she can match the good old boys when it comes to snappy sound bites, Taylor framed the female stress response as being more about “tend and befriend”—caring for your young and seeking social affiliation. This fits with striking sex differences in stress management styles, and tend-and-befriend most likely reflects the female stress response involving a stronger component of oxytocin secretion.

			Naturally, things are subtler than “male = fight/flight and female = tend/befriend.” There are frequent counterexamples to each; stress elicits prosociality in more males than just pair-bonded male marmosets, and we saw that females are plenty capable of aggression. Then there’s Mahatma Gandhi and Sarah Palin.* Why are some people exceptions to these gender stereotypes? That’s part of what the rest of this book is about.

			Stress can disrupt cognition, impulse control, emotional regulation, decision making, empathy, and prosociality. One final point. Recall from chapter 2 how the frontal cortex making you do the harder thing when it’s the right thing is value free—“right thing” is purely instrumental. Same with stress. Its effects on decision making are “adverse” only in a neurobiological sense. During a stressful crisis, an EMT may become perseverative, making her ineffectual at saving lives. A bad thing. During a stressful crisis, a sociopathic warlord may become perseverative, making him ineffectual at ethnically cleansing a village. Not a bad thing.





SOME IMPORTANT DEBUNKING: ALCOHOL


			No review of the biological events in the minutes to hours prior to a behavior can omit alcohol. As everyone knows, alcohol lessens inhibitions, making people more aggressive. Wrong, and in a familiar way—alcohol only evokes aggression only in (a) individuals prone to aggression (for example, mice with lower levels of serotonin signaling in the frontal cortex and men with the oxytocin receptor gene variant less responsive to oxytocin are preferentially made aggressive by alcohol) and (b) those who believe that alcohol makes you more aggressive, once more showing the power of social learning to shape biology.84 Alcohol works differently in everyone else—for example, a drunken stupor has caused many a quickie Vegas wedding that doesn’t seem like a great idea with the next day’s sunrise.






SUMMARY AND SOME CONCLUSIONS


			 				Hormones are great; they run circles around neurotransmitters, in terms of the versatility and duration of their effects. And this includes affecting the behaviors pertinent to this book.

				Testosterone has far less to do with aggression than most assume. Within the normal range, individual differences in testosterone levels don’t predict who will be aggressive. Moreover, the more an organism has been aggressive, the less testosterone is needed for future aggression. When testosterone does play a role, it’s facilitatory—testosterone does not “invent” aggression. It makes us more sensitive to triggers of aggression, particularly in those most prone to aggression. Also, rising testosterone levels foster aggression only during challenges to status. Finally, crucially, the rise in testosterone during a status challenge does not necessarily increase aggression; it increases whatever is needed to maintain status. In a world in which status is awarded for the best of our behaviors, testosterone would be the most prosocial hormone in existence.

				Oxytocin and vasopressin facilitate mother-infant bond formation and monogamous pair-bonding, decrease anxiety and stress, enhance trust and social affiliation, and make people more cooperative and generous. But this comes with a huge caveat—these hormones increase prosociality only toward an Us. When dealing with Thems, they make us more ethnocentric and xenophobic. Oxytocin is not a universal luv hormone. It’s a parochial one.

				Female aggression in defense of offspring is typically adaptive and is facilitated by estrogen, progesterone, and oxytocin. Importantly, females are aggressive in many other evolutionarily adaptive circumstances. Such aggression is facilitated by the presence of androgens in females and by complex neuroendocrine tricks for generating androgenic signals in “aggressive,” but not “maternal” or “affiliative,” parts of the female brain. Mood and behavioral changes around the time of menses are a biological reality (albeit poorly understood on a nuts-and-bolts level); in contrast, pathologizing these shifts is a social construct. Finally, except for rare, extreme cases, the link between PMS and aggression is minimal.

				Sustained stress has numerous adverse effects. The amygdala becomes overactive and more coupled to pathways of habitual behavior; it is easier to learn fear and harder to unlearn it. We process emotionally salient information more rapidly and automatically, but with less accuracy. Frontal function—working memory, impulse control, executive decision making, risk assessment, and task shifting—is impaired, and the frontal cortex has less control over the amygdala. And we become less empathic and prosocial. Reducing sustained stress is a win-win for us and those stuck around us.

				“I’d been drinking” is no excuse for aggression.

				Over the course of minutes to hours, hormonal effects are predominantly contingent and facilitative. Hormones don’t determine, command, cause, or invent behaviors. Instead they make us more sensitive to the social triggers of emotionally laden behaviors and exaggerate our preexisting tendencies in those domains. And where do those preexisting tendencies come from? From the contents of the chapters ahead of us.



