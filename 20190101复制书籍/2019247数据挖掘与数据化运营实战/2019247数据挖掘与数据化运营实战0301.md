# 03 数据化运营中常见的数据分析项目类型

千举万变，其道一也。

——《荀子·儒效》

3.1　目标客户的特征分析

3.2　目标客户的预测（响应、分类）模型

3.3　运营群体的活跃度定义

3.4　用户路径分析

3.5　交叉销售模型

3.6　信息质量模型

3.7　服务保障模型

3.8　用户（买家、卖家）分层模型

3.9　卖家（买家）交易模型

3.10　信用风险模型

3.11　商品推荐模型

3.12　数据产品

3.13　决策支持

数据化运营中的数据分析项目类型比较多，涉及不同的业务场景、业务目的和分析技术。在本章中，按照业务用途的不同将其做了一个大概的分类，并针对每一类项目的特点和具体采用的分析挖掘技术进行了详细的说明和举例示范。

一个成功的数据分析挖掘项目，首先要有准确的业务需求描述，之后则要求项目相关人员自始至终对业务有正确的理解和判断，所以对于本章所分享的所有分析项目类型以及对应的分析挖掘技术，读者只有在深刻理解和掌握相应业务背景的基础上才可以真正理解项目类型的特点、目的，以及相应的分析挖掘技术合适与否。

对业务的理解和思考，永远高于项目的分类和分析技术的选择。

3.1　目标客户的特征分析

目标客户的特征分析几乎是数据化运营企业实践中最普遍、频率最高的业务分析需求之一，原因在于数据化运营的第一步（最基础的步骤）就是要找准你的目标客户、目标受众，然后才是相应的运营方案、个性化的产品与服务等。是不加区别的普遍运营还是有目标有重点的精细化运营，这是传统的粗放模式与精细的数据化运营最直接、最显性的区别。

在目标客户的典型特征分析中，业务场景可以是试运营之前的虚拟特征探索，也可以是试运营之后来自真实运营数据基础上的分析、挖掘与提炼，两者目标一致，只是思路不同、数据来源不同而已。另外，分析技术也有一定的差异。

对于试运营之前的虚拟特征探索，是指目标客户在真实的业务环境里还没有产生，并没有一个与真实业务环境一致的数据来源可以用于分析目标客户的特点，因此只能通过简化、类比、假设等手段，来寻找一个与真实业务环境近似的数据来源，从而进行模拟、探索，并从中发现一些似乎可以借鉴和参考的目标用户特征，然后把这些特征放到真实的业务环境中去试运营。之后根据真实的效果反馈数据，修正我们的目标用户特征。一个典型的业务场景举例就是 A 公司推出了一个在线转账产品，用户通过该产品在线转账时产生的交易费用相比于普通的网银要便宜些。在正式上线该转账产品之前，产品运营团队需要一个初步的目标客户特征报告。很明显，在这个时刻，产品还没有上线，是无法拥有真实使用该产品的用户的，自然也没有相应数据的积累，那这个时候所做的目标客户特征分析只能是按照产品设计的初衷、产品定位，以及运营团队心中理想化的猜测，从企业历史数据中模拟、近似地整理出前期期望中的目标客户典型特征，很明显这里的数据并非来自该产品正式上线后的实际用户数据（还没有这些真实的数据产生），所以这类场景的分析只能是虚拟的特征分析。具体来说，本项目先要从企业历史数据中寻找有在线交易历史的买卖双方，在线行为活跃的用户，以及相应的一些网站行为、捆绑了某知名的第三方支付工具的用户等，然后根据这些行为字段和模拟的人群，去分析我们期望的目标客户特征，在通过历史数据仓库的对比后，准确掌握该目标群体的规模和层次，从而提交运营业务团队正式运营。

对于试运营之后的来自真实运营数据基础上的用户特征分析，相对而言，就比上述的模拟数据分析来得更真实更可行，也更贴近业务实际。在该业务场景下，数据的提取完全符合业务需求，且收集到的用户也是真实使用了该产品的用户，基于这些真实用户的分析就不是虚拟的猜测和模拟了，而是有根有据的铁的事实。在企业的数据化运营实践中，这后一种场景更加普遍，也更加可靠。

对于上面提到的案例，在经过一段时间的试运营之后，企业积累了一定数量使用该产品的用户数据。现在产品运营团队需要基于该批实际的用户数据，整理分析出该产品的核心目标用户特征分析报告，以供后期运营团队、产品开发团队、服务团队更有针对性、更有效地进行运营和服务。在这种基于真实的业务场景数据基础上的客户特征分析，有很多分析技术可以采用（本书第 11 章将针对「用户特征分析」进行专题介绍，分享其中最主要的一些分析技术），但是其中采用预测模型的思路是该场景与上述「虚拟场景」数据分析的一个不同，上述「虚拟场景」数据分析一般来说是无法进行预测模型思路的探索的。


关于目标客户特征分析的具体技术、思路、实例分享，可参考本书第 11 章。

3.2　目标客户的预测（响应、分类）模型

这里的预测（响应、分类）模型包括流失预警模型、付费预测模型、续费预测模型、运营活动响应模型等。

预测（响应、分类）模型是数据挖掘中最常用的一种模型类型，几乎成了数据挖掘技术应用的一个主要代名词。很多书籍介绍到数据挖掘的技术和应用，首先都会列举预测（响应、分类）模型，主要的原因可能是响应模型的核心就是响应概率，而响应概率其实就是我们在第 1 章中介绍的数据化运营六要素里的核心要素 —— 概率（Probability），数据化运营 6 要素的核心是以数据分析挖掘支撑的目标响应概率（Probability），在此基础上围绕产品功能优化、目标用户细分、活动（文案）创意、渠道优化、成本的调整等重要环节、要素，共同达成数据化运营的持续完善、成功。

预测（响应、分类）模型基于真实业务场景产生的数据而进行的预测（响应、分类）模型搭建，其中涉及的主要数据挖掘技术包括逻辑回归、决策树、神经网络、支持向量机等。有没有一个算法总是优先于其他算法呢？答案是否定的，没有哪个算法在任何场景下都总能最优胜任响应模型的搭建，所以在通常的建模过程中，数据分析师都会尝试多种不同的算法，然后根据随后的验证效果以及具体业务项目的资源和价值进行权衡，并做出最终的选择。

根据建模数据中实际响应比例的大小进行分类，响应模型还可以细分为普通响应模型和稀有事件响应模型，一般来讲，如果响应比例低于 1%，则应当作为稀有事件响应模型来进行处理，其中的核心就是抽样，通过抽样技术人为放大分析数据样本里响应事件的比例，增加响应事件的浓度，从而在建模过程中更好地捕捉、拟合其中自变量与因变量的关系。

预测（响应、分类）模型除了可以有效预测个体响应的概率之外，模型本身显示出的重要输入变量与目标变量的关系也有重要的业务价值，比如说可以转化成伴随（甚至导致）发生响应（生成事件）的关联因素、重要因素的提炼。而很多时候，这种重要因素的提炼，是可以作为数据化运营中的新规则、新启发，甚至是运营的「新抓手」的。诚然，从严格的统计学角度来看，预测响应模型中的输入变量与目标变量之间的重要关系并不一定是因果关系，严格意义上的因果关系还需要后期进行深入的分析和实验；即便如此，这种输入变量与目标变量之间的重要关系也常常会对数据化运营具有重要的参考和启发价值。

比如说，我们通过对在线交易的卖家进行深入分析挖掘，建立了预测响应模型，从而根据一系列特定行为和属性的组合，来判断在特定时间段内发生在线交易的可能性。这个响应模型除了生成每个 Member_Id 在特定时间段发生在线交易的可能性之外，从模型中提炼出来的一些重要输入变量与目标变量（是否发生在线交易），以及它们之间的关系（包括正向或负向关系，重要性的强弱等）对数据化运营也有着很重要的参考和启发。在本案例中，我们发现输入变量近 30 天店铺曝光量、店铺装修打分超过 25 分等与是否在线交易有着最大的正相关。根据这些发现和规则整理，尽管不能肯定这些输入变量与是否在线交易有因果关系，但这些正向的强烈的关联性也足以为提升在线交易的数据化运营提供重要的启发和抓手。我们有一定的理由相信，如果卖家提升店铺的曝光量，如果卖家把自己的店铺装修得更好，促进卖家在线成交的可能性会加大。

3.3　运营群体的活跃度定义

运营群体（目标群体）的活跃度定义，这也是数据化运营基本的普遍的要求。数据化运营与传统的粗放型运营最主要的区别（核心）就是前者是可以准确地用数据衡量，而且这种衡量是自始至终地贯穿于数据化运营的全过程；而在运营全过程的衡量监控中，活跃度作为一个综合的判断指标，又在数据化运营实践中有着广泛的应用和曝光。活跃度的定义没有统一的描述，一般都是根据特定的业务场景和运营需求来量身订做的。但是，纵观无数场景中的活跃度定义，可以发现其中是有一些固定的骨架作为基础和核心的。其中最重要、最常见的两个基本点如下。

1）活跃度的组成指标应该是该业务场景中最核心的行为因素。

2）衡量活跃度的定义合适与否的重要判断依据是其能否有效回答业务需求的终极目标。

下面我们用具体的案例来解释上述两个基本点。

案例：PM 产品是一款在线的 SAAS 产品，其用途在于协助卖家实时捕捉买家访问店铺的情况，并且通过该 PM 产品可以实现跟买家对话、交换联系方式等功能。作为 PM 产品的运营方，其运营策略是向所有平台的卖家免费提供 PM 产品的基本功能（每天只能联系一位到访的买家，也即限制了联系多位到访买家的功能）、向部分优质卖家提供一定期限内免费的 PM 产品全功能（这部分优质卖家免费获赠 PM 产品，可以享受跟付费一样的全功能）、向目标卖家在线售卖 PM 产品。

经过一段时间的运营，现在管理层需要数据分析团队定义一个合理的「PM 产品用户活跃度」，使得满足一定活跃度分值的用户能比较容易转化成为 PM 产品的付费用户，同时这个合适的定义还可以帮助有效监控每天 PM 产品的运营效果和效率。

根据上面的案例背景描述，以及之前的活跃度定义的两个基本点来看，在本案例中，该业务场景中最核心的行为因素就是卖家使用该 PM 产品与到访买家的洽谈动作（表现形式为洽谈的次数）、在线登录该 PM 产品的登录次数等。而该分析需求的终极目的就是促成付费用户的转化，所以项目最终活跃度的定义是否合适，是否满足业务需求，一个最重要的评估依据就是按照该活跃度定义出来的活跃用户群体里，可以覆盖多少实际的 PM 产品付费用户。从理论上来说，覆盖率越高越好，如果覆盖率不高，比如，实际付费用户群体里只有 50% 包含在活跃度定义的活跃群体里，那么这个活跃度的定义是不能满足当初的业务需求的，也就是说这是一个不成功的定义。

活跃度的定义所涉及的统计技术主要有两个，一个是主成分分析，另一个是数据的标准化。其中，主成分分析的目的，就是把多个核心行为指标转化为一个或少数几个主成分，并最终转化成一个综合的分数，来作为活跃度的定义，到底是取第一个主成分，还是前两个或前三个，这要取决于主成分分析的特征根和累计方差贡献率，一般来说，如果前面几个特征根的累计方差贡献率达到 80% 以上，就可以基本认为前面几个主成分就可以相应地代表原始数据的大部分信息了；至于数据标准化技术得到了普遍采用，主要是因为不同的指标有不同的度量尺度，只有在标准化之后，才可以将数据按照比例进行缩放，使之落入一个小的区间范围之内，这样，不同变量经过标准化处理后就可以有平等的分析和比较基础了。关于数据标准化的详细介绍，可参看本书 8.5.4 节和 9.3.2 节。

3.4　用户路径分析

用户路径分析是互联网行业特有的分析专题，主要是分析用户在网页上流转的规律和特点，发现频繁访问的路径模式，这些路径的发现可以有很多业务用途，包括提炼特定用户群体的主流路径、网页设计的优化和改版、用户可能浏览的下一个页面的预测、特定群体的浏览特征等。从这些典型的用途示例中可以看到，数据化运营中的很多业务部门都需要应用用户路径分析，包括运营部门、产品设计部门（PD）、用户体验设计部门（User Experience Design，UED）等。

路径分析所用的数据主要是 Web 服务器中的日志数据，不过，互联网的特性使得日志数据的规模通常都是海量的。据预测，到 2020 年，全球以电子形式存储的数据量将达到 35ZB（相当于 10 亿块 1TB 的硬盘的容量），是 2009 年全球存储量的 40 倍。而在 2010 年年底，根据 IDC 的统计，全球的数据量已经达到了 120 万 PB，或 1.2ZB。如果将这些数据都刻录在 DVD 上，那么光把这些 DVD 盘片堆叠起来就可以从地球往月球一个来回（单程约 24 万英里）。

路径分析常用的分析技术有两类，一类是有算法支持的，另一类是严格按照步骤顺序遍历主要路径的。关于路径分析中具体的算法和示例将在第 13 章做详细的说明。

在互联网数据化运营的实践中，如果能把单纯的路径分析技术、算法与其他相关的数据分析技术、挖掘技术相融合，那么将会产生更大的应用价值和更为广阔的前景。这种融合的思路包括通过聚类技术划分出不同的群体，然后分析不同群体的路径特征，针对特定人群进行的路径分析，比如，对比付费人群的主要路径与非付费人群的主要路径，优化页面布局等、根据下单付费路径中频繁出现的异常模式可能来对付费环境的页面设计进行优化，提升付费转化率，减少下单后的流失风险等。

在运营团队看来，路径分析的主要用途之一，即为监控运营活动（或者目标客户）的典型路径，看是否与当初的运营设想一致。如果不一致，就继续深入分析原因，调整运营思路或页面布局，最终目的就是提升用户点击页面的效率；其二就是通过路径分析，提炼新的有价值的频繁路径模式，并且在以后的运营中对这些模式加以应用，提升运营的效率和特定效果。比如，通过某次运营活动的路径分析，我们发现从 A 入口进来的用户有 30% 会进入 C 页面，然后再进入 B 页面，而 A 入口是系列运营活动的主要入口之一，基于这个 C 页面的重要性发现，运营人员在该页面设置了新的提醒动作，取得了较好的深度转化率。

在产品设计部门（PD）看来，路径分析是实现产品优化的一个重要依据和工具，被路径分析证明是冷僻的功能点和路径的，或许可以被进一步考虑是否有必要取消或优化。对于 UED 来说，路径分析也是这样帮助他们优化页面设计的。

3.5　交叉销售模型

交叉销售这个概念在传统行业里其实已经非常成熟了，也已被普遍应用，其背后的理论依据是一旦客户购买了商品（或者成为付费用户），企业就会想方设法保留和延长这些客户在企业的生命周期和客户的利润贡献，一般会有两个运营选择方向，一是延缓客户流失，让客户尽可能长久地留存，在该场景下，通常就是客户流失预警模型发挥作用，利用流失预警模型，提前锁定最可能流失的有价值的用户，然后客户服务团队采用各种客户关怀措施，尽量挽留客户，从而最终降低客户流失率；二是让客户消费更多的商品和服务，从而更大地提升客户的商业价值，挖掘客户利润，这种尽量挖掘客户利润的说法在以客户为中心的激烈竞争的 2.0 时代显得有些赤裸裸，所以，更加温和的说法就是通过数据分析挖掘，找出客户进一步的消费需求（潜在需求），从而更好及更主动地引导、满足、迎合客户需求，创造企业和客户的双赢。在这第二类场景中，涉及的主要应用模型就是交叉销售模型。

交叉销售模型通过对用户历史消费数据的分析挖掘，找出有明显关联性质的商品组合，然后用不同的建模方法，去构建消费者购买这些关联商品组合的可能性模型，再用其中优秀的模型去预测新客户中购买特定商品组合的可能性。这里的商品组合可以是同时购买，也可以有先后顺序，不可一概而论，关键要看具体的业务场景和业务背景。

不同的交叉销售模型有不同的思路和不同的建模技术，但是前提一般都是通过数据分析找出有明显意义和商业价值的商品组合，可以同时购买，也可以有先后顺序，然后根据找出的这些特性去建模。

综合数据挖掘的中外企业实践来看，最少有 4 种完全不同的思路，可以分别在不同的项目背景中圆满完成建立交叉销售模型的这个任务。一是按照关联技术（Association Analysis），也即通常所说的购物篮分析，发现那些有较大可能被一起采购的商品，将它们进行有针对性的促销和捆绑，这就是交叉销售；二是借鉴响应模型的思路，为某几种重要商品分别建立预测模型，对潜在消费者通过这些特定预测模型进行过滤，然后针对最有可能的前 5% 的消费者进行精确的营销推广；三是仍然借鉴预测响应模型的思路，让重要商品两两组合，找出那些最有可能消费的潜在客户；四是通过决策树清晰的树状规则，发现基于具体数据资源的具体规则（有的多，有的少），国外很多营销方案的制订和执行实际上都是通过这种方式找到灵感和思路的。

相应的建模技术主要包括关联分析（Association Analysis）、序列分析（Sequence Analysis），即在关联分析的基础上，增加了先后顺序的考虑，以及预测（响应、分类）模型技术，诸如逻辑回归、决策树等。

上面总结的是基于传统行业的实践，这些经验事实上也成功地应用到了互联网行业的数据化运营中。无论是多种在线产品的交叉销售，还是电子商务中的交叉销售，抑或各种服务的推广、运营中的商品捆绑策略，都可以从中看到交叉销售的影子，这种理念正在深入地影响着数据化运营的效果和进程。

下面针对典型的交叉销售模型的应用场景来举个例子：A 产品与 B 产品都是公司 SAAS 系列产品线上的重点产品，经过分析发现两者付费用户的重合度高达 40%，现在运营方需要一个数据分析解决方案，可以有效识别出最可能在消费 A 产品的基础上也消费 B 产品的潜在优质用户。本案例的分析需求，实际上就是一个典型的交叉销售模型的搭建需求，数据分析师在与业务团队充分沟通后，通过现有数据进行分析，找出了同时消费 A 产品和 B 产品（注意，是同时消费，还是有先后次序，这个具体的定义取决于业务需求的判断，两者取数逻辑不同，应用场景也不同，不过分析建模技术还是可以相同的）用户的相关的网站行为、商业行为、客户属性等，之后再进行数据分析和挖掘建模，最后得到了一个有效的预测模型，通过该模型可以对新的用户数据进行预测，找出最可能消费 A 产品同时也消费 B 产品的潜在付费用户人群（或名单）。这样，运营方就可以进行精准的目标运营，从而有效提升运营效果，有效提升付费用户数量和付费转化率了。

3.6　信息质量模型

信息质量模型在互联网行业和互联网数据化运营中也是有着广泛基础性应用的。具体来说，电商行业和电商平台连接买卖双方最直接、最关键的纽带就是海量的商品目录、商品 Offer、商品展示等，无论是 B2C（如当当网、凡客网），还是 C2C（如淘宝网），或者是 B2B（如阿里巴巴），只要是以商业为目的，以交易为目的的，都需要采用有效手段去提升海量商业信息（商品目录、商品 Offer、商品展示等）的质量和结构，从而促进交易。在同等条件下，一个要素齐备、布局合理、界面友好的网上店铺或商品展示一定比不具备核心要素、布局不合理、界面不友好的更加容易达成交易，更加容易获得买家的好感，这里揭示的其实就是信息质量的重要价值。

为让读者更加直观了解信息质量的含义，下面通过某网站的截图来举例说明什么是信息质量好的 Offer 效果，如图 3-1 和图 3-2 所示。

图　3-1　信息质量较好的 Offer 界面图

图　3-2　信息质量较差的 Offer 界面图

不难发现，相对于图 3-2 来说，图 3-1 中有更多的商品要素展示，包括付款方式、产品品牌、产品型号等，另外在详细信息栏目里，所包含的信息也更多更全。也就是说，图 3-1 中商品 Offer 的信息质量要明显好于图 3-2。

互联网行业的信息质量模型所应用的场合主要包括商品 Offer 质量优化、网上店铺质量优化、网上论坛的发帖质量优化、违禁信息的过滤优化等，凡是涉及信息质量监控和优化的场景都是适用（或借鉴）信息质量模型的解决方案的。

构建信息质量模型所涉及的主要还是常规的数据挖掘技术，比如回归算法、决策树等。但是对于信息质量模型的需求，由于其目标变量具有一定的特殊性，因此它与目标客户预测（响应）模型在思路和方法上会有一些不同之处，具体内容如下。

任何模型的搭建都是用于响应特定的业务场景和业务需求的，有时候搭建信息质量模型的目标变量是该信息（如商品 Offer）是否在特定的时间段产生了交易，此时，目标变量就是二元的，即是与否；更多的时候，信息质量模型的目标变量与是否交易没有直接关系（这其实很容易理解，因为影响成交的因素太多），甚至有些时候信息质量本身是主观的判断，在这种情况下，没有明确的来自实际数据的目标变量。那如何定义目标变量呢？专家打分，模型拟合是一个比较合适的变通策略。

对于专家打分，模型拟合的具体操作，下面以「商品 Offer 的星级划分」项目为例来进行具体的解释和示范。商品 Offer 其实就是网上交易中，卖家针对每种出售的商品展示具体的商品细节、交易条款、图片细节等，使其构成的一个完整的页面，一般来说买家浏览了某种具体的商品 Offer 以后，只要点击「加入购物车」就可以进行后续的购买付费流程了。在某次「商品 Offer 的星级划分」项目中，目标变量就是专家打分，由业务专家、行业专家基于行业的专业背景知识，针对商品 Offer 构成要素的权重进行人为打分，这些构成要素包括标题长度、图片数量、属性选填的比例、是否有分层价格区间、是否填写供货总量信息、是否有混批说明、是否有运营说明、是否支持在线第三方支付等。首先抽取一定数量的样本，请行业专家对这些样本逐个打分赋值，在取得每种商品 Offer 的具体分数后，把这些分数作为目标变量，利用数据挖掘的各种模型去拟合这些要素与总分数的关系，最终形成一个合适的模型，该模型比较有效地综合了专家打分的意见并且有效拟合 Offer 构成要素与总分数的关系。为了更加准确，在专家打分的基础上，还可以辅之以客户调研，从而对专家的打分和各要素的权重进行修正，最后在修正的基础上进行模型的搭建和拟合，这属于项目的技术细节，不是项目核心，故不做深入的讲解。

信息质量模型是电子商务和网上交易的基本保障，其主要目的是确保商品基本信息的优质和高效，让买家更容易全面、清楚、高效地了解商品的主要细节，让卖家更容易、更高效地展示自己的商品。无论是 C2C（如淘宝），还是 B2B（如阿里巴巴），抑或是 B2C（如当当网、凡客网），都可以用类似的方法去优化、提升自己的商品展示质量和效果，有效提升和保障交易的转化率。

3.7　服务保障模型

服务保障模型主要是站在为客户服务的角度来说的，出发点是为了让客户（平台的卖家）更好地做生意，达成更多的交易，我们（平台）应该为他们提供哪些有价值的服务去支持、保障卖家生意的发展，这里的服务方向就可以有很多的空间去想象了。比如，让卖家购买合适的增值产品，让卖家续费合适的增值产品、卖家商业信息的违禁过滤、卖家社区发帖的冷热判断等，凡是可以更好地武装卖家的，可以让卖家更好地服务买家的措施，无论是产品武装，还是宣传帮助，都属于服务保障的范畴，都是服务保障模型可以并且应该出力的方向。

针对服务保障模型的示例将会在随后的预测（响应、分类）模型里专门进行介绍，所以这里不展开讨论，但是对于服务保障环节，我们还是应该有一定的认识，无论从数据化运营的管理、客户关系管理，还是数据分析挖掘应用上，服务保障环节都是不能忽视的一个方面。

3.8　用户（买家、卖家）分层模型

用户（买家、卖家）分层模型也是数据化运营中常见的解决方案之一，它与数据化运营的本质是密切相关的。精细化运营必然会要求区别对待，而分层（分群）则是区别对待的基本形式。

分层模型是介于粗放运营与基于个体概率预测模型之间的一种折中和过渡模型，其既兼顾了（相对粗放经营而言比较）精细化的需要，又不需要（太多资源）投入到预测模型的搭建和维护中，因而在数据化运营的初期以及在战略层面的分析中，分层模型有着比较广泛的应用和较大的价值。

正如预测模型有特定的目标变量和模型应用场景一样，分层模型也有具体的分层目的和特定用途，这些具体的目的和用途就决定了分层模型的构建思路和评价依据。其常用的场景为：客户服务团队需要根据分层模型来针对不同的群体提供不同的说辞和相应的服务套餐；企业管理层需要基于在线交易卖家数量来形成以其为核心的卖家分层进化视图；运营团队需要通过客户分层模型来指导相应的运营方案的制订和执行，从而提高运营效率和付费转化率等。这些分层模型既可以为管理层、决策层提供基于特定目的的统一进化视图，又可以给业务部门做具体的数据化运营提供分群（分层）依据和参考。

分层模型常用的技术既包括统计分析技术（比如相关性分析、主成分分析等），又可以含有预测（响应、分类）模型的技术（比如通过搭建预测模型发现最重要的输入变量及其排序情况，然后根据这些变量对分层进行大致的划分，并通过实际数据进行验证），这要视具体的分析目的、业务背景和数据结构而定，同时要强调的是，一个好的分层模型的搭建一定是需要业务方的参与和贡献的，而且其中的业务逻辑和业务思考远远胜过分析技术本身。

下面我们分别用两个典型的案例来说明分层模型是如何搭建和应用的。

案例一：以交易卖家数量为核心的卖家分层进化视图

背景：某互联网公司作为买卖双方的交易平台，其最终的价值体现在买卖双方在该平台上达成交易（从而真正让买卖双方双赢，满意）。现在，管理层希望针对在线成交的卖家（群体）形成一个分层进化的视图。其基本目标就是，从免费注册的卖家开始，通过该视图可以粗略地、有代表性地勾画出卖家一步一步成长、进步乃至最终达成交易的全过程。这里的每一层都是一个或几个有代表性的重要指标门槛，顺着不同的门槛逐步进化，越往上走，人群越少，越有可能成为有交易的卖家，而最后最高一层将是近 30 天来有交易的卖家。从这个背景和目标描述里，我们可以大致想象出这个分层模型是一个类似金字塔的形状（底部人数多，越往上越小，表示人群在减少）。

这个分层模型的主要价值体现在：可以让管理层、决策层对交易卖家的成长、进化、过滤的过程有个清晰、直观的把握，并且可以从中直观地了解影响卖家交易的一系列核心因素，以及相应的大致门槛阀值，也可以让具体的业务部门直观地了解「培养成交卖家，让卖家能在线成交」的主要因素，以及相应的运营抓手。

在本案例中，有必要了解一些关键的业务背景和业务因素，比如要想在线交易，卖家的 Offer 必须是「可在线交易 Offer」。这个条件很关键，所谓「可在线交易 Offer」是指该商品的 Offer 支持支付宝等第三方在线支付手段，如果卖家的 Offer 不支持这些手段，那就无法在线交易，也就无法满足本课题的目标了。所以，这里的「卖家 Offer 必须是可在线交易 Offer」是一个前期的重要门槛和阀值，从此也可以看出，对业务背景的了解非常重要，它决定了课题是否成功。

下面来谈谈具体的分析思路，先是从最基本的免费注册的卖家（即「全会员」）开始，之后是近 30 天有登录网站的卖家（说明是「活」的卖家，这里经过了直观的业务思考），再到近 1 年有新发或重发 Offer 的卖家，然后是当前有效 Offer 的卖家，最后是当前有可在线交易 Offer 的卖家，这个分析过程其实是第一部分的思考，它们构成了金字塔的下半部分，基本上是基于业务背景的了解和顺理成章的逻辑来「进化」的，之所以在「全会员」与「当前有可在线交易 Offer」之间安插了另外 3 层逐步「进化」的指标，主要也是基于业务方需要门槛的进度和细分的考虑，但这不是主要的核心点。

接下来，从「当前有可在线交易 Offer 的卖家」开始，层层进化到最高端的「近 30 天有在线交易的卖家」，也就是找出影响卖家成交的核心因素，并将之提炼成具体的层级和门槛，这一部分则是本案例的重点和核心所在。

如何找出其中的核心要素以及重要性的先后顺序？在本课题中，使用了预测（分类、响应）模型的方法，即通过搭建预测（响应）模型（目标变量是「近 30 天是否在线成交」，输入变量由数据分析团队与业务团队共同讨论确定），并通过多种模型算法的比较，最后找出决定交易的几个最重要的输入变量及先后次序。

最终的分层模型大致如图 3-3 所示，限于企业商业隐私的考虑，针对该数据做了处理，请勿对号入座。

图　3-3　交易卖家分层示意图

该金字塔每一层里的数量代表满足该条件的会员（卖家）数量，而且各层之间的条件是连贯且兼容的，比如，从下往上数，第 6 层「当前有可交易 Offer」的用户有 204 万人，占其前一层「可交易行业卖家」269 万人的 76%，而且该层的用户必定是同时满足其下 5 层的所有条件的（包括来自可交易行业，当前有有效 Offer，近 1 年有新发或重发 Offer，近 30 天有登录网站或即时通信工具等）。

细心的读者可能会发现，最顶层的人数是 31 万，占近 30 天有交易卖家总数的 71%，为什么不能占近 30 天有交易卖家总数的 100%？这个差距正是由金字塔模型的本质所决定的，无论这个层层进化的金字塔模型多么完美，它还是无法完全圈定有交易卖家的总数，总是有一部分有交易的卖家不是满足上述金字塔上半部分的那些条件、门槛、阀值。这也是类似的分层模型只能看大数、看主流的主要原因和特点，但是只要这个模型可以圈定大多数的人群（比如本项目实现的 71%，或者更高），那它就有相当的代表性，就可以作为相应的决策参考和业务参考。

当然，这个模型是否可以投入应用，还需要进一步检验，常规的检验方法就是通过不同时间段的数据，看是否有相似的规律、门槛、占比、漏斗，也就是看这个金字塔的结构是否具有一定时间长度的稳定性。在本项目中，我们通过前后各半年的数据分别进行了验证，发现这个金字塔的结果总体还是比较稳定的，确实可以作为决策参考和业务借鉴。

案例二：客户服务的分层模型

背景：A 产品是一个在线使用的付费产品，其主要功能就是让卖家实时获悉来自己网店的买家，可以让卖家通过主动对话促成双方的交谈，一旦对上话，卖家就可以得到由系统提供的买家联系方式等。很明显，该产品的核心功能（卖点）就是让卖家第一时间抓住来店铺的买家，并通过对话拿到买家的联系方式，方便后期的跟进，直至达成交易。现在该产品的客户服务团队正在负责付费用户的后期续费工作，该客服团队希望数据分析师帮他们制作一个付费用户的分层模型，在业务方的设想中该模型至少有 3 层，每一层可以对应相应的客服方案来帮助该层客户解决问题，模型的最终目的是促进付费客户的续费率稳步提升。具体来说，业务方希望根据业务敏感和客服资源储备，对付费用户进行 3 个群体的划分，每个群体有明确的业务诊断和客服方案（第一个群体，「体质差的客户群体」，比如访客数比较少，并且客户登录在线平台的次数也比较少（导致双方握手交谈可能性不高），这群客户被认为是最次要关注的；第二个群体，「问题客户群体」，比如对该产品的功能点使用都很少的客户，针对这群客户，客服团队可以对他们提供有针对性的产品功能教育；第三个群体，「生死线客户」，这群客户特点是有相对而言数量较多的访客，但是他们很少主动洽谈（以至无法拿到买家的联系方式，影响后期的成交），之所以称之为「生死线客户」，是因为客服团队希望作为重点关怀的群体，把他们从产品使用的「无效性」上拉回来，把他们从可能流失（续费）的生死线上拉回来（这群客户有理由从产品中获益（拿到买家联系方式），只是他们没有主动联系客户，如果他们能主动与买家洽谈，从而拿到联系方式，他们的成交业务有理由明显上升）。

该案例的分层模型用不上复杂的建模技术，只需要基于简单的统计技能就可实现。在深度把握产品价值和业务背景的前提下，我们与业务方一起基于他们设想的 3 个细分群体，根据实际数据找出了相应的具体阀值。具体来说，针对「体质差的客户群体」，基于访客数量和自身登录平台的天数和次数，进行两维数据透视，就可以找到满意的阀值和门槛定义；针对「问题客户群体」，只需要针对各功能点使用情况的 10 分位，找出最低的 20%～30% 用户就可以了；针对「生死线客户群体」，同样是基于访客数量和自身主动洽谈的次数，进行两维数据透视，也可以找到满意的阀值和门槛定义，这样就能根据数据分布情况找到有很多访客，同时主动洽谈次数很少的客户群体。上述群体划分的方法主要是基于业务理解和客服团队的资源配备的，事后的方案验证也表明，该种群体划分不仅能让业务方更容易产生理解和共鸣，也能很好地稳定并提升付费用户的续费率。

3.9　卖家（买家）交易模型

卖家（买家）交易模型的主要目的是为买卖双方服务，帮助卖家获得更多的买家反馈，促进卖家完成更多的交易、获得持续的商业利益，其中涉及主要的分析类型包括：自动匹配（预测）买家感兴趣的商品（即商品推荐模型）、交易漏斗分析（找出交易环节的流失漏斗，帮助提升交易效率）、买家细分（帮助提供个性化的商品和服务）、优化交易路径设计（提升买家消费体验）等。交易模型的很多分析类型其实已经在其他项目类型里出现过了，之所以把它们另外归入卖家（买家）交易模型的类型，主要是希望和读者一起换个角度（从促进交易的角度）来看待问题和项目。「横看成岭侧成峰」，同样的模型课题，其实有不同的主题应用场景和不一样的出发点，灵活、自如是一个合格的数据分析师应该具备的专业素养。

3.10　信用风险模型

这里的信用风险包括欺诈预警、纠纷预警、高危用户判断等。在互联网高度发达，互联网技术日新月异的今天，基于网络的信用风险管理显得尤其基础，尤其重要。

虽然目前信用风险已经作为一个独立的专题被越来越多的互联网企业所重视，并且有专门的数据分析团队和风控团队负责信用风险的分析和监控管理，但是从数据分析挖掘的角度来说，信用风险分析和模型的搭建跟常规的数据分析挖掘没有本质的区别，所采用的算法都是一样的，思路也是类似的。如果一定要找出这两者之间的区别，那就得从业务背景考虑了，从风险的业务背景来看，信用风险分析与模型相比于常规的数据分析挖掘有以下一些特点：

❑分析结论或者欺诈识别模型的时效更短，需要优化（更新）的频率更高。网络上骗子的行骗手法经常会变化，导致分析预警行骗欺诈的模型也要因此持续更新。

❑行骗手段的变化很大程度上是随机性的，所以这对欺诈预警模型的及时性和准确性提出了严重的挑战。

❑对根据预测模型提炼出的核心因子进行简单的规则梳理和罗列，这样就可在风控管理的初期阶段有效锁定潜在的目标群体。

3.11　商品推荐模型

鉴于商品推荐模型在互联网和电子商务领域已经成为一个独立的分析应用领域，并且正在飞速发展并且得到了广泛应用。因此除本节以外，其他章节将不再对商品推荐模型做任何分析和探讨，至于本节，相对于其他的分析类型来说，会花费更多的笔墨和篇幅。希望能给读者提供足够的原理和案例 [1]。

3.11.1　商品推荐介绍

电子商务推荐系统主要通过统计和数据挖掘技术，并根据用户在电子商务网站的行为，主动为用户提供推荐服务，从而来提高网站体验的。根据不同的商业需求，电子商务推荐系统需要满足不同的推荐粒度，主要以商品推荐为主，但是还有一些其他粒度推荐。譬如 Query 推荐、商品类目推荐、商品标签推荐、店铺推荐等。目前，常用的商品推荐模型主要分为规则模型、协同过滤和基于内容的推荐模型。不同的推荐模型有不同的推荐算法，譬如对于规则模型，常用的算法有 Apriori 等；而协同过滤中则涉及 K 最近邻居算法、因子模型等。没有放之四海而皆准的算法，在不同的电子商务产品中，在不同的电子商务业务场景中，需要的算法也是不一样的。实际上，由于每种算法各有优缺点，因此往往需要混合多种算法，取长补短，从而提高算法的精准性。

[1] 本节内容由淘宝网的商品推荐高级算法工程师陈凡负责编写，陈凡的微博地址为 hppt://weibo.com/bicloud。

3.11.2　关联规则

1.Apriori 算法

电子商务中常用的一种数据挖掘方法就是从用户交易数据集中寻找商品之间的关联规则。关联规则中常用的一种算法是 Apriori 算法。该算法主要包含两个步骤：首先找出数据集中所有的频繁项集，这些项集出现的频繁性要大于或等于最小支持度；然后根据频繁项集产生强关联规则，这些规则必须满足最小支持度和最小置信度。

上面提到了最小支持度和最小置信度，事实上，在关联规则中用于度量规则质量的两个主要指标即为支持度和置信度。那么，什么是支持度和置信度呢？接下来进行讲解。

给定关联规则 X=＞Y，即根据 X 推出 Y。形式化定义为：

假设 D 表示交易数据集；K 为项集，即包含 k 个项的集合；Lk 表示满足最小支持度的 k 项集；Ck 表示候选 k 项集。Apriori 算法的参考文献 [1] 描述如下。

在该算法中，候选集的计算过程如下所示。

首先进行连接运算如下：

然后根据频繁项集定理（即频繁项集的子集必定是频繁项集）进行剪枝，过滤掉非频繁项集，过程如下所示：

从上述算法中可以看出，该算法存在一些困难点，譬如需要频繁扫描交易数据集，这样如果面临海量数据集，就难以满足实际应用需求；对于大型数据集，计算候选集算法的效率较低，这也是一个难以克服的问题。目前已经有一些优化的方法用于处理这些问题，譬如 FP-growth 算法 [2]。在实际应用中，随着数据的不断增长，可能还需要通过分布式计算来提高算法性能，譬如机器学习算法包 Mahout [3] 中实现了的并行版本 FP-growth 算法。

2.Apriori 算法实例

假设给定如下电子商务网站的用户交易数据集，其中，定义最小支持度为 2/9，即支持度计数为 2，最小置信度为 70%，现在要计算该数据集的关联规则，如表 3-1 所示。

计算步骤如下所示。

步骤 1，根据 Apriori 算法计算频繁项集。

1）计算频繁 1 项集。扫描交易数据集，统计每种商品出现的次数，选取大于或等于最小支持度的商品，得到了候选项集，如表 3-2 所示。

2）根据频繁 1 项集，计算频繁 2 项集。首先将频繁 1 项集和频繁 1 项集进行连接运算，得到 2 项集，如下所示：

扫描用户交易数据集，计算包含每个候选 2 项集的记录数，如表 3-3 所示。

根据最小支持度，得到频繁 2 项集，如表 3-4 所示。

3）根据频繁 2 项集，计算频繁 3 项集。首先将频繁 2 项集进行连接，得到 {{I1,I2,I3},{I1,I2,I5},{I1,I3,I5},{I2,I3,I4},{I2,I3,I5},{I2,I4,I5}}，然后根据频繁项集定理进行剪枝，即频繁项集的非空子集必须是频繁的，{I1,I2,I3} 的 2 项子集为 {I1,I2}，{I1,I3}，{I2,I3}，都在频繁 2 项集中，则保留；

{I1,I2,I5} 的 2 项子集为 {I1,I2}，{I1,I5}，{I2,I5}，都在频繁 2 项集中，则保留；

{I1,I3,I5} 的 2 项子集为 {I1,I3}，{I1,I5}，{I3,I5}，由于 {I3,I5} 不是频繁 2 项集，移除该候选集；

{I2,I3,I4} 的 2 项子集为 {I2,I3}，{I2,I4}，{I3,I4}，由于 {I3,I4} 不是频繁 2 项集，移除该候选集；

{I2,I3,I5} 的 2 项子集为 {I2,I3}，{I2,I5}，{I3,I5}，由于 {I3,I5} 不是频繁 2 项集，移除该候选集；

{I2,I4,I5} 的 2 项子集为 {I2,I4}，{I2,I5}，{I4,I5}，由于 {I4,I5} 不是频繁 2 项集，移除该候选集。通过剪枝，得到候选集 {{I1,I2,I3},{I1,I2,I5}}，扫描交易数据库，计算包含候选 3 项集的记录数，得到表 3-5。

4）根据频繁 3 项集，计算频繁 4 项集。重复上述的思路，得到 {I1,I2,I3,I5}，根据频繁项集定理，它的子集 {I2,I3,I5} 为非频繁项集，所以移除该候选集。从而，频繁 4 项集为空，至此，计算频繁项集的步骤结束。

步骤 2，根据频繁项集，计算关联规则。

这里以频繁 3 项集 {I1,I2,I5} 为例，计算关联规则。{I1,I2,I5} 的非空子集为 {I1,I2}、{I1,I5}、{I2,I5}、{I1}、{I2} 和 {I5}。

规则 1，{I1,I2}=＞{I5}, 置信度为 {I1,I2,I5} 的支持度除以 {I1,I2} 的支持度，即 2/4=50%，因其小于最小置信度，所以删除该规则。

同理，最后可以得到 {I1,I5}=＞{I2}，{I2,I5}=＞{I1} 和 {I5}=＞{I1,I2} 为 3 条强关联规则。

然而，在实际应用 Apriori 算法时，需要根据不同的粒度，譬如类目、商品等，结合不同的维度（浏览行为，购买行为等）进行考虑，从而构建符合业务需求的关联规则模型。在电子商务应用中，关联规则算法适用于交叉销售的场景。譬如，有人要出行（飞往北京），根据计算出的关联规则（如：机票 =＞酒店）来考虑，那么，可以根据用户购买的机票，为用户推荐合适的北京酒店；再比如，在情人节，根据关联规则，将巧克力和玫瑰花进行捆绑销售等。

另外，关联规则还可以用来开发个性化电子商务推荐系统的 Top N 推荐。首先，根据用户的交易数据，计算用户在特定时序内购买过的商品；然后，根据关联规则算法，计算满足最小支持度和最小置信度的商品关联规则；再根据用户已经购买的商品和商品关联规则模型，预测用户感兴趣的商品，同时过滤掉用户已经购买过的商品，对于其他的商品，则按照置信度进行排序，从而为用户产生商品推荐。

[1]Rakesh Agrawal,Ramakrishnan Srikant,Fast Algorithms for Mining Association Rules in Large Databases,Proceedings of the 20th International Conference on Very Large Data Bases,p.487-499,September 12-15,1994

[2]Jiawei Han,Jian Pei,Yiwen Yin,Mining frequent patterns without candidate generation,Proceedings of the 2000 ACM SIGMOD international conference on Management of data,p.1-12,May 15-18,2000,Dallas,Texas,United States

[3]Mahout，http://mahout.apache.org/

3.11.3　协同过滤算法

协同过滤是迄今为止最成功的推荐系统技术，被应用在很多成功的推荐系统中。电子商务推荐系统可根据其他用户的评论信息，采用协同过滤技术给目标用户推荐商品。协同过滤算法主要分为基于启发式和基于模型式两种。其中，基于启发式的协同过滤算法，又可以分为基于用户的协同过滤算法和基于项目的协同过滤算法。启发式协同过滤算法主要包含 3 个步骤：1）收集用户偏好信息；2）寻找相似的商品或者用户；3）产生推荐。

「巧妇难为无米之炊」，协同过滤的输入数据集主要是用户评论数据集或者行为数据集。这些数据集主要又分为显性数据和隐性数据两种类型。其中，显性数据主要是用户打分数据，譬如用户对商品的打分，如图 3-4 所示。

图　3-4　某电商网站用户对某商品的评分结果

但是，显性数据存在一定的问题，譬如用户很少参与评论，从而造成显性打分数据较为稀疏；用户可能存在欺诈嫌疑或者仅给定了部分信息；用户一旦评分，就不会去更新用户评分分值等。

而隐性数据主要是指用户点击行为、购买行为和搜索行为等，这些数据隐性地揭示了用户对商品的喜好，如图 3-5 所示。

图　3-5　某用户最近在某电商网站的浏览商品记录（左侧的 3 本书）

隐性数据也存在一定的问题，譬如如何识别用户是为自己购买商品，还是作为礼物赠送给朋友等。

1. 基于用户的协同过滤

基于用户（User-Based）的协同过滤算法首先要根据用户历史行为信息，寻找与新用户相似的其他用户；同时，根据这些相似用户对其他项的评价信息预测当前新用户可能喜欢的项。给定用户评分数据矩阵 R，基于用户的协同过滤算法需要定义相似度函数 s:U×U→R，以计算用户之间的相似度，然后根据评分数据和相似矩阵计算推荐结果。

在协同过滤中，一个重要的环节就是如何选择合适的相似度计算方法，常用的两种相似度计算方法包括皮尔逊相关系数和余弦相似度等。皮尔逊相关系数的计算公式如下所示：

其中，i 表示项，例如商品；Iu 表示用户 u 评价的项集；Iv 表示用户 v 评价的项集；ru,i 表示用户 u 对项 i 的评分；rv,i 表示用户 v 对项 i 的评分；表示用户 u 的平均评分；表示用户 v 的平均评分。

另外，余弦相似度的计算公式如下所示：

另一个重要的环节就是计算用户 u 对未评分商品的预测分值。首先根据上一步中的相似度计算，寻找用户 u 的邻居集 N∈U, 其中 N 表示邻居集，U 表示用户集。然后，结合用户评分数据集，预测用户 u 对项 i 的评分，计算公式如下所示：

其中，s (u,u') 表示用户 u 和用户 u' 的相似度。

假设有如下电子商务评分数据集，预测用户 C 对商品 4 的评分，见表 3-6。

表中？表示评分未知。根据基于用户的协同过滤算法步骤，计算用户 C 对商品 4 的评分，其步骤如下所示。

（1）寻找用户 C 的邻居

从数据集中可以发现，只有用户 A 和用户 D 对商品 4 评过分，因此候选邻居只有 2 个，分别为用户 A 和用户 D。用户 A 的平均评分为 4，用户 C 的平均评分为 3.667，用户 D 的平均评分为 3。根据皮尔逊相关系数公式来看，用户 C 和用户 A 的相似度为：

同理，s (C,D)=-0.515。

（2）预测用户 C 对商品 4 的评分

根据上述评分预测公式，计算用户 C 对商品 4 的评分，如下所示：

依此类推，可以计算出其他未知的评分。

2. 基于项目的协同过滤

基于项目（Item-Based）的协同过滤算法是常见的另一种算法。与 User-Based 协同过滤算法不一样的是，Item-Based 协同过滤算法计算 Item 之间的相似度，从而预测用户评分。也就是说该算法可以预先计算 Item 之间的相似度，这样就可提高性能。Item-Based 协同过滤算法是通过用户评分数据和计算的 Item 相似度矩阵，从而对目标 Item 进行预测的。

和 User-Based 协同过滤算法类似，需要先计算 Item 之间的相似度。并且，计算相似度的方法也可以采用皮尔逊关系系数或者余弦相似度，这里给出一种电子商务系统常用的相似度计算方法，即基于条件概率计算 Item 之间的相似度，计算公式如下所示：

其中，s (i,j) 表示项 i 和 j 之间的相似度；freq (i∩j) 表示 i 和 j 共同出现的频率；freq (i) 表示 i 出现的频率；freq (j) 表示 j 出现的频率；α 表示阻力因子，主要用于平衡控制流行和热门的 Item，譬如电子商务中的热销商品等。

接下来，根据上述计算的 Item 之间的相似度矩阵，结合用户的评分，预测未知评分。预测公式如下所示：

其中，pu,i 表示用户 u 对项 i 的预测评分；S 表示和项 i 相似的项集；s (i,j) 表示项 i 和 j 之间的相似度；ru,j 表示用户 u 对项 j 的评分。

3.Item-Based 协同过滤实例

在电子商务推荐系统中，商品相似度计算有着很重要的作用。它既可用于一些特定推荐场景，譬如直接根据当前的商品，为用户推荐相似度最高的 Top N 商品。同时，它还可以应用于个性化推荐，从而为用户推荐商品。电子商务网站收集了大量的用户日志，譬如用户点击日志等。

基于 Item-Based 协同过滤算法，笔者提出了一种增量式商品相似度的计算解决方案。该算法计算流程如图 3-6 所示。

图　3-6　增量式商品相似度计算流程图

其中，商品关系 i 表示第 i 天的商品关系数据集。

具体计算步骤如下。

1）获取当天用户点击行为数据，过滤掉一些噪声数据，譬如商品信息缺失等。从而得到用户会话 sessionID、商品 ID（商品标识）、浏览时间等信息，如表 3-7 所示。

由于 A4 的浏览时间和 A1、A2、A3 相差较大，因此将其过滤掉，这里定义为 1800 秒，如表 3-8 所示。

2）首先，计算任意两种商品之间的共同点击次数。然后，根据基于条件概率的商品相似度计算方法来计算商品的相似度。商品相似度公式如下。

其中，s (i,j) 表示项 i 和 j 之间的相似度；freq (i∩j) 表示 i 和 j 共同出现的频率；freq (i) 表示 i 出现的频率；freq (j) 表示 j 出现的频率。

3）合并前一天计算的商品相似度数据，进行投票判断，选择相似度较大的作为新的商品相似度，从而实现增量式商品相似度计算。

3.11.4　商品推荐模型总结

对于商品推荐模型，除了上述介绍的基于关联规则和基于协同过滤的算法外，还有其他一些常用的算法，譬如基于内容的算法，即根据商品标题、类目和属性等信息，计算商品之间的关系，然后结合用户行为特征，为用户提供商品推荐。商品推荐模型面临着许多重要问题，譬如特征提取问题，即如何从商品标题、类目和属性中提取商品的重要特征、新用户问题，即如何解决用户行为较少，提升推荐质量、新商品问题，即如何处理长尾商品问题，让更多的商品有推荐展现的机会、稀疏性问题，即对于庞大的用户和商品数据，用户评分数据往往会显得非常稀疏等。面对这些问题，在实际应用中，需要根据业务场景，充分利用各种算法的优点，从而设计出混合推荐算法，以便提升推荐质量。

3.12　数据产品

数据产品是指数据分析师为了响应数据化运营的号召，提高企业全员数据化运营的效率，以及提升企业全员使用数据、分析数据的能力而设计和开发的一系列有关数据分析应用的工具。有了这些数据产品工具，企业的非数据分析人员也能有效地进行一些特定的数据分析工作。因此可以这样理解，数据产品就是自动化、产品化了数据分析师的一部分常规工作，让系统部分取代数据分析师的劳动。

其实，我们每个人在日常生活中或多或少都使用过各种各样的数据产品，有的是收费的，有的是免费的。最常见的免费数据产品，就是我们登录自己的网上银行，来查看自己在过去任何时间段的账户交易明细。如果你有在当当网上的购物体验，那么对当当网账户里的操作应该比较熟悉，如图 3-7 所示，用户可以在「我的收藏」页面针对自己的所有收藏商品进行有效的管理，这也是一种免费的数据产品。

图　3-7　「我的收藏」页面

当然了，上面列举的这些产品更多的是方便用户进行个人财务、商品管理的，还不是专门针对用户进行数据分析支持的。下面这个例子，如图 3-8 所示则是跟数据分析功能相关的数据产品，量子恒道作为淘宝网的一个免费数据产品，可以帮助网商自我进行精准实时的数据统计、多维数据分析，从而为网商交易提供更强的数据驱动力。

图　3-8　量子恒道的分析展示

3.13　决策支持

决策支持是现代企业管理中大家耳熟能详的词汇。数据分析挖掘所承担的决策支持主要是指通过数据分析结论、数据模型对管理层的管理、决策提供响应和支持，从而帮助决策层提高决策水平和质量。

对于现代企业和事业单位的管理层来说，数据分析的决策支持一部分是通过计算机应用系统自动实现的，这部分就是所谓的决策支持系统（Decision Support System，DSS），最常见的输出物就是企业层面的核心日报、周报等。每天会由计算机应用系统自动生成这些报表，供管理层决策参考，另一部分是非常规的、特定的分析内容，包括特定的专题分析、专题调研等。

无论是报表还是专题分析，对于数据分析师来说，所涉及的承担决策支持的工作与支持业务部门的数据分析，在技术和方法上并没有本质的区别和差异。但是在以下方面会有一定的差别：

❑决策支持的数据分析工作要求数据分析师站在更高的角度，用更宽的视野进行数据分析。由于是供企业决策层参考的，所以数据分析师要站在企业全景、市场竞争的全局来考虑分析思路和结论。

❑服务的对象不同。这似乎是废话，但是在数据分析挖掘实践中，这的确也是数据分析师不能回避的问题。在实践中，因为是为决策层服务的，所以对分析的时间要求常会更严格，项目的优先级也会更高，而且对结论的准确性和精确性的要求也会相对比较苛刻。