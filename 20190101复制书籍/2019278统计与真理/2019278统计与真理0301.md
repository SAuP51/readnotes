

## 第 3 章数据分析的原理和策略

数据的交叉检验

3.1 数据分析的发展历史

数据！数据！他急切地叫着，没有黏土，我怎么能做砖.

柯南·道尔（Conan Doyle）

统计分析的形式随时代的推移而变化着，但是「从数据中提取一切信息」或者「归纳和揭示」作为统计分析的目的却一直没有改变。统计学还没有成熟为一个具有完整稳固基础的知识领域。在一定时期内某些统计方法被普遍应用，但是随时间的推移这些方法又会被更时尚的方法所取代。尽管有很多争论，统计方法和应用领域却在不断扩大。具有绘图功能的计算机已经对数据分析产生了巨大的影响。让我们来对数据分析的发展历史作一概述.

通常，描述统计学和理论统计学被人们认为是统计学中方法不同的两个领域。前者的目的是在「统计描述」的意义下综合整理给定的数据集，例如对位置、离差、高阶矩和指数的测量，并通过某些图形，如直方图、条性图、箱图和二维平面图，来表现数据直观醒目的特征。这个方法并不涉及观测数据的随机结构（或概率分布）. 因此，计算得到的各种描述统计量可用来比较不同的数据集合。基于数据集的特征和要解答的问题，甚至制定了一些规则用于选择一些可替换的统计量，如用于描述位置特征的平均值、中位数和众数。这样的统计分析被称为描述数据分析，记为 DDA（Descriptive Data Analysis）. 另一方面，在理论统计学中，虽然其目的也是综合整理数据，但它是研究概率分布下的一个特定分支（或称为模型）. 在这种情形下，综合整理或描述统计量主要依赖于某个特定的随机模型。这些统计量的分布被用来确定在推断某些未知参数时的不确定性的范围。于是这样的方法被称为推断数据分析，记为 IDA（Inferential Data Analysis）.

卡·皮尔森是第一位试图沟通 DDA 与 IDA 的统计学家。他利用基于矩和直方图的描述分析所得到的结果来进行有关分布族的推断。为此目的，卡·皮尔森发明了第一个也许也可以说是最重要的一个检验准则 —— 卡方统计量，以此用于检验已知数据是否来自某一特定的随机模型（概率分布族），或已知数据是否与某一给定的假设一致，这种检验准则「预示了做出决策的一类新方法」. 在哈克英（Hacking，1984）的文献中，卡·皮尔森的卡方检验被誉为是自 1900 年以来在科学 44

第 3 章数据分析的原理和策略 —— 数据的交叉检验

技术所有分支中 20 个①尖端发明之一。甚至和卡·皮尔森有个人分歧的著名统计学家费歇也曾对我表示了对卡·皮尔森的卡方统计量的极高的评价。卡·皮尔森还创立了一系列可通过 4 种矩量来识别的概率分布。通过直方图和卡方检验，卡·皮尔森完成的出色的研究工作之一是发现了在某些动物中锥虫大小的分布是来自两个正态分布的混合分布（参见卡·皮尔森，1914~1915）。

利用卡方检验来检定一个复合假设，例如某一概率分布属于一指定参数的分布族时，需要发展参数估计的一般方法。卡·皮尔森提出了由矩来估计参数的方法，并且基于估计量拟合的分布来进行卡方检验。这个方法其后由费歇做了两方面的完善，一是通过由极大似然法对未知参数的估计，得到已知数据的较好的拟合；其次在估计未知参数时，利用自由度的概念使我们能更准确使用卡方检验。

20~30 年代期间，费歇产生了一系列异常丰富的统计思想。在他 1922 年的一篇通过特定的随机模型来分析数据的奠基性的论文中，费歇奠定了「理论统计学」的基础。费歇发展了基于正态假定下对各种假设的精确的小样本检验，提出了利用标准检验值表来帮助检验，通常这些统计表给出了 5％和 1％时的检验临界值。这个时期内，在费歇的影响下，非常重视显著性检验。当时的统计学家，如哈特林、鲍斯（R.C.Bose）、罗伊（S.N.Roy）和威尔克斯（Wilks）等对精确抽样理论作出了很多贡献。尽管费歇在他 1922 年的论文中提到由卡·皮尔森首先考虑到的模型的设定是统计学研究的一个重要方面，但是他没有对这个问题展开进一步探讨。或许这是因为费歇的观察只是在生物学研究中的小样本范围内，因而在对模型设定问题的探求上，在通过对观测数据的详细描述分析去寻找一定的特征，或是经验地决定合适的数据变换去拟合确认一个假设的随机概率模型等问题上，费歇没有更多的研究广度。在决定模型的设定时，费歇仅依赖于他自身的经验以及如何确定数据时的外部信息.| 参见费歇 1934 年的一篇经典论文。这篇论文论述数据收集确认的方法对频率估计的影响.］在这个由费歇的成果激励统计学发展的时代，很多其他统计学家努力去探索被称为是非参数统计检验的准则，这些检验的分布是与数据所假定的随机概率模型无关的（皮特曼（Pitman），1937），并从数据所设分布的正态性的偏离出发，调查研究费歇所提出的检验准则的稳健性。

20 世纪 20~30 年代，由费歇所开创的通过实验设计来收集数据的方法也有了系统的发展，这一系统发展使人们能够通过方差分析这样特定的方法来分析数据，并能对数据做出有实际意义的解释：实验设计指导如何分析数据，而数据分

①这里所提到的 20 个尖端发明，没有特殊的顺序规定、可记为：塑料，人工智能检验，爱因斯坦的相对性理论，血型，除螽剂，电视，植物的品种改良，通讯系统，抗生素，头盖骨，原子核裂变，避孕药，治疗精神病的药，真空管（电子管），计算机，晶体管，统计学（论述什么是真实，什么是来自偶然性的学问），DNA 和激光.3.1 数据分析的发展历史

45

析显示实验设计的结构.

在统计学发展的初期，其研究的问题多数是从生物学中产生出来的，与此相应，在工业生产中对统计学的应用也小规模地发展起来。休哈特（Shewhart，1931）通过控制图引进简单的图形程序来测验生产过程中的变化，这个方法可以说是对测验异常值或变点的最初贡献

除了在估计理论中一些基本概念之外，费歇提出的很多方法是基于直觉的，并没有系统的统计推断理论，费歇定义了一致性、有效性和充分性的概念，并引进极大似然估计方法。内曼和阿·皮尔森于 1928 年（参见他们的合著论文）讨论了为导出适当的统计方法，特别是在假设检验中要设置一些公理的问题。沃尔德（1950）对这个问题进行了更深入的研究并把其完善为一种决策理论。费歇坚持认为他的方法更适合于科学推断，而内曼和沃尔德的思想更适合于技术的应用，虽然后者声称他们的理论普遍有效。沃尔德在抽样调查的应用中开发了序贯法，费歇认为这个方法也可用于生物学.［在印度统计所所做的一次演讲中，费歇把休哈特的控制图，沃尔德的序贯抽样和抽样调查作为统计方法论中三个重要的发展.」

进入 20 世纪 40 年代后可以看到抽样调查方法的发展，这种方法是调查者依据随机选取的个体对一组问题的反应所获取的信息来收集大量的数据。这种情形下，确保数据的准确性（不带偏差、记录上的错误、反应错误）和数据的可比较性（在各研究者之间，或不同的调查方法之间）这样一些问题被认为是至关重要的。马哈拉诺比斯（Mahalanobis）（1931，1944）或许是第一个认识到在抽样过程中上述提到的偏差、记录误差等是不可避免的，甚至比抽样误差更严重，他提出在设计调查过程时，应该采取一些步骤和方法来控制和查明这些误差，并发展适当的检验程序，在收集数据时检测出过失误差（异常值）和不相容的值.

至此，我们已经简略地介绍了统计学中公认的两个分支 —— 描述统计学和理论统计学。应用统计学者们感到十分需要的是清除那些有缺陷的数据，这样的数据有可能使统计分析所得到的推断无效。这里所需要的可能是一综合处理方法，首先提供分析方法去正确地理解给定的数据及其缺陷和特征，然后去选择数据分析合适的随机概率模型或是模型族，使其不但能解决特殊的问题而且能开发进一步调查研究的新课题。在这个方向上一步重要的发展是由图基（Tukey）在 1962 年和 1977 年的论文中，以及莫斯特雷（Mosteller）和图基俩人在 1968 年的论文中做出的，他们提出了被称为是探索数据分析 EDA（Exploratory Data Analysis）的方法.EDA 的哲学原理是了解数据的基本特征，然后运用稳健过程使数据适应可能的更广义的随机概率模型族，代替寻求什么样的综合统计量对指定的随机概率模型是合适的费歇问题，图基提出求给定一个综合统计量对什么样的随机概率模型族是合适的问题。这个方面也可参考查特非德（Chatfied，1985）描述的初始数据分析，这种分析似乎是描述数据分析的扩展，在最小限度利用传统的统计方法的意义下 46

第 3 章数据分析的原理和策略 —— 数据的交叉检验基于常识和经验做出推断.

图 3.1 展示了统计数据分析的各个步骤，这是基于我自己在分析处理大量数据时所获得的经验做成的，我的这种方法似乎综合了上面提到的卡·皮尔森的描述数据分析、费歇的推断统计和图基的探索数据分析，以及马哈拉诺比斯关于非抽样误差的工作.

图 3.1 中，数据表示测定值（或观察值）的全部集合，如何由实验、抽样或是历

特定问题的模型化

数据收集技术

实验设计

历史资料

随机抽样调查

（已发表的资料）

数据

如何获得新的测量值

辅助变量、专家意见、先验信息

数据的交叉检验（CED）

初始探索检测分析

（异常值、误差、偏差、伪造数据的检

出；数据内在一致性，外在有效性，特

征及有效总体表示的检测）

建模

随机模型的选择或特征化

（交叉核实法：如何利用专家意

见和已有的知识、贝叶斯分

析？）

推断数据分析（IDA）假设检验

估计（点、区间）

决策

媒介分析

综合统计量

图表示

ł.

对进一步调查分析的导向

图 3.1 统计数据分析的步骤 3.2 数据的交叉检验

47

史记录获得数据，与观察记录相关的操作过程，以及任意有关数据性质或数据随

机概率模型的先验信息（包含专家意见）等都包含在内。

数据的交叉检验 CED（Cross Examination of Data）表示任何探索或初始研究都

是为了了解数据的性质，剔除测量误差、记录误差和异常值，检验先验信息的有

效性，检测数据的真伪。数据的初始研究也用于检验一个指定模型的有效性或是

对进一步的数据分析选择一个更合适的随机概率模型或随机概率模型族.

推断数据分析 IDA（Inferential Data Analysis）表示基于对观察数据所选定的

随机概率模型所进行的估计、预测、假设检验和决策推断等统计方法的综合。数据

分析的目的不仅仅只限于解答某些特殊的问题，而是要从数据中获取一切有效信

息。数据中常常含有对新的研究导向有价值的信息，同时含有为收集数据改进未

来的实验设计或样本抽样的有价值的信息。我将数据分析的主要原理用一个基本

方程式明确给出：

数据分析 = 回答特定问题 + 提供新研究方向的信息

图 3.1 所示的数据分析的程序中，不应把数据的交叉检验和推断数据分析作

为适用不同方法的不同的范畴。它仅仅表明当我们面对数据时我们应如何开始、以

什么形式表示最终的结果以及如何应用于实际。推断数据分析的某些结果或许提

示进一步的数据交叉检验，这时也表示推断数据分析的结果会发生变化.

数据分析的一个重要方面是不可使用任何没有被当前数据或过去经验证明的

额外假设。这时出现的问题是：专家的意见在数据分析中起什么作用。我的回答是：

如果专家的意见是正确的，我们可以从中获益；如果不正确，听一

听也无害.

因此，专家的意见在计划一个抽样或设计一个实验时是有用的。

3.2 数据的交叉检验

数字本身不会说谎，但说谎者却需要算计.

格罗夫纳（C. H. Grosvenor）将军

统计学者经常被要求去分析他人所收集到的数据。按费歇的说法，这时，一个统计学者首要的工作是利用数据的交叉检验（CED）（让数字说话的艺术）来获得对数据有意义的分析和用于解释结果的一切必要的信息。在大的范围内对每一个小范畴的特殊需求进行数据交叉检验时，一个可供采用的检查项目有如下几种：

＊数据是如何收集、记录的？

× 数据中含有测量误差和记录误差吗？有关测量值的概念和定义明确吗？观 48

第 3 章数据分析的原理和策略 —— 数据的交叉检验

察值之间存在任何区别吗？

＊数据是真实的，即是所调查的原样，还是以任何方式经过人工伪造、编纂

或修改过的？是否由观察者自行决定删除了任何观察值？数据中是否存在

任何或许会过度影响统计推断的异常值？

＊提供信息的观察数据是来自什么样的实施总体？作为抽样调查总体中所

选定部分是否存在没有回答的（部分或全部）？数据信息是来自单一总体，还

是混合总体？与抽出样本单位的识别和分类有关的因素都记录下来了吗？

＊对所要调查研究的课题或是观察数据的性质是否存在任何先验信息？

通过直接与收集数据的调查者交谈可以得到上述某些问题的答案；但是对其

余的部分，则不得不通过对数据的适当分析来获得答案，即把问题代入数据或是

对数据进行交叉检验来获得答案。这时，通过直方图、二维散点图等数据图示，通

过适当的变换所得的测量值的概率坐标图以及某些描述统计量的计算都是非常有

帮助的，这些都不是例行公事。然而，数据交叉检验成功与否很大程度上依赖于数

据的性质，以及从这些数据（让数字说话）中抽取信息时统计学者本身技能。下面

我将给出几个实例

3.2.1 数据的编撰

让我们来看表 3.1，选自福克斯、霍尔和埃尔夫伯克（J.P.Fox，C.E.Hall 和

L.R. Elveback）所著《防疫学，人类和疾病》一书的第 74 页.

表 3.11846 年法拉岛麻疹流行期发病人数、死亡人数及其年龄分布统计

年龄（岁）

人口

发病人数

发病率（％）

死亡数

死亡率（％）

<1

198

154

77.8

44

28.6

1~9

1440

1117

77.?

3

0）. 3

10-19

1525

1183

77.6

2

0.2

20-29

1470

1140

77.6

4

0.3

30~39

842

653

77.6

10

1.5

40~59

1519

1178

77.6

46

3.9

60~79

752

583

77.5

46

7.9

80 +

118

92

78.0

15

16.3

和

7864

6100

77.6

170

2.8

来源：P. L. Panum：Observations Made During the Epidemic of Measles on the Faroe Islands in

the Year 1846，Delta Omega Society，New York，p.82，1940.

作者们的结论是：「麻疹的发病率虽然在各个年龄组内都很高，但死亡率却有

显著不同。一岁以下是最高的，而过了 30 岁死亡率随年龄增长而逐步上升.」这个

结论有效吗？3.2 数据的交叉检验

49

. .

表 3.1 中值得引起注意的是 8 个年龄组各自的发病率与总体的发病率

77.6％几乎没有差别，或是只有很微小的差别。如果真的发病率对所有年龄组是相

同的，这种现象是偶然发生的吗？这里很值得怀疑的是：各个年龄组的麻疹发病

数不是观察得来的，而是构造出来的。由总发病率 6100/7864=0.776 乘上各组已

知人口数，再四舍五入取最近的整数得到各组的发病数。例如，1 岁以下以及 80

岁以上两个组的发病人数可这样获得：

198×0.776=153.648≈154；118×0.776=91.568≈92·（3.1）

如果用上面的数字去除各组的人口数，即得如下发病率：

154/198=0.7777≈0.778；92/118=0.7796≈0.78·.（3.2）

这些数字与表 3.1 中作者所报告的数字完全一样，同时也说明了为什么表 3.1 中

发病率的小数点第三位略有不同的原因。参考由一个知名的、派往法拉岛去防止麻

疹发病的德国流行病专家的德文版原文报告，帕纳（Panum）指出，相关的发病数

最先并不是按年龄组分类的，而从德语翻译到英语时英语编辑假定各年龄组有相

同的发病率，利用（3.1）式来构造出各年龄组的发病人数。另外，表 3.1 中第 4 栏

标出的发病率一栏英语版第 87 页的表上并未出现，这可能是《防疫学，人类和疾

病》·书的作者福克斯，霍尔和埃尔夫伯克由（3.2）式计算得到的。由此看来，从构

造各年龄组的发病数而得到的各组年龄的死亡率和所得的结果的解释不一定是有

效的。一个统计学者常常被要求去做侦探性的工作！（另外，1~9 岁一组的发病率

应为 77.6％，而不是 77.7％！）

3.2.2 测量误差，记录误差与异常值

在任何大规模调查中，测量和记录上的误差是不可避免的。如果这些值并不

是与其他值有显著的不同，要检测出它们通常是很困难的。因此，在设计调查时，

要特别注意使这样的误差降到最小。在调查测量中当出现一个可疑的数字时，带

有审查的程序会向调查者发出警告，并容许调查者重复测量以及调查被测量的个

体值是否属于被研究的总体.

笔者有机会详察了大量有关人类测量学抽样调查所得的数据。其中有一例是

不得不放弃花高额代价收集来的全部数据（Mukherji，Rao，Trevor（1955）；

Majumdar，Rao（1958）. 当测量多变量响应数据时，如果记录和测量误差的数量不

多，由各个测量值及比值所描绘的直方图，或是由一组变量测量值所得到的二维

散点图以及计算各测量值集合的前四阶矩，偏度 Y 和峰度 2 都可以检测出记录

误差和测量误差。特别足偏度和峰度对异常值很敏感，表 3.2 给出了由不同总体抽

样所获原始数据计算得到的偏度和峰度，一些总体特征在除去极值后再计算了它 50

第 3 章数据分析的原理和策略 —— 数据的交叉检验们的偏度和峰度。各总体的样本大小约为 50. 带有＊号的数字表明在 5％置信水平下是显著的。可以看到，此时除去一个极值后再计算偏度和峰度，结果就与其他情况下所得的一致了.

表 3.2 五个男子部落中一些人类学特征测量值的偏度 Y 和峰度 y2 的统计检验

（选自 Urmila Pingle 的博士论文）

男子部落

特征 KOLAM

ΚΟΥΑ

MANNE

MARIA

RAJ GOND

1

Y2

Y2

2

Y2

72

－.-

头的长度 0.15 －0.62 0.39 0.37 1.62 4.54·0.27 0.48 －0.30 0.23

0.710.29

手的长度－0.14 0.060.48 1.12-0.05-0.08

0.05-0.09 －0.32 0.28

上颚长度 0.83 2.9310.17 0.19 1.72 8.42 －0. 17-0. 63 0.12-0.61

－0.14 －0.03

0.40 0.27

脸的长度－0.26 －（）. 07 0.44 0. 11 0.66 0.32 －0.05-0.10 －0.04-0.24

上臂长度－0.05 －0.63 1.95 6.88-0.01-0.27

0.130.76 0.14-0.40

－0.30 0.74

小臂长度－2.17 9.98-0.07 0.590.19-0.67 －0.020.28-0.06-0.07

0.08-0.62

注：每一特征值的第二行表示除去极值后的计算结果.

简单的图示如直方图和二元平面图能够帮助我们检测数据中的异常值和数据类型。今天，由于计算机高级绘图机能的存在，统计学者们已经能在统计分析中通过各种图形显示来更有效地处理数据.Cleveland（1993）出版了一本较好的关于图形处理技术的参考书，费歇 1925 年在他的《研究者的统计方法》一书中强调了在数据早期检测时图形的重要性。随着图基（1977）的奠基性论文《探索数据分析》的问世，可视性变得更确定、更有效了

3.2.3 数据的伪造

政府对积累统计数字非常热心。政府收集数据，把数据累计相加，进

行 n 次方，开三次方等，并做出漂亮的图形。但决不要忘记的是这些图形

所基于的每一个数字首先来自乡村统计员，这些乡村统计员可随心所欲

地写下任何数据.

斯坦普爵士（花花公子，1975 年 1 月）

越多的欺诈暴露于公众，听到的却是越静悄悄的处理，这不得不使 3.2 数据的交叉检验

51

我们怀疑在科学中欺诈是否是一般的特征.

布罗德和韦德（W. Broad and N. Wade，《真理的背叛者》）

接受一个新的理论，依赖于对观察数据的验证，一个科学家有时会被引诱去编造一些实验数据来拟合一个特殊的理论，从而要求承认他的主张或建立他的优先权。毫无疑问，如果一一个理论是错的，其他做类似实验的科学家们迟早会发现。然而有可能在这个理论被接受的那段时间，社会已受到一些危害。最近一个例子是「智商指数的欺骗（IQFraud）」（《今日科学》，1976 年 12 月，第 33 页.）涉及到伯特（C.Burt），他被称为是英国教育心理学之父。按照伯特的理论，人的智商的差别一般是遗传的，不受社会因素的影响，他的理论明显是由伪造数据所支持，这会影响政府按错误的方向来考虑儿童教育.

如何检测所给出数据的真伪呢？统计学系统中包含有判别数据真伪的数据分析方法吗？幸好回答是肯定的。事实上，最近几年有的统计学者已经检验了过去由某些著名科学家所生成和使用过的数据，并且发现了有些「并不是非常诚实的，那些科学家所得到的数据并不总是他们报告的结果.」霍尔顿（Haldane，1948）指出：

人类是一种常规动物，并不能模仿自然界的无序。

基于人类大脑的这个局限，统计学者已经发展了检验伪数据的技术。笔者曾同统计学专业一年级学生共同进行了下列实验来验证霍尔顿的观察结果。

我让学生做了下列实验，结果见表 3.3.

表 3.3 不同实验的结果

男子数

实际数据

期望值

假想数据

（每 5 个一组）

医院模拟数

（二项分布）

（A）

（B）

（1）

（2）

（3）

（4）

（4）

（6）

2

5

6.25

2

5

26

27

31.25

20

32

2

65

64

62.50

78

63

3

64

68

62.50

80

61

4

31

32

31.25

17

33

5

9

4

6.25

3

6

总数

200

200

200.00

200

200

x2

2.1

2.18

23.87 0.54

（i）投掷 1000 次硬币，5 次一组记录头朝上的数（见表中第 3 栏，模拟数）。

（ii）记录某产科医院连续出生的 200 个婴儿，记录每 5 个一组中男婴的人数

（见表中第 2 栏，医院）. 52

第 3 章数据分析的原理和策略 —— 数据的交叉检验（i）假想你正在投掷一个硬币，记录下想像的 1000 次结果，以 5 个一组记录

正面朝上的数字（见表中第 5 栏，假想数据（A）.

（iv）对一些还没有学习二项分布的学生，我告诉他们假想投掷硬币以 5 次为

一组，什么是我期望的每组中正面朝上的频率分布值（见表中第 4 栏），

然后让这些学生写下他们假想投掷硬币 1000 次，正面朝上的结果（见表

中第 6 栏，假想数据（B）.

由表 3.3 可以看到，自由度为 5 的卡方检验值对实际观察数据与期望值的差是合的。卡方检验值在假想数据（A）的情形下太大，这是于学生想像男女的平衡所造成的，而不是来自随机性地考虑，对假想数据（B）的卡方检验值来说是难以想像的小，这是由于学生努力使数据拟合已知的期望值。

现在我们来看一一下孟德尔的实验所产生的原始数据，基于这些数据孟德尔公式化了性格特征遗传法则，建立了遗传学的基础。费歇在他的一项著名研究中（参见《科学年鉴》，1936 年第一卷，第 115~137 页）检验了这些数据。费歇计算了孟德尔的理论值和多组实验中观察值的差的卡方检验值，其结果列在表 3.4 中.

表 3.4 孟德尔实验产生的观察值与期望值偏差的卡方检验值和概率

检验假设的实验

自由度

卡方值（观测值）

P（x>x6）

比率 3:1

7

2.1389

0.95

比率 2:1

8

5.1733

0.74

双因子

8

2.8110

0.94

遗传比率

15

3.6730

0.9987

三因子

26

15.3224

0.95

小和

64

29.1186

0.99987

植物引起的变动

20

12.4870

0.90

总和

84

41.6056

0.99993

可以看到，表 3.4 中最后一栏每一情形下的概率值都非常大，暗示「为了与理论结果非常接近，数据有可能是伪造的」.5 个实验总体这样好的拟合的可能值仅为

1-0.99993=7/100000

这个值非常小，费歇对这样罕见的偶然发生事件，作了如下评价：

尽管不能期待有任何令人满意的解释，但仍有可能的是孟德尔被他

的某些助手欺骗了，这些助手太了解什么是孟德尔所期望的结果。这种

可能已经由别的独立的实验证实：形成表 3.4 的实验数据的绝大部分，

尽管不全是伪造的，已接近孟德尔的期望.3.2 数据的交叉检验

53

霍尔顿（1948）列举了若干个由遗传学者提出的数据例子，显示这些数据与假

设的理论高度一致。霍尔顿指出，如果一个实验者十分了解一个统计学者使用什

么样的检验来检测伪造的数据，那么这个实验者就可以这样来伪造数据，使这些

数据在统计者的检验里看起来是无可怀疑的，而且在抽样误差的极限范围内证明

他提出的理论。霍尔顿称这种手段为二次伪造。例如，如果一种理论假设两种类型

事件发生的比率为 3:1，那么总是可以选择两个数使其比值既不接近 3:1 也不远

离 3:1，因而与理论值偏差的卡方值不会太大也不会太小。然而，检测出这样的二

次伪造数据的统计方法是存在的.

我曾经要求我的一个科学家同事写出一个有 50 个 H 和 T 的假想序列，来证

明 H 和 T 以 1:1 比率出现的理论，而且不要让两者看起来太接近以免让人生疑。

这个同事给了如下的序列，其中含有 29 个 H，21 个 T.

THTHTHHTHH

THHIITHTIITT

HHTTHTTHHH

ΊΗΗΤΤΗΗΗΤΗ

观测值与假设的 1:1 的理论值之间差的统计量的卡方检验值为

x2=（29-25）/25+（21-25）/25=1.28

与自由度为 1 的卡方值比较，这个值既不太小让人怀疑数据是伪造的，也不太大

以致于否定假设的理论。另外，我们可以看到上面 5 行，每行含有 10 个 H 和 T，

各行含有 H 的数目为 6，6，5，6，6，与偶然情况下所期望的值比较，这些值似乎

过于均匀。实际上，这些值的卡方值为

x2=2/5+2/5+0+2/5+2/5=8/5=1.6

与自由度 5 下的卡方值比较，难以置信的小，显示了所谓的「二次伪造」。

根据韦斯特福尔（R.S. Westfall，《科学》，第 179 卷，第 751~758 页，1973）

的看法：发现万有引力的年轻人牛顿是操纵观测值的行家，他能让观测值正好与

他的计算值吻合。韦斯特福尔在他的文章（Princpia）中，引用了 3 个具体例子。为了

证明地球表面的重力加速度与它轨道上月亮的向心加速度相等，牛顿分别计算了

地球表面的重力加速度为 15 英尺 1 英寸 1 英线

和月亮的向心加速度

15 英尺 1 英寸 1 英线 54

第 3 章数据分析的原理和策略 —— 数据的交叉检验

1 英线 = 1/12 英寸，两者相比，差仅为三千分之一（1/3000）. 声音的速度估计为

每秒 1142 英尺，精确度为千分之一。牛顿并估计了精确度为 500112 的昼夜平

分点，其精确度也为三千分之一。这样高的精确度对牛顿时代的观测技术水平来

说是前所未闻的.

布罗德（W.Broad）和韦德（N.Wade）合著的《真理的背叛》中「历史中的谎言」

一章里还提到了其他著名科学家的名字。这里我引用几段：

＊托勒密（C. Ptolemy）——－被称为是「古代最伟大的天文学家」，他的绝大多数天文观测不是夜间在埃及海岸进行的，而是白天在亚力山大市的大图书馆中进行的。他盗用了一位古希腊天文学家的著作，并不断把这些称为是他自己的研究结果.

＊伽利略 —— 总是被称为近代科学方法之父，这是因为他坚持认为不是亚里士多德的著作而是实验，才是真理的仲裁。但是这位 17 世纪意大利物理学家的同僚们因为非常困难再现他的实验结果，而怀疑他是否真的做了那些实验.

＊道尔顿（J.Dalton）——19 世纪伟大的化学家，他发明了化学链法则并证明了不同种类原子的存在，并发表了一系列高深的实验结果。但是当代的化学家没有一个能再现他所发表的实验结果.

＊密立根（R.Millikan）—— 美国物理学家，由于他首先测量了电子的电荷而荣获诺贝尔（Nobel）奖。但是为了让他的实验结果看起来比实际结果更具说服力，他大量伪造了他的工作.

为什么某些著名的科学家要去篡改事实呢？如果这些科学家更诚实一点儿的

话，会产生什么样的结果呢？（这些疑问是戈士博士提出的。戈士博士曾为印度统计研究所的所长.）

为了回答这些问题，人们必须认识科学发明的几个方而 —— 首先找出事实（数据信息），然后假定一个理论或是一种法则去解释事实和现象，以及科学家们

期望建立优先权去获得同行的承认和由这种承认所得到的利益。当一个科学家确信他的理论时，便存在一种诱惑，使得他去寻找「事实」或歪曲事实以便拟合他自己的理论。在可接受的误差范围内与理论一致的概念，直到假设检验的统计方法出现之前，是不存在的。可以认为：一个与数据信息更接近的结论意味着更准确的理论和更使人信服的证据来使同行接受。由于统计思想的出现，现在我们已经

认识到 —— 过于与数据信息接近的结果，可能意味着是一个伪造的理论！近代，也有很多关于伪造数据来建立错误的假设结果的例子，如前面提到的英国的伯特爵士。这些已经对社会和科学的进步产生了一定的危害.3.2 数据的交叉检验

55

3.2.4 拉查尼（Lazzarini）和 π 的估计

第 1 章中，我已谈到可以怎样利用随机数的蒙特卡罗模拟方法使我们来解决一些数学上很棘手的复杂问题，例如计算复杂的积分、复杂图形的面积、未知参数的估计等等。下面我将叙述蒙特卡罗法的一个有趣的应用，如何对圆的周长与其直径的比率 π 的估计，这里 π=3.14159265··

很多读者已经知道蒲丰（Buffon）针的问题.18 世纪，法国的自然科学家蒲丰计算出随机投挪一根长度为 L 的针到间隔为 a（>）的平行线束时，其针与平行线相交的概率为 p=2L/a. 如果我们随机重复多次投掷一根针，当投掷次数 N 很大、且针与线相交的次数为 R 时，可求出 p 的估计为 R/N，即当 N·∞时，几乎必然成立

R/Np

也就是说当 N 变大时，R/N 一致收敛于 p. 的蒙特卡罗估计值可由渐进方程 R/N≈2 得到（这里给定 L/a），则 x 的一个近似值为

24N

（F）

如果没有任何确定的计算方法时，可从公式（F）得到一个估计值，此时仅需要长度为 L 的一根针和一张描出了间隔为 a 的平行线束的纸，以及相当的耐心去机械地、长时间地投掷一根针.

一些人已有耐心去做过这种实验并报告了他们所得的 π 值。当然，所有的实验并不产生同样的结果，但如果 N 变大时，不同的这些值会很接近，据记载，德国法兰克福的沃尔夫教授在 1850-186010 年间，把－一根长为 36 毫米的针共投掷了 5000 次，平行线束的间隔为 45 毫米，观察到针和线相交的次数为 2532 次。利用公式（F），得到一个 π 估计值为 π=3.1416，其误差为百分之零点六。据说从 1890 年到 1900 年间，一个叫福克斯的人「非常小心地」投掷了 1200 次，得到 π=3.1419. 求得 π 的最准确估计值的是意大利数学家拉查尼（Lazzarini，他的名字常常被参考他的工作结果的后人误拼写为 Lazzerini）. 他在 1901 年的《数学期刊》中详细报告了他所做实验的结果，在 3408 次投掷中，成功了 1808 次，代进（F）方程，得到

3408~m3

利用已知 L/a=5/6，给出 π 的一个估计值为 56

第 3 章数据分析的原理和策略 —— 数据的交叉检验

=03408316×11311=11=3.1415929

这个值与真值的差仅在小数点后第 7 位上.

注意到上述计算过程中所出现的奇妙的数字，由这些数字漂亮地产生出比值 355/113 作为 π 的近似值，这个比值被认为是含有小数的最佳有理近似值（实际上，这个值是公元 5 世纪中国数学家祖冲之算出来的.）元的另一个含有较高位数的有理近似值为 52163/16604.N.T. Gridgeman（Scripta Mathematica，1961）和 T.H. O＇Bcirne（《新科学家》，1961）分别调查了此事，由他们的调查清楚地显示了拉查尼玩的游戏。当 L/a=5/6 时，为了得到比率 355/113，R/N 必须为 113/213. 这就是说，至少要在 213 次实验中，得到 113 次成功，或是在 213K 次实验中成功 113K 次，K 为任意正整数。在拉查尼的情形中 K=16. 这里考虑两种可能，一种是拉查尼一次也没做过他文中详细描述的实验，仅仅报告了他所希望得到的数字。或者，拉查尼做了不止 213 次实验，直到观察得到他所希望的成功次数才停止实验。像拉查尼做的那样重复实验 16 次，得到所希望的成功次数即 113×16 的概率为 1/3.

拉普拉斯在他所著的《概率的理论分析》一书中写到：

值得注意的是，由观察偶然性游戏开始的一门科学竟会已经成为人

类知识中最重要的研究对象，

拉普拉斯并未提到用来获得新知识的技术有时会被操纵用来支持一个错误的主张。或许，他一定想到了通过考察相同的偶然性的游戏，这样的谬误迟早会被发现.3.2.5 除异常值与数据的选择利用

被认为是电子计算机先驱的计算器发明者英国科学家拜比吉（C.Babbage），1830 年在他所著的《关于英国科学衰退的考察》一书中，把某些科学家在处理数据和使用数据时所采取的欺骗态度分为下列儿类：

（i）修饰数据：「修剪那些与平均值有极大差异的观察值，贴补那些看起来与平均值相比似乎太小的值.」

（ii）加工数据：「为了使普通的观测值看起来最正确而采用各种各样的技巧。其中之一就是进行多次重复观察，从中只选择那些一一致的，或非常接近一致的观测值。如果一个厨师不能从 100 个观测值中选择出 15 或 20 个所需要的，他会感到很失望.」

（ii）伪造数据：「从未做过的观测数据记录.」

迄今，我已谈到了伪造数据或无中生有产生的数据。下面，将讨论处理数据中所 3.2 数据的交叉检验

57

出现的异常值和不相容值这样更棘手的问题.

如何处理那些看起来是极值，或换句话说，那些与其他值不一致的观测值呢？处理「异常值」和「污染的数据」这样的棘手问题属于现代研究的领域之一。遗憾的是，除了对上面提到的修饰数据作一些有理化和某些统计上的调整以外，至今人们还没有满意的解决方法。或许，当怀疑存在异常值时，应采取的科学方法是考虑下列几种可能的情形：

＊异常值是测量或记录中一个显著错误的结果.

＊与异常值有关的单位（或个体）并不属于所研究的总体，或者与样本中其

他部分有本质的区别

＊所研究总体的测量值的分布为厚尾分布，因而较大值的出现并不罕见。处理怀疑为异常值的观测值的第一步就是验证总体中有关的部分，如有可能，对照上面列出的情形检查每一个可怀疑的部分。也许可以找到合适的处置方法来处理那些值得怀疑的异常值。偶尔，当再次测量有差异的观测值时，会导致新的发现！然而，当某一观测值被怀疑是异常值时，这样的验证，即回到观测的原点，并不总是可行的。因此，自动检索这样的数据，收集并记录补充信息是很重要的。当不可能对样本单位进行再检验或再检验费用太高时，人们可依赖于纯统计学检验去确定：

＊是否从研究对象的总体中剔除异常观察值，而把剩下的部分作为通常的

样本（有效样本）.

＊是否从研究对象的总体中剔除异常观察值，同时在统计分析的意义下做

出相应的修正.

＊是否接受（「从更哲学的观点上来说」）那些看起来似乎是异常值的观测值

是研究总体中的正常现象，再利用合适的模型进行统计分析，

目前还没有适当的统计方法来处理上述提到的问题，但是统计学者们正在从稳键推断、检出异常值和有影响观察值等各个方向进行这个方面的工作，也许结合由交叉数据检验所得到的信息，可以在推断数据分析中提供－一个统一的理论。这里提供一个例子供读者参考.

下面的例子表明，决定省略或不省略一个异常值或不真实的观察值有时会陷入非常左右为难的境地。假设从期望值为 μ，标准差为 a 的总体中得到 N 个观测值，其样本平均值为 x，又从另一个期望值为、标准差为 a 的总体中得到 M 个值，其样本平均值为 y. 如果忽视 y 来自于污染的观测值这样一个事实，则可用

p= （Nr + My） /（N+ M）

来估计。记－μ=. 如果当 8≤1，且 M=1 与 N 的大小无关时，总有 82<M-1 58

第 3 章数据分析的原理和策略 —— 数据的交叉检验

+N`，则有① E（u-p）2=+M（1+）<V（x）=

在统计学者都知道的最小二乘均方误差标准下，含有一个异常值的总体其均值与

要比较的参数标准偏差相差 1 时，会提高对的估计效果。这样的改进在小样本

的情况下是相当可观的.

3.3 媒介分析

先生：「太阳和月亮中，哪一个更重要？」

学生：「当然是月亮了，因为月亮是在最需要光亮的时候发光.」

在作出决策时，人们不得不考虑到所有有用的证据，其中有的也许是从不同

渠道所获得的多种信息，有的也许是专家们的意见。这时要注意的是以下几个问题：

＊各种信息可信赖的程度如何？

＊各种信息与要调查研究课题的相关程度有多大？

＊各种不同渠道的信息是否一致？

＊从各种渠道获得的信息可能不完全一致时，我们应如何综合利用这些信息来得到一个结论呢？

以上这些问题并不是新问题，但在一次调查研究中通常并没有强调要同时考虑这些问题。所谓媒介分析，其目的就是要尝试系统地来研究这些问题。

对任意问题相关的信息的主要来源是杂志上发表的论文或是来自特别的报告。但这些也许并没有代表对给出问题的所有的研究。例如那些没有获得成功结果

的研究报告是不会发表的。杂志的编辑们阻止发表那些统计显著性在传统检验水

平（如 p<0.05）下没有结果的研究，这些未发表的结果终止在调查者们的文件抽

屉里，而不能用于评论考察。在媒介分析中，拒绝不利结果研究中所提到的有偏性

就是指的文件抽屉问题。已经有一些方法来调整从而最小化这样的有偏性的影响。对每一条信息的评价能够使我们决定这一信息在归纳中所占的比重。但是，综合归纳所要求的各种信息必须互相没有矛盾。最终要选择一个合适的方法使其

能糅合各种信息，同时显示出最后结果的可信赖性。所有这些要求我们慎重利用

有效的统计方法，从数据的精密检查到数据的推断分析，或许也需要能解决问题

①统计学中符号 E（X）表示变量 X 的期望值，V（X）（VAR（X）表示变量 X 的方差。3.4 推断数据分析与结束语

59

的哲学论理，就像前面引用的教师和学生的对话一样.

3.4 推断数据分析与结束语

不知道问题是什么而要回答问题，当然这对任何人来说都是不寻常

的。也就是说，一个人连什么病都不懂，却要去开药方.

尼赫鲁（J. Nehru）

所谓推断数据分析，是基于一指定的随机概率模型来估计未知参数，进行相应的假设检验，预测未来的观测值，以及作出决策等的统计方法。模型的选择也许取决于我们要从数据中所获得的特殊信息。所以，所选择的模型不必要求能解释全部观测所得的数据，而是仅需对指定的问题提供有效的回答。

要回答由客户提出的问题而进行的数据分析并不是统计学者们仅有的工作、为了了解给定数据的性质，要进行更广泛的数据分析，以便发现所拥有的数据能回答哪些问题，从而提出新问题和计划进一步的调查研究.

利用不同的随机概率模型来分析给定的数据并且检验所出现的不同结果，这也是数据分析的一一种很好的实践。这样的过程比对从一个大范围的随机模型族中寻找稳键的推断过程更能说明问题。应该探索在同一组数据下利用不同的模型来回答不同问题的可能性.

在特定模型下进行分析时，有可能显示出数据的一些新的特征，也许会要求对数据分析最初的计划作出一些调整，因而推断数据分析应该是具有交互作用的.

评价某些统计过程的模拟研究，以及在复杂数据结构下用于估计参数估计量方差的自助法（bootstrap）和刀切法（jack-knife）（Efron，1979）均在很大程度上依赖于计算机的应用，尽管在解释这些数据分析的结果时需要谨慎，但这些研究已经给数据分析增添了新的内容.

在数据分析中通常有一种意见认为：一旦保证了模型的有效性则存在分析数据的最优方法，如基于给定的样本，利用ī作为正态分布均值的估计量，或是作为基于无放回抽样基础上的有限总体的均值的估计量。后一种情形的例子可考虑如下：随机选取种植的三棵树为样本来估计一行果树的平均产量。假设随机抽取的三棵树的产量观测值为 x1，x2，x3，则一个可用的估计量为 x=（x1+x2+x3）/3. 然而，如果在随机抽取样本后，我们发现其中相邻的两棵树很接近其所对应的产量的值，如为 x1 和 x2，则我们可提出总体平均值的另一估计量 =（y+x3）/2，这里 y=（x1+x2）/2. 可以看到，在至少选择两棵树相邻的情形中，如果相邻两树的产量是极大相关的，则样本的的方差小于的方差。应该探索开发对在同一随机概率模型下得到的样本数据的不同结构利用不同方法的策略。60

第 3 章数据分析的原理和策略 —— 数据的交叉检验

下面，考察所谓「加尔各答」问题。假设某人毫不了解西孟加拉省的加尔各答

和其余城市和乡镇（以此为计算单位）人口的显著差别，而试图直接从这些无替换

单位中所取的－一个简单样本来估计西孟加拉省的总人口。这种情形下通常所用的

公式为：Nx，N 表示西孟加拉省所含单位的总数，x 为 n 个随机抽样单位的样本

平均值，很多情形下 N 被证明为最优。这里我们假设加尔各答含在随机样本中，

它的人口数高于西孟加拉省任一单位人口数的好几倍。这时，如果假设 N 为全

省人口的估计量将会是一个大灾难，特别是当样本量 n 很小时。如果此时假设

x1 为样本中加尔各答的人口数，则西孟加拉省总人口数的一个合理的估计应为

x1+（x2+…+xn）

我们所做的是：在看到一个特殊观测值集合后进行分层.

统计学者常常被要求对某一数据集合的处理提供合适的统计方法（或者是软

件程序），而没有机会对这些数据做交叉检验，这时我们应该向对方说明：统计处

理不是简单地通过电话开的一张处方，或是在商店柜台买的东西。所收集的数据必

须经过一定的诊断检验，而且如果数据具有某些特殊的特征时，必须要在处理过

程中考虑，在这样的统计处理中还要不断地监视整个过程，以决定是否需要对原

定的处理做出修改.

让我来总结一下。统计分析的目的是「从观测得到的数据中提取所有的信息」

所记录的数据中有时有某种缺陷，如存在记录误差和异常值，有时甚至可能是伪

造的，一个统计学者首先应做的尝试是详细考察或交叉检验数据，以便发现可能

有的缺陷并了解数据的特征。下一步则是利用先验信息和交叉核实技术，对数据

提出一个合适的随机概率模型。基于被选择的模型进行数据推断分析，包括未知

参数的估计，假设检验，对未来观测值的预报以及做出决策。建议在可能的情形

下，利用多个不同的模型来检验数据，比起对可能利用的模型使用稳键过程来说

可以获得更多的信息，数据分析也一定会对提出新问题和计划进一步的调查研究

提供信息

最后，我必须强调统计学家和实验科学家需要合作研究。一个统计学家可以帮

助科学家设计有效的实验以便在科学家提出的问题上获得最多信息，从而使科学

家能检测自己提出的假设，并且在数据产生矛盾迹象时进行修改。就如现代实验设

计之父费歇所指出的：

实验结束后，向一个统计学家咨询的常常是要他提出一个后续的检

验。他或许能指出实验失败的原因.

参考文献

Chatfield C. 1985. The Ititial Examination of Data. J. Roy. Stat. Sco. A，148，214~-253 参考文献

61

Cleveland W S. 1993. Visualzing Data. A'T&T Bell Laboratories, Murray Hill, New Jersey

Efron B. 1979. Bootstrap Methods：Another Look at Jack-Knife. Ann. Statist. 7, 1~26

Fisher R A. 1922. On the Mathematical Foundations of Theoretical Statistics. Philos. Trans. Roy. Soc. 222, 309-368

Fisher R A. 1925. Statistical Methods for Roscarch Workers, Olivia and Boyd

Fisher R A. 1934. The Effect of Method of Ascertainment upon Estimation of Frequencies. Ann. Eugen. 6, 13-25

Fisher R A. 1934. Has Mendel's Work Becn Reddisoovered? Annals of Science 1, 115~-137

Fox J P, Hall C E and Elveback L R. 1970. Epodemiology, Man and Disease. MacMillan Co, London

Hacking Ian. 1984. Trial by Numbers. Science 84，69~70

Haldane J B S. 1948. The Faking of Genetic Results. Eureka 6，21~28

Mahalanobis P C. 1931. Revision of Risley's Anthropometric Data Relating to the 'Tribes and Castes of Bengal. Sankhya 1, 76~105

Mahalanobis P C. 1944. On Large Scale Sample Surveys. Philos. Trans. Roy. Soc., London, Series B, 231，329~451

Majumdar D N and Rao, C. C. R. 1958. Bengal Anthropometric Survey. 1945：A statistical study.

Sankhya,19,201~408

Mosteller F and Tukey J W. 1968. Data Analysis Including Statistics. In：Handbook of Social

Psychology, Vol. 2(Eds. G. Linzey and E. Aronson), Addison-Wesley

Mukherji R K, Rao C R and Trevor J C. 1955. The Ancient Inhabitants of Jebel Moya. Cambridge

University Press

Neymat J and Pearson F S. 1966. Joint Statistical Papers by I. Neyman and E. S. Pearson, Univ.

of California Press, Berkeley

Pearson K. 1914~1915. On the Probability that Two Independent Distributions of Frequency are

really Samples of the Same Population, with Special Reference to Recent work on the Identity of

Trypancsome strain. Biometrika, 10, 85~154

Pitman E J G. 1937. Significance Tests Which May Be Applied to Samples from Any Population. J.

Roy. Statist. Soc. Ser. B, 4,119-130

Rao CR. 1948. The Utilization of Multiple Measurements in Problems of Biological Classification. J.

Roy. Statist. Soc.B, 10,159~203

Rao C R. 1971. Taxonony in Anthropology. In Mathematics in Archeological and Historical

Sciences, Edin. Univ. Press, 329~358

Rao C R. 1987. Prediction of Future Observations in Growth Curve Models. Statistical Sciences, 2,

434~471

Shewart W A. 1931. Fconomic Control of Quality of Manufactured Product. D. Van Nostrand,

New York

Tukey J. 1962. The Future of Data Analysis. Ann, Math. Statist., 30,1~67 62

第 3 章数据分析的原理和策略 —— 数据的交叉检验

Tukey J. 1977. Exploratory Data Analysis( EDA). Addison Wesley

Urmila P. 1982. Morphological and Genetic Composition of Gonds of Central India：A statistical

study, Ph. D. Thesis, Submitted to Indian Statistical Institute

Wald A. 1950. Statistical 1)rrision Funrtions. Wiley, New York

本章没有引用的附加参考文献

Andrews D F. 1978. Data Analysis, Exploratory. In：International Encyclopedia of Statistics（W.

H. Kruuskal and J. M. Tanur, ed. ）97~106. The Free Press, New York

Anscombe F J and Tukey J W. 1963. The Examination and Analysis of Residuals. Technometrics,

5,141-160

Bertin J. 1980. Graphics and Graphical Analysis of Data. DeGruyter, Berlin

Mallows C L and Tukey J W. 1982. An Overview of The Techniques of Data Analysis, Emphasizing

Its Exploratory Aspects. In：Some Recent Adavances in Statistics, 113~172, Academic Press Rao C R. 1971. Data, Analysis And Statistical Thinking. In：Economic and Social Development,

Fssays in Horor of C. D. Deskmukh, 383~392（Vora and Company)

Watcher K W and Straff M L. 1990. The Future of Meta Analysis, Russel Sage Foundation 