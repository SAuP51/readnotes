# 
> 2018000模板


Notes


I have too many colleagues and friends to thank properly. This book was improved by conversations about modeling with Eric Ball, Andrea Jones-Rooy, Michael Mauboussin, Carl Simon, John Miller, Lu Hong, Helene Landemore, Jim Johnson, Skip Lupia, Josh Berke, Patrick Grim, Bob Axelrod, PJ Lamberson, Jessica Steinberg, Jessica Flack, Charlie Doering, Michael Ryall, Robert Deegan, Jay Grusin, Sarah Silvestri, Zev Berger, Ken Kollman, Jean Clipperton, Michael Barr, Benjamin Bly, Elizabeth Bruch, Abbie Jacobs, Mark Newman, Cosma Shalizi, Kent Myers, and Josh Cooper Ramo. I would also like to thank the Guggenheim Foundation for funding a sabbatical as well as the faculty, staff, and students at INSEAD and the people of Fontainebleau, France. In Ann Arbor, the staffs at Lab Cafe, Mighty Good Coffee, and all four Sweetwaters Coffee and Tea locations provided coffee and quiet support. This book has also benefited from online conversations with thousands of people who gave feedback through Model Thinking. My agent, Max Brockman; editor, TJ Kelleher; and Melissa Veronesi kept me focused over the final year. Mita Gibson and Linda Wood provided unending support and encouragement, covering for my many lapses in scheduling as well as demonstrating facility with the printer, and, in the final stages, Lucy Fleming and John Burt solved vexing typesetting issues.





Chapter 1: The Many-Model Thinker


1 See, for example, O’Neil (2016) for an account of how simple models based on data can ignore some segments of the population and can ignore the adaptive feedbacks we discuss Chapter 4.

2 See Paarsch and Shearer 1999, which analyzes the timber industry. Raw data on tree planting shows that the piece rate is negatively correlated with the number of trees planted; the more someone is paid to plant a tree, the fewer trees that person plants. The inference runs counter to standard economic logic. If you pay planters more per tree, they should work harder. In Paarsch and Shearer’s model, timber companies pay workers a per-tree piece rate so that the hourly market wage equals $20 an hour. That assumption results in the following equation for dollars per tree:

$20 = Number of Trees Planted per Hour × Dollars per Tree.

If a person can plant ten trees in an hour, then the pay per tree will equal $2. If a person can plant twenty trees in an hour, then the pay per tree will be $1. Thus, the model predicts that the piece rate will be negatively correlated with the number of trees planted. It also predicts that the piece rate times the number of trees will equal a constant.

3 For evidence on models outperforming people, see Dawes 1979, Tetlock 2005, Silver 2012, and Cohen 2013. See Kahneman 2011 on biases.

4 See Slaughter 2017 and Ramo 2016.

5 Studies show that the most impactful research and patents disproportionately draw ideas from multiple disciplines. An analysis of 35 million papers shows that in the long run, interdisciplinary papers have greater impact (Van Noorden 2015). A combination of ideas is not necessarily a combination of models, but in many cases it is; see Jones, Uzzi, and Wuchty 2008 and Wuchty, Jones, and Uzzi 2007. Freeman and Huang 2015 show that ethnic diversity also correlates with citations. If we interpret patents as evidence of innovation, then two separate strands of research link diversity of thinking to success. Shi, Adamic, Tseng, and Clarkson 2009 show that patents that cross categories produce more citations. Youn, Strumsky, Bettencourt, and Lobo 2015 show that a majority of patents include multiple subcategories. Interdisciplinary research has increased steadily to the point where, on average, social scientists cite more papers from other disciplines than from their own.

6 See Box and Draper 1987.

7 See Page 2010a.

8 I am not equating knowledge with models. I am claiming that models can represent knowledge and provide a clear way to communicate those understandings. The term “knowledge” encompasses rather broad terrain and includes physically embedded and tacit skills such as how to play tennis, speak French, or negotiate a contract. I apply a narrower definition. For a broader conception, see Adler 1970.

9 You can arrive at this approximation by noting that falling skydivers reach terminal velocities of 200 mph. Terminal velocities scale with the inverse of mass. Assume that a skydiver has a mass 400 times larger than the stuffed cheetah. The square root of 400 equals 20. Therefore, the terminal velocity of the stuffed cheetah will equal 200 mph divided by 20, or 10 mph.

10 He was correct. For the record, Fresno is 30% larger than Iceland. Ball and LuPima 2012 describe how one can take lessons from the academy to the business world.

11 See Lo 2012. For a general argument see Myerson 1992.

12 Versions of this story can be found in the writings of William James, Stephen Hawking, and Antonin Scalia.





Chapter 2: Why Model?


1 See Epstein 2008 for a finer categorization of reasons to model. Lave and March (1975) describe three categories of use: to explain empirical phenomena, to predict other, new phenomena, and to build and design systems. Implicitly, they also advocate using models to explore.

2 See Harte 1988. This categorization borrows from Johnson’s 2014 treatise on the uses of models in the social sciences. These two approaches are also known as the Galilean and minimalist idealizations. See Weisberg 2007. For more on analogies, see Pollack 2014 and Hofstadter and Sander 2013; the latter refers to analogies as the “fuel and the fire” of thinking. See also Schelling 1978, 87, for elaboration on classes of models. Daniel Little’s blog, Understanding Society, provides an entree into the topic of the ontology of social science.

3 See Arrow 1963. A collective ranking is possible if we limit the possible individual rankings. If, say, everyone had the same ranking, then the collective would as well. In general, we have no way of mapping individual rankings to a coherent collective ranking.

4 The best minds of my generation surely noticed that I borrowed “this actually happened" from Howl. See Bickel, Hammel, and O’Connell 1975.

The figure below shows one of many possible examples of adding a node and reducing total edge length. The network on the left shows four points as corners of a square. The one on the right includes a fifth point in the center. If we set the length of a side of the square to 1, the edges in the graph on the left have a total length of 3, and those on the right have a total length equal to 4 · 0.71, which is less than 3.





Simpson’s paradox arises when there are more men than women who apply to departments with higher admission rates. For example, consider a university with a medical school and a veterinary school. Suppose that 900 men apply to medical school and 480 (or 53%) are accepted, that 300 women apply and 180 (or 60%) accepted, that 100 men apply to veterinary school and 20 (or 20%) are accepted, and that 300 women apply and 90 (or 30%) are accepted. In each school, a larger percentage of women are accepted, but overall, 50% of men (500 out of 1,000) while only 45% of women (270 out of 600) are accepted.

For an example of Parrondo’s paradox, suppose that the first bet always loses $1 and the second bet loses $2 in any period whose number is not divisible by three but wins $3 in periods 3, 6, 9, 12, etc. Each bet produced an expected loss, but if you make the second bet only in the periods when it wins and make the first bet in the other periods, you will win $1 every three periods.

5 See Kooti, Hodas, and Lerman 2014.

6 Suppose that each person makes the same income I and pays a constant tax rate of t. Let c denote the percentage reduction and r denote the increase in income. Current government revenue equals I · t. After the tax cut, revenue equals I(1+r)·t(1−c). Revenue will increase if and only if I ·t < I(1+r)t(1−c). Rearranging terms gives r > c(1 + r).

7 See Ledyard, Porter, and Wessen 2000 for a market-based mechanism that produces a better solution to multidimensional payload problems.

8 I borrow the adjective “unreasonable” from physicist Eugene Wigner (1960), who described the mathematical models used in the physical sciences as unreasonably effective.

9 See Ziliak and McCloskey 2008 for a discussion of the ability of social science models to explain variation.

10 See Porter and Smith 2007 for a history on the spectrum auction.

11 See Squicciarini and Voigtländer 2015. See Mokyr 2002 for a full historical account of the importance of knowledge transfer.

12 See www.treasury.gov/initiatives/financial-stability/Pages/default.aspx.

13 For example, during the mid-1990s, about 60% of the restaurants that opened in Columbus, Ohio, failed. None received a government bailout, nor should they have. A healthy market economy includes failures. See Parsa et al. 2005.

14 Taken from the IMF’s 2009 Global Financial Stability Report. The strength of a connection was based on the correlation in portfolio values. That correlation was based on extreme events; days on which the institutions performed particularly well or particularly poorly. This measure was thought to capture the likelihood of one failure spreading to another. In point of fact, the correlations in performance could result from similarities in investment portfolios as well as one bank holding assets in another.

15 See Geithner 2014.

16 See Weisberg 2012 for a description of the San Francisco Bay model and its usefulness in policy.

17 See Stone et al. 2014 for a full account.

18 I thank Josh Epstein for the first example.

19 See Dunne 1999 and Raby 2001.





Chapter 3: The Science of Many Models


1 Levins 1966.

2 See Page 2007, 2017 for more detailed descriptions and derivation.

3 See Suroweicki 2006 on the wisdom of crowds; Tetlock 2005 on how foxes outperform hedgehogs; Kalyvas 1999 on the failure of political science to predict the fall of the Soviet Union; and Patel et al. 2011 on ensemble methods in computer science.

4 Hong and Page 2009 show that independent models require a unique set of categorizations. That is, there exists only one way to create a set of independent predictions in a binary category model.

5 See three of my earlier books—The Difference (Page 2008), Diversity and Complexity (Page 2010), and The Diversity Bonus (Page 2017)—for elaboration on the diversity prediction theorem. For data on economic predictions, see Mannes, Soll, and Larrick 2014.

6 Consider the four bungalows A, B, C, and D in the figure below, along with their market values. Create two categories based on whether or not the bungalow contains a recording studio denoted by a circle above the door). Bungalows A and B do not contain recording studios, so they belong to one category, while bungalows C and D do contain studios, so they belong to the second category.





Four Bungalows and Their Market Values

We first compute the total variation in the bungalows’ prices. This equals the sum of the squared differences from each value to the mean. We make all calculations in units of $1000. The mean value of the four bungalows equals 400, so total variation equals 100,000: Total Variation = (200 − 400)2 + (300 − 400)2 + (500 − 400)2 + (600 − 400)2 = 100, 000.

To calculate the categorization loss, we assume that we know the true mean within each category: $250,000 for the first category and $550,000 for the second category (the bungalows that have been turned into recording studios). The categorization lumps together houses of different values. That remaining variation equals the categorization loss: Categorization Loss A & B = (200 − 250)2 + (300 − 250)2 = 5, 000 and Categorization Loss C & D = (500 − 550)2 + (600 − 550)2 = 5, 000. The total categorization loss equals the sum of these two numbers, or 10,000.

To compute valuation error, assume that the model predicts prices of $300,000 for bungalows A and B and $600,000 for bungalows C and D. Valuation error equals the squared differences between the predictions for each category and the true mean. Valuation error A & B = (300−250)2 + (300−250)2 = 5, 000 and Valuation Error C & D = (600 − 550)2 + (600 − 550)2 = 5, 000. The total valuation error equals 10,000.

Total model error equals the squared differences between the predictions and the actual values: Model Error = (200 − 300)2 + (300 − 300)2 + (500 − 600)2 + (600 − 600)2 = 20, 000. Notice that the model error equals the sum of categorization loss and valuation error.

7 See Brock and Durlauf 2001 for a spin-glass model of social interactions in two dimensions. Glaeser, Sacerdote, and Schenkman 1996 have a one-dimensional model used to examine crime. Fudenberg and Levine 2006 construct an economic model of the brain.

8 Niarchos was not the first shipper to attempt to exploit scale. In 1858, Isambard Kingdom Brunel, the legendary British engineer who built the Great Western Railway, launched a nearly 700-foot-long ship, the SS Great Eastern. That ship proved a failure. A lack of hydrodynamic models resulted in a poor overall design. The boat proved seaworthy at only the slowest of speeds. It finally found use laying transatlantic cables. See West 2017 for how multiple models aid in designing ships.

9 BMI can also be written as 703 times weight (in pounds) divided by height (in inches) squared.

10 LeBron James stands 6 feet 8 inches and weighs around 250 pounds, giving him a BMI of 27.5. Kevin Durant, who stands 6 feet 9 inches and weighs 235 pounds, has a BMI of 25.2. Aston Eaton, the 2012 and 2016 Olympic decathlon gold medalist, measures 6 feet 1 inch and weighs 185 pounds, resulting in a BMI of 24.4, on the cusp of being overweight. His predecessor, 2008 Olympic decathlon gold medalist Brian Clay, had a BMI of 25.8.

11 See Flegal et al. 2012.

12 We assume a mouse 3 inches long, 1 inch high, and 1 inch wide, and an elephant 10 feet tall, 10 feet long, and 5 feet wide. The elephant has a surface area of 400 square feet, or 57,600 square inches. The elephant has a volume of 500 cubic feet, which equals 864,000 cubic inches.

13 Geoffrey West and colleagues have constructed more elaborate and accurate models that predict that metabolism should scale with mass raised to the three-quarters power. See West 2017.

14 Controlled experiments that send identical resumes but change the name demonstrate that women receive lower salary offers and lower evaluations than men (Moss-Racusina et al 2012).

15 The probability of a man becoming CEO equals the probability he receives fifteen promotions in a row, or . The probability that a man becomes a CEO relative to a woman, the likelihood ratio, equals . Given our assumptions of 50% and 40%, the likelihood ratio equals (1.25)15 = 28.4.

16 See Dyson 2004.

17 See Breiman 1996.





Chapter 4: Modeling Human Actors


1 See Haidt 2006.

2 Assume the individual has a budget of M, that the price of one unit of the consumption good, C, is $1, and that the price of one unit of housing equals PH. We can write her budget constraint as M = C + PH · H. This implies C = M − PH · H, so that we can then write her utility as a function of H.





To find the H that maximizes utility, we take the derivative with respect to H and set it equal to zero. This requires applying the chain rule for derivatives.





Moving the first term to the other side of the equation and then cross multiplying gives the following:

2PH · H = (M − PH · H)

Substituting 2PH · H for (M − PH · H) in the budget constraint gives M = 2PH · H + PH · H, or that M = 3PH · H. It follows that the individual spends of her income on housing.

3 In the United States, this is a close approximation. Source: US Bureau of Labor Statistics 2013.

4 The formal theorem is written as follows: Let X = {A, B, C,…, N} denote a finite set of outcomes, and let a lottery be a probability distribution over outcomes: L = (pA, pB,…, pN). If preferences () over lotteries satisfy completeness: any two lotteries, L and M, can be compared; transitivity: if L M, and M N, then L N; independence: if L M, then given any lottery N and any probability p > 0, the lottery pL + (1 − p)N pM + (1 − p)N; and continuity: if L M and M N, then there exists a probability p such that pL + (1 − p)N ∼ M, then preferences can be represented by a continuous utility function that assigns a real number, that is a utility, to each lottery. A sketch of the proof goes as follows: Assume that there exists a best outcome, B, and a worst outcome, W. Set the utility of B equal to 1 and the utility of W to zero. Given any other outcome A, by the continuity axiom, there exists a probability p that makes a person indifferent between receiving A for sure and receiving B with probability p and W with probability (1 − p). We write this as A ∼ pB + (1 − p)W. We then assign a utility of A equal to p. A little introspection (and a bit of math) shows that the more a person likes an outcome (or lottery), the larger p will be. And almost by magic, we have turned rankings into numbers. For a complete proof, see Von Neumann and Morgenstern 1953.

5 See Rust 1987.

6 See Camerer 2003.

7 See Harstad and Selten 2013.

8 See Myerson1999 on the use of rational choice as a benchmark.

9 See Camerer, Loewenstein, and Prelec 2005 for an early survey.

10 See Kahneman 2011 for an overview of this research.

11 The original paper by the Open Science Collaboration (2015) has led to more attempts at replication showing similar percentages.

12 See Medin, Bennis, and Chandler 2010 for the need for greater diversity in subject pools.

13 See Berg and Gigerenzer 2010. They give full voice to this line of criticism, arguing that it undermines mathematically based psychological models.

14 Kahneman and Tversky 1979.

15 Gain frame: Treatment A will save 40% of the patients for certain. Treatment B has a 50% chance of saving everyone. Loss frame: Treatment A′ will cause 60% of the patients to die for sure. Under treatment B′, there is a 50% chance that no one dies and a 50% chance that everyone dies. According to prospect theory, most doctors choose treatment A in the gain frame and B′ in the loss frame.

16 See Thaler 1981 and Laibson 1997 for early papers on the implications of hyperbolic discounting.

17 The formula for hyperbolic discounting can be written in the more general form





18 See Gigerenzer and Selten 2002.

19 See Gode and Sunder 1993.

20 See Gigerenzer and Selten 2002.

21 In his Nobel Prize lecture, Vernon Smith notes that “Ecological rationality uses reason—rational reconstruction—to examine the behavior of individuals based on their experience and folk knowledge. People follow rules without being able to articulate them, but they can be discovered.” See Smith 2002.

22 See Arthur 1994.

23 See Lucas 1976 and Campbell 1976.

24 See de Marchi 2005 for a discussion of how models illuminate what could happen. See Gilboa and Schmiedler 1995 and Bednar and Page 2007, 2018 for equation- and rule-based models in which actors apply behaviors in similar games.





Chapter 5: Normal Distributions: The Bell Curve


1 Given a set of data {xi,…, xN}, the variance equals the average squared distance to the mean, μ, which is written as:





The standard deviation equals the square root of the average squared distance to the mean, μ:





2 Any of several conditions are sufficient. One of the more common, the Lindeberg condition, requires that the proportion of the total variation that comes from any one variable will converge to zero as the number of variables grows large.

3 See Lango et al. 2010.

4 For the general case, assuming independent random variables, we have the following expressions:





Setting σi = σ for all i gives

5 Wainer 2009 provides a more thorough analysis of the policy choices involved.

6 The threshold of two standard deviations (5% significance) is a convention open to criticism, but it is what social scientists generally use. A large coefficient significant at the 6% level is likely more worth noting than a small coefficient at 4.9% significance. See Ziliak and McCloskey 2008.

7 See Gawande 2009.

8 Distributions of products of random variables are called lognormal because the logarithm of the distribution will be normally distributed. A sketch of the logic as to why goes as follows: First, we write a product of numbers, y = x1 · x2 · x3 ··· · xn, as a product of terms written as powers of 10:





We then take the logarithm base 10 of both sides to obtain the following:

log10(y) = log10(x1) + log10(x2) + log10(x3) + ··· + log10(xn)

Thus, the logarithm of the variable y can be written as the sum of the logarithms of random variables. The logarithms of those random variables are also random variables, and so long as their variances satisfy the conditions of the central limit theorem, their sum, which is log10(y), will be normally distributed.

9 See Limpert, Stahel, and Abbt 2001.

10 This idea can be traced back to Gibrat 1931.





Chapter 6: Power-Law Distributions: Long Tails


1 See Parrish 2017 for an account of the impact and cultural meanings of this flood.

2 This numerical example assumes an exponent of 2 and is borrowed from Clauset, Young, and Gleditsch 2007.

3 For a technical description of the models presented in this chapter as well as references to many examples of power laws, see Newman 2005.

4 See Newman 2005 and Piantadosi 2014 for surveys.

5 The constant C makes the total probability over all outcomes equal to 1. Given this definition, power-law distributions satisfy scale invariance. If we change the units with which we measure outcomes, the shape of the distribution does not change.

6 These probabilities can be calculated by first solving for the probability of the event not happening within a year. If an event has probability , the probability of that event not happening within a year equals (0.999)365 = 0.69. So the probability of that event happening equals 31%. The probability of a one-in-a-million event not happening in a century is calculated similarly.

7 See Cederman 2003; Clauset, Young, and Gleditsch 2007; Roberts and Turcotte 1998. The probability of a terrorist act with x deaths can be written as a constant term of approximately .06 divided by x squared. For a discrete distribution where x only takes on integer values, the power-law distribution can be written p(x) = 0.608x-2. The coefficient 0.608 is chosen so that the probabilities sum to 1: = 1.644934. The product of 0.608 and 1.644934 equals 1.

8 For the power law, we take logs of both sides and transform y = Cx-a into log(y) = log(C)−alog(x), a linear equation for log(y) in terms of log(x). When we plot the values of log(y) and log(x) we obtain a straight line. For an exponential distribution, y = C ·A-x. If we take logarithms of both sides, we obtain log(y) = log(C) − xlog(A), which means that log(y) is linear in x. That means that log(y) will decrease rapidly in log(x), creating a concave graph.

9 If we take the logarithm of a lognormal distribution, we obtain an equation of the following form: log(y) = C − b · log(x) − , where σ is the natural logarithm of the standard deviation of the lognormal distribution, a proxy for the variance of the distribution. For large σ the contribution of log(x)2 will be small until log(x) becomes sufficiently large value to cause a downturn in the graph.

10 To see how to formally distinguish between a lognormal and a power law see Broido and Clauset (2018), who show that many networks thought to have power-law distributions may not.

11 See Piantadosi 2014 for a survey of Zipf’s law in word frequencies and a range of candidate models. If the event size distribution satisfies a power law, then so too do the ranks. A general proof goes as follows: A power-law distribution with exponent a on the open interval [1, ∞) has the form pa(x) = ax-a. Assume 100 events. Let SR denote the expected size of the Rth largest event. The probability of an event larger than SR must equal . For example, if R = 3, then the probability of an event larger than S3 must equal 3%. Therefore,





Solving gives , which can be rewritten as:





In the special case where a = 2, this expression becomes .

12 See Bak 1996. How widely the model applies remains an open question. Scholars have used the concept to explain economic fluctuations, war deaths, terrorist acts, punctuated equilibria in evolution, and traffic jams. See, for example, Paczuski and Nagel 1996, Sneppen et al. 1995.

13 See Salganik, Dodd, and Watts 2006 for the original study, and Ormerod 2012 for an alternative analysis. A power-law distribution also implies a multitude of small events that constitute a large portion of the probability distribution. These small events can combine to produce economic value of the same magnitude as the large events. See Anderson 2008b. The internet has made it possible for retailers to stock enormous catalogs of books, movies, and music even though some items appeal to small numbers of people. A publisher that sells 5 million copies of a best-seller earns the same revenue as a publisher that sells 500 copies each of 10,000 different books.

14 For a specific model that shows how this could arise, see Denrell and Liu 2012.

15 Geologists measure earthquake magnitudes using the Richter scale, which equals the logarithm of the size. An earthquake measuring 6 on the Richter scale is ten times as large as an earthquake measuring 5. See Merriam and Davis 2009 on using Zipf’s law to predict earthquake sizes but not their timing.

16 See Eliot, Golub, and Jackson 2014 for an explicit model of how increasing connectedness can lead to a decreased likelihood of failure.

17 See May, Levin, and Sugihara 2008 for the full argument.

18 See Stock and Watson 2003.

19 The following explanation summarizes Carvalho and Gabaix 2003.

20 See Clarida, Galí, and Gertler 2000.

21 I thank Seth Lloyd for bringing this example to my attention.

22 We let distribution of salaries equal $100,000 times a random variable x with p(x) = 2x-3 from 1 to ∞. The variable x has a mean equal to 2, so the salary distribution has a mean value of $200,000.

23 See Weitzman 1979 for a model showing this result in more generality.

24 See Bell et al 2018.





Chapter 7: Linear Models


1 Valuable vintages, such as Bordeaux wines, receive rankings by experts. These wines also get priced in the marketplace. Prices and rankings can function as proxies for quality. Ashenfelter has fit (log) linear models for Bordeaux quality based on the amount of the winter rainfall, harvest rainfall, and average temperature in September. See Ashenfelter 2010. A log linear model expresses the logarithm of the dependent variable as a linear sum of the logarithm of the independent variables:

log(y) = b0 + b1log(x1) + b2log(x2)

This expression implies that the dependent variable can be written as a product of the independent variables. We can see this by making each side of the equation the exponent of e, resulting in the following equation:





By taking logarithms, multiplication becomes addition and one can apply the tools of linear regression. Using the price of the vintage as the dependent variable, Ashenfelter’s model has an R-squared (that is, the percentage of variation that is explained) of 83%. Evidence shows it predicts wine prices more accurately than the judgments of more qualitative wine experts. His model even predicts changes in experts’ assessments. Robert Parker, a well-known wine evaluator, initially assigned scores of 95 (out of 100) to the Pomerol and St. Emilion 1975 vintages. Ashenfelter’s model predicted lower quality rankings. In 1983, Parker lowered his rankings to below average, as Ashenfelter predicted. See Storchmann 2011.

2 See Xie 2007.

3 See Ryall and Bramson (2013) for an introduction to causal models.

4 Mauboussin 2012 shows how the equation can guide sound managerial decision-making.

5 See Bertrand and Mullainathan 2001.

6 See Shapiro, Meschede, and Osoro 2013. They are not conflating correlation and causality here. If two variables are not correlated, then we should not expect a causal relationship.

7 To find the best line to classify data, many analysts use support vector machines (SVMs), an approach similar to regression. The key difference is that SVMs find the line that maximizes the distance to the closest points in each set that separates the data into positives or negatives. If no such line exists, as will often be the case, penalties are assigned to violations. Regression, by comparison, considers the distance to all of the data points and minimizes total distance.





Chapter 8: Concavity and Convexity


1 See Arthur 1994.

2 Thirty doublings equals 230, which exceeds 1 billion.

3 See Karlsson (2016) for contextualization of Escobar’s hippos.

4 See Ebbinghaus 1885.

5 Brain researchers have found that even with chocolate, there exists an amount of consumption at which people begin to form an aversion (Small et al. 2001).

6 This, like many examples, I borrow from Lave and March 1975.

7 Suppose that you invest $3,000 a year. If the stock were a constant $15, then you could buy 200 shares each year. If the price alternated between $20 and $10, then in the high-price years you could buy 150 shares, and in the low-price years you could buy 300 shares. On average, you could buy 225 shares, which is more than you could buy with constant prices.

8 The key assumption is that the exponents in the Cobb-Douglas production function, a and (1 − a), sum to 1. This implies that if we double the number of workers and the amount of capital, total output also doubles.

Output = Constant · (2 · Workers)a(2 · Capital)(1−a)

Expanding terms and some rearranging gives a doubling of output:

Output = 2 · Constant · WorkersaCapital(1−a)

9 Output per day in the second year equals 100 = 141. In the third year, it equals 100 = 173. The growth rate equals the percentage increase in output from year to year.

10 The calculations are as follows: Year 2: machines: 290, output: 1,702 (= 100). Investment = (0.2) · 1702 = 340, so consumption = 1362. Depreciation = (0.1) · 290 = 29. Year 3: machines: 601, output: 2,453 (= 100). Investment = (0.2) · 2453 = 491, so consumption = 1962. Depreciation = (0.1) · 601 = 60.

11 The long-run equilibrium can be solved for by solving for M∗, such that 0.2 · 100 = 0.1M∗. This occurs at M∗ = 40, 000.

12 The full Solow model replaces the square root functions with a parameter a, as in the Cobb-Douglas model, and also includes a labor market.

13 To solve for the equilibrium, we set investment equal to depreciation: . Therefore, the equilibrium number of machines K∗ satisfies the equation . Placing this back into the output function, output equals .

14 Gordon (2016) takes the pessimistic view that new technologies on the horizon will produce a large increase in A. More advanced growth models make technology a function of other variables. A model by Paul Romer (1986) assumes that growth arises from an increased variety of goods: as the economy grows, so does variety. Weitzman (1998) explicitly models the generation and recombination of ideas.

15 See Arthur 2011 on lags in technology.

16 For example, countries that never connected rural villages with telephone lines were able to build radio towers and provide cell phone service. Gerschenkron (1952) refers to this as the advantage of backwardness.

17 Easterly and Fischer 1995.

18 Piketty 2014 shows that world GDP has grown only 1.6% on average from 1700 to 2012 and that half of that growth is due to population growth. Applying the rule of 72 to an 0.8% growth rate, we find that over a 300-year period average standards of living increase about 10-fold.





Chapter 9: Models of Value and Power


1 This value is found by multiplying the probability of the rower adding value times the rower’s expected added value, which equals · 10 plus · 2. Note that the Shapley values sum to 10, the total value of the game.

2 Formal calculations are as follows: Of Arun’s six ideas, two are unique, one is also proposed by Betty, and three are proposed by everyone. If he enters first, which occurs with probability , he adds value 6. If he enters second, he adds two unique ideas, none of the ideas shared by all three, and has a one-in-two chance of arriving before Betty and adding one more idea. So, he adds 2.5 ideas. If he arrives third, he adds his two unique ideas. Thus, his Shapley value equals 3.5. Betty proposes four ideas shared with one other person and three proposed by everyone. Therefore, her Shapley value equals 3. Finally, Carlos proposes three ideas proposed by one other person along with the three proposed by everyone. His Shapley value equals 2.5. Note that the Shapley values sum to 9, the total number of ideas.

3 An alternative measure of voting power, the Banzhaf-Penrose index, counts the total number of parties that can be pivotal given all possible winning coalitions and assigns a value to each party equal to the number of times it is pivotal divided by this number. See Banzhaf 1965.

4 See Groseclose and Snyder 1996 for the formal analysis.





Chapter 10: Network Models


1 See Newman 2010 for comprehensive treatment of networks; see Jackson 2008 and Tassier 2013 for network effects in social science.

2 Given any node, its minimal paths have length 1 to 4 nodes, minimal paths of length 2 to 4 nodes, and minimal paths of length 3 to 4 nodes, producing a total of 12 nodes on the minimal paths from each node. On average, the minimal paths from a node visit one other node. It follows that average betweenness for each node equals . By symmetry, all nodes must have the same betweenness.

3 See Newman 2010 for an overview of community detection algorithms. The partitions constructed by these algorithms likely differ because of the number of possibilities. A network with 100 nodes can be partitioned over 190 million ways. Due to randomness in the order in which edges are removed, the same algorithm will often produce different partitions. By applying multiple algorithms and applying each one multiple times, we increase the robustness of our inferences.

4 From the central limit theorem, we know that the degrees will be normally distributed and that the mean will be , because each edge connects two nodes.

5 Watts and Strogatz 1998.

6 See Newman 2010 for formal analysis of network formation models.

7 Ugander et al. 2011.

8 Given a network with N people, let di equal the number of neighbors of node i, that is, the degree. The average degree, , can be written as follows:





The average degree, , equals the expected number of neighbors of a node. When counting the average number of neighbors of neighbors, a node with degree di will be counted di times, once for each neighbor. Therefore, the total number of neighbors of neighbors N2 of a node can be expressed as follows:





To obtain the average degree of neighbors of a node we have to divide this by the total number of neighbors, which equals N . Therefore, it suffices to show





This can be rewritten as





The term on the left equals the variance in the degree distribution. If any two nodes have different degree, the degree distribution has positive variance, therefore, the average degree of neighbors of a node exceeds the average degree of a node.

9 See Eom and Jo 2014 for the formal model.

10 Dodds, Muhamad, and Watts 2003.

11 Newman 2010, Jackson 2008.

12 See Granovetter 1973.

13 The number of friends of degree four is calculated by summing the following eight sets of nodes: C · R · C · R = 4, 000, 000, C · R · R · C = 4, 000, 000, R · C · R · C = 4, 000, 000, C · R · R · R = 800, 000, R · C · R · R = 800, 000, R · R · C · R = 800, 000, R · R · R · C = 800, 000, and R · R · R · R = 160, 000.

14 Albert, Albert, and Nakarado 2004.

15 See Groysberg 2012. Our model of streaks explains their lack of success as regression to the mean.

16 See Burt 1995 on the value of filling structural holes.

17 See Frank et al. 2018 for a survey on the implications of teacher networks.

18 The coalitions that have nonzero value are {A, B}, {B, C}, and {A, B, C}. The value of each of the first two coalitions equals ten. The added value of the third coalition equals minus six. The coalition’s stand-alone value equals fourteen, but the coalition consists of both other coalitions, each of which has a value of ten. Therefore, the value of the coalition equals fourteen minus twenty: -6 = (14−10−10). We can then assign the following Shapley values for each player in each coalition: Coalition {1, 2}: Player 1: 5, Player 2: 5, Coalition {2, 3}: Player 2: 5, Player 3: 5, Coalition {1, 2, 3}: Player 1: -2, Player 2: -2, Player 3: -2. Summing these values produces Myerson values.





Chapter 11: Broadcast, Diffusion, and Contagion


1 The models assume discrete time steps, like days or weeks, and use difference equations that describe the number of infected (or informed) people tomorrow as a function of the number infected (or informed) today. Continuous time models require differential equations and calculus. None of the results of our models would change qualitatively if we switch to continuous time.

2 Plugging the first equation into the second gives the following expression: 36, 000 = 20, 000 + 20, 000 − Pbroad · 20, 000, which reduces to 4, 000 = Pbroad · 20,000, so Pbroad = 0.2 and NPOP = 100, 000.

3 See Griliches 1988.

4 Initial sales, I, equal 100 for each app. First, set Pdiffuse = 0.4 and POP = 1000. New sales in period three equal 0.4 · = 36. Similar calculations yield sales data for future periods. For the second set of data, let Pdiffuse = 0.3 and POP = 1, 000, 000. New sales in the second period equal 0.3 · = 30. Subsequent sales are solved for similarly.

5 Bass (1969) refers to the people who adopt the technology or buy the product as innovators and the people who copy them as imitators.

6 The formal derivation of R0 begins with the observation that for small numbers of infected people, the number of susceptible people is approximately equal to the size of the relevant population. To reduce the number of variables, we can substitute the number of susceptible people with the relevant population. We can then write the change in the number of infected people as a linear function of the number of initially infected people (see box). R0 can be derived formally as follows: when a new disease appears, it infects a small number of people. Denote this small amount by I0. Plugging into the SIR model, the number of infected people in period one equals





Approximate S0 as NPOP and the expression becomes I1 = I0 + Pcontact · Pspread · I0 − Precover I0. It follows that the number of infected increases if and only if Pcontact · Pspread > Precover, which is equivalent to





7 Quarantine cuts the probability of contact to near zero, lowering the basic reproduction number, but has high cost. In the early 1900s, tuberculosis (R0 ≈ 3) caused over one hundred thousand deaths per year in the United States. States raised property taxes to build sanitariums to house patients because surgical techniques such as removing a lung and plumage, the collapsing of the lungs and subsequent refilling with ping-pong balls, proved ineffective. See Dubos 1987.

8 To solve for the vaccination threshold, we must take into account those vaccinated. For the disease to spread, there must be contact (probability Pcontact) with an unvaccinated person (probability (1 − V)) and the disease must spread (Pspread), giving the following period one difference equation:





Using the approximation S0 = NPOP, as in the derivation of R0, this becomes

I1 = I0 + Pcontact · Pspread · I0 · (1 − V) − Precover I0

The number of infected people increases if and only if Pcontact · Pspread · (1 − V) > Precover. This can be rewritten as R0(1 − V) ≤ 1. Expanding and rearranging terms gives R0 − 1 < V · R0. Dividing both sides by R0 gives the result.

9 For an analysis of the SIR model and herd immunity see Tassier 2013.

10 Stein 2011.

11 Updike 1960.

12 Tweedle and Smith 2012.

13 See Lamberson and Page 2012b.

14 Data source: wikinoticia.com.

15 See Christakis and Fowler 2009.

16 Centola and Macy (2007) refer to diffusion that requires multiple exposures as complex contagion.





Chapter 12: Entropy: Modeling Uncertainty


1 See Smaldino 2013 for further elaboration.

2 The logarithm base 2 of a number x equals the power to which 2 must be raised to produce x, so log2(4) = 2 and log2(2N) = N. In the general case, loga(x) equals the power that a must be raised to in order to equal x. Thus, if a y = x, then loga(x) = loga(a y) = y.

3 We can write the information entropy in long form as follows:





This simplifies to





4 The diversity index, the inverse of the sum of the squares of the probabilities, satisfies the first two axioms plus the multiplication axiom. Thus, the diversity index of a known outcome equals 1 and not 0 (Page 2007, 2010a).

5 See Wolfram 2001 or Page 2010a for a more detailed description.

6 Alexander lists fifteen such properties in all. His ideas are presented along with beautiful photographs in four self-published books: The Nature of Order, Book 1: The Phenomenon of Life (2002), The Nature of Order, Book 2: The Process of Creating Life (2002), The Nature of Order, Book 3: A Vision of a Living World (2005), and The Nature of Order, Book 4: The Luminous Ground (2004). The second in this sequence is the most germane to the current discussion.





Chapter 13: Random Walks


1 See Mlodinow 2009 for an engaging tour of random walks.

2 See Taleb 2001.

3 See Turchin 1998 and Suki and Frey 2017.

4 Note that the law of large numbers says that the mean proportion converges, whereas the central limit theorem tells us that the distribution over the proportion of white balls will be normal.

5 A player who makes 46% of his three-pointers has about a probability of making nine in a row (0.469). If that player keeps taking three-pointers, then in a ten-year NBA career (about 800 games), the odds of not making nine in a row at least once (0.999800) are about 47%.

For over three decades, statisticians have pondered the question of whether basketball players and other professional athletes exhibit “hot hands,” that is, whether the probability of making any one shot or free throw is not independent of the success of the previous attempt. See, for example, Chance 2009 for an analysis of Joe DiMaggio’s fifty-six game hitting streak. In considering the evidence for hot hands, we must take behavior into account. If a player believes he has a hot hand, he may attempt more difficult shots. Further, if the defense thinks the player has a hot hand, they can tighten their defense. These behavioral responses can be accounted for by coding shots by difficulty. Gilovich, Tversky, and Vallone (1985) found no evidence of hot hands. Miller and Sanjurjo (2015) discovered an inference error in previous calculations of conditional probabilities revealing that previous studies that purported to not show a hot hand actually support the hot hand hypothesis. The error in previous analysis stemmed from the sampling technique. Those studies gathered sequences of made and missed shots for multiple players. They then calculated the probability of a basket following a randomly selected sequence of baskets. This sampling procedure introduces a subtle statistical bias that can be seen by examining a situation in which many players each take exactly four shots and each shot has an equal likelihood of being made or missed. There exist sixteen possible sequences of makes and misses. Let B represent a basket and M a missed attempt. Of those sixteen sequences, six include two consecutive makes followed by another shot: BBBB, BBBM, MBBB, BBMB, BBMM, and MBBM. These comprise the sample of cases for two consecutive baskets followed by a third shot. If BBBB is drawn, then regardless of which sequence of two B’s is chosen, the probability of a basket equals 100%. If MBBB is chosen, then the probability of a B following a BB also equals 100%. If BBBM is chosen, the probability of an M after BB equals 50%. Last, if BBMB, BBMM, or MBBM occurs, then an M necessarily follows a B. Averaging across the six cases gives the conditional probability of an M following a B as





The bias arises because there are two BB’s that could be chosen in the sequence BBBB but only one in the other sequences such BBMB. The sampling procedure makes each of the two sequences in BBBB half as likely to be chosen as the single sequence in BBMB. The implication of this bias is that if there were no hot hands, the sampling procedure would have shown misses more likely following made baskets. The fact that it did not means that made baskets were in fact more likely following made baskets.

6 Madoff announced 1.5% positive monthly returns to his clients for decades. He claimed that his investments rose each month regardless of changes in the broader market. Posting positive returns during a downturn is more difficult than outperforming the market. When the market falls, a person could beat the market yet still post negative returns. Madoff posted positive returns when the broader market fell in more than eighty months. If we make the heroic assumption that Madoff was somehow able to post positive returns even when the broader market fell three-fourths of the time, his odds of succeeding eighty periods in a row (0.7580) are about 1 in 10 billion.

7 We can solve for the standard deviation by recognizing that the value of a random walk is the sum of identical, independent random variables. Each of those random variables has a mean of zero and takes value either +1 or -1. Therefore, each has a standard deviation equal to 1. Setting σ = 1 and applying the sigma square root formula for a sum gives the result.

8 See Newman 2005 for a formal proof.

9 See Levinthal 1991 and Axtell 2001.

10 See Newman 2005 and Sneppen et al. 1995.

11 Lakes are measured by surface area. Our model produces a power-law diameter. Surface area equals a constant times the diameter squared, so area would also be power-law distributed. See Downing et al. 2006 for data.

12 On a balanced roulette wheel, all pockets have equal likelihood. If the table has any slant, then the ball will more likely fall off the outer edge as it heads uphill. For an account of how J. Doyne Farmer, Norman Packard, and friends constructed a wearable computer to exploit this phenomenon and beat roulette, see http://en.wikipedia.org/wiki/Eudaemons.

13 After N bets, the expected value of this random walk equals Given that the probability of winning is approximately , we can write the standard deviation of the value as The exact value equals

14 Peel and Clauset (2015) model each game as a single sequence and find that the sequences of scores exhibit anti-persistence: the team that scored last is less likely to score next. Given that the teams alternate possessions, this should be expected.

15 Baxter 2009.

16 A proof of this result relies on computing the probability of returning to the starting point in N steps and summing this up over all possible N. For a complete proof see: http://www.math.cornell.edu/∼mec/Winter2009/Thompson/randomwalks.html.

17 See Samuelson 1965.

18 See Grossman and Stiglitz 1980.

19 See Lo and MacKinlay 2007. Shiller 2005 shows that stocks with a relatively low price-to-earnings ratio outperform the market.

20 See Mauboussin 2012.

21 This window from 1967 to 2017 happens to begin at a peak in the S&P 500. Over most windows, the stock prices grow faster than the economy.



Chapter 14: Path Dependence


1 Hathaway 2001.

2 Pierson 2004.

3 Bednar and Page 2018.

4 See Page 2006.

5 Here is a sketch from Page 2006. It suffices to show that the probability of drawing K white balls in the first N periods equals There exist (N + 1) possibilities because K could equal zero up to N. The probability of a given sequence of K white balls in N periods can be written as the product of N fractions. The denominators of those fractions are the numbers 2 through N +1. The numerators are the numbers 1 through K (white balls) and 1 through (N − K) (gray balls). The product of the numerators equals K! times (N − K)! and the product of the denominators equals (N + 1)!. That calculation gives the probability of a particular sequence of K white balls. The number of possible ways to arrange K balls across the N periods equals Therefore, the total probability of exactly K white balls equals





6 The proof is by contradiction. Suppose the result does not hold and that in the long run, 60% of the outcomes are white. It follows that 60% of the balls in the urn will be gray. But this would imply that 60% of the outcomes will be gray, a contradiction.

7 See Lamberson and Page 2012b for a more elaborate model that relies on entropy as a measure of uncertainty.

8 See Lamberson and Page 2012a.

9 See Page 1997 for how to make decisions on public projects with positive externalities.

10 VaR can also be calculated as the probability of losing more than $10,000 at any point during the year.

11 These calculations follow from the fact that the standard deviation of the value of a random walk of length N equals 2.5% corresponds to two standard deviations.





Chapter 15: Local Interaction Models


1 In physics, the local majority model is known as the Ising model. The local majority model is a variant of the voter model, which assumes randomly selected neighbors of various sizes. See Castellano, Fortunato, and Loreto 2009.

2 For the cells along the four edges, we connect the top edge to the bottom edge, creating a cylinder, and then connect the left edge to the right edge to create a torus (a donut).

3 In alternative versions of the local majority model, cells can be activated simultaneously or according to the incentive to update, with the cells with the largest majority of neighbors in the opposite state moving first. If the cells update simultaneously, then the local majority model can produce cycles.

4 See Miller and Page 2004 for a model of standing ovations.

5 See Bednar et al. 2010 for a model of culture that includes consistency of actions across domains.

6 Here too, attaching the top to the bottom to first create a cylinder and then attaching the ends to create a skinny donut.

7 A class of models called diffusion reaction models also produce stripes on narrow shapes and splotches on wider shapes. Using these models, scientists can predict which animals will have stripes, which will have splotches, and which will be a solid color. The answer depends on the size of the mammal’s embryo during the developmental stage when the patterns form and not on the animal’s adult size. Otherwise, elephants would have splotches. See Murray 1988.

8 I thank Bernardo Huberman for this imagery.

9 Proving this involves writing a computer program that generates a random sequence of numbers or a random pattern and showing that the Game of Life mimics the computer program. The formal proof requires showing that the Game of Life is universal in the set of cellular automaton. See Berlekamp, Conway, and Guy 1982.

10 See Dennett 1991 and Hawking and Mlodinow 2011.





Chapter 16: Lyapunov Functions and Equilibria


1 See Nagel 1995 for the original experiments.

2 I thank Jenna Bednar for the example of races to the bottom within federal systems as well as several others scattered throughout the text.

3 See Page 2001 for a formal proof.

4 The presence of externalities, even negative ones, need not preclude the construction of a Lyapunov function. Both the local majority model and the route selection model contain negative externalities. In the local majority model, when a cell changes its state it imposes a negative externality on its neighbors who are in the opposite state. However, the positive externality that it creates with the neighbors it now matches is larger.

5 Guy 1983. If you are daring, start at 27.





Chapter 17: Markov Models


1 A research article would use statistical techniques to estimate transition probabilities more exactly and calculate error ranges. It would also test to see if the transition rates remain fixed over the time period. They would not if transition probabilities depend on per capita income. See Przeworski et al. 2000.

2 Flores and Nooruddin 2016.

3 See Tilly 1998.

4 The equilibrium percentage of people who have tile floors equals the probability of moving from linoleum to tile divided by the sum of the probabilities of moving from linoleum to tile or tile to linoleum. This equals A general model can be written as follows: Let D denote the percentage of people who own a costly durable good and let C denote those people who own a cheaper good. Let BUY(C) > denote the probability that someone buys the cheaper good. Let REPLACE(C) and REPLACE(D) denote the probabilities of replacing the two types of products. If the following inequality holds:

REPLACE(C) · (1 − BUY(C)) > REPLACE(D) · BUY(C)

then more people buy the cheaper good but more people own the durable good. The first part of the claim holds by assumption. To prove the second part, we first solve for the transition probabilities. The probability that someone moves from D to C is P(D, C) = REPLACE(D) · BUY(C). The probability that someone moves from C to D is P(C, D) = REPLACE(C) · (1−BUY(C)). In equilibrium, D − D · P(D, C) + CP(C, D) = D. Setting C = (1 − D), we have D = which is greater than 0.5 if P(C, D) > P(D, C). That inequality is equivalent to REPLACE(C)·(1−BUY(C)) > REPLACE(D)·BUY(C).

5 See McPhee 1963 and Ehrenberg 1969 for empirical evidence of double jeopardy. To prove the result, we need only show that consumers are equally likely to buy either product when switching brands.

6 See Briggs and Sculpher 1998 for an overview.

7 See Schrodt 1998.

8 Khmelev and Tweedie 2001.

9 Khmelev and Tweedie 2001.

10 Reynolds and Saxonhouse 1995.

11 See http://www.ams.org/samplings/feature-column/fcarc-pagerank.

12 Skillful construction of such models lies in defining useful states and assigning accurate transition probabilities. See Langville and Meyer 2012.

13 In a food web, a species links to those species it consumes. See Allesina and Pascual 2009.

14 See Russakoff 2015.





Chapter 18: Systems Dynamics Models


1 See Sterman 2000 for a more general introduction.

2 See Wellman 1990 for an analysis of the value of qualitative systems dynamics models.

3 The model assumes that all hares die by being eaten by foxes. Adding variables for hare death would complicate the model without changing the results as it would just lower the growth range of hares. The expression ˙H denotes the rate of change in H per unit of time, or The equilibrium occurs when the rates of changes in the number of both hares and foxes equal zero, To solve for the equilibrium take the equation gH − aFH = 0 and divide by H. This gives g − aF = 0. Solving for F gives the result. Next, take the equation bFH − dF = 0, and divide by F. This gives bH − d − 0. Solving for H gives the result.

4 I thank Michael Ryall of the University of Toronto for this example.

5 The model’s findings are summarized in Meadows et al. 1972.

6 The suite of models are often referred to as the Club of Rome models, as the Club of Rome, a group founded by David Rockefeller in 1968, funded reports on the models and promoted the models’ findings.

7 By manipulating more variables with small ranges, he can drive the model’s prediction to nearly 30 billion. See Miller 1998.

8 On the first point, see Hecht 2008. On the second point, see MacKenzie 2012.

9 See Sterman 2006.

10 Glantz 2008.





Chapter 19: Threshold Models with Feedbacks


1 See Granovetter 1978.

2 Airbnb’s founders paid the costs of going door-to-door by selling Obama O’s and Cap’n McCain’s cereal boxes during the 2008 presidential election.

3 See Jacobs 1989 for the revolving-door model. Empirical studies find that in jobs that require little formal education, bartending and gardening being examples, men leave (or choose not to enter) professions that include as little as 15% women (Pan 2015).

4 See Syverson 2007.

5 See Gammill and Marsh 1988 for a more detailed account.

6 See Easley et al. 2012.





Chapter 20: Spatial and Hedonic Choice Models


1 See Clark, Golder, and Golder 2008.

2 See Martin and Quinn 2002 for analysis of judicial positions.

3 Hotelling (1929) studied geographic location, Lancaster (1966) expanded Hotelling’s model to study hedonic competition, and Downs (1957) applied the model to politics.

4 The nominate model offers a more sophisticated approach to assigning ideologies based on this same idea (Poole and Rosenthal 1985).

5 The constant term (C in the expression) is chosen so as to make all of the payoffs positive. To accomplish this it can be set to the maximal possible distance between any ideal point and an alternative.

6 In constructing the cut line in this way, we assume that consumers equally weight the two attributes. We could include difference in weights. If people value sweetness more than the amount of cocoa, we would slant the cut line counterclockwise. At one extreme, if people only value sweetness, the cut line would be horizontal and divide A and B evenly on the vertical axis. The spatial model provides a clean example of how we convert an intuition—we prefer things closer to our ideal—into a formal model. Once we plot the alternatives (the chocolate bars) and the consumer’s ideal point in space and define a preference ordering over alternatives (a ranking of the alternatives from best to worst) based on their distances from the ideal point, we have, in fact, written down a utility function based on the alternative. That utility of a product equals the inverse of the distance from the ideal point.

7 Havel 1978.

8 See Martin and Quinn 2002.

9 See McCarty 2011. These percentages could change with shifts in levels of party loyalty or if the types of bills put to a vote change.

10 Formally, if we assume an odd number of voters and the existence of a single voter ideal point at the two-dimensional median, the condition requires that any line through the two-dimensional median divides the remaining voter ideal points in two equal-sized sets. See Plott 1967.

11 McKelvey (1979) showed that a sequence of elections could result in any policy in two or more dimensions, a finding that some referred to as a “chaos result.” McKelvey was careful to state that his result was a statement about sequences of outcomes that were possible given preferences and not a prediction of what would happen in a series of elections. See Kollman, Miller, and Page 1997 for a computational version of the multidimensional spatial model in which candidates move to the center under a variety of behavioral assumptions.

12 The proposer may have to offer 41.

13 See McCarty and Meirowitz 2014 for a deeper analysis of this model and other models from game theory applied to politics.

14 See Tsebelis 2002 on the effect of veto players more generally.

15 A study of housing prices in Los Angeles estimated the cost of commuting at around $28 per hour (Bajari and Kahn 2008).

16 This can be calculated as follows: Initial revenue equals price times quantity, p · q. In the first market, after the price drop, revenue falls by 10% and sales increase by 8%, so revenue equals

0.9p · 1.08q = 0.972p · q

In the second, more crowded market, quantity increases by 33%, so total revenue equals:

0.9p · 1.33q = 1.197p · q





Chapter 21: Game Theory Models Times Three


1 The formal model and proof can be written as follows: Let Ei equal the effort level of player i. The payoff to player i equals M − Ei if she wins and −Ei otherwise. Assume that the probability that player i wins equals her proportion of total effort:





To solve for the unique symmetric Nash equilibrium, we consider the effort of player i assuming that all of the other players choose a common effort level E∗. Player i’s payoff equals





The first derivative of this payoff function equals





To find a maximum, we set the first derivative equal to zero, giving . In the symmetric equilibrium Ei = E∗. Substituting in gives the result. To prove that the first derivative gives a maximum, we need only check that the second derivative of the payoff function is negative.

2 See Shalizi and Thomas 2011 on how to tease out network effects and on the difficulty of making claims about network effects with snapshot data. See Christakis and Fowler 2009 for many examples of clustered behaviors and attributes.





Chapter 22: Models of Cooperation


1 See Science magazine’s special 125th-anniversary edition, published in 2005.

2 See Martin et al. 2008 and Biernaskie 2011.

3 See Zaretsky 1998. In the bank example, ATMs would lower profits if the banks had been earning substantial geographic rents, that is, extra profits because they could exploit customers’ costs of traveling across town to go to a competing bank. I thank Simon Wilkie for this example, among many others.

4 Technically, we are showing that Grim Trigger is an equilibrium strategy in the probabilistically repeated Prisoners’ Dilemma. Other strategies, such as Tit for Tat, can also be equilibrium strategies when paired with Grim Trigger.

5 A player who defects against Grim Trigger earns a payoff of T in the first period and can earn at most zero in any future interactions. If the player uses Grim Trigger against Grim Trigger, she earns a payoff of R in each period in which the game is played. The probability of two periods of play is P, the odds of three periods are P2, and the odds on N periods are PN−1. Therefore, the expected payoff equals:





The proof that (1 + P + P2 + P3 +…) = can be shown as follows: Assume the result is true and then multiply both sides of the equation by (1 − P). The right-hand side equals 1. The left-hand side equals (1 + P + P2 + P3 + …) − (P + P2 + P3 + …), which also equals 1.

6 We need only redo the calculations for maintaining cooperation, and having P fall to . If does not support cooperation, then neither will several periods with a continuation probability P followed by a continuation probability .

7 Nowak and Sigmund (1998) refer to this as image scoring. See also Bshary and Grutter 2006.

8 Both forms of aggression can be mapped to the defect action if one assumes that they would increase the size of the warbler’s domain. See Godard 1993.

9 Four pairs of outcomes merit elaboration. When TFT plays GRIM, both cooperate forever, earning each an average payoff of 3. When TROLL plays itself, both defect in the first two periods and then cooperate forever, for an average payoff of a little less than 2. When GRIM plays TROLL, GRIM cooperates in the first round and TROLL defects; in the second round, both defect; in rounds three and four, GRIM defects and TROLL cooperates; thereafter, both defect. GRIM’s sequence of payoffs can be written as 1, 2, 4, 4, and then a long sequence of 2s, for an average of 2+. TROLL’s sequence of payoffs can be written as 4, 3, 1, 1, and then a long sequence of 2s, for an average payoff of exactly 2. When TFT plays TROLL, TFT cooperates in round one, while TROLL defects. Both defect in round two. In round three, TROLL cooperates and TFT continues to defect. In round four, TROLL cooperates for the second time and TFT reverts to cooperation. Thereafter, both cooperate forever. Each receives one payoff of 1, one payoff of 4, one payoff of 2, and a long sequence of 3s, producing an average payoff of a little less than 3.

10 In fact, both All C and GRIM are dominated by TFT. Against any strategy TFT does at least as well or better than either All C or GRIM. TFT dominates All C because TFT cannot be exploited by All D and TROLL. TFT dominates GRIM because it is able to cooperate with TROLL based on the fact that TFT forgives TROLL’s defections whereas GRIM does not. In a famous experiment, Robert Axelrod asked scholars to submit strategies for a repeated Prisoners’ Dilemma game with a continuation probability. Of the fourteen strategies submitted, TFT performed best. He then asked people to send in new strategies. This time sixty-two people submitted strategies. TFT won the second time as well. Axelrod chalks up the success of TFT to several properties of the strategy: it cooperates, it punishes, and it is also forgiving. GRIM is not forgiving, so GRIM is unable to reboot cooperation with TROLL. See Axelrod 1984. The table does not contain an average payoff against all of the strategies, as that would assume each strategy to be equally likely. One population may contain a majority of people who play TFT. Another may include a large proportion of TROLL. A third may include lots of All D and All C.

11 Suppose, for example, that the temptation payoff equals four times the sucker payoff, T = 4S, and that 5% of the population cooperates. Then P must exceed . Maintaining cooperation requires only that P exceeds . In the case where T = 4 and R = 3, evolving coordination requires . Maintaining cooperation requires P ≥ . For the general proof assume that a proportion θ of the population plays TFT (or GRIM) and a proportion (1 − θ) plays All D. Assume that each person plays against the entire population. TFT (or GRIM) playing against TFT earns a payoff of R each period, producing an expected payoff of . TFT playing against All D receives a payoff of -S. All D playing against All D receives a payoff of zero. And All D playing against TFT earns a payoff of T. Therefore, the average payoff for TFT equals , and All D earns an average payoff of outperforms All D if and only if . Therefore, TFT earns a higher payoff if and only if the following holds:





If θ is small, then will be large and the condition will not be likely to hold. See Boyd 2006 for an analysis of the difficulty of evolving cooperation relative to maintaining it.

12 We borrow this model and the analysis from Nowak (2006), who shows how repetition, reputation, and kin selection can also support cooperation.

13 The open node copies the action of the highest-performing neighbor. By assumption, all neighboring defectors earn payoffs equal to zero. The cooperating neighbor earns a payoff of K · B − D · C. This exceeds zero if and only if .

14 See Wilson 1975 for the foundations of group selection theory. Wilson has several books that take up group selection in greater detail.

15 Traulson and Nowak’s model works as follows: Divide a population of N individuals into M distinct groups of equal size. Within each group, apply the cooperative action model and assign a performance to each individual. Let the probability of choosing individual i equal the performance of i divided by the sum of the performances of all N individuals. A clone of this individual is added to the same group. If the group’s size now exceeds a threshold , then with probability (1 − q), a random individual from that same group is removed, and with probability q, the group splits into two groups with each member randomly placed in one of the groups. To keep the total number of groups constant, one of the existing groups is chosen at random and eliminated. For large M and rare splitting (small q) the number of cooperators increases if and only if the following holds: . See Nowak 2006.

16 When Michelle Peluso, an advocate of agile management, became the chief marketing officer at IBM, she created competing teams whose performance was transparent to other teams. She then rewarded the best teams (Dan 2018). This type of agile management practice borrows ideas from Agile programming, which replaces the standard waterfall approach of sequential construction with simultaneous code writing, testing, and interactions with users.

17 Another strategy, Generous Tit for Tat, cooperates initially and punishes defections only part of the time. In one set of experiments with errors, this strategy outperforms both Tit for Tat and Win Stay, Lose Shift. See Rand et al. 2009 and Wu and Axelrod 1995.

18 See Axelrod, Axelrod, and Pienta 2006.





Chapter 23: Collective Action Problems


1 See Hardin 1968 for an introduction to the tragedy of the commons.

2 See Diamond 2005.

3 See Ostrom 2005 and Ostrom, Janssen, and Anderies 2007.

4 To solve for the social optimum, suppose that each person spends X on the public good. The total utility for the population equals





Taking the derivative with respect to X and setting it equal to zero gives





Solving gives X = N.

To solve for the symmetric Nash equilibrium, we assume that each other person contributes the same amount to the public good; call this amount A. Let Y denote the amount that the individual contributes. Her utility equals





Taking the derivative with respect to Y and setting it equal to zero gives = 1. Rearranging terms and squaring both sides gives [Y + (N − 1)A] = 1. In the symmetric equilibrium, where everyone contributes the same amount (Y = A), then Y = .

5 Utilitarianism weights everyone’s lot equally. Rawls (1971) proposed an alternative: the maxmin principle, in which the ideal social outcome maximizes the utility of the least well-off person. Rawls advocates evaluating outcomes from behind a veil of ignorance so that we do not know whether we will be rich, famous, and endowed with great capacities or hindered by circumstances.

6 We can write individual j’s utility as follows:





To solve for the symmetric Nash equilibrium, we assume that every other person contributes an amount A to the public good. Let Y denote the amount that individual j contributes. Let I equal the common income level. Individual j’s utility equals





Taking the derivative with respect to Y and setting it equal to zero gives





Rearranging terms gives: . In the symmetric equilibrium, Y = A. It follows that . Squaring both sides gives [(1 − α) + αN]2 = NY, which implies

7 See Cornes and Sandler 1996 for a detailed analysis.

8 A more realistic model would assume a nonlinear congestion cost, perhaps an S-shaped curve. That assumption would capture resources like roads, in which the first few other users have no effect on an individual’s benefit and in which at some point the resource is so overcrowded as to be useless.

9 The total utility from M people using the resource equals (B − θ · M). Taking the derivative with respect to M and setting it equal to zero equals (B − 2Mθ) = 0. Solving gives M = . To solve for the Nash equilibrium, we set the value of abstaining equal to zero. People use the resource until the benefit equals the outside option: M = .

10 Note: we set the maximal benefit B equal to the population size N to reduce the number of variables. To solve for the socially optimal outcomes and Nash equilibrium, we first note that total utility equals (N − M) · M + 3(N − (N − M)) · (N − M), which reduces to 4(N − M)M. Taking the derivative with respect to M gives 4N −8M = 0. Solving gives M = . Total utility equals . To solve for the equilibrium, we find an M such that the marginal utilities at the two parks are equal. This occurs when (N − M) = 3N − 3(N − M), which can be rewritten as N = 4M. Total utility is calculated by plugging in the values for M and N − M into the utility functions.

11 To solve for equilibrium consumption, set R∗ = (1 − g)(R∗ − C∗) and solve for R∗.

12 See Kurlansky 1998.

13 To see why the variation does not cancel out, we can consider a two-period model. A growth rate of 20% in the first year results in only 96 units of the resource (80 · 1.2 = 96). A growth rate in the second year of 30% results in 98.8 = (96 − 20) · (1.3) units of the resource. If we flip the growth rates, then after the first year, there exists 104 units of the resource, and after the second year there exists 100.8 = (104 − 20) · (1.2) units of the resource.

14 Ostrom, Janssen, and Anderies 2007.

15 See Craine and Dybzinski 2013.

16 For a short overview see Ostrom 2010; for a more complete account see Ostrom 2004.





Chapter 24: Mechanism Design


1 See Ledyard, Porter, and Rangel 1997.

2 For an example of Pareto efficiency, consider the following four payoff profiles for three people:

{(3, 3, 4), (9, 0, 0), (0, 8, 1), (2, 2, 3)}

All except (2, 2, 3) are Pareto efficient. The allocation (2, 2, 3) is dominated by (3, 3, 4).

3 See Hurwicz and Schmeidler 1978.

4 The third bidder might might bid just above $60. To simplify the analysis, we assume $60 exactly.

5 The proof we give here assumes a uniform distribution of values in [0, 1] but the result holds for a larger class of distributions. Suppose that the other (N − 1) bidders all bid their true values times . A bid b will be higher than another bidder’s bid provided the other bidder’s value times is less than b. The probability that this will occur equals . It follows that the probability of being larger than all (N − 1) of the other bids equals this value raised to the (N − 1)th power. Therefore, if the bidder has a true value of V, the expected payoff from bidding b equals the value minus the bid (V − b) times the probability of b being the highest bid. The expected payoff can then be written as Expected Payoff = To maximize this value, we take the derivative with respect to b and set it equal to zero, giving the following condition:





Simplifying gives: V(N − 1) − Nb = 0, which can be rewritten as b = . To show that the bidder with the highest bid pays a price equal to the expected value of the second-highest bidder’s bid, note that given N random values drawn from a uniform distribution on the interval [0, 1], the expected value of the highest bid equals . The expected value of the second-highest bid equals The expected bid of the highest-value bidder therefore equals





which equals the expected value of the second-highest bidder.

6 Roger Myerson was my PhD advisor and received the Nobel Prize in part for this result.

7 In an all-pay auction, the optimal strategy when bidders’ values lie in the interval [0, 1] can be written as follows: A bidder with a value . So if there are three bidders, a bidder with a value of would bid .

8 For experimental evidence, see Lucking-Reiley 1999. For evidence from eBay auction experiments, see Morgan and Hossain 2006. And for the timber auction analysis, see Athey, Levin, and Seira 2011.

9 Ostrovsky, Edelman, and Schwarz 2007.

10 See Page 2012 for a brief survey.





Chapter 25: Signaling Models


1 See Simler and Hanson 2018 for many examples of how status signaling drives behavior and choices.

2 The cost of a weak type of signaling equals MC. The benefit of signaling equals given the assumption that all S strong types signal. Therefore, no weak type will signal if MC ≥. In contrast, the strong types prefer to send the signal if their benefit from separating exceeds not signaling and all N agents splitting the benefit .

From the previous calculation, the minimal signal that will not cause a weak type to signal equals . It follows that if we let , then the weak types will not signal. For the strong types to prefer to send signal , we must have . We can divide both sides by B and multiply by C to obtain , which simplifies to (, which can be rewritten as C(N − S) ≥ cN.

3 This possibility was put forth by Michael Spence, who shared the Nobel Memorial Prize in Economic Sciences for constructing a job market model of educational signaling (Spence 1973).

4 Having huge tail feathers makes a peacock less fit than if the feathers were a more moderate size. See Zahavi 1975.

5 See Bird and Smith 2005.

6 See Smith, Bird, and Bird 2003.





Chapter 26: Learning Models


1 The psychological study of learning encompasses a far broader set of contexts than we cover here. A person can learn a fact, such as what the capital of Arkansas is. A person can acquire tacit knowledge, such as how to bake bread, repair an engine, or program a computer. A person can also learn a corpus of knowledge, such as organic chemistry.

2 See Thorndike 1911, 244.

3 See Rescorla and Wagner 1972.

4 The model that I describe builds from the original Rescorla and Wagner (1972) model as well as the models by Herrnstein (1970), Bush and Mosteller (1955), Cyert and March (1963), Bendor, Diermeier, and Ting (2003), and Epstein (2014).

5 The parameter γ must be chosen so that the weight on an alternative remains positive. This will be true provided that γ exceeds the inverse of the difference between the highest possible aspiration level and the minimal reward from any alternative.

6 The presentation here follows Bendor and Swistak 1997.

7 If we construct a replicator dynamics model with a finite population in which subsequent populations are chosen randomly, then it is possible that the best alternative might not be reproduced. If so, then replicator dynamics would not locate the best alternative because it has no way of reintroducing alternatives into the population.

8 See Fudenberg and Levine 1998 and Camerer 2003.

9 The game also has a mixed strategy equilibrium in which two-thirds choose an economy car and one-third choose a gas guzzler, but that equilibrium is not stable under the learning rules that we are using, so we will ignore it.

10 To show formally: P(Economy, 1) = 0.5, P(Guzzler, 1) = 0.5, Payoff(Economy, 1) = 1.5, Payoff(Guzzler, 1) = 2, Average Payoff = 1.75. Applying the replicator equation gives Prob(Economy, 2) = and Prob(Guzzler, 2) = .

11 See Frank 1985 for a more in-depth analysis of these situations.

12 See Waltz 1979. See also Powell 1991 for a model of relative and absolute gains in international relations.

13 See Vriend 2000, which analyzes a similar payoff structure and interprets it primarily as competition between firms who produce an identical product and simultaneously choose quantities. Economists call this the Cournot competition model.

14 The Roth-Erev learning model updates the weight W(k, t) of an alternative k in period t by the following formula: W(k, t + 1) = (1 − r) · W(k, t) + Δ(k, t, e). The parameter r denotes the recency parameter, and Δ(k, t, e) = (1 − e) · payoff(k, t) if action k was chosen and Δ(k, t, e) = e · payoff(k, t) if action k was not chosen. The parameter e, the experimentation parameter, determines the weight on unchosen alternatives.

15 See Camerer and Ho 1999.

16 This analysis closely follows the behavioral spillover models of Bednar and Page (2007, 2018) and also borrows from Greif 2006. Bednar and Page stress the importance of initial actions on the equilibrium that emerges, while Grief focuses on the role of beliefs. See Gilboa and Schmeidler 1995 for an introduction to case-based decision theory. See also Akerlof and Kranton 2010 on the role of identity in economic choices.

17 The formal proof can be written as follows: Let B denote the proportion of players who buy in and choose the innovative action initially. It is then a straightforward exercise to compute the following payoffs for each type of action:

Payoff to cultural action: (1 − B) · 200 + B · 220.

Payoff to innovative strategic action: (1 − B) · 180 + B · 300.

To prove the result for replicator dynamics, note that the cultural action has a higher payoff if and only if the following holds:

(1 − B) · 200 + B · 220 > (1 − B) · 180 + 300B

Rearranging terms gives 20(1 − B) > 80B. Thus, applying replicator dynamics, the cultural action increases if and only if: 0.2 > B.





Chapter 27: Multi-Armed Bandit Problems


1 See Bergemann and Valimaki 2008 for the relevance to economic phenomena.

2 See Hills et al. 2015 for a survey.

3 See Scott 2010 for an analysis of the multi-armed bandit problem and various heuristics.

4 Gittins and Jones (1972) first characterized the optimal rule. The Gittins index can be reformulated as a Bellman equation, which applies to any problem that requires a sequence of choices that each produces a payoff. A Bellman equation relies on the construction of a value function that equals the sum of the sequence of payoffs, with future payoffs discounted according to an interest rate.

5 Roberts 2004.

6 For an analysis of an experiment with the United States Department of Agriculture’s Farm Service Agency (FSA) Microloan program see Bowers et al. 2017.

7 Data from Washington Post 2012 and Dann 2016.

8 Al Gore, George H. W. Bush, and Hillary Clinton would have received more credit for economic prosperity had they been incumbents. See Markus 1988 for an analysis through the early part of this period, Fair 2012 for more recent evidence, and Campbell, Dettrey, and Yin 2010 for evidence on candidate-versus-party effect size.





Chapter 28: Rugged-Landscape Models


1 See Page 2007 for a deeper elaboration of the value of diversity.

2 See Kauffman 1993 for a full treatment of the NK model.

3 We can derive the expected value of the local peaks and the global peaks when N = 20, K = 19. The contribution of each attribute is uniformly distributed on [0, 1]. This distribution has a mean of and a variance of . The value of each alternative equals the average of the twenty attribute contributions. Therefore, by the central limit theorem, these values are normally distributed with mean and variance , so in the case of N = 20, each standard deviation is of size . We can then estimate the average value of a local peak: 0.609. A local peak can be thought of as the best from among 21 random draws from this distribution. Therefore, its expected value will be approximately equal to that of a value drawn from the normal distribution such that of the alternatives have lower values. This will be a little less than two standard deviations above the mean. Using a normal distribution calculator, the expected average value equals 0.609. To estimate the expected value of the global peak, 0.759, we note that the global peak has the highest value of all 220 alternatives. Each alternative can be thought of as a value drawn from the distribution, so the expected value will be approximately equal to that of value drawn from the normal distribution such that of the alternatives have lower value. Using a normal distribution, the expected average value equals 0.759. The global peak has a higher value than would be expected in a million draws.

4 See Wright 2001, which argues that these positive-sum recombinations helped produce humans, societies, and the technical and scientific advancements of our age.

5 See Kauffman 1993 and Miller and Page 2007.

6 The United States allows for seventeen years from the issue date if issuing the patent takes more than three years.

7 Boldrin and Levine 2010.





Chapter 29: Opioids, Inequality, and Humility


1 Given the probabilities, the exact statistical equilibrium is 70.7% in no pain, 19.5% on opioids, and 9.8% addicted. For the first case, the percentages are 76.3%, 21.5%, and 2.2% respectively.

2 See Wakeland, Nielsen, and Geissert 2015.

3 I thank Abbie Jacobs for her commentary and insights on this section of the book.

4 See Wilkinson and Pickett 2009.

5 Comments made at the Becker Friedman Institute at the University of Chicago, “Understanding Inequality and What to Do About It,” November 6, 2015.

6 See Goldin and Katz 2008, Acemoglu and Autor 2011, and Murphy and Topel 2016.

7 See Mas-Colell, Whinston, and Green 1995 for how to prove such a result.

8 See Kaplan and Rauh 2013a, and a model by Jones and Kim (2018) that uses ability as a proxy for the scalability of an entrepreneurial idea. See Frank 1996 for early research on how inequality has occurred within every profession. For a more recent study, see Xie, Killewald, and Near 2016.

9 See Ormerod 2012.

10 Ormerod 2012 describes in detail how our increased connectedness contributes to inequality.

11 See Cancian and Reed 1999 and Schwartz and Mare 2005.

12 See Greenwood et al. 2014 for the full model.

13 The estimate is that it would have been 0.34 rather than 0.43. See Greenwood et al. 2014. The Gini coefficient measures the distance between the income distribution and an equal distribution. Let S(P) denote the total share of income (or wealth) earned (held) by the lowest P% of the population (i.e., if the bottom 30% of the population earns 2% of the income, then S(30) = 2):





If income is evenly distributed, , and GINI = 0. If all of the income goes to the top 1%, S(P) = 0 for P < 100, and S(100) = 1, so GINI = 1.

14 The calculation can be made as follows: Children belong to the four categories with probabilities (0.6, 0.25, 0.1, 0.05). That is, 60% of the offspring of high-income earners, 20% of the offspring of upper-middle-income earners, 15% of the offspring of lower-middle-income earners, and 5% of the offspring of low-income earners have high income. The percentage of high-income grandchildren equals (0.6)(0.6) + (0.25)(0.2) + (0.1)(0.15) + (0.05)(0.05) = 0.4275 and the percentage of low-income grandchildren equals (0.6)(0.05) + (0.25)(0.1) + (0.1)(0.15) + (0.05)(0.7) = 0.105.

15 Pfeffer and Killewald 2017.

16 Kaplan and Rao 2013b.

17 See Farmer 2018.




