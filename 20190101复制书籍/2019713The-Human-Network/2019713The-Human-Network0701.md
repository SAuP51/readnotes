7 • THE WISDOM AND FOLLY OF THE CROWD

What separates humans from other species? Many species exhibit complex social organizations, from the quadrillions 1 of ants whose elaborate colonies cover the globe to the spotted hyenas whose competitive matriarchal hierarchies make them the most fascinating species to roam the Serengeti. Humans are also not the only species to use tools. Jane Goodall dispelled that myth when she observed chimpanzees using blades of grass to fish delicious termites out of their mounds. Nor are we even the only species to teach things to our young. Meerkats teach their young pups how to handle scorpions by first bringing them dead ones, then later bringing them live ones with disabled stingers, and eventually bringing them healthy scorpions. Moreover, Meerkats cooperate in this endeavor: adults other than a pup’s parents help to teach the young. Humans are not even the only species to communicate with sounds, as important forms of communication have been observed among elephants, whales, birds, and many other species.

If other species have elaborate social structures, cooperate in rearing and teaching their young, communicate, and use tools, then what sets humans apart? The answer lies in our ability to grasp abstract concepts combined with our ability to communicate them to others. I was not alive in seventeenth-century China, and yet I believe that peasant uprisings and rebellions occurred there. Moreover, I cannot ever be absolutely sure that this happened — all the evidence comes from artifacts, writings, and historical accounts and research. I can read about the period, and talk to experts who have studied that moment of Chinese history in detail, but I will never have any firsthand experience of the Qing dynasty. Nonetheless, through the variety of sources of information available I can learn a great deal about what happened and be fairly confident of the basic facts. It may be some time before I have an opportunity to travel into outer space, but I can read Michael Collins’s account of Apollo 11’s voyage and get an impression of what it must be like.

I have no idea of how to build a computer, much less the many tiny components that go into it, or of the minerals needed to build some of those. In fact, it would be impossible for any single human to produce even a few of its parts from scratch. Nonetheless, computers are produced by teams of people and chains of companies, and I can learn enough about a computer to use one to perform the research and writing needed to study networks and create this book.

Ken Mattingly was an astronaut of Apollo 16, and one of only two dozen people who have flown to the moon. In his words,「This is such a big thing. I frankly don’t see how you can do it. Even though I am participating in it, I think it’s audacious to even try. I clearly could not understand, as a crewman, how to, how to make it work. I could only learn to operate my share of it.」

The human ability to grasp abstract concepts, which enables us to learn from each other, and to coordinate our activities, is a double-edged sword. We learn falsehoods as well as facts. Do vaccines lead to autism in our children? Is climate change a result of man’s activities? We cannot answer these questions based on our personal experiences, we have only anecdotes at best, and so we must rely on what we have heard from others and from trusted sources. This allows the dramatic and persistent polarization that we see in people’s beliefs on questions of fact. It enables man to achieve great scientific and engineering advances, but also leaves us open to doubts, superstitions, and polarization. 2

In this chapter we will explore how we learn from each other and when we get things right and wrong. There are systematic errors that we make in interpreting information that we obtain from friends and acquaintances. For instance, we often treat similar information from different sources as being independent confirmation of a fact, even though it may emanate from a common (unreliable) source. Divisions in networks — and homophily in particular — can lead to persistent differences in beliefs and norms across groups. Our ability to communicate in the abstract makes us susceptible to deception, and it enables errors and even fake news to crowd out the absorption of facts and real news. Despite all of these challenges, there are situations in which we get things right. We will see how our networks determine when the crowd really is wise and when it is prone to folly.

The Wisdom of the Crowd

Suppose that you need to estimate the weight of an ox, but don’t have a scale. How would you do it? If you are asking yourself why on earth you would ever need to weigh an ox, it is likely that you will never have to. But don’t worry, the example has an interesting history and point to it.

A standard method is as follows. You first take a cloth tape measure and measure the heart girth of the animal, in inches. This is like a chest measurement, measuring the circumference of the animal just behind its front legs. Next you measure the length of the animal. You measure from the point-of-shoulder to the point-of-rump (what is known as the pin bone). Basically, you are measuring from where the neck meets the front legs almost to the tail. You are advised not to sneak up on the animal, and to make sure it is calm and comfortable, especially when taking its heart girth measurement. Now you combine these numbers to estimate the volume of the ox — much like you calculated the volume of a cylinder in grade school. To estimate the weight in pounds you square the heart girth, multiply that by the length, and divide by 300. 3

If you don’t have a tape measure, but have a lot of friends, then another method is to ask each of your friends for a guess and then take either the median or average guess. The amazing accuracy with which this worked was noted in an article called「Vox Populi」published by Francis Galton in the scientific journal Nature in 1907, and brought to popular attention by James Surowiecki a century later. 4

Vox Populi is Latin for「the voice of the people,」and this phenomenon has become known as「the wisdom of the crowd.」Sir Galton went to the annual show of the West of England Fat Stock and Poultry Exhibition held at Plymouth. There was an ox to be slaughtered and a contest was held. For a six-penny fee, you could venture a guess at the animal’s weight. Those coming closest to the weight would win the contest. Eight hundred people entered the contest and Galton was able to read the guesses on 787 of the entries. The ox ended up weighing 1,198 pounds. The average guess was just one pound shy at 1,197 and the median guess was just 9 pounds over at 1,207 — both within one percent of the actual weight! 5

It was likely a more ox-savvy crowd than might include you or me. In fact, half of the guesses were within plus or minus 3 percent of the actual weight and more than 90 percent of the guesses ranged between 1,000 and 1,300 pounds. Nonetheless, the striking aspect of Galton’s analysis is the extent to which individual errors get washed out in the aggregate.

There are a few things that are critical to Galton’s example working.

One is that there is a diversity of views. Almost eight hundred different people each drew on their own personal experiences to venture a guess. The diversity of those experiences produces a range of opinions from which we can learn. 6

Next, the experiences and viewpoints cannot be biased in any systematic way. For instance, suppose that everyone used the same technique for estimating the weight of animals: for instance, they all used the tape-measure technique. That would do two things. It would reduce the diversity in their estimates, so that the differences in opinions would come from variations in measurements. That would not necessarily be a bad thing; however, it would also introduce a systematic bias. That measurement technique may systematically over- or underestimate weights.

For instance, suppose that the ox happens to be from a species that has more of their weight in their rears and less near their chests than other species. This would lead the tape-measure technique to underestimate the weight since this ox would have less weight in the place where the heart girth is measured. So, by all using the same technique to arrive at their guesses, they would tend to underestimate the weight of this ox on average. It would produce an interesting difference: instead of ranging from 1,000 to 1,300 pounds, it might be that everyone would guess somewhere between 1,130 and 1,180. Most people would not be as far off, but they would all tend to be wrong in the same direction — and so instead of having an accurate average, the average would be biased. Such systematic errors are a constant challenge for science: whenever people use the same technique or work from the same data they can be subject to common errors.

Finally, the various views have to be aggregated. If instead of picking the average or median, we had picked a guess out of a hat, or picked the maximum guess, we would not do as well as picking from the middle of the distribution. If done properly, aggregating the views of a group can outperform any individual, or at least a typical individual. 7

An essential task in any organization is processing and aggregating information from multiple sources, both internal and external. There are many ways in which it is done, and so let us have a look at a few key ones.

For the latest views on a range of events from political elections to sporting events, one place to get some of the most accurate information is from prediction markets. For instance, to predict who will win an election, a prediction market enables people to bet on who will win instead of just answering a question in a poll. You can buy a share that pays one dollar if the candidate wins and nothing if he or she loses. If you think that there is a 60 percent chance that the candidate will win, then you can think of this share as being worth 60 cents in expectation: the 60 percent chance that it will pay a dollar. If a share is selling for less than 60 cents, then by buying it you expect a profit. If it is selling for more than 60 cents, then by selling it you expect a profit. The price then becomes a sort of tug-of-war between people who have different beliefs about the odds that the candidate will win the election — coming to rest at a point that balances the buying and selling pressures. 8 This is similar to the way in which betting on some sports events works.

Of course, getting accurate prices in a prediction market requires either the diverse and unbiased participation that we discussed above or someone who has very accurate knowledge, a lot of confidence, and a lot of money. Prediction markets offer several advantages compared to polls or some sort of averaging. One is that the market adjusts depending on how confident people are. If someone is very confident in their assessment, then they can buy or sell many shares and drive the price up or down accordingly. Another advantage is that prediction markets operate in real time and can adjust quickly to new information as it becomes available. A third advantage is that such markets allow the participants to see the current best estimate and that may help them hone their own thinking. This third feature can sometimes also be a disadvantage, as people may lose faith in their own estimates if they seem to be too much of an outlier compared to the market, even when their own estimates are good ones.

The accuracy of prediction markets in many elections (e.g., the Iowa Electronic Markets), and their ability to outperform many polls, has led to their adoption in a variety of arenas. 9 They have been used by many companies, including Google, France Telecom, Intel, HP, Eli Lilly, IBM, Microsoft, among others, to forecast things ranging from sales volume to interest rates. The U.S. Department of Defense even considered using prediction markets to help various intelligence and military personnel combine their information to forecast geopolitical trends and potential terrorist activities. That idea was scrapped as the public found「betting」on such events repugnant. 10 Tom Daschle, the Senate minority leader at the time, said,「I can’t believe that anybody would seriously propose that we trade in death.」California senator Barbara Boxer found that「there is something very sick about it,」and suggested firing those who had proposed the idea. That does not mean that governments around the world will stop trying to forecast major events, but just that most will continue to find themselves unable to use markets to forecast certain events.

Another way to aggregate diverse views of what might happen, or what to do, is by having careful deliberation. This is the logic behind how juries work. It has also been used on larger scales, such as in what became known as Kasparov versus the World. In 1999, Garry Kasparov, one of the greatest chess players of all time, played a game against tens of thousands of enthusiasts who discussed strategies and voted on moves online. Kasparov played the white pieces and eventually won, but the match lasted four months and took sixty-two moves. Although the crowd did not win, Kasparov called it the greatest game in the history of chess. It is also clear that the crowd played at a level well above what most, if not all, of its members would have played individually. It also turned out that Kasparov had not only the advantage of playing the white pieces, but that he was also reading the discussion on the world forums. 11

Most of our information, however, is not aggregated via some poll, vote, market, or deliberative process.

Suppose that you have to make a decision, such as whether to buy this book, whether to vaccinate your baby, whom to vote for in an upcoming election, whether to join a protest, or which type of phone to buy. In gathering information before making your decision, you don’t have the luxury of averaging hundreds of people’s estimates, or running a prediction market, or asking for a vote on what you should do. This is where social structure plays a major role. You are the aggregator and your network matters: you learn from talking with friends, family members, and colleagues, as well as from various media that you consult or follow.

Processing all of the information around us is tricky. When a friend recommends that you don’t vaccinate your baby because they heard that it is dangerous, how do you know what to do? Where did their information come from? If you talk to more friends who say the same thing, is this new news? Could they be learning from the same source? Then you talk to another friend who says they just saw a news story saying that a new study found that vaccinations are safe and you should vaccinate your baby. How reliable was that news story and the study? Did your friend interpret the story correctly?

How will your opinions and beliefs evolve over time? Will you eventually accurately aggregate all the information that is out there just by interacting with your friends and acquaintances? How might you be fooled? How quickly do your beliefs adapt and change? Will you and your friends eventually reach a consensus? Is it possible for you to reach different conclusions than someone else in the same network? These are questions that economist Ben Golub (a former student of mine) and I investigated in detail.

To see how things can go right or wrong in a decentralized social setting, let’s go back to our ox’s weight. You have a guess but knowing little about the weight of oxen, you decide to talk with some of your friends. Some might have higher guesses than yours, pulling your impressions upward, and others might have lower guesses, pulling your impressions down. After talking with your friends your impression would be a「weighted」average (no pun intended) of your and your friends’ initial guesses. The weighted aspect reflects that you might pay more attention to some friends than others, depending on how accurate you expect their opinions to be. For instance, if one of your friends is a rancher and the other is an economist, then the rancher’s opinion might affect your view much more.

This sort of deliberation is very natural and could even optimally process the information — much in the way that Galton found the average of all the guesses to be very accurate. In your situation, however, the process does not end here. Your friends are also talking around, so that is changing their opinions too. Their new opinions reflect new information from other people in the network, including people who are not your friends. Thus, it is worth talking to your friends again. After the second time that you talk to your friends, you are incorporating information from friends of friends.

With a topic like the weight of an ox, you might get bored quickly and the process would end after a couple of iterations, at most. However, with topics more pertinent to your life, such as how likely a vaccine is to harm your child or how much you should be exercising for your health, you might continue to talk to people. Over time, your beliefs are incorporating information from friends of friends of friends.

This process is illustrated in Figure 7.1.

Figure 7.1: Networked learning. Five people in a network are estimating the weight of an ox that really weighs 1,200 pounds. The two people toward the left, with the white nodes, start by underestimating the ox’s weight and initially thinking it weighs 1,000 pounds. The two people with the black nodes start by overestimating and initially think it weighs 1,400 pounds. The person with the gray fill starts with a very good estimate of 1,200 pounds. So, lighter fill indicates a lighter estimate of the ox’s weight. People talk repeatedly with their friends, and each time, they take a new average of their latest beliefs and their friends’ latest beliefs.

The process in Figure 7.1 shows that learning via a network has some similarities to diffusion and contagion. If we are each talking to a few friends, this ends up expanding outward quickly and after just a few iterations you are indirectly processing information from everyone in the broader network. With the small-world feature of networks, it takes only a few iterations before information from one person has reached most others, at least in some diluted fashion.

This sort of learning in which each person repeatedly talks to their friends and simply keeps averaging their opinions is what is known as DeGroot learning, named after Morris DeGroot, a statistician. 12 The DeGroot model does not presume that people do arbitrarily complicated calculations, but just simple ones, like averaging numbers. Perhaps not surprisingly, when it comes to predicting how real people act, even in simple networks, the DeGroot model acts more like humans than a more omniscient and sophisticated model in which people adjust how they process information with time and in response to how they see others’ opinions fluctuate, at least in some settings, as we shall see.

However, even DeGroot learning is still more complex than simple diffusion as it involves intensities and repeated conversations.

The centralities of people matter in how influential they are in steering other people’s eventual beliefs. The friendship paradox (Chapter 2) is at work here. People who have more friends end up with their opinions being averaged by more people. In the network in Figure 7.1, the person with the black fill at the bottom of the picture is the most central by any centrality measure. Even though the average of all the starting estimates in this example would be accurate at 1,200 pounds, the fact that the dark-fill people with heavier guesses are more central than the white-fill people with lighter guesses makes the eventual consensus overshoot and overestimate the weight.

So, more central opinions have more of an impact. If you recall our discussion of centralities, you will realize that since people are talking again and again and again…what will really matter will not simply be someone’s degree, but instead their eigenvector centrality. You are right. Being friends with other people who are well connected means that my opinion will spread to them, and then outward from them, and so having well-connected friends is as important as having many friends. Indeed, how much each person’s initial opinion enters into the eventual overall opinion held by the society if the society keeps averaging repeatedly is exactly proportional to their eigenvector centrality. 13

If the society keeps going through this process, it will eventually reach a consensus. The intuition behind this is seen in Figure 7.1 as the shades of the different nodes will eventually come to be the same. The person with the darkest shade will eventually lighten, and the person with the lightest will eventually darken. As long as someone is darker or lighter than their neighbors, they will be moved, and eventually the whole network will come to the same shade. 14

What that consensus is depends on the starting estimates and the centralities of all the nodes. The eventual consensus belief is actually given by an amazingly simple formula: you just add up each person’s initial estimate multiplied by their eigenvector centrality. 15

There are some important biases in this process.

One is that there are「echoes」: your own opinion gets reflected back at you. Your friends’ opinions are partly based on your past opinions — so part of the「new」information you get from repeatedly talking to your friends are echoes of your beliefs. As your friends begin to confirm your beliefs, you can end up being overconfident. It is quite natural: you feel better about an opinion if other people agree with it. Even if you know a lot about the structure of the network, filtering out your echoes is hard.

A second, and even more extensive bias, is double counting. If you talk to both Lisa and Emilie, and they are each friends with Alex, then Alex’s opinion is getting to you through two different channels. You end up double counting Alex’s information. Hearing the same information from multiple sources makes it appear to be more reliable than if you hear it from one original source, even when they are just relaying the same information. 16

Double counting and echoes are illustrated in Figure 7.2.

Biases driven by double counting information and not filtering out echoes are hard to avoid. You want to know if you should see the latest Star Wars movie. You read a review that says that the cinematography is spectacular. Both of your friends say the same thing. Is it really their own opinions? Were their opinions swayed by the reviews they read? Were they affected by the conversations they had since they saw it? When you eventually see it, and someone asks you how much you liked the movie, is your opinion now a bit higher because your friends loved the cinematography or because a critic also suggested that it was great? Do you even know how much of your impression of the movie is really entirely yours, and how much of it was shaped by what you heard before and after? If you tell your friend that you thought the dialogue was lousy, and they agree, how much more confident in that opinion do you become? Are they echoing your opinion or did they really think the dialogue was poor?

Figure 7.2: DeGroot learning: Double counting and echoes.

There are situations in which you will explicitly relay someone else’s opinion, and say that it is not from you. If someone asks me where interest rates might be heading, it’s not my expertise, but I might quote the opinion of one of my colleagues who is an expert. But even when I do, I often cannot explain where my expert friend’s information came from.

One way to directly see whether people are subject to double counting, and failing to sort out echoes of their own influence, is to do an experiment in which the information fed into the network is fully controlled. If we know precisely what information people start with, and what the network of interactions is, then in addition to checking whether people fall prey to double counting and echoes, we can also check whether DeGroot learning matches people’s behavior.

Arun Chandrasekhar, Horacio Larreguy, and Juan Pablo Xandri, 17 did exactly that. It turns out that DeGroot learning was amazingly good at predicting how people’s beliefs evolved.

The researchers put people in the experiment into networks. Whom each person could talk to — their friends — was assigned so that the experimenters knew what information came from whom. The networks were such that everyone could reach all of the other subjects in the experiment within a distance of at most four hops: there were friends, friends of friends, friends of friends of friends, up to a distance of four.

Chandrasekhar, Larreguy, and Xandri also controlled people’s initial information and what they were trying to guess. There were two indistinguishable bags, each of which contained seven balls. One bag had five blue balls and two yellow balls — let’s call that the blue bag — and the other bag had two blue balls and five yellow balls — which we’ll call the yellow bag. The experimenters picked one of the two bags for the experiment, but the people in the experiment did not see which bag it was. Then each person privately got to see one ball randomly pulled out of the bag. If you happen to see a blue ball, then it is most likely that it is the blue bag (in fact, your best guess would be that there is a 5/7 chance that it is the blue bag). Instead, you might happen to see a yellow ball in which case you will think that there is only a 2/7 chance that it is the blue bag and a 5/7 chance that it is the yellow bag. After each person saw one ball randomly pulled out, in private, they each made an initial guess. After their first guess, they got to see how their friends in the network guessed.

After seeing their friends’ guesses they got to guess again. Then they got to see their friends’ second guesses. They got to guess again, and so forth. You might want to change your guess over time. If you initially guessed blue, but saw that all four of your experimental friends had guessed yellow, then presuming that your friends are paying attention to the game, you would infer that they all saw yellow balls. That would be four yellow balls to one blue ball, so you should switch your second guess to yellow. But each person in the network had different sets of friends, reaching out in the network. One of your friends might have initially guessed yellow but then later switched to blue. What should you infer from that? Also, it could be that some of them are changing because of you (echoes) or in reaction to a common friend (double counting). Sorting all of these guesses and changes in guesses becomes quite tricky after just a couple of rounds.

People knew what the overall network of friendships looked like, so they actually knew if some of their friends had a friend in common. So we can see if people acted sophisticatedly like a high-powered carefully programmed computer, filtering out echoes and avoiding double counting; or whether they acted more in line with DeGroot learning, which has people make guesses, without thinking too deeply, that just keep changing based on the most recent guesses of their neighbors.

There was a total of 665 participants in the experiment, put into networks of 7 each. So there were 95 separate networks, and many different guesses and situations for each person; overall there was an abundance of data on how people behaved. Thus the experiment had pretty good accuracy in terms of distinguishing how sophisticated people are.

Presuming that people are simply following DeGroot learning (with equal weight on each friend) correctly predicts 94 percent of the guesses; while presuming that people are fully sophisticated correctly predicts only 74 percent of the guesses. There are many guesses where things are easy to predict and so we should expect any model to match a good fraction of the guesses. For instance, on our first guess, we should each guess whatever color ball we saw. On our second guess, we should each guess what the majority of guesses were among our friends in the first round. The models don’t really diverge until we get to later rounds where echoes can appear (my friends changed because of me), and double counting can appear (two of my friends are both changing due to seeing the behavior of some friend who is common to both of them), and so forth. That’s where DeGroot learning starts to dominate: people do fall victim to double counting and echoes — and the simple DeGroot model is an amazingly accurate predictor of their behaviors and much more accurate than a fully rational and sophisticated model of behavior.

Other experiments also find that people fall prey to double counting and echoes, and have many other quirks. 18 Most important, this happens not just in small-stakes experiments, but also in hugely expensive decisions in our day-to-day lives.

Michael Bailey, Ruiqing Cao, Theresa Kuchler, and Johannes Stroebel tracked how people’s decisions to buy houses were affected by interaction with their friends. 19 They tracked people’s friends via Facebook and examined how the experiences of those friends influenced a person’s decision. As an example, consider a person living in Los Angeles, let’s call him Charlie, who is deciding on whether to buy a house or instead to rent. Charlie has a friend in Boston, let’s call her Lucy, thousands of miles away. If Lucy’s house has gone up in value, then it turns out that Charlie is more likely to buy a house, and will pay more, and buy a bigger house, than if Lucy’s house has fallen in value. Charlie’s decision is influenced by Lucy’s experience with her house thousands of miles away. The study is careful to account for all kinds of possible confounds, such as people’s characteristics and economic trends. The size of the effect is large on many dimensions: a 5 percent increase in a friend’s house value over the past two years corresponded to a person being 3 percent more likely to buy a house, and to their buying a 2 percent larger house, and paying 3 percent more for it. Also, if friends’ housing investments did poorly, then a person was more likely to sell their house and to take less money for it. In addition, the more variation there was in the outcomes of a typical friend of Charlie’s experiences, the more cautious Charlie became. So, for instance, having two friends whose houses went up by 5 percent had more of an impact than having one whose house went up by 15 percent and another whose went down by 5 percent.

There are several interesting things to note. First, people’s decisions are linked to their friends’ information, even those who live far away. Second, this shows up sizably in important life decisions: buying houses. Third, it does not appear that people are properly processing the information they are getting from friends. Lucy’s good luck with housing is from a market far away and based on what happened over the past two years. How predictive is this about what Charlie should be doing now? It turns out that people in the study did not adjust for where their friends were living — the Boston market is much less correlated with the Los Angeles market than the San Diego market is, but Charlie listened just as much to Lucy who lived in Boston as to Linus who lived in San Diego even though Linus’s experience was much more informative.

Most of us are stuck with echoes, double counting, and paying attention to people whose information might not be relevant. Can we still manage to aggregate information well through our networks? Would we come close to assessing accurately the weight of the ox in a network in which each of us only talks to our friends?

It turns out, as Ben Golub and I found, that even a process as naive as DeGroot learning leads to very accurate eventual beliefs if a few critical conditions are met.

We have already seen some of the conditions: we need a diversity of views and they cannot be systematically biased, so it should be that if we were to average all of the opinions in the society the result would be accurate. If the society does not have the right information out there among its members to begin with, it has no chance. Beyond these conditions, the communication network has to be well「balanced.」If all of us are friends with the same person, then his or her belief can dominate the overall outcome. The exact condition that ensures accurate learning is that the eigenvector centrality of each individual in the society has to be small relative to the sum of the centralities of the others. If we look at a network, what ensures this is a balance condition: roughly that the attention that people pay to any small group cannot greatly outweigh the attention that they place on others.

Figure 7.3: Panel (a) an unbalanced network. Panel (b) a balanced network. The network in (a) is more efficient in having fewer links and having someone who has access to all the information in the network, but it can end up overreflecting the center person’s views.

We see an example of an unbalanced versus a balanced network in Figure 7.3. All of the unbalanced network passes through a single person. If that person places more weight on his or her own opinion than those of his or her friends (a natural tendency 20 ), then that will be reflected back in the final beliefs. In contrast, the symmetry of the more balanced network means that nobody ends up driving the overall consensus that emerges. 21 The unbalanced network can save on communication costs, as it offers one-stop shopping for information: each peripheral person only needs to talk to one person to get information about what everyone is thinking, which is why one might see such starlike networks emerge. 22 But such unbalanced and centralized networks can end up with biased opinions.

Whom people pay attention to is something that has been extensively studied. For instance, in a series of studies in the 1940s and 1950s Paul Lazarsfeld examined how people formed their opinions. First was a study of 2,400 adults in Ohio during the months leading up to the 1940 presidential election. Lazarsfeld, together with two colleagues and a team of research assistants, interviewed a series of people repeatedly, and asked with whom they had talked, which media they were paying attention to, and what caused them to change their opinions whenever there was a switch. 23 Lazarsfeld also was involved with a later study of eight hundred women in Decatur, Illinois, asking them how they formed opinions on a variety of topics, including consumer products. 24 From these studies emerged a theory of「two-step communication」that was elaborated upon in a book by Elihu Katz together with Lazarsfeld. The two-step communication theory posits that there are people who operate as「opinion leaders」 — mavens, as it were — who relay information gleaned from media to other people,「opinion followers.」A similar theory was the centerpiece of Malcolm Gladwell’s Law of the Few. 25

Are there situations in which a society relies heavily on just one person’s opinion? It is not hard to find examples. Some have suggested that Robert Parker, a famous wine critic, held immense influence within the wine industry. It is hard to dispute that Parker was「the」wine critic for several decades.

The wine industry is one in which information from such critics is vital. More than thirty billion bottles of wine are consumed each year, produced by tens of thousands of wineries many of which ship all over world. The quality of a wine depends on local weather and soil conditions, as well as how the vines are handled, when the grapes are picked, and how the wine is made. Even the same winemaker working from the same vineyards may have substantial variation in the quality of a wine from one year to the next. Putting all of this together with the high costs of many wines means that information from others about the quality and features that one can expect from any given wine is very valuable.

Robert Parker is a classic example of a self-made man. The son of a salesman, he founded his wine-rating newsletter in the late 1970s, at a time when he notes that there was a shortage of wine criticism — especially if you did not read French. For years he worked as a lawyer for a bank, and tasted wines and sold his newsletter on the side. But his was the right palate at the right time. Parker accepted no advertising and paid for the wines he tasted — he did not want to be swayed by any gifts or business ties to wine producers. He began rating wines on a 100-point scale, with a score above 90 generally indicating an excellent wine. Such a scale is now the standard in the industry.

Tasting wines takes talent, as one not only has to be able to discern what it tastes like now, but also what it will taste like when it reaches its maturity, often years after it is bottled. This involves detecting tannins, acid, sugar content, and various flavors, and understanding how they will evolve with time. Parker’s influence began to really take off when he called the 1982 Bordeaux a great vintage, contrary to many others doing early tastings of the wines. It is now considered to have been one of the greatest vintages of any wine in history. As James Laube of the Wine Spectator put it,「along came 1982 in Bordeaux, with the most magnificent outpouring of great wines the world had ever tasted.」26 By the mid-1980s Parker had quit his day job and was rating wines full-time. Parker quickly emerged as the focal point in the industry. Max Lalondrelle, who buys wines for Berry Bros. & Rudd (a wine merchant in the U.K.), put it this way:「Nobody sells wine like Robert Parker. If he turns around and says 2012 is the worst vintage I’ve tasted, nobody will buy it, but if he says it’s the best, everybody will.」27

One effect of this is what many have called the「Parkerization」of wines. Winemakers sensing that Parker tends to like big wines — ripe, rich wines with strong flavors of the grapes, the oak barrels in which wines are often matured, the earth that nourished the vines, and a significant level of alcohol — have tended to tilt their wines in that direction. Elin McCoy’s biography of Parker 28 quotes a Bordeaux merchant describing the impact for one winemaker’s profits as saying「the difference between a score of 85 and 95 was 6 to 7 million Euro.」

It can be wonderful to have a critic with such a discerning palate and memory for tastes and smells (and a nose insured for a million dollars) to recommend wines for the world. However, if you don’t like the same sort of wines as Robert Parker, this can be bad news. Should we really be alarmed that one critic has enormous influence on wine sales? The wine industry has sales in the hundreds of billions of dollars a year, and having one critic’s taste determine the success or failure of a wine introduces an enormous amount of uncertainty and risk into winemakers’ lives.

Estimating the weight of an ox works better by having many estimates, even from pretty naive guessers, than just one estimate from someone who is fairly accurate but not perfect. The same is true of rating all sorts of things from wines to stocks. 29

Evaluating wines and many other products is becoming easier. Even if none of my friends has tasted the latest vintage of some small-production Burgundy, there are people who have, and it is not hard for me to find their views online. Our networks for such information continue to grow and connect with people whom we have never met and will never hear from again, thus helping diversify the critical views that we draw from. This can help if the reviews really represent some independent experiences and new information. 30

However, there are situations in which all the information traces back to one source. If that source turns out to have been unreliable, especially if it appeared reputable at the time, the results can be disastrous. This is especially true of matters requiring expertise.

On February 28, 1998, a leading British medical journal, The Lancet , published an article by Andrew Wakefield and twelve other researchers that found a link between autism and a vaccine for measles, mumps, and rubella — the MMR vaccine. Their explanation for what they thought might be going on was plausible: giving the three vaccines in combination caused intestinal problems and an immunity response, which ultimately led to problems with brain development in some children.

Given the worldwide rise in diagnoses of autism, and the number of parents whose children get the MMR vaccine each year, this was important news. The publication of the results in a reputable medical journal led to a firestorm of reporting on the subject. It was reported and re-reported, and became a widespread topic of conversation. As a first study on this explicit connection, it would be some time before the medical community had a closer look at the connection. Basically, the information originated entirely from one source in the network — the Lancet article. But people were hearing about it everywhere.

As it turned out, there were several serious problems with the study. First, it was based on just twelve children who were selected for the study. As autism can often appear around the same age as children get vaccines, it is natural to see an association between the two, and with a sample of twelve it is difficult to judge much of anything. Moreover, inferring any causation from such a study is clearly impossible. Although the article did not claim causation, it put forth a theory for causation that was misread by some as the conclusion of the study, and Wakefield suggested that the vaccines should be halted until further studies sorted out the correlation.

But there were even bigger problems with the study than the fact that it did not really establish any correlation or causation. Wakefield had received funding from a legal organization that was involved in suing vaccine manufacturers, which is considered a conflict of interest and of which The Lancet should have been informed. Most troubling was the report by Brian Deer, published in The Sunday Times on February 8, 2009, stating that the data were not accurate and did not match the actual hospital records, and that Wakefield had manipulated the data. 31 In 2010, the General Medical Council of the United Kingdom found Wakefield guilty of misconduct and struck him from the medical record (revoking his medical license) based on his conflict of interest and a finding that the study failed to act in the best interests of its vulnerable child patients. 32

The Lancet fully retracted the article in 2010. By then a number of studies that involved larger data sets from around the world found no connection between the vaccinations and autism. 33 However, much damage had already been done. In 1998, when the study was published there were seventy-four reported cases of measles in the U.K. 34 The MMR vaccination rate in the U.K. soon dropped from over 90 percent to 80 percent. Estimates based on World Health Organization data are that, between 2000 and 2010, approximately five million children in Europe aged two to twelve went unvaccinated. 35 As we know from Chapter 3, lowering a vaccination rate even slightly can allow a disease to resurge. Predictably, within a few years measles cases went up by a factor of more than twenty. Routinely measles outbreaks were in the thousands by 2007 and stayed high until 2014.

The consequences of a dip in a society’s vaccination rate are painful and can touch any of us. My close friend and coauthor, Toni Calvó-Armengol — some of whose contributions we have already seen in this book — died of the mumps in 2007. It was a year in which, with its slumping vaccination of children, Spain had over ten thousand reported cases of mumps. Such a sizable outbreak of a disease and its consequences, which could have been prevented by wider adoption of an effective and inexpensive (MMR) vaccine, are a tragedy.

Over time, the sheer volume of studies finding no relation between any vaccines and autism filtered into the conversations, pushing beliefs back and vaccination rates upward. Some of the increases in vaccination rates came from the reality of the diseases themselves. Once measles or mumps were resurging, people had to think harder about refusing to vaccinate their children. A discredited danger from the vaccine began to appear less worrisome than the real chances of a child getting the measles, mumps, or rubella. The higher the stakes, the more incentivized people are to actively seek and filter information, rather than let opinions come to them.

The Changing News Landscape

「Falsehood flies, and the Truth comes limping after it.」

 —  JONATHAN SWIFT 36

「Democracy Dies in Darkness」

 —  THE WASHINGTON POST

As the vaccination example makes clear, having an informed population requires that quality information be disseminated widely.

The Internet has brought with it some interesting twists on how information is both produced and spread. Ironically, the ease with which information spreads can have a negative impact on how it is produced. There are two main effects of the ease with which people can package and repackage information.

If I wanted to, I could set up an official-sounding organization tomorrow and, say, call it「The Global Vaccination Information Center.」I could build a Web site with an official-looking logo — making it look like it was scientific, or solid in some way — and I could start posting whatever information I wanted. I could build a series of such sites, and have them reference each other. I might also find other people with the same perspective who are writing about the same topics, and cite them, and they might start citing me. If when people look for「mmr vaccine side effects,」they start hitting my fictitious site I am in business. It is relatively inexpensive and can reach people around the globe. I could push my view even if it happened to be terribly distorted.

The point here is not about whether there are any dangers associated with vaccines, but about how information is produced and spread. The more sources of information that pop up on any subject that are intertwined and pushing unreliable information, the harder it becomes to learn the truth. It might so happen that it all balances out, but even if that happens, learning is slowed down when there is a higher ratio of noise to content. Providing fake news can also be used as a political weapon, to incite distrust and hatred between groups, and to move groups to action.

The Pakistani minister of defense Khawaja Muhammad Asif once wrote:「Israeli def min threatens nuclear retaliation presuming pak role in Syria against Daesh. Israel forgets Pakistan is a Nuclear state too AH.」37

What was that all about? The minister of defense of Pakistan was reminding Israel that Pakistan has nuclear weapons, and appears to have been saying this in reaction to thinking that the Israelis were threatening to use nuclear weapons against Pakistan. An Internet「news」Web site had published a story with the headline:「Israeli Defense Minister: If Pakistan sends ground troops to Syria on any pretext, we will destroy this country with a nuclear attack.」It seems that the Pakistani minister of defense believed the story and thought that Israel was threatening that if Pakistan meddled in Syria, then Israel would launch a nuclear attack on Pakistan. The tweet in reaction leads one down a scary path of「tit for tat」(retaliation in kind), when there was no「tat.」The Israeli defense minister never said what was quoted in the story, and in fact the story did not even have the Israeli defense minister’s correct name.

The Pakistani defense minister is not the first to be fooled by what he thought was real news. Hundreds of thousands of people were famously frightened on October 30, 1938, when Orson Welles led a broadcast of an adaptation of The War of the Worlds on the radio. They were fooled by a series of simulated news bulletins. For almost half an hour, the radio station did not interrupt the bulletins to tell the audience that they were all fiction. People who tuned in after the introduction were in for a shocking news stream covering an invasion from Mars. The broadcast bounced from news of explosions on Mars, to the landing of a cylinder in New Jersey, to interviews with military and government officials, updates on evacuations, and various other news flashes — all designed to sound like authentic news reports. A headline of The New York Times the next day read「Radio Listeners in Panic, Taking War Drama as Fact.」38 The broadcast snarled phone lines as many people called each other, the police, newspapers, and the radio station, trying to make sense of the broadcast. Early estimates of a million or more panicked individuals overstate the reaction, but there were likely hundreds of thousands of temporarily frightened people. 39

When fake news is less absurd than an invasion by Martians, it becomes yet harder to tell fiction from fact.

Even major news services stumble from time to time. Would you believe a story with a headline「Blondes to Die Out in 200 Years」if it appeared on the BBC news site? (Perhaps it should have said「Dye Out.」) The story 40 was based on a study by「German scientists」claiming that, due to blond hair being a recessive gene, blonds would become extinct within two hundred years. The story also predicted that the last blond would be born in Finland. No, it was not published on April Fool’s. As it failed to provide any detailed reference to the「study」that it discussed, it was hard to trace its origins. The study was also re-reported by other major news sources, such as CBS, ABC, and CNN, and attributed to the World Health Organization (which denied it). Mention of the fictitious study seems to have first appeared in a German women’s magazine called Allegra , which quoted a World Health Organization scientist who never existed. 41  Allegra ’s story was later relayed on the German wire service, which may have been what led it to be picked up by the other news services. Stephen Colbert, later making fun of the fiasco, proposed that selective breeding be used to save the blonds.

So, how well does a typical person do at sorting fake from real news on the Internet? Let’s set aside errors by major news providers and just examine telling clearer fact from fiction. Sam Wineburg and some of his colleagues from the Stanford History Education Group 42 tested whether students from middle school through college were able to infer the reliability of various information that they saw on the Internet. They were given tasks such as answering whether a posted picture of wilted daisies really offered proof of fallout from a nuclear disaster, discerning which stories on a site were news and which ones were advertisements, and discerning the reliability of articles on sites of professional medical organizations with varying motivations. The report summarizes the findings by saying,「When thousands of students respond to dozens of tasks there are endless variations….However, at each level — middle school, high school, and college — these variations paled in comparison to a stunning and dismaying consistency. Overall, young people’s ability to reason about the information on the Internet can be summed up in one word: bleak.」

Inaccurate news that enters our networks slows or even precludes learning by biasing beliefs away from the truth. However, beyond the proliferation of fake news, and sites that appear to be something that they are not, the production of detailed and accurate news is also under fire from another angle.

Technological changes have not only decreased barriers to entry, they have also increased the speed of delivery and updating. The combination of technological changes has immense benefits. All sorts of information about a myriad of facts is at your fingertips — or just a voice command away. Do you need information about a medical condition, or a recipe, a problem with an app, the current weather in Beijing, or do you want to learn more about Cosimo de’ Medici’s life? Answers are available in abundance, and are easy to find. Most are remarkably reliable and many can be accessed for free. The variety, depth, and quality of information at our disposal is astounding. Moreover, news can be reported quickly. If you want information about a celebrity’s death halfway across the globe just hours or even minutes ago, you can access it.

How does one reconcile this cornucopia of information with a concern about fake news and a claim that incentives for investigative reporting are under fire? Information about a recipe, how to get some app running, the weather, or Cosimo’s life are not controversial. They have no real policy implications. If you want information about rehabilitating a knee after surgery most sites will have similar information, but if you start looking for information about birth control you will see variance. If you start looking for information about the conduct of a prominent politician, a government agency, or some private company, things can get even dicier. To get objective views on a variety of such topics, we rely on journalists to dig up information and to sift through, sometimes mountains of it, and to paint a fair picture of what is going on.

Newspapers have a long history of breaking important stories, and some remarkably timely. Clare Hollingworth had one of the most spectacular starts to a journalistic career imaginable. In 1938 and 1939 Hollingworth was doing volunteer work in Poland, helping Czech refugees escape from lands annexed by Nazi Germany under the Munich Agreement. In August 1939, on a trip to England, her passion for writing and knowledge of the region around the German-Polish border sufficiently impressed Arthur Wilson, editor of the Daily Telegraph , that he hired her directly. Her first week on the job had her flying back to Warsaw. From there she was assigned to head to the southern part of Poland, in Katowice, near the current border with the Czech Republic — and the lands that Germany had taken over in 1938. Germany had closed the border and Hollingworth saw that only diplomatic cars were permitted to cross. Clare borrowed a car, complete with Union Jack flags, from her friend the British consul, with whom she had worked closely in helping refugees escape. She set off across the border to investigate. On her trip back, she passed along a valley in which German troops and tanks were massing. One of the large camouflaging covers blew off in the wind, and Clare was there to see what lay beneath. Upon her quick return to Poland, she wired the story that was to become the first of her many scoops, and one of the most important stories of the time. The headline of the Daily Telegraph on August 29, 1939, read「1,000 tanks massed on Polish border. Ten divisions reported ready for swift stroke.」She did not have to wait long for her second big story. Two days later, when she was back in Katowice, war erupted, and she was wakened by the explosions and gunfire. Hollingworth had many more scoops and adventures. She was the first to interview the Shah of Iran in 1941, she identified British agent Kim Philby as a Soviet spy in 1963, was an early predictor of a stalemate in the Vietnam War, and she opened the Beijing office of the Telegraph in 1973. It is said that even though she died at the ripe age of 105, she always kept a passport within reach in case a story called. 43

As more people get their news via various social media and news aggregators, the ability for any news service to get revenue for its reporting has diminished. You might think that reputations for accuracy and careful reporting would still be rewarded. However, having people do the dangerous legwork that Clare Hollingworth did throughout her career no longer pays. A story from a reputable news service delivering high-quality reporting can be almost instantly quoted, repackaged, and delivered elsewhere. The news services that delivered careful reporting used to be rewarded by having a time advantage: if they got a story first, it was theirs throughout that news cycle. It would take a day, or at least a half day, before it could be re-reported. Having a reputation for always being on top of the major stories and breaking new stories built followers. Now that lead time is a matter of minutes. That speed erodes the incentives to be a news producer rather than a news repackager. 44

This increasingly opens news to the Wild West of the Internet. Major social networking sites have advantages of scope. When people check up on what their friends are doing or saying, they can check news feeds that are tailored to their interests, which the site can infer. It’s also one-stop shopping: catch up with your friends and get news at the same time. Will these sorts of media have incentives to invest in major reporting of their own? It’s not easy to see why, as any story that they deliver can be repackaged — it would not be unique to their site. What will draw people to the sites is the social connections that they offer, and the news is packaged as the add-on, not as the main attractor. The emphasis becomes more on speed and matching topics to people, and there is less reward for providing careful and deliberate quality.

A report on the state of media by the FCC (Federal Communications Commission) 45 states:「An abundance of media outlets does not translate into an abundance of reporting . In many communities, there are now more outlets, but less local accountability reporting」(emphasis in the original).

The FCC oversees media in the U.S. and one of its charges is to promote competition and diversity in media. Its detailed report and concerns about the scarcity of investigative reporting seem well-justified. As an example, it cites situations in which reporting could have prevented disasters. One reference is to a mining disaster. As I found by looking into the details, the story is particularly disturbing:

Methane is commonly released in coal mining, as it is naturally stored in coal, and in fact coal mining is a major source of the methane released around the globe. When combined with the coal dust that is released during mining, it produces a highly explosive atmosphere. Ensuring the safety of a mine requires a series of precautions: proper ventilation to avoid a methane buildup, various spray systems that control coal dust, rock dusting (another method to control coal dust), and warning systems that monitor the atmosphere in the mine. At 3:27 p.m. on April 5, 2010, a thousand feet underground, in the Upper Big Branch Mine in West Virginia, a longwall shearer — an immense digging machine with enormous teeth — hit sandstone causing sparks.

The company used a code system to give employees advance warning of government inspections, actively concealed violations when inspections were imminent, and kept two sets of books: one for review by inspectors and the other only for company officials. Miners were told that raising safety concerns would jeopardize their jobs. As a result, there were many violations in the mine that day. Some of the critical spray systems were missing, and the company did not use adequate rock dust and so coal dust was at dangerously high levels. Supports were never installed in some parts of the mine, and their collapse limited ventilation, which led methane to accumulate. The methane detector on at least one piece of equipment had been deliberately rewired so that the equipment could operate illegally. 46 The methane that had built up in the area ignited and, combined with the extensive buildup of coal dust throughout the mine, caused a massive explosion that blew through miles of tunnels underground. Twenty-nine of the thirty-one miners who were working at the time were killed.

The Mine Safety and Health Administration’s (MSHA) investigation found that the explosion was due to flagrant safety violations, and issued 369 citations and more than $10 million in penalties. Controlling the coal dust and methane that are common in such mines is not difficult, but it does cost money. It turns out that such citations were not new to the mine, despite its concealment of many of its safety violations. For instance, The Washington Post reported that the mine had been flagged for 1,342 safety violations in the past five years, and fifty times in the previous month. But the reporting was reactive: it was after the explosion. The government had been issuing citations and the mine kept ignoring or appealing them, over a period of years, until disaster inevitably struck.

There were three levels of failure. Clearly the company flagrantly and criminally ignored their responsibility to ensure their miners’ safety. Second, the government system set in place to avoid such disasters had failed. In fact, there had been another explosion at the same mine due to a methane buildup and improper ventilation in 1997, and the MSHA knew of the significant methane buildup in the same area in 2004, but did not check whether the recommendations to fix the problem were ever implemented. Moreover, although there were numerous citations, the mine was allowed to operate for years despite its clear lack of safety. 47 This leads us to the third source of failure: a scarcity of reporting. We rely on investigative reporting to help unearth such failures before disasters occur. A free press ensures that public and private enterprises act in our collective best interest. When systems are corrupt or broken, it is hard to fix them if no light is shone on the problem until after the disaster.

In the year 2000, an estimated 56,400 people were employed in newsrooms at U.S. newspapers. By 2015, the number was down to 32,900. 48 Maybe that is not surprising, as newspapers have been under pressure from television and other media for some time. Moreover, many staff jobs have been automated, as now one does not need to talk to a person to place an advertisement, but can do it online. But the drop in numbers is not just due to the termination of nonreporting staff. For instance, television network news staffs have dropped by half since the 1980s, as have news magazine staffs since 1985. Even the fifty all-news local radio stations that existed in 1980 dropped to thirty by 2010 and reach only a third of the U.S. 49 A major source of news for many people remains local television news. However even there reporting is on the wane, and the amount of investigative reporting that local television delivers is limited. According to the FCC:「Topics like local education, health care, and government get minimal coverage. In a 2010 study of Los Angeles TV news by the Annenberg School of Communications, such topics took up just a little over one minute of the thirty minute broadcast.」50

One way directly to measure how much investigative reporting is being done is to see how much information is being requested. In the United States, reporters (or citizens) can request information under the Freedom of Information Act. Between 2005 and 2010 the number of requests for information covered by the Freedom of Information Act dropped by almost 50 percent. 51

In the world at large, newspaper circulation is dropping throughout North America and Europe, but actually growing in Asia. Economic growth, increased literacy rates, and low prices have increased circulation in China and India faster than circulation has dropped elsewhere, so that worldwide circulation is rising. However, revenues continue to drop, including digital revenues. Advertising revenues (including both print and digital) have plummeted, and revenues from digital subscriptions have grown much more slowly than news services had hoped. Overall, even though more than a third of people read newspapers online, revenue from all digital sources provides less than 8 percent of the industry’s total. 52

As the world becomes increasingly digital and mobile, where will the money come from to support investigative news production? It is not obvious how the Clare Hollingworths of the future will be paid. Although technology is amazing in the variety, volume, and speed of the information it provides, it is also becoming more challenging to earn revenue to pay for news that is hard to produce but easy to repackage. It tilts news production toward shorter, catchier, and more easily produced news, and away from the news that serves to police a democracy, which can be costly and time-consuming to collect.

As the FCC report suggests, it is not hard to see why David Simon, who reported for the Baltimore Sun for more than a decade before creating the HBO show The Wire , stated in a 2009 Senate hearing:「It is going to be one of the great times to be a corrupt politician.」53

Our discussion has covered a number of sizable impediments to learning in human networks. But there is still the elephant in the room: homophily. No story of social learning is complete without it.

Polarization: It’s the Homophily Talking

People can live meters away from each other and belong to almost completely different social networks of generation, social class, ethnicity, religion, and, in many cultures, of gender.

Despite the breadth and speed of modern connectedness, we have not seen a decrease in the polarization in opinions and beliefs that people hold. In fact, there is evidence that political views are actually diverging in many countries.

One way to see this is to use textual analysis to track how the ways in which people express themselves are changing over time. One of my colleagues at Stanford, Matt Gentzkow, together with Jesse Shapiro from the University of Chicago, were pioneers in using such techniques to study biases and slants in media. They teamed up with Matt Taddy to analyze partisanship by analyzing people’s speech patterns to quantify how partisanship has been changing over time. 54 They measure partisanship based on how easy it is to identify political party membership from the terminology a politician uses. When talking about immigration policy does a politician talk about「illegal aliens」or「undocumented workers,」and when talking about a cut in taxes does he refer to it as「tax reform」or ‘「tax breaks for the wealthy」? It is not hard to guess which term is used more often by people from which political party.

Subtle as well as blatant differences in terminology reveal one’s political leanings. It has not always been this way. Partisanship in U.S. politics was remarkably constant from the 1870s through the 1990s. However, after 1990 partisanship began a sudden and steep increase. For example, by counting how many times various snippets of words appear in one minute of a typical congressional speech from 1870 or 1990, a listener could be about 55 percent sure of the speaker’s political party. So, one minute of terminology would provide a slight clue to a person’s political leaning, but only 5 percent more than flipping a coin. However, by 2008 the terminology used by the different parties had diverged. By counting snippets of words used, and not the actual points made, one could be 82 percent sure of a speaker’s political leanings. This is after only one minute of speech. After four more minutes of tracking words used in a 2008 speech, we can be more than 95 percent sure of a speaker’s political party, while listening to speeches from 1990 or before leads only to a 65 percent certainty. 55 Although differences in the terminology are just one facet of polarization, they mean that our perception that politics is becoming more divisive is justified.

The increased partisanship in rhetoric is not just hot air: we also see more legislative gridlock. 56 Although parties have always disagreed, legislatures used to be places of compromise. Many of the bills that ultimately passed enjoyed bipartisan support. Votes now tend to be split more consistently along party lines. To measure this I pulled data on who voted on each side of a bill in Congress. 57

In 2015 there were 339 votes in the Senate. The two senators who almost never voted the same way were Barbara Boxer, a Democrat from California, and Marco Rubio, a Republican from Florida. They voted the same way only 11 percent of the time. Basically, if you knew how Barbara Boxer was going to vote on a bill, you could be pretty sure that Marco Rubio’s vote would be otherwise. The pair that agreed the most were Democrats Mazie Hirono from Hawaii and Jack Reed from Rhode Island, who voted the same way on more than 98 percent of the bills. In fact, the top thirty pairs in terms of voting the same way were all Democrats. Republicans were more split in their votes — a fracture that seems to be dominating the party’s politics to an extent not seen since the Whigs imploded in the mid-nineteenth century. The important point regarding partisanship is how infrequently senators agreed with each other across parties, and how less frequent this is compared to 1990.

In Figure 7.4, two senators are linked if they voted the same way on at least half of the bills. 58 In 1990 that connects 82 percent of the senators to each other, while in 2015 it connects only 53 percent of the senators to each other — and very few of those connections remain across parties. An interesting feature of the networks is that some of the senators are pulled away from the main clumps of the parties. The positions of the nodes were not picked by me, but by an algorithm that I used to draw the network. This algorithm groups nodes closer together that are connected to each other and moves nodes away from each other if they are less connected. 59

These patterns are not unique to U.S. politics. Nationalist parties have gained ground in countries like France and Austria. The Brexit vote uncovered a bitter divide in the U.K. A few years ago, Belgium spent a record 589 days without a government — with its Flemish-Walloon ethnic divide proving too wide. Spain spent much of 2016 with a zombie government, as its splintered parliament of regional interests was unable to put together a governing coalition.

How homophily affects the spread of information depends on the type of information in question. To understand this let’s have a look at two types of information that we are constantly processing.

We help each other out by relaying pure bits of information that one does not need to interpret:「A bank will be offering microfinance in our village.」「Our coach has been fired.」「Our company is in financial distress and will be shutting our plant next year.」「A new Star Wars movie is being filmed.」These are things that you either know or don’t — factoids or memes — all that is being transferred from one person to another is awareness . This sort of learning operates much like the contagion processes we saw earlier. It is enough to talk to one person to become aware, and often the information is easy to convey.

Figures 7.4a–b: Votes in the U.S. Senate. Two senators are linked if they voted the same way on at least half of the votes. In 1990, 82 percent of pairs of senators were linked. In 2015, only 53 percent of pairs of senators were linked. The data are all votes in the Senate from GovTrack, which I scraped using Python code from Renzo Lucioni, as adapted by Peter Aldhous. 60

A very different form of learning concerns things like estimating the weight of our ox. This is something for which we can have different estimates. How dangerous are certain vaccines? How large should our government’s budget be next year? How likely is it that climate change will become catastrophic? Will a certain candidate be a good leader? These are the sorts of questions to which the DeGroot model applies. Learning of this sort is more complex and exhibits different learning dynamics. We are aggregating: assessing and combining information from multiple sources.

There are dramatic differences between how these two varieties of learning are affected by homophily — as Ben Golub and I found when comparing DeGroot learning to simpler forms of diffusion.

Homophily’s effect on simple awareness of some factoid can be minimal. As long as a network is already dense enough to enable diffusion in its various parts, all that is needed is a small amount of interaction across groups to enable awareness of some fact to flow freely throughout the network. The explanation is quite simple, and in fact holds for contagion, diffusion, and learning settings in which the path structure of the networks matters most. 61 Suppose we have a society that is starkly divided, for instance a feudal society of nobles and peasants, or a company with plants in different locations, or a community that separates itself along ethnic lines. For awareness to reach across groups, only one connection needs to manage to spread the information from one group to another. If you are in a large company, if a rumor that the CEO is about to be fired spread widely among one sizable group of employees, say in production, it would be hard for it not to also leap across and spread widely among another sizable group such as those in marketing. It might never get started and stay within a small group of insiders; however, if it does manage to spread widely among any part of the company it will spread widely at more or less the same speed throughout the rest of the company too. 62 This echoes what we saw in Chapter 6: simple forms of contagion can easily breach schisms in social networks with nobles and monarchs dying alongside their subjects of many diseases. This is seen in Figure 7.5.

In contrast, homophily has a much more pronounced impact on more nuanced things like beliefs and opinions that take on a range of values — such as the extent to which human activity is affecting our climate. 63 If I am aggregating my friends’ views, and most of them start with similar views, then it can take an eternity for a minority view among a subset of my friends to begin to have an effect. We act like skeptics: the new information is going against most of what we are hearing and have been hearing. The process depends so much on repetition and inertia that a view only held by a small minority of our friends and acquaintances almost never has a chance to sizably shift our beliefs.

Figure 7.5: Spread of a meme with homophily: something that is either known or not spreads quickly, despite homophily.

Figure 7.6: DeGroot learning with homophily: Beliefs that can take on a spectrum of values shift slowly in the face of homophily — the relative weight on the new belief is low.

The difference between these two sorts of learning is seen by contrasting Figures 7.5 and 7.6.

The issue of vaccination provides a rich illustration. As we mentioned before, the reportedly fraudulent study published and later retracted led to a dramatic drop in vaccination rates. But that drop was not evenly spread. For instance, Minnesota is home to a tight-knit community of immigrants from Somalia. Although overall the state saw little reaction to the news about a link between MMR vaccines and autism, with vaccination rates remaining close to 90 percent, among the Somali community the vaccination rate dropped from over 90 percent to 42 percent by 2014. In fact, Andrew Wakefield, the lead author of the original study, visited the community several times between 2010 and 2011 to warn the population of the dangers of the MMR vaccine. His visits, and activism by other people fearful of the MMR vaccine, were effective in lowering vaccination rates. But the fear of vaccination was largely confined within the strong borders of the community, as were the dozens of cases of the measles that struck the Somali community in Minnesota in 2017. 64

Another example of the impact of homophily on beliefs and behaviors is seen in the longline fishing industry, as studied by Michele Barnes and her colleagues from the University of Hawaii at Manoa. 65 Longline fishing refers to the industry that produces fresh tuna and swordfish for much of the world. Hawaii is a major hub in the industry, supplying over a thousand trips annually, and generating between $50 million and $100 million a year in revenues. The name「longline fishing」describes a technique. Fish are caught on long lines that have baited hooks attached at various intervals, often branching off via short lines. Hundreds and even thousands of hooks attach to a single line. For tuna and swordfish the lines are run near the surface. A challenge posed by the technique is that it not only catches tuna and swordfish, but also other species of fish, as well as sharks, turtles, and even birds. These are called bycatch.

Bycatch are undesirable to the fisherman for a variety of reasons. First, some of the species are endangered and so their bycatch is limited. Second, bycatch can be dangerous. As you can imagine, bringing in large tuna and swordfish is already dangerous, but detaching a shark from the line can be even more challenging. Third, each hook catching bycatch is one fewer hook for the desired catch, and time is wasted removing bycatch from the lines and repairing broken gear.

There are various ways in which bycatch can be avoided: changing baits, varying the depth of the lines, knowing how to spot high shark areas, knowing lunar and seasonal patterns of water conditions and bycatch locations, and sharing information with other fishers about current shark and other bycatch activity. 66 Thus, the fishers learn from each other.

Among Hawaiian longline fishers, the network of information sharing is very homophilistic. Michele and her coauthors interviewed nearly all of the fishers and asked with whom they commonly exchanged important information about fishing. The fishers break into three ethnic groups: Vietnamese Americans, European Americans, and Korean Americans (ordered from largest to smallest group). The Vietnamese American and Korean American fishers are typically first-generation immigrants and speak limited English, while the European Americans tend to be from the mainland U.S. Homophily along these ethnic divides is strong: 88 percent of the fishers’ connections in the network are to their own ethnicity.

Barnes and her colleagues focused on shark bycatch, and found that Vietnamese American and Korean American fishers have similar rates of bycatch to each other, but rates that are significantly higher than that of the European Americans. Their estimate is that if all the fishers had the same (low) bycatch rate, ten thousand fewer sharks would be bycaught per year, corresponding to a 12 percent reduction of shark bycatch in the Hawaiian longline fishery.

Part of the differences in bycatch might have to do with cultural background. To see how much ethnic origin matters, Barnes and her colleagues dug deeper to look at how individual fishers behave. For instance, a few fishers of each ethnic background link to networks of some other group, such as a few European American, whose ties are predominately with Korean Americans. What predicts these individual fishers’ bycatch is not their own ethnicity, but the network group with whom most of their ties lie. As further evidence that information is playing a role, Barnes and her colleagues, from interviews with the fishers, found that they share information within their networks about locations to avoid shark bycatch hotspots and discuss updated fishing technologies that improve efficiency.

As no direct information flows were observed in the study, we cannot be certain that homophily’s impact on information is what caused differences in bycatch. Nonetheless, it does show us that different groups can maintain largely disjointed networks and different practices within the same industry, and in this case, in the same waters.

The Challenges of Being Human

「Only two things are infinite, the universe and human stupidity, and I’m not sure about the former.」

 —  ALBERT EINSTEIN

Whether Einstein said this or not, the quotation points out something important: our collective intelligence, impressive as it is, can get things wrong.

Our ability to grasp and communicate abstract thoughts has enabled us, as a species, to dominate our globe. Collectively humans have enormous knowledge, far beyond what any one of us could possibly master. But that same ability allows us to believe falsehoods. Our knowledge is not centralized and carefully aggregated by some omniscient being; rather it is decentralized and constantly changing. We process information from many sources. Very simple memes and ideas can flow easily, but we face significant challenges in processing and aggregating more complex information. Our networks are full of cycles and when we hear the same information from many channels, we are subject to double counting and can become convinced of information’s veracity, even when it is just the same news coming at us via multiple paths in our networks. Coupled with homophily, and people’s selective attention to sources of news, there is ample room for people to live in largely separate echo chambers and hold conflicting views across chambers.

Nonetheless, in spite of all of our human foibles, if: our networks are balanced enough, views in the population are centered around the truth, there are enough repeated conversations, and there are no strong preferences to manipulate or bias people’s beliefs, then we can reach a consensus and get things right. The more charged or political a subject becomes, and the more people want beliefs to reach certain conclusions, the more selective people become in whom they talk to and what they repeat and the more homophily has an impact, resulting in polarization.

In addition to the complexities of how information is processed through our human networks, we face the challenge that technology affects not only the spreading of news but also the collection and discovery of news. Along with the extraordinary benefits of constantly making it easier to store, post, search for, copy, and broadcast information, technology changes incentives to produce true or false news. As the cost of producing and spreading fake but believable news gets close to zero, along with a vanishing reward to extensive digging for the truth, we need to become better at filtering information.

8 • THE INFLUENCE OF OUR FRIENDS AND OUR LOCAL NETWORK STRUCTURES

「He that walketh with wise men shall be wise: but a companion of fools shall be destroyed.」

 —  PROVERBS 13:20

