# 2021008刘嘉的概率论R02

## 记忆时间

## 0200. 偷看上帝的安排

0201频率法概率是对发生频率的计算.md

0202大数定律局部频率不是整体概率.md

## 0201. 频率法：概率是对发生频率的计算

上一模块，我们重点讲了概率论的四块基石 —— 随机、概率、独立性和概率计算，也了解了概率度量的三种方式 —— 定义法、频率法和迭代法。现在，我们对概率论这座大厦已经有了基本的认知。从这一讲开始，我们进入课程的第二模块，我会详细讲讲上面度量概率的第二种方法 —— 频率法，也就是利用频率度量概率。频率法非常重要，不仅囊括了概率论中最重要的结论，还是现代统计学的基础，所以请认真学习这一讲。

### 1.1 概率就是对发生频率的计算

关于频率法，前面讲度量概率的三种方法的时候大概讲过，我再带你复习一遍。要理解频率法，我们得先理解「频率」这个词。这很好理解。频率，就是某个随机事件在整体事件中出现的比例。一个随机事件出现的次数除以整体事件的次数，得到的值就是这个随机事件发生的频率。

频率法就认为，在有足够多的数据的情况下，随机事件发生的频率会无限接近它真实的概率。比如，很多人认为飞机是一种危险的交通工具，到底有多危险呢？衡量飞机的危险性，最直接的方法就是计算失事率嘛。我们用过去这么多年飞机失事的次数，除以飞机总的飞行次数，得出的就是飞机失事的频率。频率法认为，这个飞机失事的频率，就是未来飞机失事的概率。

再比如，要预测江苏考生明年高考考上清华大学的概率。我们把历史的数据收集来，对于每一年来说，用清华大学在江苏省的录取人数，除以那一年整个江苏省的考生人数，就是那一年的录取率。把最近几年的录取率平均一下，就可以大致得出一名江苏考生明年高考考上清华的概率。

总之，在频率法的眼中，概率是可以靠随机事件发生的频率来计算出的。进一步说，频率法理解这个世界的底层逻辑是，一个随机事件的发生，是存在一个真实的、客观的概率的。只要我们做的试验足够多，或者掌握的数据足够多，计算出来随机事件发生的频率，就是可以无限接近这个真实的、客观的概率。

### 1.2 频率法在试验上被验证

说起来似乎很好理解，就是当数据足够多时，一件事发生的概率可以用它发生的频率来度量。但不知道你有没有这样的疑问：概率和频率压根不是一个东西，完完全全的俩概念。我们用频率来度量概率，真的靠谱吗？

好问题。我们不妨做试验检验一下。把定义法中常见的抛硬币的例子放到频率法中，去检验一下频率法是否真的可行。我们知道，在定义法中，硬币正面朝上的概率是 50%。假设现在我们不知道 50% 这个事情，我就抛硬币，正面朝上的频率是不是真的也是 50% 呢？

要不，你跟着我一起抛硬币试试？我抛一次，结果正面朝上。正面朝上的次数除以抛硬币的总次数，结果是 100%，和 50% 差得太远了。这样可以吗？好像不行。这就是单独的一次随机事件，好像还谈不上频率，频率总要多抛几次。那我们来抛 10 次。我刚刚抛出 7 次正面、3 次反面，正面朝上的频率是 70%，那正面出现的概率就是 70% 吗？这离 50% 还是差得有点远。能用抛了 10 次的这个频率，来度量硬币正面朝上的概率吗？看来还是不行。不过好像和只抛一次相比，离 50% 近一些了。要不我们再多抛几次？

其实，不用我们再抛了。这个世界，有很多数学家抛了几千几万次硬币，并把结果记录了下来。结果显示，当抛了成千上万次后，硬币正面朝上的频率确实会非常接近于 50%。也就是说，大量的试验证明，频率法是靠谱的。他们枯燥的、一次又一次地抛硬币，并记录结果，就是为了验证频率法和定义法，并给这些所谓的「显而易见的结论」建立信心。每当看到这些乏味的数字的记录，我都能鲜活地感受到他们对探索这个世界的满满的热情。

### 1.3 频率法在数学上被证明

当然，抛去这种对他们热情的感动，以数学的视角来看，试验结果再怎么和我们的猜测一致，也仅仅是经验，它怎么就能证明频率法一定正确呢？我们抛几千、几万次是这样，但会不会是有特殊情况没有遇到呢？万一抛几十万、几百万次就不是这样了呢？退一步说，就算频率法对抛硬币有效，它对其他随机事件的概率也有效吗？

这可不行。数学要的不是经验，而是完完全全的证明。数学和很多学科最大的差异，也正在于此。你兴致勃勃地说你用 10000 个试验验证了你的猜测，数学家往往会很冷静的杠一句：「你能证明吗？」

比如，你观察到「两点之间直线最短」，但你能保证所有的两点之间，都是直线的距离最短吗？这些问题靠有限的试验回答不了，而只能靠证明，靠逻辑推演。数学证明才是数学意义上的确信。现在你大概明白，为什么数学皇冠上的明珠往往都是对那些伟大猜想的证明了吧？比如哥德巴赫猜想、黎曼猜想等。

当我们通过试验验证了频率法可行之后，一众数学家就出场了，他们确实通过数学上的证明，彻底证实了这个结论。其中，第一个对频率和概率这个关系进行证明的，是雅各布·伯努利，一个十七世纪的瑞士数学家，也是那个时代最有才华的数学家之一。记住这个名字，雅各布·伯努利，他花了 20 年的时间，证明了这个「不言自明」或者说「显而易见」的结论 —— 随着试验数据不断累积，频率和概率的差距会越来越小。也就是说，只要重复的试验或者观测的数据足够多，随机事件发生的频率就会无限接近它的概率。这就是我们现在常说的「大数定律」。

1『伯努利也是我们流动力学伯努利方程的奠基人，真是大牛。（2021-02-12）』

证明过程我就不讲了，你需要知道的是：正因为在数学上证明了大数定律，我们才从根本上确认了用频率度量概率是合理的。换句话说，频率法是确定靠谱的。再深入一点，大数定律也证明了：在相同环境、重复试验的条件下，用历史数据预测未来是可行的，也是合理的。这就是统计学的根基，也是很多使用统计学方法进行研究的学科的根基。所以你看，大数定律是不是很重要？当年雅各布也意识到自己的证明很重要，所以将它称之为「黄金定理」。

### 1.4「足够多」到底是多少

如果你认真听肯定会发现，我在说大数定律的时候，都会加一句限定 ——「重复的次数足够多、积累的数据足够多」。可问题是，「足够多」到底是多少呢？事实上，大数定律是一个数学上「无限」的概念，类似于「无穷大」「无穷小」，是永远也无法触达的。在现实中，无限，臣妾真的做不到啊。

所以，为了让这么有用的大数定律在现实中真正发挥作用，就必须做一些限制条件，让需要重复的次数，或者采集的数据量变成有限的。对于这个问题，数学家专门设置了两个概念：一个叫「精度误差」，另一个叫「置信度」。听着很高大上，但我一解释你就能明白。

大数定律告诉我们，数据或者试验越多，频率就会越接近概率。当然，只是接近，在真实概率上下浮动。这种浮动的范围就是「精度误差」。比如，前面那些数学家们抛硬币的结果，并不是刚好等于理想的 50%，这个和理想值之间的差距，就是精度误差。假如你抛出正面朝上的频率是在 47-53% 之间，那么精度误差就是 +-3%。针对这 +-3% 的误差率，我做 100 组试验，或者统计学上叫 100 组样本，如果有 95 组样本算出来的频率，正好在这个精度误差的范围之内，我们就称之为 95% 的「置信度」。

1『大赞啊，通过这里例子算是基本明白置信度的概念了，之前一直迷迷糊糊的。精度误差和置信度，做一张主题卡片。（2021-02-12）』——已完成

你现在不理解也没有关系，这两个都是统计学的概念。你只需要理解一点 —— 通过这两个限定，容忍一定错误的发生，我们在用频率度量概率时，可以大幅减少试验的次数或者采集的数据量。比如，99.9% 的置信度和 2% 的精度误差，就可以把重复的次数从无限降低到 7000 次左右；如果把置信度下降到 95%，重复次数可以降低到 2500 次左右；如果再放宽点标准，把精度误差从 2% 变成 3%，试验次数可以下降到 1000 次左右。

今天，95% 的置信度已经成为许多学科，比如经济学和医学的实际参考标准。民意调查也常常将 95% 的置信度和 3% 的精度误差结合在一起，选择调查人数。本质原因就是我们刚才说的，在保证实用性，也就是概率相对准确的情况下，大幅度降低试验或者样本采集的数量。

你看，当我们试图通过频率来测量概率的时候，数学上完全理想的效果是无法达到的。我们必须在保证概率的精度，和减少工作量之间进行取舍。现实中，几乎所有的数据调查和统计结果，一方面，都是基于用频率来测量概率这个底层逻辑；另一方面，也都要进行相应程度的妥协。

### 黑板墙

思考题：你最近遇到过要用频率度量的概率问题吗？这些度量有标注限定条件吗？

下节预告：我们来详细看看大数定律这个概率论中的黄金定理。

#### 01

刘老师说出了开赌场赚钱的核心基石。频率法，有一个前提，就是样本之间的独立性。一群人猜牛的体重，如果彼此不受影响，猜的人越多，平均后越接近真实值，但如果刻意影响判断者，就会出现羊群效应。桥水的达利欧，这个策略用的非常好。

作者回复：非常好的联系和引申。需要注意一点的是，大家一起猜牛的体重，平均更接近真实的情况，这件事反应了多样性的价值。但这件事成立有个前提条件，这是很多讲多样性忽略的，这是一个数学条件，就是每个人猜对的概率要大于随机猜测猜对的概率。本质上群体还是要有些知识储备和认知。举个例子，我掷个子，不给大家看，让大家猜，群体智能多样性就不起作用了。

#### 02

记得一位教授在教授概率论的时候，会给学生们布置一道作业：每个人回去投掷 100 次硬币，然后把每次的结果记录下来。教授说他每次都能找出那些没有扔硬币，直接按自己的想法填结果交作业的同学 —— 在真正的随机情况下，一定会出现连续几次、甚至十几次是同一面的情况，但自己想当然写结果的同学都会认为只有正反交替出现才看起来足够像随机。

作者回复：我们都是蹩脚的随机制造者，主观性越强，也就是你越想制造随机，越不随机。

#### 03

归纳法只是经验层面，不可靠。数学是逻辑抽象层面的东西，就像现实中不存在没有宽度的线，没有厚度的面。只是归纳法得到的结论，大多不准确，就像罗素的火鸡一样，永远不知道圣诞节的到来。大数定律也是因为数学上证明了，才能是绝对正确。

作者回复：非常好。归纳法不可靠。不过，归纳法目的不是追求可靠性。归纳法解決的主要问题之一是执果索因，为认识规律做铺垫，推出一般性猜想或假说，然后再运用演绎对其进行修正和补充，直至最后得到物理学的普遍性结论。

#### 04

大数定律告诉我们，我们的个人命运不取決于一两次选择，而取決于我们的系统。当我们在人生的旅途中犯过一两次失误，错误时，不要纠结，它并不能把你怎样，你应该努力多去尝试，用更多的选择，努力，稀释曾经的过往，最终使得自己的人生更加辉煌。当然前提是数据量一定要大，所以，突破自己的舒适区，多去尝试，尝试，再尝试。

作者回复：不过，数学的无限可能非常冷酷。你以为系统是你的人生，对世界来说，系统是很多人的人生。打个比方吧，比如俄罗斯轮盘赌，六个弹孔放一颗子弹，这是系统。你觉得打 6 枪是人的一生，不管多少困难熬过这一颗子弹就好了，结果可能是，每枪是一个人的人生，有的人一生太平，中了那枪的你一生坎坷。你知道活在百年战争五代十国这样的乱世，就再也等不到贞观之治康乾盛世。无限是个混蛋。

#### 05

想到了胡适博士提出的「大胆假设，小心求证」与老师在这一讲中采用的概率法的差异。前者最大的问题在于给自己预设了立场和结论。这样一来，逻辑的链条变成了：设立结论 => 寻找材料 => 证明结论，但是科学的研究逻辑应该是归纳法，即：搜集材料 => 总结提炼 => 得出结论。可能这样看没有什么太大的问题，但是实际应用起来就会出现麻烦，1）因为在人文社科领域，能够利用的材料太多了，甚至于可以说「你想要的我都有」，如果研究者预先设定了立场和结论去搜集材料，很容易收集到符合自己结论的证据，而忽略与自己结论相左的材料（有时候并非是有意地去选择材料，而是在预设立场后，检索材料的范围会自然而然地倾向自己的立场）; 2）预设立场之后很容易由意见之争演化为意气之争，即大家不在事实的层面进行争论，而是在尽力维护自己的立场，争个输贏，争个胜负；因此，这样的研究路径得出的结果可能看上去并没有问题，材料证据可以对应结论，但是可能会造成严重的以偏概全，甚至与事实完全相反，也就是网上经常说的，成功的谎言都是不完整的事实。当然如果能做到完完全全的「小心」，这样的情况是可以避免的，但是能做到这种程度是很难的，所以不推崇这种研究方法。而以归纳法的形式进行研究，尽力保持空白的状态对材料进行搜集，再对这些材料进行分析，有多少材料表现了 A 结论，多少表现了 B 结论，多少 C。哪条是主流，哪条是支流，这样虽然也难以做到完全的公平公正，但是相较前者好了很多。

#### 06

说起这个就想到那位曾在航空公司工作的「内鬼」，利用之前积累的数据，估计飞机晚点频率骗保的事。这个案子看到的时候我也在叹气，延误保险这种产品能被人利用到这个地步，说是骗保数额过百万，如果不是这个人一直这么干，这种保险运营的低效还一直不会有人注意到吧。现实中一旦有意识地记录一些事情发生的频率，不少魔鬼就出现了。

作者回复：后面课程里还专门讲到了这个例子。

#### 07

世界上，有些事情确实是可以运用频率法来度量概率；通过重复验证、总结经验，我们可以得出置信度较高的结论，趋近于真实的概率。比如说在工程上，包括在药物实验上，我们通常会要求 95% 以上的置信度，这样就可以在有限次实验的基础之上，得到非常接近于真实概率的结论。但是，在真实世界中，很多事情都是难以重复，也就无法运用频率法和置信度，来进行验证、总结经验了。比如，对于投资这件事情，我们就很难用量化度量的方式来计算概率。隔壁吴军老师《信息论》课程中也曾提到过不少关于置信度的例子。很多基金经理宣称自己 10 年的平均回报率能够跑大盘；但是，如果我们以月为单位进行统计，按照股市的波动幅度，至少需要 1000 个以上的样本，也就是大约需要 100 年左右的数据。那么，1 0 年的数据，样本无疑是太小了，这样一点差异根本就不存在很高的置信度。今天，无论我们从事任何行业，学会运用频率法和置信度来计算事件的概率，确实是需要掌握的工具。但是，也要切记，世界上很多事情是无法重复验证的；对于前人的经验，但是切忌照搬照抄，而是要在具体的工作中，进行反复的检验、验证，并根据实际情况进行调整、优化。只有这样，才能总结出置信度更高、更可靠的经验。

#### 08

我是在线教育行业的产品经理，当用户数量达到一定规模时，有点理想的公司都想尝试 AI 教学，结合今天所学，我理解下，如果按 95% 的置信度（实际上学习这件事情精确度 99% 才是理想），和 2% 的精度误差来度量频率，知识点下答对题目的频率，每个题目是关联知识点，借此来判断知识点的掌握程度，那么单一知识点下是不是至少要有 1000 道题，每位同学要进行作完这 1000 多道题之后，就可以知道他这个知识点的掌握程度呢？这是学生个体情况。

然而，每个学生吸收程度会分个等级 ABCD，如何让程序准确识别学生所处等级呢，首先是不是随机 1000 多名学生（假设初中学段），然后，从 2670 个知识点随机 1000 个知识点配 1000 道题目，最后根据分布划出本校的学生分层。

第一步计算学生自身情况，第二步计算学校内所处层次，第三步结合知识图谱指引学生如何提升自己，这一切都是动态的，不知道是不是这么理解，如果是这样一个量级的话，那么学生要是拿下初中学段 2670 个知识点需要做的题量百万级别，为了精准推送相关题目，学生又进入题海中。

现在没有算法的情況下，粗暴的作法是一个知识点直接给 3 道题，一次性答对标记掌握，一道不对推 3 道，直到做对，结果学生还是在题海中。这种应用场景下，题目和知识点关联，题目难易度是动态的，学生层次也是动态的，是如何进行数据上测量，给学生更精准的题目进行查漏补缺的练习，提供学生和题目直接的匹配度。

作者回复：学生会做这道题，掌握知识点也许不是个随机事件，不需要频率法度量。这个能力相对稳定，随机因素很小，就和视力一样，最下面那行也就 8-10 就差不多了。在线教育，我的理解这是一个推荐系统，到底是知识图谱的这种给定逻辑的推荐（依照知识的树状结构前后关联），还是基于数据相关性（错了这题的孩子也经常错那题），还是再综合学习记忆的科学研究方法（推半个月前会做的题目加深记忆）。我觉得这个是可以通过 AB 测试分析最后成绩提高结果，来评估推荐策略的好坏。

#### 09

昨晚的直播说到高考的题数很多，这其中是不是有利用到大样本大于均值的概率小于小样本大于均值的概率？

作者回复：正态分布，出 50 题，比只出 20 题，方差更小，波动性更小。对高考来说，能考出你真实的能力的概率越大（也就是你考出你能力的分数附近的概率越大）。

#### 10

大家在购买车辆（产）保险的时候，就会涉及到用频率度量的概率问题，例如刚买车的时候，想开车，但驾驶技术没那么娴熟，那么自然就会购买全险，像现在由于疫情，外出的机会大大減少了，而且也由于积累了丰富的驾驶经验与知识，那么购买的车险的项目就会有所删减，甚至会直接调整保额的高低出行次数 x 驾驶技术就是理解为频率，而保额就所谓的限定条件。

作者回复：车险的事儿，可以再深入一点。现在车险基本上是频率法测算整体出险概率，配合个体出现次数做一个调整。如果，能做到对每个人出现的概率进行准确的评估，比如按照整体概率，一年一万块车险，但你开的又少，又不出市区，驾驶习惯有非常好，家里还有大车库，如果算出的出险概率是整体的 1/10，我就可以卖你 3000 块的车险，注意，这可不是薄利多销，这毛利可是更高了。还更加便宜。是不是很有趣？再深一步，谁会知道你的驾驶习惯？驾驶路径？用车情況？高德？百度地图？不是的，可能最好的是 #车# 本身。而可能未来最适合的卖车辆保险的不是保险公司，而是车厂。

#### 11

各种抽卡机制的手游真的是符合公布出来的概率吗？来，实践一下，只要肝得足够久、氪金足够多，会得到答案的。虽然我真的这样想，但是我亲友的观点也非常值得关注。她说总是在不想玩的时候会抽到一张 sg，因为「游戏在挽留你」。假设是真的，那么我觉得游戏应该是在收集一些类似于游戏时长和各种动作的数据，推测「要离开」，然后调整了概率。

作者回复：留住用户，游戏里的随机更像个性化推荐。

#### 12

在早期英文里面的加密解密，破译者利用单词字母出现的频率破解加密文本，是否就是用了这节课的频率法？在密码学里面有置信度这个概念吗？

作者回复：是的，也有。

#### 13

今天的课程，让我想起归纳法，也叫归纳推理。归纳推理是一种由个别到一般的推理。由一定程度的关于个别事物的观点过渡到范围较大的观点，由特殊具体的事例推导出一般原理、原则的解释方法。自然界和社会中的一般，都存在于个别、特殊之中，并通过个别而存在。一般都存在于具体的对象和现象之中，因此，只有通过认识个别，オ能认识一般。人们在解释一个较大事物时，从个别、特殊的事物总结、概括出各种各样的带有一般性的原理或原则，然后才可能从这些原理、原则出发，再得出关于个别事物的结论。这种认识秩序贯穿于人们的解释活动中，不断从个别上升到一般，即对个别事物的认识上升到对事物的一般规律性的认识。

而使用频率法去逼近那个理应存在的「概率值」，正是这样的一种推理方法在数学中的代表性表现。有人说，我们现有的知识中，99% 都来自于归纳推理，没错，因为这是我们去认知这个世界几乎唯一的方式一观察，归纳，总结，得出经验，形成理论。但是我们必须得注意，基于归纳推理得出的经验或者理论，在现实应用中天生可能面对一个问题，基础条件的变化和外界环境的变化。

不知道你是不是注意到课程当中的一句话：在（相同环境、重复试验）的条件下，用历史数据预测未来是可行的，也是合理的。但是现实中，要么就是环境变化了，要么就是实验的基础条件发生变化了，总会有些变化，让我们不得不舍弃过去的经验，比如我们现在常说的 VUCA 时代，比如总有新技术出现会影响我们的工作和生活。

那么，是不是在这样的情況下，我们就不能再用归纳推理去总结和归纳自己的经验和理论了呢？并不是，我们发现，通过自己经历的事件去总结经验并形成自己的決策理论模型依然是我们当前提升自己能力的基础。只是在现在和未来，我们还需要另一个底层认知拆分清楚事件发生的前提假设和外界环境，搞清楚到底是哪些要素发生了变化，根据自己的实际情况才能做出正确的決策或者选择。明白在一件事情里，哪些是自己知道的，哪些是自己不知道的，哪些是不变的，哪些是变化的。分清知之为知之，明确不知为不知，才是真知也。

## 0202. 大数定律：局部频率不是整体概率

上一讲我们从整体上介绍了频率法，知道了当数据无限的时候，频率就将趋于概率。这给我们认识世界带来了很大的信心。因为我们知道，我们可以用某一件事已经发生的频率，去预测它未来发生的概率了，也就有了通过历史预测未来的可能。而频率法的基础，正是大数定律。所以这一讲，我就带你详细了解一下大数定律这个概率论中的「黄金定理」。

### 2.1 大数定律证明了整体的确定性

上一讲说了，雅各布花 20 年时间证明了大数定律。其实准确地说，他证明的是「弱大数定律」。什么是弱大数定律呢？就是说，试验的数量越多，频率接近真实概率的可能性越大。注意，这里说的是「可能性」。也就是说，弱大数定律只证明了，随着数据的增加，频率接近概率的可能性越来越大，而不是 100% 的一定接近。这在数学上有个专业的名词，叫「依概率收敛」。

弱大数定律是一个伟大的证明。雅各布的伟大之处就在于，他找到了对抗局部随机性的办法，用频率构建起了确定的整体概率。通过他的证明我们知道，不管局部怎么随机，整体概率稳定的可能性是非常大的。但整体概率稳定的可能性很大和一定稳定，还是有些差别的。只有一定、100% 的稳定，才是真正的确定性。

一个世纪前，苏联数学家、概率论的先驱柯尔莫哥洛夫 (Kolmogorov) 在雅各布的基础上，做出了更加严密的证明，也就是「强大数定律」。他通过计算证明，随着数据越来越多，频率接近概率不仅是可能性越来越大，而是几乎一定。也就是说，随着数据越来越多，频率最终一定会接近真实概率。

到此为止，我们先用弱大数定律找到了整体，又用强大数定律确定了整体一定是稳定的。大数定律又被称为「黄金定理」，它让我们真正能用整体的确定性来对抗局部的随机性。

### 2.2 现实中的频率都是局部频率

有了整体的确定性，我们就能用大数定律搞定这个世界了吗？

很遗憾，不是的。因为大数定律起作用有个限制条件，只有在数据无限的情况下，随机事件发生的频率才等于它的概率。但上一讲说了，无限是个数学概念，现实中哪有什么无限呢？无论我扔多少次硬币，都是有限次数的；无论我记录了多少次飞行的数据，都是有限次数的；无论我记录了一个球员多少场比赛投篮的命中情况，都是有限次数的。准确地说，现实中所有的事情都是有限的。我们记录的所有频率，都只是局部频率。

问题是，只有数据量足够多的时候，局部频率才会接近真实概率。当数据量很少的时候，一件事发生的频率可能和它的真实概率相差很大。

举个例子吧。英国和法国曾经共同研制了一款超音速客机，叫「协和式客机」，1976 年投入使用，从巴黎飞到纽约只需要 3 小时 20 分钟，比普通民航客机节省超过一半的时间。协和式客机不仅拥有当时最高级别的安全设计，还有当时最高级别的安全保障，所以在长达 24 年的飞行中，它没有发生过一起致死事故，一度被认为是世界最安全的飞机。直到 2000 年 7 月 25 日，协和式客机出现了一次坠机事故。

截止那个时候，协和式客机总共飞行了八万多次，因为这次坠机事故，它的致死事故率立即从 24 年来的 0 上升到了八万分之一，也就是每百万次飞行失事 12 次。而作为对比，波音 737 的飞行超过一亿次，它的致死事故率只有百万分之 0.4，只有协和式客机的 1/30。这是协和式客机唯一一次重大事故。但因为这次事故，它一下子从世界上最安全的飞机变成了最危险的。仅仅三年之后，协和式客机就停飞了。

你说波音 737 真的比协和式客机安全 30 倍吗？不一定。因为协和式客机的飞行数据太少了，只有区区八万次，它出事故的频率和真实的事故率之间，可能有很大的误差。而这个误差到底有多大呢？那次失事是意外，还是飞机的设计真的有缺陷？八万分之一的致死事故率到底比真实概率大，还是比真实概率小？这些我们都无法知道，因为没办法让协和式飞机再飞一亿次了。

我们只知道，当数据有限的时候，局部频率和整体概率之间是有误差的。只有随着数据量的增加，局部频率才会越来越接近于整体概率。大数定律就像一根绳索，用整体的确定性约束着局部的随机性，随着数据的增加把频率这个口袋越勒越紧。

### 2.3 整体不需要对局部进行补偿

这种整体对局部的约束作用，是怎么进行的呢？

很多人会有一种朴素的想法，叫作「补偿思维」。举个例子，当硬币连续抛了 10 次都是正面朝上后，很多人就认为，下一次反面朝上的概率肯定得更高一些。因为只有这样才能补偿不平衡的状况，要不然怎么保证最终硬币正面朝上的概率还是 50% 呢？看起来很合理，但我要告诉你的是，这种思维是错的。整体不需要通过补偿来对局部产生作用，大数定律并不通过补偿来实现。

1『关键信息来了，整体不需要对局部进行补充，即大树定律并不通过补偿来实现。做一张主题卡片。（2021-02-12）』

还是刚才的例子，假如抛硬币前 10 次都是正面，那想让正面朝上的概率稳定在 50%，后面是不是得抛出更多的反面来补偿呢？不需要。比如，我们再抛 1000 次，假设 500 次正面，500 次反面，没有补偿吧？现在正面的频率是多少呢？510 除以 1010，下降成了 50.50% 了。抛 10000 次，假设 5000 次朝上，5000 次朝下，还是没有补偿，这时候正面朝上的频率，就变成了 50.05%，非常接近于 50% 了。

打个比方，把一勺糖放在一杯水里，你会觉得很甜，可是放到大海里呢？海水的味道几乎不会有任何改变。我们并没有把糖从大海里取出来，糖仍然在，只是大海里的水太多了，一勺糖对它的影响就被削弱，小到可以忽略不计了。就像网上被大家吐槽的，五块钱的玛莎拉蒂跑车的优惠券，优惠五块钱，对买玛莎拉蒂跑车没影响呀。

明白了吧？大数定律不会对已经发生的情况进行补偿，而是利用大量的正常数据，削弱那部分异常数据的影响。正常数据越多，异常数据的影响就越小，直到小到可以忽略不计。

### 2.4 整体通过均值回归对局部起作用

可问题是，我们怎么保证未来一定有大量的正常数据呢？换句话说，整体的确定性到底是如何保证的呢？这就要涉及到另一个词 —— 均值回归。

均值回归的意思是说，如果一个数据和它的正常状态偏差很大，那么它向正常状态回归的概率就会变大。现实中，均值回归的例子很多。比如，身高特别高的人，孩子往往不如他高；连续几年超高收益率的基金经理，后几年往往神奇不在…… 怎么理解这种现象呢？

其实，均值回归更准确的叫法应该是「趋均值回归」，趋向均值的方向回归。所以它产生作用的对象，是那些特殊的、异常的、极端的数据。这些异常的状态是没法长期持续的，所以回归正常值的概率会变大。不过，至于是比正常值稍微高一些，还是稍微低一些，都有可能，完全是随机的。

比如，一个同学正常的数学水平是 80 分，这次超水平发挥考了 100 分，下一场考试，他大概率考不到 100 分，但可能考 90 分，可能考 80 分，也可能考 70 分。这些都比 100 分正常，都更接近他的真实水平，所以都是均值回归。而不是说上次考 100 分，这次只能考 60 分、50 分来补偿上次的高分。

总之，大数定律不需要补偿，而是通过均值回归，通过产生大量的正常数据，削弱之前异常数据的影响。明白了这个道理，再去审视我们的生活，很多现象就好理解了。比如我们经常会说一些俗语，运气不好的时候，会说「三十年河东，三十年河西」；打牌或者玩游戏连着输的时候，会说「否极泰来」。怎么理解这些话呢？

严格地说，都有一定的道理，但又都不全对。为什么说有一定的道理呢？因为它们蕴含了朴素的概率思维，知道在大多数情况下，不正常的状态难以持续。正常情况下，谁的运气也不可能一直坏嘛。为什么说它们不全对呢？因为不管是「三十年河东，三十年河西」，还是「否极泰来」，背后都蕴含着刚才我们说的补偿思维，认为三十年河东后，之后三十年一定河西；「否极」后一定会「泰来」，一定有好运气。

而我们现在知道，大数定律不需要通过补偿来实现。极度的坏运气过后不一定就有好运气，而是通过均值回归，让运气回到不那么坏的正常状态。所以更准确的说法应该是，「否极」后，可能「泰来」，也可能是回到运气不好不坏的状态，都有可能。

### 黑板墙

思考题：你还能找到类似于「三十年河东，三十年河西」「否极泰来」这样的俗语吗？能不能用这一讲的内容分析一下？

下节预告：说完了频率，学会了计算概率，我们就能清晰的衡量一件事的价值，从而做出科学决策了吗？这个问题，我们下一讲再说。

#### 01

真正重要的不是问题，而是看待问题的态度，我们的老祖宗特别明白这个道理，所以有很多帮助我们积极思考的话流传至今。比如：「山穷水尽疑无路，柳暗花明又一村」，「船到桥头自然直」。现在我们知道了，就局部的个体而言，这句话是不成立的，你可能真的穷途未路，也可能「船到桥头自然沉」，但是，只有后来有更多的船均值回归，那统计结果就是另一首诗句「沉舟畔千帆过，病树前头万木春」。

#### 02

大概明白了大数定律的补偿和均值回归，均值回归通过后面大量数据来「稀释」前面的数据，以回归到均值。但是如果后面的数据量不够大呢？不能大到足够稀释前面的数据呢？比如，抛硬币，一共可以抛 100 万次，前 99 万次都是正面朝上（虽然概率小，但肯定存在这种情况），最后剩的 1 万次，正面朝上和朝下哪个多？仅剩的 1 万次如何来「稀释」前面的 99 万次，以期回归均值？

作者回复：大数定律是个无限。不存在后面数据不够。但现实却是。所以这就是随机的力量，我们叫运气。

#### 03

又查了一下均值回归，这最初是金融学的一个概念，股票价格无论高于或低于价值中枢（或均值）都会以很高的概率向价值中枢回归的趋势，所以没有股票会一直涨、也没有股票会一直跌。按理说在低于中枢回归值的位置买入，长远来看肯定会赚啊，可为什么大部分人总在亏钱？我觉得原因有两个：1）在高于均值的位置买入，虽然也可能会涨，但难度更大；2）时间不够长，股票价格还没有均值回归。

在了解均值回归的过程中，还看到了均值回归遗传：比如父母的身高、智商等等很突出，到下一代却很平庸了，然后我突然联想到每个人的运气也应该会符合均值回归吧？那会不会每个人的均值回归水位线也有高低之分？这样一想，是不是人与人之间真的就不太公平？

作者回复：难度更大，翻译成概率的语言就是概率更小。