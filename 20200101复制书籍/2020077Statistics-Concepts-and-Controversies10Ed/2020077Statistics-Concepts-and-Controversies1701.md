Learn some fundamental concepts about chance behavior.

Interpret probabilities like 1 in 133,000.

Identify some common「myths」concerning chance behavior, such as misinterpretations of the law of averages and the notion of the「hot hand」in sports.

Case Study: Shared Birthdays

On January 14, 2017, CBS News reported that in the Gardner family, mom, dad, and son all share the same birthday. The news article went on to say the odds of that happening are about 1 in 133,000. That’s a lot less likely than getting hit by lightning sometime in your lifetime, which some put at roughly 1 in 12,000. The rarity of the event is what made the story newsworthy.

Just how amazing is this event? By the end of this chapter, you will be able to assess coincidences such as a mother, father, and son all having the same birthday. Are these events as surprising as they seem?

The Idea of Probability

Chance is a slippery subject. We start by thinking about「what would happen if we perform the same action over and over many times?」We will consider examples like the 1-in-2 chance of a head in tossing a coin before we try to think about more-complicated situations.

Even the rules of football agree that tossing a coin avoids favoritism. Favoritism in choosing subjects for a sample survey or allotting patients to treatment and placebo groups in a medical experiment is as undesirable as it is in awarding first possession of the ball in football. That’s why statisticians recommend random samples and randomized experiments, which are fancy versions of tossing a coin. A big fact emerges when we watch coin tosses or the results of random samples closely: chance behavior is unpredictable in the short run but has a regular and predictable distribution of outcomes in the long run.

Toss a coin or choose a simple random sample. The result can’t be predicted in advance because the result will vary when you toss the coin or choose the sample repeatedly. But there is still a regular pattern in the results, a pattern that emerges clearly only after many repetitions. This remarkable fact is the basis for the idea of probability.

Example 1

Coin tossing

When you toss a coin, there are only two possible outcomes, heads or tails. Figure 17.1 shows the results of tossing a coin 1000 times. For each number of tosses from 1 to 1000, we have plotted the proportion of those tosses that gave a head. The first toss was a head, so the proportion of heads starts at 1. The second toss was a tail, reducing the proportion of heads to 0.5 after two tosses. The next four tosses were tails followed by a head, so the proportion of heads after seven tosses is 2/7, or 0.286.

Figure 17.1 Toss a coin many times. The proportion of heads changes as we make more tosses but eventually gets very close to 0.5. This is what we mean when we say,「The probability of a head is one-half.」

The number of tosses 1, 5, 10, 50, 100, 500, and 1000 are represented along the horizontal axis. The proportion of heads is represented along the vertical axis and its values range from 0 to 1, in increments of 0.1. The curve originates at (1, 1) and takes a steep decline to (5, 0.2). Then, the curve passes through many points with multiple rises and falls and finally ends at (1000, 0.5). A dotted horizontal line starts from the point 0.5 on the vertical axis and is parallel to the horizontal axis.

The proportion of tosses that produce heads is quite variable at first, but it settles down as we make more and more tosses. Eventually, this proportion gets close to 0.5 and stays there. We say that 0.5 is the probability of a head. The probability 0.5 appears as a horizontal line on the graph.

「Random」in statistics is a description of events that are unpredictable in the short run but that exhibit a kind of order that emerges only in the long run. It is not a synonym for「haphazard,」which is defined as lacking any principle of organization. We encounter the unpredictable side of randomness in our everyday experience, but we rarely see enough repetitions of the same random phenomenon to observe the long-term regularity that probability describes. You can see that regularity emerging in Figure 17.1. In the very long run, the proportion of tosses that gives a head is 0.5. This is the intuitive idea of probability. A probability of 0.5 means that the outcome「occurs half the time in a very large number of repetitions, or trials, of a random phenomenon.」

Key Terms

We call a phenomenon random if individual outcomes are uncertain but there is, nonetheless, a regular distribution of outcomes in a large number of repetitions.

The probability of any outcome of a random phenomenon is a number between 0 and 1 that describes the proportion of times the outcome would occur in a very long series of repetitions.

We might suspect that a coin has probability 0.5 of coming up heads just because the coin has two sides. We might be tempted to theorize that for events with two seemingly equally likely outcomes, each outcome should have probability 0.5 of occurring. But babies must have one of the two sexes, and the probabilities aren’t equal—the probability of a boy is about 0.51, not 0.50. The idea of probability is empirical. That is, it is based on data rather than theorizing alone. Probability describes what happens in very many trials, and we must actually observe many coin tosses or many babies to pin down a probability. In the case of tossing a coin, some diligent people have in fact made thousands of tosses.

Example 2

Some coin tossers

The French naturalist Count Buffon (1707–1788) tossed a coin 4040 times. Result: 2048 heads, or proportion for heads.

Around 1900, the English statistician Karl Pearson heroically tossed a coin 24,000 times. Result: 12,012 heads, a proportion of 0.5005.

While imprisoned by the Germans during World War II, the South African mathematician John Kerrich tossed a coin 10,000 times. Result: 5067 heads, a proportion of 0.5067.

An outcome with probability 0 never occurs. An outcome with probability 1 happens on every repetition. An outcome with probability one-half, or 1-in-2, happens half the time in a very long series of trials. Of course, we can never observe a probability exactly. We could always continue tossing the coin, for example. Mathematical probability is an idealization based on imagining what would happen in an infinitely long series of trials.

Statistics in Your World

Does God play dice? Few things in the world are truly random in the sense that no amount of information will allow us to predict the outcome. We could, in principle, apply the laws of physics to a tossed coin, for example, and calculate whether it will land heads or tails. But randomness does rule events inside individual atoms. Albert Einstein didn’t like this feature of the new quantum theory.「God does not play dice with the universe,」said the great scientist. Many years later, it appears that Einstein was wrong.

We aren’t thinking deeply here. That some things are random is simply an observed fact about the world. Probability just gives us a language to describe the long-term regularity of random behavior. The outcome of a coin toss, the time between emissions of particles by a radioactive source, and the sexes of the next litter of lab rats are all random. So is the outcome of a random sample or a randomized experiment. The behavior of large groups of individuals is often as random as the behavior of many coin tosses or many random samples. Life insurance, for example, is based on the fact that deaths occur at random among many individuals.

Example 3

The probability of dying

We can’t predict whether a particular person will die in the next year. But if we observe millions of people, deaths are random. In 2016, the National Center for Health Statistics reported that the proportion of men aged 20 to 24 years who die in any one year is 0.0014. This is the probability that a young man will die next year. For women that age, the probability of death is about 0.0005.

If an insurance company sells many policies to people aged 20 to 24, it knows that it will have to pay off next year on about 0.14% of the policies sold on men’s lives and on about 0.05% of the policies sold on women’s lives. It will charge more to insure a man because the probability of having to pay is higher.

The Ancient History of Chance

Randomness is most easily noticed in many repetitions of games of chance: rolling dice, dealing shuffled cards, spinning a roulette wheel. Chance devices similar to these have been used from remote antiquity to discover the will of the gods. The most common method of randomization in ancient times was「rolling the bones」—that is, tossing several astragali. The astragalus (Figure 17.2) is a six-sided animal heel bone that, when thrown, will come to rest on one of four sides (the other two sides are rounded). Cubical dice, made of pottery or bone, came later, but even dice existed before 2000 B.C. Gambling on the throw of astragali or dice is, compared with divination, almost a modern development. There is no clear record of this vice before about 300 B.C. Gambling reached flood tide in Roman times, then temporarily receded (along with divination) in the face of Christian displeasure.

Figure 17.2 Animal heel bones (astragali).

Chance devices such as astragali have been used from the beginning of recorded history. Yet none of the great mathematicians of antiquity studied the regular pattern of many throws of bones or dice. Perhaps this is because astragali and most ancient dice were so irregular that each had a different pattern of outcomes. Or perhaps the reasons lie deeper, in the classical reluctance to engage in systematic experimentation.

Professional gamblers, who are not as inhibited as philosophers and mathematicians, did notice the regular pattern of outcomes of dice or cards and tried to adjust their bets to the odds of success.「How should I bet?」is the question that launched mathematical probability. The systematic study of randomness began (we oversimplify, but not too much) when seventeenth-century French gamblers asked French mathematicians for help in figuring out the「fair value」of bets on games of chance. Probability theory, the mathematical study of randomness, originated with Pierre de Fermat and Blaise Pascal in the seventeenth century and was well developed by the time statisticians took it over in the twentieth century.

Myths about Chance Behavior

The idea of probability seems straightforward. It answers the question,「What would happen if we did this many times?」In fact, both the behavior of random phenomena and the idea of probability are a bit subtle. We meet chance behavior constantly, and psychologists tell us that we deal with it poorly.

The myth of short-run regularity The idea of probability is that randomness is regular in the long run. Unfortunately, our intuition about randomness tries to tell us that random phenomena should also be regular in the short run. When they aren’t, we look for some explanation other than chance variation.

Example 4

What looks random?

Toss a fair coin six times and record heads (H) or tails (T) on each toss. Which of these outcomes is most probable?

HTHTTH HHHTTT TTTTTT

Almost everyone says that HTHTTH is more probable because TTTTTT and HHHTTT do not「look random.」In fact, all three are equally probable. That heads and tails are equally probable says all specific outcomes of heads and tails in six tosses are equally likely. That heads and tails are equally probable says only that about half of a very long sequence of tosses will be heads. This is because in very long sequences of tosses, the number of outcomes for which the proportion of heads is approximately one-half is much larger than the number of outcomes for which the proportion is not near one-half. That heads and tails are equally probable doesn’t say that heads and tails must come close to alternating in the short run. It doesn’t say that specific outcomes that balance the number of heads and tails are more likely than specific outcomes that don’t. The coin has no memory. It doesn’t know what past outcomes were, and it can’t try to create a balanced sequence.

The outcome TTTTTT in tossing six coins looks unusual because of the run of six straight tails. The outcome HHHTTT also looks unusual because of the pattern of a run of three straight heads followed by a run of three straight tails. Runs seem「not random」to our intuition but are not necessarily unusual. Here’s an example more striking than tossing coins.

Example 5

The hot hand in basketball

On January 23, 2015, against the Sacramento Kings, Klay Thompson was ice cold. He had missed his previous five shots before the end of the first half, including an uncontested layup. But after half-time, Thompson erupted. He made his next 13 shots in a row and finished the quarter with a record-smashing 37 points. After the game, Green was asked whether someone could possibly do that in the「NBA 2K」video game. His response?「Nah, you don’t get that hot in 2K」

Belief that runs must result from something other than「just chance」influences behavior. If a basketball player makes several consecutive shots, both the fans and his teammates believe that he has a「hot hand」and is more likely to make the next shot. This is not supported by data. Careful study has shown that runs of baskets made or missed are no more frequent in basketball than would be expected if each shot is independent of the player’s previous shots. Players perform consistently, not in streaks. If a player makes half her shots in the long run, her hits and misses behave just like tosses of a coin—and that means that runs of hits and misses are more common than our intuition expects.

Now it’s your turn

17.1 Coin tossing and randomness. Toss a coin 10 times and record heads (H) or tails (T) on each toss. Which of these outcomes is most probable? Least probable?

HTHTTHHTHT TTTTTHHHHH HHHHHHHHHH

The myth of the surprising coincidence On November 18, 2006, Ohio State beat Michigan in football by a score of 42 to 39. Later that day, the winning numbers in the Pick 4 Ohio lottery were 4239. What an amazing coincidence!

Well, maybe not. It is certainly unlikely that the Pick 4 lottery would match the Ohio State versus Michigan score that day, but it is not so unlikely that sometime during the 2006 season, the winning number of some state lottery would match the recent score of some professional, college, or high school football game involving a team in the state. There are 32 NFL teams, 235 NCAA Division I teams, 150 NCAA Division II teams, and 231 NCAA Division III teams. There are also more than 25,000 high school football teams. All play a number of games during the season. Almost all states have a Pick 3 or Pick 4 lottery game, with winning numbers often drawn multiple times per week. That’s a lot of opportunities to match a Pick 3 or Pick 4 lottery number that has digits that could conceivably be a football score like 217 or 4239.

When something unusual happens, we look back and say,「Wasn’t that unlikely?」We would have said the same if any of thousands of other unlikely things had happened. Here’s an example where it was possible to actually calculate the probabilities.

Example 6

Winning the lottery twice

In 1986, Evelyn Marie Adams won the New Jersey State lottery for the second time, adding $1.5 million to her previous $3.9 million jackpot. The New York Times (February 14, 1986) claimed that the odds of one person winning the big prize twice were about 1 in 17 trillion. Nonsense, said two statistics professors in a letter that appeared in the Times two weeks later. The chance that Evelyn Marie Adams would win twice in her lifetime is indeed tiny, but it is almost certain that someone among the millions of regular lottery players in the United States would win two jackpot prizes. The statisticians estimated even odds (a probability of one-half) of another double winner within seven years. Sure enough, Robert Humphries won his second Pennsylvania lottery jackpot ($6.8 million total) in May 1988. You might find it interesting to do an Internet search of「man wins state lottery two times」or「woman wins state lottery two times.」A recent double winner was a man who won million-dollar prizes in the Canadian lottery in April 2018 and again in August 2018.

Unusual events—especially distressing events—bring out the human desire to pinpoint a reason, a cause. Here’s a sequel to our earlier discussion of causation: sometimes it’s just the play of chance.

Example 7

Cancer clusters

Between 1996 and 2013, 37 children in Clyde, Ohio, a town of 6000 halfway between Toledo and Cleveland, were diagnosed with cancer. Four of the children had died. With many of the diagnoses coming between 2002 and 2006, state health authorities declared it a cancer cluster, saying the number and type of diagnoses exceed what would be expected statistically for so small a population over that time. In the fall of 2012, the EPA found high levels of toxic, possibly cancer-causing chemical compounds in soil samples from Whirlpool Park, formerly a residential area owned by home appliance manufacturer Whirlpool Corporation from the 1950s until 2008. Locals told news reporters that「black sludge」had been dumped in the area during that time. However, a February 2015 article in the Akron Beacon Journal reported that a suit against Whirlpool was dropped and that「Ohio health and environmental investigators have spent years testing the air and water around Clyde and talking with the children and their families about where they live and work and what they might have been exposed to. But they’ve never come up with the answer.」

Cancer is a common disease, accounting for more than 23% of all deaths in the United States. That cancer cases sometimes occur in clusters in the same neighborhood is not surprising; there are bound to be clusters somewhere simply by chance. But when a cancer cluster occurs in our neighborhood, we tend to suspect the worst and look for someone to blame. State authorities get several thousand calls a year from people worried about「too much cancer」in their area. But the National Cancer Institute finds that the majority of reported cancer clusters are simply the result of chance.

Statistics in Your World

The probability of rain is … You work all week. Then it rains on the weekend. Can there really be a statistical truth behind our perception that the weather is against us? At least on the East Coast of the United States, the answer is Yes. Going back to 1946, it seems that Sundays receive 22% more precipitation than Mondays. The likely explanation is that the pollution from all those workday cars and trucks forms the seeds for raindrops—with just enough delay to cause rain on the weekend.

Two Massachusetts cancer clusters, one in Randolph, Massachusetts, and one in Woburn, Massachusetts, were investigated by statisticians from the Harvard School of Public Health in the 1980s. The investigators tried to obtain complete data on everyone who had lived in the neighborhoods in the periods in question and to estimate their exposure to the suspect drinking water. They also tried to obtain data on other factors that might explain cancer, such as smoking and occupational exposure to toxic substances. The verdict: chance is the likely explanation of the Randolph cluster, but there is evidence of an association between drinking water from the two Woburn wells and developing childhood leukemia.

The myth of the law of averages Roaming the gambling floors in Las Vegas, watching money disappear into the drop boxes under the tables, is revealing. You can see some interesting human behavior in a casino. When the shooter in the dice game craps rolls several winners in a row, some gamblers think she has a「hot hand」and bet that she will keep on winning. Others say that「the law of averages」means that she must now lose so that wins and losses will balance out. Believers in the law of averages think that if you toss a coin six times and get TTTTTT, the next toss must be more likely to give a head. It’s true that in the long run heads must appear half the time. What is myth is that future outcomes must make up for an imbalance like six straight tails.

Coins and dice have no memories. A coin doesn’t know that the first six outcomes were tails, and it can’t try to get a head on the next toss to even things out. Of course, things do even out in the long run. After 10,000 tosses, the results of the first six tosses don’t matter. They are overwhelmed by the results of the next 9994 tosses, not compensated for.

Example 8

We want a boy

Belief in this phony「law of averages」can lead to consequences close to disastrous. A few years ago,「Dear Abby」published in her advice column a letter from a distraught mother of eight girls. It seems that she and her husband had planned to limit their family to four children. When all four were girls, they tried again—and again, and again. After seven straight girls, even her doctor had assured her that「the law of averages was in our favor 100 to 1.」Unfortunately for this couple, having children is like tossing coins. Eight girls in a row is highly unlikely, but once seven girls have been born, it is not at all unlikely that the next child will be a girl—and it was.

What is the law of averages? Is there a「law of averages」? There is, although it is sometimes referred to as the「law of large numbers.」It states that in a large number of「independent」repetitions of a random phenomenon (such as coin tossing), averages or proportions are likely to become more stable as the number of trials increases, whereas sums or counts are likely to become more variable. This does not happen by compensation for a run of bad luck because, by「independent,」we mean that knowing the outcome of one trial does not change the probabilities for the outcomes of any other trials. The trials have no memory.

Figures 17.1 and 17.3 show what happens when we toss a coin repeatedly many times. In Figure 17.1 (page 406), we see that the proportion of heads gradually becomes closer and closer to 0.5 as the number of tosses increases. This illustrates the law of large numbers. However, Figure 17.3 shows, for these same tosses, how far the total number of heads differs from exactly half of the tosses being heads. We see that how this difference varies more and more as the number of tosses increases. The law of large numbers does not apply to sums or counts.

Figure 17.3 Toss a coin many times. The difference between the observed number of heads and exactly one-half the number of tosses becomes more variable as the number of tosses increases.

The data on the graph are as follows: The number of tosses, 1, 5, 10, 50, 100, 500, and 1000 are represented along the horizontal axis. The number of heads minus half the number of tosses are represented along the vertical axis and its values range from negative 20 to 10, in intervals of 5. A dotted line starts at 0 and runs parallel to the horizontal axis. The curve originates from (1, 0.5) and gradually passes through the points (5, negative 2), (10, negative 3), (50, negative 6), (100, negative 1), and (500, 5), and ends at the point (1000, negative 13). The data given are approximate.

It is not uncommon to see the law of averages misstated in terms of the sums or counts rather than means or proportions. For example, assuming that the birth rates for boys and girls in the United States are equal, you may hear someone state that the total number of males and females in the United States should be nearly equal rather than stating that the proportion of males and females in the United States should be nearly equal.

Now it’s your turn

17.2 Coin tossing and the law of averages. The author C. S. Lewis once wrote the following, referring to the law of averages:「If you tossed a coin a billion times, you could predict a nearly equal number of heads and tails.」Is this a correct statement of the law of averages? If not, how would you rewrite the statement so that it is correct?

Personal Probabilities

Joe sits staring into his beer as his favorite baseball team, the Chicago Cubs, loses another game. The Cubbies have made some good off-season acquisitions, so let’s ask Joe,「What’s the chance that the Cubs will go to the World Series next year?」Joe brightens up.「Oh, about 10%,」he says.

Does Joe assign probability 0.10 to the Cubs’ appearing in the World Series? The outcome of next year’s pennant race is certainly unpredictable, but we can’t reasonably ask what would happen in many repetitions. Next year’s baseball season will happen only once and will differ from all other seasons in players, weather, and many other ways. The answer to our question seems clear: if probability measures「what would happen if we did this many times,」Joe’s 0.10 is not a probability. Probability is based on data about many repetitions of the same random phenomenon. Joe is giving us something else, his personal judgment.

Yet we often use the term「probability」in a way that includes personal judgments of how likely it is that some event will happen. We make decisions based on these judgments—we take the bus downtown because we think the probability of finding a parking spot is low. More serious decisions also take judgments about likelihood into account. A company deciding whether to build a new plant must judge how likely it is that there will be high demand for its products three years from now when the plant is ready. Many companies express「How likely is it?」judgments as numbers—probabilities—and use these numbers in their calculations. High demand in three years, like the Cubs’ winning next year’s pennant, is a one-time event that doesn’t fit the「do it many times」way of thinking. What is more, several company officers may give several different probabilities, reflecting differences in their individual judgment. We need another kind of probability, personal probability.

Key Terms

A personal probability of an outcome is a number between 0 and 1 that expresses an individual’s judgment of how likely the outcome is.

Personal probabilities have the great advantage that they aren’t limited to repeatable settings. They are useful because we base decisions on them:「I think the probability that the Patriots will win the Super Bowl is 0.75, so I’m going to bet on the game.」Just remember that personal probabilities are different in kind from probabilities as「proportions in many repetitions.」Because they express individual opinion, they can’t be said to be right or wrong.

This is true even in a「many repetitions」setting. If Craig has a gut feeling that the probability of a head on the next toss of this coin is 0.7, that’s what Craig thinks and that’s all there is to it. Tossing the coin many times may show that the proportion of heads is very close to 0.5, but that’s another matter. There is no reason a person’s degree of confidence in the outcome of one try must agree with the results of many tries. We stress this because it is common to say that「personal probability」and「what happens in many trials」are somehow two interpretations of the same idea. In fact, they are quite different ideas.

Why do we even use the word「probability」for personal opinions? There are two good reasons. First, we usually do base our personal opinions on data from many trials when we have such data. Data from Buffon, Pearson, and Kerrich (Example 2) and perhaps from our own experience convince us that coins come up heads very close to half the time in many tosses. When we say that a coin has probability one-half of coming up heads on this toss, we are applying to a single toss a measure of the chance of a head based on what would happen in a long series of tosses. Second, personal probability and probability as long-term proportion both obey the same mathematical rules. Both kinds of probabilities are numbers between 0 and 1. We will look at more of the rules of probability in the next chapter. These rules apply to both kinds of probability.

Although「personal probability」and「what happens in many trials」are different ideas, what happens in many trials often causes us to revise our personal probability of an event. If Craig has a gut feeling that the probability of a head when he tosses a particular coin is 0.7, that’s what Craig thinks. If he tosses it 20 times and gets nine heads, he may continue to believe that the probability of heads is 0.7—because personal probabilities need not agree with the results of many trials. But he may also decide to revise his personal probability downward based on what he has observed. Is there a sensible way to do this, or is this also just a matter of personal opinion?

In statistics, there are formal methods for using data to adjust personal probabilities. These are called Bayes’ procedures. The basic rule, called Bayes’ theorem, is attributed to the Reverend Thomas Bayes, who discussed the rule in「An Essay towards Solving a Problem in the Doctrine of Chances」published in 1764. The mathematics is somewhat complicated, and we will not discuss the details. However, the use of Bayes’ procedures is becoming increasingly common among practitioners.

Probability and Risk

Once we understand that「personal judgment of how likely」and「what happens in many repetitions」are different ideas, we have a good start toward understanding why the public and the experts disagree so strongly about what is risky and what isn’t. The experts use probabilities from data to describe the risk of an unpleasant event. Individuals and society, however, seem to ignore data. We worry about some risks that almost never occur while ignoring others that are much more probable.

Example 9

Asbestos in the schools

High exposure to asbestos is dangerous. Low exposure, such as that experienced by teachers and students in schools where asbestos is present in the insulation around pipes, is not very risky. The probability that a teacher who works for 30 years in a school with typical asbestos levels will get cancer from the asbestos is around 15/1,000,000. The risk of dying in a car accident during a lifetime of driving is about 15,000/1,000,000. That is, driving regularly is about 1000 times more risky than teaching in a school where asbestos is present.

Risk does not stop us from driving. Yet the much smaller risk from asbestos launched massive cleanup campaigns and a federal requirement that every school inspect for asbestos and make the findings public.

Why do we take asbestos so much more seriously than driving? Why do we worry about very unlikely threats such as tornadoes and terrorists more than we worry about heart attacks?

We feel safer when a risk seems under our control than when we cannot control it. We are in control (or so we imagine) when we are driving, but we can’t control the risk from asbestos or tornadoes or terrorists.

It is hard to comprehend very small probabilities. Probabilities of 15 per million and 15,000 per million are both so small that our intuition cannot distinguish between them. Psychologists have shown that we generally overestimate very small risks and underestimate higher risks. Perhaps this is part of the general weakness of our intuition about how probability operates.

The probabilities for risks like asbestos in the schools are not as certain as probabilities for tossing coins. They must be estimated by experts from complicated statistical studies. Perhaps it is safest to suspect that the experts may have underestimated the level of risk.

Statistics in Your World

What are the odds? Gamblers often express chance in terms of odds rather than probability. Odds of to in favor of an outcome means that the probability of that outcome is So「odds of 5 to 1 in favor of an outcome」is another way of saying「probability 5/6.」A probability is always between 0 and 1, but odds range from 0 to infinity. Although odds are mainly used in gambling, they give us a way to make very small probabilities clearer.「Odds of 999 to 1」may be easier to understand than「probability 0.999.」

Our reactions to risk depend on more than probability, even if our personal probabilities are higher than the experts’ data-based probabilities. We are influenced by our psychological makeup and by social standards. As one writer noted,「Few of us would leave a baby sleeping alone in a house while we drove off on a 10-minute errand, even though car-crash risks are much greater than home risks.」

Chapter 17 Summary and Exercises

Chapter 17: Statistics in Summary

Some things in the world, both natural and of human design, are random. That is, their outcomes have a clear pattern in very many repetitions even though the outcome of any one trial is unpredictable.

Probability describes the long-term regularity of random phenomena. The probability of an outcome is the proportion of very many repetitions on which that outcome occurs. A probability is a number between 0 (the outcome never occurs) and 1 (always occurs). We emphasize this kind of probability because it is based on data.

Probabilities describe only what happens in the long run. Short runs of random phenomena like tossing coins or shooting a basketball often don’t look random to us because they do not show the regularity that in fact emerges only in very many repetitions.

Personal probabilities express an individual’s personal judgment of how likely outcomes are. Personal probabilities are also numbers between 0 and 1. Different people can have different personal probabilities, and a personal probability does not need to agree with a proportion based on data about similar cases.

This chapter summary will help you evaluate the Case Study.

Link It

This chapter begins our study of the mathematics of chance or「probability.」The important fact is that random phenomena are unpredictable in the short run but have a regular and predictable behavior in the long run.

The long-run behavior of random phenomena will help us understand both why and in what way we can trust random samples and randomized comparative experiments, the subjects of Chapters 2 through 6. It is the key to generalizing what we learn from data produced by random samples and randomized comparative experiments to some wider universe or population. We will study how this is done in Part IV. As a first step in this direction, we will look more carefully at the basic rules of probability in the next chapter.

Case Study Evaluated

Use what you have learned in this chapter to evaluate the Case Study. Start by reviewing the Chapter Summary. Then answer each of the following questions in complete sentences. Be sure to communicate clearly enough for any of your classmates to understand what you are saying.

In the Case Study described at the beginning of this chapter, you were told that the odds of all three members of the Gardner family having the same birthday is about one in 133,000. And a statistician can show that if birth dates are random and independent, the chance that three people, selected at random, all have the same birthday is, in fact, about one in 133,000.

Go to the most recent Census Bureau data on families (online at www.census.gov/data/tables/2016/demo/families/cps-2016.html) and look under Table H1. Households By Type and Tenure of Householder for Selected Characteristics: 2016. How many family households in the United States consist of a married couple with three members?

Assume that the families you found in the previous question all consist of a married couple with one child. Explain why the probability that there is some 3-person family in the United States in which the parents and child all have the same birthday is much larger than the 1 in 133,000 probability that in one randomly selected 3-person family the parents and child all have the same birthday.

Write a paragraph discussing whether the「surprising」coincidence described in the Case Study that began this chapter is as surprising as it might first appear.

In this chapter you have:

Learned some fundamental concepts about chance behavior such as the notion of randomness.

Interpreted probabilities like 1 in 133,000 as the proportion of times an outcome would occur in a very long series of trials.

Identified some common「myths」concerning chance behavior such as misinterpretations of the law of averages and the notion of the「hot hand」in sports.

Online Resources

The first half of the Snapshots video, Probability, introduces the concepts of randomness and probability in the context of weather forecasts.

Check the Basics

For Exercise 17.1, see page 411; for Exercise 17.2, see page 415.

17.3 Randomness. Random phenomena have which of the following characteristics?

They must be natural events. Man-made events cannot be random.

They exhibit a clear pattern in very many repetitions, although any one trial of the phenomenon is unpredictable.

Future outcomes must compensate for an imbalance that may occur in the short run, thus preserving the law of averages.

They are completely unpredictable; that is, they display no clear pattern no matter how often the phenomenon is repeated.

17.4 Probability. The probability of a specific outcome of a random phenomenon is

the number of times it occurs in very many repetitions of the phenomenon.

the number repetitions of the phenomenon it takes for the outcome to first occur.

the proportion of times it occurs in very many repetitions of the phenomenon.

the ratio of the number of times it occurs to the number of times it does not occur in very many repetitions of the phenomenon.

17.5 Probability. Which of the following is true of probability?

It is a number between 0 and 1.

A probability of 0 means the outcome never occurs.

A probability of 1 means the outcome always occurs.

All of the above are true.

17.6 Probability. I toss a coin 1000 times and observe the outcome「heads」481 times. Which of the following can be concluded from this result?

This is suspicious because we should observe exactly 500 heads if the coin is tossed 1000 times.

The probability of heads is approximately 481.

Our best estimate of the probability of heads is 0.481, but a longer sequence of flips should yield a better estimate of this probability.

If we flip the coin several more times, we will get more heads than tails in order to balance out the fact that the first thousand flips had too few heads.

17.7 Personal probabilities. Which of the following is true of a personal probability about the outcome of a phenomenon?

It expresses an individual’s judgment of how likely an outcome is.

It can be any number because personal probabilities need not be restricted to values between 0 and 1.

It must closely agree with the proportion of times the outcome would occur if the phenomenon was repeated a large number of times.

Very small values indicate strong disagreement with the probability most people would assign to the outcome, and very large values indicate strong agreement with the probability most people would assign to the outcome.

Chapter 17 Exercises

17.8 Nickels spinning. Hold a nickel upright on its edge under your forefinger on a hard surface, then snap it with your other forefinger so that it spins for some time before falling. Based on 50 spins, estimate the probability of heads.

17.9 Nickels falling over. You may feel that it is obvious that the probability of a head in tossing a coin is about 1-in-2 because the coin has two faces. Such opinions are not always correct. The previous exercise asked you to spin a nickel rather than toss it—that changes the probability of a head. Now try another variation. Stand a nickel on edge on a hard, flat surface. Pound the surface with your hand so that the nickel falls over. What is the probability that it falls with heads upward? Make at least 50 trials to estimate the probability of a head.

17.10 Random digits. The table of random digits (Table A) was produced by a random mechanism that gives each digit probability 0.1 of being a 0. What proportion of the 400 digits in lines 120 to 129 in the table are 0s? This proportion is an estimate, based on 400 repetitions, of the true probability, which in this case is known to be 0.1.

17.11 How many tosses to get a head? When we toss a penny, experience shows that the probability (long-term proportion) of a head is close to 1-in-2. Suppose now that we toss the penny repeatedly until we get a head. What is the probability that the first head comes up in an even number of tosses (two, four, six, and so on)? To find out, repeat this experiment 50 times, and keep a record of the number of tosses needed to get the first head on each of your 50 trials.

From your experiment, estimate the probability of the first head on the second toss. What value should we expect this probability to have?

Use your results to estimate the probability that the first head appears on an even-numbered toss.

17.12 Tossing a thumbtack. Toss a thumbtack on a hard surface 50 times. How many times did it land with the point up? What is the approximate probability of landing point up?

17.13 Rolling dice. Roll a pair of dice 100 times. How many times did you roll a 5? What is the approximate probability of rolling a 5?

17.14 Four-of-a-kind. You read in a book on poker that the probability of being dealt four-of-a-kind (a hand containing four cards of the same value, such as four kings) in a five-card poker hand is about 0.00024. Explain in simple language what this means.

17.15 From words to probabilities. Probability is a measure of how likely an event is to occur. Match one of the probabilities that follow with each statement of likelihood given. (The probability is usually a more exact measure of likelihood than is the verbal statement.)

0 0.01 0.4 0.6 0.99 1

This event is impossible. It can never occur.

This event is certain. It will occur on every trial.

This event is very unlikely, but it will occur once in a while in a long sequence of trials.

This event will occur more often than not.

17.16 Winning a baseball game. Over the period from 1965 to 2018, the champions of baseball’s two major leagues won 63% of their home games during the regular season. At the end of each season, the two league champions meet in the baseball World Series. Would you use the results from the regular season to assign probability 0.63 to the event that the home team wins a World Series game? Explain your answer.

17.17 Will you have an accident? The probability that a randomly chosen driver will be involved in an accident in the next year is about 0.3. This is based on the proportion of millions of drivers who have accidents.「Accident」includes things like crumpling a fender in your own driveway, not just highway accidents.

What do you think is your own probability of being in an accident in the next year? This is a personal probability.

Give some reasons your personal probability might be a more accurate prediction of your「true chance」of having an accident than the probability for a random driver.

Almost everyone says that their personal probability is lower than the random driver probability. Why do you think this is true?

17.18 Marital status. Based on 2018 data, the probability that a randomly chosen woman over 64 years of age is divorced is about 0.14. This probability is a long-run proportion based on all the millions of women over 64. Let’s suppose that the proportion stays at 0.14 for the next 45 years. Bridget is now 20 years old and is not married.

Bridget thinks her own chances of being divorced after age 64 are about 5%. Explain why this is a personal probability.

Give some good reasons Bridget’s personal probability might differ from the proportion of all women over 64 who are divorced.

You are a government official charged with looking into the impact of the Social Security system on retirement-aged divorced women. You care only about the probability 0.14, not about anyone’s personal probability. Why?

17.19 Personal probability versus data. Give an example in which you would rely on a probability found as a long-term proportion from data on many trials. Give an example in which you would rely on your own personal probability.

17.20 Personal probability? When there are few data, we often fall back on personal probability. There had been just 24 space shuttle launches, all successful, before the Challenger disaster in January 1986. The shuttle program management thought the chances of such a failure were only 1 in 100,000.

Suppose 1 in 100,000 is a correct estimate of the chance of such a failure. If a shuttle was launched every day, about how many failures would one expect in 300 years?

Give some reasons such an estimate is likely to be too optimistic.

17.21 Personal random numbers? Ask several of your friends (at least 10 people) to choose a four-digit number「at random.」How many of the numbers chosen start with 1 or 2? How many start with 8 or 9? (There is strong evidence that people in general tend to choose numbers starting with low digits.)

17.22 Playing Pick 4. The Pick 4 games in many state lotteries announce a four-digit winning number each day. The winning number is essentially a four-digit group from a table of random digits. You win if your choice matches the winning digits, in exact order. The winnings are divided among all players who matched the winning digits. That suggests a way to get an edge.

The winning number might be, for example, either 2873 or 9999. Explain why these two outcomes have exactly the same probability. (It is 1 in 10,000.)

If you asked many people which outcome is more likely to be the randomly chosen winning number, most would favor one of them. Use the information in this chapter to say which one and to explain why. If you choose a number that people think is unlikely, you have the same chance to win, but you will win a larger amount because few other people will choose your number.

17.23 Surprising? During the Michigan versus Ohio State football game in 2018, news media reported that Jim Harbaugh and Urban Meyer, the head coaches of Michigan and Ohio State, respectively, were born in the same hospital in Toledo, Ohio. That a pair of coaches from two arch rivals were also born in the same hospital was reported as an extraordinarily improbable event. Should this fact (that they are the head coaches of two famous arch rivals and both were born in the same hospital) surprise you? Explain your answer.

17.24 An eerie coincidence? A September 13, 2011, New York Post article reported that the first three winners at Belmont Park were horses wearing the numbers 9, 1, 1 on the tenth-year anniversary of the 9/11 attacks on America. Should this fact surprise you? Explain your answer.

17.25 Curry’s free throws. The basketball player Stephen Curry is the all-time career free-throw shooter among active players. He makes 90.4% of his free throws. In today’s game, Curry misses his first two free throws. The TV commentator says,「Curry’s technique looks out of rhythm today.」Explain why the claim that Curry’s technique has deteriorated is not justified.

17.26 In the long run. Probability works not by compensating for imbalances but by overwhelming them. Suppose that the first 10 tosses of a coin give 10 tails and that tosses after that are exactly half heads and half tails. (Exact balance is unlikely, but the example illustrates how the first 10 outcomes are swamped by later outcomes.) What is the proportion of heads after the first 10 tosses? What is the proportion of heads after 100 tosses if half of the last 90 produce heads (45 heads)? What is the proportion of heads after 1000 tosses if half of the last 990 produce heads? What is the proportion of heads after 10,000 tosses if half of the last 9990 produce heads?

17.27 The「law of averages.」The baseball player Jose Altuve gets a hit about 31.6% of the time over an entire season. After he has failed to hit safely in nine straight at-bats, the TV commentator says,「Jose is due for a hit by the law of averages.」Is that right? Why?

17.28 Snow coming. A meteorologist, predicting below-average snowfall this winter, says,「First, in looking at the past few winters, there has been above-average snowfall. Even though we are not supposed to use the law of averages, we are due.」Do you think that「due by the law of averages」makes sense in talking about the weather? Explain.

17.29 An unenlightened gambler.

A gambler knows that red and black are equally likely to occur on each spin of a roulette wheel. He observes five consecutive reds occur and bets heavily on black on the next spin. Asked why, he explains that black is「due by the law of averages.」Explain to the gambler what is wrong with this reasoning.

After listening to you explain why red and black are still equally likely after five reds on the roulette wheel, the gambler moves to a poker game. He is dealt five straight red cards. He remembers what you said and assumes that the next card dealt in the same hand is equally likely to be red or black. Is the gambler right or wrong, and why?

17.30 Reacting to risks. The probability of dying if you play high school football is about 10 per million each year you play. The risk of getting cancer from asbestos if you attend a school in which asbestos is present for 10 years is about 5 per million. If we ban asbestos from schools, should we also ban high school football? Briefly explain your position.

17.31 Reacting to risks. National newspapers such as USA Today and the New York Times carry many more stories about deaths from airplane crashes than about deaths from motor vehicle crashes. Motor vehicle accidents killed about 32,700 people in the United States in 2013. Crashes of all scheduled air carriers worldwide, including commuter carriers, killed 325 people in 2016, and nobody died in a crash on a U.S.–certificated scheduled airline operating anywhere in the world.

Why do the news media give more attention to airplane crashes?

How does news coverage help explain why many people consider flying more dangerous than driving?

17.32 What probability doesn’t say. The probability of a head in tossing a coin is 1-in-2. This means that as we make more tosses, the proportion of heads will eventually get close to 0.5. It does not mean that the count of heads will get close to one-half the number of tosses. To see why, imagine that the proportion of heads is 0.49 in 100 tosses, 0.493 in 1000 tosses, 0.4969 in 10,000 tosses, and 0.49926 in 100,000 tosses of a coin. How many heads came up in each set of tosses? How close is the number of heads to half the number of tosses?

Exploring the Web

Access these exercises on the text website: macmillanlearning.com/scc10e.

CHAPTER 18 Probability Models

In this chapter you will:

