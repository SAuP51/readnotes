Data mining issues regarding privacy and data security are addressed popularly in literature. Books on privacy and security in data mining include Thuraisingham [Thu04]; Aggarwal and Yu [AY08]; Vaidya, Clifton, and Zhu [VCZ10]; and Fung, Wang, Fu, and Yu [FWFY10]. Research articles include Agrawal and Srikant [AS00]; Evfimievski, Srikant, Agrawal, and Gehrke [ESAG02]; and Vaidya and Clifton [VC03]. Differential privacy was introduced by Dwork [Dwo06] and studied by many such as Hay, Rastogi, Miklau, and Suciu [HRMS10].

There have been many discussions on trends and research directions of data mining in various forums. Several books are collections of articles on these issues such as Kargupta, Han, Yu, et al. [KHY+08].

Bibliography

[AAD+96] Agarwal, S.; Agrawal, R.; Deshpande, P.M.; Gupta, A.; Naughton, J.F.; Ramakrishnan, R.; Sarawagi, S., On the computation of multidimensional aggregates, In: Proc. 1996 Int. Conf. Very Large Data Bases (VLDB’96) Bombay, India. (Sept. 1996), pp. 506–521.

[AAP01] Agarwal, R.; Aggarwal, C.C.; Prasad, V.V.V., A tree projection algorithm for generation of frequent itemsets, J. Parallel and Distributed Computing 61 (2001) 350–371.

[AB79] Abraham, B.; Box, G.E.P., Bayesian analysis of some outlier problems in time series, Biometrika 66 (1979) 229–248.

[AB99] Albert, R.; Barabasi, A.-L., Emergence of scaling in random networks, Science 286 (1999) 509–512.

[ABA06] Agyemang, M.; Barker, K.; Alhajj, R., A comprehensive survey of numeric and symbolic outlier mining techniques, Intell. Data Anal 10 (2006) 521–538.

[ABKS99] Ankerst, M.; Breunig, M.; Kriegel, H.-P.; Sander, J., OPTICS: Ordering points to identify the clustering structure, In: Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99) Philadelphia, PA. (June 1999), pp. 49–60.

[AD91] Almuallim, H.; Dietterich, T.G., Learning with many irrelevant features, In: Proc. 1991 Nat. Conf. Artificial Intelligence (AAAI’91) Anaheim, CA. (July 1991), pp. 547–552.

[AEEK99] Ankerst, M.; Elsen, C.; Ester, M.; Kriegel, H.-P., Visual classification: An interactive approach to decision tree construction, In: Proc. 1999 Int. Conf. Knowledge Discovery and Data Mining (KDD’99) San Diego, CA. (Aug. 1999), pp. 392–396.

[AEMT00] Ahmed, K.M.; El-Makky, N.M.; Taha, Y., A note on「beyond market basket: Generalizing association rules to correlations.」, SIGKDD Explorations 1 (2000) 46–48.

[AG60] Anscombe, F.J.; Guttman, I., Rejection of outliers, Technometrics 2 (1960) 123–147.

[Aga06] Agarwal, D., Detecting anomalies in cross-classified streams: A Bayesian approach, Knowl. Inf. Syst 11 (2006) 29–44.

[AGAV09] Amigó, E.; Gonzalo, J.; Artiles, J.; Verdejo, F., A comparison of extrinsic clustering evaluation metrics based on formal constraints, Information Retrieval 12 (4) (2009) 461–486.

[Agg06] Aggarwal, C.C., Data Streams: Models and Algorithms. (2006) Kluwer Academic .

[AGGR98] Agrawal, R.; Gehrke, J.; Gunopulos, D.; Raghavan, P., Automatic subspace clustering of high dimensional data for data mining applications, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 94–105.

[AGM04] Afrati, F.N.; Gionis, A.; Mannila, H., Approximating a collection of frequent sets, In: Proc. 2004 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’04) Seattle, WA. (Aug. 2004), pp. 12–19.

[AGS97] Agrawal, R.; Gupta, A.; Sarawagi, S., Modeling multidimensional databases, In: Proc. 1997 Int. Conf. Data Engineering (ICDE’97) Birmingham, England. (Apr. 1997), pp. 232–243.

[Aha92] Aha, D., Tolerating noisy, irrelevant, and novel attributes in instance-based learning algorithms, Int. J. Man-Machine Studies 36 (1992) 267–287.

[AHS96] Arabie, P.; Hubert, L.J.; De Soete, G., Clustering and Classification. (1996) World Scientific .

[AHWY03] Aggarwal, C.C.; Han, J.; Wang, J.; Yu, P.S., A framework for clustering evolving data streams, In: Proc. 2003 Int. Conf. Very Large Data Bases (VLDB’03) Berlin, Germany. (Sept. 2003), pp. 81–92.

[AHWY04a] Aggarwal, C.C.; Han, J.; Wang, J.; Yu, P.S., A framework for projected clustering of high dimensional data streams, In: Proc. 2004 Int. Conf. Very Large Data Bases (VLDB’04) Toronto, Ontario, Canada. (Aug. 2004), pp. 852–863.

[AHWY04b] Aggarwal, C.C.; Han, J.; Wang, J.; Yu, P.S., On demand classification of data streams, In: Proc. 2004 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’04) Seattle, WA. (Aug. 2004), pp. 503–508.

[AIS93] Agrawal, R.; Imielinski, T.; Swami, A., Mining association rules between sets of items in large databases, In: Proc. 1993 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’93) Washington, DC. (May 1993), pp. 207–216.

[AK93] Anand, T.; Kahn, G., Opportunity explorer: Navigating large databases using knowledge discovery templates, In: Proc. AAAI-93 Workshop Knowledge Discovery in Databases Washington, DC. (July 1993), pp. 45–51.

[AL99] Aumann, Y.; Lindell, Y., A statistical theory for quantitative association rules, In: Proc. 1999 Int. Conf. Knowledge Discovery and Data Mining (KDD’99) San Diego, CA. (Aug. 1999), pp. 261–270.

[All94] Allen, B.P., Case-based reasoning: Business applications, Communications of the ACM 37 (1994) 40–42.

[Alp11] Alpaydin, E., Introduction to Machine Learning. 2nd ed. (2011) MIT Press, Cambridge, MA .

[ALSS95] Agrawal, R.; Lin, K.-I.; Sawhney, H.S.; Shim, K., Fast similarity search in the presence of noise, scaling, and translation in time-series databases, In: Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95) Zurich, Switzerland. (Sept. 1995), pp. 490–501.

[AMS+96] Agrawal, R.; Mehta, M.; Shafer, J.; Srikant, R.; Arning, A.; Bollinger, T., The Quest data mining system, In: Proc. 1996 Int. Conf. Data Mining and Knowledge Discovery (KDD’96) Portland, OR. (Aug. 1996), pp. 244–249.

[Aok98] Aoki, P.M., Generalizing「search」in generalized search trees, In: Proc. 1998 Int. Conf. Data Engineering (ICDE’98) Orlando, FL. (Feb. 1998), pp. 380–389.

[AP94] Aamodt, A.; Plazas, E., Case-based reasoning: Foundational issues, methodological variations, and system approaches, AI Communications 7 (1994) 39–52.

[AP05] Angiulli, F.; Pizzuti, C., Outlier mining in large high-dimensional data sets, IEEE Trans. on Knowl. and Data Eng 17 (2005) 203–215.

[APW+99] Aggarwal, C.C.; Procopiuc, C.; Wolf, J.; Yu, P.S.; Park, J.-S., Fast algorithms for projected clustering, In: Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99) Philadelphia, PA. (June 1999), pp. 61–72.

[ARV09] Arora, S.; Rao, S.; Vazirani, U., Expander flows, geometric embeddings and graph partitioning, J. ACM 56 (2) (2009) 1–37.

[AS94a] Agrawal, R.; Srikant, R., Fast algorithm for mining association rules in large databases, In: Research Report RJ 9839 (June 1994) IBM Almaden Research Center, San Jose, CA.

[AS94b] Agrawal, R.; Srikant, R., Fast algorithms for mining association rules, In: Proc. 1994 Int. Conf. Very Large Data Bases (VLDB’94) Santiago, Chile. (Sept. 1994), pp. 487–499.

[AS95] Agrawal, R.; Srikant, R., Mining sequential patterns, In: Proc. 1995 Int. Conf. Data Engineering (ICDE’95) Taipei, Taiwan. (Mar. 1995), pp. 3–14.

[AS96] Agrawal, R.; Shafer, J.C., Parallel mining of association rules: Design, implementation, and experience, IEEE Trans. Knowledge and Data Engineering 8 (1996) 962–969.

[AS00] Agrawal, R.; Srikant, R., Privacy-preserving data mining, In: Proc. 2000 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’00) Dallas, TX. (May 2000), pp. 439–450.

[ASS00] Allwein, E.; Shapire, R.; Singer, Y., Reducing multiclass to binary: A unifying approach for margin classifiers, Journal of Machine Learning Research 1 (2000) 113–141.

[AV07] Arthur, D.; Vassilvitskii, S., K-means++: The advantages of careful seeding, In: Proc. 2007 ACM-SIAM Symp. on Discrete Algorithms (SODA’07) Tokyo. (2007), pp. 1027–1035.

[Avn95] Avner, S., Discovery of comprehensible symbolic rules in a neural network, In: Proc. 1995 Int. Symp. Intelligence in Neural and Biological Systems Washington, DC. (1995), pp. 64–67.

[AY99] Aggarwal, C.C.; Yu, P.S., A new framework for itemset generation, In: Proc. 1998 ACM Symp. Principles of Database Systems (PODS’98) Seattle, WA. (June 1999), pp. 18–24.

[AY01] Aggarwal, C.C.; Yu, P.S., Outlier detection for high dimensional data, In: Proc. 2001 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’01) Santa Barbara, CA. (May 2001), pp. 37–46.

[AY08] Aggarwal, C.C.; Yu, P.S., Privacy-Preserving Data Mining: Models and Algorithms. (2008) Springer, New York .

[BA97] Breslow, L.A.; Aha, D.W., Simplifying decision trees: A survey, Knowledge Engineering Rev. 12 (1997) 1–40.

[Bay98] Bayardo, R.J., Efficiently mining long patterns from databases, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 85–93.

[BB98] Bagga, A.; Baldwin, B., Entity-based cross-document coreferencing using the vector space model, In: Proc. 1998 Annual Meeting of the Association for Computational Linguistics and Int. Conf. Computational Linguistics (COLING-ACL’98) Montreal, Quebec, Canada. (Aug. 1998).

[BB01] Baldi, P.; Brunak, S., Bioinformatics: The Machine Learning Approach. 2nd ed. (2001) MIT Press, Cambridge, MA .

[BB02] Borgelt, C.; Berthold, M.R., Mining molecular fragments: Finding relevant substructures of molecules, In: Proc. 2002 Int. Conf. Data Mining (ICDM’02) Maebashi, Japan. (Dec. 2002), pp. 211–218.

[BBD+02] Babcock, B.; Babu, S.; Datar, M.; Motwani, R.; Widom, J., Models and issues in data stream systems, In: Proc. 2002 ACM Symp. Principles of Database Systems (PODS’02) Madison, WI. (June 2002), pp. 1–16.

[BC83] Beckman, R.J.; Cook, R.D., Outlier…s, Technometrics 25 (1983) 119–149.

[BCC10] Buettcher, S.; Clarke, C.L.A.; Cormack, G.V., Information Retrieval: Implementing and Evaluating Search Engines. (2010) MIT Press, Cambridge, MA .

[BCG01] Burdick, D.; Calimlim, M.; Gehrke., J., MAFIA: A maximal frequent itemset algorithm for transactional databases, In: Proc. 2001 Int. Conf. Data Engineering (ICDE’01) Heidelberg, Germany. (Apr. 2001), pp. 443–452.

[BCP93] Brown, D.E.; Corruble, V.; Pittard, C.L., A comparison of decision tree classifiers with backpropagation neural networks for multimodal classification problems, Pattern Recognition 26 (1993) 953–961.

[BD01] Bickel, P.J.; Doksum, K.A., Mathematical Statistics: Basic Ideas and Selected Topics. (2001) Prentice-Hall ; Vol. 1..

[BD02] Brockwell, P.J.; Davis, R.A., Introduction to Time Series and Forecasting. 2nd ed. (2002) Springer, New York .

[BDF+97] Barbará, D.; DuMouchel, W.; Faloutsos, C.; Haas, P.J.; Hellerstein, J.H.; Ioannidis, Y.; Jagadish, H.V.; Johnson, T.; Ng, R.; Poosala, V.; Ross, K.A.; Servcik, K.C., The New Jersey data reduction report, Bull. Technical Committee on Data Engineering 20 (Dec. 1997) 3–45.

[BDG96] Bruce, A.; Donoho, D.; Gao, H.-Y., Wavelet analysis, IEEE Spectrum 33 (Oct. 1996) 26–35.

[BDJ+05] Burdick, D.; Deshpande, P.; Jayram, T.S.; Ramakrishnan, R.; Vaithyanathan, S., OLAP over uncertain and imprecise data, In: Proc. 2005 Int. Conf. Very Large Data Bases (VLDB’05) Trondheim, Norway. (Aug. 2005), pp. 970–981.

[Ben08] Benninga, S., Financial Modeling. 3rd. ed. (2008) MIT Press, Cambridge, MA .

[Ber81] Bertin, J., Graphics and Graphic Information Processing. (1981) Walter de Gruyter, Berlin .

[Ber03] Berry, M.W., Survey of Text Mining: Clustering, Classification, and Retrieval. (2003) Springer, New York .

[Bez81] Bezdek, J.C., Pattern Recognition with Fuzzy Objective Function Algorithms. (1981) Plenum Press .

[BFOS84] Breiman, L.; Friedman, J.; Olshen, R.; Stone, C., Classification and Regression Trees. (1984) Wadsworth International Group .

[BFR98] Bradley, P.; Fayyad, U.; Reina, C., Scaling clustering algorithms to large databases, In: Proc. 1998 Int. Conf. Knowledge Discovery and Data Mining (KDD’98) New York. (Aug. 1998), pp. 9–15.

[BG04] Bhattacharya, I.; Getoor, L., Iterative record linkage for cleaning and integration, In: Proc. SIGMOD 2004 Workshop on Research Issues on Data Mining and Knowledge Discovery (DMKD’04) Paris, France. (June 2004), pp. 11–18.

[B-G05] Ben-Gal, I., Outlier detection, In: (Editors: Maimon, O.; Rockach, L.) Data Mining and Knowledge Discovery Handbook: A Complete Guide for Practitioners and Researchers Kluwer Academic. (2005).

[BGKW03] Bucila, C.; Gehrke, J.; Kifer, D.; White, W., DualMiner: A dual-pruning algorithm for itemsets with constraints, Data Mining and Knowledge Discovery 7 (2003) 241–272.

[BGMP03] Bonchi, F.; Giannotti, F.; Mazzanti, A.; Pedreschi, D., ExAnte: Anticipated data reduction in constrained pattern mining, In: Proc. 7th European Conf. Principles and Pratice of Knowledge Discovery in Databases (PKDD’03), Vol. 2838/2003 (Sept. 2003) Cavtat-Dubrovnik, Croatia, pp. 59–70.

[BGRS99] Beyer, K.S.; Goldstein, J.; Ramakrishnan, R.; Shaft, U., When is「nearest neighbor」meaningful? In: Proc. 1999 Int. Conf. Database Theory (ICDT’99) Jerusalem, Israel. (Jan. 1999), pp. 217–235.

[BGV92] Boser, B.; Guyon, I.; Vapnik, V.N., A training algorithm for optimal margin classifiers, In: Proc. Fifth Annual Workshop on Computational Learning Theory (1992) ACM Press, San Mateo, CA, pp. 144–152.

[Bis95] Bishop, C.M., Neural Networks for Pattern Recognition. (1995) Oxford University Press .

[Bis06] Bishop, C.M., Pattern Recognition and Machine Learning. (2006) Springer, New York .

[BJR08] Box, G.E.P.; Jenkins, G.M.; Reinsel, G.C., Time Series Analysis: Forecasting and Control. 4th ed. (2008) Prentice-Hall .

[BKNS00] Breunig, M.M.; Kriegel, H.-P.; Ng, R.; Sander, J., LOF: Identifying density-based local outliers, In: Proc. 2000 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’00) Dallas, TX. (May 2000), pp. 93–104.

[BL99] Berry, M.J.A.; Linoff, G., Mastering Data Mining: The Art and Science of Customer Relationship Management. (1999) John Wiley & Sons .

[BL04] Berry, M.J.A.; Linoff, G.S., Data Mining Techniques: For Marketing, Sales, and Customer Relationship Management. (2004) John Wiley & Sons .

[BL09] Blei, D.; Lafferty, J., Topic models, In: (Editors: Srivastava, A.; Sahami, M.) Text Mining: Theory and Applications Taylor and Francis. (2009).

[BLC+03] Barbará, D.; Li, Y.; Couto, J.; Lin, J.-L.; Jajodia, S., Bootstrapping a data mining intrusion detection system, In: Proc. 2003 ACM Symp. on Applied Computing (SAC’03) Melbourne, FL. (March 2003).

[BM98] Blum, A.; Mitchell, T., Combining labeled and unlabeled data with co-training, In: Proc. 11th Conf. Computational Learning Theory (COLT’98) Madison, WI. (1998), pp. 92–100.

[BMAD06] Bakar, Z.A.; Mohemad, R.; Ahmad, A.; Deris, M.M., A comparative study for outlier detection techniques in data mining, In: Proc. 2006 IEEE Conf. Cybernetics and Intelligent Systems Bangkok, Thailand. (2006), pp. 1–6.

[BMS97] Brin, S.; Motwani, R.; Silverstein, C., Beyond market basket: Generalizing association rules to correlations, In: Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97) Tucson, AZ. (May 1997), pp. 265–276.

[BMUT97] Brin, S.; Motwani, R.; Ullman, J.D.; Tsur, S., Dynamic itemset counting and implication rules for market basket analysis, In: Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97) Tucson, AZ. (May 1997), pp. 255–264.

[BN92] Buntine, W.L.; Niblett, T., A further comparison of splitting rules for decision-tree induction, Machine Learning 8 (1992) 75–85.

[BO04] Baxevanis, A.; Ouellette, B.F.F., Bioinformatics: A Practical Guide to the Analysis of Genes and Proteins. 3rd ed. (2004) John Wiley & Sons .

[BP92] Bezdek, J.C.; Pal, S.K., Fuzzy Models for Pattern Recognition: Methods That Search for Structures in Data. (1992) IEEE Press .

[BP98] Brin, S.; Page, L., The anatomy of a large-scale hypertextual web search engine, In: Proc. 7th Int. World Wide Web Conf. (WWW’98) Brisbane, Australia. (Apr. 1998), pp. 107–117.

[BPT97] Baralis, E.; Paraboschi, S.; Teniente, E., Materialized view selection in a multidimensional database, In: Proc. 1997 Int. Conf. Very Large Data Bases (VLDB’97) Athens, Greece. (Aug. 1997); pp. 98–12.

[BPW88] Bareiss, E.R.; Porter, B.W.; Weir, C.C., Protos: An exemplar-based learning apprentice, Int. J. Man-Machine Studies 29 (1988) 549–561.

[BR99] Beyer, K.; Ramakrishnan, R., Bottom-up computation of sparse and iceberg cubes, In: Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99) Philadelphia, PA. (June 1999), pp. 359–370.

[Bre96] Breiman, L., Bagging predictors, Machine Learning 24 (1996) 123–140.

[Bre01] Breiman, L., Random forests, Machine Learning 45 (2001) 5–32.

[BS97] Barbará, D.; Sullivan, M., Quasi-cubes: Exploiting approximation in multidimensional databases, SIGMOD Record 26 (1997) 12–17.

[BS03] Bay, S.D.; Schwabacher, M., Mining distance-based outliers in near linear time with randomization and a simple pruning rule, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 29–38.

[BST99] Berson, A.; Smith, S.J.; Thearling, K., Building Data Mining Applications for CRM. (1999) McGraw-Hill .

[BT99] Ballou, D.P.; Tayi, G.K., Enhancing data quality in data warehouse environments, Communications of the ACM 42 (1999) 73–78.

[BU95] Brodley, C.E.; Utgoff, P.E., Multivariate decision trees, Machine Learning 19 (1995) 45–77.

[Bun94] Buntine, W.L., Operations for learning with graphical models, J. Artificial Intelligence Research 2 (1994) 159–225.

[Bur98] Burges, C.J.C., A tutorial on support vector machines for pattern recognition, Data Mining and Knowledge Discovery 2 (1998) 121–168.

[BW00] Barbará, D.; Wu, X., Using loglinear models to compress datacubes, In: Proc. 1st Int. Conf. Web-Age Information Management (WAIM’00) Shanghai, China. (2000), pp. 311–322.

[BW01] Babu, S.; Widom, J., Continuous queries over data streams, SIGMOD Record 30 (2001) 109–120.

[BYRN11] Baeza-Yates, R.A.; Ribeiro-Neto, B.A., Modern Information Retrieval. 2nd ed. (2011) Addison-Wesley, Boston .

[Cat91]

[CBK09] Chandola, V.; Banerjee, A.; Kumar, V., Anomaly detection: A survey, ACM Computing Surveys 41 (2009) 1–58.

[CC00] Cheng, Y.; Church, G., Biclustering of expression data, In: Proc. 2000 Int. Conf. Intelligent Systems for Molecular Biology (ISMB’00) La Jolla, CA. (Aug. 2000), pp. 93–103.

[CCH91] Cai, Y.; Cercone, N.; Han, J., Attribute-oriented induction in relational databases, In: (Editors: Piatetsky-Shapiro, G.; Frawley, W.J.) Knowledge Discovery in Databases AAAI/MIT Press. (1991), pp. 213–228.

[CCLR05] Chen, B.-C.; Chen, L.; Lin, Y.; Ramakrishnan, R., Prediction cubes, In: Proc. 2005 Int. Conf. Very Large Data Bases (VLDB’05) Trondheim, Norway. (Aug. 2005), pp. 982–993.

[CCS93] Codd, E.F.; Codd, S.B.; Salley, C.T., Beyond decision support, Computer World 27 (30) (July 1993) 5–12.

[CD97] Chaudhuri, S.; Dayal, U., An overview of data warehousing and OLAP technology, SIGMOD Record 26 (1997) 65–74.

[CDH+02] Chen, Y.; Dong, G.; Han, J.; Wah, B.W.; Wang, J., Multidimensional regression analysis of time-series data streams, In: Proc. 2002 Int. Conf. Very Large Data Bases (VLDB’02) Hong Kong, China. (Aug. 2002), pp. 323–334.

[CDH+06] Chen, Y.; Dong, G.; Han, J.; Pei, J.; Wah, B.W.; Wang, J., Regression cubes with lossless compression and aggregation, IEEE Trans. Knowledge and Data Engineering 18 (2006) 1585–1599.

[CDI98] Chakrabarti, S.; Dom, B.E.; Indyk, P., Enhanced hypertext classification using hyper-links, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 307–318.

[CDK+99] Chakrabarti, S.; Dom, B.E.; Kumar, S.R.; Raghavan, P.; Rajagopalan, S.; Tomkins, A.; Gibson, D.; Kleinberg, J.M., Mining the web's link structure, COMPUTER 32 (1999) 60–67.

[CGC94] Chaturvedi, A.; Green, P.; Carroll, J., k-means, k-medians and k-modes: Special cases of partitioning multiway data, In: The Classification Society of North America (CSNA) Meeting Presentation Houston, TX. (1994).

[CGC01] Chaturvedi, A.; Green, P.; Carroll, J., k-modes clustering, J. Classification 18 (2001) 35–55.

[CH67] Cover, T.; Hart, P., Nearest neighbor pattern classification, IEEE Trans. Information Theory 13 (1967) 21–27.

[CH92] Cooper, G.; Herskovits, E., A Bayesian method for the induction of probabilistic networks from data, Machine Learning 9 (1992) 309–347.

[CH07] Cook, D.J.; Holder, L.B., Mining Graph Data. (2007) John Wiley & Sons .

[Cha03a] Chakrabarti, S., Mining the Web: Discovering Knowledge from Hypertext Data. (2003) Morgan Kaufmann .

[Cha03b] Chatfield, C., The Analysis of Time Series: An Introduction. 6th ed. (2003) Chapman & Hall .

[CHN+96] Cheung, D.W.; Han, J.; Ng, V.; Fu, A.; Fu, Y., A fast distributed algorithm for mining association rules, In: Proc. 1996 Int. Conf. Parallel and Distributed Information Systems Miami Beach, FL. (Dec. 1996), pp. 31–44.

[CHNW96] Cheung, D.W.; Han, J.; Ng, V.; Wong, C.Y., Maintenance of discovered association rules in large databases: An incremental updating technique, In: Proc. 1996 Int. Conf. Data Engineering (ICDE’96) New Orleans, LA. (Feb. 1996), pp. 106–114.

[CHY96] Chen, M.S.; Han, J.; Yu., P.S., Data mining: An overview from a database perspective, IEEE Trans. Knowledge and Data Engineering 8 (1996) 866–883.

[CK98] Carey, M.; Kossman, D., Reducing the braking distance of an SQL query engine, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York. (Aug. 1998), pp. 158–169.

[CKT06] Chakrabarti, D.; Kumar, R.; Tomkins, A., Evolutionary clustering, In: Proc. 2006 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’06) Philadelphia, PA. (Aug. 2006), pp. 554–560.

[Cle93] Cleveland, W., Visualizing Data. (1993) Hobart Press .

[CSZ06] Chapelle, O.; Schölkopf, B.; Zien, A., Semi-supervised Learning. (2006) MIT Press, Cambridge, MA .

[CM94] Curram, S.P.; Mingers, J., Neural networks, decision tree induction and discriminant analysis: An empirical comparison, J. Operational Research Society 45 (1994) 440–450.

[CMC05] Cao, H.; Mamoulis, N.; Cheung, D.W., Mining frequent spatio-temporal sequential patterns, In: Proc. 2005 Int. Conf. Data Mining (ICDM’05) Houston, TX. (Nov. 2005), pp. 82–89.

[CMS09] Croft, B.; Metzler, D.; Strohman, T., Search Engines: Information Retrieval in Practice. (2009) Addison-Wesley, Boston .

[CN89] Clark, P.; Niblett, T., The CN2 induction algorithm, Machine Learning 3 (1989) 261–283.

[Coh95] Cohen, W., Fast effective rule induction, In: Proc. 1995 Int. Conf. Machine Learning (ICML’95) Tahoe City, CA. (July 1995), pp. 115–123.

[Coo90] Cooper, G.F., The computational complexity of probabilistic inference using Bayesian belief networks, Artificial Intelligence 42 (1990) 393–405.

[CPS98] Cios, K.; Pedrycz, W.; Swiniarski, R., Data Mining Methods for Knowledge Discovery. (1998) Kluwer Academic .

[CR95] Chauvin, Y.; Rumelhart, D., Backpropagation: Theory, Architectures, and Applications. (1995) Lawrence Erlbaum .

[Cra89] Crawford, S.L., Extensions to the CART algorithm, Int. J. Man-Machine Studies 31 (Aug. 1989) 197–217.

[CRST06] Chen, B.-C.; Ramakrishnan, R.; Shavlik, J.W.; Tamma, P., Bellwether analysis: Predicting global aggregates from local regions, In: Proc. 2006 Int. Conf. Very Large Data Bases (VLDB’06) Seoul, Korea. (Sept. 2006), pp. 655–666.

[CS93a] Chan, P.K.; Stolfo, S.J., Experiments on multistrategy learning by metalearning, In: Proc. 2nd. Int. Conf. Information and Knowledge Management (CIKM’93) Washington, DC. (Nov. 1993), pp. 314–323.

[CS93b] Chan, P.K.; Stolfo, S.J., Toward multi-strategy parallel & distributed learning in sequence analysis, In: Proc. 1st Int. Conf. Intelligent Systems for Molecular Biology (ISMB’93) Bethesda, MD. (July 1993), pp. 65–73.

[CS96] Craven, M.W.; Shavlik, J.W., Extracting tree-structured representations of trained networks, In: (Editors: Touretzky, D.; Mozer, M.; Hasselmo, M.) Advances in Neural Information Processing Systems (1996) MIT Press, Cambridge, MA.

[CS97] Craven, M.W.; Shavlik, J.W., Using neural networks in data mining, Future Generation Computer Systems 13 (1997) 211–229.

[CS-T00] Cristianini, N.; Shawe-Taylor, J., An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods. (2000) Cambridge University Press .

[CSZ+07] Chi, Y.; Song, X.; Zhou, D.; Hino, K.; Tseng, B.L., Evolutionary spectral clustering by incorporating temporal smoothness, In: Proc. 2007 ACM SIGKDD Intl. Conf. Knowledge Discovery and Data Mining (KDD’07) San Jose, CA. (Aug. 2007), pp. 153–162.

[CTTX05] Cong, G.; Tan, K.-Lee; Tung, A.K.H.; Xu, X., Mining top-k covering rule groups for gene expression data, In: Proc. 2005 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’05) Baltimore, MD. (June 2005), pp. 670–681.

[CWL+08] Cong, G.; Wang, L.; Lin, C.-Y.; Song, Y.-I.; Sun, Y., Finding question-answer pairs from online forums, In: Proc. 2008 Int. ACM SIGIR Conf. Research and Development in Information Retrieval (SIGIR’08) Singapore. (July 2008), pp. 467–474.

[CYHH07] Cheng, H.; Yan, X.; Han, J.; Hsu, C.-W., Discriminative frequent pattern analysis for effective classification, In: Proc. 2007 Int. Conf. Data Engineering (ICDE’07) Istanbul, Turkey. (Apr. 2007), pp. 716–725.

[CYHY08] Cheng, H.; Yan, X.; Han, J.; Yu, P.S., Direct discriminative pattern mining for effective classification, In: Proc. 2008 Int. Conf. Data Engineering (ICDE’08) Cancun, Mexico. (Apr. 2008), pp. 169–178.

[CYZ+08] Chen, C.; Yan, X.; Zhu, F.; Han, J.; Yu, P.S., Graph OLAP: Towards online analytical processing on graphs, In: Proc. 2008 Int. Conf. Data Mining (ICDM’08) Pisa, Italy. (Dec. 2008), pp. 103–112.

[Dar10] Darwiche, A., Bayesian networks, Communications of the ACM 53 (2010) 80–90.

[Das91] Dasarathy, B.V., Nearest Neighbor (NN) Norms: NN Pattern Classification Techniques. (1991) IEEE Computer Society Press .

[Dau92] Daubechies, I., Ten Lectures on Wavelets. (1992) Capital City Press .

[DB95] Dietterich, T.G.; Bakiri, G., Solving multiclass learning problems via error-correcting output codes, J. Artificial Intelligence Research 2 (1995) 263–286.

[DBK+97] Drucker, H.; Burges, C.J.C.; Kaufman, L.; Smola, A.; Vapnik, V.N., Support vector regression machines, In: (Editors: Mozer, M.; Jordan, M.; Petsche, T.) Advances in Neural Information Processing Systems 9 (1997) MIT Press, Cambridge, MA, pp. 155–161.

[DE84] Day, W.H.E.; Edelsbrunner, H., Efficient algorithms for agglomerative hierarchical clustering methods, J. Classification 1 (1984) 7–24.

[De01] In: (Editors: Dzeroski, S.; Lavrac, N.) Relational Data Mining (2001) Springer, New York.

[DEKM98] Durbin, R.; Eddy, S.; Krogh, A.; Mitchison, G., Biological Sequence Analysis: Probability Models of Proteins and Nucleic Acids. (1998) Cambridge University Press .

[Dev95] Devore, J.L., Probability and Statistics for Engineering and the Sciences. 4th ed. (1995) Duxbury Press .

[Dev03] Devore, J.L., Probability and Statistics for Engineering and the Sciences. 6th ed. (2003) Duxbury Press .

[DH73] Donath, W.E.; Hoffman, A.J., Lower bounds for the partitioning of graphs, IBM J. Research and Development 17 (1973) 420–425.

[DH00] Domingos, P.; Hulten, G., Mining high-speed data streams, In: Proc. 2000 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’00) Boston, MA. (Aug. 2000), pp. 71–80.

[DHL+01] Dong, G.; Han, J.; Lam, J.; Pei, J.; Wang, K., Mining multi-dimensional constrained gradients in data cubes, In: Proc. 2001 Int. Conf. Very Large Data Bases (VLDB’01) Rome, Italy. (Sept. 2001), pp. 321–330.

[DHL+04] Dong, G.; Han, J.; Lam, J.; Pei, J.; Wang, K.; Zou, W., Mining constrained gradients in multi-dimensional databases, IEEE Trans. Knowledge and Data Engineering 16 (2004) 922–938.

[DHS01] Duda, R.O.; Hart, P.E.; Stork, D.G., Pattern Classification. 2nd ed. (2001) John Wiley & Sons .

[DJ03] Dasu, T.; Johnson, T., Exploratory Data Mining and Data Cleaning. (2003) John Wiley & Sons .

[DJMS02] Dasu, T.; Johnson, T.; Muthukrishnan, S.; Shkapenyuk, V., Mining database structure; or how to build a data quality browser, In: Proc. 2002 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’02) Madison, WI. (June 2002), pp. 240–251.

[DL97] Dash, M.; Liu, H., Feature selection methods for classification, Intelligent Data Analysis 1 (1997) 131–156.

[DL99] Dong, G.; Li, J., Efficient mining of emerging patterns: Discovering trends and differences, In: Proc. 1999 Int. Conf. Knowledge Discovery and Data Mining (KDD’99) San Diego, CA. (Aug. 1999), pp. 43–52.

[DLR77] Dempster, A.P.; Laird, N.M.; Rubin, D.B., Maximum likelihood from incomplete data via the EM algorithm, J. Royal Statistical Society, Series B 39 (1977) 1–38.

[DLY97] Dash, M.; Liu, H.; Yao, J., Dimensionality reduction of unsupervised data, In: Proc. 1997 IEEE Int. Conf. Tools with AI (ICTAI’97) (1997) IEEE Computer Society, Newport Beach, CA, pp. 532–539.

[DM02] Dasgupta, D.; Majumdar, N.S., Anomaly detection in multidimensional data using negative selection algorithm, In: Proc. 2002 Congress on Evolutionary Computation (CEC’02) Washington, DC. (2002), pp. 1039–1044; Chapter 12.

[DNR+97] Deshpande, P.; Naughton, J.; Ramasamy, K.; Shukla, A.; Tufte, K.; Zhao, Y., Cubing algorithms, storage estimation, and storage and processing alternatives for OLAP, Bull. Technical Committee on Data Engineering 20 (1997) 3–11.

[Dob90] Dobson, A.J., An Introduction to Generalized Linear Models. (1990) Chapman & Hall .

[Dob01] Dobson, A.J., An Introduction to Generalized Linear Models. 2nd ed. (2001) Chapman & Hall .

[Dom94] Domingos, P., The RISE system: Conquering without separating, In: Proc. 1994 IEEE Int. Conf. Tools with Artificial Intelligence (TAI’94) New Orleans, LA. (1994), pp. 704–707.

[Dom99] Domingos, P., The role of Occam's razor in knowledge discovery, Data Mining and Knowledge Discovery 3 (1999) 409–425.

[DP96] Domingos, P.; Pazzani, M., Beyond independence: Conditions for the optimality of the simple Bayesian classifier, In: Proc. 1996 Int. Conf. Machine Learning (ML’96) Bari, Italy. (July 1996), pp. 105–112.

[DP97] Devore, J.; Peck, R., Statistics: The Exploration and Analysis of Data. (1997) Duxbury Press .

[DP07] Dong, G.; Pei, J., Sequence Data Mining. (2007) Springer, New York .

[DR99] Donjerkovic, D.; Ramakrishnan, R., Probabilistic optimization of top N queries, In: Proc. 1999 Int. Conf. Very Large Data Bases (VLDB’99) Edinburgh, UK. (Sept. 1999), pp. 411–422.

[DR05] Davidson, I.; Ravi, S.S., Clustering with constraints: Feasibility issues and the k-means algorithm, In: Proc. 2005 SIAM Int. Conf. Data Mining (SDM’05) Newport Beach, CA. (Apr. 2005).

[DT93] Dhar, V.; Tuzhilin, A., Abstract-driven pattern discovery in databases, IEEE Trans. Knowledge and Data Engineering 5 (1993) 926–938.

[Dun03] Dunham, M., Data Mining: Introductory and Advanced Topics. (2003) Prentice-Hall .

[DWB06] Davidson, I.; Wagstaff, K.L.; Basu, S., Measuring constraint-set utility for partitional clustering algorithms, In: Proc. 10th European Conf. Principles and Practice of Knowledge Discovery in Databases (PKDD’06) Berlin, Germany. (Sept. 2006), pp. 115–126.

[Dwo06] Dwork, C., Differential privacy, In: Proc. 2006 Int. Col. Automata, Languages and Programming (ICALP) Venice, Italy. (July 2006), pp. 1–12.

[DYXY07] Dai, W.; Yang, Q.; Xue, G.; Yu, Y., Boosting for transfer learning, In: Proc. 24th Intl. Conf. Machine Learning Corvallis, OR. (June 2007), pp. 193–200.

[Ega75] Egan, J.P., Signal Detection Theory and ROC Analysis. (1975) Academic Press .

[EK10] Easley, D.; Kleinberg, J., Networks, Crowds, and Markets: Reasoning about a Highly Connected World. (2010) Cambridge University Press .

[Esk00] Eskin, E., Anomaly detection over noisy data using learned probability distributions, In: Proc. 17th Int. Conf. Machine Learning (ICML’00) Stanford, CA. (2000).

[EKSX96] Ester, M.; Kriegel, H.-P.; Sander, J.; Xu, X., A density-based algorithm for discovering clusters in large spatial databases, In: Proc. 1996 Int. Conf. Knowledge Discovery and Data Mining (KDD’96) Portland, OR. (Aug. 1996), pp. 226–231.

[EKX95] Ester, M.; Kriegel, H.-P.; Xu, X., Knowledge discovery in large spatial databases: Focusing techniques for efficient class identification, In: Proc. 1995 Int. Symp. Large Spatial Databases (SSD’95) Portland, ME. (Aug. 1995), pp. 67–82.

[Elk97] Elkan, C., Boosting and naïve Bayesian learning, In: Technical Report CS97-557 (Sept. 1997) Dept. Computer Science and Engineering, University of California at San Diego.

[Elk01] Elkan, C., The foundations of cost-sensitive learning, In: Proc. 17th Intl. Joint Conf. Artificial Intelligence (IJCAI’01) Seattle, WA. (2001), pp. 973–978.

[EN10] Elmasri, R.; Navathe, S.B., Fundamentals of Database Systems. 6th ed. (2010) Addison-Wesley, Boston .

[Eng99] English, L., Improving Data Warehouse and Business Information Quality: Methods for Reducing Costs and Increasing Profits. (1999) John Wiley & Sons .

[ESAG02] Evfimievski, A.; Srikant, R.; Agrawal, R.; Gehrke, J., Privacy preserving mining of association rules, In: Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’02) Edmonton, Alberta, Canada. (July 2002), pp. 217–228.

[ET93] Efron, B.; Tibshirani, R., An Introduction to the Bootstrap. (1993) Chapman & Hall .

[FB74] Finkel, R.A.; Bentley, J.L., Quad-trees: A data structure for retrieval on composite keys, ACTA Informatica 4 (1974) 1–9.

[FB08] Friedman, J.; Bogdan, E.P., Predictive learning via rule ensembles, Ann. Applied Statistics 2 (2008) 916–954.

[FBF77] Friedman, J.H.; Bentley, J.L.; Finkel, R.A., An algorithm for finding best matches in logarithmic expected time, ACM Transactions on Math Software 3 (1977) 209–226.

[FFF99] Faloutsos, M.; Faloutsos, P.; Faloutsos, C., On power-law relationships of the internet topology, In: Proc. ACM SIGCOMM’99 Conf. Applications, Technologies, Architectures, and Protocols for Computer Communication Cambridge, MA. (Aug. 1999), pp. 251–262.

[FG02] Fishelson, M.; Geiger, D., Exact genetic linkage computations for general pedigrees, Disinformation 18 (2002) 189–198.

[FGK+05] Fagin, R.; Guha, R.V.; Kumar, R.; Novak, J.; Sivakumar, D.; Tomkins, A., Multi-structural databases, In: Proc. 2005 ACM SIGMOD-SIGACT-SIGART Symp. Principles of Database Systems (PODS’05) Baltimore, MD. (June 2005), pp. 184–195.

[FGW01] Fayyad, U.; Grinstein, G.; Wierse, A., Information Visualization in Data Mining and Knowledge Discovery. (2001) Morgan Kaufmann .

[FH51] Fix, E.; Hodges Jr., J.L., Discriminatory analysis, non-parametric discrimination: Consistency properties, In: Technical Report 21-49-004(4) (1951) USAF School of Aviation Medicine, Randolph Field, Texas.

[FH87] Fukunaga, K.; Hummels, D., Bayes error estimation using Parzen and k-nn procedure, IEEE Trans. Pattern Analysis and Machine Learning 9 (1987) 634–643.

[FH95] Fu, Y.; Han, J., Meta-rule-guided mining of association rules in relational databases, In: Proc. 1995 Int. Workshop Integration of Knowledge Discovery with Deductive and Object-Oriented Databases (KDOOD’95) Singapore. (Dec. 1995), pp. 39–46.

[FI90] Fayyad, U.M.; Irani, K.B., What should be minimized in a decision tree? In: Proc. 1990 Nat. Conf. Artificial Intelligence (AAAI’90) Boston, MA. (1990), pp. 749–754.

[FI92] Fayyad, U.M.; Irani, K.B., The attribute selection problem in decision tree generation, In: Proc. 1992 Nat. Conf. Artificial Intelligence (AAAI’92) San Jose, CA. (1992), pp. 104–110.

[FI93] Fayyad, U.; Irani, K., Multi-interval discretization of continuous-valued attributes for classification learning, In: Proc. 1993 Int. Joint Conf. Artificial Intelligence (IJCAI’93) Chambery, France. (1993), pp. 1022–1029.

[Fie73] Fiedler, M., Algebraic connectivity of graphs, Czechoslovak Mathematical J. 23 (1973) 298–305.

[FL90] Fahlman, S.; Lebiere, C., The cascade-correlation learning algorithm, In: Technical Report CMU-CS-90-100 Computer Sciences Department, Carnegie Mellon University. (1990).

[FL95] Faloutsos, C.; Lin, K.-I., FastMap: A fast algorithm for indexing, data-mining and visualization of traditional and multimedia datasets, In: Proc. 1995 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’95) San Jose, CA. (May 1995), pp. 163–174.

[Fle87] Fletcher, R., Practical Methods of Optimization. (1987) John Wiley & Sons .

[FMMT96] Fukuda, T.; Morimoto, Y.; Morishita, S.; Tokuyama, T., Data mining using two-dimensional optimized association rules: Scheme, algorithms, and visualization, In: Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’96) Montreal, Quebec, Canada. (June 1996), pp. 13–23.

[FP05]

[FPP07] Freedman, D.; Pisani, R.; Purves, R., Statistics. 4th ed. (2007) W. W. Norton & Co. .

[FPSS+96] In: (Editors: Fayyad, U.M.; Piatetsky-Shapiro, G.; Smyth, P.; Uthurusamy, R.) Advances in Knowledge Discovery and Data Mining (1996) AAAI/MIT Press.

[FP97] Fawcett, T.; Provost, F., Adaptive fraud detection, Data Mining and Knowledge Discovery 1 (1997) 291–316.

[FR02] Fraley, C.; Raftery, A.E., Model-based clustering, discriminant analysis, and density estimation, J. American Statistical Association 97 (2002) 611–631.

[Fri77] Friedman, J.H., A recursive partitioning decision rule for nonparametric classifiers, IEEE Trans. Computer 26 (1977) 404–408.

[Fri01] Friedman, J.H., Greedy function approximation: A gradient boosting machine, Ann. Statistics 29 (2001) 1189–1232.

[Fri03]

[FRM94] Faloutsos, C.; Ranganathan, M.; Manolopoulos, Y., Fast subsequence matching in time-series databases, In: Proc. 1994 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’94 Minneapolis, MN. (May 1994), pp. 419–429.

[FS93] Fayyad, U.; Smyth, P., Image database exploration: Progress and challenges, In: Proc. AAAI’93 Workshop Knowledge Discovery in Databases (KDD’93) Washington, DC. (July 1993), pp. 14–27.

[FS97] Freund, Y.; Schapire, R.E., A decision-theoretic generalization of on-line learning and an application to boosting, J. Computer and System Sciences 55 (1997) 119–139.

[FS06] Feldman, R.; Sanger, J., The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data. (2006) Cambridge University Press .

[FSGM+98] Fang, M.; Shivakumar, N.; Garcia-Molina, H.; Motwani, R.; Ullman, J.D., Computing iceberg queries efficiently, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York, NY. (Aug. 1998), pp. 299–310.

[FW94] Furnkranz, J.; Widmer, G., Incremental reduced error pruning, In: Proc. 1994 Int. Conf. Machine Learning (ICML’94) New Brunswick, NJ. (1994), pp. 70–77.

[FWFY10] Fung, B.C.M.; Wang, K.; Fu, A.W.-C.; Yu, P.S., Introduction to Privacy-Preserving Data Publishing: Concepts and Techniques. (2010) Chapman & Hall/CRC .

[FYM05] Fujimaki, R.; Yairi, T.; Machida, K., An approach to spacecraft anomaly detection problem using kernel feature space, In: Proc. 2005 Int. Workshop Link Discovery (LinkKDD’05) Chicago, IL. (2005), pp. 401–410.

[Gal93] Gallant, S.I., Neural Network Learning and Expert Systems. (1993) MIT Press, Cambridge, MA .

[Gat00] Gates, B., Business @ the Speed of Thought: Succeeding in the Digital Economy. (2000) Warner Books .

[GCB+97] Gray, J.; Chaudhuri, S.; Bosworth, A.; Layman, A.; Reichart, D.; Venkatrao, M.; Pellow, F.; Pirahesh, H., Data cube: A relational aggregation operator generalizing group-by, cross-tab and sub-totals, Data Mining and Knowledge Discovery 1 (1997) 29–54.

[GFKT01] Getoor, L.; Friedman, N.; Koller, D.; Taskar, B., Learning probabilistic models of relational structure, In: Proc. 2001 Int. Conf. Machine Learning (ICML’01) Williamstown, MA. (2001), pp. 170–177.

[GFS+01] Galhardas, H.; Florescu, D.; Shasha, D.; Simon, E.; Saita, C.-A., Declarative data cleaning: Language, model, and algorithms, In: Proc. 2001 Int. Conf. Very Large Data Bases (VLDB’01) Rome, Italy. (Sept. 2001), pp. 371–380.

[GG92] Gersho, A.; Gray, R.M., Vector Quantization and Signal Compression. (1992) Kluwer Academic .

[GG98] Gaede, V.; Günther, O., Multidimensional access methods, ACM Computing Surveys 30 (1998) 170–231.

[GGR99] Ganti, V.; Gehrke, J.E.; Ramakrishnan, R., CACTUS—clustering categorical data using summaries, In: Proc. 1999 Int. Conf. Knowledge Discovery and Data Mining (KDD’99) San Diego, CA. (1999), pp. 73–83.

[GGRL99] Gehrke, J.; Ganti, V.; Ramakrishnan, R.; Loh, W.-Y., BOAT—optimistic decision tree construction, In: Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99) Philadelphia, PA. (June 1999), pp. 169–180.

[GHL06] Gonzalez, H.; Han, J.; Li, X., Flowcube: Constructuing RFID flowcubes for multi-dimensional analysis of commodity flows, In: Proc. 2006 Int. Conf. Very Large Data Bases (VLDB’06) Seoul, Korea. (Sept. 2006), pp. 834–845.

[GHLK06] Gonzalez, H.; Han, J.; Li, X.; Klabjan, D., Warehousing and analysis of massive RFID data sets, In: Proc. 2006 Int. Conf. Data Engineering (ICDE’06) Atlanta, GA. (Apr. 2006), p. 83.

[GKK+01] Grossman, R.L.; Kamath, C.; Kegelmeyer, P.; Kumar, V.; Namburu, R.R., Data Mining for Scientific and Engineering Applications. (2001) Kluwer Academic .

[GKR98] Gibson, D.; Kleinberg, J.M.; Raghavan, P., Clustering categorical data: An approach based on dynamical systems, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York, NY. (Aug. 1998), pp. 311–323.

[GM99] Gupta, A.; Mumick, I.S., Materialized Views: Techniques, Implementations, and Applications. (1999) MIT Press, Cambridge, MA .

[GMMO00] Guha, S.; Mishra, N.; Motwani, R.; O’Callaghan, L., Clustering data streams, In: Proc. 2000 Symp. Foundations of Computer Science (FOCS’00) Redondo Beach, CA. (2000), pp. 359–366.

[GMP+09] Ginsberg, J.; Mohebbi, M.H.; Patel, R.S.; Brammer, L.; Smolinski, M.S.; Brilliant, L., Detecting influenza epidemics using search engine query data, Nature 457 (Feb. 2009) 1012–1014.

[GMUW08] Garcia-Molina, H.; Ullman, J.D.; Widom, J., Database Systems: The Complete Book. 2nd ed. (2008) Prentice Hall .

[GMV96] Guyon, I.; Matic, N.; Vapnik, V., Discoverying informative patterns and data cleaning, In: (Editors: Fayyad, U.M.; Piatetsky-Shapiro, G.; Smyth, P.; Uthurusamy, R.) Advances in Knowledge Discovery and Data Mining AAAI/MIT Press. (1996), pp. 181–203.

[Gol89] Goldberg, D., Genetic Algorithms in Search, Optimization, and Machine Learning. (1989) Addison-Wesley, Reading, MA .

[GR04] Grossman, D.A.; Frieder, O., Information Retrieval: Algorithms and Heuristics. (2004) Springer, New York .

[GR07] Grunwald, P.D.; Rissanen, J., The Minimum Description Length Principle. (2007) MIT Press, Cambridge, MA .

[GRG98] Gehrke, J.; Ramakrishnan, R.; Ganti, V., RainForest: A framework for fast decision tree construction of large datasets, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York, NY. (Aug. 1998), pp. 416–427.

[GRS98] Guha, S.; Rastogi, R.; Shim, K., CURE: An efficient clustering algorithm for large databases, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 73–84.

[GRS99] Guha, S.; Rastogi, R.; Shim, K., ROCK: A robust clustering algorithm for categorical attributes, In: Proc. 1999 Int. Conf. Data Engineering (ICDE’99) Sydney, Australia. (Mar. 1999), pp. 512–521.

[Gru69] Grubbs, F.E., Procedures for detecting outlying observations in samples, Technometrics 11 (1969) 1–21.

[Gup97] Gupta, H., Selection of views to materialize in a data warehouse, In: Proc. 7th Int. Conf. Database Theory (ICDT’97) Delphi, Greece. (Jan. 1997), pp. 98–112.

[Gut84] Guttman, A., R-Tree: A dynamic index structure for spatial searching, In: Proc. 1984 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’84) Boston, MA. (June 1984), pp. 47–57.

[GW07] Gonzalez, R.C.; Woods, R.E., Digital Image Processing. 3rd ed. (2007) Prentice Hall .

[GZ03a] Goethals, B.; Zaki, M., An introduction to workshop frequent itemset mining implementations, In: Proc. ICDM’03 Int. Workshop Frequent Itemset Mining Implementations (FIMI’03) Melbourne, FL. (Nov. 2003), pp. 1–13.

[GZ03b] Grahne, G.; Zhu, J., Efficiently using prefix-trees in mining frequent itemsets, In: Proc. ICDM’03 Int. Workshop on Frequent Itemset Mining Implementations (FIMI’03) Melbourne, FL. (Nov. 2003).

[HA04] Hodge, V.J.; Austin, J., A survey of outlier detection methodologies, Artificial Intelligence Review 22 (2004) 85–126.

[HAC+99] Hellerstein, J.M.; Avnur, R.; Chou, A.; Hidber, C.; Olston, C.; Raman, V.; Roth, T.; Haas, P.J., Interactive data analysis: The control project, IEEE Computer 32 (1999) 51–59.

[Ham94] Hamilton, J., Time Series Analysis. (1994) Princeton University Press .

[Han98] Han, J., Towards on-line analytical mining in large databases, SIGMOD Record 27 (1998) 97–107.

[Har68] Hart, P.E., The condensed nearest neighbor rule, IEEE Trans. Information Theory 14 (1968) 515–516.

[Har72] Hartigan, J., Direct clustering of a data matrix, J. American Stat. Assoc. 67 (1972) 123–129.

[Har75] Hartigan, J.A., Clustering Algorithms. (1975) John Wiley & Sons .

[Hay99] Haykin, S.S., Neural Networks: A Comprehensive Foundation. (1999) Prentice-Hall .

[Hay08] Haykin, S., Neural Networks and Learning Machines. (2008) Prentice-Hall .

[HB87] Hanson, S.J.; Burr, D.J., Minkowski-r back-propagation: Learning in connectionist models with non-euclidian error signals, In: Neural Information Proc. Systems Conf. Denver, CO. (1987), pp. 348–357.

[HBV01] Halkidi, M.; Batistakis, Y.; Vazirgiannis, M., On clustering validation techniques, J. Intelligent Information Systems 17 (2001) 107–145.

[HCC93] Han, J.; Cai, Y.; Cercone, N., Data-driven discovery of quantitative rules in relational databases, IEEE Trans. Knowledge and Data Engineering 5 (1993) 29–40.

[HCD94] Holder, L.B.; Cook, D.J.; Djoko, S., Substructure discovery in the subdue system, In: Proc. AAAI’94 Workshop on Knowledge Discovery in Databases (KDD’94) Seattle, WA. (July 1994), pp. 169–180.

[Hec96] Heckerman, D., Bayesian networks for knowledge discovery, In: (Editors: Fayyad, U.M.; Piatetsky-Shapiro, G.; Smyth, P.; Uthurusamy, R.) Advances in Knowledge Discovery and Data Mining (1996) MIT Press, Cambridge, MA, pp. 273–305.

[HF94] Han, J.; Fu, Y., Dynamic generation and refinement of concept hierarchies for knowledge discovery in databases, In: Proc. AAAI’94 Workshop Knowledge Discovery in Databases (KDD’94) Seattle, WA. (July 1994), pp. 157–168.

[HF95] Han, J.; Fu, Y., Discovery of multiple-level association rules from large databases, In: Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95) Zurich, Switzerland. (Sept. 1995), pp. 420–431.

[HF96] Han, J.; Fu, Y., Exploration of the power of attribute-oriented induction in data mining, In: (Editors: Fayyad, U.M.; Piatetsky-Shapiro, G.; Smyth, P.; Uthurusamy, R.) Advances in Knowledge Discovery and Data Mining AAAI/MIT Press. (1996), pp. 399–421.

[HFLP01] Horn, P.S.; Feng, L.; Li, Y.; Pesce, A.J., Effect of outliers and nonhealthy individuals on reference interval estimation, Clinical Chemistry 47 (2001) 2137–2145.

[HG05] Heller, K.A.; Ghahramani, Z., Bayesian hierarchical clustering, In: Proc. 22nd Int. Conf. Machine Learning (ICML’05) Bonn, Germany. (2005), pp. 297–304.

[HG07] Hinneburg, A.; Gabriel, H.-H., DENCLUE 2.0: Fast clustering based on kernel density estimation, In: Proc. 2007 Int. Conf. Intelligent Data Analysis (IDA’07) Ljubljana, Slovenia. (2007), pp. 70–80.

[HGC95] Heckerman, D.; Geiger, D.; Chickering, D.M., Learning Bayesian networks: The combination of knowledge and statistical data, Machine Learning 20 (1995) 197–243.

[HH01] Hilderman, R.J.; Hamilton, H.J., Knowledge Discovery and Measures of Interest. (2001) Kluwer Academic .

[HHW97] Hellerstein, J.; Haas, P.; Wang, H., Online aggregation, In: Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97) Tucson, AZ. (May 1997), pp. 171–182.

[Hig08] Higgins, R.C., Analysis for Financial Management with S&P Bind-In Card. (2008) Irwin/McGraw-Hill .

[HK91] Hoschka, P.; Klösgen, W., A support system for interpreting statistical data, In: (Editors: Piatetsky-Shapiro, G.; Frawley, W.J.) Knowledge Discovery in Databases AAAI/MIT Press. (1991), pp. 325–346.

[HK98] Hinneburg, A.; Keim, D.A., An efficient approach to clustering in large multimedia databases with noise, In: Proc. 1998 Int. Conf. Knowledge Discovery and Data Mining (KDD’98) New York, NY. (Aug. 1998), pp. 58–65.

[HKGT03] Hadjieleftheriou, M.; Kollios, G.; Gunopulos, D.; Tsotras, V.J., Online discovery of dense areas in spatio-temporal databases, In: Proc. 2003 Int. Symp. Spatial and Temporal Databases (SSTD’03) Santorini Island, Greece. (July 2003), pp. 306–324.

[HKKR99] Höppner, F.; Klawonn, F.; Kruse, R.; Runkler, T., Fuzzy Cluster Analysis: Methods for Classification, Data Analysis and Image Recognition. (1999) Wiley .

[HKP91] Hertz, J.; Krogh, A.; Palmer, R.G., Introduction to the Theory of Neural Computation. (1991) Addison-Wesley, Reading, MA .

[HLW07] Hsu, W.; Lee, M.L.; Wang, J., Temporal and Spatio-Temporal Data Mining. (2007) IGI Publishing .

[HLZ02] Hsu, W.; Lee, M.L.; Zhang, J., Image mining: Trends and developments, J. Intelligent Information Systems 19 (2002) 7–23.

[HMM86] Hong, J.; Mozetic, I.; Michalski, R.S., Incremental learning of attribute-based descriptions from examples, the method and user's guide, In: Report ISG 85-5, UIUCDCS-F-86-949 Department of Computer Science, University of Illinois at Urbana-Champaign. (1986).

[HMS66] Hunt, E.B.; Marin, J.; Stone, P.T., Experiments in Induction. (1966) Academic Press .

[HMS01] Hand, D.J.; Mannila, H.; Smyth, P., Principles of Data Mining (Adaptive Computation and Machine Learning). (2001) MIT Press, Cambridge, MA .

[HN90] Hecht-Nielsen, R., Neurocomputing. (1990) Addison-Wesley, Reading, MA .

[Hor08] Horak, R., Telecommunications and Data Communications Handbook. 2nd ed. (2008) Wiley-Interscience .

[HP07] Hua, M.; Pei, J., Cleaning disguised missing data: A heuristic approach, In: Proc. 2007 ACM SIGKDD Intl. Conf. Knowledge Discovery and Data Mining (KDD’07) San Jose, CA. (Aug. 2007), pp. 950–958.

[HPDW01] Han, J.; Pei, J.; Dong, G.; Wang, K., Efficient computation of iceberg cubes with complex measures, In: Proc. 2001 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’01) Santa Barbara, CA. (May 2001), pp. 1–12.

[HPS97] Hosking, J.; Pednault, E.; Sudan, M., A statistical perspective on data mining, Future Generation Computer Systems 13 (1997) 117–134.

[HPY00] Han, J.; Pei, J.; Yin, Y., Mining frequent patterns without candidate generation, In: Proc. 2000 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’00) Dallas, TX. (May 2000), pp. 1–12.

[HRMS10] Hay, M.; Rastogi, V.; Miklau, G.; Suciu, D., Boosting the accuracy of differentially-private queries through consistency, In: Proc. 2010 Int. Conf. Very Large Data Bases (VLDB’10) Singapore. (Sept. 2010), pp. 1021–1032.

[HRU96] Harinarayan, V.; Rajaraman, A.; Ullman, J.D., Implementing data cubes efficiently, In: Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’96) Montreal, Quebec, Canada. (June 1996), pp. 205–216.

[HS05] Hellerstein, J.M.; Stonebraker, M., Readings in Database Systems. 4th ed. (2005) MIT Press, Cambridge, MA .

[HSG90] Harp, S.A.; Samad, T.; Guha, A., Designing application-specific neural networks using the genetic algorithm, In: (Editor: Touretzky, D.S.) Advances in Neural Information Processing Systems II Morgan Kaufmann. (1990), pp. 447–454.

[HT98] Hastie, T.; Tibshirani, R., Classification by pairwise coupling, Ann. Statistics 26 (1998) 451–471.

[HTF09] Hastie, T.; Tibshirani, R.; Friedman, J., The Elements of Statistical Learning: Data Mining, Inference, and Prediction. 2nd ed. (2009) Springer Verlag .

[Hua98] Huang, Z., Extensions to the k-means algorithm for clustering large data sets with categorical values, Data Mining and Knowledge Discovery 2 (1998) 283–304.

[Hub94] Huberty, C.H., Applied Discriminant Analysis. (1994) Wiley-Interscience .

[Hub96] Hubbard, B.B., The World According to Wavelets. (1996) A. K. Peters .

[HWB+04] Huan, J.; Wang, W.; Bandyopadhyay, D.; Snoeyink, J.; Prins, J.; Tropsha, A., Mining spatial motifs from protein structure graphs, In: Proc. 8th Int. Conf. Research in Computational Molecular Biology (RECOMB) San Diego, CA. (Mar. 2004), pp. 308–315.

[HXD03] He, Z.; Xu, X.; Deng, S., Discovering cluster-based local outliers, Pattern Recognition Lett. 24 (June, 2003) 1641–1650.

[IGG03] Imhoff, C.; Galemmo, N.; Geiger, J.G., Mastering Data Warehouse Design: Relational and Dimensional Techniques. (2003) John Wiley & Sons .

[IKA02] Imielinski, T.; Khachiyan, L.; Abdulghani, A., Cubegrades: Generalizing association rules, Data Mining and Knowledge Discovery 6 (2002) 219–258.

[IM96] Imielinski, T.; Mannila, H., A database perspective on knowledge discovery, Communications of the ACM 39 (1996) 58–64.

[Inm96] Inmon, W.H., Building the Data Warehouse. (1996) John Wiley & Sons .

[IWM98] Inokuchi, A.; Washio, T.; Motoda, H., An apriori-based algorithm for mining frequent substructures from graph data, In: Proc. 2000 European Symp. Principles of Data Mining and Knowledge Discovery (PKDD’00) Lyon, France. (Sept. 1998), pp. 13–23.

[Jac88] Jacobs, R., Increased rates of convergence through learning rate adaptation, Neural Networks 1 (1988) 295–307.

[Jai10] Jain, A.K., Data clustering: 50 years beyond k-means, Pattern Recognition Lett. 31 (8) (2010) 651–666.

[Jam85] James, M., Classification Algorithms. (1985) John Wiley & Sons .

[JBD05] Ji, X.; Bailey, J.; Dong, G., Mining minimal distinguishing subsequence patterns with gap constraints, In: Proc. 2005 Int. Conf. Data Mining (ICDM’05) Houston, TX. (Nov. 2005), pp. 194–201.

[JD88] Jain, A.K.; Dubes, R.C., Algorithms for Clustering Data. (1988) Prentice-Hall .

[Jen96] Jensen, F.V., An Introduction to Bayesian Networks. (1996) Springer Verlag .

[JL96] John, G.H.; Langley, P., Static versus dynamic sampling for data mining, In: Proc. 1996 Int. Conf. Knowledge Discovery and Data Mining (KDD’96) Portland, OR. (Aug. 1996), pp. 367–370.

[JMF99] Jain, A.K.; Murty, M.N.; Flynn, P.J., Data clustering: A survey, ACM Computing Surveys 31 (1999) 264–323.

[Joh97]

[Joh99] John, G.H., Behind-the-scenes data mining: A report on the KDD-98 panel, SIGKDD Explorations 1 (1999) 6–8.

[JP04] Jones, N.C.; Pevzner, P.A., An Introduction to Bioinformatics Algorithms. (2004) MIT Press, Cambridge, MA .

[JSD+10] Ji, M.; Sun, Y.; Danilevsky, M.; Han, J.; Gao, J., Graph regularized transductive classification on heterogeneous information networks, In: Proc. 2010 European Conf. Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD’10) Barcelona, Spain. (Sept. 2010), pp. 570–586.

[JTH01] Jin, W.; Tung, K.H.; Han, J., Mining top-n local outliers in large databases, In: Proc. 2001 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’01) San Fransisco, CA. (Aug. 2001), pp. 293–298.

[JTHW06] Jin, W.; Tung, A.K.H.; Han, J.; Wang, W., Ranking outliers using symmetric neighborhood relationship, In: Proc. 2006 Pacific-Asia Conf. Knowledge Discovery and Data Mining (PAKDD’06) Singapore. (Apr. 2006).

[JW92] Johnson, R.A.; Wichern, D.A., Applied Multivariate Statistical Analysis. 3rd ed. (1992) Prentice-Hall .

[JW02a] Jeh, G.; Widom, J., SimRank: A measure of structural-context similarity, In: Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’02) Edmonton, Alberta, Canada. (July 2002), pp. 538–543.

[JW02b] Johnson, R.A.; Wichern, D.A., Applied Multivariate Statistical Analysis. 5th ed. (2002) Prentice Hall .

[Kam09] Kamath, C., Scientific Data Mining: A Practical Perspective. (2009) Society for Industrial and Applied Mathematic (SIAM) .

[Kas80] Kass, G.V., An exploratory technique for investigating large quantities of categorical data, Applied Statistics 29 (1980) 119–127.

[KBDM09] Kulis, B.; Basu, S.; Dhillon, I.; Mooney, R., Semi-supervised graph clustering: A kernel approach, Machine Learning 74 (2009) 1–22.

[Kec01] Kecman, V., Learning and Soft Computing. (2001) MIT Press, Cambridge, MA .

[Kei97] Keim, D.A., Visual techniques for exploring databases, In: Tutorial Notes, 3rd Int. Conf. Knowledge Discovery and Data Mining (KDD’97) Newport Beach, CA. (Aug. 1997).

[Ker92] Kerber, R., ChiMerge: Discretization of numeric attributes, In: Proc. 1992 Nat. Conf. Artificial Intelligence (AAAI’92) San Jose, CA. (1992), pp. 123–128.

[KF09] Koller, D.; Friedman, N., Probabilistic Graphical Models: Principles and Techniques. (2009) MIT Press, Cambridge, MA .

[KH95] Koperski, K.; Han, J., Discovery of spatial association rules in geographic information databases, In: Proc. 1995 Int. Symp. Large Spatial Databases (SSD’95) Portland, ME. (Aug. 1995), pp. 47–66.

[KH97] Kononenko, I.; Hong, S.J., Attribute selection for modeling, Future Generation Computer Systems 13 (1997) 181–195.

[KH09] Kim, M.-S.; Han, J., A particle-and-density based evolutionary clustering method for dynamic networks, In: Proc. 2009 Int. Conf. Very Large Data Bases (VLDB’09) Lyon, France. (Aug. 2009).

[KHC97] Kamber, M.; Han, J.; Chiang, J.Y., Metarule-guided mining of multi-dimensional association rules using data cubes, In: Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97) Newport Beach, CA. (Aug. 1997), pp. 207–210.

[KHK99] Karypis, G.; Han, E.-H.; Kumar, V., CHAMELEON: A hierarchical clustering algorithm using dynamic modeling, COMPUTER 32 (1999) 68–75.

[KHY+08] Kargupta, H.; Han, J.; Yu, P.S.; Motwani, R.; Kumar, V., Next Generation of Data Mining. (2008) Chapman & Hall/CRC .

[KJ97] Kohavi, R.; John, G.H., Wrappers for feature subset selection, Artificial Intelligence 97 (1997) 273–324.

[KJSY04] Kargupta, H.; Joshi, A.; Sivakumar, K.; Yesha, Y., Data Mining: Next Generation Challenges and Future Directions. (2004) AAAI/MIT Press, Cambridge, MA .

[KK01] Kuramochi, M.; Karypis, G., Frequent subgraph discovery, In: Proc. 2001 Int. Conf. Data Mining (ICDM’01) San Jose, CA. (Nov. 2001), pp. 313–320.

[KKW+10] Kim, H.S.; Kim, S.; Weninger, T.; Han, J.; Abdelzaher, T., NDPMine: Efficiently mining discriminative numerical features for pattern-based classification, In: Proc. 2010 European Conf. Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD’10) Barcelona, Spain. (Sept. 2010).

[KKZ09] Kriegel, H.-P.; Kroeger, P.; Zimek, A., Clustering high-dimensional data: A survey on subspace clustering, pattern-based clustering, and correlation clustering, ACM Trans. Knowledge Discovery from Data (TKDD) 3 (1) (2009) 1–58.

[KLA+08] Khan, M.; Le, H.; Ahmadi, H.; Abdelzaher, T.; Han, J., DustMiner: Troubleshooting interactive complexity bugs in sensor networks, In: Proc. 2008 ACM Int. Conf. Embedded Networked Sensor Systems (SenSys’08) Raleigh, NC. (Nov. 2008), pp. 99–112.

[Kle99] Kleinberg, J.M., Authoritative sources in a hyperlinked environment, J. ACM 46 (1999) 604–632.

[KLV+98] Kennedy, R.L.; Lee, Y.; Van Roy, B.; Reed, C.D.; Lippman, R.P., Solving Data Mining Problems Through Pattern Recognition. (1998) Prentice-Hall .

[KM90] Kodratoff, Y.; Michalski, R.S., Machine Learning, An Artificial Intelligence Approach. (1990) Morgan Kaufmann ; Vol. 3.

[KM94] Kivinen, J.; Mannila, H., The power of sampling in knowledge discovery, In: Proc. 13th ACM Symp. Principles of Database Systems Minneapolis, MN. (May 1994), pp. 77–85.

[KMN+02] Kanungo, T.; Mount, D.M.; Netanyahu, N.S.; Piatko, C.D.; Silverman, R.; Wu, A.Y., An efficient k-means clustering algorithm: Analysis and implementation, IEEE Trans. Pattern Analysis and Machine Intelligence (PAMI) 24 (2002) 881–892.

[KMR+94] Klemettinen, M.; Mannila, H.; Ronkainen, P.; Toivonen, H.; Verkamo, A.I., Finding interesting rules from large sets of discovered association rules, In: Proc. 3rd Int. Conf. Information and Knowledge Management Gaithersburg, MD. (Nov. 1994), pp. 401–408.

[KMS03] Kubica, J.; Moore, A.; Schneider, J., Tractable group detection on large link data sets, In: Proc. 2003 Int. Conf. Data Mining (ICDM’03) Melbourne, FL. (Nov. 2003), pp. 573–576.

[KN97] Knorr, E.; Ng, R., A unified notion of outliers: Properties and computation, In: Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97) Newport Beach, CA. (Aug. 1997), pp. 219–222.

[KNNL04] Kutner, M.H.; Nachtsheim, C.J.; Neter, J.; Li, W., Applied Linear Statistical Models with Student CD. (2004) Irwin .

[KNT00] Knorr, E.M.; Ng, R.T.; Tucakov, V., Distance-based outliers: Algorithms and applications, The VLDB J. 8 (2000) 237–253.

[Koh95] Kohavi, R., A study of cross-validation and bootstrap for accuracy estimation and model selection, In: Proc. 14th Joint Int. Conf. Artificial Intelligence (IJCAI’95), Vol. 2 (Aug. 1995) Montreal, Quebec, Canada, pp. 1137–1143.

[Kol93] Kolodner, J.L., Case-Based Reasoning. (1993) Morgan Kaufmann .

[Kon95] Kononenko, I., On biases in estimating multi-valued attributes, In: Proc. 14th Joint Int. Conf. Artificial Intelligence (IJCAI’95), Vol. 2 (Aug. 1995) Montreal, Quebec, Canada, pp. 1034–1040.

[Kot88] Koton, P., Reasoning about evidence in causal explanation, In: Proc. 7th Nat. Conf. Artificial Intelligence (AAAI’88) St. Paul, MN. (Aug. 1988), pp. 256–263.

[KPR98] Kleinberg, J.M.; Papadimitriou, C.; Raghavan, P., A microeconomic view of data mining, Data Mining and Knowledge Discovery 2 (1998) 311–324.

[KPS03] Karp, R.M.; Papadimitriou, C.H.; Shenker, S., A simple algorithm for finding frequent elements in streams and bags, ACM Trans. Database Systems 28 (2003) 51–55.

[KR90] Kaufman, L.; Rousseeuw, P.J., Finding Groups in Data: An Introduction to Cluster Analysis. (1990) John Wiley & Sons .

[KR02] Kimball, R.; Ross, M., The Data Warehouse Toolkit: The Complete Guide to Dimensional Modeling. 2nd ed. (2002) John Wiley & Sons .

[KR03] Krane, D.; Raymer, R., Fundamental Concepts of Bioinformatics. (2003) Benjamin Cummings .

[Kre02] Krebs, V., Mapping networks of terrorist cells, Connections 24 (2002) 43–52; (Winter).

[KRR+00] Kumar, R.; Raghavan, P.; Rajagopalan, S.; Sivakumar, D.; Tomkins, A.; Upfal, E., Stochastic models for the web graph, In: Proc. 2000 IEEE Symp. Foundations of Computer Science (FOCS’00) Redondo Beach, CA. (Nov. 2000), pp. 57–65.

[KRTM08] Kimball, R.; Ross, M.; Thornthwaite, W.; Mundy, J., The Data Warehouse Lifecycle Toolkit. (2008) John Wiley & Sons, Hoboken, NJ .

[KSZ08] Kriegel, H.-P.; Schubert, M.; Zimek, A., Angle-based outlier detection in high-dimensional data, In: Proc. 2008 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’08) Las Vegas, NV. (Aug. 2008), pp. 444–452.

[KT99] Kleinberg, J.M.; Tomkins, A., Application of linear algebra in information retrieval and hypertext analysis, In: Proc. 18th ACM Symp. Principles of Database Systems (PODS’99) Philadelphia, PA. (May 1999), pp. 185–193.

[KYB03] Korf, I.; Yandell, M.; Bedell, J., BLAST. (2003) O’Reilly Media, Sebastopol, CA .

[Lam98] Lam, W., Bayesian network refinement via machine learning approach, IEEE Trans. Pattern Analysis and Machine Intelligence 20 (1998) 240–252.

[Lau95] Lauritzen, S.L., The EM algorithm for graphical association models with missing data, Computational Statistics and Data Analysis 19 (1995) 191–201.

[LCH+09] Lo, D.; Cheng, H.; Han, J.; Khoo, S.; Sun, C., Classification of software behaviors for failure detection: A discriminative pattern mining approach, In: Proc. 2009 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’09) Paris, France. (June 2009), pp. 557–566.

[LDH+08] Lin, C.X.; Ding, B.; Han, J.; Zhu, F.; Zhao, B., Text cube: Computing IR measures for multidimensional text database analysis, In: Proc. 2008 Int. Conf. Data Mining (ICDM’08) Pisa, Italy. (Dec. 2008), pp. 905–910.

[LDH+10] Li, Z.; Ding, B.; Han, J.; Kays, R.; Nye, P., Mining periodic behaviors for moving objects, In: Proc. 2010 ACM SIGKDD Conf. Knowledge Discovery and Data Mining (KDD’10) Washington, DC. (July 2010), pp. 1099–1108.

[LDR00] Li, J.; Dong, G.; Ramamohanrarao, K., Making use of the most expressive jumping emerging patterns for classification, In: Proc. 2000 Pacific-Asia Conf. Knowledge Discovery and Data Mining (PAKDD’00) Kyoto, Japan. (Apr. 2000), pp. 220–232.

[LDS90] Le Cun, Y.; Denker, J.S.; Solla, S.A., Optimal brain damage, In: (Editor: Touretzky, D.) Advances in Neural Information Processing Systems Morgan Kaufmann. (1990).

[Lea96] Leake, D.B., CBR in context: The present and future, In: (Editor: Leake, D.B.) Cased-Based Reasoning: Experiences, Lessons, and Future Directions AAAI Press. (1996), pp. 3–30.

[LGT97] Lawrence, S.; Giles, C.L.; Tsoi, A.C., Symbolic conversion, grammatical inference and rule extraction for foreign exchange rate prediction, In: (Editors: Abu-Mostafa, Y.; Weigend, A.S.; Refenes, P.N.) Neural Networks in the Capital Markets (1997) World Scientific, London.

[LHC97] Liu, B.; Hsu, W.; Chen, S., Using general impressions to analyze discovered classification rules, In: Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97) Newport Beach, CA. (Aug. 1997), pp. 31–36.

[LHF98] Lu, H.; Han, J.; Feng, L., Stock movement and n-dimensional inter-transaction association rules, In: Proc. 1998 SIGMOD Workshop Research Issues on Data Mining and Knowledge Discovery (DMKD’98) Seattle, WA. (June 1998), pp. 12:1–12:7.

[LHG04] Li, X.; Han, J.; Gonzalez, H., High-dimensional OLAP: A minimal cubing approach, In: Proc. 2004 Int. Conf. Very Large Data Bases (VLDB’04) Toronto, Ontario, Canada. (Aug. 2004), pp. 528–539.

[LHKG07] Li, X.; Han, J.; Kim, S.; Gonzalez, H., Roam: Rule- and motif-based anomaly detection in massive moving object data sets, In: Proc. 2007 SIAM Int. Conf. Data Mining (SDM’07) Minneapolis, MN. (Apr. 2007).

[LHM98] Liu, B.; Hsu, W.; Ma, Y., Integrating classification and association rule mining, In: Proc. 1998 Int. Conf. Knowledge Discovery and Data Mining (KDD’98) New York. (Aug. 1998), pp. 80–86.

[LHP01] Li, W.; Han, J.; Pei, J., CMAR: Accurate and efficient classification based on multiple class-association rules, In: Proc. 2001 Int. Conf. Data Mining (ICDM’01) San Jose, CA. (Nov. 2001), pp. 369–376.

[LHTD02] Liu, H.; Hussain, F.; Tan, C.L.; Dash, M., Discretization: An enabling technique, Data Mining and Knowledge Discovery 6 (2002) 393–423.

[LHW07] Lee, J.-G.; Han, J.; Whang, K., Clustering trajectory data, In: Proc. 2007 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’07) Beijing, China. (June 2007).

[LHXS06] Liu, H.; Han, J.; Xin, D.; Shao, Z., Mining frequent patterns on very high dimensional data: A top-down row enumeration approach, In: Proc. 2006 SIAM Int. Conf. Data Mining (SDM’06) Bethesda, MD. (Apr. 2006).

[LHY+08] Li, X.; Han, J.; Yin, Z.; Lee, J.-G.; Sun, Y., Sampling Cube: A framework for statistical OLAP over sampling data, In: Proc. 2008 ACM SIGMOD Int. Conf. Management of Data (SIGMOD’08) Vancouver, British Columbia, Canada. (June 2008), pp. 779–790.

[Liu06] Liu, B., Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data. (2006) Springer, New York .

[LJK00] Laurikkala, J.; Juhola, M.; Kentala, E., Informal identification of outliers in medical data, In: Proc. 5th Int. Workshop on Intelligent Data Analysis in Medicine and Pharmacology Berlin, Germany. (Aug. 2000).

[LKCH03] Lee, Y.-K.; Kim, W.-Y.; Cai, Y.D.; Han, J., CoMine: Efficient mining of correlated patterns, In: Proc. 2003 Int. Conf. Data Mining (ICDM’03) Melbourne, FL. (Nov. 2003), pp. 581–584.

[LKF05] Leskovec, J.; Kleinberg, J.; Faloutsos, C., Graphs over time: Densification laws, shrinking diameters and possible explanations, In: Proc. 2005 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’05) Chicago, IL. (Aug. 2005), pp. 177–187.

[LLLY03] Liu, G.; Lu, H.; Lou, W.; Yu, J.X., On computing, storing and querying frequent patterns, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 607–612.

[LLMZ04] Li, Z.; Lu, S.; Myagmar, S.; Zhou, Y., CP-Miner: A tool for finding copy-paste and related bugs in operating system code, In: Proc. 2004 Symp. Operating Systems Design and Implementation (OSDI’04) San Francisco, CA. (Dec. 2004), pp. 20–22.

[Llo57] Lloyd, S.P., Least squares quantization in PCM, IEEE Trans. Information Theory 28 (1982) 128–137; (original version: Technical Report, Bell Labs, 1957).

[LLS00] Lim, T.-S.; Loh, W.-Y.; Shih, Y.-S., A comparison of prediction accuracy, complexity, and training time of thirty-three old and new classification algorithms, Machine Learning 40 (2000) 203–228.

[LM97] Laskey, K.; Mahoney, S., Network fragments: Representing knowledge for constructing probabilistic models, In: Proc. 13th Annual Conf. Uncertainty in Artificial Intelligence San Francisco, CA. (Aug. 1997), pp. 334–341.

[LM98a] Liu, H.; Motoda, H., Feature Selection for Knowledge Discovery and Data Mining. (1998) Kluwer Academic .

[LM98b] In: (Editors: Liu, H.; Motoda, H.) Feature Extraction, Construction, and Selection: A Data Mining Perspective (1998) Kluwer Academic.

[LNHP99] Lakshmanan, L.V.S.; Ng, R.; Han, J.; Pang, A., Optimization of constrained frequent set queries with 2-variable constraints, In: Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99) Philadelphia, PA. (June 1999), pp. 157–168.

[L-NK03] Liben-Nowell, D.; Kleinberg, J., The link prediction problem for social networks, In: Proc. 2003 Int. Conf. Information and Knowledge Management (CIKM’03) New Orleans, LA. (Nov. 2003), pp. 556–559.

[Los01] Loshin, D., Enterprise Knowledge Management: The Data Quality Approach. (2001) Morgan Kaufmann .

[LP97] Lenarcik, A.; Piasta, Z., Probabilistic rough classifiers with mixture of discrete and continuous variables, In: (Editors: Lin, T.Y.; Cercone, N.) Rough Sets and Data Mining: Analysis for Imprecise Data (1997) Kluwer Academic, pp. 373–383.

[LPH02] Lakshmanan, L.V.S.; Pei, J.; Han, J., Quotient cube: How to summarize the semantics of a data cube, In: Proc. 2002 Int. Conf. Very Large Data Bases (VLDB’02) Hong Kong, China. (Aug. 2002), pp. 778–789.

[LPWH02] Liu, J.; Pan, Y.; Wang, K.; Han, J., Mining frequent itemsets by opportunistic projection, In: Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’02) Edmonton, Alberta, Canada. (July 2002), pp. 239–248.

[LPZ03] Lakshmanan, L.V.S.; Pei, J.; Zhao, Y., QC-Trees: An efficient summary structure for semantic OLAP, In: Proc. 2003 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’03) San Diego, CA. (June 2003), pp. 64–75.

[LS95] Liu, H.; Setiono, R., Chi2: Feature selection and discretization of numeric attributes, In: Proc. 1995 IEEE Int. Conf. Tools with AI (ICTAI’95) Washington, DC. (Nov. 1995), pp. 388–391.

[LS97] Loh, W.Y.; Shih, Y.S., Split selection methods for classification trees, Statistica Sinica 7 (1997) 815–840.

[LSBZ87] Langley, P.; Simon, H.A.; Bradshaw, G.L.; Zytkow, J.M., Scientific Discovery: Computational Explorations of the Creative Processes. (1987) MIT Press, Cambridge, MA .

[LSL95] Lu, H.; Setiono, R.; Liu, H., Neurorule: A connectionist approach to data mining, In: Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95) Zurich, Switzerland. (Sept. 1995), pp. 478–489.

[LSW97] Lent, B.; Swami, A.; Widom, J., Clustering association rules, In: Proc. 1997 Int. Conf. Data Engineering (ICDE’97) Birmingham, England. (Apr. 1997), pp. 220–231.

[Lux07] Luxburg, U., A tutorial on spectral clustering, Statistics and Computing 17 (2007) 395–416.

[LV88] Loh, W.Y.; Vanichsetakul, N., Tree-structured classificaiton via generalized discriminant analysis, J. American Statistical Association 83 (1988) 715–728.

[LZ05] Li, Z.; Zhou, Y., PR-Miner: Automatically extracting implicit programming rules and detecting violations in large software code, In: Proc. 2005 ACM SIGSOFT Symp. Foundations of Software Engineering (FSE’05) Lisbon, Portugal. (Sept. 2005).

[MA03] Mitra, S.; Acharya, T., Data Mining: Multimedia, Soft Computing, and Bioinformatics. (2003) John Wiley & Sons .

[MAE05] Metwally, A.; Agrawal, D.; El Abbadi, A., Efficient computation of frequent and top-k elements in data streams, In: Proc. 2005 Int. Conf. Database Theory (ICDT’05) Edinburgh, Scotland. (Jan. 2005), pp. 398–412.

[Mac67] MacQueen, J., Some methods for classification and analysis of multivariate observations, Berkeley, CA. Proc. 5th Berkeley Symp. Math. Stat. Prob. 1 (1967) 281–297.

[Mag94] Magidson, J., The CHAID approach to segmentation modeling: CHI-squared automatic interaction detection, In: (Editor: Bagozzi, R.P.) Advanced Methods of Marketing Research (1994) Blackwell Business, pp. 118–159.

[Man00] Mannila, H., Theoretical frameworks of data mining, SIGKDD Explorations 1 (2000) 30–32.

[MAR96] Mehta, M.; Agrawal, R.; Rissanen, J., SLIQ: A fast scalable classifier for data mining, In: Proc. 1996 Int. Conf. Extending Database Technology (EDBT’96) Avignon, France. (Mar. 1996), pp. 18–32.

[Mar09] Marsland, S., Machine Learning: An Algorithmic Perspective. (2009) Chapman & Hall/CRC .

[MB88] McLachlan, G.J.; Basford, K.E., Mixture Models: Inference and Applications to Clustering. (1988) John Wiley & Sons .

[MC03] Mahoney, M.V.; Chan, P.K., Learning rules for anomaly detection of hostile network traffic, In: Proc. 2003 Int. Conf. Data Mining (ICDM’03) Melbourne, FL. (Nov. 2003).

[MCK+04] Mamoulis, N.; Cao, H.; Kollios, G.; Hadjieleftheriou, M.; Tao, Y.; Cheung, D., Mining, indexing, and querying historical spatiotemporal data, In: Proc. 2004 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’04) Seattle, WA. (Aug. 2004), pp. 236–245.

[MCM83] Michalski, R.S.; Carbonell, J.G.; Mitchell, T.M., Machine Learning, An Artificial Intelligence Approach. (1983) Morgan Kaufmann ; Vol. 1.

[MCM86] Michalski, R.S.; Carbonell, J.G.; Mitchell, T.M., Machine Learning, An Artificial Intelligence Approach. (1986) Morgan Kaufmann ; Vol. 2.

[MD88] Muralikrishna, M.; DeWitt, D.J., Equi-depth histograms for extimating selectivity factors for multi-dimensional queries, In: Proc. 1988 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’88) Chicago, IL. (June 1988), pp. 28–36.

[Mei03] Meilǎ, M., Comparing clusterings by the variation of information, In: Proc. 16th Annual Conf. Computational Learning Theory (COLT’03) Washington, DC. (Aug. 2003), pp. 173–187.

[Mei05] Meilǎ, M., Comparing clusterings: An axiomatic view, In: Proc. 22nd Int. Conf. Machine Learning (ICML’05) Bonn, Germany. (2005), pp. 577–584.

[Men03] Mena, J., Investigative Data Mining with Security and Criminal Detection. (2003) Butterworth-Heinemann .

[MFS95] Malerba, D.; Floriana, E.; Semeraro, G., A further comparison of simplification methods for decision tree induction, In: (Editors: Fisher, D.; Lenz, H.) Learning from Data: AI and Statistics (1995) Springer Verlag.

[MH95] Martin, J.K.; Hirschberg, D.S., The time complexity of decision tree induction, In: Technical Report ICS-TR 95-27 Department of Information and Computer Science, University of California, Irvine, CA. (Aug. 1995), pp. 1–27.

[MH09] Miller, H.; Han, J., Geographic Data Mining and Knowledge Discovery. 2nd ed. (2009) Chapman & Hall/CRC .

[Mic83] Michalski, R.S., A theory and methodology of inductive learning, In: (Editors: Michalski, R.S.; Carbonell, J.G.; Mitchell, T.M.) Machine Learning: An Artificial Intelligence Approach, Vol. 1 (1983) Morgan Kaufmann, pp. 83–134.

[Mic92] Michalewicz, Z., Genetic Algorithms + Data Structures = Evolution Programs. (1992) Springer Verlag .

[Mil98] Miller, R.G., Survival Analysis. (1998) Wiley-Interscience .

[Min89] Mingers, J., An empirical comparison of pruning methods for decision-tree induction, Machine Learning 4 (1989) 227–243.

[Mir98] Mirkin, B., Mathematical classification and clustering, J. Global Optimization 12 (1998) 105–108.

[Mit96] Mitchell, M., An Introduction to Genetic Algorithms. (1996) MIT Press, Cambridge, MA .

[Mit97] Mitchell, T.M., Machine Learning. (1997) McGraw-Hill .

[MK91] Manago, M.; Kodratoff, Y., Induction of decision trees from complex structured data, In: (Editors: Piatetsky-Shapiro, G.; Frawley, W.J.) Knowledge Discovery in Databases (1991) AAAI/MIT Press, pp. 289–306.

[MLSZ06] Mei, Q.; Liu, C.; Su, H.; Zhai, C., A probabilistic approach to spatiotemporal theme pattern mining on weblogs, In: Proc. 15th Int. Conf. World Wide Web (WWW’06) Edinburgh, Scotland. (May 2006), pp. 533–542.

[MM95] Major, J.; Mangano, J., Selecting among rules induced from a hurricane database, J. Intelligent Information Systems 4 (1995) 39–52.

[MM02] Manku, G.; Motwani, R., Approximate frequency counts over data streams, In: Proc. 2002 Int. Conf. Very Large Data Bases (VLDB’02) Hong Kong, China. (Aug. 2002), pp. 346–357.

[MN89] Mézard, M.; Nadal, J.-P., Learning in feedforward layered networks: The tiling algorithm, J. Physics 22 (1989) 2191–2204.

[MO04] Madeira, S.C.; Oliveira, A.L., Biclustering algorithms for biological data analysis: A survey, IEEE/ACM Trans. Computational Biology and Bioinformatics 1 (1) (2004) 24–25.

[MP69] Minsky, M.L.; Papert, S., Perceptrons: An Introduction to Computational Geometry. (1969) MIT Press, Cambridge, MA .

[MRA95] Metha, M.; Rissanen, J.; Agrawal, R., MDL-based decision tree pruning, In: Proc. 1995 Int. Conf. Knowledge Discovery and Data Mining (KDD’95) Montreal, Quebec, Canada. (Aug. 1995), pp. 216–221.

[MRS08] Manning, C.D.; Raghavan, P.; Schutze, H., Introduction to Information Retrieval. (2008) Cambridge University Press .

[MS03a] Markou, M.; Singh, S., Novelty detection: A review—part 1: Statistical approaches, Signal Processing 83 (2003) 2481–2497.

[MS03b] Markou, M.; Singh, S., Novelty detection: A review—part 2: Neural network based approaches, Signal Processing 83 (2003) 2499–2521.

[MST94] Michie, D.; Spiegelhalter, D.J.; Taylor, C.C., Machine Learning, Neural and Statistical Classification. (1994) Ellis Horwood, Chichester, England .

[MT94] Michalski, R.S.; Tecuci, G., Machine Learning, A Multistrategy Approach. (1994) Morgan Kaufmann ; Vol. 4.

[MTV94] Mannila, H.; Toivonen, H.; Verkamo, A.I., Efficient algorithms for discovering association rules, In: Proc. AAAI’94 Workshop Knowledge Discovery in Databases (KDD’94) Seattle, WA. (July 1994), pp. 181–192.

[MTV97] Mannila, H.; Toivonen, H.; Verkamo, A.I., Discovery of frequent episodes in event sequences, Data Mining and Knowledge Discovery 1 (1997) 259–289.

[Mur98] Murthy, S.K., Automatic construction of decision trees from data: A multi-disciplinary survey, Data Mining and Knowledge Discovery 2 (1998) 345–389.

[Mut05]

[MXC+07] Mei, Q.; Xin, D.; Cheng, H.; Han, J.; Zhai, C., Semantic annotation of frequent patterns, ACM Trans. Knowledge Discovery from Data (TKDD) 15 (2007) 321–348.

[MY97] Miller, R.J.; Yang, Y., Association rules over interval data, In: Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97) Tucson, AZ. (May 1997), pp. 452–461.

[MZ06] Mei, Q.; Zhai, C., A mixture model for contextual text mining, In: Proc. 2006 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’06) Philadelphia, PA. (Aug. 2006), pp. 649–655.

[NB86] Niblett, T.; Bratko, I., Learning decision rules in noisy domains, In: (Editor: Brammer, M.A.) Expert Systems ’86: Research and Development in Expert Systems III (Dec. 1986) British Computer Society Specialist Group on Expert Systems, pp. 25–34.

[NBW06] Newman, M.; Barabasi, A.-L.; Watts, D.J., The Structure and Dynamics of Networks. (2006) Princeton University Press .

[NC03] Noble, C.C.; Cook, D.J., Graph-based anomaly detection, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 631–636.

[New10] Newman, M., Networks: An Introduction. (2010) Oxford University Press .

[NG04] Newman, M.E.J.; Girvan, M., Finding and evaluating community structure in networks, Physical Rev. E 69 (2004) 113–128.

[NGE-R09] Neville, J.; Gallaher, B.; Eliassi-Rad, T., Evaluating statistical tests for within-network classifiers of relational data, In: Proc. 2009 Int. Conf. Data Mining (ICDM’09) Miami, FL. (Dec. 2009), pp. 397–406.

[NH94] Ng, R.; Han, J., Efficient and effective clustering method for spatial data mining, In: Proc. 1994 Int. Conf. Very Large Data Bases (VLDB’94) Santiago, Chile. (Sept. 1994), pp. 144–155.

[NJW01] Ng, A.Y.; Jordan, M.I.; Weiss, Y., On spectral clustering: Analysis and an algorithm, In: (Editors: Dietterich, T.G.; Becker, S.; Ghahramani, Z.) Advances in Neural Information Processing Systems 14 (2001) MIT Press, Cambridge, MA, pp. 849–856.

[NK04] Nijssen, S.; Kok, J., A quick start in frequent structure mining can make a difference, In: Proc. 2004 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’04) Seattle, WA. (Aug. 2004), pp. 647–652.

[NKNW96] Neter, J.; Kutner, M.H.; Nachtsheim, C.J.; Wasserman, L., Applied Linear Statistical Models. 4th ed. (1996) Irwin .

[NLHP98] Ng, R.; Lakshmanan, L.V.S.; Han, J.; Pang, A., Exploratory mining and pruning optimizations of constrained associations rules, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 13–24.

[NRS99] Natsev, A.; Rastogi, R.; Shim, K., Walrus: A similarity retrieval algorithm for image databases, In: Proc. 1999 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’99) Philadelphia, PA. (June 1999), pp. 395–406.

[NW99] Nocedal, J.; Wright, S.J., Numerical Optimization. (1999) Springer Verlag .

[OFG97] Osuna, E.; Freund, R.; Girosi, F., An improved training algorithm for support vector machines, In: Proc. 1997 IEEE Workshop Neural Networks for Signal Processing (NNSP’97) Amelia Island, FL. (Sept. 1997), pp. 276–285.

[OG95] O’Neil, P.; Graefe, G., Multi-table joins through bitmapped join indices, SIGMOD Record 24 (Sept. 1995) 8–11.

[Ols03] Olson, J.E., Data Quality: The Accuracy Dimension. (2003) Morgan Kaufmann .

[Omi03] Omiecinski, E., Alternative interest measures for mining associations, IEEE Trans. Knowledge and Data Engineering 15 (2003) 57–69.

[OMM+02] O’Callaghan, L.; Meyerson, A.; Motwani, R.; Mishra, N.; Guha, S., Streaming-data algorithms for high-quality clustering, In: Proc. 2002 Int. Conf. Data Engineering (ICDE’02) San Fransisco, CA. (Apr. 2002), pp. 685–696.

[OQ97] O’Neil, P.; Quass, D., Improved query performance with variant indexes, In: Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97) Tucson, AZ. (May 1997), pp. 38–49.

[ORS98] Özden, B.; Ramaswamy, S.; Silberschatz, A., Cyclic association rules, In: Proc. 1998 Int. Conf. Data Engineering (ICDE’98) Orlando, FL. (Feb. 1998), pp. 412–421.

[Pag89] Pagallo, G., Learning DNF by decision trees, In: Proc. 1989 Int. Joint Conf. Artificial Intelligence (IJCAI’89) San Francisco, CA. (1989), pp. 639–644.

[Paw91] Pawlak, Z., Rough Sets, Theoretical Aspects of Reasoning about Data. (1991) Kluwer Academic .

[PB00] Pinheiro, J.C.; Bates, D.M., Mixed Effects Models in S and S-PLUS. (2000) Springer Verlag .

[PBTL99] Pasquier, N.; Bastide, Y.; Taouil, R.; Lakhal, L., Discovering frequent closed itemsets for association rules, In: Proc. 7th Int. Conf. Database Theory (ICDT’99) Jerusalem, Israel. (Jan. 1999), pp. 398–416.

[PCT+03] Pan, F.; Cong, G.; Tung, A.K.H.; Yang, J.; Zaki, M., CARPENTER: Finding closed patterns in long biological datasets, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 637–642.

[PCY95a] Park, J.S.; Chen, M.S.; Yu, P.S., An effective hash-based algorithm for mining association rules, In: Proc. 1995 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’95) San Jose, CA. (May 1995), pp. 175–186.

[PCY95b] Park, J.S.; Chen, M.S.; Yu, P.S., Efficient parallel mining for association rules, In: Proc. 4th Int. Conf. Information and Knowledge Management Baltimore, MD. (Nov. 1995), pp. 31–36.

[Pea88] Pearl, J., Probabilistic Reasoning in Intelligent Systems. (1988) Morgan Kaufmann .

[PHL01] Pei, J.; Han, J.; Lakshmanan, L.V.S., Mining frequent itemsets with convertible constraints, In: Proc. 2001 Int. Conf. Data Engineering (ICDE’01) Heidelberg, Germany. (Apr. 2001), pp. 433–442.

[PHL+01] Pei, J.; Han, J.; Lu, H.; Nishio, S.; Tang, S.; Yang, D., H-Mine: Hyper-Structure Mining of Frequent Patterns in Large Databases, In: Proc. 2001 Int. Conf. Data Mining (ICDM’01) San Jose, CA. (Nov. 2001), pp. 441–448.

[PHL04] Parsons, L.; Haque, E.; Liu, H., Subspace clustering for high dimensional data: A review, SIGKDD Explorations 6 (2004) 90–105.

[PHM00] Pei, J.; Han, J.; Mao, R., CLOSET: An efficient algorithm for mining frequent closed itemsets, In: Proc. 2000 ACM-SIGMOD Int. Workshop Data Mining and Knowledge Discovery (DMKD’00) Dallas, TX. (May 2000), pp. 11–20.

[PHM-A+01] Pei, J.; Han, J.; Mortazavi-Asl, B.; Pinto, H.; Chen, Q.; Dayal, U.; Hsu, M.-C., PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth, In: Proc. 2001 Int. Conf. Data Engineering (ICDE’01) Heidelberg, Germany. (Apr. 2001), pp. 215–224.

[PHM-A+04] Pei, J.; Han, J.; Mortazavi-Asl, B.; Wang, J.; Pinto, H.; Chen, Q.; Dayal, U.; Hsu, M.-C., Mining sequential patterns by pattern-growth: The prefixSpan approach, IEEE Trans. Knowledge and Data Engineering 16 (2004) 1424–1440.

[PI97] Poosala, V.; Ioannidis, Y., Selectivity estimation without the attribute value independence assumption, In: Proc. 1997 Int. Conf. Very Large Data Bases (VLDB’97) Athens, Greece. (Aug. 1997), pp. 486–495.

[PKGF03] Papadimitriou, S.; Kitagawa, H.; Gibbons, P.B.; Faloutsos, C., Loci: Fast outlier detection using the local correlation integral, In: Proc. 2003 Int. Conf. Data Engineering (ICDE’03) Bangalore, India. (Mar. 2003), pp. 315–326.

[PKMT99] Pfeffer, A.; Koller, D.; Milch, B.; Takusagawa, K., SPOOK: A system for probabilistic object-oriented knowledge representation, In: Proc. 15th Annual Conf. Uncertainty in Artificial Intelligence (UAI’99) Stockholm, Sweden. (1999), pp. 541–550.

[PKZT01] Papadias, D.; Kalnis, P.; Zhang, J.; Tao, Y., Efficient OLAP operations in spatial data warehouses, In: Proc. 2001 Int. Symp. Spatial and Temporal Databases (SSTD’01) Redondo Beach, CA. (July 2001), pp. 443–459.

[PL07] Pang, B.; Lee, L., Opinion mining and sentiment analysis, Foundations and Trends in Information Retrieval 2 (2007) 1–135.

[Pla98] Platt, J.C., Fast training of support vector machines using sequential minimal optimization, In: (Editors: Schölkopf, B.; Burges, C.J.C.; Smola, A.) Advances in Kernel Methods—Support Vector Learning (1998) MIT Press, Cambridge, MA, pp. 185–208.

[PP07] Patcha, A.; Park, J.-M., An overview of anomaly detection techniques: Existing solutions and latest technological trends, Computer Networks 51 (12) (2007) 3448–3470.

[PS85] Preparata, F.P.; Shamos, M.I., Computational Geometry: An Introduction. (1985) Springer Verlag .

[P-S91] Piatetsky-Shapiro, G., Notes AAAI’91 Workshop Knowledge Discovery in Databases (KDD’91). (July 1991) Anaheim, CA .

[P-SF91] Piatetsky-Shapiro, G.; Frawley, W.J., Knowledge Discovery in Databases. (1991) AAAI/MIT Press .

[PTCX04] Pan, F.; Tung, A.K.H.; Cong, G.; Xu, X., COBBLER: Combining column and row enumeration for closed pattern discovery, In: Proc. 2004 Int. Conf. Scientific and Statistical Database Management (SSDBM’04) Santorini Island, Greece. (June 2004), pp. 21–30.

[PTVF07] Press, W.H.; Teukolosky, S.A.; Vetterling, W.T.; Flannery, B.P., Numerical Recipes: The Art of Scientific Computing. (2007) Cambridge University Press, Cambridge .

[PY10] Pan, S.J.; Yang, Q., A survey on transfer learning, IEEE Trans. Knowledge and Data Engineering 22 (2010) 1345–1359.

[Pyl99] Pyle, D., Data Preparation for Data Mining. (1999) Morgan Kaufmann .

[PZC+03] Pei, J.; Zhang, X.; Cho, M.; Wang, H.; Yu, P.S., Maple: A fast algorithm for maximal pattern-based clustering, In: Proc. 2003 Int. Conf. Data Mining (ICDM’03) Melbourne, FL. (Dec. 2003), pp. 259–266.

[QC-J93] Quinlan, J.R.; Cameron-Jones, R.M., FOIL: A midterm report, In: Proc. 1993 European Conf. Machine Learning (ECML’93) Vienna, Austria. (1993), pp. 3–20.

[QR89] Quinlan, J.R.; Rivest, R.L., Inferring decision trees using the minimum description length principle, Information and Computation 80 (Mar. 1989) 227–248.

[Qui86] Quinlan, J.R., Induction of decision trees, Machine Learning 1 (1986) 81–106.

[Qui87] Quinlan, J.R., Simplifying decision trees, Int. J. Man-Machine Studies 27 (1987) 221–234.

[Qui88] Quinlan, J.R., An empirical comparison of genetic and decision-tree classifiers, In: Proc. 1988 Int. Conf. Machine Learning (ICML’88) Ann Arbor, MI. (June 1988), pp. 135–141.

[Qui89] Quinlan, J.R., Unknown attribute values in induction, In: Proc. 1989 Int. Conf. Machine Learning (ICML’89) Ithaca, NY. (June 1989), pp. 164–168.

[Qui90] Quinlan, J.R., Learning logic definitions from relations, Machine Learning 5 (1990) 139–166.

[Qui93] Quinlan, J.R., C4.5: Programs for Machine Learning. (1993) Morgan Kaufmann .

[Qui96] Quinlan, J.R., Bagging, boosting, and C4.5, In: Portland, OR. Proc. 1996 Nat. Conf. Artificial Intelligence (AAAI’96), Vol. 1 (Aug. 1996), pp. 725–730.

[RA87] Rissland, E.L.; Ashley, K., HYPO: A case-based system for trade secret law, In: Proc. 1st Int. Conf. Artificial Intelligence and Law Boston, MA. (May 1987), pp. 60–66.

[Rab89] Rabiner, L.R., A tutorial on hidden Markov models and selected applications in speech recognition, Proc. IEEE 77 (1989) 257–286.

[RBKK95] Russell, S.; Binder, J.; Koller, D.; Kanazawa, K., Local learning in probabilistic networks with hidden variables, In: Proc. 1995 Joint Int. Conf. Artificial Intelligence (IJCAI’95) Montreal, Quebec, Canada. (Aug. 1995), pp. 1146–1152.

[RC07] Ramakrishnan, R.; Chen, B.-C., Exploratory mining in cube space, Data Mining and Knowledge Discovery 15 (2007) 29–54.

[Red92] Redman, T., Data Quality: Management and Technology. (1992) Bantam Books .

[Red01] Redman, T., Data Quality: The Field Guide. (2001) Digital Press (Elsevier) .

[RG03] Ramakrishnan, R.; Gehrke, J., Database Management Systems. 3rd ed. (2003) McGraw-Hill .

[RGN10] De Raedt, L.; Guns, T.; Nijssen, S., Constraint programming for data mining and machine learning, In: Proc. 2010 AAAI Conf. Artificial Intelligence (AAAI’10) Atlanta, GA. (July 2010), pp. 1671–1675.

[RH01] Raman, V.; Hellerstein, J.M., Potter's wheel: An interactive data cleaning system, In: Proc. 2001 Int. Conf. Very Large Data Bases (VLDB’01) Rome, Italy. (Sept. 2001), pp. 381–390.

[RH07] Rosenberg, A.; Hirschberg, J., V-measure: A conditional entropy-based external cluster evaluation measure, In: Proc. 2007 Joint Conf. Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL’07) Prague, Czech Republic. (June 2007), pp. 410–420.

[RHS01] Roddick, J.F.; Hornsby, K.; Spiliopoulou, M., An updated bibliography of temporal, spatial, and spatio-temporal data mining research, In: (Editors: Roddick, J.F.; Hornsby, K.) Lecture Notes in Computer Science 2007 (2001) Springer, New York, pp. 147–163; TSDM 2000.

[RHW86] Rumelhart, D.E.; Hinton, G.E.; Williams, R.J., Learning internal representations by error propagation, In: (Editors: Rumelhart, D.E.; McClelland, J.L.) Parallel Distributed Processing (1986) MIT Press, Cambridge, MA.

[Rip96] Ripley, B.D., Pattern Recognition and Neural Networks. (1996) Cambridge University Press .

[RM86] Rumelhart, D.E.; McClelland, J.L., Parallel Distributed Processing. (1986) MIT Press, Cambridge, MA .

[RMS98] Ramaswamy, S.; Mahajan, S.; Silberschatz, A., On the discovery of interesting patterns in association rules, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York. (Aug. 1998), pp. 368–379.

[RN95] Russell, S.; Norvig, P., Artificial Intelligence: A Modern Approach. (1995) Prentice-Hall .

[RNI09] Radovanović, M.; Nanopoulos, A.; Ivanović, M., Nearest neighbors in high-dimensional data: The emergence and influence of hubs, In: Proc. 2009 Int. Conf. Machine Learning (ICML’09) Montreal, Quebec, Canada. (June 2009), pp. 865–872.

[Ros58] Rosenblatt, F., The perceptron: A probabilistic model for information storage and organization in the brain, Psychological Rev. 65 (1958) 386–498.

[RS89] Riesbeck, C.; Schank, R., Inside Case-Based Reasoning. (1989) Lawrence Erlbaum .

[RS97] Ross, K.; Srivastava, D., Fast computation of sparse datacubes, In: Proc. 1997 Int. Conf. Very Large Data Bases (VLDB’97) Athens, Greece. (Aug. 1997), pp. 116–125.

[RS98] Rastogi, R.; Shim, K., Public: A decision tree classifer that integrates building and pruning, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York. (Aug. 1998), pp. 404–415.

[RS01] Ramsey, F.; Schafer, D., The Statistical Sleuth: A Course in Methods of Data Analysis. (2001) Duxbury Press .

[RSC98] Ross, K.A.; Srivastava, D.; Chatziantoniou, D., Complex aggregation at multiple granularities, In: Proc. Int. Conf. Extending Database Technology (EDBT’98) Valencia, Spain. (Mar. 1998), pp. 263–277.

[Rus06] Russ, J.C., The Image Processing Handbook. 5th ed. (2006) CRC Press .

[SA95] Srikant, R.; Agrawal, R., Mining generalized association rules, In: Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95) Zurich, Switzerland. (Sept. 1995), pp. 407–419.

[SA96] Srikant, R.; Agrawal, R., Mining sequential patterns: Generalizations and performance improvements, In: Proc. 5th Int. Conf. Extending Database Technology (EDBT’96) Avignon, France. (Mar. 1996), pp. 3–17.

[SAM96] Shafer, J.; Agrawal, R.; Mehta, M., SPRINT: A scalable parallel classifier for data mining, In: Proc. 1996 Int. Conf. Very Large Data Bases (VLDB’96) Bombay, India. (Sept. 1996), pp. 544–555.

[SAM98] Sarawagi, S.; Agrawal, R.; Megiddo, N., Discovery-driven exploration of OLAP data cubes, In: Proc. Int. Conf. Extending Database Technology (EDBT’98) Valencia, Spain. (Mar. 1998), pp. 168–182.

[SBSW99] Schölkopf, B.; Bartlett, P.L.; Smola, A.; Williamson, R., Shrinking the tube: A new support vector regression algorithm, In: (Editors: Kearns, M.S.; Solla, S.A.; Cohn, D.A.) Advances in Neural Information Processing Systems 11 (1999) MIT Press, Cambridge, MA, pp. 330–336.

[SC03] Shekhar, S.; Chawla, S., Spatial Databases: A Tour. (2003) Prentice-Hall .

[Sch86] Schlimmer, J.C., Learning and representation change, In: Proc. 1986 Nat. Conf. Artificial Intelligence (AAAI’86) Philadelphia, PA. (1986), pp. 511–515.

[Sch07] Schaeffer, S.E., Graph clustering, Computer Science Rev. 1 (2007) 27–64.

[SCZ98] Sheikholeslami, G.; Chatterjee, S.; Zhang, A., WaveCluster: A multi-resolution clustering approach for very large spatial databases, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York. (Aug. 1998), pp. 428–439.

[SD90] Shavlik, J.W.; Dietterich, T.G., Readings in Machine Learning. (1990) Morgan Kaufmann .

[SD02] Soukup, T.; Davidson, I., Visual Data Mining: Techniques and Tools for Data Visualization and Mining. (2002) Wiley .

[SDJL96] Srivastava, D.; Dar, S.; Jagadish, H.V.; Levy, A.V., Answering queries with aggregation using views, In: Proc. 1996 Int. Conf. Very Large Data Bases (VLDB’96) Bombay, India. (Sept. 1996), pp. 318–329.

[SDN98] Shukla, A.; Deshpande, P.M.; Naughton, J.F., Materialized view selection for multidimensional datasets, In: Proc. 1998 Int. Conf. Very Large Data Bases (VLDB’98) New York. (Aug. 1998), pp. 488–499.

[SE10] Seni, G.; Elder, J.F., Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions. (2010) Morgan and Claypool .

[Set10] Settles, B., Active learning literature survey, In: Computer Sciences Technical Report 1648 (2010) University of Wisconsin–Madison.

[SF86] Schlimmer, J.C.; Fisher, D., A case study of incremental concept induction, In: Proc. 1986 Nat. Conf. Artificial Intelligence (AAAI’86) Philadelphia, PA. (1986), pp. 496–501.

[SFB99] Shanmugasundaram, J.; Fayyad, U.M.; Bradley, P.S., Compressed data cubes for OLAP aggregate query approximation on continuous dimensions, In: Proc. 1999 Int. Conf. Knowledge Discovery and Data Mining (KDD’99) San Diego, CA. (Aug. 1999), pp. 223–232.

[SG92] Smyth, P.; Goodman, R.M., An information theoretic approach to rule induction, IEEE Trans. Knowledge and Data Engineering 4 (1992) 301–316.

[She31] Shewhart, W.A., Economic Control of Quality of Manufactured Product. (1931) D. Van Nostrand .

[Shi99] Shih, Y.-S., Families of splitting criteria for classification trees, Statistics and Computing 9 (1999) 309–315.

[SHK00] Stefanovic, N.; Han, J.; Koperski, K., Object-based selective materialization for efficient implementation of spatial data cubes, IEEE Trans. Knowledge and Data Engineering 12 (2000) 938–958.

[Sho97] Shoshani, A., OLAP and statistical databases: Similarities and differences, In: Proc. 16th ACM Symp. Principles of Database Systems Tucson, AZ. (May 1997), pp. 185–196.

[Shu88] Shumway, R.H., Applied Statistical Time Series Analysis. (1988) Prentice-Hall .

[SHX04] Shao, Z.; Han, J.; Xin, D., MM-Cubing: Computing iceberg cubes by factorizing the lattice space, In: Proc. 2004 Int. Conf. Scientific and Statistical Database Management (SSDBM’04) Santorini Island, Greece. (June 2004), pp. 213–222.

[SHZ+09] Sun, Y.; Han, J.; Zhao, P.; Yin, Z.; Cheng, H.; Wu, T., RankClus: Integrating clustering with ranking for heterogeneous information network analysis, In: Proc. 2009 Int. Conf. Extending Data Base Technology (EDBT’09) Saint Petersburg, Russia. (Mar. 2009), pp. 565–576.

[Sil10] Silvestri, F., Mining query logs: Turning search usage data into knowledge, Foundations and Trends in Information Retrieval 4 (2010) 1–174.

[SK08] Shieh, J.; Keogh, E., iSAX: Indexing and mining terabyte sized time series, In: Proc. 2008 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’08) Las Vegas, NV. (Aug. 2008), pp. 623–631.

[SKS10] Silberschatz, A.; Korth, H.F.; Sudarshan, S., Database System Concepts. 6th ed. (2010) McGraw-Hill .

[SLT+01] Shekhar, S.; Lu, C.-T.; Tan, X.; Chawla, S.; Vatsavai, R.R., Map cube: A visualization tool for spatial data warehouses, In: (Editors: Miller, H.J.; Han, J.) Geographic Data Mining and Knowledge Discovery (2001) Taylor and Francis, pp. 73–108.

[SM97] Setubal, J.C.; Meidanis, J., Introduction to Computational Molecular Biology. (1997) PWS Publishing Co. .

[SMT91] Shavlik, J.W.; Mooney, R.J.; Towell, G.G., Symbolic and neural learning algorithms: An experimental comparison, Machine Learning 6 (1991) 111–144.

[SN88] Saito, K.; Nakano, R., Medical diagnostic expert system based on PDP model, In: Proc. 1988 IEEE Int. Conf. Neural Networks San Mateo, CA. (1988), pp. 225–262.

[SOMZ96] Shen, W.; Ong, K.; Mitbander, B.; Zaniolo, C., Metaqueries for data mining, In: (Editors: Fayyad, U.M.; Piatetsky-Shapiro, G.; Smyth, P.; Uthurusamy, R.) Advances in Knowledge Discovery and Data Mining (1996) AAAI/MIT Press, pp. 375–398.

[SON95] Savasere, A.; Omiecinski, E.; Navathe, S., An efficient algorithm for mining association rules in large databases, In: Proc. 1995 Int. Conf. Very Large Data Bases (VLDB’95) Zurich, Switzerland. (Sept. 1995), pp. 432–443.

[SON98] Savasere, A.; Omiecinski, E.; Navathe, S., Mining for strong negative associations in a large database of customer transactions, In: Proc. 1998 Int. Conf. Data Engineering (ICDE’98) Orlando, FL. (Feb. 1998), pp. 494–502.

[SR81] Sokal, R.; Rohlf, F., Biometry. (1981) Freeman .

[SR92] Skowron, A.; Rauszer, C., The discernibility matrices and functions in information systems, In: (Editor: Slowinski, R.) Intelligent Decision Support, Handbook of Applications and Advances of the Rough Set Theory (1992) Kluwer Academic, pp. 331–362.

[SS88] Siedlecki, W.; Sklansky, J., On automatic feature selection, Int. J. Pattern Recognition and Artificial Intelligence 2 (1988) 197–220.

[SS94] Sarawagi, S.; Stonebraker, M., Efficient organization of large multidimensional arrays, In: Proc. 1994 Int. Conf. Data Engineering (ICDE’94) Houston, TX. (Feb. 1994), pp. 328–336.

[SS01] Sathe, G.; Sarawagi, S., Intelligent rollups in multidimensional OLAP data, In: Proc. 2001 Int. Conf. Very Large Data Bases (VLDB’01) Rome, Italy. (Sept. 2001), pp. 531–540.

[SS05] Shumway, R.H.; Stoffer, D.S., Time Series Analysis and Its Applications. (2005) Springer, New York .

[ST96] Silberschatz, A.; Tuzhilin, A., What makes patterns interesting in knowledge discovery systems, IEEE Trans. Knowledge and Data Engineering 8 (Dec. 1996) 970–974.

[STA98] Sarawagi, S.; Thomas, S.; Agrawal, R., Integrating association rule mining with relational database systems: Alternatives and implications, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 343–354.

[STH+10] Sun, Y.; Tang, J.; Han, J.; Gupta, M.; Zhao, B., Community evolution detection in dynamic heterogeneous information networks, In: Proc. 2010 KDD Workshop Mining and Learning with Graphs (MLG’10) Washington, DC. (July 2010).

[Ste72] Stefansky, W., Rejecting outliers in factorial designs, Technometrics 14 (1972) 469–479.

[Sto74] Stone, M., Cross-validatory choice and assessment of statistical predictions, J. Royal Statistical Society 36 (1974) 111–147.

[SVA97] Srikant, R.; Vu, Q.; Agrawal, R., Mining association rules with item constraints, In: Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97) Newport Beach, CA. (Aug. 1997), pp. 67–73.

[SW49] Shannon, C.E.; Weaver, W., The Mathematical Theory of Communication. (1949) University of Illinois Press .

[Swe88] Swets, J., Measuring the accuracy of diagnostic systems, Science 240 (1988) 1285–1293.

[Swi98] Swiniarski, R., Rough sets and principal component analysis and their applications in feature extraction and selection, data model building and classification, In: (Editors: Pal, S.K.; Skowron, A.) Rough Fuzzy Hybridization: A New Trend in Decision-Making (1999) Springer Verlag, Singapore.

[SWJR07] Song, X.; Wu, M.; Jermaine, C.; Ranka, S., Conditional anomaly detection, IEEE Trans. on Knowledge and Data Engineering 19 (5) (2007) 631–645.

[SZ04] Shasha, D.; Zhu, Y., High Performance Discovery in Time Series: Techniques and Case Studies. (2004) Springer, New York .

[TD02] Tax, D.M.J.; Duin, R.P.W., Using two-class classifiers for multiclass classification, In: Proc. 16th Intl. Conf. Pattern Recognition (ICPR’2002) Montreal, Quebec, Canada. (2002), pp. 124–127.

[TFPL04] Tao, Y.; Faloutsos, C.; Papadias, D.; Liu, B., Prediction and indexing of moving objects with unknown motion patterns, In: Proc. 2004 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’04) Paris, France. (June 2004), pp. 611–622.

[TG01] Tsoukatos, I.; Gunopulos, D., Efficient mining of spatiotemporal patterns, In: Proc. 2001 Int. Symp. Spatial and Temporal Databases (SSTD’01) Redondo Beach, CA. (July 2001), pp. 425–442.

[THH01] Tung, A.K.H.; Hou, J.; Han, J., Spatial clustering in the presence of obstacles, In: Proc. 2001 Int. Conf. Data Engineering (ICDE’01) Heidelberg, Germany. (Apr. 2001), pp. 359–367.

[THLN01] Tung, A.K.H.; Han, J.; Lakshmanan, L.V.S.; Ng, R.T., Constraint-based clustering in large databases, In: Proc. 2001 Int. Conf. Database Theory (ICDT’01) London. (Jan. 2001), pp. 405–419.

[THP08] Tian, Y.; Hankins, R.A.; Patel, J.M., Efficient aggregation for graph summarization, In: Proc. 2008 ACM SIGMOD Int. Conf. Management of Data (SIGMOD’08) Vancouver, British Columbia, Canada. (June 2008), pp. 567–580.

[Thu04] Thuraisingham, B., Data mining for counterterrorism, In: (Editors: Kargupta, H.; Joshi, A.; Sivakumar, K.; Yesha, Y.) Data Mining: Next Generation Challenges and Future Directions (2004) AAAI/MIT Press, pp. 157–183.

[TK08] Theodoridis, S.; Koutroumbas, K., Pattern Recognition. 4th ed. (2008) Academic Press .

[TKS02] Tan, P.-N.; Kumar, V.; Srivastava, J., Selecting the right interestingness measure for association patterns, In: Proc. 2002 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’02) Edmonton, Alberta, Canada. (July 2002), pp. 32–41.

[TLZN08] Tang, L.; Liu, H.; Zhang, J.; Nazeri, Z., Community evolution in dynamic multi-mode networks, In: Proc. 2008 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’08) Las Vegas, NV. (Aug. 2008), pp. 677–685.

[Toi96] Toivonen, H., Sampling large databases for association rules, In: Proc. 1996 Int. Conf. Very Large Data Bases (VLDB’96) Bombay, India. (Sept. 1996), pp. 134–145.

[TS93] Towell, G.G.; Shavlik, J.W., Extracting refined rules from knowledge-based neural networks, Machine Learning 13 (Oct. 1993) 71–101.

[TSK05] Tan, P.N.; Steinbach, M.; Kumar, V., Introduction to Data Mining. (2005) Addison-Wesley, Boston .

[TSS04] Tanay, A.; Sharan, R.; Shamir, R., Biclustering algorithms: A survey, In: (Editor: Aluru, S.) Handbook of Computational Molecular Biology (2004) Chapman & Hall, London, pp. 26:1–26:17.

[Tuf83] Tufte, E.R., The Visual Display of Quantitative Information. (1983) Graphics Press .

[Tuf90] Tufte, E.R., Envisioning Information. (1990) Graphics Press .

[Tuf97] Tufte, E.R., Visual Explanations: Images and Quantities, Evidence and Narrative. (1997) Graphics Press .

[Tuf01] Tufte, E.R., The Visual Display of Quantitative Information. 2nd ed. (2001) Graphics Press .

[TXZ06] Tao, Y.; Xiao, X.; Zhou, S., Mining distance-based outliers from large databases in any metric space, In: Proc. 2006 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’06) Philadelphia, PA. (Aug. 2006), pp. 394–403.

[UBC97] Utgoff, P.E.; Berkman, N.C.; Clouse, J.A., Decision tree induction based on efficient tree restructuring, Machine Learning 29 (1997) 5–44.

[UFS91] Uthurusamy, R.; Fayyad, U.M.; Spangler, S., Learning useful rules from inconclusive data, In: (Editors: Piatetsky-Shapiro, G.; Frawley, W.J.) Knowledge Discovery in Databases (1991) AAAI/MIT Press, pp. 141–157.

[Utg88] Utgoff, P.E., An incremental ID3, In: Proc. Fifth Int. Conf. Machine Learning (ICML’88) San Mateo, CA. (1988), pp. 107–120.

[Val87] Valduriez, P., Join indices, ACM Trans. Database Systems 12 (1987) 218–246.

[Vap95] Vapnik, V.N., The Nature of Statistical Learning Theory. (1995) Springer Verlag .

[Vap98] Vapnik, V.N., Statistical Learning Theory. (1998) John Wiley & Sons .

[VC71] Vapnik, V.N.; Chervonenkis, A.Y., On the uniform convergence of relative frequencies of events to their probabilities, Theory of Probability and Its Applications 16 (1971) 264–280.

[VC03] Vaidya, J.; Clifton, C., Privacy-preserving k-means clustering over vertically partitioned data, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug 2003).

[VC06] Vuk, M.; Curk, T., ROC curve, lift chart and calibration plot, Metodološki zvezki 3 (2006) 89–108.

[VCZ10] Vaidya, J.; Clifton, C.W.; Zhu, Y.M., Privacy Preserving Data Mining. (2010) Springer, New York .

[VGK02] Vlachos, M.; Gunopulos, D.; Kollios, G., Discovering similar multidimensional trajectories, In: Proc. 2002 Int. Conf. Data Engineering (ICDE’02) San Fransisco, CA. (Apr. 2002), pp. 673–684.

[VMZ06] Veloso, A.; Meira, W.; Zaki, M., Lazy associative classificaiton, In: Proc. 2006 Int. Conf. Data Mining (ICDM’06) Hong Kong, China. (2006), pp. 645–654.

[vR90] van Rijsbergen, C.J., Information Retrieval. (1990) Butterworth .

[VWI98] Vitter, J.S.; Wang, M.; Iyer, B.R., Data cube approximation and histograms via wavelets, In: Proc. 1998 Int. Conf. Information and Knowledge Management (CIKM’98) Washington, DC. (Nov. 1998), pp. 96–104.

[Wat95] Waterman, M.S., Introduction to Computational Biology: Maps, Sequences, and Genomes (Interdisciplinary Statistics). (1995) CRC Press .

[Wat03] Watts, D.J., Six Degrees: The Science of a Connected Age. (2003) W. W. Norton & Company .

[WB98] Westphal, C.; Blaxton, T., Data Mining Solutions: Methods and Tools for Solving Real-World Problems. (1998) John Wiley & Sons .

[WCH10] Wu, T.; Chen, Y.; Han, J., Re-examination of interestingness measures in pattern mining: A unified framework, Data Mining and Knowledge Discovery 21 (3) (2010) 371–397.

[WCRS01] Wagstaff, K.; Cardie, C.; Rogers, S.; Schrödl, S., Constrained k-means clustering with background knowledge, In: Proc. 2001 Int. Conf. Machine Learning (ICML’01) Williamstown, MA. (June 2001), pp. 577–584.

[Wei04] Weiss, G.M., Mining with rarity: A unifying framework, SIGKDD Explorations 6 (2004) 7–19.

[WF94] Wasserman, S.; Faust, K., Social Network Analysis: Methods and Applications. (1994) Cambridge University Press .

[WF05] Witten, I.H.; Frank, E., Data Mining: Practical Machine Learning Tools and Techniques. 2nd ed. (2005) Morgan Kaufmann .

[WFH11] Witten, I.H.; Frank, E.; Hall, M.A., Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. 3rd ed. (2011) Morgan Kaufmann, Boston .

[WFYH03] Wang, H.; Fan, W.; Yu, P.S.; Han, J., Mining concept-drifting data streams using ensemble classifiers, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 226–235.

[WHH00] Wang, K.; He, Y.; Han, J., Mining frequent itemsets using support constraints, In: Proc. 2000 Int. Conf. Very Large Data Bases (VLDB’00) Cairo, Egypt. (Sept. 2000), pp. 43–52.

[WHJ+10] Wang, C.; Han, J.; Jia, Y.; Tang, J.; Zhang, D.; Yu, Y.; Guo, J., Mining advisor-advisee relationships from research publication networks, In: Proc. 2010 ACM SIGKDD Conf. Knowledge Discovery and Data Mining (KDD’10) Washington, DC. (July 2010).

[WHLT05] Wang, J.; Han, J.; Lu, Y.; Tzvetkov, P., TFP: An efficient algorithm for mining top-k frequent closed itemsets, IEEE Trans. Knowledge and Data Engineering 17 (2005) 652–664.

[WHP03] Wang, J.; Han, J.; Pei, J., CLOSET+: Searching for the best strategies for mining frequent closed itemsets, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 236–245.

[WI98] Weiss, S.M.; Indurkhya, N., Predictive Data Mining. (1998) Morgan Kaufmann .

[Wid95] Widom, J., Research problems in data warehousing, In: Proc. 4th Int. Conf. Information and Knowledge Management Baltimore, MD. (Nov. 1995), pp. 25–30.

[WIZD04] Weiss, S.; Indurkhya, N.; Zhang, T.; Damerau, F., Text Mining: Predictive Methods for Analyzing Unstructured Information. (2004) Springer, New York .

[WK91] Weiss, S.M.; Kulikowski, C.A., Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning, and Expert Systems. (1991) Morgan Kaufmann .

[WK05] Wang, J.; Karypis, G., HARMONY: Efficiently mining the best rules for classification, In: Proc. 2005 SIAM Conf. Data Mining (SDM’05) Newport Beach, CA. (Apr. 2005), pp. 205–216.

[WLFY02] Wang, W.; Lu, H.; Feng, J.; Yu, J.X., Condensed cube: An effective approach to reducing data cube size, In: Proc. 2002 Int. Conf. Data Engineering (ICDE’02) San Fransisco, CA. (Apr. 2002), pp. 155–165.

[WRL94] Widrow, B.; Rumelhart, D.E.; Lehr, M.A., Neural networks: Applications in industry, business and science, Communications of the ACM 37 (1994) 93–105.

[WSF95] Wang, R.; Storey, V.; Firth, C., A framework for analysis of data quality research, IEEE Trans. Knowledge and Data Engineering 7 (1995) 623–640.

[Wu83] Wu, C.F.J., On the convergence properties of the EM algorithm, Ann. Statistics 11 (1983) 95–103.

[WW96] Wand, Y.; Wang, R., Anchoring data quality dimensions in ontological foundations, Communications of the ACM 39 (1996) 86–95.

[WWYY02] Wang, H.; Wang, W.; Yang, J.; Yu, P.S., Clustering by pattern similarity in large data sets, In: Proc. 2002 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’02) Madison, WI. (June 2002), pp. 418–427.

[WXH08] Wu, T.; Xin, D.; Han, J., ARCube: Supporting ranking aggregate queries in partially materialized data cubes, In: Proc. 2008 ACM SIGMOD Int. Conf. Management of Data (SIGMOD’08) Vancouver, British Columbia, Canada. (June 2008), pp. 79–92.

[WXMH09] Wu, T.; Xin, D.; Mei, Q.; Han, J., Promotion analysis in multi-dimensional space, Lyon, France. Proc. 2009 Int. Conf. Very Large Data Bases (VLDB’09) 2 (1) (Aug. 2009) 109–120.

[WYM97] Wang, W.; Yang, J.; Muntz, R., STING: A statistical information grid approach to spatial data mining, In: Proc. 1997 Int. Conf. Very Large Data Bases (VLDB’97) Athens, Greece. (Aug. 1997), pp. 186–195.

[XCYH06] Xin, D.; Cheng, H.; Yan, X.; Han, J., Extracting redundancy-aware top-k patterns, In: Proc. 2006 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’06) Philadelphia, PA. (Aug. 2006), pp. 444–453.

[XHCL06] Xin, D.; Han, J.; Cheng, H.; Li, X., Answering top-k queries with multi-dimensional selections: The ranking cube approach, In: Proc. 2006 Int. Conf. Very Large Data Bases (VLDB’06) Seoul, Korea. (Sept. 2006), pp. 463–475.

[XHLW03] Xin, D.; Han, J.; Li, X.; Wah, B.W., Star-cubing: Computing iceberg cubes by top-down and bottom-up integration, In: Proc. 2003 Int. Conf. Very Large Data Bases (VLDB’03) Berlin, Germany. (Sept. 2003), pp. 476–487.

[XHSL06] Xin, D.; Han, J.; Shao, Z.; Liu, H., C-cubing: Efficient computation of closed cubes by aggregation-based checking, In: Proc. 2006 Int. Conf. Data Engineering (ICDE’06) Atlanta, GA. (Apr. 2006), p. 4.

[XHYC05] Xin, D.; Han, J.; Yan, X.; Cheng, H., Mining compressed frequent-pattern sets, In: Proc. 2005 Int. Conf. Very Large Data Bases (VLDB’05) Trondheim, Norway. (Aug. 2005), pp. 709–720.

[XOJ00] Xiang, Y.; Olesen, K.G.; Jensen, F.V., Practical issues in modeling large diagnostic systems with multiply sectioned Bayesian networks, Intl. J. Pattern Recognition and Artificial Intelligence (IJPRAI) 14 (2000) 59–71.

[XPK10] Xing, Z.; Pei, J.; Keogh, E., A brief survey on sequence classification, SIGKDD Explorations 12 (2010) 40–48.

[XSH+04] Xiong, H.; Shekhar, S.; Huang, Y.; Kumar, V.; Ma, X.; Yoo, J.S., A framework for discovering co-location patterns in data sets with extended spatial objects, In: Proc. 2004 SIAM Int. Conf. Data Mining (SDM’04) Lake Buena Vista, FL. (Apr. 2004).

[XYFS07] Xu, X.; Yuruk, N.; Feng, Z.; Schweiger, T.A.J., SCAN: A structural clustering algorithm for networks, In: Proc. 2007 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’07) San Jose, CA. (Aug. 2007), pp. 824–833.

[XZYL08] Xu, T.; Zhang, Z.M.; Yu, P.S.; Long, B., Evolutionary clustering by hierarchical Dirichlet process with hidden Markov state, In: Proc. 2008 Int. Conf. Data Mining (ICDM’08) Pisa, Italy. (Dec. 2008), pp. 658–667.

[YC01] Ye, N.; Chen, Q., An anomaly detection technique based on a chi-square statistic for detecting intrusions into information systems, Quality and Reliability Engineering International 17 (2001) 105–112.

[YCHX05] Yan, X.; Cheng, H.; Han, J.; Xin, D., Summarizing itemset patterns: A profile-based approach, In: Proc. 2005 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’05) Chicago, IL. (Aug. 2005), pp. 314–323.

[YFB01] Yang, C.; Fayyad, U.; Bradley, P.S., Efficient discovery of error-tolerant frequent itemsets in high dimensions, In: Proc. 2001 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’01) San Fransisco, CA. (Aug. 2001), pp. 194–203.

[YFM+97] Yoda, K.; Fukuda, T.; Morimoto, Y.; Morishita, S.; Tokuyama, T., Computing optimized rectilinear regions for association rules, In: Proc. 1997 Int. Conf. Knowledge Discovery and Data Mining (KDD’97) Newport Beach, CA. (Aug. 1997), pp. 96–103.

[YH02] Yan, X.; Han, J., gSpan: Graph-based substructure pattern mining, In: Proc. 2002 Int. Conf. Data Mining (ICDM’02) Maebashi, Japan. (Dec. 2002), pp. 721–724.

[YH03a] Yan, X.; Han, J., CloseGraph: Mining closed frequent graph patterns, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 286–295.

[YH03b] Yin, X.; Han, J., CPAR: Classification based on predictive association rules, In: Proc. 2003 SIAM Int. Conf. Data Mining (SDM’03) San Fransisco, CA. (May 2003), pp. 331–335.

[YHA03] Yan, X.; Han, J.; Afshar, R., CloSpan: Mining closed sequential patterns in large datasets, In: Proc. 2003 SIAM Int. Conf. Data Mining (SDM’03) San Fransisco, CA. (May 2003), pp. 166–177.

[YHF10] Yu, P.S.; Han, J.; Faloutsos, C., Link Mining: Models, Algorithms and Applications. (2010) Springer, New York .

[YHY05] Yin, X.; Han, J.; Yu, P.S., Cross-relational clustering with user's guidance, In: Proc. 2005 ACM SIGKDD Int. Conf. Knowledge Discovery in Databases (KDD’05) Chicago, IL. (Aug. 2005), pp. 344–353.

[YHY07] Yin, X.; Han, J.; Yu, P.S., Object distinction: Distinguishing objects with identical names by link analysis, In: Proc. 2007 Int. Conf. Data Engineering (ICDE’07) Istanbul, Turkey. (Apr. 2007).

[YHY08] Yin, X.; Han, J.; Yu, P.S., Truth discovery with multiple conflicting information providers on the Web, IEEE Trans. Knowledge and Data Engineering 20 (2008) 796–808.

[YHYY04] Yin, X.; Han, J.; Yang, J.; Yu, P.S., CrossMine: Efficient classification across multiple database relations, In: Proc. 2004 Int. Conf. Data Engineering (ICDE’04) Boston, MA. (Mar. 2004), pp. 399–410.

[YK09] Ye, L.; Keogh, E., Time series shapelets: A new primitive for data mining, In: Proc. 2009 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’09) Paris, France. (June 2009), pp. 947–956.

[YWY07] Yuan, J.; Wu, Y.; Yang, M., Discovery of collocation patterns: From visual words to visual phrases, In: Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR’07) Minneapolis, MN. (June 2007), pp. 1–8.

[YYH03] Yu, H.; Yang, J.; Han, J., Classifying large data sets using SVM with hierarchical clusters, In: Proc. 2003 ACM SIGKDD Int. Conf. Knowledge Discovery and Data Mining (KDD’03) Washington, DC. (Aug. 2003), pp. 306–315.

[YYH05] Yan, X.; Yu, P.S.; Han, J., Graph indexing based on discriminative frequent structure analysis, ACM Trans. Database Systems 30 (2005) 960–993.

[YZ94] Yager, R.R.; Zadeh, L.A., Fuzzy Sets, Neural Networks and Soft Computing. (1994) Van Nostrand Reinhold .

[YZYH06] Yan, X.; Zhu, F.; Yu, P.S.; Han, J., Feature-based substructure similarity search, ACM Trans. Database Systems 31 (2006) 1418–1453.

[Zad65] Zadeh, L.A., Fuzzy sets, Information and Control 8 (1965) 338–353.

[Zad83] Zadeh, L., Commonsense knowledge representation based on fuzzy logic, Computer 16 (1983) 61–65.

[Zak00] Zaki, M.J., Scalable algorithms for association mining, IEEE Trans. Knowledge and Data Engineering 12 (2000) 372–390.

[Zak01] Zaki, M., SPADE: An efficient algorithm for mining frequent sequences, Machine Learning 40 (2001) 31–60.

[ZDN97] Zhao, Y.; Deshpande, P.M.; Naughton, J.F., An array-based algorithm for simultaneous multidimensional aggregates, In: Proc. 1997 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’97) Tucson, AZ. (May 1997), pp. 159–170.

[ZH02] Zaki, M.J.; Hsiao, C.J., CHARM: An efficient algorithm for closed itemset mining, In: Proc. 2002 SIAM Int. Conf. Data Mining (SDM’02) Arlington, VA. (Apr. 2002), pp. 457–473.

[Zha08] Zhai, C., Statistical Language Models for Information Retrieval. (2008) Morgan and Claypool .

[ZHL+98] Zaïane, O.R.; Han, J.; Li, Z.N.; Chiang, J.Y.; Chee, S., MultiMedia-Miner: A system prototype for multimedia data mining, In: Proc. 1998 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’98) Seattle, WA. (June 1998), pp. 581–583.

[Zhu05] Zhu, X., Semi-supervised learning literature survey, In: Computer Sciences Technical Report 1530 (2005) University of Wisconsin–Madison.

[ZHZ00] Zaïane, O.R.; Han, J.; Zhu, H., Mining recurrent items in multimedia with progressive resolution refinement, In: Proc. 2000 Int. Conf. Data Engineering (ICDE’00) San Diego, CA. (Feb. 2000), pp. 461–470.

[Zia91] Ziarko, W., The discovery, analysis, and representation of data dependencies in databases, In: (Editors: Piatetsky-Shapiro, G.; Frawley, W.J.) Knowledge Discovery in Databases (1991) AAAI Press, pp. 195–209.

[ZL06] Zhou, Z.-H.; Liu, X.-Y., Training cost-sensitive neural networks with methods addressing the class imbalance problem, IEEE Trans. Knowledge and Data Engineering 18 (2006) 63–77.

[ZPOL97] Zaki, M.J.; Parthasarathy, S.; Ogihara, M.; Li, W., Parallel algorithm for discovery of association rules, Data Mining and Knowledge Discovery 1 (1997) 343–374.

[ZRL96] Zhang, T.; Ramakrishnan, R.; Livny, M., BIRCH: An efficient data clustering method for very large databases, In: Proc. 1996 ACM-SIGMOD Int. Conf. Management of Data (SIGMOD’96) Montreal, Quebec, Canada. (June 1996), pp. 103–114.

[ZS02] Zapkowicz, N.; Stephen, S., The class imbalance program: A systematic study, Intelligence Data Analysis 6 (2002) 429–450.

[ZYH+07] Zhu, F.; Yan, X.; Han, J.; Yu, P.S.; Cheng, H., Mining colossal frequent patterns by core pattern fusion, In: Proc. 2007 Int. Conf. Data Engineering (ICDE’07) Istanbul, Turkey. (Apr. 2007), pp. 706–715.

[ZYHY07] Zhu, F.; Yan, X.; Han, J.; Yu, P.S., gPrune: A constraint pushing framework for graph pattern mining, In: Proc. 2007 Pacific-Asia Conf. Knowledge Discovery and Data Mining (PAKDD’07) Nanjing, China. (May 2007), pp. 388–400.

[ZZ09] Zhang, Z.; Zhang, R., Multimedia Data Mining: A Systematic Introduction to Concepts and Theory. (2009) Chapman & Hall .

[ZZH09] Zhang, D.; Zhai, C.; Han, J., Topic cube: Topic modeling for OLAP on multidimensional text databases, In: Proc. 2009 SIAM Int. Conf. Data Mining (SDM’09) Sparks, NV. (Apr. 2009), pp. 1123–1134.

Index

Numbers and Symbols

.632 bootstrap

371

δ-bicluster algorithm

517–518

δ-pCluster

518–519

A

absolute-error criterion

455

absolute support

246

abstraction levels

281

accuracy

attribute construction and

105

boosting

382

with bootstrap

371

classification

377–385

classifier

330, 366

with cross-validation

370–371

data

84

with holdout method

370

measures

369

random forests

383

with random subsampling

370

rule selection based on

361

activation function

402

active learning

25, 430, 437

ad hoc data mining

31

AdaBoost

380–382 algorithm illustration

382

TrAdaBoost

436

adaptive probabilistic networks

397

advanced data analysis

3, 4

advanced database systems

4

affinity matrix

520, 521

agglomerative hierarchical method

459 AGNES

459, 460

divisive hierarchical clustering versus

459–460

Agglomerative Nesting (AGNES)

459, 460

aggregate cells

189

aggregation

112 bootstrap

379

complex data types and

166

cube computation and

193

data cube

110–111

at multiple granularities

230–231

multiway array

195–199

simultaneous

193, 195

AGNES.

seeAgglomerative Nesting

algebraic measures

145

algorithms.

all_confidence measure

268, 272

all-versus-all (AVA)

430–431

analysis of variance (ANOVA)

600

analytical processing

153

ancestor cells

189

angle-based outlier detection (ABOD)

580

angle-based outlier factor (ABOF)

580

anomalies.

seeoutliers

anomaly mining.

seeoutlier analysis

anomaly-based detection

614

antimonotonic constraints

298, 301

antimonotonic measures

194

antimonotonicity

249

apex cuboids

111, 138, 158

application domain-specific semantics

282

applications

33, 607–618 business intelligence

27

computer science

613

domain-specific

625

engineering

613, 624

exploration

623

financial data analysis

607–609

intrusion detection/prevention

614–615

recommender systems

615–618

retail industry

609–611

science

611–613

social science and social studies

613

targeted

27–28

telecommunications industry

611

Web search engines

28

application-specific outlier detection

548–549

approximate patterns

281 mining

307–312

Apriori algorithm

248–253, 272 dynamic itemset counting

256

efficiency, improving

254–256

example

250–252

hash-based technique

255

join step

249

partitioning

255–256

prune step

249–250

pseudocde

253

sampling

256

transaction reduction

255

Apriori property

194, 201, 249 antimonotonicity

249

in Apriori algorithm

298

Apriori pruning method

194

arrays

3-D for dimensions

196

sparse compression

198–199

association analysis

17–18

association rules

245 approximate

281

Boolean

281

compressed

281

confidence

21, 245, 246, 416

constraint-based

281

constraints

296–297

correlation

265, 272

discarded

17

fittest

426

frequent patterns and

280

generation from frequent itemsets

253, 254

hybrid-dimensional

288

interdimensional

288

intradimensional

287

metarule-guided mining of

295–296

minimum confidence threshold

18, 245

minimum support threshold

245

mining

272

multidimensional

17, 287–289, 320

multilevel

281, 283–287, 320

near-match

281

objective measures

21

offspring

426

quantitative

281, 289, 320

redundancy-aware top-k

281

single-dimensional

17, 287

spatial

595

strong

264–265, 272

support

21, 245, 246, 417

top-k

281

types of values in

281

associative classification

415, 416–419, 437 CBA

417

CMAR

417–418

CPAR

418–419

rule confidence

416

rule support

417

steps

417

asymmetric binary dissimilarity

71

asymmetric binary similarity

71

attribute construction

112 accuracy and

105

multivariate splits

344

attribute selection measures

331, 336–344 CHAID

343

gain ratio

340–341

Gini index

341–343

information gain

336–340

Minimum Description Length (MDL)

343–344

multivariate splits

343–344

attribute subset selection

100, 103–105 decision tree induction

105

forward selection/backward elimination combination

105

greedy methods

104–105

stepwise backward elimination

105

stepwise forward selection

105

attribute vectors

40, 328

attribute-oriented induction (AOI)

166–178, 180 algorithm

173

for class comparisons

175–178

for data characterization

167–172

data generalization by

166–178

generalized relation

172

implementation of

172–174

attributes

9, 40 abstraction level differences

99

behavioral

546, 573

binary

41–42, 79

Boolean

41

categorical

41

class label

328

contextual

546, 573

continuous

44

correlated

54–56

dimension correspondence

10

discrete

44

generalization

169–170

generalization control

170

generalization threshold control

170

grouping

231

interval-scaled

43, 79

of mixed type

75–77

nominal

41, 79

numeric

43–44, 79

ordered

103

ordinal

41, 79

qualitative

41

ratio-scaled

43–44, 79

reducts of

427

removal

169

repetition

346

set of

118

splitting

333

terminology for

40

type determination

41

types of

39

unordered

103

audio data mining

604–607, 624

automatic classification

445

AVA.

seeall-versus-all

AVC-group

347

AVC-set

347

average()

215

B

background knowledge

30–31

backpropagation

393, 398–408, 437 activation function

402

algorithm illustration

401

biases

402, 404

case updating

404

efficiency

404

epoch updating

404

error

403

functioning of

400–403

hidden layers

399

input layers

399

input propagation

401–402

interpretability and

406–408

learning

400

learning rate

403–404

logistic function

402

multilayer feed-forward neural network

398–399

network pruning

406–407

neural network topology definition

400

output layers

399

sample learning calculations

404–406

sensitivity analysis

408

sigmoid function

402

squashing function

403

terminating conditions

404

unknown tuple classification

406

weights initialization

401see alsoclassification

bagging

379–380 algorithm illustration

380

boosting versus

381–382

in building random forests

383

bar charts

54

base cells

189

base cuboids

111, 137–138, 158

Basic Local Alignment Search Tool (BLAST)

591

Baum-Welch algorithm

591

Bayes’ theorem

350–351

Bayesian belief networks

393–397, 436 algorithms

396

components of

394

conditional probability table (CPT)

394, 395

directed acyclic graph

394–395

gradient descent strategy

396–397

illustrated

394

mechanisms

394–396

problem modeling

395–396

topology

396

training

396–397see alsoclassification

Bayesian classification

basis

350

Bayes’ theorem

350–351

class conditional independence

350

naive

351–355, 385

posterior probability

351

prior probability

351

BCubed precision metric

488, 489

BCubed recall metric

489

behavioral attributes

546, 573

believability, data

85

BI (business intelligence)

27

biases

402, 404

biclustering

512–519, 538 application examples

512–515

enumeration methods

517, 518–519

gene expression example

513–514

methods

517–518

optimization-based methods

517–518

recommender system example

514–515

types of

538

biclusters

511 with coherent values

516

with coherent values on rows

516

with constant values

515

with constant values on columns

515

with constant values on rows

515

as submatrix

515

types of

515–516

bimodal

47

bin boundaries

89

binary attributes

41, 79 asymmetric

42, 70

as Boolean

41

contingency table for

70

dissimilarity between

71–72

example

41–42

proximity measures

70–72

symmetric

42, 70–71see alsoattributes

binning

discretization by

115

equal-frequency

89

smoothing by bin boundaries

89

smoothing by bin means

89

smoothing by bin medians

89

biological sequences

586, 624 alignment of

590–591

analysis

590

BLAST

590

hidden Markov model

591

as mining trend

624

multiple sequence alignment

590

pairwise alignment

590

phylogenetic tree

590

substitution matrices

590

bipartite graphs

523

BIRCH

458, 462–466 CF-trees

462–463, 464, 465–466

clustering feature

462, 463, 464

effectiveness

465

multiphase clustering technique

464–465see alsohierarchical methods

bitmap indexing

160–161, 179

bitmapped join indexing

163, 179

bivariate distribution

40

BLAST.

seeBasic Local Alignment Search Tool

BOAT.

Boolean association rules

281

Boolean attributes

41

boosting

380 accuracy

382

AdaBoost

380–382

bagging versus

381–382

weight assignment

381

bootstrap method

371, 386

bottom-up design approach

133, 151–152

bottom-up subspace search

510–511

boxplots

49 computation

50

example

50

five-number summary

49

illustrated

50

in outlier visualization

555

BUC

200–204, 235 for 3-D data cube computation

200

algorithm

202

Apriori property

201

bottom-up construction

201

iceberg cube construction

201

partitioning snapshot

203

performance

204

top-down processing order

200, 201

business intelligence (BI)

27

business metadata

135

business query view

151

C

C4.5

332, 385 class-based ordering

358

gain ratio use

340

greedy approach

332

pessimistic pruning

345

rule extraction

358see alsodecision tree induction

cannot-link constraints

533

CART

332, 385 cost complexity pruning algorithm

345

Gini index use

341

greedy approach

332see alsodecision tree induction

case updating

404

case-based reasoning (CBR)

425–426 challenges

426

categorical attributes

41

CBA.

seeClassification Based on Associations

CBLOF.

seecluster-based local outlier factor

CELL method

562, 563

cells

10–11 aggregate

189

ancestor

189

base

189

descendant

189

dimensional

189

exceptions

231

residual value

234

central tendency measures

39, 44, 45–47 mean

45–46

median

46–47

midrange

47

for missing values

88

models

47

centroid distance

108

CF-trees

462–463, 464 nodes

465

parameters

464

structure illustration

464

CHAID

343

Chameleon

459, 466–467 clustering illustration

466

relative closeness

467

relative interconnectivity

466–467see alsohierarchical methods

Chernoff faces

60 asymmetrical

61

illustrated

62

ChiMerge

117

chi-square test

95

chunking

195

chunks

195 2-D

197

3-D

197

computation of

198

scanning order

197

CLARA.

seeClustering Large Applications

CLARANS.

seeClustering Large Applications based upon Randomized Search

class comparisons

166, 175, 180 attribute-oriented induction for

175–178

mining

176

presentation of

175–176

procedure

175–176

class conditional independence

350

class imbalance problem

384–385, 386 ensemble methods for

385

on multiclass tasks

385

oversampling

384–385, 386

threshold-moving approach

385

undersampling

384–385, 386

class label attributes

328

class-based ordering

357

class/concept descriptions

15

classes

15, 166 contrasting

15

equivalence

427

target

15

classification

18, 327–328, 385 accuracy

330

accuracy improvement techniques

377–385

active learning

433–434

advanced methods

393–442

applications

327

associative

415, 416–419, 437

automatic

445

backpropagation

393, 398–408, 437

bagging

379–380

basic concepts

327–330

Bayes methods

350–355

Bayesian belief networks

393–397, 436

boosting

380–382

case-based reasoning

425–426

of class-imbalanced data

383–385

confusion matrix

365–366, 386

costs and benefits

373–374

decision tree induction

330–350

discriminative frequent pattern-based

437

document

430

ensemble methods

378–379

evaluation metrics

364–370

example

19

frequent pattern-based

393, 415–422, 437

fuzzy set approaches

428–429, 437

general approach to

328

genetic algorithms

426–427, 437

heterogeneous networks

593

homogeneous networks

593

IF-THEN rules for

355–357

interpretability

369

k-nearest-neighbor

423–425

lazy learners

393, 422–426

learning step

328

model representation

18

model selection

364, 370–377

multiclass

430–432, 437

in multimedia data mining

596

neural networks for

19, 398–408

pattern-based

282, 318

perception-based

348–350

precision measure

368–369

as prediction problem

328

process

328

process illustration

329

random forests

382–383

recall measure

368–369

robustness

369

rough set approach

427–428, 437

rule-based

355–363, 386

scalability

369

semi-supervised

432–433, 437

sentiment

434

spatial

595

speed

369

support vector machines (SVMs)

393, 408–415, 437

transfer learning

434–436

tree pruning

344–347, 385

web-document

435

Classification Based on Associations (CBA)

417

Classification based on Multiple Association Rules (CMAR)

417–418

Classification based on Predictive Association Rules (CPAR)

418–419

classification-based outlier detection

571–573, 582 one-class model

571–572

semi-supervised learning

572see alsooutlier detection

classifiers

328 accuracy

330, 366

bagged

379–380

Bayesian

350, 353

case-based reasoning

425–426

comparing with ROC curves

373–377

comparison aspects

369

decision tree

331

error rate

367

k-nearest-neighbor

423–425

Naive Bayesian

351–352

overfitting data

330

performance evaluation metrics

364–370

recognition rate

366–367

rule-based

355

Clementine

603, 606

CLIQUE

481–483 clustering steps

481–482

effectiveness

483

strategy

481see alsocluster analysis; grid-based methods

closed data cubes

192

closed frequent itemsets

247, 308 example

248

mining

262–264

shortcomings for compression

308–309

closed graphs

591

closed patterns

280 top-k most frequent

307

closure checking

263–264

cloud computing

31

cluster analysis

19–20, 443–495 advanced

497–541

agglomerative hierarchical clustering

459–461

applications

444, 490

attribute types and

446

as automatic classification

445

biclustering

511, 512–519

BIRCH

458, 462–466

Chameleon

458, 466–467

CLIQUE

481–483

clustering quality measurement

484, 487–490

clustering tendency assessment

484–486

constraint-based

447, 497, 532–538

correlation-based

511

as data redundancy technique

108

as data segmentation

445

DBSCAN

471–473

DENCLUE

476–479

density-based methods

449, 471–479, 491

in derived space

519–520

dimensionality reduction methods

519–522

discretization by

116

distance measures

461–462

distance-based

445

divisive hierarchical clustering

459–461

evaluation

483–490, 491

example

20

expectation-maximization (EM) algorithm

505–508

graph and network data

497, 522–532

grid-based methods

450, 479–483, 491

heterogeneous networks

593

hierarchical methods

449, 457–470, 491

high-dimensional data

447, 497, 508–522

homogeneous networks

593

in image recognition

444

incremental

446

interpretability

447

k-means

451–454

k-medoids

454–457

k-modes

454

in large databases

445

as learning by observation

445

low-dimensional

509

methods

448–451

multiple-phase

458–459

number of clusters determination

484, 486–487

OPTICS

473–476

orthogonal aspects

491

for outlier detection

445

outlier detection and

543

partitioning methods

448, 451–457, 491

pattern

282, 308–310

probabilistic hierarchical clustering

467–470

probability model-based

497–508

PROCLUS

511

requirements

445–448, 490–491

scalability

446

in search results organization

444

spatial

595

spectral

519–522

as standalone tool

445

STING

479–481

subspace

318–319, 448

subspace search methods

510–511

taxonomy formation

20

techniques

443, 444

as unsupervised learning

445

usability

447

use of

444

cluster computing

31

cluster samples

108–109

cluster-based local outlier factor (CBLOF)

569–570

clustering.

seecluster analysis

clustering features

462, 463, 464

Clustering Large Applications based upon Randomized Search (CLARANS)

457

Clustering Large Applications (CLARA)

456–457

clustering quality measurement, 484t

487–490 cluster completeness

488

cluster homogeneity

487–488

extrinsic methods

487–489

intrinsic methods

487, 489–490

rag bag

488

silhouette coefficient

489–490

small cluster preservation

488

clustering space

448

clustering tendency assessment

484–486 homogeneous hypothesis

486

Hopkins statistic

484–485

nonhomogeneous hypothesis

486

nonuniform distribution of data

484see alsocluster analysis

clustering with obstacles problem

537

clustering-based methods

552, 567–571 example

553see alsooutlier detection

clustering-based outlier detection

567–571, 582 approaches

567

distance to closest cluster

568–569

fixed-width clustering

570

intrusion detection by

569–570

objects not belonging to a cluster

568

in small clusters

570–571

weakness of

571

clustering-based quantitative associations

290–291

clusters

66, 443, 444, 490 arbitrary shape, discovery of

446

assignment rule

497–498

completeness

488

constraints on

533

cuts and

529–530

density-based

472

determining number of

484, 486–487

discovery of

318

fuzzy

499–501

graph clusters, finding

528–529

on high-dimensional data

509

homogeneity

487–488

merging

469, 470

ordering

474–475, 477

pattern-based

516

probabilistic

502–503

separation of

447

shapes

471

small, preservation

488

CMAR.

seeClassification based on Multiple Association Rules

CN2

359, 363

collaborative recommender systems

610, 617, 618

collective outlier detection

548, 582 categories of

576

contextual outlier detection versus

575

on graph data

576

structure discovery

575

collective outliers

575, 581 mining

575–576

co-location patterns

319, 595

colossal patterns

302, 320 core descendants

305, 306

core patterns

304–305

illustrated

303

mining challenge

302–303

Pattern-Fusion mining

302–307

combined significance

312

complete-linkage algorithm

462

completeness

data

84–85

data mining algorithm

22

complex data types

166 biological sequence data

586, 590–591

graph patterns

591–592

mining

585–598, 625

networks

591–592

in science applications

612

summary

586

symbolic sequence data

586, 588–590

time-series data

586, 587–588

composite join indices

162

compressed patterns

281 mining

307–312

mining by pattern clustering

308–310

compression

100, 120 lossless

100

lossy

100

theory

601

computer science applications

613

concept characterization

180

concept comparison

180

concept description

166, 180

concept hierarchies

142, 179 for generalizing data

150

illustrated

143, 144

implicit

143

manual provision

144

multilevel association rule mining with

285

multiple

144

for nominal attributes

284

for specializing data

150

concept hierarchy generation

112, 113, 120 based on number of distinct values

118

illustrated

112

methods

117–119

for nominal data

117–119

with prespecified semantic connections

119

schema

119

conditional probability table (CPT)

394, 395–396

confidence

21 association rule

21

interval

219–220

limits

373

rule

245, 246

conflict resolution strategy

356

confusion matrix

365–366, 386 illustrated

366

connectionist learning

398

consecutive rules

92

Constrained Vector Quantization Error (CVQE) algorithm

536

constraint-based clustering

447, 497, 532–538, 539 categorization of constraints and

533–535

hard constraints

535–536

methods

535–538

soft constraints

536–537

speeding up

537–538see alsocluster analysis

constraint-based mining

294–301, 320 interactive exploratory mining/analysis

295

as mining trend

623

constraint-based patterns/rules

281

constraint-based sequential pattern mining

589

constraint-guided mining

30

constraints

antimonotonic

298, 301

association rule

296–297

cannot-link

533

on clusters

533

coherence

535

conflicting

535

convertible

299–300

data

294

data-antimonotonic

300

data-pruning

300–301, 320

data-succinct

300

dimension/level

294, 297

hard

534, 535–536, 539

inconvertible

300

on instances

533, 539

interestingness

294, 297

knowledge type

294

monotonic

298

must-link

533, 536

pattern-pruning

297–300, 320

rules for

294

on similarity measures

533–534

soft

534, 536–537, 539

succinct

298–299

content-based retrieval

596

context indicators

314

context modeling

316

context units

314

contextual attributes

546, 573

contextual outlier detection

546–547, 582 with identified context

574

normal behavior modeling

574–575

structures as contexts

575

summary

575

transformation to conventional outlier detection

573–574

contextual outliers

545–547, 573, 581 example

546, 573

mining

573–575

contingency tables

95

continuous attributes

44

contrasting classes

15, 180 initial working relations

177

prime relation

175, 177

convertible constraints

299–300

COP k-means algorithm

536

core descendants

305 colossal patterns

306

merging of core patterns

306

core patterns

304–305

core ratio

305

correlation analysis

94 discretization by

117

interestingness measures

264

with lift

266–267

nominal data

95–96

numeric data

96–97

redundancy and

94–98

correlation coefficient

94, 96 numeric data

96–97

correlation rules

265, 272

correlation-based clustering methods

511

correlations

18

cosine measure

268

cosine similarity

77 between two term-frequency vectors

78

cost complexity pruning algorithm

345

cotraining

432–433

covariance

94, 97 numeric data

97–98

CPAR.

seeClassification based on Predictive Association Rules

credit policy analysis

608–609

CRM.

seecustomer relationship management

crossover operation

426

cross-validation

370–371, 386 k-fold

370

leave-one-out

371

in number of clusters determination

487

stratified

371

cube gradient analysis

321

cube shells

192, 211 computing

211

cube space

discovery-driven exploration

231–234

multidimensional data analysis in

227–234

prediction mining in

227

subspaces

228–229

cuboid trees

205

cuboids

137 apex

111, 138, 158

base

111, 137–138, 158

child

193

individual

190

lattice of

139, 156, 179, 188–189, 234, 290

sparse

190

subset selection

160see alsodata cubes

curse of dimensionality

158, 179

customer relationship management (CRM)

619

customer retention analysis

610

CVQE.

seeConstrained Vector Quantization Error algorithm

cyber-physical systems (CPS)

596, 623–624

D

data

antimonotonicity

300

archeology

6

biological sequence

586, 590–591

complexity

32

conversion to knowledge

2

cyber-physical system

596

for data mining

8

data warehouse

13–15

database

9–10

discrimination

16

dredging

6

generalizing

150

graph

14

growth

2

linearly inseparable

413–415

linearly separated

409

multimedia

14, 596

multiple sources

15, 32

multivariate

556

networked

14

overfitting

330

relational

10

sample

219

similarity and dissimilarity measures

65–78

skewed

47, 271

spatial

14, 595

spatiotemporal

595–596

specializing

150

statistical descriptions

44–56

streams

598

symbolic sequence

586, 588–589

temporal

14

text

14, 596–597

time-series

586, 587

「tombs」

5

training

18

transactional

13–14

types of

33

web

597–598

data auditing tools

92

data characterization

15, 166 attribute-oriented induction

167–172

data mining query

167–168

example

16

methods

16

output

16

data classification.

seeclassification

data cleaning

6, 85, 88–93, 120 in back-end tools/utilities

134

binning

89–90

discrepancy detection

91–93

by information network analysis

592–593

missing values

88–89

noisy data

89

outlier analysis

90

pattern mining for

318

as process

91–93

regression

90see alsodata preprocessing

data constraints

294 antimonotonic

300

pruning data space with

300–301

succinct

300see alsoconstraints

data cube aggregation

110–111

data cube computation

156–160, 214–215 aggregation and

193

average()

215

BUC

200–204, 235

cube operator

157–159

cube shells

211

full

189–190, 195–199

general strategies for

192–194

iceberg

160, 193–194

memory allocation

199

methods

194–218, 235

multiway array aggregation

195–199

one-pass

198

preliminary concepts

188–194

shell fragments

210–218, 235

Star-Cubing

204–210, 235

data cubes

10, 136, 178, 188 3-D

138

4-D

138, 139

apex cuboid

111, 138, 158

base cuboid

111, 137–138, 158

closed

192

cube shell

192

cuboids

137

curse of dimensionality

158

discovery-driven exploration

231–234

example

11–13

full

189–190, 196–197

gradient analysis

321

iceberg

160, 190–191, 201, 235

lattice of cuboids

157, 234, 290

materialization

159–160, 179, 234

measures

145

multidimensional

12, 136–139

multidimensional data mining and

26

multifeature

227, 230–231, 235

multimedia

596

prediction

227–230, 235

qualitative association mining

289–290

queries

230

query processing

218–227

ranking

225–227, 235

sampling

218–220, 235

shell

160, 211

shell fragments

192, 210–218, 235

sparse

190

spatial

595

technology

187–242

data discretization.

seediscretization

data dispersion

44, 48–51 boxplots

49–50

five-number summary

49

quartiles

48–49

standard deviation

50–51

variance

50–51

data extraction, in back-end tools/utilities

134

data focusing

168

data generalization

179–180 by attribute-oriented induction

166–178

data integration

6, 85–86, 93–99, 120 correlation analysis

94–98

detection/resolution of data value conflicts

99

entity identification problem

94

by information network analysis

592–593

object matching

94

redundancy and

94–98

schema

94

tuple duplication

98–99see alsodata preprocessing

data marts

132, 142 data warehouses versus

142

dependent

132

distributed

134

implementation

132

independent

132

data matrix

67–68 dissimilarity matrix versus

67–68

relational table

67–68

rows and columns

68

as two-mode matrix

68

data migration tools

93

data mining

5–8, 33, 598, 623 ad hoc

31

applications

607–618

biological data

624

complex data types

585–598, 625

cyber-physical system data

596

data streams

598

data types for

8

data warehouses for

154

database types and

32

descriptive

15

distributed

615, 624

efficiency

31

foundations, views on

600–601

functionalities

15–23, 34

graphs and networks

591–594

incremental

31

as information technology evolution

2–5

integration

623

interactive

30

as interdisciplinary effort

29–30

invisible

33, 618–620, 625

issues in

29–33, 34

in knowledge discovery

7

as knowledge search through data

6

machine learning similarities

26

methodologies

29–30, 585–607

motivation for

1–5

multidimensional

11–13, 26, 33–34, 155–156, 179, 227–230

multimedia data

596

OLAP and

154

as pattern/knowledge discovery process

8

predictive

15

presentation/visualization of results

31

privacy-preserving

32, 621–622, 624–625, 626

query languages

31

relational databases

10

scalability

31

sequence data

586

social impacts

32

society and

618–622

spatial data

595

spatiotemporal data and moving objects

595–596, 623–624

statistical

598

text data

596–597, 624

trends

622–625, 626

ubiquitous

618–620, 625

user interaction and

30–31

visual and audio

602–607, 624, 625

Web data

597–598, 624

data mining systems

10

data models

entity-relationship (ER)

9, 139

multidimensional

135–146

data objects

40, 79 similarity

40

terminology for

40

data preprocessing

83–124 cleaning

88–93

forms illustration

87

integration

93–99

overview

84–87

quality

84–85

reduction

99–111

in science applications

612

summary

87

tasks in

85–87

transformation

111–119

data quality

84, 120 accuracy

84

believability

85

completeness

84–85

consistency

85

interpretability

85

timeliness

85

data reduction

86, 99–111, 120 attribute subset selection

103–105

clustering

108

compression

100, 120

data cube aggregation

110–111

dimensionality

86, 99–100, 120

histograms

106–108

numerosity

86, 100, 120

parametric

105–106

principle components analysis

102–103

sampling

108

strategies

99–100

theory

601

wavelet transforms

100–102see alsodata preprocessing

data rich but information poor

5

data scrubbing tools

92

data security-enhancing techniques

621

data segmentation

445

data selection

8

data source view

151

data streams

14, 598, 624

data transformation

8, 87, 111–119, 120 aggregation

112

attribute construction

112

in back-end tools/utilities

134

concept hierarchy generation

112, 120

discretization

111, 112, 120

normalization

112, 113–115, 120

smoothing

112

strategies

112–113see alsodata preprocessing

data types

complex

166

complex, mining

585–598

for data mining

8

data validation

592–593

data visualization

56–65, 79, 602–603 complex data and relations

64–65

geometric projection techniques

58–60

hierarchical techniques

63–64

icon-based techniques

60–63

mining process

603

mining result

603, 605

pixel-oriented techniques

57–58

in science applications

613

summary

65

tag clouds

64, 66

techniques

39–40

data warehouses

10–13, 26, 33, 125–185 analytical processing

153

back-end tools/utilities

134, 178

basic concepts

125–135

bottom-up design approach

133, 151–152

business analysis framework for

150

business query view

151

combined design approach

152

data mart

132, 142

data mining

154

data source view

151

design process

151

development approach

133

development tools

153

dimensions

10

enterprise

132

extractors

151

fact constellation

141–142

for financial data

608

framework illustration

11

front-end client layer

132

gateways

131

geographic

595

implementation

156–165

information processing

153

integrated

126

metadata

134–135

modeling

10, 135–150

models

132–134

multitier

134

multitiered architecture

130–132

nonvolatile

127

OLAP server

132

operational database systems versus

128–129

planning and analysis tools

153

retail industry

609–610

in science applications

612

snowflake schema

140–141

star schema

139–140

subject-oriented

126

three-tier architecture

131, 178

time-variant

127

tools

11

top-down design approach

133, 151

top-down view

151

update-driven approach

128

usage for information processing

153

view

151

virtual

133

warehouse database server

131

database management systems (DBMSs)

9

database queries.

seequeries

databases

9 inductive

601

relational.

seerelational databases

research

26

statistical

148–149

technology evolution

3

transactional

13–15

types of

32

web-based

4

data/pattern analysis.

seedata mining

DBSCAN

471–473 algorithm illustration

474

core objects

472

density estimation

477

density-based cluster

472

density-connected

472, 473

density-reachable

472, 473

directly density-reachable

472

neighborhood density

471see alsocluster analysis; density-based methods

DDPMine

422

decimal scaling, normalization by

115

decision tree analysis, discretization by

116

decision tree induction

330–350, 385 algorithm differences

336

algorithm illustration

333

attribute selection measures

336–344

attribute subset selection

105

C4.5

332

CART

332

CHAID

343

gain ratio

340–341

Gini index

332, 341–343

ID3

332

incremental versions

336

information gain

336–340

multivariate splits

344

parameters

332

scalability and

347–348

splitting criterion

333

from training tuples

332–333

tree pruning

344–347, 385

visual mining for

348–350

decision trees

18, 330 branches

330

illustrated

331

internal nodes

330

leaf nodes

330

pruning

331, 344–347

root node

330

rule extraction from

357–359

deep web

597

default rules

357

DENCLUE

476–479 advantages

479

clusters

478

density attractor

478

density estimation

476

kernel density estimation

477–478

kernels

478see alsocluster analysis; density-based methods

dendrograms

460

densification power law

592

density estimation

476 DENCLUE

477–478

kernel function

477–478

density-based methods

449, 471–479, 491 DBSCAN

471–473

DENCLUE

476–479

object division

449

OPTICS

473–476

STING as

480see alsocluster analysis

density-based outlier detection

564–567 local outlier factor

566–567

local proximity

564

local reachability density

566

relative density

565

descendant cells

189

descriptive mining tasks

15

DIANA (Divisive Analysis)

459, 460

dice operation

148

differential privacy

622

dimension tables

136

dimensional cells

189

dimensionality reduction

86, 99–100, 120

dimensionality reduction methods

510, 519–522, 538 list of

587

spectral clustering

520–522

dimension/level

application of

297

constraints

294

dimensions

10, 136 association rule

281

cardinality of

159

concept hierarchies and

142–144

in multidimensional view

33

ordering of

210

pattern

281

ranking

225

relevance analysis

175

selection

225

shared

204see alsodata warehouses

direct discriminative pattern mining

422

directed acyclic graphs

394–395

discernibility matrix

427

discovery-driven exploration

231–234, 235

discrepancy detection

91–93

discrete attributes

44

discrete Fourier transform (DFT)

101, 587

discrete wavelet transform (DWT)

100–102, 587

discretization

112, 120 by binning

115

by clustering

116

by correlation analysis

117

by decision tree analysis

116

by histogram analysis

115–116

techniques

113

discriminant analysis

600

discriminant rules

16

discriminative frequent pattern-based classification

416, 419–422, 437 basis for

419

feature generation

420

feature selection

420–421

framework

420–421

learning of classification model

421

dispersion of data

44, 48–51

dissimilarity

asymmetric binary

71

between attributes of mixed type

76–77

between binary attributes

71–72

measuring

65–78, 79

between nominal attributes

69

on numeric data

72–74

between ordinal attributes

75

symmetric binary

70–71

dissimilarity matrix

67, 68 data matrix versus

67–68

n-by-n table representation

68

as one-mode matrix

68

distance measures

461–462 Euclidean

72–73

Manhattan

72–73

Minkowski

73

supremum

73–74

types of

72

distance-based cluster analysis

445

distance-based outlier detection

561–562 nested loop algorithm

561, 562see alsooutlier detection

distributed data mining

615, 624

distributed privacy preservation

622

distributions

boxplots for visualizing

49–50

five-number summary

49

distributive measures

145

Divisive Analysis (DIANA)

459, 460

divisive hierarchical method

459 agglomerative hierarchical clustering versus

459–460

DIANA

459, 460

DNA chips

512

document classification

430

documents

language model

26

topic model

26–27

drill-across operation

148

drill-down operation

11, 146–147

drill-through operation

148

dynamic itemset counting

256

E

eager learners

423, 437

Eclat (Equivalence Class Transformation) algorithm

260, 272

e-commerce

609

editing method

425

efficiency

Apriori algorithm

255–256

backpropagation

404

data mining algorithms

31

elbow method

486

email spam filtering

435

engineering applications

613

ensemble methods

378–379, 386 bagging

379–380

boosting

380–382

for class imbalance problem

385

random forests

382–383

types of

378, 386

enterprise warehouses

132

entity identification problem

94

entity-relationship (ER) data model

9, 139

epoch updating

404

equal-frequency histograms

107, 116

equal-width histograms

107, 116

equivalence classes

427

error rates

367

error-correcting codes

431–432

Euclidean distance

72 mathematical properties

72–73

weighted

74see alsodistance measures

evaluation metrics

364–370

evolution, of database system technology

3–5

evolutionary searches

579

exception-based, discovery-driven exploration

231–234, 235

exceptions

231

exhaustive rules

358

expectation-maximization (EM) algorithm

505–508, 538 expectation step (E-step)

505

fuzzy clustering with

505–507

maximization step (M-step)

505

for mixture models

507–508

for probabilistic model-based clustering

507–508

steps

505see alsoprobabilistic model-based clustering

expected values

97 cell

234

exploratory data mining.

seemultidimensional data mining

extraction

data

134

rule, from decision tree

357–359

extraction/transformation/loading (ETL) tools

93

extractors

151

F

fact constellation

141 example

141–142

illustrated

142

fact tables

136 summary

165

factor analysis

600

facts

136

false negatives

365

false positives

365

farthest-neighbor clustering algorithm

462

field overloading

92

financial data analysis

607–609 credit policy analysis

608–609

crimes detection

609

data warehouses

608

loan payment prediction

608–609

targeted marketing

609

FindCBLOF algorithm

569–570

five-number summary

49

fixed-width clustering

570

FOIL

359, 363, 418

Forest-RC

383

forward algorithm

591

FP-growth

257–259, 272 algorithm illustration

260

example

257–258

performance

259

FP-trees

257 condition pattern base

258

construction

257–258

main memory-based

259

mining

258, 259

Frag-Shells

212, 213

fraudulent analysis

610–611

frequency patterns

approximate

281, 307–312

compressed

281, 307–312

constraint-based

281

near-match

281

redundancy-aware top-k

281

top-k

281

frequent itemset mining

18, 272, 282 Apriori algorithm

248–253

closed patterns

262–264

market basket analysis

244–246

max patterns

262–264

methods

248–264

pattern-growth approach

257–259

with vertical data format

259–262, 272

frequent itemsets

243, 246, 272 association rule generation from

253, 254

closed

247, 248, 262–264, 308

finding

247

finding by confined candidate generation

248–253

maximal

247, 248, 262–264, 308

subsets

309

frequent pattern mining

279 advanced forms of patterns

320

application domain-specific semantics

282

applications

317–319, 321

approximate patterns

307–312

classification criteria

280–283

colossal patterns

301–307

compressed patterns

307–312

constraint-based

294–301, 320

data analysis usages

282

for data cleaning

318

direct discriminative

422

high-dimensional data

301–307

in high-dimensional space

320

in image data analysis

319

for indexing structures

319

kinds of data and features

282

multidimensional associations

287–289

in multilevel, multidimensional space

283–294

multilevel associations

283–294

in multimedia data analysis

319

negative patterns

291–294

for noise filtering

318

Pattern-Fusion

302–307

quantitative association rules

289–291

rare patterns

291–294

in recommender systems

319

road map

279–283

scalable computation and

319

scope of

319–320

in sequence or structural data analysis

319

in spatiotemporal data analysis

319

for structure and cluster discovery

318

for subspace clustering

318–319

in time-series data analysis

319

top-k

310

in video data analysis

319see alsofrequent patterns

frequent pattern-based classification

415–422, 437 associative

415, 416–419

discriminative

416, 419–422

framework

422

frequent patterns

17, 243 abstraction levels

281

association rule mapping

280

basic

280

closed

262–264, 280

concepts

243–244

constraint-based

281

dimensions

281

diversity

280

exploration

313–319

growth

257–259, 272

max

262–264, 280

mining

243–244, 279–325

mining constraints or criteria

281

number of dimensions involved in

281

semantic annotation of

313–317

sequential

243

strong associations

437

structured

243

trees

257–259

types of values in

281

frequent subgraphs

591

front-end client layer

132

full materialization

159, 179, 234

fuzzy clustering

499–501, 538 data set for

506

with EM algorithm

505–507

example

500

expectation step (E-step)

505

flexibility

501

maximization step (M-step)

506–507

partition matrix

499

as soft clusters

501

fuzzy logic

428

fuzzy sets

428–429, 437, 499 evaluation

500–501

example

499

G

gain ratio

340 C4.5 use of

340

formula

341

maximum

341

gateways

131

gene expression

513–514

generalization

attribute

169–170

attribute, control

170

attribute, threshold control

170

in multimedia data mining

596

process

172

results presentation

174

synchronous

175

generalized linear models

599–600

generalized relations

attribute-oriented induction

172

presentation of

174

threshold control

170

generative model

467–469

genetic algorithms

426–427, 437

genomes

15

geodesic distance

525–526, 539 diameter

525

eccentricity

525

measurements based on

526

peripheral vertex

525

radius

525

geographic data warehouses

595

geometric projection visualization

58–60

Gini index

341 binary enforcement

332

binary indexes

341

CART use of

341

decision tree induction using

342–343

minimum

342

partitioning and

342

global constants, for missing values

88

global outliers

545, 581 detection

545

example

545

Google

Flu Trends

2

popularity of

619–620

gradient descent strategy

396–397 algorithms

397

greedy hill-climbing

397

as iterative

396–397

graph and network data clustering

497, 522–532, 539 applications

523–525

bipartite graph

523

challenges

523–525, 530

cuts and clusters

529–530

generic method

530–531

geodesic distance

525–526

methods

528–532

similarity measures

525–528

SimRank

526–528

social network

524–525

web search engines

523–524see alsocluster analysis

graph cuts

539

graph data

14

graph index structures

591

graph pattern mining

591–592, 612–613

graphic displays

data presentation software

44–45

histogram

54, 55

quantile plot

51–52

quantile-quantile plot

52–54

scatter plot

54–56

greedy hill-climbing

397

greedy methods, attribute subset selection

104–105

grid-based methods

450, 479–483, 491 CLIQUE

481–483

STING

479–481see alsocluster analysis

grid-based outlier detection

562–564 CELL method

562, 563

cell properties

562

cell pruning rules

563see alsooutlier detection

group-based support

286

group-by clause

231

grouping attributes

231

grouping variables

231

Grubb' test

555

H

hamming distance

431

hard constraints

534, 539 example

534

handling

535–536

harmonic mean

369

hash-based technique

255

heterogeneous networks

592 classification of

593

clustering of

593

ranking of

593

heterogeneous transfer learning

436

hidden Markov model (HMM)

590, 591

hierarchical methods

449, 457–470, 491 agglomerative

459–461

algorithmic

459, 461–462

Bayesian

459

BIRCH

458, 462–466

Chameleon

458, 466–467

complete linkages

462, 463

distance measures

461–462

divisive

459–461

drawbacks

449

merge or split points and

458

probabilistic

459, 467–470

single linkages

462, 463see alsocluster analysis

hierarchical visualization

63 treemaps

63, 65

Worlds-with-Worlds

63, 64

high-dimensional data

301 clustering

447

data distribution of

560

frequent pattern mining

301–307

outlier detection in

576–580, 582

row enumeration

302

high-dimensional data clustering

497, 508–522, 538, 553 biclustering

512–519

dimensionality reduction methods

510, 519–522

example

508–509

problems, challenges, and methodologies

508–510

subspace clustering methods

509, 510–511see alsocluster analysis

HilOut algorithm

577–578

histograms

54, 106–108, 116 analysis by discretization

115–116

attributes

106

binning

106

construction

559

equal-frequency

107

equal-width

107

example

54

illustrated

55, 107

multidimensional

108

as nonparametric model

559

outlier detection using

558–560

holdout method

370, 386

holistic measures

145 homogeneous networks

592

classification of

593

clustering of

593

Hopkins statistic

484–485

horizontal data format

259

hybrid OLAP (HOLAP)

164–165, 179

hybrid-dimensional association rules

288

I

IBM Intelligent Miner

603, 606

iceberg condition

191

iceberg cubes

160, 179, 190, 235 BUC construction

201

computation

160, 193–194, 319

computation and storage

210–211

computation with Star-Cubing algorithm

204–210

materialization

319

specification of

190–191see alsodata cubes

icon-based visualization

60 Chernoff faces

60–61

stick figure technique

61–63see alsodata visualization

ID3

332, 385 greedy approach

332

information gain

336see alsodecision tree induction

IF-THEN rules

355–357 accuracy

356

conflict resolution strategy

356

coverage

356

default rule

357

extracting from decision tree

357

form

355

rule antecedent

355

rule consequent

355

rule ordering

357

satisfied

356

triggered

356

illustrated

149

image data analysis

319

imbalance problem

367

imbalance ratio (IR)

270 skewness

271

inconvertible constraints

300

incremental data mining

31

indexes

bitmapped join

163

composite join

162

Gini

332, 341–343

inverted

212, 213

indexing

bitmap

160–161, 179

bitmapped join

179

frequent pattern mining for

319

join

161–163, 179

OLAP

160–163

inductive databases

601

inferential statistics

24

information age, moving toward

1–2

information extraction systems

430

information gain

336–340 decision tree induction using

338–339

ID3 use of

336

pattern frequency support versus

421

single feature plot

420

split-point

340

information networks

analysis

592–593

evolution of

594

link prediction in

593–594

mining

623

OLAP in

594

role discovery in

593–594

similarity search in

594

information processing

153

information retrieval (IR)

26–27 challenges

27

language model

26

topic model

26–27

informativeness model

535

initial working relations

168, 169, 177

instance-based learners.

seelazy learners

instances, constraints on

533, 539

integrated data warehouses

126

integrators

127

intelligent query answering

618

interactive data mining

604, 607

interactive mining

30

intercuboid query expansion

221 example

224–225

method

223–224

interdimensional association rules

288

interestingness

21–23 assessment methods

23

components of

21

expected

22

objective measures

21–22

strong association rules

264–265

subjective measures

22

threshold

21–22

unexpected

22

interestingness constraints

294 application of

297

interpretability

backpropagation and

406–408

classification

369

cluster analysis

447

data

85

data quality and

85

probabilistic hierarchical clustering

469

interquartile range (IQR)

49, 555

interval-scaled attributes

43, 79

intracuboid query expansion

221 example

223

method

221–223

value usage

222

intradimensional association rules

287

intrusion detection

569–570 anomaly-based

614

data mining algorithms

614–615

discriminative classifiers

615

distributed data mining

615

signature-based

614

stream data analysis

615

visualization and query tools

615

inverted indexes

212, 213

invisible data mining

33, 618–620, 625

IQR.

seeInterquartile range

IR.

seeinformation retrieval

item merging

263

item skipping

263

items

13

itemsets

246 candidate

251, 252

dependent

266

dynamic counting

256

imbalance ratio (IR)

270, 271

negatively correlated

292

occurrence independence

266

strongly negatively correlated

292see alsofrequent itemsets

iterative Pattern-Fusion

306

iterative relocation techniques

448

J

Jaccard coefficient

71

join indexing

161–163, 179

K

k-anonymity method

621–622

Karush-Kuhn-Tucker (KKT) conditions

412

k-distance neighborhoods

565

kernel density estimation

477–478

kernel function

415

k-fold cross-validation

370–371

k-means

451–454 algorithm

452

application of

454

CLARANS

457

within-cluster variation

451, 452

clustering by

453

drawback of

454–455

functioning of

452

scalability

454

time complexity

453

variants

453–454

k-means clustering

536

k-medoids

454–457 absolute-error criterion

455

cost function for

456

PAM

455–457

k-nearest-neighbor classification

423 closeness

423

distance-based comparisons

425

editing method

425

missing values and

424

number of neighbors

424–425

partial distance method

425

speed

425

knowledge

background

30–31

mining

29

presentation

8

representation

33

transfer

434

knowledge bases

5, 8

knowledge discovery

data mining in

7

process

8

knowledge discovery from data (KDD)

6

knowledge extraction.

seedata mining

knowledge mining.

seedata mining

knowledge type constraints

294

k-predicate sets

289

Kulczynski measure

268, 272 negatively correlated pattern based on

293–294

L

language model

26

Laplacian correction

355

lattice of cuboids

139, 156, 179, 188–189, 234

lazy learners

393, 422–426, 437 case-based reasoning classifiers

425–426

k-nearest-neighbor classifiers

423–425

l-diversity method

622

learning

active

430, 433–434, 437

backpropagation

400

as classification step

328

connectionist

398

by examples

445

by observation

445

rate

397

semi-supervised

572

supervised

330

transfer

430, 434–436, 438

unsupervised

330, 445, 490

learning rates

403–404

leave-one-out

371

lift

266, 272 correlation analysis with

266–267

likelihood ratio statistic

363

linear regression

90, 105 multiple

106

linearly

412–413

linearly inseparable data

413–415

link mining

594

link prediction

594

load, in back-end tools/utilities

134

loan payment prediction

608–609

local outlier factor

566–567

local proximity-based outliers

564–565

logistic function

402

log-linear models

106

lossless compression

100

lossy compression

100

lower approximation

427

M

machine learning

24–26 active

25

data mining similarities

26

semi-supervised

25

supervised

24

unsupervised

25

Mahalanobis distance

556

majority voting

335

Manhattan distance

72–73

MaPle

519

margin

410

market basket analysis

244–246, 271–272 example

244

illustrated

244

Markov chains

591

materialization

full

159, 179, 234

iceberg cubes

319

no

159

partial

159–160, 192, 234

semi-offline

226

max patterns

280

max_confidence measure

268, 272

maximal frequent itemsets

247, 308 example

248

mining

262–264

shortcomings for compression

308–309

maximum marginal hyperplane (MMH)

409 SVM finding

412

maximum normed residual test

555

mean

39, 45 bin, smoothing by

89

example

45

for missing values

88

trimmed

46

weighted arithmetic

45

measures

145 accuracy-based

369

algebraic

145

all_confidence

272

antimonotonic

194

attribute selection

331

categories of

145

of central tendency

39, 44, 45–47

correlation

266

data cube

145

dispersion

48–51

distance

72–74, 461–462

distributive

145

holistic

145

Kulczynski

272

max_confidence

272

of multidimensional databases

146

null-invariant

272

pattern evaluation

267–271

precision

368–369

proximity

67, 68–72

recall

368–369

sensitivity

367

significance

312

similarity/dissimilarity

65–78

specificity

367

median

39, 46 bin, smoothing by

89

example

46

formula

46–47

for missing values

88

metadata

92, 134, 178 business

135

importance

135

operational

135

repositories

134–135

metarule-guided mining

of association rules

295–296

example

295–296

metrics

73 classification evaluation

364–370

microeconomic view

601

midrange

47

MineSet

603, 605

minimal interval size

116

minimal spanning tree algorithm

462

minimum confidence threshold

18, 245

Minimum Description Length (MDL)

343–344

minimum support threshold

18, 190 association rules

245

count

246

Minkowski distance

73

min-max normalization

114

missing values

88–89

mixed-effect models

600

mixture models

503, 538 EM algorithm for

507–508

univariate Gaussian

504

mode

39, 47 example

47

model selection

364 with statistical tests of significance

372–373

models

18

modularity

of clustering

530

use of

539

MOLAP.

seemultidimensional OLAP

monotonic constraints

298

motifs

587

moving-object data mining

595–596, 623–624

multiclass classification

430–432, 437 all-versus-all (AVA)

430–431

error-correcting codes

431–432

one-versus-all (OVA)

430

multidimensional association rules

17, 283, 288, 320 hybrid-dimensional

288

interdimensional

288

mining

287–289

mining with static discretization of quantitative attributes

288

with no repeated predicates

288see alsoassociation rules

multidimensional data analysis

in cube space

227–234

in multimedia data mining

596

spatial

595

of top-k results

226

multidimensional data mining

11–13, 34, 155–156, 179, 187, 227, 235 data cube promotion of

26

dimensions

33

example

228–229

retail industry

610

multidimensional data model

135–146, 178 data cube as

136–139

dimension table

136

dimensions

142–144

fact constellation

141–142

fact table

136

snowflake schema

140–141

star schema

139–140

multidimensional databases

measures of

146

querying with starnet model

149–150

multidimensional histograms

108

multidimensional OLAP (MOLAP)

132, 164, 179

multifeature cubes

227, 230, 235 complex query support

231

examples

230–231

multilayer feed-forward neural networks

398–399 example

405

illustrated

399

layers

399

units

399

multilevel association rules

281, 283, 284, 320 ancestors

287

concept hierarchies

285

dimensions

281

group-based support

286

mining

283–287

reduced support

285, 286

redundancy, checking

287

uniform support

285–286

multimedia data

14

multimedia data analysis

319

multimedia data mining

596

multimodal

47

multiple linear regression

90, 106

multiple sequence alignment

590

multiple-phase clustering

458–459

multitier data warehouses

134

multivariate outlier detection

556 with Mahalanobis distance

556

with multiple clusters

557

with multiple parametric distributions

557

with χ2-static

556

multiway array aggregation

195, 235 for full cube computation

195–199

minimum memory requirements

198

must-link constraints

533, 536

mutation operator

426

mutual information

315–316

mutually exclusive rules

358

N

naive Bayesian classification

385 class label prediction with

353–355

functioning of

351–352

nearest-neighbor clustering algorithm

461

near-match patterns/rules

281

negative correlation

55, 56

negative patterns

280, 283, 320 example

291–292

mining

291–294

negative transfer

436

negative tuples

364

negatively skewed data

47

neighborhoods

density

471

distance-based outlier detection

560

k-distance

565

nested loop algorithm

561, 562

networked data

14

networks

592 heterogeneous

592, 593

homogeneous

592, 593

information

592–594

mining in science applications

612–613

social

592

statistical modeling of

592–594

neural networks

19, 398 backpropagation

398–408

as black boxes

406

for classification

19, 398

disadvantages

406

fully connected

399, 406–407

learning

398

multilayer feed-forward

398–399

pruning

406–407

rule extraction algorithms

406, 407

sensitivity analysis

408

three-layer

399

topology definition

400

two-layer

399

neurodes

399

Ng-Jordan-Weiss algorithm

521, 522

no materialization

159

noise filtering

318

noisy data

89–91

nominal attributes

41 concept hierarchies for

284

correlation analysis

95–96

dissimilarity between

69

example

41

proximity measures

68–70

similarity computation

70

values of

79, 288see alsoattributes

nonlinear SVMs

413–415

nonparametric statistical methods

553–558

nonvolatile data warehouses

127

normalization

112, 120 data transformation by

113–115

by decimal scaling

115

min-max

114

z-score

114–115

null rules

92

null-invariant measures

270–271, 272

null-transactions

270, 272 number of

270

problem

292–293

numeric attributes

43–44, 79 covariance analysis

98

interval-scaled

43, 79

ratio-scaled

43–44, 79

numeric data, dissimilarity on

72–74

numeric prediction

328, 385 classification

328

support vector machines (SVMs) for

408

numerosity reduction

86, 100, 120 techniques

100

O

object matching

94

objective interestingness measures

21–22

one-class model

571–572

one-pass cube computation

198

one-versus-all (OVA)

430

online analytical mining (OLAM)

155, 227

online analytical processing (OLAP)

4, 33, 128, 179 access patterns

129

data contents

128

database design

129

dice operation

148

drill-across operation

148

drill-down operation

11, 135–136, 146

drill-through operation

148

example operations

147

functionalities of

154

hybrid OLAP

164–165, 179

indexing

125, 160–163

in information networks

594

in knowledge discovery process

125

market orientation

128

multidimensional (MOLAP)

132, 164, 179

OLTP versus

128–129, 130

operation integration

125

operations

146–148

pivot (rotate) operation

148

queries

129, 130, 163–164

query processing

125, 163–164

relational OLAP

132, 164, 165, 179

roll-up operation

11, 135–136, 146

sample data effectiveness

219

server architectures

164–165

servers

132

slice operation

148

spatial

595

statistical databases versus

148–149

user-control versus automation

167

view

129

online transaction processing (OLTP)

128 access patterns

129

customer orientation

128

data contents

128

database design

129

OLAP versus

128–129, 130

view

129

operational metadata

135

OPTICS

473–476 cluster ordering

474–475, 477

core-distance

475

density estimation

477

reachability-distance

475

structure

476

terminology

476see alsocluster analysis; density-based methods

ordered attributes

103

ordering

class-based

358

dimensions

210

rule

357

ordinal attributes

42, 79 dissimilarity between

75

example

42

proximity measures

74–75

outlier analysis

20–21 clustering-based techniques

66

example

21

in noisy data

90

spatial

595

outlier detection

543–584 angle-based (ABOD)

580

application-specific

548–549

categories of

581

CELL method

562–563

challenges

548–549

clustering analysis and

543

clustering for

445

clustering-based methods

552–553, 560–567

collective

548, 575–576

contextual

546–547, 573–575

distance-based

561–562

extending

577–578

global

545

handling noise in

549

in high-dimensional data

576–580, 582

with histograms

558–560

intrusion detection

569–570

methods

549–553

mixture of parametric distributions

556–558

multivariate

556

novelty detection relationship

545

proximity-based methods

552, 560–567, 581

semi-supervised methods

551

statistical methods

552, 553–560, 581

supervised methods

549–550

understandability

549

univariate

554

unsupervised methods

550

outlier subgraphs

576

outliers

angle-based

20, 543, 544, 580

collective

547–548, 581

contextual

545–547, 573, 581

density-based

564

distance-based

561

example

544

global

545, 581

high-dimensional, modeling

579–580

identifying

49

interpretation of

577

local proximity-based

564–565

modeling

548

in small clusters

571

types of

545–548, 581

visualization with boxplot

555

oversampling

384, 386 example

384–385

P

pairwise alignment

590

pairwise comparison

372

PAM.

seePartitioning Around Medoids algorithm

parallel and distributed data-intensive mining algorithms

31

parallel coordinates

59, 62

parametric data reduction

105–106

parametric statistical methods

553–558

Pareto distribution

592

partial distance method

425

partial materialization

159–160, 179, 234 strategies

192

partition matrix

538

partitioning

algorithms

451–457

in Apriori efficiency

255–256

bootstrapping

371, 386

criteria

447

cross-validation

370–371, 386

Gini index and

342

holdout method

370, 386

random sampling

370, 386

recursive

335

tuples

334

Partitioning Around Medoids (PAM) algorithm

455–457

partitioning methods

448, 451–457, 491 centroid-based

451–454

global optimality

449

iterative relocation techniques

448

k-means

451–454

k-medoids

454–457

k-modes

454

object-based

454–457see alsocluster analysis

path-based similarity

594

pattern analysis, in recommender systems

282

pattern clustering

308–310

pattern constraints

297–300

pattern discovery

601

pattern evaluation

8

pattern evaluation measures

267–271 all_confidence

268

comparison

269–270

cosine

268

Kulczynski

268

max_confidence

268

null-invariant

270–271see alsomeasures

pattern space pruning

295

pattern-based classification

282, 318

pattern-based clustering

282, 516

Pattern-Fusion

302–307 characteristics

304

core pattern

304–305

initial pool

306

iterative

306

merging subpatterns

306

shortcuts identification

304see alsocolossal patterns

pattern-guided mining

30

patterns

actionable

22

co-location

319

colossal

301–307, 320

combined significance

312

constraint-based generation

296–301

context modeling of

314–315

core

304–305

distance

309

evaluation methods

264–271

expected

22

expressed

309

frequent

17

hidden meaning of

314

interesting

21–23, 33

metric space

306–307

negative

280, 291–294, 320

negatively correlated

292, 293

rare

280, 291–294, 320

redundancy between

312

relative significance

312

representative

309

search space

303

strongly negatively correlated

292

structural

282

type specification

15–23

unexpected

22see alsofrequent patterns

pattern-trees

264

Pearson' correlation coefficient

222

percentiles

48

perception-based classification (PBC)

348 illustrated

349

as interactive visual approach

607

pixel-oriented approach

348–349

split screen

349

tree comparison

350

phylogenetic trees

590

pivot (rotate) operation

148

pixel-oriented visualization

57

planning and analysis tools

153

point queries

216, 217, 220

pool-based approach

433

positive correlation

55, 56

positive tuples

364

positively skewed data

47

possibility theory

428

posterior probability

351

postpruning

344–345, 346

power law distribution

592

precision measure

368–369

predicate sets

frequent

288–289

k

289

predicates

repeated

288

variables

295

prediction

19 classification

328

link

593–594

loan payment

608–609

with naive Bayesian classification

353–355

numeric

328, 385

prediction cubes

227–230, 235 example

228–229

Probability-Based Ensemble

229–230

predictive analysis

18–19

predictive mining tasks

15

predictive statistics

24

predictors

328

prepruning

344, 346

prime relations

contrasting classes

175, 177

deriving

174

target classes

175, 177

principle components analysis (PCA)

100, 102–103 application of

103

correlation-based clustering with

511

illustrated

103

in lower-dimensional space extraction

578

procedure

102–103

prior probability

351

privacy-preserving data mining

33, 621, 626 distributed

622

k-anonymity method

621–622

l-diversity method

622

as mining trend

624–625

randomization methods

621

results effectiveness, downgrading

622

probabilistic clusters

502–503

probabilistic hierarchical clustering

467–470 agglomerative clustering framework

467, 469

algorithm

470

drawbacks of using

469–470

generative model

467–469

interpretability

469

understanding

469see alsohierarchical methods

probabilistic model-based clustering

497–508, 538 expectation-maximization algorithm

505–508

fuzzy clusters and

499–501

product reviews example

498

user search intent example

498see alsocluster analysis

probability

estimation techniques

355

posterior

351

prior

351

probability and statistical theory

601

Probability-Based Ensemble (PBE)

229–230

PROCLUS

511

profiles

614

proximity measures

67 for binary attributes

70–72

for nominal attributes

68–70

for ordinal attributes

74–75

proximity-based methods

552, 560–567, 581 density-based

564–567

distance-based

561–562

effectiveness

552

example

552

grid-based

562–564

types of

552, 560see alsooutlier detection

pruning

cost complexity algorithm

345

data space

300–301

decision trees

331, 344–347

in k-nearest neighbor classification

425

network

406–407

pattern space

295, 297–300

pessimistic

345

postpruning

344–345, 346

prepruning

344, 346

rule

363

search space

263, 301

sets

345

shared dimensions

205

sub-itemset

263

pyramid algorithm

101

Q

quality control

600

quantile plots

51–52

quantile-quantile plots

52 example

53–54

illustrated

53see alsographic displays

quantitative association rules

281, 283, 288, 320 clustering-based mining

290–291

data cube-based mining

289–290

exceptional behavior disclosure

291

mining

289

quartiles

48 first

49

third

49

queries

10 intercuboid expansion

223–225

intracuboid expansion

221–223

language

10

OLAP

129, 130

point

216, 217, 220

processing

163–164, 218–227

range

220

relational operations

10

subcube

216, 217–218

top-k

225–227

query languages

31

query models

149–150

query-driven approach

128

querying function

433

R

rag bag criterion

488

RainForest

385

random forests

382–383

random sampling

370, 386

random subsampling

370

random walk

526 similarity based on

527

randomization methods

621

range

48 interquartile

49

range queries

220

ranking

cubes

225–227, 235

dimensions

225

function

225

heterogeneous networks

593

rare patterns

280, 283, 320 example

291–292

mining

291–294

ratio-scaled attributes

43–44, 79

reachability density

566

reachability distance

565

recall measure

368–369

recognition rate

366–367

recommender systems

282, 615 advantages

616

biclustering for

514–515

challenges

617

collaborative

610, 615, 616, 617, 618

content-based approach

615, 616

data mining and

615–618

error types

617–618

frequent pattern mining for

319

hybrid approaches

618

intelligent query answering

618

memory-based methods

617

use scenarios

616

recursive partitioning

335

reduced support

285, 286

redundancy

in data integration

94

detection by correlations analysis

94–98

redundancy-aware top-k patterns

281, 311, 320 extracting

310–312

finding

312

strategy comparison

311–312

trade-offs

312

refresh, in back-end tools/utilities

134

regression

19, 90 coefficients

105–106

example

19

linear

90, 105–106

in statistical data mining

599

regression analysis

19, 328 in time-series data

587–588

relational databases

9 components of

9

mining

10

relational schema for

10

relational OLAP (ROLAP)

132, 164, 165, 179

relative significance

312

relevance analysis

19

repetition

346

replication

347 illustrated

346

representative patterns

309

retail industry

609–611

RIPPER

359, 363

robustness, classification

369

ROC curves

374, 386 classification models

377

classifier comparison with

373–377

illustrated

376, 377

plotting

375

roll-up operation

11, 146

rough set approach

428–429, 437

row enumeration

302

rule ordering

357

rule pruning

363

rule quality measures

361–363

rule-based classification

355–363, 386 IF-THEN rules

355–357

rule extraction

357–359

rule induction

359–363

rule pruning

363

rule quality measures

361–363

rules for constraints

294

S

sales campaign analysis

610

samples

218 cluster

108–109

data

219

simple random

108

stratified

109–110

sampling

in Apriori efficiency

256

as data redundancy technique

108–110

methods

108–110

oversampling

384–385

random

386

with replacement

380–381

uncertainty

433

undersampling

384–385

sampling cubes

218–220, 235 confidence interval

219–220

framework

219–220

query expansion with

221

SAS Enterprise Miner

603, 604

scalability

classification

369

cluster analysis

446

cluster methods

445

data mining algorithms

31

decision tree induction and

347–348

dimensionality and

577

k-means

454

scalable computation

319

SCAN.

seeStructural Clustering Algorithm for Networks

core vertex

531

illustrated

532

scatter plots

54 2-D data set visualization with

59

3-D data set visualization with

60

correlations between attributes

54–56

illustrated

55

matrix

56, 59

schemas

integration

94

snowflake

140–141

star

139–140

science applications

611–613

search engines

28

search space pruning

263, 301

second guess heuristic

369

selection dimensions

225

self-training

432

semantic annotations

applications

317, 313, 320–321

with context modeling

316

from DBLP data set

316–317

effectiveness

317

example

314–315

of frequent patterns

313–317

mutual information

315–316

task definition

315

Semantic Web

597

semi-offline materialization

226

semi-supervised classification

432–433, 437 alternative approaches

433

cotraining

432–433

self-training

432

semi-supervised learning

25 outlier detection by

572

semi-supervised outlier detection

551

sensitivity analysis

408

sensitivity measure

367

sentiment classification

434

sequence data analysis

319

sequences

586 alignment

590

biological

586, 590–591

classification of

589–590

similarity searches

587

symbolic

586, 588–590

time-series

586, 587–588

sequential covering algorithm

359 general-to-specific search

360

greedy search

361

illustrated

359

rule induction with

359–361

sequential pattern mining

589 constraint-based

589

in symbolic sequences

588–589

shapelets method

590

shared dimensions

204 pruning

205

shared-sorts

193

shared-partitions

193

shell cubes

160

shell fragments

192, 235 approach

211–212

computation algorithm

212, 213

computation example

214–215

precomputing

210

shrinking diameter

592

sigmoid function

402

signature-based detection

614

significance levels

373

significance measure

312

significance tests

372–373, 386

silhouette coefficient

489–490

similarity

asymmetric binary

71

cosine

77–78

measuring

65–78, 79

nominal attributes

70

similarity measures

447–448, 525–528 constraints on

533

geodesic distance

525–526

SimRank

526–528

similarity searches

587 in information networks

594

in multimedia data mining

596

simple random sample with replacement (SRSWR)

108

simple random sample without replacement (SRSWOR)

108

SimRank

526–528, 539 computation

527–528

random walk

526–528

structural context

528

simultaneous aggregation

195

single-dimensional association rules

17, 287

single-linkage algorithm

460, 461

singular value decomposition (SVD)

587

skewed data

balanced

271

negatively

47

positively

47

wavelet transforms on

102

slice operation

148

small-world phenomenon

592

smoothing

112 by bin boundaries

89

by bin means

89

by bin medians

89

for data discretization

90

snowflake schema

140 example

141

illustrated

141

star schema versus

140

social networks

524–525, 526–528 densification power law

592

evolution of

594

mining

623

small-world phenomenon

592see alsonetworks

social science/social studies data mining

613

soft clustering

501

soft constraints

534, 539 example

534

handling

536–537

space-filling curve

58

sparse data

102

sparse data cubes

190

sparsest cuts

539

sparsity coefficient

579

spatial data

14

spatial data mining

595

spatiotemporal data analysis

319

spatiotemporal data mining

595, 623–624

specialized SQL servers

165

specificity measure

367

spectral clustering

520–522, 539 effectiveness

522

framework

521

steps

520–522

speech recognition

430

speed, classification

369

spiral method

152

split-point

333, 340, 342

splitting attributes

333

splitting criterion

333, 342

splitting rules.

seeattribute selection measures

splitting subset

333

SQL, as relational query language

10

square-error function

454

squashing function

403

standard deviation

51 example

51

function of

50

star schema

139 example

139–140

illustrated

140

snowflake schema versus

140

Star-Cubing

204–210, 235 algorithm illustration

209

bottom-up computation

205

example

207

for full cube computation

210

ordering of dimensions and

210

performance

210

shared dimensions

204–205

starnet query model

149 example

149–150

star-nodes

205

star-trees

205 compressed base table

207

construction

205

statistical data mining

598–600 analysis of variance

600

discriminant analysis

600

factor analysis

600

generalized linear models

599–600

mixed-effect models

600

quality control

600

regression

599

survival analysis

600

statistical databases (SDBs)

148 OLAP systems versus

148–149

statistical descriptions

24, 79 graphic displays

44–45, 51–56

measuring the dispersion

48–51

statistical hypothesis test

24

statistical models

23–24 of networks

592–594

statistical outlier detection methods

552, 553–560, 581 computational cost of

560

for data analysis

625

effectiveness

552

example

552

nonparametric

553, 558–560

parametric

553–558see alsooutlier detection

statistical theory, in exceptional behavior disclosure

291

statistics

23 inferential

24

predictive

24

StatSoft

602, 603

stepwise backward elimination

105

stepwise forward selection

105

stick figure visualization

61–63

STING

479–481 advantages

480–481

as density-based clustering method

480

hierarchical structure

479, 480

multiresolution approach

481see alsocluster analysis; grid-based methods

stratified cross-validation

371

stratified samples

109–110

stream data

598, 624

strong association rules

272 interestingness and

264–265

misleading

265

Structural Clustering Algorithm for Networks (SCAN)

531–532

structural context-based similarity

526

structural data analysis

319

structural patterns

282

structure similarity search

592

structures

as contexts

575

discovery of

318

indexing

319

substructures

243

Student' t-test

372

subcube queries

216, 217–218

sub-itemset pruning

263

subjective interestingness measures

22

subject-oriented data warehouses

126

subsequence

589 matching

587

subset checking

263–264

subset testing

250

subspace clustering

448 frequent patterns for

318–319

subspace clustering methods

509, 510–511, 538 biclustering

511

correlation-based

511

examples

538

subspace search methods

510–511

subspaces

bottom-up search

510–511

cube space

228–229

outliers in

578–579

top-down search

511

substitution matrices

590

substructures

243

sum of the squared error (SSE)

501

summary fact tables

165

superset checking

263

supervised learning

24, 330

supervised outlier detection

549–550 challenges

550

support

21 association rule

21

group-based

286

reduced

285, 286

uniform

285–286

support, rule

245, 246

support vector machines (SVMs)

393, 408–415, 437 interest in

408

maximum marginal hyperplane

409, 412

nonlinear

413–415

for numeric prediction

408

with sigmoid kernel

415

support vectors

411

for test tuples

412–413

training/testing speed improvement

415

support vectors

411, 437 illustrated

411

SVM finding

412

supremum distance

73–74

surface web

597

survival analysis

600

SVMs.

seesupport vector machines

symbolic sequences

586, 588 applications

589

sequential pattern mining in

588–589

symmetric binary dissimilarity

70

synchronous generalization

175

T

tables

9 attributes

9

contingency

95

dimension

136

fact

165

tuples

9

tag clouds

64, 66

Tanimoto coefficient

78

target classes

15, 180 initial working relations

177

prime relation

175, 177

targeted marketing

609

taxonomy formation

20

technologies

23–27, 33, 34

telecommunications industry

611

temporal data

14

term-frequency vectors

77 cosine similarity between

78

sparse

77

table

77

terminating conditions

404

test sets

330

test tuples

330

text data

14

text mining

596–597, 624

theoretical foundations

600–601, 625

three-layer neural networks

399

threshold-moving approach

385

tilted time windows

598

timeliness, data

85

time-series data

586, 587 cyclic movements

588

discretization and

590

illustrated

588

random movements

588

regression analysis

587–588

seasonal variations

588

shapelets method

590

subsequence matching

587

transformation into aggregate approximations

587

trend analysis

588

trend or long-term movements

588

time-series data analysis

319

time-series forecasting

588

time-variant data warehouses

127

top-down design approach

133, 151

top-down subspace search

511

top-down view

151

topic model

26–27

top-k patterns/rules

281

top-k queries

225 example

225–226

ranking cubes to answer

226–227

results

225

user-specified preference components

225

top-k strategies

comparison illustration

311

summarized pattern

311

traditional

311

TrAdaBoost

436

training

Bayesian belief networks

396–397

data

18

sets

328

tuples

332–333

transaction reduction

255

transactional databases

13 example

13–14

transactions, components of

13

transfer learning

430, 435, 434–436, 438 applications

435

approaches to

436

heterogeneous

436

negative transfer and

436

target task

435

traditional learning versus

435

treemaps

63, 65

trend analysis

spatial

595

in time-series data

588

for time-series forecasting

588

trends, data mining

622–625, 626

triangle inequality

73

trimmed mean

46

trimodal

47

true negatives

365

true positives

365

t-test

372

tuples

9 duplication

98–99

negative

364

partitioning

334, 337

positive

364

training

332–333

two sample t-test

373

two-layer neural networks

399

two-level hash index structure

264

U

ubiquitous data mining

618–620, 625

uncertainty sampling

433

undersampling

384, 386 example

384–385

uniform support

285–286

unimodal

47

unique rules

92

univariate distribution

40

univariate Gaussian mixture model

504

univariate outlier detection

554–555

unordered attributes

103

unordered rules

358

unsupervised learning

25, 330, 445, 490 clustering as

25, 445, 490

example

25

supervised learning versus

330

unsupervised outlier detection

550 assumption

550

clustering methods acting as

551

upper approximation

427

user interaction

30–31

V

values

exception

234

expected

97, 234

missing

88–89

residual

234

in rules or patterns

281

variables

grouping

231

predicate

295

predictor

105

response

105

variance

51, 98 example

51

function of

50

variant graph patterns

591

version space

433

vertical data format

260 example

260–262

frequent itemset mining with

259–262, 272

video data analysis

319

virtual warehouses

133

visibility graphs

537

visible points

537

visual data mining

602–604, 625 data mining process visualization

603

data mining result visualization

603

data visualization

602–603

as discipline integration

602

illustrations

604–607

interactive

604, 607

as mining trend

624

Viterbi algorithm

591

W

warehouse database servers

131

warehouse refresh software

151

waterfall method

152

wavelet coefficients

100

wavelet transforms

99, 100–102 discrete (DWT)

100–102

for multidimensional data

102

on sparse and skewed data

102

web directories

28

web mining

597, 624 content

597

as mining trend

624

structure

597–598

usage

598

web search engines

28, 523–524

web-document classification

435

weight arithmetic mean

46

weighted Euclidean distance

74

Wikipedia

597

WordNet

597

working relations

172 initial

168, 169

World Wide Web (WWW)

1–2, 4, 14

Worlds-with-Worlds

63, 64

wrappers

127

Z

z-score normalization

114–115

