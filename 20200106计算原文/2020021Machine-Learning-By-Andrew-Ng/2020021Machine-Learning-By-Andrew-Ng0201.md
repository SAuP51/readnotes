1.1 训练，验证，测试集（Train / Dev / Test sets）

大家可能已经了解了，那么本周，我们将继续学习如何有效运作神经网络，内容涉及超 参数调优，如何构建数据，以及如何确保优化算法快速运行，从而使学习算法在合理时间内 完成自我学习。

第一周，我们首先说说神经网络机器学习中的问题，然后是随机神经网络，还会学习一 些确保神经网络正确运行的技巧，带着这些问题，我们开始今天的课程。

在配置训练、验证和测试数据集的过程中做出正确决策会在很大程度上帮助大家创建高 效的神经网络。训练神经网络时，我们需要做出很多决策，例如：

神经网络分多少层；每层含有多少个隐藏单元；学习速率是多少；各层采用哪些激活函 数。

124 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

创建新应用的过程中，我们不可能从一开始就准确预测出这些信息和其他超级参数。实 际上，应用型机器学习是一个高度迭代的过程，通常在项目启动时，我们会先有一个初步想 法，比如构建一个含有特定层数，隐藏单元数量或数据集个数等等的神经网络，然后编码，并尝试运行这些代码，通过运行和测试得到该神经网络或这些配置信息的运行结果，你可能 会根据输出结果重新完善自己的想法，改变策略，或者为了找到更好的神经网络不断迭代更 新自己的方案。

现如今，深度学习已经在自然语言处理，计算机视觉，语音识别以及结构化数据应用等 众多领域取得巨大成功。结构化数据无所不包，从广告到网络搜索。其中网络搜索不仅包括 网络搜索引擎，还包括购物网站，从所有根据搜索栏词条传输结果的网站。再到计算机安全，物流，比如判断司机去哪接送货，范围之广，不胜枚举。

我发现，可能有自然语言处理方面的人才想踏足计算机视觉领域，或者经验丰富的语音 识别专家想投身广告行业，又或者，有的人想从电脑安全领域跳到物流行业，在我看来，从 一个领域或者应用领域得来的直觉经验，通常无法转移到其他应用领域，最佳决策取决于你 所拥有的数据量，计算机配置中输入特征的数量，用 GPU 训练还是 CPU，GPU 和 CPU 的具 体配置以及其他诸多因素。

目前为止，我觉得，对于很多应用系统，即使是经验丰富的深度学习行家也不太可能一 开始就预设出最匹配的超级参数，所以说，应用深度学习是一个典型的迭代过程，需要多次 循环往复，才能为应用程序找到一个称心的神经网络，因此循环该过程的效率是决定项目进 展速度的一个关键因素，而创建高质量的训练数据集，验证集和测试集也有助于提高循环效 率。

假设这是训练数据，我用一个长方形表示，我们通常会将这些数据划分成几部分，一部 分作为训练集，一部分作为简单交叉验证集，有时也称之为验证集，方便起见，我就叫它验

125 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

证集（dev set），其实都是同一个概念，最后一部分则作为测试集。接下来，我们开始对训练执行算法，通过验证集或简单交叉验证集选择最好的模型，经 过充分验证，我们选定了最终模型，然后就可以在测试集上进行评估了，为了无偏评估算法 的运行状况。

在机器学习发展的小数据量时代，常见做法是将所有数据三七分，就是人们常说的 70% 验证集，30% 测试集，如果没有明确设置验证集，也可以按照 60% 训练，20% 验证和 20% 测 试集来划分。这是前几年机器学习领域普遍认可的最好的实践方法。

如果只有 100 条，1000 条或者 1 万条数据，那么上述比例划分是非常合理的。但是在大数据时代，我们现在的数据量可能是百万级别，那么验证集和测试集占数据总 量的比例会趋向于变得更小。因为验证集的目的就是验证不同的算法，检验哪种算法更有效，因此，验证集要足够大才能评估，比如 2 个甚至 10 个不同算法，并迅速判断出哪种算法更 有效。我们可能不需要拿出 20% 的数据作为验证集。

比如我们有 100 万条数据，那么取 1 万条数据便足以进行评估，找出其中表现最好的 12 种算法。同样地，根据最终选择的分类器，测试集的主要目的是正确评估分类器的性能，所以，如果拥有百万数据，我们只需要 1000 条数据，便足以评估单个分类器，并且准确评

126 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

估该分类器的性能。假设我们有 100 万条数据，其中 1 万条作为验证集，1 万条作为测试集，100 万里取 1 万，比例是 1%，即：训练集占 98%，验证集和测试集各占 1%。对于数据量过 百万的应用，训练集可以占到 99.5%，验证和测试集各占 0.25%，或者验证集占 0.4%，测试 集占 0.1%。

总结一下，在机器学习中，我们通常将样本分成训练集，验证集和测试集三部分，数据 集规模相对较小，适用传统的划分比例，数据集规模较大的，验证集和测试集要小于数据总 量的 20% 或 10%。后面我会给出如何划分验证集和测试集的具体指导。

现代深度学习的另一个趋势是越来越多的人在训练和测试集分布不匹配的情况下进行 训练，假设你要构建一个用户可以上传大量图片的应用程序，目的是找出并呈现所有猫咪图 片，可能你的用户都是爱猫人士，训练集可能是从网上下载的猫咪图片，而验证集和测试集 是用户在这个应用上上传的猫的图片，就是说，训练集可能是从网络上抓下来的图片。而验 证集和测试集是用户上传的图片。结果许多网页上的猫咪图片分辨率很高，很专业，后期制 作精良，而用户上传的照片可能是用手机随意拍摄的，像素低，比较模糊，这两类数据有所 不同，针对这种情况，根据经验，我建议大家要确保验证集和测试集的数据来自同一分布，关于这个问题我也会多讲一些。因为你们要用验证集来评估不同的模型，尽可能地优化性能。如果验证集和测试集来自同一个分布就会很好。

但由于深度学习算法需要大量的训练数据，为了获取更大规模的训练数据集，我们可以 采用当前流行的各种创意策略，例如，网页抓取，代价就是训练集数据与验证集和测试集数 据有可能不是来自同一分布。但只要遵循这个经验法则，你就会发现机器学习算法会变得更 快。我会在后面的课程中更加详细地解释这条经验法则。

最后一点，就算没有测试集也不要紧，测试集的目的是对最终所选定的神经网络系统做 出无偏估计，如果不需要无偏估计，也可以不设置测试集。所以如果只有验证集，没有测试 集，我们要做的就是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。因为验证集中已经涵盖测试集数据，其不再提供无偏性能评估。

127 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

当然，如果你不需要无偏估计，那就再好不过了。

在机器学习中，如果只有一个训练集和一个验证集，而没有独立的测试集，遇到这种情 况，训练集还被人们称为训练集，而验证集则被称为测试集，不过在实际应用中，人们只是 把测试集当成简单交叉验证集使用，并没有完全实现该术语的功能，因为他们把验证集数据 过度拟合到了测试集中。如果某团队跟你说他们只设置了一个训练集和一个测试集，我会很 谨慎，心想他们是不是真的有训练验证集，因为他们把验证集数据过度拟合到了测试集中，让这些团队改变叫法，改称其为「训练验证集」，而不是「训练测试集」，可能不太容易。即便 我认为「训练验证集「在专业用词上更准确。实际上，如果你不需要无偏评估算法性能，那么 这样是可以的。

所以说，搭建训练验证集和测试集能够加速神经网络的集成，也可以更有效地衡量算法 地偏差和方差，从而帮助我们更高效地选择合适方法来优化算法。

128 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.2 偏差，方差（Bias /Variance）

我注意到，几乎所有机器学习从业人员都期望深刻理解偏差和方差，这两个概念易学难 精，即使你自己认为已经理解了偏差和方差的基本概念，却总有一些意想不到的新东西出现。关于深度学习的误差问题，另一个趋势是对偏差和方差的权衡研究甚浅，你可能听说过这两 个概念，但深度学习的误差很少权衡二者，我们总是分别考虑偏差和方差，却很少谈及偏差 和方差的权衡问题，下面我们来一探究竟。

假设这就是数据集，如果给这个数据集拟合一条直线，可能得到一个逻辑回归拟合，但 它并不能很好地拟合该数据，这是高偏差（high bias）的情况，我们称为「欠拟合」（underfitting）。

相反的如果我们拟合一个非常复杂的分类器，比如深度神经网络或含有隐藏单元的神经 网络，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式分类器方差 较高（high variance），数据过度拟合（overfitting）。

在两者之间，可能还有一些像图中这样的，复杂程度适中，数据拟合适度的分类器，这 个数据拟合看起来更加合理，我们称之为「适度拟合」（just right）是介于过度拟合和欠拟合 中间的一类。

在这样一个只有𝑥 1 和𝑥 2 两个特征的二维数据集中，我们可以绘制数据，将偏差和方差可 视化。在多维空间数据中，绘制数据和可视化分割边界无法实现，但我们可以通过几个指标，

129 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

来研究偏差和方差。

我们沿用猫咪图片分类这个例子，左边一张是猫咪图片，右边一张不是。理解偏差和方 差的两个关键数据是训练集误差（Train set error）和验证集误差（Dev set error），为了方便 论证，假设我们可以辨别图片中的小猫，我们用肉眼识别几乎是不会出错的。

假定训练集误差是 1%，为了方便论证，假定验证集误差是 11%，可以看出训练集设置 得非常好，而验证集设置相对较差，我们可能过度拟合了训练集，在某种程度上，验证集并 没有充分利用交叉验证集的作用，像这种情况，我们称之为「高方差」。

通过查看训练集误差和验证集误差，我们便可以诊断算法是否具有高方差。也就是说衡 量训练集和验证集误差就可以得出不同结论。

假设训练集误差是 15%，我们把训练集误差写在首行，验证集误差是 16%，假设该案例 中人的错误率几乎为 0%，人们浏览这些图片，分辨出是不是猫。算法并没有在训练集中得 到很好训练，如果训练数据的拟合度不高，就是数据欠拟合，就可以说这种算法偏差比较高。相反，它对于验证集产生的结果却是合理的，验证集中的错误率只比训练集的多了 1%，所 以这种算法偏差高，因为它甚至不能拟合训练集，这与上一张幻灯片最左边的图片相似。

再举一个例子，训练集误差是 15%，偏差相当高，但是，验证集的评估结果更糟糕，错 误率达到 30%，在这种情况下，我会认为这种算法偏差高，因为它在训练集上结果不理想，而且方差也很高，这是方差偏差都很糟糕的情况。

再看最后一个例子，训练集误差是 0.5%，验证集误差是 1%，用户看到这样的结果会很 开心，猫咪分类器只有 1% 的错误率，偏差和方差都很低。

有一点我先在这个简单提一下，具体的留在后面课程里讲，这些分析都是基于假设预测 的，假设人眼辨别的错误率接近 0%，一般来说，最优误差也被称为贝叶斯误差，所以，最 优误差接近 0%，我就不在这里细讲了，如果最优误差或贝叶斯误差非常高，比如 15%。我 们再看看这个分类器（训练误差 15%，验证误差 16%），15% 的错误率对训练集来说也是非 常合理的，偏差不高，方差也非常低。

130 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

当所有分类器都不适用时，如何分析偏差和方差呢？比如，图片很模糊，即使是人眼，或者没有系统可以准确无误地识别图片，在这种情况下，最优误差会更高，那么分析过程就 要做些改变了，我们暂时先不讨论这些细微差别，重点是通过查看训练集误差，我们可以判 断数据拟合情况，至少对于训练数据是这样，可以判断是否有偏差问题，然后查看错误率有 多高。当完成训练集训练，开始使用验证集验证时，我们可以判断方差是否过高，从训练集 到验证集的这个过程中，我们可以判断方差是否过高。

以上分析的前提都是假设基本误差很小，训练集和验证集数据来自相同分布，如果没有 这些假设作为前提，分析过程更加复杂，我们将会在稍后课程里讨论。

上一张幻灯片，我们讲了高偏差和高方差的情况，大家应该对优质分类器有了一定的认 识，偏差和方差都高是什么样子呢？这种情况对于两个衡量标准来说都是非常糟糕的。

我们之前讲过，这样的分类器，会产生高偏差，因为它的数据拟合度低，像这种接近线 性的分类器，数据拟合度低。

131 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

但是如果我们稍微改变一下分类器，我用紫色笔画出，它会过度拟合部分数据，用紫色 线画出的分类器具有高偏差和高方差，偏差高是因为它几乎是一条线性分类器，并未拟合数 据。

这种二次曲线能够很好地拟合数据。

这条曲线中间部分灵活性非常高，却过度拟合了这两个样本，这类分类器偏差很高，因 为它几乎是线性的。

132 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

而采用曲线函数或二次元函数会产生高方差，因为它曲线灵活性太高以致拟合了这两个 错误样本和中间这些活跃数据。

这看起来有些不自然，从两个维度上看都不太自然，但对于高维数据，有些数据区域偏 差高，有些数据区域方差高，所以在高维数据中采用这种分类器看起来就不会那么牵强了。

总结一下，我们讲了如何通过分析在训练集上训练算法产生的误差和验证集上验证算法 产生的误差来诊断算法是否存在高偏差和高方差，是否两个值都高，或者两个值都不高，根 据算法偏差和方差的具体情况决定接下来你要做的工作，下节课，我会根据算法偏差和方差 的高低情况讲解一些机器学习的基本方法，帮助大家更系统地优化算法，我们下节课见。

133 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.3 机器学习基础（Basic Recipe for Machine Learning）

上节课我们讲的是如何通过训练误差和验证集误差判断算法偏差或方差是否偏高，帮助 我们更加系统地在机器学习中运用这些方法来优化算法性能。下图就是我在训练神经网络用到的基本方法：（尝试这些方法，可能有用，可能没用）

这是我在训练神经网络时用到地基本方法，初始模型训练完成后，我首先要知道算法的 偏差高不高，如果偏差较高，试着评估训练集或训练数据的性能。如果偏差的确很高，甚至 无法拟合训练集，那么你要做的就是选择一个新的网络，比如含有更多隐藏层或者隐藏单元 的网络，或者花费更多时间来训练网络，或者尝试更先进的优化算法，后面我们会讲到这部 分内容。你也可以尝试其他方法，可能有用，也可能没用。

一会儿我们会看到许多不同的神经网络架构，或许你能找到一个更合适解决此问题的新 的网络架构，加上括号，因为其中一条就是你必须去尝试，可能有用，也可能没用，不过采 用规模更大的网络通常都会有所帮助，延长训练时间不一定有用，但也没什么坏处。训练学 习算法时，我会不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到 可以拟合数据为止，至少能够拟合训练集。

如果网络足够大，通常可以很好的拟合训练集，只要你能扩大网络规模，如果图片很模 糊，算法可能无法拟合该图片，但如果有人可以分辨出图片，如果你觉得基本误差不是很高，那么训练一个更大的网络，你就应该可以…… 至少可以很好地拟合训练集，至少可以拟合或 者过拟合训练集。一旦偏差降低到可以接受的数值，检查一下方差有没有问题，为了评估方 差，我们要查看验证集性能，我们能从一个性能理想的训练集推断出验证集的性能是否也理

134 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

想，如果方差高，最好的解决办法就是采用更多数据，如果你能做到，会有一定的帮助，但 有时候，我们无法获得更多数据，我们也可以尝试通过正则化来减少过拟合，这个我们下节 课会讲。有时候我们不得不反复尝试，但是，如果能找到更合适的神经网络框架，有时它可 能会一箭双雕，同时减少方差和偏差。如何实现呢？想系统地说出做法很难，总之就是不断 重复尝试，直到找到一个低偏差，低方差的框架，这时你就成功了。

有两点需要大家注意：

第一点，高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同，我通常会用训练验证集来诊断算法是否存在偏差或方差问题，然后根据结果选择尝试部分方 法。举个例子，如果算法存在高偏差问题，准备更多训练数据其实也没什么用处，至少这不 是更有效的方法，所以大家要清楚存在的问题是偏差还是方差，还是两者都有问题，明确这 一点有助于我们选择出最有效的方法。

第二点，在机器学习的初期阶段，关于所谓的偏差方差权衡的讨论屡见不鲜，原因是我 们能尝试的方法有很多。可以增加偏差，减少方差，也可以减少偏差，增加方差，但是在深 度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差却不影响到另一方。但在 当前的深度学习和大数据时代，只要持续训练一个更大的网络，只要准备了更多数据，那么 也并非只有这两种情况，我们假定是这样，那么，只要正则适度，通常构建一个更大的网络 便可以，在不影响方差的同时减少偏差，而采用更多数据通常可以在不过多影响偏差的同时 减少方差。这两步实际要做的工作是：训练网络，选择网络或者准备更多数据，现在我们有 工具可以做到在减少偏差或方差的同时，不对另一方产生过多不良影响。我觉得这就是深度 学习对监督式学习大有裨益的一个重要原因，也是我们不用太过关注如何平衡偏差和方差的 一个重要原因，但有时我们有很多选择，减少偏差或方差而不增加另一方。最终，我们会得 到一个非常规范化的网络。从下节课开始，我们将讲解正则化，训练一个更大的网络几乎没 有任何负面影响，而训练一个大型神经网络的主要代价也只是计算时间，前提是网络是比较 规范化的。

今天我们讲了如何通过组织机器学习来诊断偏差和方差的基本方法，然后选择解决问 题的正确操作，希望大家有所了解和认识。我在课上不止一次提到了正则化，它是一种非常 实用的减少方差的方法，正则化时会出现偏差方差权衡问题，偏差可能略有增加，如果网络 足够大，增幅通常不会太高，我们下节课让大家更好理解如何实现神经网络的正则化。

135 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.4 正则化（Regularization）

深度学习可能存在过拟合问题 —— 高方差，有两个解决方法，一个是正则化，另一个是 准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者 获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。

如果你怀疑神经网络过度拟合了数据，即存在高方差问题，那么最先想到的方法可能是 正则化，另一个解决高方差的方法就是准备更多数据，这也是非常可靠的办法，但你可能无 法时时准备足够多的训练数据，或者，获取更多数据的成本很高，但正则化有助于避免过度 拟合，或者减少网络误差，下面我们就来讲讲正则化的作用原理。

我们用逻辑回归来实现这些设想，求成本函数𝐽的最小值，它是我们定义的成本函数，参数包含一些训练数据和不同数据中个体预测的损失，𝑤和𝑏是逻辑回归的两个参数，𝑤是一 个多维度参数矢量，𝑏是一个实数。在逻辑回归函数中加入正则化，只需添加参数 λ，也就 是正则化参数，一会儿再详细讲。

𝜆 2𝑚 

乘以𝑤范数的平方，𝑤欧几里德范数的平方等于𝑤𝑗 （𝑗 值从 1 到𝑛 𝑥 ）平方的和，也可 表示为𝑤 𝑇 𝑤，也就是向量参数𝑤 的欧几里德范数（2 范数）的平方，此方法称为𝐿2 正则化。因为这里用了欧几里德法线，被称为向量参数𝑤的𝐿2 范数。

为什么只正则化参数𝑤？为什么不再加上参数 𝑏 呢？你可以这么做，只是我习惯省略 不写，因为𝑤通常是一个高维参数矢量，已经可以表达高偏差问题，𝑤可能包含有很多参数，我们不可能拟合所有参数，而𝑏只是单个数字，所以𝑤几乎涵盖所有参数，而不是𝑏，如果加 了参数𝑏，其实也没太大影响，因为𝑏只是众多参数中的一个，所以我通常省略不计，如果你 想加上这个参数，完全没问题。

136 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

𝐿2 正则化是最常见的正则化类型，你们可能听说过𝐿1 正则化，𝐿1 正则化，加的不是𝐿2 范数，而是正则项𝑚 𝜆 乘以∑ 𝑗=1 𝑛 𝑥 |𝑤|，∑ 𝑗=1 𝑛 𝑥 |𝑤| 也被称为参数𝑤向量的𝐿1 范数，无论分母是𝑚还 是 2𝑚，它都是一个比例常量。

如果用的是𝐿1 正则化，𝑤最终会是稀疏的，也就是说𝑤向量中有很多 0，有人说这样有 利于压缩模型，因为集合中参数均为 0，存储模型所占用的内存更少。实际上，虽然𝐿1 正则 化使模型变得稀疏，却没有降低太多存储内存，所以我认为这并不是𝐿1 正则化的目的，至少 不是为了压缩模型，人们在训练网络时，越来越倾向于使用𝐿2 正则化。

我们来看最后一个细节，𝜆是正则化参数，我们通常使用验证集或交叉验证集来配置这 个参数，尝试各种各样的数据，寻找最好的参数，我们要考虑训练集之间的权衡，把参数设 置为较小值，这样可以避免过拟合，所以 λ 是另外一个需要调整的超级参数，顺便说一下，为了方便写代码，在 Python 编程语言中，𝜆是一个保留字段，编写代码时，我们删掉𝑎，写 成𝑙𝑎𝑚𝑏𝑑，以免与 Python 中的保留字段冲突，这就是在逻辑回归函数中实现𝐿2 正则化的过 程，如何在神经网络中实现𝐿2 正则化呢？

神经网络含有一个成本函数，该函数包含𝑊 [1] ，𝑏 [1] 到𝑊 [𝑙] ，𝑏 [𝑙] 所有参数，字母𝐿是神经 网络所含的层数，因此成本函数等于𝑚个训练样本损失函数的总和乘以 1 𝑚 ，正则项为

137 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

|𝑊 [𝑙] |2 ，我们称 ||𝑊 [𝑙] ||2 为范数平方，这个矩阵范数 ||𝑊 [𝑙] ||2 （即平方范数），被定义 为矩阵中所有元素的平方求和。

𝜆 2𝑚 

∑1 𝐿 

我们看下求和公式的具体参数，第一个求和符号其值𝑖从 1 到𝑛 [𝑙−1] ，第二个其𝐽值从 1 到 𝑛 [𝑙] ，因为𝑊是一个𝑛 [𝑙] × 𝑛 [𝑙−1] 的多维矩阵，𝑛 [𝑙] 表示𝑙 层单元的数量，𝑛 [𝑙−1] 表示第𝑙 − 1 层隐 藏单元的数量。

该矩阵范数被称作「弗罗贝尼乌斯范数」，用下标𝐹标注，鉴于线性代数中一些神秘晦涩 的原因，我们不称之为「矩阵𝐿2 范数」，而称它为「弗罗贝尼乌斯范数」，矩阵𝐿2 范数听起来更 自然，但鉴于一些大家无须知道的特殊原因，按照惯例，我们称之为「弗罗贝尼乌斯范数」，它表示一个矩阵中所有元素的平方和。

该如何使用该范数实现梯度下降呢？ 用 backprop 计算出𝑑𝑊的值，backprop 会给出𝐽对𝑊的偏导数，实际上是𝑊 [𝑙] ，把𝑊 [𝑙] 替 换为𝑊 [𝑙] 减去学习率乘以𝑑𝑊。

这就是之前我们额外增加的正则化项，既然已经增加了这个正则项，现在我们要做的就 是给𝑑𝑊加上这一项 𝜆 𝑚 𝑊 [𝑙] ，然后计算这个更新项，使用新定义的𝑑𝑊 [𝑙] ，它的定义含有相关 参数代价函数导数和，以及最后添加的额外正则项，这也是𝐿2 正则化有时被称为「权重衰减」

138 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

的原因。

我们用𝑑𝑊 [𝑙] 的定义替换此处的𝑑𝑊 [𝑙] ，可以看到，𝑊 [𝑙] 的定义被更新为𝑊 [𝑙] 减去学习率 𝑎 乘以 backprop 再加上 𝜆 𝑚 𝑊 [𝑙] 。

该正则项说明，不论𝑊 [𝑙] 是什么，我们都试图让它变得更小，实际上，相当于我们给矩 阵 W 乘以 (1 − 𝑎 𝑚 𝜆) 倍的权重，矩阵𝑊减去𝛼 𝑚 𝜆 倍的它，也就是用这个系数 (1 − 𝑎 𝑚 𝜆) 乘以矩阵 𝑊，该系数小于 1，因此𝐿2 范数正则化也被称为「权重衰减」，因为它就像一般的梯度下降，𝑊被更新为少了𝑎乘以 backprop 输出的最初梯度值，同时𝑊也乘以了这个系数，这个系数小 于 1，因此𝐿2 正则化也被称为「权重衰减」。

我不打算这么叫它，之所以叫它「权重衰减」是因为这两项相等，权重指标乘以了一个小 于 1 的系数。

以上就是在神经网络中应用𝐿2 正则化的过程，有人会问我，为什么正则化可以预防过拟 合，我们放在下节课讲，同时直观感受一下正则化是如何预防过拟合的。

139 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.5 为 什 么 正 则 化 有 利 于 预 防 过 拟 合 呢 ？ （ Why regularization reduces overfitting?）

为什么正则化有利于预防过拟合呢？为什么它可以减少方差问题？我们通过两个例子 来直观体会一下。

左图是高偏差，右图是高方差，中间是 Just Right，这几张图我们在前面课程中看到过。

现在我们来看下这个庞大的深度拟合神经网络。我知道这张图不够大，深度也不够，但 你可以想象这是一个过拟合的神经网络。这是我们的代价函数𝐽，含有参数𝑊，𝑏。我们添加 正则项，它可以避免数据权值矩阵过大，这就是弗罗贝尼乌斯范数，为什么压缩𝐿2 范数，或 者弗罗贝尼乌斯范数或者参数可以减少过拟合？

直观上理解就是如果正则化𝜆设置得足够大，权重矩阵𝑊被设置为接近于 0 的值，直观 理解就是把多隐藏单元的权重设为 0，于是基本上消除了这些隐藏单元的许多影响。如果是 这种情况，这个被大大简化了的神经网络会变成一个很小的网络，小到如同一个逻辑回归单 元，可是深度却很大，它会使这个网络从过度拟合的状态更接近左图的高偏差状态。

140 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

但是𝜆会存在一个中间值，于是会有一个接近「Just Right」的中间状态。直观理解就是𝜆增加到足够大，𝑊会接近于 0，实际上是不会发生这种情况的，我们尝 试消除或至少减少许多隐藏单元的影响，最终这个网络会变得更简单，这个神经网络越来越 接近逻辑回归，我们直觉上认为大量隐藏单元被完全消除了，其实不然，实际上是该神经网 络的所有隐藏单元依然存在，但是它们的影响变得更小了。神经网络变得更简单了，貌似这 样更不容易发生过拟合，因此我不确定这个直觉经验是否有用，不过在编程中执行正则化时，你实际看到一些方差减少的结果。

我们再来直观感受一下，正则化为什么可以预防过拟合，假设我们用的是这样的双曲线 激活函数。

用𝑔(𝑧) 表示𝑡𝑎𝑛ℎ(𝑧), 那么我们发现，只要𝑧非常小，如果𝑧只涉及少量参数，这里我们利 用了双曲正切函数的线性状态，只要𝑧可以扩展为这样的更大值或者更小值，激活函数开始 变得非线性。

现在你应该摒弃这个直觉，如果正则化参数 λ 很大，激活函数的参数会相对较小，因为

141 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

代价函数中的参数变大了，

如果𝑊很小，相对来说，𝑧也会很小。

特别是，如果𝑧的值最终在这个范围内，都是相对较小的值，𝑔(𝑧) 大致呈线性，每层几 乎都是线性的，和线性回归函数一样。

第一节课我们讲过，如果每层都是线性的，那么整个网络就是一个线性网络，即使是一 个非常深的深层网络，因具有线性激活函数的特征，最终我们只能计算线性函数，因此，它 不适用于非常复杂的决策，以及过度拟合数据集的非线性决策边界，如同我们在幻灯片中看 到的过度拟合高方差的情况。

总结一下，如果正则化参数变得很大，参数𝑊很小，𝑧也会相对变小，此时忽略𝑏的影响，𝑧会相对变小，实际上，𝑧的取值范围很小，这个激活函数，也就是曲线函数𝑡𝑎𝑛ℎ会相对呈线 性，整个神经网络会计算离线性函数近的值，这个线性函数非常简单，并不是一个极复杂的 高度非线性函数，不会发生过拟合。

大家在编程作业里实现正则化的时候，会亲眼看到这些结果，总结正则化之前，我给大 家一个执行方面的小建议，在增加正则化项时，应用之前定义的代价函数𝐽，我们做过修改，增加了一项，目的是预防权重过大。

142 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

如果你使用的是梯度下降函数，在调试梯度下降时，其中一步就是把代价函数𝐽设计成 这样一个函数，在调试梯度下降时，它代表梯度下降的调幅数量。可以看到，代价函数对于 梯度下降的每个调幅都单调递减。如果你实施的是正则化函数，请牢记，𝐽已经有一个全新 的定义。如果你用的是原函数𝐽，也就是这第一个项正则化项，你可能看不到单调递减现象，为了调试梯度下降，请务必使用新定义的𝐽函数，它包含第二个正则化项，否则函数𝐽可能不 会在所有调幅范围内都单调递减。

这就是𝐿2 正则化，它是我在训练深度学习模型时最常用的一种方法。在深度学习中，还 有一种方法也用到了正则化，就是 dropout 正则化，我们下节课再讲。

143 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.6 dropout 正则化（Dropout Regularization）

除了𝐿2 正则化，还有一个非常实用的正则化方法 ——「Dropout（随机失活）」，我们来看 看它的工作原理。

假设你在训练上图这样的神经网络，它存在过拟合，这就是 dropout 所要处理的，我们 复制这个神经网络，dropout 会遍历网络的每一层，并设置消除神经网络中节点的概率。假 设网络中的每一层，每个节点都以抛硬币的方式设置概率，每个节点得以保留和消除的概率 都是 0.5，设置完节点概率，我们会消除一些节点，然后删除掉从该节点进出的连线，最后 得到一个节点更少，规模更小的网络，然后用 backprop 方法进行训练。

这是网络节点精简后的一个样本，对于其它样本，我们照旧以抛硬币的方式设置概率，保留一类节点集合，删除其它类型的节点集合。对于每个训练样本，我们都将采用一个精简

144 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

后神经网络来训练它，这种方法似乎有点怪，单纯遍历节点，编码也是随机的，可它真的有 效。不过可想而知，我们针对每个训练样本训练规模极小的网络，最后你可能会认识到为什 么要正则化网络，因为我们在训练极小的网络。

如何实施 dropout 呢？方法有几种，接下来我要讲的是最常用的方法，即 inverted dropout（反向随机失活），出于完整性考虑，我们用一个三层（𝑙 = 3）网络来举例说明。编码中会有很多涉及到 3 的地方。我只举例说明如何在某一层中实施 dropout。

首先要定义向量𝑑，𝑑 [3] 表示一个三层的 dropout 向量：

d3 = np.random.rand(a3.shape[0],a3.shape[1]) 

然后看它是否小于某数，我们称之为 keep-prob，keep-prob 是一个具体数字，上个示例 中它是 0.5，而本例中它是 0.8，它表示保留某个隐藏单元的概率，此处 keep-prob 等于 0.8，它意味着消除任意一个隐藏单元的概率是 0.2，它的作用就是生成随机矩阵，如果对𝑎 [3] 进行 因子分解，效果也是一样的。𝑑 [3] 是一个矩阵，每个样本和每个隐藏单元，其中𝑑 [3] 中的对应 值为 1 的概率都是 0.8，对应为 0 的概率是 0.2，随机数字小于 0.8。它等于 1 的概率是 0.8，等于 0 的概率是 0.2。

接下来要做的就是从第三层中获取激活函数，这里我们叫它𝑎 [3] ，𝑎 [3] 含有要计算的激活 函数，𝑎 [3] 等于上面的𝑎 [3] 乘以𝑑 [3] ，a3 =np.multiply (a3,d3)，这里是元素相乘，也可写 为𝑎3 ∗= 𝑑3，它的作用就是让𝑑 [3] 中所有等于 0 的元素（输出），而各个元素等于 0 的概率

只有 20%，乘法运算最终把𝑑 [3] 中相应元素输出，即让𝑑 [3] 中 0 元素与𝑎 [3] 中相对元素归零。

如果用 python 实现该算法的话，𝑑 [3] 则是一个布尔型数组，值为 true 和 false，而不是 1 和 0，乘法运算依然有效，python 会把 true 和 false 翻译为 1 和 0，大家可以用 python 尝

145 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

试一下。最后，我们向外扩展𝑎 [3] ，用它除以 0.8，或者除以 keep-prob 参数。

𝑎3/= 𝑘𝑒𝑒𝑝 − 𝑝𝑟𝑜𝑏 

下面我解释一下为什么要这么做，为方便起见，我们假设第三隐藏层上有 50 个单元或 50 个神经元，在一维上𝑎 [3] 是 50，我们通过因子分解将它拆分成 50 × 𝑚维的，保留和删除它 们的概率分别为 80% 和 20%，这意味着最后被删除或归零的单元平均有 10（50×20%=10） 个，现在我们看下𝑧 [4] ，𝑧 [4] = 𝑤 [4] 𝑎 [3] + 𝑏 [4] ，我们的预期是，𝑎 [3] 减少 20%，也就是说𝑎 [3] 中 有 20% 的元素被归零，为了不影响𝑧 [4] 的期望值，我们需要用𝑤 [4] 𝑎 [3] /0.8，它将会修正或弥 补我们所需的那 20%，𝑎 [3] 的期望值不会变，划线部分就是所谓的 dropout 方法。

它的功能是，不论 keep-prop 的值是多少 0.8，0.9 甚至是 1，如果 keep-prop 设置为 1，那么就不存在 dropout，因为它会保留所有节点。反向随机失活（inverted dropout）方法通 过除以 keep-prob，确保𝑎 [3] 的期望值不变。

事实证明，在测试阶段，当我们评估一个神经网络时，也就是用绿线框标注的反向随机 失活方法，使测试阶段变得更容易，因为它的数据扩展问题变少，我们将在下节课讨论。

据我了解，目前实施 dropout 最常用的方法就是 Inverted dropout，建议大家动手实践 一下。Dropout 早期的迭代版本都没有除以 keep-prob，所以在测试阶段，平均值会变得越 来越复杂，不过那些版本已经不再使用了。

现在你使用的是𝑑向量，你会发现，不同的训练样本，清除不同的隐藏单元也不同。实 际上，如果你通过相同训练集多次传递数据，每次训练数据的梯度不同，则随机对不同隐藏 单元归零，有时却并非如此。比如，需要将相同隐藏单元归零，第一次迭代梯度下降时，把 一些隐藏单元归零，第二次迭代梯度下降时，也就是第二次遍历训练集时，对不同类型的隐 藏层单元归零。向量𝑑或𝑑 [3] 用来决定第三层中哪些单元归零，无论用 foreprop 还是 backprop，这里我们只介绍了 foreprob。

如何在测试阶段训练算法，在测试阶段，我们已经给出了𝑥，或是想预测的变量，用的 是标准计数法。我用𝑎 [0] ，第 0 层的激活函数标注为测试样本𝑥，我们在测试阶段不使用

146 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

dropout 函数，尤其是像下列情况：

𝑧 [1] = 𝑤 [1] 𝑎 [0] + 𝑏[1] 

𝑎 [1] = 𝑔 [1] (𝑧 [1] ) 

𝑧 [2] = 𝑤 [2] 𝑎 [1] + 𝑏[2] 

𝑎 [2] = ⋯ 

以此类推直到最后一层，预测值为𝑦。

显然在测试阶段，我们并未使用 dropout，自然也就不用抛硬币来决定失活概率，以及 要消除哪些隐藏单元了，因为在测试阶段进行预测时，我们不期望输出结果是随机的，如果 测试阶段应用 dropout 函数，预测会受到干扰。理论上，你只需要多次运行预测处理过程，每一次，不同的隐藏单元会被随机归零，预测处理遍历它们，但计算效率低，得出的结果也 几乎相同，与这个不同程序产生的结果极为相似。

Inverted dropout 函数在除以 keep-prob 时可以记住上一步的操作，目的是确保即使在 测试阶段不执行 dropout 来调整数值范围，激活函数的预期结果也不会发生变化，所以没必 要在测试阶段额外添加尺度参数，这与训练阶段不同。

𝑙 = 𝑘𝑒𝑒𝑝 − 𝑝𝑟𝑜𝑏 

这就是 dropout，大家可以通过本周的编程练习来执行这个函数，亲身实践一下。为什么 dropout 会起作用呢？下节课我们将更加直观地了解 dropout 的具体功能。

147 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.7 理解 dropout（Understanding Dropout）

Dropout 可以随机删除网络中的神经单元，他为什么可以通过正则化发挥如此大的作用 呢？

直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单 元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout 将产生收缩权重的平方范数的效果，和之前讲的𝐿2 正则化类似；实施 dropout 的结果实它会 压缩权重，并完成一些预防过拟合的外层正则化；𝐿2 对不同权重的衰减是不同的，它取决于 激活函数倍增的大小。

总结一下，dropout 的功能类似于𝐿2 正则化，与𝐿2 正则化不同的是应用方式不同会带来 一点点小变化，甚至更适用于不同的输入范围。

第二个直观认识是，我们从单个神经元入手，如图，这个单元的工作就是输入并生成一 些有意义的输出。通过 dropout，该单元的输入几乎被消除，有时这两个单元会被删除，有 时会删除其它单元，就是说，我用紫色圈起来的这个单元，它不能依靠任何特征，因为特征 都有可能被随机清除，或者说该单元的输入也都可能被随机清除。我不愿意把所有赌注都放 在一个节点上，不愿意给任何一个输入加上太多权重，因为它可能会被删除，因此该单元将 通过这种方式积极地传播开，并为单元的四个输入增加一点权重，通过传播所有权重，dropout 将产生收缩权重的平方范数的效果，和我们之前讲过的𝐿2 正则化类似，实施 dropout 的结果是它会压缩权重，并完成一些预防过拟合的外层正则化。

148 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

事实证明，dropout 被正式地作为一种正则化的替代形式，𝐿2 对不同权重的衰减是不同 的，它取决于倍增的激活函数的大小。

总结一下，dropout 的功能类似于𝐿2 正则化，与𝐿2 正则化不同的是，被应用的方式不同，dropout 也会有所不同，甚至更适用于不同的输入范围。

实施 dropout 的另一个细节是，这是一个拥有三个输入特征的网络，其中一个要选择的 参数是 keep-prob，它代表每一层上保留单元的概率。所以不同层的 keep-prob 也可以变化。第一层，矩阵𝑊 [1] 是 7×3，第二个权重矩阵𝑊 [2] 是 7×7，第三个权重矩阵𝑊 [3] 是 3×7，以此类 推，𝑊 [2] 是最大的权重矩阵，因为𝑊 [2] 拥有最大参数集，即 7×7，为了预防矩阵的过拟合，对于这一层，我认为这是第二层，它的 keep-prob 值应该相对较低，假设是 0.5。对于其它 层，过拟合的程度可能没那么严重，它们的 keep-prob 值可能高一些，可能是 0.7，这里是 0.7。如果在某一层，我们不必担心其过拟合的问题，那么 keep-prob 可以为 1，为了表达清 除，我用紫色线笔把它们圈出来，每层 keep-prob 的值可能不同。

注意 keep-prob 的值是 1，意味着保留所有单元，并且不在这一层使用 dropout，对于有 可能出现过拟合，且含有诸多参数的层，我们可以把 keep-prob 设置成比较小的值，以便应 用更强大的 dropout，有点像在处理𝐿2 正则化的正则化参数𝜆，我们尝试对某些层施行更多

149 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

正则化，从技术上讲，我们也可以对输入层应用 dropout，我们有机会删除一个或多个输入 特征，虽然现实中我们通常不这么做，keep-prob 的值为 1，是非常常用的输入值，也可以 用更大的值，或许是 0.9。但是消除一半的输入特征是不太可能的，如果我们遵守这个准则，keep-prob 会接近于 1，即使你对输入层应用 dropout。

总结一下，如果你担心某些层比其它层更容易发生过拟合，可以把某些层的 keep-prob 值设置得比其它层更低，缺点是为了使用交叉验证，你要搜索更多的超级参数，另一种方案 是在一些层上应用 dropout，而有些层不用 dropout，应用 dropout 的层只含有一个超级参 数，就是 keep-prob。

结束前分享两个实施过程中的技巧，实施 dropout，在计算机视觉领域有很多成功的第 一次。计算视觉中的输入量非常大，输入太多像素，以至于没有足够的数据，所以 dropout 在计算机视觉中应用得比较频繁，有些计算机视觉研究人员非常喜欢用它，几乎成了默认的 选择，但要牢记一点，dropout 是一种正则化方法，它有助于预防过拟合，因此除非算法过 拟合，不然我是不会使用 dropout 的，所以它在其它领域应用得比较少，主要存在于计算机 视觉领域，因为我们通常没有足够的数据，所以一直存在过拟合，这就是有些计算机视觉研 究人员如此钟情于 dropout 函数的原因。直观上我认为不能概括其它学科。

dropout 一大缺点就是代价函数𝐽不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。定义明确的代价函数𝐽每次迭代 后都会下降，因为我们所优化的代价函数 J 实际上并没有明确定义，或者说在某种程度上很 难计算，所以我们失去了调试工具来绘制这样的图片。我通常会关闭 dropout 函数，将 keepprob 的值设为 1，运行代码，确保𝐽函数单调递减。然后打开 dropout 函数，希望在 dropout 过程中，代码并未引入 bug。我觉得你也可以尝试其它方法，虽然我们并没有关于这些方法 性能的数据统计，但你可以把它们与 dropout 方法一起使用。

150 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.8 其他正则化方法（Other regularization methods）

除了𝐿2 正则化和随机失活（dropout）正则化，还有几种方法可以减少神经网络中的过 拟合:

一。数据扩增 假设你正在拟合猫咪图片分类器，如果你想通过扩增训练数据来解决过拟合，但扩增数 据代价高，而且有时候我们无法扩增数据，但我们可以通过添加这类图片来增加训练集。例 如，水平翻转图片，并把它添加到训练集。所以现在训练集中有原图，还有翻转后的这张图 片，所以通过水平翻转图片，训练集则可以增大一倍，因为训练集有冗余，这虽然不如我们 额外收集一组新图片那么好，但这样做节省了获取更多猫咪图片的花费。

除了水平翻转图片，你也可以随意裁剪图片，这张图是把原图旋转并随意放大后裁剪的，仍能辨别出图片中的猫咪。

通过随意翻转和裁剪图片，我们可以增大数据集，额外生成假训练数据。和全新的，独 立的猫咪图片数据相比，这些额外的假的数据无法包含像全新数据那么多的信息，但我们这 么做基本没有花费，代价几乎为零，除了一些对抗性代价。以这种方式扩增算法数据，进而 正则化数据集，减少过拟合比较廉价。

151 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

像这样人工合成数据的话，我们要通过算法验证，图片中的猫经过水平翻转之后依然是 猫。大家注意，我并没有垂直翻转，因为我们不想上下颠倒图片，也可以随机选取放大后的 部分图片，猫可能还在上面。

对于光学字符识别，我们还可以通过添加数字，随意旋转或扭曲数字来扩增数据，把这 些数字添加到训练集，它们仍然是数字。为了方便说明，我对字符做了强变形处理，所以数 字 4 看起来是波形的，其实不用对数字 4 做这么夸张的扭曲，只要轻微的变形就好，我做成 这样是为了让大家看的更清楚。实际操作的时候，我们通常对字符做更轻微的变形处理。因 为这几个 4 看起来有点扭曲。所以，数据扩增可作为正则化方法使用，实际功能上也与正则 化相似。

二.early stopping

还有另外一种常用的方法叫作 early stopping，运行梯度下降时，我们可以绘制训练误 差，或只绘制代价函数𝐽的优化过程，在训练集上用 0-1 记录分类误差次数。呈单调下降趋 势，如图。

因为在训练过程中，我们希望训练误差，代价函数𝐽都在下降，通过 early stopping，我 们不但可以绘制上面这些内容，还可以绘制验证集误差，它可以是验证集上的分类误差，或 验证集上的代价函数，逻辑损失和对数损失等，你会发现，验证集误差通常会先呈下降趋势，然后在某个节点处开始上升，early stopping 的作用是，你会说，神经网络已经在这个迭代过 程中表现得很好了，我们在此停止训练吧，得到验证集误差，它是怎么发挥作用的？

152 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

当你还未在神经网络上运行太多迭代过程的时候，参数𝑤接近 0，因为随机初始化𝑤值 时，它的值可能都是较小的随机值，所以在你长期训练神经网络之前𝑤依然很小，在迭代过 程和训练过程中𝑤的值会变得越来越大，比如在这儿，神经网络中参数𝑤的值已经非常大了，所以 early stopping 要做就是在中间点停止迭代过程，我们得到一个𝑤值中等大小的弗罗贝 尼乌斯范数，与𝐿2 正则化相似，选择参数𝑤范数较小的神经网络，但愿你的神经网络过度拟 合不严重。

术语 early stopping 代表提早停止训练神经网络，训练神经网络时，我有时会用到 early stopping，但是它也有一个缺点，我们来了解一下。

我认为机器学习过程包括几个步骤，其中一步是选择一个算法来优化代价函数𝐽，我们 有很多种工具来解决这个问题，如梯度下降，后面我会介绍其它算法，例如 Momentum，RMSprop 和 Adam 等等，但是优化代价函数𝐽之后，我也不想发生过拟合，也有一些工具可 以解决该问题，比如正则化，扩增数据等等。

153 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

在机器学习中，超级参数激增，选出可行的算法也变得越来越复杂。我发现，如果我们 用一组工具优化代价函数𝐽，机器学习就会变得更简单，在重点优化代价函数𝐽时，你只需要 留意𝑤和𝑏，𝐽(𝑤, 𝑏) 的值越小越好，你只需要想办法减小这个值，其它的不用关注。然后，预 防过拟合还有其他任务，换句话说就是减少方差，这一步我们用另外一套工具来实现，这个 原理有时被称为「正交化」。思路就是在一个时间做一个任务，后面课上我会具体介绍正交化，如果你还不了解这个概念，不用担心。

但对我来说 early stopping 的主要缺点就是你不能独立地处理这两个问题，因为提早停 止梯度下降，也就是停止了优化代价函数𝐽，因为现在你不再尝试降低代价函数𝐽，所以代价 函数𝐽的值可能不够小，同时你又希望不出现过拟合，你没有采取不同的方式来解决这两个 问题，而是用一种方法同时解决两个问题，这样做的结果是我要考虑的东西变得更复杂。

如果不用 early stopping，另一种方法就是𝐿2 正则化，训练神经网络的时间就可能很长。我发现，这导致超级参数搜索空间更容易分解，也更容易搜索，但是缺点在于，你必须尝试 很多正则化参数𝜆的值，这也导致搜索大量𝜆值的计算代价太高。

Early stopping 的优点是，只运行一次梯度下降，你可以找出𝑤的较小值，中间值和较大 值，而无需尝试𝐿2 正则化超级参数𝜆的很多值。

如果你还不能完全理解这个概念，没关系，下节课我们会详细讲解正交化，这样会更好 理解。

虽然𝐿2 正则化有缺点，可还是有很多人愿意用它。吴恩达老师个人更倾向于使用𝐿2 正则 化，尝试许多不同的𝜆值，假设你可以负担大量计算的代价。而使用 early stopping 也能得到 相似结果，还不用尝试这么多𝜆值。

这节课我们讲了如何使用数据扩增，以及如何使用 early stopping 降低神经网络中的方 差或预防过拟合。

154 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.9 归一化输入（Normalizing inputs）

训练神经网络，其中一个加速训练的方法就是归一化输入。假设一个训练集有两个特征，输入特征为 2 维，归一化需要两个步骤：

1. 零均值

2. 归一化方差； 我们希望无论是训练集和测试集都是通过相同的𝜇和𝜎 2 定义的数据转换，这两个是由训 练集得出来的。

1 第一步是零均值化，= 𝑚

𝜇 

∑𝑖=1 𝑚 

𝑥 (𝑖) ，它是一个向量，𝑥等于每个训练数据 𝑥减去𝜇，意

思是移动训练集，直到它完成零均值化。

155 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

第二步是归一化方差，注意特征𝑥 1 的方差比特征𝑥 2 的方差要大得多，我们要做的是给𝜎 1 赋值，𝜎 2 = 𝑚 ∑ 𝑖=1 𝑚 (𝑥 (𝑖) ) 2 ，这是节点𝑦 的平方，𝜎 2 是一个向量，它的每个特征都有方差，注

意，我们已经完成零值均化，(𝑥 (𝑖) ) 2 元素𝑦2 就是方差，我们把所有数据除以向量𝜎 2 ，最后变 成上图形式。

𝑥 1 和𝑥 2 的方差都等于 1。提示一下，如果你用它来调整训练数据，那么用相同的 𝜇 和 𝜎 2 来归一化测试集。尤其是，你不希望训练集和测试集的归一化有所不同，不论𝜇的值是什 么，也不论𝜎 2 的值是什么，这两个公式中都会用到它们。所以你要用同样的方法调整测试集，而不是在训练集和测试集上分别预估𝜇 和 𝜎 2 。因为我们希望不论是训练数据还是测试数据，都是通过相同 μ 和𝜎 2 定义的相同数据转换，其中𝜇和𝜎 2 是由训练集数据计算得来的。

我们为什么要这么做呢？为什么我们想要归一化输入特征，回想一下右上角所定义的代 价函数。

𝑚 1 𝐽(𝑤, 𝑏) = ∑ 𝐿(𝑦 , 𝑦 (𝑖) ) 𝑚 𝑖=1 

如果你使用非归一化的输入特征，代价函数会像这样：

156 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

这是一个非常细长狭窄的代价函数，你要找的最小值应该在这里。但如果特征值在不同 范围，假如𝑥 1 取值范围从 1 到 1000，特征𝑥 2 的取值范围从 0 到 1，结果是参数𝑤 1 和𝑤 2 值的 范围或比率将会非常不同，这些数据轴应该是𝑤 1 和𝑤 2 ，但直观理解，我标记为𝑤和𝑏，代价 函数就有点像狭长的碗一样，如果你能画出该函数的部分轮廓，它会是这样一个狭长的函数。

然而如果你归一化特征，代价函数平均起来看更对称，如果你在上图这样的代价函数上 运行梯度下降法，你必须使用一个非常小的学习率。因为如果是在这个位置，梯度下降法可 能需要多次迭代过程，直到最后找到最小值。但如果函数是一个更圆的球形轮廓，那么不论 从哪个位置开始，梯度下降法都能够更直接地找到最小值，你可以在梯度下降法中使用较大 步长，而不需要像在左图中那样反复执行。

当然，实际上𝑤是一个高维向量，因此用二维绘制𝑤并不能正确地传达并直观理解，但 总地直观理解是代价函数会更圆一些，而且更容易优化，前提是特征都在相似范围内，而不 是从 1 到 1000，0 到 1 的范围，而是在 - 1 到 1 范围内或相似偏差，这使得代价函数𝐽优化起 来更简单快速。

157 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

实际上如果假设特征𝑥 1 范围在 0-1 之间，𝑥 2 的范围在 - 1 到 1 之间，𝑥 3 范围在 1-2 之间，它们是相似范围，所以会表现得很好。

当它们在非常不同的取值范围内，如其中一个从 1 到 1000，另一个从 0 到 1，这对优化 算法非常不利。但是仅将它们设置为均化零值，假设方差为 1，就像上一张幻灯片里设定的 那样，确保所有特征都在相似范围内，通常可以帮助学习算法运行得更快。

所以如果输入特征处于不同范围内，可能有些特征值从 0 到 1，有些从 1 到 1000，那么 归一化特征值就非常重要了。如果特征值处于相似范围内，那么归一化就不是很重要了。执 行这类归一化并不会产生什么危害，我通常会做归一化处理，虽然我不确定它能否提高训练 或算法速度。

这就是归一化特征输入，下节课我们将继续讨论提升神经网络训练速度的方法。

158 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.10 梯度消失 / 梯度爆炸（Vanishing / Exploding gradients）

训练神经网络，尤其是深度神经所面临的一个问题就是梯度消失或梯度爆炸，也就是你 训练神经网络的时候，导数或坡度有时会变得非常大，或者非常小，甚至于以指数方式变小，这加大了训练的难度。

这节课，你将会了解梯度消失或梯度爆炸的真正含义，以及如何更明智地选择随机初始 化权重，从而避免这个问题。假设你正在训练这样一个极深的神经网络，为了节约幻灯片 上的空间，我画的神经网络每层只有两个隐藏单元，但它可能含有更多，但这个神经网络会 有参数𝑊 [1] ，𝑊 [2] ，𝑊 [3] 等等，直到𝑊 [𝑙] ，为了简单起见，假设我们使用激活函数𝑔(𝑧) = 𝑧，也就是线性激活函数，我们忽略𝑏，假设𝑏 [𝑙] =0，如果那样的话，输出：

𝑦 = 𝑊 [𝑙] 𝑊 [𝐿−1] 𝑊 [𝐿−2] … 𝑊 [3] 𝑊 [2] 𝑊 [1] 𝑥 

如果你想考验我的数学水平，𝑊 [1] 𝑥 = 𝑧 [1] ，因为𝑏 = 0，所以我想𝑧 [1] = 𝑊 [1] 𝑥，𝑎 [1] = 𝑔(𝑧 [1] )，因为我们使用了一个线性激活函数，它等于𝑧 [1] ，所以第一项𝑊 [1] 𝑥 = 𝑎 [1] ，通过推 理，你会得出𝑊 [2] 𝑊 [1] 𝑥 = 𝑎 [2] ，因为𝑎 [2] = 𝑔(𝑧 [2] )，还等于𝑔(𝑊 [2] 𝑎 [1] )，可以用𝑊 [1] 𝑥替换 𝑎 [1] ，所以这一项就等于𝑎 [2] ，这个就是𝑎 [3] (𝑊 [3] 𝑊 [2] 𝑊 [1] 𝑥)。

所有这些矩阵数据传递的协议将给出𝑦而不是𝑦的值。1.5 0 假设每个权重矩阵𝑊 [𝑙] = [从技术上来讲，最后一项有不同维度，可能它就]，0 1.5 1.5 0 (𝐿−1) 是余下的权重矩阵，𝑦 = 𝑊 [1] 𝑥，[因为我们假设所有矩阵都等于它，它是 1.5] 0 1.5

倍的单位矩阵，最后的计算结果就是𝑦，𝑦也就是等于 1.5 (𝐿−1) 𝑥。如果对于一个深度神经网络 来说𝐿值较大，那么𝑦的值也会非常大，实际上它呈指数级增长的，它增长的比率是 1.5 𝐿 ，因

159 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

此对于一个深度神经网络，𝑦的值将爆炸式增长。0.5 0 相反的，如果权重是 0.5，𝑊 [𝑙] = [它比 1 小，这项也就变成了 0.5 𝐿 ，矩阵𝑦 =]，0 0.5 0.5 0 𝑊 [1] 𝑥，[再次忽略𝑊 [𝐿] ，因此每个矩阵都小于 1，假设𝑥 1 和𝑥 2 都是 1，激活函

](𝐿−1) 0 0.5 数将变成 1 2 ，1 2 ，1 4 ，1 4 ，1 8 ，1 8 等，直到最后一项变成 1 2 𝐿 ，所以作为自定义函数，激活函数的值将

以指数级下降，它是与网络层数数量𝐿相关的函数，在深度网络中，激活函数以指数级递减。我希望你得到的直观理解是，权重𝑊只比 1 略大一点，或者说只是比单位矩阵大一点，0.9 0 深度神经网络的激活函数将爆炸式增长，如果𝑊比 1 略小一点，可能是 [ ]。0 0.9

在深度神经网络中，激活函数将以指数级递减，虽然我只是讨论了激活函数以与𝐿相关 的指数级数增长或下降，它也适用于与层数𝐿相关的导数或梯度函数，也是呈指数级增长或 呈指数递减。

对于当前的神经网络，假设𝐿 = 150，最近 Microsoft 对 152 层神经网络的研究取得了很 大进展，在这样一个深度神经网络中，如果激活函数或梯度函数以与𝐿相关的指数增长或递 减，它们的值将会变得极大或极小，从而导致训练难度上升，尤其是梯度指数小于𝐿时，梯 度下降算法的步长会非常非常小，梯度下降算法将花费很长时间来学习。

总结一下，我们讲了深度神经网络是如何产生梯度消失或爆炸问题的，实际上，在很长 一段时间内，它曾是训练深度神经网络的阻力，虽然有一个不能彻底解决此问题的解决方案，但是已在如何选择初始化权重问题上提供了很多帮助。

160 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.11 神经网络的权重初始化（Weight Initialization for Deep Networks）

上节课，我们学习了深度神经网络如何产生梯度消失和梯度爆炸问题，最终针对该问题，我们想出了一个不完整的解决方案，虽然不能彻底解决问题，却很有用，有助于我们为神经 网络更谨慎地选择随机初始化参数，为了更好地理解它，我们先举一个神经单元初始化地例 子，然后再演变到整个深度网络。

我们来看看只有一个神经元的情况，然后才是深度网络。单个神经元可能有 4 个输入特征，从𝑥 1 到𝑥 4 ，经过𝑎 = 𝑔(𝑧) 处理，最终得到𝑦，稍后讲 深度网络时，这些输入表示为𝑎 [𝑙] ，暂时我们用𝑥表示。

𝑧 = 𝑤 1 𝑥 1 + 𝑤 2 𝑥 2 + ⋯ + 𝑤 𝑛 𝑥 𝑛 ，𝑏 = 0，暂时忽略𝑏，为了预防𝑧值过大或过小，你可以看 到𝑛越大，你希望𝑤 𝑖 越小，因为𝑧是𝑤 𝑖 𝑥 𝑖 的和，如果你把很多此类项相加，希望每项值更小，最合理的方法就是设置𝑤 𝑖 = 𝑛 1 ，𝑛表示神经元的输入特征数量，实际上，你要做的就是设置

某层权重矩阵𝑤 [𝑙] = 𝑛𝑝. 𝑟𝑎𝑛𝑑𝑜𝑚. 𝑟𝑎𝑛𝑑𝑛(shape) ∗ np. sqrt (𝑛 [𝑙−1] 1 )，𝑛 [𝑙−1] 就是我喂给第𝑙层神

经单元的数量（即第𝑙 − 1 层神经元数量）。

161 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

结果，如果你是用的是 Relu 激活函数，而不是 1 ，方差设置为 2 ，效果会更好。你常常

𝑛 

𝑛 

发现，初始化时，尤其是使用 Relu 激活函数时，𝑔 [𝑙] (𝑧) = 𝑅𝑒𝑙𝑢(𝑧), 它取决于你对随机变量的 熟悉程度，这是高斯随机变量，然后乘以它的平方根，也就是引用这个方差 2 𝑛 。这里，我用

的是𝑛 [𝑙−1] ，因为本例中，逻辑回归的特征是不变的。但一般情况下𝑙层上的每个神经元都有 𝑛 [𝑙−1] 个输入。如果激活函数的输入特征被零均值和标准方差化，方差是 1，𝑧也会调整到相 似范围，这就没解决问题（梯度消失和爆炸问题）。但它确实降低了梯度消失和爆炸问题，因为它给权重矩阵𝑤设置了合理值，你也知道，它不能比 1 大很多，也不能比 1 小很多，所 以梯度没有爆炸或消失过快。

我提到了其它变体函数，刚刚提到的函数是 Relu 激活函数，一篇由 Herd 等人撰写的论 文曾介绍过。对于几个其它变体函数，如 tanh 激活函数，有篇论文提到，常量 1 比常量 2

的效率更高，对于 tanh 函数来说，它是√

1 

𝑛 [𝑙−1] 

，这里平方根的作用与这个公式作用相同

(np. sqrt (𝑛 [𝑙−1] 1 ))，它适用于 tanh 激活函数，被称为 Xavier 初始化。Yoshua Bengio 和他的同

事还提出另一种方法，你可能在一些论文中看到过，它们使用的是公式√𝑛 [𝑙−1] +𝑛 [𝑙] 2 。其它理论 已对此证明，但如果你想用 Relu 激活函数，也就是最常用的激活函数，我会用这个公式

np. sqrt (𝑛 [𝑙−1] 2 )，如果使用 tanh 函数，可以用公式√𝑛 [𝑙−1] 1 ，有些作者也会使用这个函数。实际上，我认为所有这些公式只是给你一个起点，它们给出初始化权重矩阵的方差的默 认值，如果你想添加方差，方差参数则是另一个你需要调整的超级参数，可以给公式

162 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

np. sqrt (𝑛 [𝑙−1] 2 ) 添加一个乘数参数，调优作为超级参数激增一份子的乘子参数。有时调优该超 级参数效果一般，这并不是我想调优的首要超级参数，但我发现调优过程中产生的问题，虽 然调优该参数能起到一定作用，但考虑到相比调优，其它超级参数的重要性，我通常把它的 优先级放得比较低。希望你现在对梯度消失或爆炸问题以及如何为权重初始化合理值已经有了一个直观认 识，希望你设置的权重矩阵既不会增长过快，也不会太快下降到 0，从而训练出一个权重或 梯度不会增长或消失过快的深度网络。我们在训练深度网络时，这也是一个加快训练速度的 技巧。

163 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.12 梯度的数值逼近（Numerical approximation of gradients）

在实施 backprop 时，有一个测试叫做梯度检验，它的作用是确保 backprop 正确实施。因为有时候，你虽然写下了这些方程式，却不能 100% 确定，执行 backprop 的所有细节都是 正确的。为了逐渐实现梯度检验，我们首先说说如何计算梯度的数值逼近，下节课，我们将 讨论如何在 backprop 中执行梯度检验，以确保 backprop 正确实施。

我们先画出函数𝑓，标记为𝑓(𝜃)，𝑓(𝜃) = 𝜃3 ，先看一下𝜃的值，假设𝜃 = 1，不增大𝜃的 值，而是在𝜃 右侧，设置一个𝜃 + 𝜀，在𝜃左侧，设置𝜃 − 𝜀。因此𝜃 = 1，𝜃 + 𝜀 = 1.01, 𝜃 − 𝜀 = 0.99,，跟以前一样，𝜀的值为 0.01，看下这个小三角形，计算高和宽的比值，就是更准确的 梯度预估，选择𝑓函数在𝜃 − 𝜀上的这个点，用这个较大三角形的高比上宽，技术上的原因我 就不详细解释了，较大三角形的高宽比值更接近于𝜃的导数，把右上角的三角形下移，好像 有了两个三角形，右上角有一个，左下角有一个，我们通过这个绿色大三角形同时考虑了这 两个小三角形。所以我们得到的不是一个单边公差而是一个双边公差。

我们写一下数据算式，图中绿色三角形上边的点的值是𝑓(𝜃 + 𝜀)，下边的点是𝑓(𝜃 − 𝜀)，

这个三角形的高度是𝑓(𝜃 + 𝜀) − 𝑓(𝜃 − 𝜀)，这两个宽度都是 ε，所以三角形的宽度是 2𝜀，高 宽比值为 𝑓(𝜃+𝜀)−(𝜃−𝜀) 2𝜀 ，它的期望值接近𝑔(𝜃)，𝑓(𝜃) = 𝜃3 传入参数值：

164 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

3 ，大家可以用计算器算算结果，结果应该是 3.0001，而前面 一张幻灯片上面是，当𝜃 = 1 时，𝑔(𝜃) = 3𝜃 2 = 3，所以这两个𝑔(𝜃) 值非常接近，逼近误差为

𝑓(𝜃+𝜀)−𝑓(𝜃−𝜀) 2𝜀 

= 

(1.01) 3 −(0.99) 2×0.01 

0.0001，前一张幻灯片，我们只考虑了单边公差，即从𝜃到𝜃 + 𝜀之间的误差，𝑔(𝜃) 的值为

3.0301，逼近误差是 0.03，不是 0.0001，所以使用双边误差的方法更逼近导数，其结果接近 于 3，现在我们更加确信，𝑔(𝜃) 可能是𝑓导数的正确实现，在梯度检验和反向传播中使用该 方法时，最终，它与运行两次单边公差的速度一样，实际上，我认为这种方法还是非常值得 使用的，因为它的结果更准确。

这是一些你可能比较熟悉的微积分的理论，如果你不太明白我讲的这些理论也没关系，导数的官方定义是针对值很小的𝜀，导数的官方定义是𝑓 ′ (𝜃) = 2𝜀 𝑓(𝜃+𝜀)−𝑓(𝜃−𝜀) ，如果你上过微 积分课，应该学过无穷尽的定义，我就不在这里讲了。

对于一个非零的𝜀，它的逼近误差可以写成𝑂(𝜀 2)，ε 值非常小，如果𝜀 = 0.01，𝜀 2 = 0.0001，大写符号𝑂的含义是指逼近误差其实是一些常量乘以𝜀 2 ，但它的确是很准确的逼近误差，所 以大写𝑂的常量有时是 1。然而，如果我们用另外一个公式逼近误差就是𝑂(𝜀)，当𝜀小于 1 时，实际上𝜀比𝜀 2 大很多，所以这个公式近似值远没有左边公式的准确，所以在执行梯度检验时，我们使用双边误差，即𝑓(𝜃+𝜀)−𝑓(𝜃−𝜀) ，而不使用单边公差，因为它不够准确。

2𝜀 

如果你不理解上面两条结论，所有公式都在这儿，不用担心，如果你对微积分和数值逼 近有所了解，这些信息已经足够多了，重点是要记住，双边误差公式的结果更准确，下节课 我们做梯度检验时就会用到这个方法。我们讲了如何使用双边误差来判断别人给你的函数 𝑔(𝜃)，是否正确实现了函数𝑓的偏导，现在我们可以使用这个方法来检验反向传播是否得以 正确实施，如果不正确，它可能有 bug 需要你来解决。

165 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.13 梯度检验（Gradient checking）

梯度检验帮我们节省了很多时间，也多次帮我发现 backprop 实施过程中的 bug，接下 来，我们看看如何利用它来调试或检验 backprop 的实施是否正确。

假设你的网络中含有下列参数，𝑊 [1] 和𝑏 [1] ……𝑊 [𝑙] 和𝑏 [𝑙] ，为了执行梯度检验，首先要做 的就是，把所有参数转换成一个巨大的向量数据，你要做的就是把矩阵𝑊转换成一个向量，把所有𝑊矩阵转换成向量之后，做连接运算，得到一个巨型向量𝜃，该向量表示为参数𝜃，代 价函数𝐽是所有𝑊和𝑏的函数，现在你得到了一个𝜃的代价函数𝐽（即𝐽(𝜃)）。接着，你得到与 𝑊和𝑏顺序相同的数据，你同样可以把𝑑𝑊 [1] 和𝑑𝑏 [1] ……𝑑𝑊 [𝑙] 和𝑑𝑏 [𝑙] 转换成一个新的向量，用 它们来初始化大向量𝑑𝜃，它与𝜃具有相同维度。

同样的，把𝑑𝑊 [1] 转换成矩阵，𝑑𝑏 [1] 已经是一个向量了，直到把𝑑𝑊 [𝑙] 转换成矩阵，这样 所有的𝑑𝑊都已经是矩阵，注意𝑑𝑊 [1] 与𝑊 [1] 具有相同维度，𝑑𝑏 [1] 与𝑏 [1] 具有相同维度。经过 相同的转换和连接运算操作之后，你可以把所有导数转换成一个大向量𝑑𝜃，它与𝜃具有相同 维度，现在的问题是𝑑𝜃和代价函数𝐽的梯度或坡度有什么关系？

这就是实施梯度检验的过程，英语里通常简称为「grad check」，首先，我们要清楚𝐽是超 参数𝜃的一个函数，你也可以将𝐽函数展开为𝐽(𝜃 1 , 𝜃 2 ,𝜃 3 , … …)，不论超级参数向量𝜃的维度是 多少，为了实施梯度检验，你要做的就是循环执行，从而对每个𝑖也就是对每个𝜃组成元素计 算𝑑𝜃 approx [𝑖] 的值，我使用双边误差，也就是

𝐽(𝜃1 , 𝜃 2 ,… 𝜃 𝑖 + 𝜀, … ) − 𝐽(𝜃1 , 𝜃 2 ,… 𝜃 𝑖 − 𝜀, … ) 𝑑𝜃 approx [𝑖] = 2𝜀 

只对𝜃 𝑖 增加𝜀，其它项保持不变，因为我们使用的是双边误差，对另一边做同样的操作，只不过是减去𝜀，𝜃其它项全都保持不变。

166 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

从上节课中我们了解到这个值（𝑑𝜃 approx [𝑖]）应该逼近𝑑𝜃[𝑖]= 𝜕𝜃 𝑖 𝜕𝐽 ，𝑑𝜃[𝑖] 是代价函数的偏

导数，然后你需要对𝑖的每个值都执行这个运算，最后得到两个向量，得到𝑑𝜃的逼近值 𝑑𝜃 approx ，它与𝑑𝜃具有相同维度，它们两个与𝜃具有相同维度，你要做的就是验证这些向量 是否彼此接近。

具体来说，如何定义两个向量是否真的接近彼此？我一般做下列运算，计算这两个向量 的距离，𝑑𝜃 approx [𝑖] − 𝑑𝜃[𝑖] 的欧几里得范数，注意这里（||𝑑𝜃 approx − 𝑑𝜃||2 ）没有平方，它 是误差平方之和，然后求平方根，得到欧式距离，然后用向量长度归一化，使用向量长度的 欧几里得范数。分母只是用于预防这些向量太小或太大，分母使得这个方程式变成比率，我 们实际执行这个方程式，𝜀可能为 10−7 ，使用这个取值范围内的𝜀，如果你发现计算方程式得 到的值为 10−7 或更小，这就很好，这就意味着导数逼近很有可能是正确的，它的值非常小。

如果它的值在 10−5 范围内，我就要小心了，也许这个值没问题，但我会再次检查这个向 量的所有项，确保没有一项误差过大，可能这里有 bug。

如果左边这个方程式结果是 10−3 ，我就会担心是否存在 bug，计算结果应该比 10−3 小很 多，如果比 10−3 大很多，我就会很担心，担心是否存在 bug。这时应该仔细检查所有𝜃项，看是否有一个具体的𝑖值，使得𝑑𝜃 approx [𝑖] 与𝑑𝜃[𝑖] 大不相同，并用它来追踪一些求导计算是

167 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

否正确，经过一些调试，最终结果会是这种非常小的值（10−7 ），那么，你的实施可能是正 确的。

在实施神经网络时，我经常需要执行 foreprop 和 backprop，然后我可能发现这个梯度 检验有一个相对较大的值，我会怀疑存在 bug，然后开始调试，调试，调试，调试一段时间 后，我得到一个很小的梯度检验值，现在我可以很自信的说，神经网络实施是正确的。

现在你已经了解了梯度检验的工作原理，它帮助我在神经网络实施中发现了很多 bug，希望它对你也有所帮助。

168 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1.14 梯 度 检 验 应 用 的 注 意 事 项 （ Gradient Checking Implementation Notes）

这节课，分享一些关于如何在神经网络实施梯度检验的实用技巧和注意事项。

首先，不要在训练中使用梯度检验，它只用于调试。我的意思是，计算所有𝑖值的 𝑑𝜃 approx [𝑖] 是一个非常漫长的计算过程，为了实施梯度下降，你必须使用𝑊和𝑏 backprop 来 计算𝑑𝜃，并使用 backprop 来计算导数，只要调试的时候，你才会计算它，来确认数值是否 接近𝑑𝜃。完成后，你会关闭梯度检验，梯度检验的每一个迭代过程都不执行它，因为它太慢 了。

第二点，如果算法的梯度检验失败，要检查所有项，检查每一项，并试着找出 bug，也 就是说，如果𝑑𝜃 approx [𝑖] 与𝑑𝜃[𝑖] 的值相差很大，我们要做的就是查找不同的𝑖值，看看是哪个 导致𝑑𝜃 approx [𝑖] 与𝑑𝜃[𝑖] 的值相差这么多。举个例子，如果你发现，相对某些层或某层的𝜃或 𝑑𝜃的值相差很大，但是 dw [𝑙] 的各项非常接近，注意𝜃的各项与𝑏和𝑤的各项都是一一对应的，这时，你可能会发现，在计算参数𝑏的导数𝑑𝑏的过程中存在 bug。反过来也是一样，如果你 发现它们的值相差很大，𝑑𝜃 approx [𝑖] 的值与𝑑𝜃[𝑖] 的值相差很大，你会发现所有这些项目都来 自于𝑑𝑤或某层的𝑑𝑤，可能帮你定位 bug 的位置，虽然未必能够帮你准确定位 bug 的位置，但它可以帮助你估测需要在哪些地方追踪 bug。

第三点，在实施梯度检验时，如果使用正则化，请注意正则项。如果代价函数𝐽(𝜃) =

169 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第一周：深度学习的实践层面 (Practical aspects of Deep Learning)

1 

𝑚 

∑ 𝐿(𝑦 

𝜆 , 𝑦 (𝑖) ) + 2𝑚 ∑ ||𝑊 [𝑙] ||2 ，这就是代价函数𝐽的定义，𝑑𝜃等于与𝜃相关的𝐽函数的梯度，

包括这个正则项，记住一定要包括这个正则项。第四点，梯度检验不能与 dropout 同时使用，因为每次迭代过程中，dropout 会随机消 除隐藏层单元的不同子集，难以计算 dropout 在梯度下降上的代价函数𝐽。因此 dropout 可 作为优化代价函数𝐽的一种方法，但是代价函数𝐽被定义为对所有指数极大的节点子集求和。而在任何迭代过程中，这些节点都有可能被消除，所以很难计算代价函数𝐽。你只是对成本 函数做抽样，用 dropout，每次随机消除不同的子集，所以很难用梯度检验来双重检验 dropout 的计算，所以我一般不同时使用梯度检验和 dropout。如果你想这样做，可以把 dropout 中 的 keepprob 设置为 1.0，然后打开 dropout，并寄希望于 dropout 的实施是正确的，你还可 以做点别的，比如修改节点丢失模式确定梯度检验是正确的。实际上，我一般不这么做，我 建议关闭 dropout，用梯度检验进行双重检查，在没有 dropout 的情况下，你的算法至少是 正确的，然后打开 dropout。

最后一点，也是比较微妙的一点，现实中几乎不会出现这种情况。当𝑤和𝑏接近 0 时，梯度下降的实施是正确的，在随机初始化过程中……，但是在运行梯度下降时，𝑤和𝑏变得更 大。可能只有在𝑤和𝑏接近 0 时，backprop 的实施才是正确的。但是当𝑊和𝑏变大时，它会变 得越来越不准确。你需要做一件事，我不经常这么做，就是在随机初始化过程中，运行梯度 检验，然后再训练网络，𝑤和𝑏会有一段时间远离 0，如果随机初始化值比较小，反复训练网 络之后，再重新运行梯度检验。

这就是梯度检验，恭喜大家，这是本周最后一课了。回顾这一周，我们讲了如何配置训 练集，验证集和测试集，如何分析偏差和方差，如何处理高偏差或高方差以及高偏差和高方 差并存的问题，如何在神经网络中应用不同形式的正则化，如𝐿2 正则化和 dropout，还有加 快神经网络训练速度的技巧，最后是梯度检验。这一周我们学习了很多内容，你可以在本周 编程作业中多多练习这些概念。祝你好运，期待下周再见。

170 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

第二周：优化算法 (Optimization algorithms)

2.1 Mini-batch 梯度下降（Mini-batch gradient descent）

本周将学习优化算法，这能让你的神经网络运行得更快。机器学习的应用是一个高度依 赖经验的过程，伴随着大量迭代的过程，你需要训练诸多模型，才能找到合适的那一个，所 以，优化算法能够帮助你快速训练模型。

其中一个难点在于，深度学习没有在大数据领域发挥最大的效果，我们可以利用一个巨 大的数据集来训练神经网络，而在巨大的数据集基础上进行训练速度很慢。因此，你会发现，使用快速的优化算法，使用好用的优化算法能够大大提高你和团队的效率，那么，我们首先 来谈谈 mini-batch 梯度下降法。

你之前学过，向量化能够让你有效地对所有𝑚个样本进行计算，允许你处理整个训练集，而无需某个明确的公式。

所以我们要把训练样本放大巨大的矩阵𝑋当中去，𝑋 = [𝑥 (1) 𝑥 (2) 𝑥 (3) … … 𝑥 (𝑚) ]。

𝑌也是如此，𝑌 = [𝑦 (1) 𝑦 (2) 𝑦 (3) … … 𝑦 (𝑚) ]。

所以𝑋的维数是 (𝑛 𝑥 , 𝑚)，𝑌的维数是 (1, 𝑚)，向量化能够让你相对较快地处理所有𝑚个样

本。如果𝑚很大的话，处理速度仍然缓慢。比如说，如果𝑚是 500 万或 5000 万或者更大的 一个数，在对整个训练集执行梯度下降法时，你要做的是，你必须处理整个训练集，然后才 能进行一步梯度下降法，然后你需要再重新处理 500 万个训练样本，才能进行下一步梯度下

171 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

降法。所以如果你在处理完整个 500 万个样本的训练集之前，先让梯度下降法处理一部分，你的算法速度会更快，准确地说，这是你可以做的一些事情。

你可以把训练集分割为小一点的子集训练，这些子集被取名为 mini-batch，假设每一个 子集中只有 1000 个样本，那么把其中的𝑥 (1) 到𝑥 (1000) 取出来，将其称为第一个子训练集，也 叫做 mini-batch，然后你再取出接下来的 1000 个样本，从𝑥 (1001) 到𝑥 (2000) ，然后再取 1000 个样本，以此类推。

接下来我要说一个新的符号，把𝑥 (1) 到𝑥 (1000) 称为𝑋 {1} ，𝑥 (1001) 到𝑥 (2000) 称为𝑋 {2} ，如果 你的训练样本一共有 500 万个，每个 mini-batch 都有 1000 个样本，也就是说，你有 5000 个 mini-batch，因为 5000 乘以 1000 就是 5000 万。

你共有 5000 个 mini-batch，所以最后得到是𝑋{5000}

对𝑌也要进行相同处理，你也要相应地拆分𝑌的训练集，所以这是𝑌 {1} ，然后从𝑦 (1001) 到 𝑦 (2000) ，这个叫𝑌 {2} ，一直到𝑌 {5000} 。

mini-batch 的数量𝑡组成了𝑋 {𝑡} 和𝑌 {𝑡} ，这就是 1000 个训练样本，包含相应的输入输出对。

在继续课程之前，先确定一下我的符号，之前我们使用了上角小括号 (𝑖) 表示训练集里的 值，所以𝑥 (𝑖) 是第𝑖个训练样本。我们用了上角中括号 [𝑙] 来表示神经网络的层数，𝑧 [𝑙] 表示神经 网络中第𝑙层的𝑧值，我们现在引入了大括号𝑡来代表不同的 mini-batch，所以我们有𝑋 {𝑡} 和𝑌 {𝑡} ，检查一下自己是否理解无误。

172 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

𝑋 {𝑡} 和𝑌 {𝑡} 的维数：如果𝑋 {1} 是一个有 1000 个样本的训练集，或者说是 1000 个样本的𝑥 值，所以维数应该是 (𝑛 𝑥 , 1000)，𝑋 {2} 的维数应该是 (𝑛 𝑥 ,1000)，以此类推。因此所有的子集 维数都是 (𝑛 𝑥 ,1000)，而这些（𝑌 {𝑡} ）的维数都是 (1,1000)。

解释一下这个算法的名称，batch 梯度下降法指的是我们之前讲过的梯度下降法算法，就是同时处理整个训练集，这个名字就是来源于能够同时看到整个 batch 训练集的样本被处 理，这个名字不怎么样，但就是这样叫它。

相比之下，mini-batch 梯度下降法，指的是我们在下一张幻灯片中会讲到的算法，你每 次同时处理的单个的 mini-batch 𝑋 {𝑡} 和𝑌 {𝑡} ，而不是同时处理全部的𝑋和𝑌训练集。

那么究竟 mini-batch 梯度下降法的原理是什么？在训练集上运行 mini-batch 梯度下降 法，你运行 for t=1……5000，因为我们有 5000 个各有 1000 个样本的组，在 for 循环里你 要做得基本就是对𝑋 {𝑡} 和𝑌 {𝑡} 执行一步梯度下降法。假设你有一个拥有 1000 个样本的训练集，而且假设你已经很熟悉一次性处理完的方法，你要用向量化去几乎同时处理 1000 个样本。

首先对输入也就是𝑋 {𝑡} ，执行前向传播，然后执行𝑧 [1] = 𝑊 [1] 𝑋 + 𝑏 [1] ，之前我们这里只

173 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

有，但是现在你正在处理整个训练集，你在处理第一个 mini-batch，在处理 mini-batch 时它 变成了𝑋 {𝑡} ，即𝑧 [1] = 𝑊 [1] 𝑋 {𝑡} + 𝑏 [1] ，然后执行𝐴 [1]𝑘 = 𝑔 [1] (𝑍 [1] )，之所以用大写的𝑍是因为 这是一个向量内涵，以此类推，直到𝐴 [𝐿] = 𝑔 [𝐿] (𝑍 [𝐿] )，这就是你的预测值。注意这里你需要 用到一个向量化的执行命令，这个向量化的执行命令，一次性处理 1000 个而不是 500 万个 样本。1 接下来你要计算损失成本函数𝐽，因为子集规模是 1000，𝐽 = ∑ 𝑖=1 𝑙 𝐿(𝑦 , 𝑦 (𝑖) )，说明

1000 

一下，这（𝐿(𝑦 , 𝑦 (𝑖) )）指的是来自于 mini-batch𝑋 {𝑡} 和𝑌 {𝑡} 中的样本。如果你用到了正则化，你也可以使用正则化的术语:

1 𝐽 = ∑ 𝑖=1 𝑙 𝐿(𝑦 , 𝑦 (𝑖) ) + 21000 𝜆 ∑ 𝑙 ||𝑤 [𝑙] ||2 𝐹 ，因为这是一个 mini-batch 的损失，所以我

1000 

1 将𝐽损失记为上角标𝑡，放在大括号里（𝐽 {𝑡} = 1000 ∑ 𝑖=1 𝑙 𝐿(𝑦 , 𝑦 (𝑖) ) + 21000 𝜆 ∑ 𝑙 ||𝑤 [𝑙] ||2 𝐹 ）。

你也会注意到，我们做的一切似曾相识，其实跟之前我们执行梯度下降法如出一辙，除 了你现在的对象不是𝑋，𝑌，而是𝑋 {𝑡} 和𝑌 {𝑡} 。接下来，你执行反向传播来计算𝐽{𝑡} 的梯度，你 只是使用𝑋 {𝑡} 和𝑌 {𝑡} ，然后你更新加权值，

𝑊实际上是𝑊 [𝑙] ，更新为𝑊 [𝑙] : = 𝑊 [𝑙] − 𝑎𝑑𝑊 [𝑙] ，

对𝑏做相同处理，𝑏 [𝑙] : = 𝑏 [𝑙] − 𝑎𝑑𝑏 [𝑙] 。

这是使用 mini-batch 梯度下降法训练样本的一步，我写下的代码也可被称为进行「一代」（1 epoch）的训练。一代这个词意味着只是一次遍历了训练集。

174 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

使用 batch 梯度下降法，一次遍历训练集只能让你做一个梯度下降，使用 mini-batch 梯 度下降法，一次遍历训练集，能让你做 5000 个梯度下降。当然正常来说你想要多次遍历训 练集，还需要为另一个 while 循环设置另一个 for 循环。所以你可以一直处理遍历训练集，直到最后你能收敛到一个合适的精度。

如果你有一个丢失的训练集，mini-batch 梯度下降法比 batch 梯度下降法运行地更快，所以几乎每个研习深度学习的人在训练巨大的数据集时都会用到，下一个视频中，我们将进 一步深度讨论 mini-batch 梯度下降法，你也会因此更好地理解它的作用和原理。

175 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.2 理解 mini-batch 梯度下降法（Understanding mini-batch gradient descent）

在上周视频中，你知道了如何利用 mini-batch 梯度下降法来开始处理训练集和开始梯度 下降，即使你只处理了部分训练集，即使你是第一次处理，本视频中，我们将进一步学习如 何执行梯度下降法，更好地理解其作用和原理。

使用 batch 梯度下降法时，每次迭代你都需要历遍整个训练集，可以预期每次迭代成本 都会下降，所以如果成本函数𝐽是迭代次数的一个函数，它应该会随着每次迭代而减少，如 果𝐽在某次迭代中增加了，那肯定出了问题，也许你的学习率太大。

使用 mini-batch 梯度下降法，如果你作出成本函数在整个过程中的图，则并不是每次迭 代都是下降的，特别是在每次迭代中，你要处理的是𝑋 {𝑡} 和𝑌 {𝑡} ，如果要作出成本函数𝐽{𝑡} 的 图，而𝐽 {𝑡} 只和𝑋 {𝑡} ，𝑌 {𝑡} 有关，也就是每次迭代下你都在训练不同的样本集或者说训练不同 的 mini-batch，如果你要作出成本函数𝐽的图，你很可能会看到这样的结果，走向朝下，但有 更多的噪声，所以如果你作出𝐽 {𝑡} 的图，因为在训练 mini-batch 梯度下降法时，会经过多代，你可能会看到这样的曲线。没有每次迭代都下降是不要紧的，但走势应该向下，噪声产生的 原因在于也许𝑋 {1} 和𝑌 {1} 是比较容易计算的 mini-batch，因此成本会低一些。不过也许出于偶 然，𝑋 {2} 和𝑌 {2} 是比较难运算的 mini-batch，或许你需要一些残缺的样本，这样一来，成本会 更高一些，所以才会出现这些摆动，因为你是在运行 mini-batch 梯度下降法作出成本函数 图。

你需要决定的变量之一是 mini-batch 的大小，𝑚就是训练集的大小，极端情况下:

如果 mini-batch 的大小等于𝑚，其实就是 batch 梯度下降法，在这种极端情况下，你就

176 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

有了 mini-batch 𝑋 {1} 和𝑌 {1} ，并且该 mini-batch 等于整个训练集，所以把 mini-batch 大小设 为𝑚可以得到 batch 梯度下降法。

另一个极端情况，假设 mini-batch 大小为 1，就有了新的算法，叫做随机梯度下降法，每个样本都是独立的 mini-batch，当你看第一个 mini-batch，也就是𝑋 {1} 和𝑌 {1} ，如果 minibatch 大小为 1，它就是你的第一个训练样本，这就是你的第一个训练样本。接着再看第二 个 mini-batch，也就是第二个训练样本，采取梯度下降步骤，然后是第三个训练样本，以此 类推，一次只处理一个。

看在两种极端下成本函数的优化情况，如果这是你想要最小化的成本函数的轮廓，最小 值在那里，batch 梯度下降法从某处开始，相对噪声低些，幅度也大一些，你可以继续找最 小值。

相反，在随机梯度下降法中，从某一点开始，我们重新选取一个起始点，每次迭代，你 只对一个样本进行梯度下降，大部分时候你向着全局最小值靠近，有时候你会远离最小值，因为那个样本恰好给你指的方向不对，因此随机梯度下降法是有很多噪声的，平均来看，它 最终会靠近最小值，不过有时候也会方向错误，因为随机梯度下降法永远不会收敛，而是会 一直在最小值附近波动，但它并不会在达到最小值并停留在此。

实际上你选择的 mini-batch 大小在二者之间，大小在 1 和𝑚之间，而 1 太小了，𝑚太大 了，原因在于如果使用 batch 梯度下降法，mini-batch 的大小为𝑚，每个迭代需要处理大量 训练样本，该算法的主要弊端在于特别是在训练样本数量巨大的时候，单次迭代耗时太长。

177 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

如果训练样本不大，batch 梯度下降法运行地很好。

相反，如果使用随机梯度下降法，如果你只要处理一个样本，那这个方法很好，这样做 没有问题，通过减小学习率，噪声会被改善或有所减小，但随机梯度下降法的一大缺点是，你会失去所有向量化带给你的加速，因为一次性只处理了一个训练样本，这样效率过于低下，所以实践中最好选择不大不小的 mini-batch 尺寸，实际上学习率达到最快。你会发现两个好 处，一方面，你得到了大量向量化，上个视频中我们用过的例子中，如果 mini-batch 大小为 1000 个样本，你就可以对 1000 个样本向量化，比你一次性处理多个样本快得多。另一方面，你不需要等待整个训练集被处理完就可以开始进行后续工作，再用一下上个视频的数字，每 次训练集允许我们采取 5000 个梯度下降步骤，所以实际上一些位于中间的 mini-batch 大小 效果最好。

用 mini-batch 梯度下降法，我们从这里开始，一次迭代这样做，两次，三次，四次，它 不会总朝向最小值靠近，但它比随机梯度下降要更持续地靠近最小值的方向，它也不一定在 很小的范围内收敛或者波动，如果出现这个问题，可以慢慢减少学习率，我们在下个视频会

178 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

讲到学习率衰减，也就是如何减小学习率。如果 mini-batch 大小既不是 1 也不是𝑚，应该取中间值，那应该怎么选择呢？其实是有 指导原则的。

首先，如果训练集较小，直接使用 batch 梯度下降法，样本集较小就没必要使用 minibatch 梯度下降法，你可以快速处理整个训练集，所以使用 batch 梯度下降法也很好，这里 的少是说小于 2000 个样本，这样比较适合使用 batch 梯度下降法。不然，样本数目较大的 话，一般的 mini-batch 大小为 64 到 512，考虑到电脑内存设置和使用的方式，如果 minibatch 大小是 2 的𝑛次方，代码会运行地快一些，64 就是 2 的 6 次方，以此类推，128 是 2 的 7 次方，256 是 2 的 8 次方，512 是 2 的 9 次方。所以我经常把 mini-batch 大小设成 2 的次 方。在上一个视频里，我的 mini-batch 大小设为了 1000，建议你可以试一下 1024，也就是 2 的 10 次方。也有 mini-batch 的大小为 1024，不过比较少见，64 到 512 的 mini-batch 比较 常见。

最后需要注意的是在你的 mini-batch 中，要确保𝑋 {𝑡} 和𝑌 {𝑡} 要符合 CPU/GPU 内存，取决 于你的应用方向以及训练集的大小。如果你处理的 mini-batch 和 CPU/GPU 内存不相符，不 管你用什么方法处理数据，你会注意到算法的表现急转直下变得惨不忍睹，所以我希望你对 一般人们使用的 mini-batch 大小有一个直观了解。事实上 mini-batch 大小是另一个重要的变 量，你需要做一个快速尝试，才能找到能够最有效地减少成本函数的那个，我一般会尝试几 个不同的值，几个不同的 2 次方，然后看能否找到一个让梯度下降优化算法最高效的大小。希望这些能够指导你如何开始找到这一数值。

你学会了如何执行 mini-batch 梯度下降，令算法运行得更快，特别是在训练样本数目较 大的情况下。不过还有个更高效的算法，比梯度下降法和 mini-batch 梯度下降法都要高效的 多，我们在接下来的视频中将为大家一一讲解。

179 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.3 指数加权平均数（Exponentially weighted averages）

我想向你展示几个优化算法，它们比梯度下降法快，要理解这些算法，你需要用到指数 加权平均，在统计中也叫做指数加权移动平均，我们首先讲这个，然后再来讲更复杂的优化 算 法 。

虽然现在我生活在美国，实际上我生于英国伦敦。比如我这儿有去年伦敦的每日温度，所以 1 月 1 号，温度是 40 华氏度，相当于 4 摄氏度。我知道世界上大部分地区使用摄氏度，但 是美国使用华氏度。在 1 月 2 号是 9 摄氏度等等。在年中的时候，一年 365 天，年中就是 说，大概 180 天的样子，也就是 5 月末，温度是 60 华氏度，也就是 15 摄氏度等等。夏季温 度转暖，然后冬季降温。

你用数据作图，可以得到以下结果，起始日在 1 月份，这里是夏季初，这里是年末，相 当于 12 月末。

180 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

这里是 1 月 1 号，年中接近夏季的时候，随后就是年末的数据，看起来有些杂乱，如果 要计算趋势的话，也就是温度的局部平均值，或者说移动平均值。

你要做的是，首先使𝑣 0 = 0，每天，需要使用 0.9 的加权数之前的数值加上当日温度的

0.1 倍，即𝑣 1 = 0.9𝑣 0 + 0.1𝜃1 ，所以这里是第一天的温度值。第二天，又可以获得一个加权平均数，0.9 乘以之前的值加上当日的温度 0.1 倍，即𝑣 2 =

0.9𝑣 1 + 0.1𝜃2 ，以此类推。第二天值加上第三日数据的 0.1，如此往下。大体公式就是某天的𝑣等于前一天𝑣值的 0.9 加上当日温度的 0.1。如此计算，然后用红线作图的话，便得到这样的结果。

你得到了移动平均值，每日温度的指数加权平均值。看一下上一张幻灯片里的公式，𝑣 𝑡 = 0.9𝑣 𝑡−1 + 0.1𝜃 𝑡 ，我们把 0.9 这个常数变成𝛽，将之

前的 0.1 变成 (1 − 𝛽)，即𝑣 𝑡 = 𝛽𝑣 𝑡−1 + (1 − 𝛽)𝜃𝑡

181 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

由于以后我们要考虑的原因，在计算时可视𝑣 𝑡 大概是 (1−𝛽) 1 的每日温度，如果𝛽是 0.9，你

会想，这是十天的平均值，也就是红线部分。我们来试试别的，将𝛽设置为接近 1 的一个值，比如 0.98，计算

1 (1−0.98) 

= 50，这就是粗

略平均了一下，过去 50 天的温度，这时作图可以得到绿线。

这个高值𝛽要注意几点，你得到的曲线要平坦一些，原因在于你多平均了几天的温度，所以这个曲线，波动更小，更加平坦，缺点是曲线进一步右移，因为现在平均的温度值更多，要平均更多的值，指数加权平均公式在温度变化时，适应地更缓慢一些，所以会出现一定延 迟，因为当𝛽 = 0.98，相当于给前一天的值加了太多权重，只有 0.02 的权重给了当日的值，所以温度变化时，温度上下起伏，当𝛽 较大时，指数加权平均值适应地更缓慢一些。

我们可以再换一个值试一试，如果𝛽是另一个极端值，比如说 0.5，根据右边的公式 1 （ (1−𝛽) ），这是平均了两天的温度。

作图运行后得到黄线。

由于仅平均了两天的温度，平均的数据太少，所以得到的曲线有更多的噪声，有可能出 现异常值，但是这个曲线能够更快适应温度变化。

182 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

所以指数加权平均数经常被使用，再说一次，它在统计学中被称为指数加权移动平均值，我们就简称为指数加权平均数。通过调整这个参数（𝛽），或者说后面的算法学习，你会发 现这是一个很重要的参数，可以取得稍微不同的效果，往往中间有某个值效果最好，𝛽为中 间值时得到的红色曲线，比起绿线和黄线更好地平均了温度。

现在你知道计算指数加权平均数的基本原理，下一个视频中，我们再聊聊它的本质作用。

183 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.4 理 解 指 数 加 权 平 均 数 （ Understanding exponentially weighted averages）

上个视频中，我们讲到了指数加权平均数，这是几个优化算法中的关键一环，而这几个 优化算法能帮助你训练神经网络。本视频中，我希望进一步探讨算法的本质作用。回忆一下这个计算指数加权平均数的关键方程。

𝑣 𝑡 = 𝛽𝑣 𝑡−1 + (1 − 𝛽)𝜃𝑡 

𝛽 = 0.9 的时候，得到的结果是红线，如果它更接近于 1，比如 0.98，结果就是绿线，如 果𝛽小一点，如果是 0.5，结果就是黄线。

我们进一步地分析，来理解如何计算出每日温度的平均值。同样的公式，𝑣 𝑡 = 𝛽𝑣 𝑡−1 + (1 − 𝛽)𝜃𝑡

使𝛽 = 0.9，写下相应的几个公式，所以在执行的时候，𝑡从 0 到 1 到 2 到 3，𝑡的值在不 断增加，为了更好地分析，我写的时候使得𝑡的值不断减小，然后继续往下写。

首先看第一个公式，理解𝑣 100 是什么？我们调换一下这两项（0.9𝑣 99 0.1𝜃100 ），𝑣 100 =

0.1𝜃 100 + 0.9𝑣 99 。

那么𝑣99 是什么？我们就代入这个公式（𝑣 99 = 0.1𝜃 99 + 0.9𝑣98 ），所以：

𝑣 100 = 0.1𝜃 100 + 0.9(0.1𝜃 99 + 0.9𝑣 98 )。

那么𝑣98 是什么？你可以用这个公式计算（𝑣 98 = 0.1𝜃 98 + 0.9𝑣97 ），把公式代进去，所 以：

𝑣 100 = 0.1𝜃 100 + 0.9(0.1𝜃 99 + 0.9(0.1𝜃 98 + 0.9𝑣 97 ))。

184 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

以此类推，如果你把这些括号都展开，

𝑣 100 = 0.1𝜃 100 + 0.1 × 0.9𝜃 99 + 0.1 × (0.9) 2 𝜃 98 + 0.1 × (0.9) 3 𝜃 97 + 0.1 × (0.9) 4 𝜃 96 + ⋯ 

所以这是一个加和并平均，100 号数据，也就是当日温度。我们分析𝑣 100 的组成，也就 是在一年第 100 天计算的数据，但是这个是总和，包括 100 号数据，99 号数据，97 号数据 等等。画图的一个办法是，假设我们有一些日期的温度，所以这是数据，这是𝑡，所以 100 号 数据有个数值，99 号数据有个数值，98 号数据等等，𝑡为 100，99，98 等等，这就是数日的 温度数值。

然后我们构建一个指数衰减函数，从 0.1 开始，到 0.1 × 0.9，到 0.1 × (0.9) 2 ，以此类推，所以就有了这个指数衰减函数。

计算𝑣 100 是通过，把两个函数对应的元素，然后求和，用这个数值 100 号数据值乘以 0.1，99 号数据值乘以 0.1 乘以 (0.9) 2 ，这是第二项，以此类推，所以选取的是每日温度，将其与 指数衰减函数相乘，然后求和，就得到了𝑣 100 。

185 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

结果是，稍后我们详细讲解，不过所有的这些系数（0.10.1 × 0.90.1 × (0.9) 2 0.1 × (0.9) 3 …），相加起来为 1 或者逼近 1，我们称之为偏差修正，下个视频会涉及。

最后也许你会问，到底需要平均多少天的温度。实际上 (0.9) 10 大约为 0.35，这大约是 1 ，𝑒 e 是自然算法的基础之一。大体上说，如果有 1 − 𝜀，在这个例子中，𝜀 = 0.1，所以 1 − 𝜀 = 0.9，(1 − 𝜀)𝜀 (1) 约等于 1 𝑒 ，大约是 0.34，0.35，换句话说，10 天后，曲线的高度下降到 1 3 ，相当 于在峰值的 1 𝑒 。

又因此当𝛽 = 0.9 的时候，我们说仿佛你在计算一个指数加权平均数，只关注了过去 10 天的温度，因为 10 天后，权重下降到不到当日权重的三分之一。

相反，如果，那么 0.98 需要多少次方才能达到这么小的数值？(0.98) 50 大约等于 1 𝑒 ，所

186 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

以前 50 天这个数值比 1 大，数值会快速衰减，所以本质上这是一个下降幅度很大的函数，你

𝑒 

可以看作平均了 50 天的温度。因为在例子中，要代入等式的左边，𝜀 = 0.02，所以 1 𝜀 为 50，

1 (1−𝛽) 

我们由此得到公式，我们平均了大约

天的温度，这里𝜀代替了 1 − 𝛽，也就是说根据一些

常数，你能大概知道能够平均多少日的温度，不过这只是思考的大致方向，并不是正式的数 学证明。

最后讲讲如何在实际中执行，还记得吗？我们一开始将𝑣 0 设置为 0，然后计算第一天𝑣 1 ，然后𝑣 2 ，以此类推。

现在解释一下算法，可以将𝑣 0 ，𝑣 1 ，𝑣 2 等等写成明确的变量，不过在实际中执行的话，你要做的是，一开始将𝑣初始化为 0，然后在第一天使𝑣: = 𝛽𝑣 + (1 − 𝛽)𝜃1 ，然后第二天，更 新𝑣值，𝑣: = 𝛽𝑣 + (1 − 𝛽)𝜃2 ，以此类推，有些人会把𝑣加下标，来表示𝑣是用来计算数据的指 数加权平均数。

再说一次，但是换个说法，𝑣 𝜃 = 0，然后每一天，拿到第𝑡天的数据，把𝑣更新为𝑣: = 𝛽𝑣 𝜃 + (1 − 𝛽)𝜃 𝑡 。指数加权平均数公式的好处之一在于，它占用极少内存，电脑内存中只占用一行数字而

187 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

已，然后把最新数据代入公式，不断覆盖就可以了，正因为这个原因，其效率，它基本上只 占用一行代码，计算指数加权平均数也只占用单行数字的存储和内存，当然它并不是最好的，也不是最精准的计算平均数的方法。如果你要计算移动窗，你直接算出过去 10 天的总和，过去 50 天的总和，除以 10 和 50 就好，如此往往会得到更好的估测。但缺点是，如果保存 所有最近的温度数据，和过去 10 天的总和，必须占用更多的内存，执行更加复杂，计算成 本也更加高昂。

所以在接下来的视频中，我们会计算多个变量的平均值，从计算和内存效率来说，这是 一个有效的方法，所以在机器学习中会经常使用，更不用说只要一行代码，这也是一个优势。

现在你学会了计算指数加权平均数，你还需要知道一个专业概念，叫做偏差修正，下一 个视频我们会讲到它，接着你就可以用它构建更好的优化算法，而不是简单直接的梯度下降 法。

188 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.5 指 数 加 权 平 均 的 偏 差 修 正 （ Bias correction in exponentially weighted averages）

你学过了如何计算指数加权平均数，有一个技术名词叫做偏差修正，可以让平均数运算 更加准确，来看看它是怎么运行的。

𝑣 𝑡 = 𝛽𝑣 𝑡−1 + (1 − 𝛽)𝜃𝑡 

在上一个视频中，这个（红色）曲线对应𝛽的值为 0.9，这个（绿色）曲线对应的𝛽=0.98，如果你执行写在这里的公式，在𝛽等于 0.98 的时候，得到的并不是绿色曲线，而是紫色曲线，你可以注意到紫色曲线的起点较低，我们来看看怎么处理。

计算移动平均数的时候，初始化𝑣 0 = 0，𝑣 1 = 0.98𝑣 0 + 0.02𝜃1 ，但是𝑣 0 = 0，所以这部 分没有了（0.98𝑣 ），所以𝑣 1 = 0.02𝜃1 ，所以如果一天温度是 40 华氏度，那么𝑣 1 = 0.02𝜃 1 =

0.02 × 40 = 8，因此得到的值会小很多，所以第一天温度的估测不准。𝑣 2 = 0.98𝑣 1 + 0.02𝜃 2 ，如果代入𝑣 1 ，然后相乘，所以𝑣 2 = 0.98 × 0.02𝜃 1 + 0.02𝜃 2 =

0.0196𝜃 1 + 0.02𝜃2 ，假设𝜃1 和𝜃2 都是正数，计算后𝑣 2 要远小于𝜃1 和𝜃2 ，所以𝑣 2 不能很好估测 出这一年前两天的温度。

有个办法可以修改这一估测，让估测变得更好，更准确，特别是在估测初期，也就是不 用𝑣 𝑡 ，而是用 1−𝛽 𝑡 𝑣 𝑡 ，t 就是现在的天数。举个具体例子，当𝑡 = 2 时，1 − 𝛽 𝑡 = 1 − 0.98 2 = 0.0396，

𝑣 2 0.0396 

因此对第二天温度的估测变成了

= 

0.0196𝜃 1 +0.02𝜃 

2 ，也就是𝜃1 和𝜃2 的加权平均数，并去除 0.0396

189 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

了偏差。你会发现随着𝑡增加，𝛽 𝑡 接近于 0，所以当𝑡很大的时候，偏差修正几乎没有作用，因此当𝑡较大的时候，紫线基本和绿线重合了。不过在开始学习阶段，你才开始预测热身练 习，偏差修正可以帮助你更好预测温度，偏差修正可以帮助你使结果从紫线变成绿线。

在机器学习中，在计算指数加权平均数的大部分时候，大家不在乎执行偏差修正，因为 大部分人宁愿熬过初始时期，拿到具有偏差的估测，然后继续计算下去。如果你关心初始时 期的偏差，在刚开始计算指数加权移动平均数的时候，偏差修正能帮助你在早期获取更好的 估测。

所以你学会了计算指数加权移动平均数，我们接着用它来构建更好的优化算法吧！

190 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.6 动量梯度下降法（Gradient descent with Momentum）

还有一种算法叫做 Momentum，或者叫做动量梯度下降法，运行速度几乎总是快于标 准的梯度下降算法，简而言之，基本的想法就是计算梯度的指数加权平均数，并利用该梯度 更新你的权重，在本视频中，我们呢要一起拆解单句描述，看看你到底如何计算。

例如，如果你要优化成本函数，函数形状如图，红点代表最小值的位置，假设你从这里 （蓝色点）开始梯度下降法，如果进行梯度下降法的一次迭代，无论是 batch 或 mini-batch 下降法，也许会指向这里，现在在椭圆的另一边，计算下一步梯度下降，结果或许如此，然 后再计算一步，再一步，计算下去，你会发现梯度下降法要很多计算步骤对吧？

慢慢摆动到最小值，这种上下波动减慢了梯度下降法的速度，你就无法使用更大的学习 率，如果你要用较大的学习率（紫色箭头），结果可能会偏离函数的范围，为了避免摆动过 大，你要用一个较小的学习率。

另一个看待问题的角度是，在纵轴上，你希望学习慢一点，因为你不想要这些摆动，但 是在横轴上，你希望加快学习，你希望快速从左向右移，移向最小值，移向红点。所以使用 动量梯度下降法，你需要做的是，在每次迭代中，确切来说在第𝑡次迭代的过程中，你会计 算微分𝑑𝑊，𝑑𝑏，我会省略上标 [𝑙]，你用现有的 mini-batch 计算𝑑𝑊，𝑑𝑏。如果你用 batch 梯 度下降法，现在的 mini-batch 就是全部的 batch，对于 batch 梯度下降法的效果是一样的。如果现有的 mini-batch 就是整个训练集，效果也不错，你要做的是计算𝑣 𝑑𝑊 = 𝛽𝑣 𝑑𝑊 +

191 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

− 𝛽)𝜃 𝑡 ，𝑑𝑊的移动平均数，接 着同样地计算𝑣 𝑑𝑏 𝑣 𝑑𝑏 = 𝛽𝑣 𝑑𝑏 + (1 − 𝛽)𝑑𝑏，然后重新赋值权重，𝑊: = 𝑊 − 𝑎𝑣 𝑑𝑊 ，同样𝑏: =

(1 

− 𝛽)𝑑𝑊，这跟我们之前的计算相似，也就是𝑣 = 𝛽𝑣 +

(1 

，𝑏 − 𝑎𝑣 𝑑𝑏 ，这样就可以减缓梯度下降的幅度。

例如，在上几个导数中，你会发现这些纵轴上的摆动平均值接近于零，所以在纵轴方向，你希望放慢一点，平均过程中，正负数相互抵消，所以平均值接近于零。但在横轴方向，所 有的微分都指向横轴方向，因此横轴方向的平均值仍然较大，因此用算法几次迭代后，你发 现动量梯度下降法，最终纵轴方向的摆动变小了，横轴方向运动更快，因此你的算法走了一 条更加直接的路径，在抵达最小值的路上减少了摆动。

动量梯度下降法的一个本质，这对有些人而不是所有人有效，就是如果你要最小化碗状 函数，这是碗的形状，我画的不太好。

它们能够最小化碗状函数，这些微分项，想象它们为你从山上往下滚的一个球，提供了 加速度，Momentum 项相当于速度。

想象你有一个碗，你拿一个球，微分项给了这个球一个加速度，此时球正向山下滚，球 因为加速度越滚越快，而因为𝛽 稍小于 1，表现出一些摩擦力，所以球不会无限加速下去，所以不像梯度下降法，每一步都独立于之前的步骤，你的球可以向下滚，获得动量，可以从 碗向下加速获得动量。我发现这个球从碗滚下的比喻，物理能力强的人接受得比较好，但不 是所有人都能接受，如果球从碗中滚下这个比喻，你理解不了，别担心。

最后我们来看具体如何计算，算法在此。

192 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

所以你有两个超参数，学习率𝑎以及参数𝛽，𝛽控制着指数加权平均数。𝛽最常用的值是 0.9，我们之前平均了过去十天的温度，所以现在平均了前十次迭代的梯度。实际上𝛽为 0.9 时，效果不错，你可以尝试不同的值，可以做一些超参数的研究，不过 0.9 是很棒的鲁棒数。那么关于偏差修正，所以你要拿𝑣 𝑑𝑊 和𝑣 𝑑𝑏 除以 1 − 𝛽 𝑡 ，实际上人们不这么做，因为 10 次迭 代之后，因为你的移动平均已经过了初始阶段。实际中，在使用梯度下降法或动量梯度下降 法时，人们不会受到偏差修正的困扰。当然𝑣 𝑑𝑊 初始值是 0，要注意到这是和𝑑𝑊拥有相同维 数的零矩阵，也就是跟𝑊拥有相同的维数，𝑣 𝑑𝑏 的初始值也是向量零，所以和𝑑𝑏拥有相同的 维数，也就是和𝑏是同一维数。

最后要说一点，如果你查阅了动量梯度下降法相关资料，你经常会看到一个被删除了的 专业词汇，1 − 𝛽被删除了，最后得到的是𝑣 𝑑𝑊 = 𝛽𝑣 𝑑𝑊 + 𝑑𝑊。用紫色版本的结果就是，所 以𝑣 𝑑𝑊 缩小了 1 − 𝛽倍，相当于乘以 1−𝛽 1 ，所以你要用梯度下降最新值的话，𝑎要根据 1−𝛽 1 相应

193 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

变化。实际上，二者效果都不错，只会影响到学习率𝑎的最佳值。我觉得这个公式用起来没 有那么自然，因为有一个影响，如果你最后要调整超参数𝛽，就会影响到𝑣 𝑑𝑊 和𝑣 𝑑𝑏 ，你也许 还要修改学习率𝑎，所以我更喜欢左边的公式，而不是删去了 1 − 𝛽的这个公式，所以我更倾 向于使用左边的公式，也就是有 1 − 𝛽的这个公式，但是两个公式都将𝛽设置为 0.9，是超参 数的常见选择，只是在这两个公式中，学习率𝑎的调整会有所不同。所以这就是动量梯度下降法，这个算法肯定要好于没有 Momentum 的梯度下降算法，我们还可以做别的事情来加快学习算法，我们将在接下来的视频中探讨这些问题。

194 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.7 RMSprop 

你们知道了动量（Momentum）可以加快梯度下降，还有一个叫做 RMSprop 的算法，全称是 root mean square prop 算法，它也可以加速梯度下降，我们来看看它是如何运作的。

回忆一下我们之前的例子，如果你执行梯度下降，虽然横轴方向正在推进，但纵轴方向 会有大幅度摆动，为了分析这个例子，假设纵轴代表参数𝑏，横轴代表参数𝑊，可能有𝑊 1 ，𝑊2 或者其它重要的参数，为了便于理解，被称为𝑏和𝑊。

所以，你想减缓𝑏方向的学习，即纵轴方向，同时加快，至少不是减缓横轴方向的学习，RMSprop 算法可以实现这一点。

在第𝑡次迭代中，该算法会照常计算当下 mini-batch 的微分𝑑𝑊，𝑑𝑏，所以我会保留这个 指数加权平均数，我们用到新符号𝑆 𝑑𝑊 ，而不是𝑣 𝑑𝑊 ，因此𝑆 𝑑𝑊 = 𝛽𝑆 𝑑𝑊 + (1 − 𝛽)𝑑𝑊2 ，澄清 一下，这个平方的操作是针对这一整个符号的，这样做能够保留微分平方的加权平均数，同 样𝑆 𝑑𝑏 = 𝛽𝑆 𝑑𝑏 + (1 − 𝛽)𝑑𝑏 2 ，再说一次，平方是针对整个符号的操作。

𝑑𝑊 𝑑𝑏 接着 RMSprop 会这样更新参数值，𝑊: = 𝑊 − 𝑎 ，𝑏: = 𝑏 − 𝛼 ，我们来理解一下

√𝑆 

𝑑𝑊 

√𝑆 

𝑑𝑏 

其原理。记得在横轴方向或者在例子中的𝑊方向，我们希望学习速度快，而在垂直方向，也 就是例子中的𝑏方向，我们希望减缓纵轴上的摆动，所以有了𝑆 𝑑𝑊 和𝑆 𝑑𝑏 ，我们希望𝑆 𝑑𝑊 会相 对较小，所以我们要除以一个较小的数，而希望𝑆 𝑑𝑏 又较大，所以这里我们要除以较大的数 字，这样就可以减缓纵轴上的变化。你看这些微分，垂直方向的要比水平方向的大得多，所

195 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

以斜率在𝑏方向特别大，所以这些微分中，𝑑𝑏较大，𝑑𝑊较小，因为函数的倾斜程度，在纵轴 上，也就是 b 方向上要大于在横轴上，也就是𝑊方向上。𝑑𝑏的平方较大，所以𝑆 𝑑𝑏 也会较大，而相比之下，𝑑𝑊会小一些，亦或𝑑𝑊平方会小一些，因此𝑆 𝑑𝑊 会小一些，结果就是纵轴上的 更新要被一个较大的数相除，就能消除摆动，而水平方向的更新则被较小的数相除。

RMSprop 的影响就是你的更新最后会变成这样（绿色线），纵轴方向上摆动较小，而横 轴方向继续推进。还有个影响就是，你可以用一个更大学习率𝑎，然后加快学习，而无须在 纵轴上垂直方向偏离。

要说明一点，我一直把纵轴和横轴方向分别称为𝑏和𝑊，只是为了方便展示而已。实际 中，你会处于参数的高维度空间，所以需要消除摆动的垂直维度，你需要消除摆动，实际上 是参数𝑊1 ，𝑊2 等的合集，水平维度可能𝑊3 ，𝑊 4 等等，因此把𝑊和𝑏分开只是方便说明。实 际中𝑑𝑊是一个高维度的参数向量，𝑑𝑏也是一个高维度参数向量，但是你的直觉是，在你要 消除摆动的维度中，最终你要计算一个更大的和值，这个平方和微分的加权平均值，所以你 最后去掉了那些有摆动的方向。所以这就是 RMSprop，全称是均方根，因为你将微分进行平 方，然后最后使用平方根。

最后再就这个算法说一些细节的东西，然后我们再继续。下一个视频中，我们会将 RMSprop 和 Momentum 结合起来，我们在 Momentum 中采用超参数𝛽，为了避免混淆，我 们现在不用𝛽，而采用超参数𝛽 2 以保证在 Momentum 和 RMSprop 中采用同一超参数。要确 保你的算法不会除以 0，如果𝑆 𝑑𝑊 的平方根趋近于 0 怎么办？得到的答案就非常大，为了确 保数值稳定，在实际操练的时候，你要在分母上加上一个很小很小的𝜀，𝜀是多少没关系，10−8 是个不错的选择，这只是保证数值能稳定一些，无论什么原因，你都不会除以一个很小很小 的数。所以 RMSprop 跟 Momentum 有很相似的一点，可以消除梯度下降中的摆动，包括

196 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

mini-batch 梯度下降，并允许你使用一个更大的学习率𝑎，从而加快你的算法学习速度。所以你学会了如何运用 RMSprop，这是给学习算法加速的另一方法。关于 RMSprop 的 一个有趣的事是，它首次提出并不是在学术研究论文中，而是在多年前 Jeff Hinton 在 Coursera 的课程上。我想 Coursera 并不是故意打算成为一个传播新兴的学术研究的平台，但是却达 到了意想不到的效果。就是从 Coursera 课程开始，RMSprop 开始被人们广为熟知，并且发 展迅猛。

我们讲过了 Momentum，我们讲了 RMSprop，如果二者结合起来，你会得到一个更好 的优化算法，在下个视频中我们再好好讲一讲为什么。

197 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.8 Adam 优化算法 (Adam optimization algorithm)

在深度学习的历史上，包括许多知名研究者在内，提出了优化算法，并很好地解决了一 些问题，但随后这些优化算法被指出并不能一般化，并不适用于多种神经网络，时间久了，深度学习圈子里的人开始多少有些质疑全新的优化算法，很多人都觉得动量（Momentum） 梯度下降法很好用，很难再想出更好的优化算法。所以 RMSprop 以及 Adam 优化算法（Adam 优化算法也是本视频的内容），就是少有的经受住人们考验的两种算法，已被证明适用于不 同的深度学习结构，这个算法我会毫不犹豫地推荐给你，因为很多人都试过，并且用它很好 地解决了许多问题。

Adam 优化算法基本上就是将 Momentum 和 RMSprop 结合在一起，那么来看看如何使 用 Adam 算法。

使用 Adam 算法，首先你要初始化，𝑣 𝑑𝑊 = 0，𝑆 𝑑𝑊 = 0，𝑣 𝑑𝑏 = 0，𝑆 𝑑𝑏 = 0，在第𝑡次迭 代中，你要计算微分，用当前的 mini-batch 计算𝑑𝑊，𝑑𝑏，一般你会用 mini-batch 梯度下降 法。接下来计算 Momentum 指数加权平均数，所以𝑣 𝑑𝑊 = 𝛽 1 𝑣 𝑑𝑊 + (1 − 𝛽 1)𝑑𝑊（使用𝛽 1 ，这样就不会跟超参数𝛽 2 混淆，因为后面 RMSprop 要用到𝛽 2 ），使用 Momentum 时我们肯定 会用这个公式，但现在不叫它𝛽，而叫它𝛽 1 。同样𝑣 𝑑𝑏 = 𝛽 1 𝑣 𝑑𝑏 + (1 − 𝛽 1)𝑑𝑏。

接着你用 RMSprop 进行更新，即用不同的超参数𝛽 2 ，𝑆 𝑑𝑊 = 𝛽 2 𝑆 𝑑𝑊 + (1 − 𝛽 2)(𝑑𝑊) 2 ，再说一次，这里是对整个微分𝑑𝑊进行平方处理，𝑆 𝑑𝑏 = 𝛽 2 𝑆 𝑑𝑏 + (1 − 𝛽 2)(𝑑𝑏) 2 。

相当于 Momentum 更新了超参数𝛽 1 ，RMSprop 更新了超参数𝛽 2 。一般使用 Adam 算法

198 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

的时候，要计算偏差修正，𝑣 𝑑𝑊 corrected ，修正也就是在偏差修正之后，

𝑣 𝑣 𝑑𝑊 corrected = 1−𝛽 𝑑𝑊 1 𝑡 ，

𝑣 同样𝑣 𝑑𝑏 corrected = 𝑑𝑏 1 𝑡 ，1−𝛽

𝑆 𝑆 𝑆也使用偏差修正，也就是𝑆 𝑑𝑊 corrected = 𝑑𝑊 2 𝑡 ，𝑆 𝑑𝑏 corrected = 𝑑𝑏 2 𝑡 。1−𝛽 1−𝛽

corrected 

最后更新权重，所以𝑊更新后是𝑊: = 𝑊 −

𝑎𝑣 𝑑𝑊 

（如果你只是用 Momentum，使

√𝑆 𝑑𝑊 corrected 

+𝜀 

用𝑣 𝑑𝑊 或者修正后的𝑣 𝑑𝑊 ，但现在我们加入了 RMSprop 的部分，所以我们要除以修正后𝑆𝑑𝑊 的平方根加上𝜀）。

𝛼𝑣db corrected 根据类似的公式更新𝑏值，𝑏: = 𝑏 − 。

√𝑆 db corrected 

+𝜀 

所以 Adam 算法结合了 Momentum 和 RMSprop 梯度下降法，并且是一种极其常用的学 习算法，被证明能有效适用于不同神经网络，适用于广泛的结构。

本算法中有很多超参数，超参数学习率𝑎很重要，也经常需要调试，你可以尝试一系列 值，然后看哪个有效。𝛽 1 常用的缺省值为 0.9，这是 dW 的移动平均数，也就是𝑑𝑊的加权平 均数，这是 Momentum 涉及的项。至于超参数𝛽 2 ，Adam 论文作者，也就是 Adam 算法的发 明者，推荐使用 0.999，这是在计算 (𝑑𝑊) 2 以及 (𝑑𝑏) 2 的移动加权平均值，关于𝜀的选择其实 没那么重要，Adam 论文的作者建议𝜀为 10−8 ，但你并不需要设置它，因为它并不会影响算 法表现。但是在使用 Adam 的时候，人们往往使用缺省值即可，𝛽 1 ，𝛽 2 和𝜀都是如此，我觉 得没人会去调整𝜀，然后尝试不同的𝑎值，看看哪个效果最好。你也可以调整𝛽 1 和𝛽 2 ，但我认 识的业内人士很少这么干。

为什么这个算法叫做 Adam？Adam 代表的是 Adaptive Moment Estimation，𝛽 1 用于计算

199 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

这个微分（𝑑𝑊），叫做第一矩，𝛽 2 用来计算平方数的指数加权平均数（(𝑑𝑊) 2 ），叫做第 二矩，所以 Adam 的名字由此而来，但是大家都简称 Adam 权威算法。顺便提一下，我有一个老朋友兼合作伙伴叫做 Adam Coates。据我所知，他跟 Adam 算 法没有任何关系，不过我觉得他偶尔会用到这个算法，不过有时有人会问我这个问题，我想 你可能也有相同的疑惑。

这就是关于 Adam 优化算法的全部内容，有了它，你可以更加快速地训练神经网络，在 结束本周课程之前，我们还要讲一下超参数调整，以及更好地理解神经网络的优化问题有哪 些。下个视频中，我们将讲讲学习率衰减。

200 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.9 学习率衰减 (Learning rate decay)

加快学习算法的一个办法就是随时间慢慢减少学习率，我们将之称为学习率衰减，我们 来看看如何做到，首先通过一个例子看看，为什么要计算学习率衰减。

假设你要使用 mini-batch 梯度下降法，mini-batch 数量不大，大概 64 或者 128 个样本，在迭代过程中会有噪音（蓝色线），下降朝向这里的最小值，但是不会精确地收敛，所以你 的算法最后在附近摆动，并不会真正收敛，因为你用的𝑎是固定值，不同的 mini-batch 中有 噪音。

但要慢慢减少学习率𝑎的话，在初期的时候，𝑎学习率还较大，你的学习还是相对较快，但随着𝑎变小，你的步伐也会变慢变小，所以最后你的曲线（绿色线）会在最小值附近的一 小块区域里摆动，而不是在训练过程中，大幅度在最小值附近摆动。

所以慢慢减少𝑎的本质在于，在学习初期，你能承受较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些。

你可以这样做到学习率衰减，记得一代要遍历一次数据，如果你有以下这样的训练集:

你应该拆分成不同的 mini-batch，第一次遍历训练集叫做第一代。第二次就是第二代，

201 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

依此类推，你可以将𝑎学习率设为𝑎 =

1 1+𝑑𝑒𝑐𝑎𝑦𝑟𝑎𝑡𝑒∗epoch−num 

𝑎（decay-rate 称为衰减率，epoch0 num 为代数，𝛼0 为初始学习率），注意这个衰减率是另一个你需要调整的超参数。

这里有一个具体例子，如果你计算了几代，也就是遍历了几次，如果𝑎 0 为 0.2，衰减率 1 decay-rate 为 1，那么在第一代中，𝑎 = 1+1 𝑎 0 = 0.1，这是在代入这个公式计算

𝑎 = 

1 1+𝑑𝑒𝑐𝑎𝑦𝑟𝑎𝑡𝑒∗epoch−num 

𝑎 0 ，

此时衰减率是 1 而代数是 1。在第二代学习率为 0.67，第三代变成 0.5，第四代为 0.4 等 等，你可以自己多计算几个数据。要理解，作为代数函数，根据上述公式，你的学习率呈递 减趋势。如果你想用学习率衰减，要做的是要去尝试不同的值，包括超参数𝑎 0 ，以及超参数 衰退率，找到合适的值，除了这个学习率衰减的公式，人们还会用其它的公式。

比如，这个叫做指数衰减，其中𝑎相当于一个小于 1 的值，如𝑎 = 0.95 epoch−num 𝑎0 ，所 以你的学习率呈指数下降。

202 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

𝑘 𝑘 人们用到的其它公式有𝑎 = 𝑎0 或者𝑎 = 𝑎0 （𝑡为 mini-batch 的数字）。√epoch−num √ 𝑡

有时人们也会用一个离散下降的学习率，也就是某个步骤有某个学习率，一会之后，学 习率减少了一半，一会儿减少一半，一会儿又一半，这就是离散下降（discrete stair cease） 的意思。

到现在，我们讲了一些公式，看学习率𝑎究竟如何随时间变化。人们有时候还会做一件 事，手动衰减。如果你一次只训练一个模型，如果你要花上数小时或数天来训练，有些人的 确会这么做，看看自己的模型训练，耗上数日，然后他们觉得，学习速率变慢了，我把𝑎调 小一点。手动控制𝑎当然有用，时复一时，日复一日地手动调整𝑎，只有模型数量小的时候有 用，但有时候人们也会这么做。

所以现在你有了多个选择来控制学习率𝑎。你可能会想，好多超参数，究竟我应该做哪 一个选择，我觉得，现在担心为时过早。下一周，我们会讲到，如何系统选择超参数。对我 而言，学习率衰减并不是我尝试的要点，设定一个固定的𝑎，然后好好调整，会有很大的影 响，学习率衰减的确大有裨益，有时候可以加快训练，但它并不是我会率先尝试的内容，但 下周我们将涉及超参数调整，你能学到更多系统的办法来管理所有的超参数，以及如何高效 搜索超参数。

这就是学习率衰减，最后我还要讲讲神经网络中的局部最优以及鞍点，所以能更好理解 在训练神经网络过程中，你的算法正在解决的优化问题，下个视频我们就好好聊聊这些问题。

203 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

2.10 局部最优的问题 (The problem of local optima)

在深度学习研究早期，人们总是担心优化算法会困在极差的局部最优，不过随着深度学 习理论不断发展，我们对局部最优的理解也发生了改变。我向你展示一下现在我们怎么看待 局部最优以及深度学习中的优化问题。

这是曾经人们在想到局部最优时脑海里会出现的图，也许你想优化一些参数，我们把它 们称之为𝑊1 和𝑊2 ，平面的高度就是损失函数。在图中似乎各处都分布着局部最优。梯度下 降法或者某个算法可能困在一个局部最优中，而不会抵达全局最优。如果你要作图计算一个 数字，比如说这两个维度，就容易出现有多个不同局部最优的图，而这些低维的图曾经影响 了我们的理解，但是这些理解并不正确。事实上，如果你要创建一个神经网络，通常梯度为 零的点并不是这个图中的局部最优点，实际上成本函数的零梯度点，通常是鞍点。

也就是在这个点，这里是𝑊1 和𝑊2 ，高度即成本函数𝐽的值。

204 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

但是一个具有高维度空间的函数，如果梯度为 0，那么在每个方向，它可能是凸函数，也可能是凹函数。如果你在 2 万维空间中，那么想要得到局部最优，所有的 2 万个方向都需 要是这样，但发生的机率也许很小，也许是 2 −20000 ，你更有可能遇到有些方向的曲线会这样 向上弯曲，另一些方向曲线向下弯，而不是所有的都向上弯曲，因此在高维度空间，你更可 能碰到鞍点。

就像下面的这种：

而不会碰到局部最优。至于为什么会把一个曲面叫做鞍点，你想象一下，就像是放在马 背上的马鞍一样，如果这是马，这是马的头，这就是马的眼睛，画得不好请多包涵，然后你 就是骑马的人，要坐在马鞍上，因此这里的这个点，导数为 0 的点，这个点叫做鞍点。我想 那确实是你坐在马鞍上的那个点，而这里导数为 0。

205 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第二周：优化算法 (Optimization algorithms)

所以我们从深度学习历史中学到的一课就是，我们对低维度空间的大部分直觉，比如你 可以画出上面的图，并不能应用到高维度空间中。适用于其它算法，因为如果你有 2 万个参 数，那么𝐽函数有 2 万个维度向量，你更可能遇到鞍点，而不是局部最优点。

如果局部最优不是问题，那么问题是什么？结果是平稳段会减缓学习，平稳段是一块区 域，其中导数长时间接近于 0，如果你在此处，梯度会从曲面从从上向下下降，因为梯度等 于或接近 0，曲面很平坦，你得花上很长时间慢慢抵达平稳段的这个点，因为左边或右边的 随机扰动，我换个笔墨颜色，大家看得清楚一些，然后你的算法能够走出平稳段（红色笔）。

我们可以沿着这段长坡走，直到这里，然后走出平稳段。

所以此次视频的要点是，首先，你不太可能困在极差的局部最优中，条件是你在训练较 大的神经网络，存在大量参数，并且成本函数𝐽被定义在较高的维度空间。

第二点，平稳段是一个问题，这样使得学习十分缓慢，这也是像 Momentum 或是 RMSprop，Adam 这样的算法，能够加速学习算法的地方。在这些情况下，更成熟的优化算 法，如 Adam 算法，能够加快速度，让你尽早往下走出平稳段。

因为你的网络要解决优化问题，说实话，要面临如此之高的维度空间，我觉得没有人有 那么好的直觉，知道这些空间长什么样，而且我们对它们的理解还在不断发展，不过我希望 这一点能够让你更好地理解优化算法所面临的问题。

206 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

第三周

超 参 数 调 试 、 Batch

正则化和程序框架

（Hyperparameter tuning） 

3.1 调试处理（Tuning process）

大家好，欢迎回来，目前为止，你已经了解到，神经网络的改变会涉及到许多不同超参 数的设置。现在，对于超参数而言，你要如何找到一套好的设定呢？在此视频中，我想和你 分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧，希望这些能够让你更有 效的聚焦到合适的超参设定中。

关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率𝑎到 Momentum （动量梯度下降法）的参数𝛽。如果使用 Momentum 或 Adam 优化算法的参数，𝛽 1 ，𝛽 2 和𝜀，也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰 减。所以，你使用的不是单一的学习率𝑎。接着，当然你可能还需要选择 mini-batch 的大小。

结果证实一些超参数比其它的更为重要，我认为，最为广泛的学习应用是𝑎，学习速率 是需要调试的最重要的超参数。

除了𝑎，还有一些参数需要调试，例如 Momentum 参数𝛽，0.9 就是个很好的默认值。我 还会调试 mini-batch 的大小，以确保最优算法运行有效。我还会经常调试隐藏单元，我用橙 色圈住的这些，这三个是我觉得其次比较重要的，相对于𝑎而言。重要性排第三位的是其他 因素，层数有时会产生很大的影响，学习率衰减也是如此。当应用 Adam 算法时，事实上，我从不调试𝛽 1 ，𝛽 2 和𝜀，我总是选定其分别为 0.9，0.999 和 10−8 ，如果你想的话也可以调试

207 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

它们。但希望你粗略了解到哪些超参数较为重要，𝑎无疑是最重要的，接下来是我用橙色圈住 的那些，然后是我用紫色圈住的那些，但这不是严格且快速的标准，我认为，其它深度学习 的研究者可能会很不同意我的观点或有着不同的直觉。

现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参 1，超参 2，常见的做法是在网格中取样点，像 这样，然后系统的研究这些数值。这里我放置的是 5×5 的网格，实践证明，网格可以是 5×5，也可多可少，但对于这个例子，你可以尝试这所有的 25 个点，然后选择哪个参数效果最好。当参数的数量相对较少时，这个方法很实用。

在深度学习领域，我们常做的，我推荐你采用下面的做法，随机选择点，所以你可以选 择同等数量的点，对吗？25 个点，接着，用这些随机取的点试验超参数的效果。之所以这么 做是因为，对于你要解决的问题而言，你很难提前知道哪个超参数最重要，正如你之前看到 的，一些超参数的确要比其它的更重要。

举个例子，假设超参数 1 是𝑎（学习速率），取一个极端的例子，假设超参数 2 是 Adam 算法中，分母中的𝜀。在这种情况下，𝑎的取值很重要，而𝜀取值则无关紧要。如果你在网格 中取点，接着，你试验了𝑎的 5 个取值，那你会发现，无论𝜀取何值，结果基本上都是一样的。所以，你知道共有 25 种模型，但进行试验的𝑎值只有 5 个，我认为这是很重要的。

对比而言，如果你随机取值，你会试验 25 个独立的𝑎，似乎你更有可能发现效果做好的 那个。

208 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

我已经解释了两个参数的情况，实践中，你搜索的超参数可能不止两个。假如，你有三 个超参数，这时你搜索的不是一个方格，而是一个立方体，超参数 3 代表第三维，接着，在 三维立方体中取值，你会试验大量的更多的值，三个超参数中每个都是。

实践中，你搜索的可能不止三个超参数有时很难预知，哪个是最重要的超参数，对于你 的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论 结果是什么。

当你给超参数取值时，另一个惯例是采用由粗糙到精细的策略。

比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个 点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域（小蓝色方框内），

209 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你 怀疑这些超参数在这个区域的最优结果，那在整个的方格中进行粗略搜索后，你会知道接下 来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的 搜索也经常使用。

通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而 言的最优值，或在超参搜索过程中你最想优化的东西。

我希望，这能给你提供一种方法去系统地组织超参数搜索过程。另一个关键点是随机取 值和精确搜索，考虑使用由粗糙到精细的搜索过程。但超参数的搜索内容还不止这些，在下 一个视频中，我会继续讲解关于如何选择超参数取值的合理范围。

210 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.2 为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）

在上一个视频中，你已经看到了在超参数范围中，随机取值可以提升你的搜索效率。但 随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数，这很重要。在这个视频中，我会教你怎么做。

假设你要选取隐藏单元的数量𝑛 [𝑙] ，假设，你选取的取值范围是从 50 到 100 中某点，这 种情况下，看到这条从 50-100 的数轴，你可以随机在其取点，这是一个搜索特定超参数的 很直观的方式。或者，如果你要选取神经网络的层数，我们称之为字母𝐿，你也许会选择层 数为 2 到 4 中的某个值，接着顺着 2，3，4 随机均匀取样才比较合理，你还可以应用网格搜 索，你会觉得 2，3，4，这三个数值是合理的，这是在几个在你考虑范围内随机均匀取值的 例子，这些取值还蛮合理的，但对某些超参数而言不适用。

看看这个例子，假设你在搜索超参数𝑎（学习速率），假设你怀疑其值最小是 0.0001 或 最大是 1。如果你画一条从 0.0001 到 1 的数轴，沿其随机均匀取值，那 90% 的数值将会落在

211 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

0.1 到 1 之间，结果就是，在 0.1 到 1 之间，应用了 90% 的资源，而在 0.0001 到 0.1 之间，只有 10% 的搜索资源，这看上去不太对。反而，用对数标尺搜索超参数的方式会更合理，因此这里不使用线性轴，分别依次取

0.0001，0.001，0.01，0.1，1，在对数轴上均匀随机取点，这样，在 0.0001 到 0.001 之间，就会有更多的搜索资源可用，还有在 0.001 到 0.01 之间等等。

所以在 Python 中，你可以这样做，使 r=-4*np.random.rand ()，然后𝑎随机取值，𝑎 = 10 𝑟 ，所以，第一行可以得出𝑟 ∈ [4,0]，那么𝑎 ∈ [10 −4 , 10 0]，所以最左边的数字是 10−4 ，最右边是 100 。

更常见的情况是，如果你在 10 𝑎 和 10 𝑏 之间取值，在此例中，这是 10𝑎 （0.0001），你可 以通过 0.0001 算出𝑎的值，即 - 4，在右边的值是 10 𝑏 ，你可以算出𝑏的值 1，即 0。你要做的就 是在 [𝑎, 𝑏] 区间随机均匀地给𝑟取值，这个例子中𝑟 ∈ [−4,0]，然后你可以设置𝑎的值，基于随 机取样的超参数𝑎 = 10 𝑟 。

所以总结一下，在对数坐标下取值，取最小值的对数就得到𝑎的值，取最大值的对数就 得到𝑏值，所以现在你在对数轴上的 10 𝑎 到 10 𝑏 区间取值，在𝑎，𝑏间随意均匀的选取𝑟值，将 超参数设置为 10 𝑟 ，这就是在对数轴上取值的过程。

212 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

最后，另一个棘手的例子是给𝛽 取值，用于计算指数的加权平均值。假设你认为𝛽是 0.9 到 0.999 之间的某个值，也许这就是你想搜索的范围。记住这一点，当计算指数的加权平均 值时，取 0.9 就像在 10 个值中计算平均值，有点类似于计算 10 天的温度平均值，而取 0.999 就是在 1000 个值中取平均。

所以和上张幻灯片上的内容类似，如果你想在 0.9 到 0.999 区间搜索，那就不能用线性 轴取值，对吧？不要随机均匀在此区间取值，所以考虑这个问题最好的方法就是，我们要探 究的是 1 − 𝛽，此值在 0.1 到 0.001 区间内，所以我们会给 1 − 𝛽取值，大概是从 0.1 到 0.001，应用之前幻灯片中介绍的方法，这是 10−1 ，这是 10−3 ，值得注意的是，在之前的幻灯片里，我们把最小值写在左边，最大值写在右边，但在这里，我们颠倒了大小。这里，左边的是最 大值，右边的是最小值。所以你要做的就是在 [−3, −1] 里随机均匀的给 r 取值。你设定了 1 𝛽 = 10 𝑟 ，所以𝛽 = 1 − 10 𝑟 ，然后这就变成了在特定的选择范围内超参数随机取值。希望用 这种方式得到想要的结果，你在 0.9 到 0.99 区间探究的资源，和在 0.99 到 0.999 区间探究 的一样多。

所以，如果你想研究更多正式的数学证明，关于为什么我们要这样做，为什么用线性轴 取值不是个好办法，这是因为当𝛽 接近 1 时，所得结果的灵敏度会变化，即使𝛽有微小的变 化。所以𝛽 在 0.9 到 0.9005 之间取值，无关紧要，你的结果几乎不会变化。

213 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

但𝛽值如果在 0.999 到 0.9995 之间，这会对你的算法产生巨大影响，对吧？在这两种情 况下，是根据大概 10 个值取平均。但这里，它是指数的加权平均值，基于 1000 个值，现在 1 是 2000 个值，因为这个公式 1−𝛽 ，当𝛽接近 1 时，𝛽就会对细微的变化变得很敏感。所以整

个取值过程中，你需要更加密集地取值，在𝛽 接近 1 的区间内，或者说，当 1 − 𝛽 接近于 0 时，这样，你就可以更加有效的分布取样点，更有效率的探究可能的结果。

希望能帮助你选择合适的标尺，来给超参数取值。如果你没有在超参数选择中作出正确 的标尺决定，别担心，即使你在均匀的标尺上取值，如果数值总量较多的话，你也会得到还 不错的结果，尤其是应用从粗到细的搜索方法，在之后的迭代中，你还是会聚焦到有用的超 参数取值范围上。

希望这会对你的超参数搜索有帮助，下一个视频中，我们将会分享一些关于如何组建搜 索过程的思考，希望它能使你的工作更高效。

214 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.3 超参数调试实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）

到现在为止，你已经听了许多关于如何搜索最优超参数的内容，在结束我们关于超参数 搜索的讨论之前，我想最后和你分享一些建议和技巧，关于如何组织你的超参数搜索过程。

如今的深度学习已经应用到许多不同的领域，某个应用领域的超参数设定，有可能通用 于另一领域，不同的应用领域出现相互交融。比如，我曾经看到过计算机视觉领域中涌现的 巧妙方法，比如说 Confonets 或 ResNets，这我们会在后续课程中讲到。它还成功应用于语 音识别，我还看到过最初起源于语音识别的想法成功应用于 NLP 等等。

深度学习领域中，发展很好的一点是，不同应用领域的人们会阅读越来越多其它研究领 域的文章，跨领域去寻找灵感。

就超参数的设定而言，我见到过有些直觉想法变得很缺乏新意，所以，即使你只研究一 个问题，比如说逻辑学，你也许已经找到一组很好的参数设置，并继续发展算法，或许在几 个月的过程中，观察到你的数据会逐渐改变，或也许只是在你的数据中心更新了服务器，正 因为有了这些变化，你原来的超参数的设定不再好用，所以我建议，或许只是重新测试或评 估你的超参数，至少每隔几个月一次，以确保你对数值依然很满意。

最后，关于如何搜索超参数的问题，我见过大概两种重要的思想流派或人们通常采用的 两种重要但不同的方式。

215 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

一种是你照看一个模型，通常是有庞大的数据组，但没有许多计算资源或足够的 CPU 和 GPU 的前提下，基本而言，你只可以一次负担起试验一个模型或一小批模型，在这种情况下，即使当它在试验时，你也可以逐渐改良。比如，第 0 天，你将随机参数初始化，然后开始试 验，然后你逐渐观察自己的学习曲线，也许是损失函数 J，或者数据设置误差或其它的东西，在第 1 天内逐渐减少，那这一天末的时候，你可能会说，看，它学习得真不错。我试着增加 一点学习速率，看看它会怎样，也许结果证明它做得更好，那是你第二天的表现。两天后，你会说，它依旧做得不错，也许我现在可以填充下 Momentum 或减少变量。然后进入第三 天，每天，你都会观察它，不断调整你的参数。也许有一天，你会发现你的学习率太大了，所以你可能又回归之前的模型，像这样，但你可以说是在每天花时间照看此模型，即使是它 在许多天或许多星期的试验过程中。所以这是一个人们照料一个模型的方法，观察它的表现，耐心地调试学习率，但那通常是因为你没有足够的计算能力，不能在同一时间试验大量模型 时才采取的办法。

另一种方法则是同时试验多种模型，你设置了一些超参数，尽管让它自己运行，或者是 一天甚至多天，然后你会获得像这样的学习曲线，这可以是损失函数 J 或实验误差或损失或

216 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

数据误差的损失，但都是你曲线轨迹的度量。同时你可以开始一个有着不同超参数设定的不 同模型，所以，你的第二个模型会生成一个不同的学习曲线，也许是像这样的一条（紫色曲 线），我会说这条看起来更好些。与此同时，你可以试验第三种模型，其可能产生一条像这 样的学习曲线（红色曲线），还有另一条（绿色曲线），也许这条有所偏离，像这样，等等。或者你可以同时平行试验许多不同的模型，橙色的线就是不同的模型。用这种方式你可以试 验许多不同的参数设定，然后只是最后快速选择工作效果最好的那个。在这个例子中，也许 这条看起来是最好的（下方绿色曲线）。

打个比方，我把左边的方法称为熊猫方式。当熊猫有了孩子，他们的孩子非常少，一次 通常只有一个，然后他们花费很多精力抚养熊猫宝宝以确保其能成活，所以，这的确是一种 照料，一种模型类似于一只熊猫宝宝。对比而言，右边的方式更像鱼类的行为，我称之为鱼 子酱方式。在交配季节，有些鱼类会产下一亿颗卵，但鱼类繁殖的方式是，它们会产生很多 卵，但不对其中任何一个多加照料，只是希望其中一个，或其中一群，能够表现出色。我猜，这就是哺乳动物繁衍和鱼类，很多爬虫类动物繁衍的区别。我将称之为熊猫方式与鱼子酱方 式，因为这很有趣，更容易记住。

所以这两种方式的选择，是由你拥有的计算资源决定的，如果你拥有足够的计算机去平 行试验许多模型，那绝对采用鱼子酱方式，尝试许多不同的超参数，看效果怎么样。但在一 些应用领域，比如在线广告设置和计算机视觉应用领域，那里的数据太多了，你需要试验大 量的模型，所以同时试验大量的模型是很困难的，它的确是依赖于应用的过程。但我看到那 些应用熊猫方式多一些的组织，那里，你会像对婴儿一样照看一个模型，调试参数，试着让 它工作运转。尽管，当然，甚至是在熊猫方式中，试验一个模型，观察它工作与否，也许第

217 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

二或第三个星期后，也许我应该建立一个不同的模型（绿色曲线），像熊猫那样照料它，我 猜，这样一生中可以培育几个孩子，即使它们一次只有一个孩子或孩子的数量很少。

所以希望你能学会如何进行超参数的搜索过程，现在，还有另一种技巧，能使你的神经 网络变得更加坚实，它并不是对所有的神经网络都适用，但当适用时，它可以使超参数搜索 变得容易许多并加速试验过程，我们在下个视频中再讲解这个技巧。

218 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.4 归一化网络的激活函数（Normalizing activations in a network）

在深度学习兴起后，最重要的一个思想是它的一种算法，叫做 Batch 归一化，由 Sergey loffe 和 Christian Szegedy 两位研究者创造。Batch 归一化会使你的参数搜索问题变得很容易，使神经网络对超参数的选择更加稳定，超参数的范围会更加庞大，工作效果也很好，也会是 你的训练更加容易，甚至是深层网络。让我们来看看 Batch 归一化是怎么起作用的吧。

当训练一个模型，比如 logistic 回归时，你也许会记得，归一化输入特征可以加快学习 过程。你计算了平均值，从训练集中减去平均值，计算了方差，接着根据方差归一化你的数 据集，在之前的视频中我们看到，这是如何把学习问题的轮廓，从很长的东西，变成更圆的 东西，更易于算法优化。所以这是有效的，对 logistic 回归和神经网络的归一化输入特征值 而言。

那么更深的模型呢？你不仅输入了特征值𝑥，而且这层有激活值𝑎 [1] ，这层有激活值𝑎[2] 等等。如果你想训练这些参数，比如𝑤 [3] ，𝑏 [3] ，那归一化𝑎 [2] 的平均值和方差岂不是很好？ 以便使𝑤 [3] ，𝑏 [3] 的训练更有效率。在 logistic 回归的例子中，我们看到了如何归一化𝑥 1 ，𝑥 2 ，𝑥 3 ，会帮助你更有效的训练𝑤和𝑏。

所以问题来了，对任何一个隐藏层而言，我们能否归一化𝑎值，在此例中，比如说𝑎 [2] 的 值，但可以是任何隐藏层的，以更快的速度训练𝑤 [3] ，𝑏 [3] ，因为𝑎 [2] 是下一层的输入值，所

219 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

以就会影响𝑤 [3] ，𝑏 [3] 的训练。简单来说，这就是 Batch 归一化的作用。尽管严格来说，我们 真正归一化的不是𝑎 [2] ，而是𝑧 [2] ，深度学习文献中有一些争论，关于在激活函数之前是否应 该将值𝑧 [2] 归一化，或是否应该在应用激活函数𝑎 [2] 后再规范值。实践中，经常做的是归一化 𝑧 [2] ，所以这就是我介绍的版本，我推荐其为默认选择，那下面就是 Batch 归一化的使用方 法。

在神经网络中，已知一些中间值，假设你有一些隐藏单元值，从𝑧(1) 到𝑧 (𝑚) ，这些来源 于隐藏层，所以这样写会更准确，即𝑧 [𝑙](𝑖) 为隐藏层，𝑖从 1 到𝑚，但这样书写，我要省略𝑙及 方括号，以便简化这一行的符号。所以已知这些值，如下，你要计算平均值，强调一下，所 有这些都是针对𝑙层，但我省略𝑙及方括号，然后用正如你常用的那个公式计算方差，接着，你会取每个𝑧 (𝑖) 值，使其规范化，方法如下，减去均值再除以标准偏差，为了使数值稳定，通常将𝜀作为分母，以防𝜎 = 0 的情况。

所以现在我们已把这些𝑧值标准化，化为含平均值 0 和标准单位方差，所以𝑧的每一个分 量都含有平均值 0 和方差 1，但我们不想让隐藏单元总是含有平均值 0 和方差 1，也许隐藏 单元有了不同的分布会有意义，所以我们所要做的就是计算，我们称之为𝑧̃ (𝑖) ，𝑧̃ = 𝛾𝑧 norm (𝑖) + 𝛽，这里𝛾和𝛽是你模型的学习参数，所以我们使用梯度下降或一些其它类似梯度下降的算法，比如 Momentum 或者 Nesterov，Adam，你会更新𝛾和𝛽，正如更新神经网络的权重一样。

请注意𝛾和𝛽的作用是，你可以随意设置𝑧̃ (𝑖) 的平均值，事实上，如果𝛾 = √𝜎 2 + 𝜀，如果

𝛾等于这个分母项（𝑧 norm (𝑖) = 𝑧 (𝑖) −𝜇 √𝜎 2 +𝜀 中的分母），𝛽等于𝜇，这里的这个值是𝑧 norm (𝑖) = 2 𝑧 (𝑖) −𝜇 中的 √𝜎 +𝜀

220 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

𝜇，那么𝛾𝑧 norm (𝑖) + 𝛽的作用在于，它会精确转化这个方程，如果这些成立（𝛾 = √𝜎 2 + 𝜀, 𝛽 = 𝜇），那么𝑧̃ (𝑖) = 𝑧 (𝑖) 。

通过对𝛾和𝛽合理设定，规范化过程，即这四个等式，从根本来说，只是计算恒等函数，通过赋予𝛾和𝛽其它值，可以使你构造含其它平均值和方差的隐藏单元值。

所以，在网络匹配这个单元的方式，之前可能是用𝑧(1) ，𝑧 (2) 等等，现在则会用𝑧̃ (𝑖) 取代 𝑧 (𝑖) ，方便神经网络中的后续计算。如果你想放回 [𝑙]，以清楚的表明它位于哪层，你可以把 它放这。

所以我希望你学到的是，归一化输入特征𝑋是怎样有助于神经网络中的学习，Batch 归 一化的作用是它适用的归一化过程，不只是输入层，甚至同样适用于神经网络中的深度隐藏 层。你应用 Batch 归一化了一些隐藏单元值中的平均值和方差，不过训练输入和这些隐藏单 元值的一个区别是，你也许不想隐藏单元值必须是平均值 0 和方差 1。

比如，如果你有 sigmoid 激活函数，你不想让你的值总是全部集中在这里，你想使它们 有更大的方差，或不是 0 的平均值，以便更好的利用非线性的 sigmoid 函数，而不是使所有 的值都集中于这个线性版本中，这就是为什么有了𝛾和𝛽两个参数后，你可以确保所有的𝑧(𝑖) 值可以是你想赋予的任意值，或者它的作用是保证隐藏的单元已使均值和方差标准化。那里，均值和方差由两参数控制，即𝛾和𝛽，学习算法可以设置为任何值，所以它真正的作用是，使

221 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

隐藏单元值的均值和方差标准化，即𝑧 (𝑖) 有固定的均值和方差，均值和方差可以是 0 和 1，也可以是其它值，它是由𝛾和𝛽两参数控制的。我希望你能学会怎样使用 Batch 归一化，至少就神经网络的单一层而言，在下一个视频 中，我会教你如何将 Batch 归一化与神经网络甚至是深度神经网络相匹配。对于神经网络许 多不同层而言，又该如何使它适用，之后，我会告诉你，Batch 归一化有助于训练神经网络 的原因。所以如果觉得 Batch 归一化起作用的原因还显得有点神秘，那跟着我走，在接下来 的两个视频中，我们会弄清楚。

222 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.5 将 Batch Norm 拟合进神经网络（Fitting Batch Norm into a neural network）

你已经看到那些等式，它可以在单一隐藏层进行 Batch 归一化，接下来，让我们看看它 是怎样在深度网络训练中拟合的吧。

假设你有一个这样的神经网络，我之前说过，你可以认为每个单元负责计算两件事。第 一，它先计算𝑧，然后应用其到激活函数中再计算𝑎，所以我可以认为，每个圆圈代表着两步 的计算过程。同样的，对于下一层而言，那就是𝑧 1 [2] 和𝑎 1 [2] 等。所以如果你没有应用 Batch 归 一化，你会把输入𝑋拟合到第一隐藏层，然后首先计算𝑧[1] ，这是由𝑤 [1] 和𝑏 [1] 两个参数控制 的。接着，通常而言，你会把𝑧 [1] 拟合到激活函数以计算𝑎 [1] 。但 Batch 归一化的做法是将𝑧[1] 值进行 Batch 归一化，简称 BN，此过程将由𝛽 [1] 和𝛾 [1] 两参数控制，这一操作会给你一个新 的规范化的𝑧 [1] 值（𝑧̃ [1] ），然后将其输入激活函数中得到𝑎 [1] ，即𝑎 [1] = 𝑔 [1] (𝑧̃)。

现在，你已在第一层进行了计算，此时 Batch 归一化发生在𝑧的计算和𝑎之间，接下来，你需要应用𝑎 [1] 值来计算𝑧 [2] ，此过程是由𝑤 [2] 和𝑏 [2] 控制的。与你在第一层所做的类似，你 会将𝑧 [2] 进行 Batch 归一化，现在我们简称 BN，这是由下一层的 Batch 归一化参数所管制的，即𝛽 [2] 和𝛾 [2] ，现在你得到𝑧̃[2] ，再通过激活函数计算出𝑎 [2] 等等。

223 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

所以需要强调的是 Batch 归一化是发生在计算𝑧和𝑎之间的。直觉就是，与其应用没有归 一化的𝑧值，不如用归一过的𝑧̃，这是第一层（𝑧̃[1] ）。第二层同理，与其应用没有规范过的 𝑧 [2] 值，不如用经过方差和均值归一后的𝑧̃[2] 。所以，你网络的参数就会是𝑤 [1] ，𝑏 [1] ，𝑤 [2] 和 𝑏 [2] 等等，我们将要去掉这些参数。但现在，想象参数𝑤 [1] ，𝑏 [1] 到𝑤 [𝑙] ，𝑏 [𝑙] ，我们将另一些 参数加入到此新网络中𝛽 [1] ，𝛽 [2] ，𝛾 [1] ，𝛾 [2] 等等。对于应用 Batch 归一化的每一层而言。需 要澄清的是，请注意，这里的这些𝛽（𝛽 [1] ，𝛽 [2] 等等）和超参数𝛽没有任何关系，下一张幻 灯片中会解释原因，后者是用于 Momentum 或计算各个指数的加权平均值。Adam 论文的 作者，在论文里用𝛽代表超参数。Batch 归一化论文的作者，则使用𝛽代表此参数（𝛽 [1] ，𝛽[2] 等等），但这是两个完全不同的𝛽。我在两种情况下都决定使用𝛽，以便你阅读那些原创的论 文，但 Batch 归一化学习参数𝛽 [1] ，𝛽 [2] 等等和用于 Momentum、Adam、RMSprop 算法中的 𝛽不同。

所以现在，这是你算法的新参数，接下来你可以使用想用的任何一种优化算法，比如使 用梯度下降法来执行它。

举个例子，对于给定层，你会计算𝑑𝛽 [𝑙] ，接着更新参数𝛽为𝛽 [𝑙] = 𝛽 [𝑙] − 𝛼𝑑𝛽 [𝑙] 。你也可 以使用 Adam 或 RMSprop 或 Momentum，以更新参数𝛽和𝛾，并不是只应用梯度下降法。

即使在之前的视频中，我已经解释过 Batch 归一化是怎么操作的，计算均值和方差，减 去均值，再除以方差，如果它们使用的是深度学习编程框架，通常你不必自己把 Batch 归一 化步骤应用于 Batch 归一化层。因此，探究框架，可写成一行代码，比如说，在 TensorFlow 框架中，你可以用这个函数（tf.nn.batch_normalization）来实现 Batch 归一化，我们 稍后讲解，但实践中，你不必自己操作所有这些具体的细节，但知道它是如何作用的，你可 以更好的理解代码的作用。但在深度学习框架中，Batch 归一化的过程，经常是类似一行代 码的东西。

所以，到目前为止，我们已经讲了 Batch 归一化，就像你在整个训练站点上训练一样，或就像你正在使用 Batch 梯度下降法。

224 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

实践中，Batch 归一化通常和训练集的 mini-batch 一起使用。你应用 Batch 归一化的方 式就是，你用第一个 mini-batch (𝑋 {1} )，然后计算𝑧 [1] ，这和上张幻灯片上我们所做的一样，应用参数𝑤 [1] 和𝑏 [1] ，使用这个 mini-batch (𝑋 {1} )。接着，继续第二个 mini-batch (𝑋 {2} )，接着 Batch 归一化会减去均值，除以标准差，由𝛽 [1] 和𝛾 [1] 重新缩放，这样就得到了𝑧̃[1] ，而所有的 这些都是在第一个 mini-batch 的基础上，你再应用激活函数得到𝑎 [1] 。然后用𝑤 [2] 和𝑏 [2] 计算 𝑧 [2] ，等等，所以你做的这一切都是为了在第一个 mini-batch (𝑋 {1} ) 上进行一步梯度下降法。

类似的工作，你会在第二个 mini-batch（𝑋 {2} ）上计算𝑧[1] ，然后用 Batch 归一化来计算 𝑧̃ ，所以 Batch 归一化的此步中，你用第二个 mini-batch（𝑋 {2} ）中的数据使𝑧̃ [1] 归一化，这 里的 Batch 归一化步骤也是如此，让我们来看看在第二个 mini-batch（𝑋 {2} ）中的例子，在 mini-batch 上计算𝑧[1] 的均值和方差，重新缩放的𝛽和𝛾得到𝑧[1] ，等等。

然后在第三个 mini-batch（𝑋 {3} ）上同样这样做，继续训练。现在，我想澄清此参数的一个细节。先前我说过每层的参数是𝑤 [𝑙] 和𝑏 [𝑙] ，还有𝛽 [𝑙] 和𝛾 [𝑙] ，请注意计算𝑧的方式如下，𝑧 [𝑙] = 𝑤 [𝑙] 𝑎 [𝑙−1] + 𝑏 [𝑙] ，但 Batch 归一化做的是，它要看这个 minibatch，先将𝑧 [𝑙] 归一化，结果为均值 0 和标准方差，再由𝛽和𝛾重缩放，但这意味着，无论𝑏[𝑙] 的值是多少，都是要被减去的，因为在 Batch 归一化的过程中，你要计算𝑧 [𝑙] 的均值，再减去 平均值，在此例中的 mini-batch 中增加任何常数，数值都不会改变，因为加上的任何常数都 将会被均值减去所抵消。

所以，如果你在使用 Batch 归一化，其实你可以消除这个参数（𝑏 [𝑙] ），或者你也可以，暂时把它设置为 0，那么，参数变成𝑧 [𝑙] = 𝑤 [𝑙] 𝑎 [𝑙−1] ，然后你计算归一化的𝑧 [𝑙] ，𝑧̃ = 𝛾 [𝑙] 𝑧 [𝑙] + 𝛽 [𝑙] ，你最后会用参数𝛽 [𝑙] ，以便决定𝑧̃ [𝑙] 的取值，这就是原因。

225 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

所以总结一下，因为 Batch 归一化超过了此层𝑧 [𝑙] 的均值，𝑏 [𝑙] 这个参数没有意义，所以，你必须去掉它，由𝛽 [𝑙] 代替，这是个控制参数，会影响转移或偏置条件。

最后，请记住𝑧 [𝑙] 的维数，因为在这个例子中，维数会是 (𝑛 [𝑙] , 1)，𝑏 [𝑙] 的尺寸为 (𝑛 [𝑙] , 1)，如果是 l 层隐藏单元的数量，那𝛽 [𝑙] 和𝛾 [𝑙] 的维度也是 (𝑛 [𝑙] , 1)，因为这是你隐藏层的数量，你 有𝑛 [𝑙] 隐藏单元，所以𝛽 [𝑙] 和𝛾 [𝑙] 用来将每个隐藏层的均值和方差缩放为网络想要的值。

让我们总结一下关于如何用 Batch 归一化来应用梯度下降法，假设你在使用 mini-batch 梯度下降法，你运行𝑡 = 1 到 batch 数量的 for 循环，你会在 mini-batch 𝑋 {𝑡} 上应用正向 prop，每个隐藏层都应用正向 prop，用 Batch 归一化代替𝑧 [𝑙] 为𝑧̃ [𝑙] 。接下来，它确保在这个 minibatch 中，𝑧值有归一化的均值和方差，归一化均值和方差后是𝑧̃ [𝑙] ，然后，你用反向 prop 计 算𝑑𝑤 [𝑙] 和𝑑𝑏 [𝑙] ，及所有 l 层所有的参数，𝑑𝛽 [𝑙] 和𝑑𝛾 [𝑙] 。尽管严格来说，因为你要去掉𝑏，这 部分其实已经去掉了。最后，你更新这些参数：𝑤 [𝑙] = 𝑤 [𝑙] − αd𝑤 [𝑙] ，和以前一样，𝛽 [𝑙] = 𝛽 [𝑙] 𝛼𝑑𝛽 [𝑙] ，对于𝛾也是如此𝛾 [𝑙] = 𝛾 [𝑙] − 𝛼𝑑𝛾 [𝑙] 。

如果你已将梯度计算如下，你就可以使用梯度下降法了，这就是我写到这里的，但也适 用于有 Momentum、RMSprop、Adam 的梯度下降法。与其使用梯度下降法更新 mini-batch，你可以使用这些其它算法来更新，我们在之前几个星期中的视频中讨论过的，也可以应用其 它的一些优化算法来更新由 Batch 归一化添加到算法中的𝛽 和𝛾 参数。

226 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

我希望，你能学会如何从头开始应用 Batch 归一化，如果你想的话。如果你使用深度学 习编程框架之一，我们之后会谈。，希望，你可以直接调用别人的编程框架，这会使 Batch 归一化的使用变得很容易。

现在，以防 Batch 归一化仍然看起来有些神秘，尤其是你还不清楚为什么其能如此显著 的加速训练，我们进入下一个视频，详细讨论 Batch 归一化为何效果如此显著，它到底在做 什么。

227 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.6 Batch Norm 为什么奏效？（Why does Batch Norm work?）

为什么 Batch 归一化会起作用呢？ 一个原因是，你已经看到如何归一化输入特征值𝑥，使其均值为 0，方差 1，它又是怎样 加速学习的，有一些从 0 到 1 而不是从 1 到 1000 的特征值，通过归一化所有的输入特征值 𝑥，以获得类似范围的值，可以加速学习。所以 Batch 归一化起的作用的原因，直观的一点 就是，它在做类似的工作，但不仅仅对于这里的输入值，还有隐藏单元的值，这只是 Batch 归一化作用的冰山一角，还有些深层的原理，它会有助于你对 Batch 归一化的作用有更深的 理解，让我们一起来看看吧。

Batch 归一化有效的第二个原因是，它可以使权重比你的网络更滞后或更深层，比如，第 10 层的权重更能经受得住变化，相比于神经网络中前层的权重，比如第 1 层，为了解释 我的意思，让我们来看看这个最生动形象的例子。

这是一个网络的训练，也许是个浅层网络，比如 logistic 回归或是一个神经网络，也许 是个浅层网络，像这个回归函数。或一个深层网络，建立在我们著名的猫脸识别检测上，但 假设你已经在所有黑猫的图像上训练了数据集，如果现在你要把此网络应用于有色猫，这种 情况下，正面的例子不只是左边的黑猫，还有右边其它颜色的猫，那么你的 cosfa 可能适用 的不会很好。

如果图像中，你的训练集是这个样子的，你的正面例子在这儿，反面例子在那儿（左图），但你试图把它们都统一于一个数据集，也许正面例子在这，反面例子在那儿（右图）。你也

228 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

许无法期待，在左边训练得很好的模块，同样在右边也运行得很好，即使存在运行都很好的 同一个函数，但你不会希望你的学习算法去发现绿色的决策边界，如果只看左边数据的话。

所以使你数据改变分布的这个想法，有个有点怪的名字「Covariate shift」，想法是这样的，如果你已经学习了𝑥到𝑦 的映射，如果𝑥的分布改变了，那么你可能需要重新训练你的学习 算法。这种做法同样适用于，如果真实函数由𝑥到𝑦 映射保持不变，正如此例中，因为真实 函数是此图片是否是一只猫，训练你的函数的需要变得更加迫切，如果真实函数也改变，情 况就更糟了。

「Covariate shift」的问题怎么应用于神经网络呢？试想一个像这样的深度网络，让我们从 这层（第三层）来看看学习过程。此网络已经学习了参数𝑤 [3] 和𝑏 [3] ，从第三隐藏层的角度来 看，它从前层中取得一些值，接着它需要做些什么，使希望输出值𝑦接近真实值𝑦。

让我先遮住左边的部分，从第三隐藏层的角度来看，它得到一些值，称为𝑎 1 [2] ，𝑎 2 [2] ，𝑎 3 [2] ，𝑎 4 [2] ，但这些值也可以是特征值𝑥 1 ，𝑥 2 ，𝑥 3 ，𝑥 4 ，第三层隐藏层的工作是找到一种方式，使 这些值映射到𝑦，你可以想象做一些截断，所以这些参数𝑤 [3] 和𝑏 [3] 或𝑤 [4] 和𝑏 [4] 或𝑤 [5] 和𝑏 [5] ，也许是学习这些参数，所以网络做的不错，从左边我用黑色笔写的映射到输出值𝑦。

229 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

现在我们把网络的左边揭开，这个网络还有参数𝑤 [2] ，𝑏 [2] 和𝑤 [1] ，𝑏 [1] ，如果这些参数 改变，这些𝑎 [2] 的值也会改变。所以从第三层隐藏层的角度来看，这些隐藏单元的值在不断 地改变，所以它就有了「Covariate shift」的问题，上张幻灯片中我们讲过的。

Batch 归一化做的，是它减少了这些隐藏值分布变化的数量。如果是绘制这些隐藏的单 元值的分布，也许这是重整值𝑧，这其实是𝑧 1 [2] ，𝑧2 [2] ，我要绘制两个值而不是四个值，以便 我们设想为 2D，Batch 归一化讲的是𝑧 1 [2] ，𝑧2 [2] 的值可以改变，它们的确会改变，当神经网络 在之前层中更新参数，Batch 归一化可以确保无论其怎样变化𝑧1 [2] ，𝑧 2 [2] 的均值和方差保持不 变，所以即使𝑧 1 [2] ，𝑧 2 [2] 的值改变，至少他们的均值和方差也会是均值 0，方差 1，或不一定 必须是均值 0，方差 1，而是由𝛽 [2] 和𝛾 [2] 决定的值。如果神经网络选择的话，可强制其为均 值 0，方差 1，或其他任何均值和方差。但它做的是，它限制了在前层的参数更新，会影响 数值分布的程度，第三层看到的这种情况，因此得到学习。

Batch 归一化减少了输入值改变的问题，它的确使这些值变得更稳定，神经网络的之后 层就会有更坚实的基础。即使使输入分布改变了一些，它会改变得更少。它做的是当前层保 持学习，当改变时，迫使后层适应的程度减小了，你可以这样想，它减弱了前层参数的作用 与后层参数的作用之间的联系，它使得网络每层都可以自己学习，稍稍独立于其它层，这有 助于加速整个网络的学习。

230 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

所以，希望这能带给你更好的直觉，重点是 Batch 归一化的意思是，尤其从神经网络后 层之一的角度而言，前层不会左右移动的那么多，因为它们被同样的均值和方差所限制，所 以，这会使得后层的学习工作变得更容易些。

Batch 归一化还有一个作用，它有轻微的正则化效果，Batch 归一化中非直观的一件事 是，每个 mini-batch，我会说 mini-batch𝑋 {𝑡} 的值为𝑧 [𝑡] ，𝑧 [𝑙] ，在 mini-batch 计算中，由均值 和方差缩放的，因为在 mini-batch 上计算的均值和方差，而不是在整个数据集上，均值和方 差有一些小的噪声，因为它只在你的 mini-batch 上计算，比如 64 或 128 或 256 或更大的训 练例子。因为均值和方差有一点小噪音，因为它只是由一小部分数据估计得出的。缩放过程 从𝑧 [𝑙] 到𝑧̃ [𝑙] ，过程也有一些噪音，因为它是用有些噪音的均值和方差计算得出的。

所以和 dropout 相似，它往每个隐藏层的激活值上增加了噪音，dropout 有增加噪音的 方式，它使一个隐藏的单元，以一定的概率乘以 0，以一定的概率乘以 1，所以你的 dropout 含几重噪音，因为它乘以 0 或 1。

对比而言，Batch 归一化含几重噪音，因为标准偏差的缩放和减去均值带来的额外噪音。

231 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

这里的均值和标准差的估计值也是有噪音的，所以类似于 dropout，Batch 归一化有轻微的 正则化效果，因为给隐藏单元添加了噪音，这迫使后部单元不过分依赖任何一个隐藏单元，类似于 dropout，它给隐藏层增加了噪音，因此有轻微的正则化效果。因为添加的噪音很微 小，所以并不是巨大的正则化效果，你可以将 Batch 归一化和 dropout 一起使用，如果你想 得到 dropout 更强大的正则化效果。

也许另一个轻微非直观的效果是，如果你应用了较大的 mini-batch，对，比如说，你用 了 512 而不是 64，通过应用较大的 min-batch，你减少了噪音，因此减少了正则化效果，这 是 dropout 的一个奇怪的性质，就是应用较大的 mini-batch 可以减少正则化效果。

说到这儿，我会把 Batch 归一化当成一种正则化，这确实不是其目的，但有时它会对你 的算法有额外的期望效应或非期望效应。但是不要把 Batch 归一化当作正则化，把它当作将 你归一化隐藏单元激活值并加速学习的方式，我认为正则化几乎是一个意想不到的副作用。

所以希望这能让你更理解 Batch 归一化的工作，在我们结束 Batch 归一化的讨论之前，我想确保你还知道一个细节。Batch 归一化一次只能处理一个 mini-batch 数据，它在 minibatch 上计算均值和方差。所以测试时，你试图做出预测，试着评估神经网络，你也许没有 mini-batch 的例子，你也许一次只能进行一个简单的例子，所以测试时，你需要做一些不同 的东西以确保你的预测有意义。

在下一个也就是最后一个 Batch 归一化视频中，让我们详细谈谈你需要注意的一些细 节，来让你的神经网络应用 Batch 归一化来做出预测。

232 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.7 测试时的 Batch Norm（Batch Norm at test time）

Batch 归一化将你的数据以 mini-batch 的形式逐一处理，但在测试时，你可能需要对每 个样本逐一处理，我们来看一下怎样调整你的网络来做到这一点。

回想一下，在训练时，这些就是用来执行 Batch 归一化的等式。在一个 mini-batch 中，你将 mini-batch 的𝑧 (𝑖) 值求和，计算均值，所以这里你只把一个 mini-batch 中的样本都加起 来，我用 m 来表示这个 mini-batch 中的样本数量，而不是整个训练集。然后计算方差，再 算𝑧 norm (𝑖) ，即用均值和标准差来调整，加上𝜀是为了数值稳定性。𝑧̃是用𝛾和𝛽再次调整𝑧 得 到的。

请注意用于调节计算的𝜇和𝜎 2 是在整个 mini-batch 上进行计算，但是在测试时，你可能 不能将一个 mini-batch 中的 6428 或 2056 个样本同时处理，因此你需要用其它方式来得到𝜇 和𝜎 2 ，而且如果你只有一个样本，一个样本的均值和方差没有意义。那么实际上，为了将你 的神经网络运用于测试，就需要单独估算𝜇和𝜎 2 ，在典型的 Batch 归一化运用中，你需要用 一个指数加权平均来估算，这个平均数涵盖了所有 mini-batch，接下来我会具体解释。

我们选择𝑙层，假设我们有 mini-batch，𝑋 [1] ，𝑋 [2] ，𝑋 [3] …… 以及对应的𝑦值等等，那么在

233 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

为𝑙层训练𝑋 {1} 时，你就得到了𝜇 [𝑙] ，我还是把它写做第一个 mini-batch 和这一层的𝜇吧，（𝜇 [𝑙] → 𝜇 {1}[𝑙] ）。当你训练第二个 mini-batch，在这一层和这个 mini-batch 中，你就会得到第二个𝜇 （𝜇 {2}[𝑙] ）值。然后在这一隐藏层的第三个 mini-batch，你得到了第三个𝜇（𝜇 {3}[𝑙] ）值。正如 我们之前用的指数加权平均来计算𝜃1 ，𝜃2 ，𝜃3 的均值，当时是试着计算当前气温的指数加权 平均，你会这样来追踪你看到的这个均值向量的最新平均值，于是这个指数加权平均就成了 你对这一隐藏层的𝑧均值的估值。同样的，你可以用指数加权平均来追踪你在这一层的第一 个 mini-batch 中所见的𝜎 2 的值，以及第二个 mini-batch 中所见的𝜎 2 的值等等。因此在用不 同的 mini-batch 训练神经网络的同时，能够得到你所查看的每一层的𝜇和𝜎 2 的平均数的实时 数值。

最后在测试时，对应这个等式（𝑧 norm (𝑖) = 𝑧 (𝑖) −𝜇 √𝜎 2 +𝜀 ），你只需要用你的𝑧值来计算𝑧 norm (𝑖) ，用 𝜇和𝜎 2 的指数加权平均，用你手头的最新数值来做调整，然后你可以用左边我们刚算出来的

𝑧 norm 和你在神经网络训练过程中得到的𝛽和𝛾参数来计算你那个测试样本的𝑧̃值。

总结一下就是，在训练时，𝜇和𝜎 2 是在整个 mini-batch 上计算出来的包含了像是 64 或 28 或其它一定数量的样本，但在测试时，你可能需要逐一处理样本，方法是根据你的训练 集估算𝜇和𝜎 2 ，估算的方式有很多种，理论上你可以在最终的网络中运行整个训练集来得到 𝜇和𝜎 2 ，但在实际操作中，我们通常运用指数加权平均来追踪在训练过程中你看到的𝜇和𝜎2 的值。还可以用指数加权平均，有时也叫做流动平均来粗略估算𝜇和𝜎 2 ，然后在测试中使用 𝜇和𝜎 2 的值来进行你所需要的隐藏单元𝑧值的调整。在实践中，不管你用什么方式估算𝜇和𝜎 2 ，这套过程都是比较稳健的，因此我不太会担心你具体的操作方式，而且如果你使用的是某种 深度学习框架，通常会有默认的估算𝜇和𝜎 2 的方式，应该一样会起到比较好的效果。但在实 践中，任何合理的估算你的隐藏单元𝑧值的均值和方差的方式，在测试中应该都会有效。

Batch 归一化就讲到这里，使用 Batch 归一化，你能够训练更深的网络，让你的学习算 法运行速度更快，在结束这周的课程之前，我还想和你们分享一些关于深度学习框架的想法，让我们在下一段视频中一起讨论这个话题。

234 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.8 Softmax 回归（Softmax regression）

到目前为止，我们讲到过的分类的例子都使用了二分分类，这种分类只有两种可能的标 记 0 或 1，这是一只猫或者不是一只猫，如果我们有多种可能的类型的话呢？有一种 logistic 回归的一般形式，叫做 Softmax 回归，能让你在试图识别某一分类时做出预测，或者说是多 种分类中的一个，不只是识别两个分类，我们来一起看一下。

假设你不单需要识别猫，而是想识别猫，狗和小鸡，我把猫加做类 1，狗为类 2，小鸡 是类 3，如果不属于以上任何一类，就分到「其它」或者说「以上均不符合」这一类，我把它叫 做类 0。这里显示的图片及其对应的分类就是一个例子，这幅图片上是一只小鸡，所以是类 3，猫是类 1，狗是类 2，我猜这是一只考拉，所以以上均不符合，那就是类 0，下一个类 3，以此类推。我们将会用符号表示，我会用大写的𝐶来表示你的输入会被分入的类别总个数，在这个例子中，我们有 4 种可能的类别，包括「其它」或「以上均不符合」这一类。当有 4 个分 类时，指示类别的数字，就是从 0 到𝐶 − 1，换句话说就是 0、1、2、3。

在这个例子中，我们将建立一个神经网络，其输出层有 4 个，或者说𝐶个输出单元，因 此𝑛，即输出层也就是𝐿层的单元数量，等于 4，或者一般而言等于𝐶。我们想要输出层单元 的数字告诉我们这 4 种类型中每个的概率有多大，所以这里的第一个节点 (最后输出的第 1 个方格 + 圆圈) 输出的应该是或者说我们希望它输出「其它」类的概率。在输入𝑋的情况下，这 个 (最后输出的第 2 个方格 + 圆圈) 会输出猫的概率。在输入𝑋的情况下，这个会输出狗的概率 (最后输出的第 3 个方格 + 圆圈)。在输入𝑋的情况下，输出小鸡的概率（最后输出的第 4 个方 格 + 圆圈），我把小鸡缩写为 bc（baby chick）。因此这里的𝑦将是一个 4 × 1 维向量，因为它 必须输出四个数字，给你这四种概率，因为它们加起来应该等于 1，输出中的四个数字加起

235 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

来应该等于 1。让你的网络做到这一点的标准模型要用到 Softmax 层，以及输出层来生成输出，让我把 式子写下来，然后回过头来，就会对 Softmax 的作用有一点感觉了。

在神经网络的最后一层，你将会像往常一样计算各层的线性部分，𝑧 [𝑙] 这是最后一层的𝑧 变量，记住这是大写𝐿层，和往常一样，计算方法是𝑧 [𝑙] = 𝑊 [𝑙] 𝑎 [𝐿−1] + 𝑏 [𝑙] ，算出了𝑧之后，你需要应用 Softmax 激活函数，这个激活函数对于 Softmax 层而言有些不同，它的作用是这 样的。首先，我们要计算一个临时变量，我们把它叫做 t，它等于𝑒 𝑧 [𝑙] ，这适用于每个元素，而这里的𝑧 [𝑙] ，在我们的例子中，𝑧 [𝑙] 是 4×1 的，四维向量𝑡 = 𝑒 𝑧 [𝑙] ，这是对所有元素求幂，𝑡 也是一个 4×1 维向量，然后输出的𝑎 [𝑙] ，基本上就是向量𝑡，但是会归一化，使和为 1。因此 [𝑙] 𝑧 𝑒 𝑎 [𝑙] = ∑ 4 𝑡 𝑖 ，换句话说，𝑎 [𝑙] 也是一个 4×1 维向量，而这个四维向量的第𝑖个元素，我把它写

𝑗=1 

下来，𝑎 𝑖 [𝑙] =

𝑡 𝑖 

∑ 𝑗=1 4 

𝑡 

𝑖 ，以防这里的计算不够清晰易懂，我们马上会举个例子来详细解释。

我们来看一个例子，详细解释，假设你算出了𝑧 [𝑙] ，𝑧 [𝑙] 是一个四维向量，假设为𝑧 [𝑙] = 5 𝑒5 2 𝑒2 [我们要做的就是用这个元素取幂方法来计算𝑡，所以𝑡 = [ −1]，如果你按一下计算器 −1 𝑒

]，3 𝑒3 

148.4 7.4 就会得到以下值𝑡 = [我们从向量𝑡得到向量𝑎 [𝑙] 就只需要将这些项目归一化，使总和

]，20.1 

0.4 

为 1。如果你把𝑡的元素都加起来，把这四个数字加起来，得到 176.3，最终𝑎 [𝑙] =

𝑡 

。

176.3 

236 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

𝑒 5 例如这里的第一个节点，它会输出 176.3

= 0.842，这样说来，对于这张图片，如果这是

你得到的𝑧值 ([

5 2 

𝑒 2 它是类 0 的概率就是 84.2%。下一个节点输出 176.3

])，−1 3 

= 0.042，也就是 4.2%

𝑒 −1 的几率。下一个是 176.3

3 

𝑒 = 0.002。最后一个是 176.3 = 0.114，也就是 11.4% 的概率属于类 3，也就是小鸡组，对吧？这就是它属于类 0，类 1，类 2，类 3 的可能性。

神经网络的输出𝑎 [𝑙] ，也就是𝑦，是一个 4×1 维向量，这个 4×1 向量的元素就是我们算出

0.842 0.042 来的这四个数字 ([所以这种算法通过向量𝑧 [𝑙] 计算出总和为 1 的四个概率。

])，0.114 

0.002 

如果我们总结一下从𝑧 [𝑙] 到𝑎 [𝑙] 的计算步骤，整个计算过程，从计算幂到得出临时变量𝑡，再归一化，我们可以将此概括为一个 Softmax 激活函数。设𝑎 [𝑙] = 𝑔 [𝑙] (𝑧 [𝑙] )，这一激活函数 的与众不同之处在于，这个激活函数𝑔 需要输入一个 4×1 维向量，然后输出一个 4×1 维向 量。之前，我们的激活函数都是接受单行数值输入，例如 Sigmoid 和 ReLu 激活函数，输入 一个实数，输出一个实数。Softmax 激活函数的特殊之处在于，因为需要将所有可能的输出

237 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

归一化，就需要输入一个向量，最后输出一个向量。那么 Softmax 分类器还可以代表其它的什么东西么？我来举几个例子，你有两个输入 𝑥 1 ，𝑥 2 ，它们直接输入到 Softmax 层，它有三四个或者更多的输出节点，输出𝑦，我将向你 展示一个没有隐藏层的神经网络，它所做的就是计算𝑧 [1] = 𝑊 [1] 𝑥 + 𝑏 [1] ，而输出的出𝑎 [𝑙] ，或者说𝑦，𝑎 [𝑙] = 𝑦 = 𝑔(𝑧 [1] )，就是𝑧 [1] 的 Softmax 激活函数，这个没有隐藏层的神经网络应 该能让你对 Softmax 函数能够代表的东西有所了解。

这个例子中（左边图），原始输入只有𝑥 1 和𝑥 2 ，一个𝐶 = 3 个输出分类的 Softmax 层能 够代表这种类型的决策边界，请注意这是几条线性决策边界，但这使得它能够将数据分到 3 个类别中，在这张图表中，我们所做的是选择这张图中显示的训练集，用数据的 3 种输出标 签来训练 Softmax 分类器，图中的颜色显示了 Softmax 分类器的输出的阈值，输入的着色是 基于三种输出中概率最高的那种。因此我们可以看到这是 logistic 回归的一般形式，有类似 线性的决策边界，但有超过两个分类，分类不只有 0 和 1，而是可以是 0，1 或 2。

这是（中间图）另一个 Softmax 分类器可以代表的决策边界的例子，用有三个分类的数 据集来训练，这里（右边图）还有一个。对吧，但是直觉告诉我们，任何两个分类之间的决 策边界都是线性的，这就是为什么你看到，比如这里黄色和红色分类之间的决策边界是线性 边界，紫色和红色之间的也是线性边界，紫色和黄色之间的也是线性决策边界，但它能用这 些不同的线性函数来把空间分成三类。

我们来看一下更多分类的例子，这个例子中（左边图）𝐶 = 4，因此这个绿色分类和 Softmax 仍旧可以代表多种分类之间的这些类型的线性决策边界。另一个例子（中间图）是 𝐶 = 5 类，最后一个例子（右边图）是𝐶 = 6，这显示了 Softmax 分类器在没有隐藏层的情况

238 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

下能够做到的事情，当然更深的神经网络会有𝑥，然后是一些隐藏单元，以及更多隐藏单元 等等，你就可以学习更复杂的非线性决策边界，来区分多种不同分类。我希望你了解了神经网络中的 Softmax 层或者 Softmax 激活函数有什么作用，下一个视 频中，我们来看一下你该怎样训练一个使用 Softmax 层的神经网络。

239 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.9 训练一个 Softmax 分类器（Training a Softmax classifier）

上一个视频中我们学习了 Softmax 层和 Softmax 激活函数，在这个视频中，你将更深入 地了解 Softmax 分类，并学习如何训练一个使用了 Softmax 层的模型。

回忆一下我们之前举的的例子，输出层计算出的𝑧 [𝑙] 如下，𝑧 [𝑙] = [

5 2 

] 我们有四个分类 −1 3

𝑒5 𝐶 = 4，𝑧 [𝑙] 可以是 4×1 维向量，我们计算了临时变量𝑡，= [ 𝑒2 𝑒 −1 𝑒3

𝑡 

]，对元素进行幂运算，最

后，如果你的输出层的激活函数𝑔 [𝐿] () 是 Softmax 激活函数，那么输出就会是这样的：

简单来说就是用临时变量𝑡将它归一化，使总和为 1，于是这就变成了𝑎 [𝐿] ，你注意到向 量𝑧中，最大的元素是 5，而最大的概率也就是第一种概率。

1 0 

Softmax 这个名称的来源是与所谓 hardmax 对比，hardmax 会把向量𝑧变成这个向量 [

]，0 0 

hardmax 函数会观察𝑧的元素，然后在𝑧中最大元素的位置放上 1，其它位置放上 0，所这是

240 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

一个 hard max，也就是最大的元素的输出为 1，其它的输出都为 0。与之相反，Softmax 所 做的从𝑧到这些概率的映射更为温和，我不知道这是不是一个好名字，但至少这就是 softmax 这一名称背后所包含的想法，与 hardmax 正好相反。

有一点我没有细讲，但之前已经提到过的，就是 Softmax 回归或 Softmax 激活函数将 logistic 激活函数推广到𝐶类，而不仅仅是两类，结果就是如果𝐶 = 2，那么𝐶 = 2 的 Softmax 实际上变回了 logistic 回归，我不会在这个视频中给出证明，但是大致的证明思路是这样的，如果𝐶 = 2，并且你应用了 Softmax，那么输出层𝑎 [𝐿] 将会输出两个数字，如果𝐶 = 2 的话，也 许输出 0.842 和 0.158，对吧？这两个数字加起来要等于 1，因为它们的和必须为 1，其实它 们是冗余的，也许你不需要计算两个，而只需要计算其中一个，结果就是你最终计算那个数 字的方式又回到了 logistic 回归计算单个输出的方式。这算不上是一个证明，但我们可以从 中得出结论，Softmax 回归将 logistic 回归推广到了两种分类以上。

接下来我们来看怎样训练带有 Softmax 输出层的神经网络，具体而言，我们先定义训练 神经网络使会用到的损失函数。举个例子，我们来看看训练集中某个样本的目标输出，真实 0 1 标签是 [用上一个视频中讲到过的例子，这表示这是一张猫的图片，因为它属于类 1，现]，0 0

0.3 0.2 在我们假设你的神经网络输出的是𝑦，𝑦是一个包括总和为 1 的概率的向量，𝑦 = [ 你

]，0.4 

0.1 

0.3 0.2 可以看到总和为 1，这就是𝑎 [𝑙] ，𝑎 [𝑙] = 𝑦 = [ 对于这个样本神经网络的表现不佳，这实

]。0.4 际上是一只猫，但却只分配到 20% 是猫的概率，所以在本例中表现不佳。

0.1 

241 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

那么你想用什么损失函数来训练这个神经网络？在 Softmax 分类中，我们一般用到的损 失函数是𝐿(𝑦 , 𝑦) = − ∑ 𝑗=1 4 𝑦 𝑗 𝑙𝑜𝑔 𝑦 𝑗 ，我们来看上面的单个样本来更好地理解整个过程。注意

在这个样本中𝑦 1 = 𝑦 3 = 𝑦 4 = 0，因为这些都是 0，只有𝑦 2 = 1，如果你看这个求和，所有含 有值为 0 的𝑦 𝑗 的项都等于 0，最后只剩下−𝑦 2 𝑡𝑙𝑜𝑔 𝑦2 ，因为当你按照下标𝑗全部加起来，所有 的 项 都 为 0 ，除 了 𝑗 = 2 时 ，又 因 为 𝑦 2 = 1 ，所 以 它 就 等 于 − 𝑙𝑜𝑔 𝑦 2 。𝐿(𝑦 , 𝑦) =

− ∑ 𝑗=1 4 𝑦 𝑗 log 𝑦 = −𝑦 2 𝑙𝑜𝑔 𝑦 2 = − 𝑙𝑜𝑔 𝑦2 

这就意味着，如果你的学习算法试图将它变小，因为梯度下降法是用来减少训练集的损 失的，要使它变小的唯一方式就是使−log𝑦 变小，要想做到这一点，就需要使𝑦 尽可能大，因为这些是概率，所以不可能比 1 大，但这的确也讲得通，因为在这个例子中𝑥是猫的图片，0.3

0.2 你就需要这项输出的概率尽可能地大（𝑦 = [ 0.1

] 中第二个元素）。0.4

概括来讲，损失函数所做的就是它找到你的训练集中的真实类别，然后试图使该类别相 应的概率尽可能地高，如果你熟悉统计学中最大似然估计，这其实就是最大似然估计的一种 形式。但如果你不知道那是什么意思，也不用担心，用我们刚刚讲过的算法思维也足够了。

这是单个训练样本的损失，整个训练集的损失𝐽又如何呢？也就是设定参数的代价之类 的，还有各种形式的偏差的代价，它的定义你大致也能猜到，就是整个训练集损失的总和，把你的训练算法对所有训练样本的预测都加起来，

𝑚 1 𝐽(𝑤 [1] ,𝑏 [1] , … … ) = ∑ 𝐿(𝑦 , 𝑦 (𝑖) ) 𝑚 𝑖=1 

因此你要做的就是用梯度下降法，使这里的损失最小化。

242 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

最后还有一个实现细节，注意因为𝐶 = 4，𝑦是一个 4×1 向量，𝑦也是一个 4×1 向量，如 果你实现向量化，矩阵大写𝑌就是 [𝑦 (1) 𝑦 (2) … … 𝑦 (𝑚) ]，例如如果上面这个样本是你的第一个 0 0 1 …

1 0 0 … 训练样本，那么矩阵𝑌 = [ ]，那么这个矩阵𝑌最终就是一个 4 × 𝑚维矩阵。类似 0 1 0 …

0 0 0 … 

0.3 0.2 的，𝑌 = [𝑦 𝑦 (2) … … 𝑦 (𝑚) ]，这个其实就是𝑦 （𝑎 [𝑙](1) = 𝑦 (1) = [ 或是第一个训练

]），0.4 

0.1 

0.3 … 

0.2 … 样本的输出，那么𝑌 = [ ]，𝑌本身也是一个 4 × 𝑚维矩阵。

0.1 … 

0.4 … 

最后我们来看一下，在有 Softmax 输出层时如何实现梯度下降法，这个输出层会计算 𝑧 [𝑙] ，它是𝐶 × 1 维的，在这个例子中是 4×1，然后你用 Softmax 激活函数来得到𝑎 [𝑙] 或者说𝑦，然后又能由此计算出损失。我们已经讲了如何实现神经网络前向传播的步骤，来得到这些输 出，并计算损失，那么反向传播步骤或者梯度下降法又如何呢？其实初始化反向传播所需要

的关键步骤或者说关键方程是这个表达式𝑑𝑧 [𝑙] = 𝑦 − 𝑦，你可以用𝑦这个 4×1 向量减去𝑦这个

4×1 向量，你可以看到这些都会是 4×1 向量，当你有 4 个分类时，在一般情况下就是𝐶 × 1，𝜕𝐽 这符合我们对𝑑𝑧的一般定义，这是对𝑧 [𝑙] 损失函数的偏导数（𝑑𝑧 [𝑙] = 𝜕𝑧 [𝑙] ），如果你精通微积 分就可以自己推导，或者说如果你精通微积分，可以试着自己推导，但如果你需要从零开始

243 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

使用这个公式，它也一样有用。

有了这个，你就可以计算𝑑𝑧 [𝑙] ，然后开始反向传播的过程，计算整个神经网络中所需要 的所有导数。

但在这周的初级练习中，我们将开始使用一种深度学习编程框架，对于这些编程框架，通常你只需要专注于把前向传播做对，只要你将它指明为编程框架，前向传播，它自己会弄 明白怎样反向传播，会帮你实现反向传播，所以这个表达式值得牢记（𝑑𝑧 [𝑙] = 𝑦 − 𝑦），如 果你需要从头开始，实现 Softmax 回归或者 Softmax 分类，但其实在这周的初级练习中你不 会用到它，因为编程框架会帮你搞定导数计算。

Softmax 分类就讲到这里，有了它，你就可以运用学习算法将输入分成不止两类，而是 𝐶个不同类别。接下来我想向你展示一些深度学习编程框架，可以让你在实现深度学习算法 时更加高效，让我们在下一个视频中一起讨论。

244 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.10 深度学习框架（Deep Learning frameworks）

你已经差不多从零开始学习了使用 Python 和 NumPy 实现深度学习算法，很高兴你这 样做了，因为我希望你理解这些深度学习算法实际上在做什么。但你会发现，除非应用更复 杂的模型，例如卷积神经网络，或者循环神经网络，或者当你开始应用很大的模型，否则它 就越来越不实用了，至少对大多数人而言，从零开始全部靠自己实现并不现实。

幸运的是，现在有很多好的深度学习软件框架，可以帮助你实现这些模型。类比一下，我猜你知道如何做矩阵乘法，你还应该知道如何编程实现两个矩阵相乘，但是当你在建很大 的应用时，你很可能不想用自己的矩阵乘法函数，而是想要访问一个数值线性代数库，它会 更高效，但如果你明白两个矩阵相乘是怎么回事还是挺有用的。我认为现在深度学习已经很 成熟了，利用一些深度学习框架会更加实用，会使你的工作更加有效，那就让我们来看下有 哪些框架。

现在有许多深度学习框架，能让实现神经网络变得更简单，我们来讲主要的几个。每个 框架都针对某一用户或开发群体的，我觉得这里的每一个框架都是某类应用的可靠选择，有 很多人写文章比较这些深度学习框架，以及这些深度学习框架发展得有多好，而且因为这些 框架往往不断进化，每个月都在进步，如果你想看看关于这些框架的优劣之处的讨论，我留 给你自己去网上搜索，但我认为很多框架都在很快进步，越来越好，因此我就不做强烈推荐 了，而是与你分享推荐一下选择框架的标准。

一个重要的标准就是便于编程，这既包括神经网络的开发和迭代，还包括为产品进行配 置，为了成千上百万，甚至上亿用户的实际使用，取决于你想要做什么。

第二个重要的标准是运行速度，特别是训练大数据集时，一些框架能让你更高效地运行

245 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

和训练神经网络。还有一个标准人们不常提到，但我觉得很重要，那就是这个框架是否真的开放，要是一 个框架真的开放，它不仅需要开源，而且需要良好的管理。不幸的是，在软件行业中，一些 公司有开源软件的历史，但是公司保持着对软件的全权控制，当几年时间过去，人们开始使 用他们的软件时，一些公司开始逐渐关闭曾经开放的资源，或将功能转移到他们专营的云服 务中。因此我会注意的一件事就是你能否相信这个框架能长时间保持开源，而不是在一家公 司的控制之下，它未来有可能出于某种原因选择停止开源，即便现在这个软件是以开源的形 式发布的。但至少在短期内，取决于你对语言的偏好，看你更喜欢 Python，Java 还是 C++ 或 者其它什么，也取决于你在开发的应用，是计算机视觉，还是自然语言处理或者线上广告，等等，我认为这里的多个框架都是很好的选择。

程序框架就讲到这里，通过提供比数值线性代数库更高程度的抽象化，这里的每一个程 序框架都能让你在开发深度机器学习应用时更加高效。

246 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

3.11 TensorFlow 

欢迎来到这周的最后一个视频，有很多很棒的深度学习编程框架，其中一个是 TensorFlow，我很期待帮助你开始学习使用 TensorFlow，我想在这个视频中向你展示 TensorFlow 程序的基本结构，然后让你自己练习，学习更多细节，并运用到本周的编程练习 中，这周的编程练习需要花些时间来做，所以请务必留出一些空余时间。

先提一个启发性的问题，假设你有一个损失函数𝐽需要最小化，在本例中，我将使用这 个高度简化的损失函数，𝐽𝑤 = 𝑤 2 − 10𝑤 + 25，这就是损失函数，也许你已经注意到该函数 其实就是 (𝑤 − 5) 2 ，如果你把这个二次方式子展开就得到了上面的表达式，所以使它最小的 𝑤值是 5，但假设我们不知道这点，你只有这个函数，我们来看一下怎样用 TensorFlow 将其 最小化，因为一个非常类似的程序结构可以用来训练神经网络。其中可以有一些复杂的损失 函数𝐽(𝑤, 𝑏) 取决于你的神经网络的所有参数，然后类似的，你就能用 TensorFlow 自动找到 使损失函数最小的𝑤和𝑏的值。但让我们先从左边这个更简单的例子入手。

我在我的 Jupyter notebook 中运行 Python，import numpy as np import tensorflow as tf #导入 TensorFlow w = tf.Variable (0,dtype = tf.float32) #接下来，让我们定义参数 w，在 TensorFlow 中，你要用 tf.Variable () 来定义参数 #然后我们定义损失函数： cost = tf.add (tf.add (w**2,tf.multiply (- 10.,w)),25) #然后我们定义损失函数 J

247 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

#然后我们再写： train = tf.train.GradientDescentOptimizer (0.01).minimize (cost) #(让我们用 0.01 的学习率，目标是最小化损失)。#最后下面的几行是惯用表达式:

init = tf.global_variables_initializer () session = tf.Sessions ()# 这样就开启了一个 TensorFlow session。session.run (init)# 来初始化全局变量。#然后让 TensorFlow 评估一个变量，我们要用到:

session.run (w) #上面的这一行将 w 初始化为 0，并定义损失函数，我们定义 train 为学习算法，它用 梯度下降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以 #上面 的这一行将 w 初始化为 0，并定义损失函数，我们定义 train 为学习算法，它用梯度下 降法优化器使损失函数最小化，但实际上我们还没有运行学习算法，所以 session.run (w) 评估了 w，让我：： print (session.run (w))

#所以如果我们运行这个，它评估𝑤等于 0，因为我们什么都还没运行。

#现在让我们输入： session.run (train)，它所做的就是运行一步梯度下降法。#接下来在运行了一步梯度下降法后，让我们评估一下 w 的值，再 print： print (session.run (w)) #在一步梯度下降法之后，w 现在是 0.1。

现在我们运行梯度下降 1000 次迭代：

248 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

这是运行了梯度下降的 1000 次迭代，最后𝑤变成了 4.99999，记不记得我们说 (𝑤 − 5) 2 最小化，因此𝑤的最优值是 5，这个结果已经很接近了。

希望这个让你对 TensorFlow 程序的大致结构有了了解，当你做编程练习，使用更多 TensorFlow 代码时，我这里用到的一些函数你会熟悉起来，这里有个地方要注意，𝑤是我们 想要优化的参数，因此将它称为变量，注意我们需要做的就是定义一个损失函数，使用这些 add 和 multiply 之类的函数。TensorFlow 知道如何对 add 和 mutiply，还有其它函数求 导，这就是为什么你只需基本实现前向传播，它能弄明白如何做反向传播和梯度计算，因为 它已经内置在 add，multiply 和平方函数中。

对了，要是觉得这种写法不好看的话，TensorFlow 其实还重载了一般的加减运算等等，因此你也可以把𝑐𝑜𝑠𝑡写成更好看的形式，把之前的 cost 标成注释，重新运行，得到了同样 的结果。

一旦𝑤被称为 TensorFlow 变量，平方，乘法和加减运算都重载了，因此你不必使用上面 这种不好看的句法。

TensorFlow 还有一个特点，我想告诉你，那就是这个例子将𝑤的一个固定函数最小化了。如果你想要最小化的函数是训练集函数又如何呢？不管你有什么训练数据𝑥，当你训练神经 网络时，训练数据𝑥会改变，那么如何把训练数据加入 TensorFlow 程序呢？

我会定义𝑥，把它想做扮演训练数据的角色，事实上训练数据有𝑥和𝑦，但这个例子中只 有𝑥，把𝑥定义为：

x = tf.placeholder (tf.float32,[3,1])，让它成为 [3,1] 数组，我要做的就是，

249 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

因为𝑐𝑜𝑠𝑡这个二次方程的三项前有固定的系数，它是𝑤 2 + 10𝑤 + 25，我们可以把这些数字 1，-10 和 25 变成数据，我要做的就是把𝑐𝑜𝑠𝑡替换成：

cost = x [0][0]*w**2 +x [1][0]*w + x [2][0]，现在𝑥变成了控制这个二次函数 系数的数据，这个 placeholder 函数告诉 TensorFlow，你稍后会为𝑥提供数值。

让我们再定义一个数组，coefficient = np.array ([[1.],[-10.],[25.]])，这 就是我们要接入𝑥的数据。最后我们需要用某种方式把这个系数数组接入变量𝑥，做到这一点 的句法是，在训练这一步中，要提供给𝑥的数值，我在这里设置：

feed_dict = {x:coefficients} 

好了，希望没有语法错误，我们重新运行它，希望得到和之前一样的结果。

现在如果你想改变这个二次函数的系数，假设你把： coefficient = np.array ([[1.],[-10.],[25.]])

改为： coefficient = np.array ([[1.],[-20.],[100.]])

现在这个函数就变成了 (𝑤 − 10) 2 ，如果我重新运行，希望我得到的使 (𝑤 − 10) 2 最小化 的𝑤值为 10，让我们看一下，很好，在梯度下降 1000 次迭代之后，我们得到接近 10 的𝑤。

250 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

在你做编程练习时，见到更多的是，TensorFlow 中的 placeholder 是一个你之后会赋值 的变量，这种方式便于把训练数据加入损失方程，把数据加入损失方程用的是这个句法，当 你运行训练迭代，用 feed_dict 来让 x=coefficients。如果你在做 mini-batch 梯度下 降，在每次迭代时，你需要插入不同的 mini-batch，那么每次迭代，你就用 feed_dict 来 喂入训练集的不同子集，把不同的 mini-batch 喂入损失函数需要数据的地方。

希望这让你了解了 TensorFlow 能做什么，让它如此强大的是，你只需说明如何计算损 失函数，它就能求导，而且用一两行代码就能运用梯度优化器，Adam 优化器或者其他优化 器。

251 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

这还是刚才的代码，我稍微整理了一下，尽管这些函数或变量看上去有点神秘，但你在 做编程练习时多练习几次就会熟悉起来了。

还有最后一点我想提一下，这三行（蓝色大括号部分）在 TensorFlow 里是符合表达习 惯的，有些程序员会用这种形式来替代，作用基本上是一样的。

但这个 with 结构也会在很多 TensorFlow 程序中用到，它的意思基本上和左边的相同，但是 Python 中的 with 命令更方便清理，以防在执行这个内循环时出现错误或例外。所以你 也会在编程练习中看到这种写法。那么这个代码到底做了什么呢？让我们看这个等式：

cost = x[0][0]*w**2 +x[1][0]*w + x[2][0]#(w-5)**2 

TensorFlow 程序的核心是计算损失函数，然后 TensorFlow 自动计算出导数，以及如何 最小化损失，因此这个等式或者这行代码所做的就是让 TensorFlow 建立计算图，计算图所 做的就是取𝑥[0][0]，取𝑤，然后将它平方，然后𝑥[0][0] 和𝑤 2 相乘，你就得到了𝑥[0][0] ∗ 𝑤2 ，以此类推，最终整个建立起来计算𝑐𝑜𝑠𝑡 = [0][0] ∗ 𝑤 ∗∗ 2 + 𝑥[1][0] ∗ 𝑤 + 𝑥[2][0]，最后你得 到了损失函数。

252 

第二门课 改善深层神经网络：超参数调试、正则化以及优化 (Improving Deep Neural Networks:Hyperparameter tuning, Regularization and Optimization)- 第三周 超参数调试、Batch 正则化和程序 框架（Hyperparameter tuning）

TensorFlow 的优点在于，通过用这个计算损失，计算图基本实现前向传播，TensorFlow 已经内置了所有必要的反向函数，回忆一下训练深度神经网络时的一组前向函数和一组反向 函数，而像 TensorFlow 之类的编程框架已经内置了必要的反向函数，这也是为什么通过内 置函数来计算前向函数，它也能自动用反向函数来实现反向传播，即便函数非常复杂，再帮 你计算导数，这就是为什么你不需要明确实现反向传播，这是编程框架能帮你变得高效的原 因之一。

如果你看 TensorFlow 的使用说明，我只是指出 TensorFlow 的说明用了一套和我不太一 样的符号来画计算图，它用了𝑥[0][0]，𝑤，然后它不是写出值，想这里的𝑤2 ，TensorFlow 使 用说明倾向于只写运算符，所以这里就是平方运算，而这两者一起指向乘法运算，以此类推，然后在最后的节点，我猜应该是一个将𝑥[2][0] 加上去得到最终值的加法运算。

为本课程起见，我认为计算图用第一种方式会更容易理解，但是如果你去看 TensorFlow 的使用说明，如果你看到说明里的计算图，你会看到另一种表示方式，节点都用运算来标记 而不是值，但这两种呈现方式表达的是同样的计算图。

在编程框架中你可以用一行代码做很多事情，例如，你不想用梯度下降法，而是想用 Adam 优化器，你只要改变这行代码，就能很快换掉它，换成更好的优化算法。所有现代深 度学习编程框架都支持这样的功能，让你很容易就能编写复杂的神经网络。

我希望我帮助你了解了 TensorFlow 程序典型的结构，概括一下这周的内容，你学习了 如何系统化地组织超参数搜索过程，我们还讲了 Batch 归一化，以及如何用它来加速神经网 络的训练，最后我们讲了深度学习的编程框架，有很多很棒的编程框架，这最后一个视频我 们重点讲了 TensorFlow。有了它，我希望你享受这周的编程练习，帮助你更熟悉这些概念。

253 

第三门课 结构化机器学习项目（Structuring Machine Learning Projects）- 第一周 机器学习（ML）策略 （1）（ML strategy（1））

第三门课 结构化机器学习项目（Structuring

Machine Learning Projects） 

第一周 机器学习（ML）策略（1）（ML strategy（1））

