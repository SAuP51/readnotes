5.3　技术尖端论

「技术尖端论」也是数据分析师，尤其是年轻的刚接触数据分析应用的数据分析师里比较有代表性的一种错误观念和思想。持有这种观念的分析师，会过分追求所谓尖端的、高级的、时髦的、显示自己技术水准的数据分析挖掘技术，认为分析技术越高级越好，越尖端越厉害。在数据分析项目实践中的主要表现就是面对一个分析课题，持「技术尖端论」的分析师首先想到的是选择一个最尖端的、最高级的分析技术去解决，而不是从课题本身的真实需求出发去思考最合理、最有性价比的分析技术。

任何一个数据分析课题，至少都会有两种以上的不同分析技术和分析思路。不同的分析技术常常需要不同的分析资源投入，还需要不同的业务资源配合，而产出物也有可能是不同精度和不同表现形式的。这其中孰优孰劣，根据什么做判断呢？是根据项目、课题本身的需求精度、资源限制（包括时间资源、业务配合资源、数据分析资源投入）等来做判断和选择，还是按照分析技术的高级与否做判断和选择？不同的考虑方式和选择结果，决定着项目的资源投入和对业务需求满足的匹配程度，一味选择尖端的、高级的算法和分析技术很可能会造成项目资源投入的浪费，并且很可能不是最适合业务需求的方案。最贵的，不一定是最适合你的，我们在生活中的体验和感悟同样也是适用于数据分析课题的场景和数据化运营应用的。

举一个实际的案例来说明。如某在线新产品上线试运营了两个月，产生了一批付费购买的用户，现在产品运营团队希望能比较深入、全面地了解目标用户的基本特征和大致的群体规模。针对这个分析需求，基于当前的业务背景（刚刚上线运营两个月）应该用什么样的分析思路和分析技术呢？目标用户特征群体筛选课题的解决思路，至少有 3 种以上的分析技术可以完成：有简单的技术，如统计描述总结、相关性分析、假设检验等；有常规的技术，比如聚类分析等；也有更加需要资源投入的技术，比如针对单个目标用户的预计付费概率的预测模型。具体到本案例，由于产品刚刚上线运营两个月，业务方对目标用户的大致情况还没有一个详细、全面的了解，而且无法使用精确的付费概率预测模型（2 个月的数据很难完全支撑起一个有效的预测模型的搭建和验证），所以综合考虑，简单地统计描述总结，进行相关性分析和假设检验是现阶段、现有业务背景下比较具有性价比的优选思路和解决办法。

追求技术的进步和发展本身没有错，但是一味强调技术的先进性，忘记了业务因素对分析课题的决定性影响，忘记了数据分析工作的目的是为业务服务、满足业务需求的根本宗旨，实际上就是本末倒置、舍本逐末，其实践后果通常就是浪费了分析资源，或者丢掉了最佳性价比的方案，或者根本无法与真实的业务需求有效对接。

应对并防止「技术尖端论」的一些有效的管理措施和管理制度包括 5.2 节谈到的课题需求评估机制，即用专家集体的力量提炼出最合适的、最具性价比的分析思路和技术，以及经常性的分析师团队的技术分享，如项目课题分享、同行间的课题交流，从不同的实际案例中深刻体会如何权衡分析思路、为什么「适用性」比「尖端性」更好、为什么「性价比」的考虑比单纯的「技术性高低」的考虑更可靠更有意义，从而逐渐开阔分析师的思路和视野，丰富分析师的经验。

5.4　建模与应用两段论

「建模与应用两段论」在当前的企业数据化运营实践中比较普遍，相当数量的数据分析师都自觉或者不自觉地在工作中表现出「两段论」的现象，比如不少数据分析师一旦将模型搭建好并验证通过之后，就将之丢给业务方去应用，至于业务方具体应该如何应用模型，数据分析师不太关心。又比如，模型或数据分析结论、方案在业务应用中出现了问题或瓶颈，但是相关的数据分析师不愿意去主动进行分析、诊断，或者不太清楚如何找出造成业务落地应用困境的原因，只能将这些问题和困难丢给业务落地应用方自己去摸索。

「建模与应用两段论」的背后既有分析师自身对业务背景了解不足、业务知识欠缺，或者业务经验不够的原因，又有分析师「偷懒，多一事不如少一事」的心态在作怪，也就是「不负责任」的态度在作怪，就是不能真正有效支持业务需求，最终致使其不能落地应用。更深层次的原因也可能来源于企业管理层、决策层对于数据分析团队的定位和认识比较简单肤浅，对于数据化运营和数据挖掘应用的看法比较落后（如果数据分析团队和数据分析师被认为仅仅是企业里的一个部门、一个分析的职能，「铁路警察，各管一段」、「分析师出模型，业务方管应用」似乎也就顺理成章了）。

一个复杂的挖掘模型也好，一份数据分析报告也罢，对于企业的数据化运营的应用场景来讲都只是万里长征第一步。要真正给企业带来价值，重点在于其后的业务落地应用环节，这个环节比单纯的数据分析和数据建模更复杂、更关键，它需要多团队多专业的协调和配合，离不开数据分析师（数据分析团队）持续地跟踪、讨论、修正、建议。如果数据分析师不能参与落地应用环节，可以肯定地说这个业务落地应用的效果不会好到哪里去。因为除了单纯的模型方案之外，业务应用团队还需要了解数据建模的思路、数据分析师具体的提醒、业务落地应用中碰到困难时分析师的及时诊断和建议、应用效果评估时分析师给出的合理评估思路和评估框架等。更重要的是，数据分析（挖掘建模）过程绝不是简简单单的一蹴而就的过程，很多时候它是一个要通过与业务方的讨论、沟通，不断修正不断完善的过程。脱离了应用中的及时沟通、讨论、反馈、修正，这个模型也不可能有多大的业务应用价值，这样的数据挖掘模型（或者数据分析报告）也没有什么大的价值和意义。

应对和防止「建模与应用脱节」的有效管理措施包括：对于数据分析师的考核和考评不是基于模型（或者分析报告和建议）本身，而是基于模型（项目）业务落地应用后的实际效果和业务反馈，这种考核制度促使数据分析师必须全程参与项目应用（数据化运营），从而显著减少「建模与应用脱节」的可能性；另外，上面几节谈到的分析师管理的实线和虚线的「双线主管」制度也可以有效督促数据分析师加强分析与应用的结合性，确保分析、建模真正来源于业务需求，并真正有效服务于业务需求。

5.5　机器万能论

「机器万能论」的主要特点就是在建模过程中，认为机器（分析软件）是可以最大程度（甚至几乎可以完全）代替分析师手工劳动，于是，即使在很多关键的需要人工介入的步骤和节点，数据分析师仍然简单、轻率地交给机器去处理，盲目、过分地依赖机器的「智能」。其主要的表现形式就是，数据分析师拿了一堆分析数据，不加任何处理（或者只做了简单的处理）就交给机器（分析软件）去自动完成模型搭建，然后直接拿这个去交差，提交业务应用。

「机器万能论」背后的原因主要在于数据分析师自身对于数据挖掘技术、数据分析技术的理解和掌握不熟悉、不透彻，对于挖掘技术和分析技术的把握还是很粗糙，或者是浅尝辄止，分析技术层面的基本功不扎实。在数据挖掘项目中，80% 的时间是花在数据的熟悉、清洗、整理、转换等数据处理阶段的，在这个阶段虽然机器（分析软件）可以大量取代分析师手工进行规范化的、重复性的工作，但是仍然有相当多关键性的工作是需要分析师手工进行的，比如机器最多可以告诉你数据的分布统计特征、变量之间的相关性，但是背后隐藏的是什么样的业务逻辑，如何取舍这些变量等核心的问题是需要分析师去判断去决定的（机器在这时是无能为力的）；又比如，现在很多分析（挖掘）软件都有默认（Default）的参数设置，但是实际上这些默认的设置并不能有效符合任何一个特定的、具体的数据分析课题场景。因此在具体的数据建模过程中，各种算法的参数如何设置，选择哪种算法最合适等这些重要的问题，都是需要数据分析师凭借自己的专业水平和项目经验去作出判断和决定。另外，即使是经验丰富的优秀数据分析师，在层出不穷的新的业务需求和新的业务场景面前，也常常出现已有的经验、原理等无法有效解决新问题、新挑战的情况。在这种情形下，就更需要数据分析师从大量的分析数据里不断探索、尝试了，其中的过程有可能是耗时、曲折、充满艰辛的。

上述种种场景都说明了，数据分析和数据挖掘建模过程中，纵然有先进的分析（挖掘）工具，但是数据分析师人工的投入和判断仍然是必不可少的，我们经常需要手工进行探索。「机器万能论」不可取，不可信，更不可行。

任何事情要做好，都必须具有持续的热情和兴趣。没有热情和兴趣的驱使，就没有持久的深入钻研的动力，也就无法在一个领域、一个专业里得到快乐和干出成绩。数据分析师如果没有对于数据分析、数据挖掘的兴趣和热情，也就不可能深入钻研相关技术，很可能会简单轻松奉行「机器万能论」。把一切都交给机器（分析软件）去撞大运。虽然放手让机器去「万能」很轻松，但是其结果基本上都是不靠谱的、都是不能足够有效满足业务应用需求的。「有得必有失」、「付出才有回报」这些人间的正道，同样也是数据挖掘里的「正道」。

「机器万能论」的根源是对于分析、挖掘技术缺乏必要的理解和掌握，「因为不知如何下手，所以交给机器去代理」。无论有没有相应的管理措施，管理措施带来的效果都不如分析师找到自己对于数据分析、挖掘的热爱和兴趣的效果来得有效和彻底。管理的手段大多是被动的，只有主动的兴趣和热情才是更直接、更有效、更彻底摈弃「机器万能论」的良方，这也是为什么企业在招聘数据分析师的时候，要重点考察应聘者对于数据分析专业的兴趣和热情。

其实，岂止是数据分析领域需要从业者的专业兴趣和热情，人生一路的风景，哪一幕的精彩不是因为兴趣和热情所激发和创造出来的呢？

5.6　幸福的家庭都是相似的，不幸的家庭各有各的不幸

「幸福的家庭都是相似的，不幸的家庭各有各的不幸」，这是俄国大文豪列夫·托尔斯泰在其经典名著《安娜·卡列尼娜》里的经典名言，流传甚广，是人生智慧的高度总结与概括。这句充满智慧的格言同样适用于数据分析师的成长，适用于数据分析挖掘项目的成败，适用于数据化运营的输赢。

成功的数据分析师一定是相似的，他们身上都没有这 5 大错误观念的影子，且没有受其影响；不成功的数据分析师一定是各有各的不幸，有的身上具有某一个错误观念，有的身上同时兼备多个错误观念。

成功的数据分析挖掘项目也一定是相似的，它们背后的分析师都没有这 5 大错误观念的影子，且没有受其影响；不成功的数据分析挖掘项目也一定是各有各的不幸，有的受某一个错误观念影响，有的受多个错误观念影响。

成功的数据化运营也一定是相似的，它们背后的团队都没有这 5 大错误观念的影子，且没有受其影响；不成功的数据化运营也一定是各有各的不幸，有的受某一个错误观念影响，有的受多个错误观念影响。

大道至简，万法归宗，生活的智慧当然也是数据分析挖掘的智慧。

第 6 章　数据挖掘项目完整应用案例演示

举一隅，不以三隅反，则不复也。

——《论语·述而》

6.1　项目背景和业务分析需求的提出

6.2　数据分析师参与需求讨论

6.3　制定需求分析框架和分析计划

6.4　抽取样本数据、熟悉数据、数据清洗和摸底

6.5　按计划初步搭建挖掘模型

6.6　与业务方讨论模型的初步结论，提出新的思路和模型优化方案

6.7　按优化方案重新抽取样本并建模，提炼结论并验证模型

6.8　完成分析报告和落地应用建议

6.9　制定具体的落地应用方案和评估方案

6.10　业务方实施落地应用方案并跟踪、评估效果

6.11　落地应用方案在实际效果评估后，不断修正完善

6.12　不同运营方案的评估、总结和反馈

6.13　项目应用后的总结和反思

数据挖掘是科学，也是艺术，或者说一半是科学，一半是艺术。所谓科学，是指数据挖掘的算法、流程和分析技术的应用是科学的、严谨的；所谓艺术，是指在具体的分析过程中，融入了分析师的创新思维、主观的判断和取舍，尤其表现在挖掘思路的推敲和衍生变量的创建等方面。

本章将以一个完整的数据挖掘项目为例来进行分享和跟踪，包括从业务需求的提出到落地应用反馈的全过程，一方面揭示数据挖掘全过程中所有环节的顺序、内容和相应的关键目标，另一方面从科学和艺术两个方面来具体阐释数据挖掘中各个步骤的特点和价值。

事物的发展很少是一帆风顺的，更多的时候充斥着反复曲折，呈螺旋前进状态，只要每一次的反复和曲折都能够有所提升和突破，那么离成功就会越来越近了。本章的案例也真实地反映了商业实战中的数据挖掘是如何在曲折反复中逐步前进的。完成一个好的模型，达成一个满意的业务应用结果，这只是数据分析师分内的任务和工作职责；而自觉主动地从项目中总结、提升自己，从挫折中发现自己的不足，从而积极改进、完善，更应该成为数据分析师的态度和专业理念。

通过本章的案例，希望向有缘的读者传递以下几个方面的信息：

❑数据挖掘实战中的流程会有一些基本的顺序，按着流程进行挖掘是数据分析严谨性的体现。

❑数据挖掘和模型搭建只是数据化运营中的一个环节，数据化运营是跨团队跨专业的协同作业，数据挖掘模型和结论只有在落地应用的业务场景中才能得到检验，才能体现出价值。从这个角度来说，没有落地应用的数据分析和数据挖掘还不是严格意义上的「完成」。

❑落地应用中的运营方案对模型的应用效果影响极大，所以数据分析师不仅要熟悉数据分析和模型搭建，还要熟悉与运营相关的业务技能，这也是数据挖掘和数据化运营中复合型技能的要求。

鉴于对企业商业机密的考量，本章的项目描述中对于大部分数据都做了有意识的修改和处理，所以案例中的数据已经不能代表企业的真实数据特征了，特此说明。

6.1　项目背景和业务分析需求的提出

某互联网公司「免费会员运营团队」的主要工作内容就是不断培养和提升免费会员的成熟度和电子商务专业度，以便在条件具备的时候可以适时将部分优质的免费会员提升为付费会员，成为付费会员后将可以享受到更多的专业服务，并且可使电子商务技能升级，从而有助于他们从电子商务中获得更大的利益。

按照该运营团队既定的客户分层思路，他们所负责的免费会员按照活跃度来划分可分为高活跃度、中活跃度和低活跃度 3 类群体，活跃度划分的指标主要是 30 天之内登录网站的次数，以及某核心入口 30 天以来的 PV 量。需要强调的是，活跃度划分的这两大核心指标是另外一个项目得出的结论，因涉及企业的商业机密，本书对此不做过多的阐述和数据罗列，读者只需要记住该项目的活跃度划分有这两个指标就可以了。

高活跃度的免费用户一直是该运营团队的重点客户群体，高活跃度群体的付费转化率也一直是最高的，且转化数量也是最多的。但是，困扰运营方的一个重要问题是，高活跃度用户的流失率比较大，有相当比例的高活跃度免费用户在短时间里会从高活跃度跌落到中、低活跃度群体里。

面对这种业务困境，运营方希望数据分析团队能通过数据分析和数据挖掘建模的方法，提前锁定最可能流失的高活跃度用户，这样可以方便运营团队有的放矢针对这些「高危」用户群采取挽留措施，从而可以有效降低他们的流失率和流失数量。

6.2　数据分析师参与需求讨论

接到业务方的初步分析需求之后，数据分析师针对该潜在的项目与相关运营方一起进行了需求讨论。

在数据化运营的商业实战中，这类讨论的主要目的如下：

❑针对需求收集相关的背景数据和指标，与业务方一起熟悉背景中的相关业务逻辑，并收集业务方对需求的相关建议、看法，这些信息对于需求的确认和思路的规划乃至后期的分析都是至关重要的。

❑从数据分析的专业角度评价初步的业务分析需求是否合理，是否可行。尽管说业务方对于业务需求最有发言权，对业务最了解、最敏感，但是从数据化运营的商业实践中来看，业务方提出的分析需求并不是每一个都是合理的，都是可行的。在某些情况下，某些分析需求本身就是「伪命题」；又或者说在具体的场景下，某些分析需求暂时无法进行，比如数据储备不足、样本量太少等。

在本需求的讨论阶段，数据分析师与相关业务团队进行了多次有针对性的讨论，并参与到他们的业务工作流程和实施中，因此对需求有了一定程度的了解和熟悉，并且从数据分析的专业角度对数据的范围、样本有了大致的了解，在此基础上决定接受业务方的分析需求。这样，流程就可以往下进行了。

6.3　制定需求分析框架和分析计划

在本阶段，针对前面对业务的初步了解和需求背景的分析，数据分析师制订了初步的分析框架和分析计划。

分析框架的主要内容如下：

❑分析需求转化成数据分析项目中目标变量的定义。具体到本案例，高活跃度免费用户的流失是这样定义的，在某个时间点（A 点）用户是满足高活跃度用户标准要求的（属于高活跃度用户群体），随后过 A 点 7 天，也就是 1 周之后，这 1 周也是配合运营的时间节奏来确定的，该用户从高活跃度群体跌落到中级甚至是最低级的活跃度群体里，并且在过 A 点 14 天，即 2 周之后仍然没有回到高活跃度标准的，就定义为高活跃度免费用户的流失群体。数据分析师在给出这个初步定义时，要强调上述高活跃度用户的流失定义只是当前的初步定义，随着后期进行数据抽取，并与业务方进一步讨论，有了更深入的分析后，上述流失的定义是可以修改和完善的，修改和完善的最终目的是为了数据分析和挖掘的工作能最有效地支持业务应用，并提升业务工作效率。

❑分析思路的大致描述。具体到本案例，分析思路是通过搭建分类模型来比较准确且有效地来提前锁定有可能流失的用户群体。

❑分析样本的数据抽取规则。关于数据抽取的规则，限于企业的商业机密，不能分享太多，基本上是指根据上面目标变量的定义，选择一个适当的时间窗口，然后抽取一定的样本数据。

❑潜在分析变量（模型输入变量）的大致圈定和罗列。经过前期与业务方的调研和沟通，数据分析师和业务方已经大致圈定了相关变量，即从业务经验判断和以往的分析工作中，提炼整理出来的大约 63 个原始变量，具体见表 6-1。因涉及企业的商业隐私，这里就不具体说明各变量的中文含义了，总而言之，是从业务经验的角度大致罗列了这些似乎对目标变量的预测有意义的相关变量。

❑分析过程中的项目风险思考和主要的应对策略。具体到本案例，项目风险思考主要包括模型效果不好的可能性，即有可能分类模型的思路被证明是不好的，也有可能是模型效果不好，或者准确度不高，或者模型不稳定。是否有相应的分析对策来部分弥补，如果分类模型的思路被证明是行不通的，可以退而求其次进行流失用户的群体特征细分，或者重新定义流失用户等。

❑项目的落地应用价值分析和展望。具体到本案例，则主要集中在 3 个方面：模型投入应用后提前锁定有高流失风险的高活跃度用户群体，从而可以使运营方有针对性地开展挽留、服务等运营工作；可以将建模过程中发现的有价值的、最可能影响流失的重要字段和指标选择性地提供给运营方，用于制定运营方案和策略的依据和参考；针对影响流失的核心指标和字段，可以提供给相关业务方，以作为进行客户关系管理的依据和参考线索。

分析计划主要是指分析过程中时间节点的安排和相应的分析进度的设置，具体可见以下示例，见表 6-2。

6.4　抽取样本数据、熟悉数据、数据清洗和摸底

本阶段的主要内容包括：根据前期讨论的分析思路和建模思路，以及初步圈定的分析字段（分析变量）编写代码，从数据仓库中提取分析、建模所需的样本数据；通过对样本数据的熟悉和摸底，找到无效数据、脏数据、错误数据等，并且对样本数据中存在的这些明显的数据质量问题进行清洗、剔除、转换，同时视具体的业务场景和项目需求，决定是否产生衍生变量，以及怎样衍生等。

在互联网行业，由于业务发展迅猛，产品日新月异，不断在优化或换代，且相关的存储方案和战略方向在不断修改和调整，所有这些因素都导致了数据仓库的数据存储或多或少都存在这样或那样的漏洞、缺憾、偏差，而且直接导致了具体抽取的分析样本数据中不可避免地存在无效数据、脏数据、错误数据等有问题的数据。对于这些数据问题，在本环节不仅要将其明确找出来，还要应用具体的技术手段来加以应对。具体针对本项目的数据质量来说，本阶段有下列主要的发现和应对策略：

❑通过对原始样本数据和原始字段的摸底、排查，发现有些字段缺失值高达 50% 以上，经过研究发现这些缺失是数据仓库存储过程中的记录缺失，或者是由于产品优化后的业务逻辑更改所造成的，这些问题虽然可以向相关的数据仓库接口人反映，但是对于本项目来说已经无法回滚所需的真实数据了，对这些数据我们采取直接删除的措施。

❑通过输入变量之间的相关性分析，找出潜在共线性问题的相关输入变量，对于高度线性相关的变量只保留一个。

❑在数据仓库的数据回滚过程中造成了某些字段的严重不符合逻辑或明显自相矛盾，比如用户最近 30 天登录网站次数为 0，其最近 30 天发布产品信息的天数不为 0。针对类似的严重不符合逻辑的数据问题，要提请数据仓库重新回滚数据，直到数据正确为止。

经过处理，即删除严重缺失数据、数据仓库重新回滚明显矛盾的数据、对高度相关性的部分数据的有取有舍，在本阶段结束时共保留了 36 个比较有意义的字段、变量和相应数据。

关于数据清洗的主要注意事项和常用技术，在第 8 章中会有比较详细的介绍和分析。

6.5　按计划初步搭建挖掘模型

对数据进行初步的摸底和清洗之后，就进入初步搭建挖掘模型阶段了。在该阶段，包括以下 3 个主要的工作内容：

❑进一步筛选模型的输入变量。最终进入模型的输入变量应遵循「少而精」的总原则，该总原则一方面是为了提高模型的稳定性，另一方面也是为了有效提升模型的预测精度。关于如何筛选模型的输入变量，在 8.6 节、9.3.3 节、第 10 章中会有比较详细、深入的分析和讨论，有兴趣的读者可以参考上述章节详细了解。

❑尝试不同的挖掘算法和分析方法，并比较不同方案的效果、效率和稳定性。关于模型的比较和优化，7.4 节有比较详细的整理和总结，有兴趣的读者可以参考阅读。

❑整理经过模型挑选出来的与目标变量的预测最相关的一系列核心输入变量，将其作为与业务方讨论落地应用时的参考和建议。

具体针对本项目实践来说，本阶段在通过不同算法的尝试和对结果的比较中，发现神经网络搭建的模型相对来说准确度更高、效率更高，如图 6-1 所示。

图　6-1　不同算法的模型效果（响应率）比较

从图 6-1 可以看出：通过神经网络模型得到的分数最高的前 10% 的用户中，流失率高达 44% 左右，而样本的整体流失率在 10.1% 左右；得分最高的前 20% 的用户中，流失率高达 29%；得分最高的前 30% 的用户中，流失率高达 24%。

通过逻辑回归模型得到的分数最高的前 10% 的用户中，流失率高达 41% 左右；得分最高的前 20% 的用户中，流失率高达 27%；得分最高的前 30% 用户中，流失率高达 23%。

通过对上述的模型效果的比较，大致可以认为，目前的神经网络模型相对于其他模型而言，有更高的预测效果，可以更多地有效锁定有流失风险的用户。

6.6　与业务方讨论模型的初步结论，提出新的思路和模型优化方案

在本阶段，需要整理模型的初步报告、结论，以及对主要预测字段进行提炼，还要通过与业务方沟通和分享，在此基础上讨论出模型的可能优化方向，并对落地应用的方案进行讨论，同时罗列出注意事项。

具体针对本项目而言，除了上面提到的模型比较之外，还对核心自变量进行了整理提炼，并进行了权重排序，如图 6-2 所示。

图　6-2　核心自变量的提炼

针对目前模型的表现和后期的落地应用场景，数据分析师就下列事项与运营方交换了意见，其中沟通和讨论的主要内容如下：

❑对建模时给出的流失用户的定义要进行后续新数据的跟踪，看该定义是否合理，是否表现稳定，是否符合业务运营的需求。

❑在后期的落地应用中，针对模型所判断出来的流失风险最大的用户群，可以考虑进行更加深入的分析，以找出运营的抓手和进一步的细分特征，其中所涉及的技术包括聚类技术、特征阀值的设定等。

❑模型落地应用后的效果跟踪也非常关键，主要包括：对于模型的稳定性要结合新的数据来验证，要考虑如何评价运营的挽留效果，如何设置运营组和对照组，如何进行客观公正公平的评价（包括模型效果的评价和运营效果的评价等）。

❑模型的优化要遵循资源合理应用的总原则。关于模型的优化和限度，第 7 章有详细的分享和讨论，在此不再过多地扩展讲解。

❑细分建模也是提升模型效果的一种有效手段。具体针对本项目而言，即开通了 WinPort 的会员，其流失率 7%；未开通 Win Port 的会员，其流失率高达 15%。那么，针对这两类群体分别建模，有可能会提升模型的预测效果和效率。

❑在项目实践过程中，业务团队的直觉和建议有时候会有「一字千金」的价值，所以要鼓励业务方积极参与模型的讨论和建议。

❑预测模型的搭建和完善也跟网站分析一样，遵循着「持续优化，永无止境」的规律。

在上述讨论、交流的基础上，业务团队也提出了很多有价值的建议和意见，在此不一一列举了。但是当数据分析师对截止到当前的进度和成果进行反思时，突然发现了一个以前没有想到、但有可能会非常严重的漏洞。截止到目前为止，无论是数据分析师，还是业务团队都没有考虑到是否有可能从当初高活跃度客户的定义里直接推测出是否有流失的可能性。当初高活跃度的定义主要是依据用户在某入口页面的 30 天 PV 量是否超过相应的行业平均值来给出的，那么我们有理由推测，虽然用户在该入口页面的 30 天 PV 量大于相应行业的平均值，但是超过的幅度不大，只是超过行业平均值的 10%，这样的用户是否更加容易流失呢？这种猜测看上去有道理，但是当初都没有想到。如果这个猜测被验证是正确的，并且效果比上述的预测模型还好，那么这个预测模型就没有意义了。

在将这个重要的想法及时跟业务方进行沟通后，得到了业务方的理解和支持，那么接下来就要验证该猜想了。首先要增加衍生变量，围绕上述猜想增添了下列衍生变量，主要是衡量用户跟行业平均值的差值和比例，具体衍生变量如图 6-3 所示。

图　6-3　模型优化时新增的衍生变量一览表

6.7　按优化方案重新抽取样本并建模，提炼结论并验证模型

在上述优化方案和新增衍生变量的基础上，重新抽取样本，一方面验证之前的重要猜想；另一方面尝试搭建新的模型提升预测效果。

在随后的数据验证中，虽然之前的猜想不成立，但是通过增加新的衍生变量，重新搭建的预测模型的效果明显要比之前的模型效果好，如图 6-4 所示。

图　6-4　增添衍生变量后新的模型效果提升明显

从图 6-4 可以看出，增加了新的衍生变量之后，模型的整体预测效果和效率相比于前期的模型有了明显的提升和改善，具体数据如下。

通过神经网络模型得到的分数最高的前 10% 的用户中，流失率高达 47% 左右，而样本的整体流失率在 10.1% 左右；得分最高的前 20% 的用户中，流失率高达 34%；得分最高的前 30% 的用户中，流失率高达 27%。

通过决策树模型得到的分数最高的前 10% 的用户中，流失率高达 45% 左右；得分最高的前 20% 的用户中，流失率高达 33%；得分最高的前 30% 用户中，流失率高达 26%。

相应的，逻辑回归模型的效果也比之前，没有考虑这些衍生变量时有明显提升，对此读者可以自己对比、评价。

在对上述的模型效果进行比较后，初步可以认为，目前的神经网络模型相比于其他模型而言，有更好的预测效果，可以更多地有效锁定有流失风险的用户。

模型建好了，还不能马上提交给业务方进行落地应用，还必须用最新的实际数据来验证模型的稳定性。如果通过相关验证得知模型的稳定性非常好，那无论对模型的效果，还是对项目应用的前景，就都有比较充足的底气了。

6.8　完成分析报告和落地应用建议

在上述模型优化和验证的基础上，提交给业务方一份详细完整的项目结论和应用建议，包括以下内容：

❑模型的预测效果和效率，以及在最新的实际数据中验证模型的结果，即模型的稳定性。

❑通过模型整理出来的可以作为运营参考的重要自变量及相应的特征、规律。

❑数据分析师根据模型效果和效率数据提出的落地应用的分层建议，以及相应的运营建议，其包括：预测模型打分应用基础上进一步的客户特征分层、相应细分群体运营通道的选择、运营文案的主题或噱头、运营引导的方向和目的、对照组与运营组的设置、效果监控的方案等。

6.9　制定具体的落地应用方案和评估方案

经过与业务方的讨论，最终的运营方案确定为如下内容。

鉴于在打分靠前的 Top30% 的用户里，模型可以有效圈定大约 75% 的流失用户，业务方决定将这群得分最高的 Top30% 用户作为运营的重点群体。在该重点群体中抽取 5% 样本作为对照组，不做任何运营触碰，用于后期对运营组的效果进行比较；该重点群体的剩余 95% 则作为运营组，进行个性化的运营。并且根据业务方提出的一些抓手对作为运营组的群体进行了进一步的细分。共分成 6 个细分群体，每个细分群体有一个明确的抓手（特征）可以进行针对性的运营方案的设计和执行。举例来说，其中一个细分群体的特点是开通了 WP 产品但是还没有升级，相应的运营文案的主题就是您的 WP 还没有自测评分，评分系统是为您量身订做的测评工具，帮您发现 WP 中的不足，并提供改进建议，建议您即刻升级使用，升级可以一键完成，并且是完全免费的。

运营的通道以电子邮件传递为主，以即时通信工具 IM 为辅。

6.10　业务方实施落地应用方案并跟踪、评估效果

按照上述的运营和监控方案对运营组和对照组进行分层的精细化运营，一周后效果结论出来了，效果结论是从以下两方面来测量的。

❑预测模型的稳定性评测。根据对照组的模型来进行验证，经验证，模型的稳定性非常好，与当初模型拟合时的稳定性完全一致，得分最高的 30% 用户群里，可以有效覆盖 75% 的流失用户。

❑运营效果，即流失客户的挽留效果的评测。6 个细分群体的运营组与未作运营触碰的对照组相比，没有流失率上的差别，换句话说，本次运营没有达到挽留客户，降低流失率的目的。

根据对邮件运营方式每个环节的完成率进行分析，有充足的理由可以认为电子邮件通道的打开率和行动率非常低。总体的运营效果非常差，如图 6-5 所示。

图　6-5　第一次运营的效果评估图

面对该模型落地应用后的首次实战评估效果不佳，业务方和数据分析师一起讨论了原因并寻找突破口。当时会议主要的焦点如下：

❑从电子邮件运营的效果来看，邮件运营组相比于对照组没有实质性的流失降低，个别组甚至流失率高于对照组。同时，电子邮件运营的打开率和行动率都非常低，是运营文案的问题？还是运营通道即电子邮件的问题？或者是其他的问题呢？

❑从 IM 运营的效果看，除了个别细分组的效果好些外，大部分的效果也跟对照组没有区别，是否是文案和运营策略需要调整……

❑接下来的运营策略是什么？

6.11　落地应用方案在实际效果评估后，不断修正完善

