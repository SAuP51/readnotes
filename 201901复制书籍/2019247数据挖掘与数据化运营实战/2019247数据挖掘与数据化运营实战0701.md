# 07 数据挖掘建模的优化和限度

没有最好，只有更好。

7.1　数据挖掘模型的优化要遵循有效、适度的原则

7.2　如何有效地优化模型

7.3　如何思考优化的限度

7.4　模型效果评价的主要指标体系

「没有最好，只有更好」这个广告语之所以能成为经典，是因为它揭示了「任何事物的发展和进步都是可以无限深入的」这样一个真理。一个人可以不断进步，一个产品也可以不断升级，同样，一个数据挖掘模型也是可以不断完善、不断优化、不断提升的。只是，数据挖掘模型的每一次优化、每一次提升都需要有资源的投入，而且都是为了满足特定的业务需求。在模型优化和资源投入之间，在投入数据分析资源和满足特定业务需求之间，又有一个微妙的平衡点 —— 性价比。这个微妙的平衡点决定了模型的优化和完善是有限度的。本章的主题是模型优化的总体原则、模型评价的指标体系、模型优化的具体思路和方向，以及具体考虑优化的限度时应注意的几个典型因素。

7.1　数据挖掘模型的优化要遵循有效、适度的原则

任何一个数据挖掘模型都是针对一个特定业务需求的，围绕着一个具体的业务需求，数据挖掘模型总是可以有办法不断完善、不断提升，即提升精确度、提升转化率等。这里自然就出现了一个限度的问题，到底模型优化到什么程度才算可以呢？或者说模型到了什么程度算可以接受？什么程度不能接受，要继续优化呢？这是数据挖掘商业实践中经常碰到的问题，对此，有一个有效、适度的总原则必须坚持。

既然任何一个数据挖掘模型都是针对一个特定业务需求的，那么评价模型是否合格的一个原则性标准就是模型的结论或应用效果是否满足当初的业务需求，即有效的原则。虽然这个原则的表述听上去比较虚，但是具体到业务实践和具体的分析需求中，一般都是有一系列具体、明确、可量化的指标和尺度的。比如，一个某付费产品的续费客户预测模型的建模需求，必然要求所构建的预测模型能有效锁定最可能续费的用户群体，从而可以提升续费转化率，是相对于不做客户细分时的总体续费转化率来说的，即原始转化率，或者称为随机转化率，最起码在对最终模型进行验证后，确实可以得出模型挑选出的优质群体的续费转化率显著高于随机转化率这样的结论，这时才可以称为有效。

一旦模型满足了有效的标准，是否还要继续优化呢？此时要考虑第二个原则，即适度的原则。所谓适度，是说此时模型还是可以继续投入资源、投入精力去持续优化的，即继续不断提升模型的精度、转化率等，但是必须要考虑投入产出之间的性价比是否合适，是否适度。如果花了很大的力气，投入了很多的资源，但是模型的提升不明显，即模型优化的投入与产出相比得不偿失，那么就违反了适度的原则；如果花了较少的力气，增加了不多的资源，但是模型的提升很明显，很显著（相比当初已经有效的模型而言），那么可以认为这种持续性的优化是适度的，是具有较好的性价比的。

在第 6 章分享的案例中，包含了模型优化的详细思路、过程、效果对比，以及落地应用的跟踪。从这个详细的案例可以发现，换个思路、新添分析变量、不断尝试不同的算法、对算法的参数进行调整、将数据的处理方式进行变化等，常常是可以有效提升模型效果的。

有效和适度作为模型优化的总原则听上去很简单，但是在实际操作中则需要数据分析师具备一定的项目经验，且要对业务有足够的理解和把握，否则是不容易实现有效和适度目的的。数据挖掘建模的王道是有丰富的项目经验积累，个中没有捷径可走，唯有踏踏实实多实践、多做项目、多动手、多思考，仅此而已。

7.2　如何有效地优化模型

7.2.1　从业务思路上优化

从业务思路上优化模型是最重要的模型优化措施（没有「之一」），这也是很多数据分析师在尝试模型优化时最容易忽视或根本就没想过的方法。很多时候，这个思路和方法对于模型效用的提升是根本性的，是源头上的突破，因而常常更有效。之所以说它常常有效果，主要是因为经过前期的数据熟悉、分析和初步建模之后，我们对数据逻辑之间的关系更加敏锐了，而且对于需求目标的认识更加深刻了，并且前期建模过程中常常会有一些新的关联和联想给我们提供了新的更加贴切的灵感，所有这些正面的因素形成合力，拓宽了我们的业务思路，加强了我们的业务洞察力，换个角度看问题，又是一幅新的风景，通过这种方式常常可以轻松优化、提升模型。

第 6 章里分享过的「H 层会员流失预警模型」，其建模过程中的优化思路就属于从业务思路上优化：在初步建模完成后，我们审视当初的建模思路，发现有一个潜在的、致命的思路漏洞、那就是我们没有考虑到在提取数据的那个时间窗口里，虽然当时处于 H 层但是非常接近 H 层最低点位置的人群，他们所处的这个低层位置的指标，是否可以直接取代预测模型的作用而有效引导出随后两周这类人群从 H 层流失的结论？换言之，这个群体是否会整体上或者绝大多数流失？由于我们发现了这个漏洞，重新增加了对这个假设的验证过程，更重要的是因此增添了一系列与此相关的新的变量，从后期的模型优化和最终的解决方案来看，正是由于这些新的思路和新关键字段的增添，使得模型的预测效果得到显著提升。这个案例非常具体、生动地说明了从思路上优化模型是多么有效，多么给力。

从业务思路上优化主要可以从以下几个层面进行考虑。

❑有没有更加明显且直观的规则、指标可以代替复杂的建模？通过对这些直观的假设进行验证、思考并增添相关的新衍生变量，有时候就可以有效优化模型。上面的案例就是这种思路的成果：如果「近 30 天登录 ## 助手的 PV 量」接近「近 30 天行业标准的登录 ## 助手的 PV 量，即活跃层与中间层的分界线」，那么，对于符合该指标条件的这部分 H 层会员在随后两周后大批量流失（或跌落）到中间层是否有明显的趋势？只要这个直观的猜测（或规则）经过数据验证是事实，那么就没有必要去搭建复杂的模型了，可以直接用这个简单的规则去判断。正是基于这个思考，我们一方面对这个猜想进行了验证，另一方面在模型中增加了核心的新的相关输入变量，包括：H 层用户近 30 天登录 ## 助手的 PV 量，与相应的近 30 天行业标准的登录 ## 助手的 PV 量差值 Visit_Assist_pv_Gap，以及两者的比值 Visit_Assist_pv_Rate 等）相信这些新增的变量从业务直觉上看是与用户流失的结果有密切关系的。虽然上面直观的猜想并没有被实际的数据所证实，但是由此带来的新的变量成了最终模型得以优化的最核心指标。

❑有没有一些明显的业务逻辑（业务假设）在前期的建模阶段被疏忽了呢？比如要搭建一个类似于「竞价排名」业务的续费用户（提前充值）预测模型，那么除了直接从数据仓库中提取相关的字段、数据之外，是否考虑到了用户提前充值的行为很可能跟其当前账户里的余额多少有关，或者跟其最近月均消耗金额与余额的比例有关？这些深入的思考可以让我们增添一些衍生的变量、字段，而这些衍生的变量常常能给模型带来明显的效果提升。

❑通过前期的初步建模和数据熟悉，是否有新的发现，甚至能颠覆之前的业务推测或业务直觉呢？如果有，适时调整新的分析思路，常常就会有明显的模型效果提升作用。比如，起初我们会猜想有佛教信仰的人应该是寺庙收入的主流目标群体，其承担了寺庙的绝大多数门票和捐款收入，但是仔细观察数据我们会发现其实在现实生活中不一定信仰佛教，但是一定有愿望乞求佛菩萨保佑，即保佑发财、保佑升官、保佑平安等的香客才是寺庙收入真正的主流目标群体。这种观察直接颠覆了之前的猜想，如果要为某寺庙寻找收入提升的方式，那么修改原先的目标群体，重新定位于那些乞求佛菩萨保佑的信众，宣传有求必应的灵验性，或许是提升收入的重要策略。针对这个新的目标群体构建的数据模型，理论上来说其效果会有明显的提升。

❑目标变量的定义是否稳定（在不同时间点抽样验证）？如果不稳定，通常应该考虑一个更加合适的相关的稳定的变量作为目标，并重新建模。

通过与业务需求方的「头脑风暴」，可以发掘出新的想法和思路，从更多的角度、更多的层次考虑业务逻辑，从而更全面地增加衍生字段。对于数据分析师来说，不仅自己要多角度、多层次考虑业务逻辑，更重要的是要与业务团队充分沟通、共同探讨，在大家的思维碰撞中发现新的火花。

7.2.2　从建模的技术思路上优化

从建模的技术思路上优化是指在建模的总体技术思路、总体技术方向上进行比较、权衡。建模的总体技术思路包括不同的建模算法、不同的抽样方法、有没有必要通过细分群体来分别建模等。

一般来讲，不同的建模算法针对不同的具体业务场景会有不同的表现，没有哪种算法可以永远优越于其他算法，所以数据分析师在具体的业务项目实践中应该多尝试不同的建模算法，从中比较、权衡，择其优者而用之（在本章的后半部分，会详细介绍模型的评价指标体系和评估方向）。这里的建模算法是广义上的，包括基本的统计分析技术，只要是可以解决业务问题，都是我们的候选算法。而对于不同建模算法的比较，既包括预测响应（或分类）模型思路里不同算法的比较，如综合考虑逻辑回归算法、决策树算法、神经网络算法、支持向量机算法等，又有广义上的算法比较。比如，在 A 产品付费用户特征分析项目中，实际上有至少 3 种完全不同的技术思路可以应用，包括基本的统计分析方法，如找出有统计差异显著性的特征字段及组合、常规的聚类分析方法，如对付费用户群体进行几个重要业务变量的聚类划分，以及预测项目模型的思路，它不仅可以找出特征字段，还可以有效预测潜在的最可能付费的目标人群。很明显，3 种不同的思路有更多种不同的算法可以尝试，究竟哪种思路和算法最适合本项目，要权衡的因素很多，包括项目的资源是否充足、现有数据的完整情况、项目的时间节点、模型精度要求等，但是从模型优化的角度来考虑，对不同的算法多尝试、多比较，是数据分析师常用的一种优化思路。

同样的道理，如何抽样对于模型的效果也有着非常重要的影响。基于业务背景的判断和现有的数据资源状况，数据分析师要决定是否抽样，以及如何抽样。对于稀有事件的建模预测，还会涉及过抽样，过抽样的浓度需要调整，需要结合具体的业务背景考虑。有关数据抽样的问题，将在本书第 8 章中做进一步的总结和分享。

针对细分群体分别建模也是建模过程中常用的、有效的模型优化思路和方法之一。细分建模的思路和作用很容易理解，细分本身就是对分析对象的一次筛选，即所谓的物以类聚，人以群分。细分后的各个群体相比之前的整体对象来说一定是多了些精细化的分割，群里多了一些共性，群里的数据因此更加「整齐，少了噪声」，群间多了一些差异，所以更适合分别建模，分别分析，基于这些精细化的群体分别建模，常能更明显提升模型的效果。当然了，不是说只要做了细分，模型就一定会得到明显的提升，因为模型的提升还涉及具体的细分方案是否合理、是否合适，细分的关键指标的挑选是否精准，细分后核心群体里的逻辑关系是否与建模所希望寻找的逻辑关系相吻合等因素。但是，总体来说，细分后的群体，尤其是核心群体（占有最大比例的目标事件）的模型效果提升常常是很明显的。比如，某产品是用于线上店铺装修的一个付费产品，其功能是帮助店家有效装修网上的店铺。在有关该产品的付费用户预测模型中，初期的模型效果不太理想，但我们通过建模和数据摸底发现了一个有趣的现象，那就是过去 30 天主动查看自己店面外观（该变量是指卖家像买家那样浏览自己的店铺前台，而不是作为卖家进行后台打理）的用户相比于过去 30 天完全不查看自己店面外观的用户来说，前者购买该产品的比例远远高于后者，并且在最终成为该产品的付费用户中，来自前者的付费用户数量远远高于来自后者的付费用户。其比例为 91∶9，限于企业的商业隐私，无法提供更具体的数据规模，不过，相信现有的数据和背景已经足够让读者充分理解项目背景，并体会项目中的思路和方法了。因此在该模型的优化过程中，我们采用了细分建模的优化思路，并针对重点细分群体（该群体中付费用户数量占总付费用户数量的 91%，其基本阀值是「过去 30 天内主动查看自己店面外观达 1 天次以上的用户」）重新建模，结果模型的效果有了明显的提升；而对于另外剩下的那个小群体（该群体中付费用户数量占总付费用户数量的 9%，其基本阀值是「过去 30 天内主动查看自己店面外观为 0 天次的用户」），我们用简单的统计分析工具做了一个简单的重要变量筛选，有效锁定了该群体中更有可能转化为付费用户的人群，并找出其特征。其实，就算在这个小群体里无法找出付费用户的特征，整个项目的优化也是比较明显的，因为虽然我们放弃了 9% 的付费用户，但是通过细分优化后的模型，可以更有效地覆盖可能产生付费用户中 91% 的目标用户的预测模型，并且模型的提升和效率更加明显。因此从这个案例中，也可以得到这样的认识，即细分建模有时候会通过故意漏掉一小部分目标用户，从而可以针对剩下的绝大多数目标用户进行更有效的预测。

当然了，针对细分群体分别建模更多的时候并非如上面的案例一样操作，即只针对「过去 30 天主动查看自己店面外观的用户」建模，放弃对「过去 30 天没有查看自己店面外观的用户」建模，而是真正地分别建立多个模型，从而一一对应不同的核心客户群体。同样是苹果手机 iPhone 的核心目标群体，即目标消费者，其实可以细分成苹果发烧友消费者、非发烧友消费者，两个群体的购买动机、消费心理等一定有比较明显的差异，从理论上来说，对两个不同群体分别建模来进行分析应该比笼统地分析建模更加精准，这是很容易理解的。

7.2.3　从建模的技术技巧上优化

之所以本节专门针对建模技巧进行总结和分享，对应于 7.2.2 节的建模技术思路上优化，是想强调，在建模过程中，业务思路上的优化比建模技术思路上的优化更重要，而建模技术思路上的优化又比单纯的建模技巧的优化更重要。很多数据分析师，尤其是刚刚涉足该职业的分析师，总是非常热衷于对技巧的掌握和应用，殊不知在真正成功的数据挖掘应用中这些建模技巧最多只是「术」层面上的，而所谓「术」更多的是「锦上添花」而不能「雪中送炭」。与之相对应的是，思路上的优化，尤其是业务思路上的优化才是真正「道」层面上的，是方向性的，是可以产生质变的因素和条件，所以它是可以「雪中送炭」的，是最有可能显著提升模型效果的。

既然建模技巧更多起到的是「锦上添花」的作用，这倒也很符合模型优化的初衷，如果业务思路正确了，建模技术思路正确了，再加上这些建模技巧，的确是可以有效优化和提升模型的。

事实上，本书相当的篇幅都涉及了各种类型课题即模型的分析技巧和建模技巧。第 8～13 章分别介绍了大量的建模技巧和需要注意的事项，这些所罗列、分享的各种技术细节和技巧，当然也可以用于建模优化的技巧和措施，有关这 6 章所罗列的技术措施和技巧，本章就不重复了，希望读者在实践中将它们有机地结合起来，并应用到具体的业务实践中。

7.3　如何思考优化的限度

在已经可以满足业务需求的情况下，是否继续优化模型呢？这里要考虑的就是优化限度，即适度的问题。其中有以下两个主要因素需要重点思考。

数据化运营实践中的数据分析和数据挖掘非常强调时效性，在业务需求给出的有限时间里完成优化并投入应用。因此，时间因素是思考适度的主要维度。分析师要对模型继续优化的方案、思路有非常大的把握对由此决定的优化完成的时间节点有准确的判断，以确保是在业务需求规定的时间节点之前完成优化的。

从投入与产出的对比来考虑是思考适度的另一个主要思路。成熟的、经验丰富的数据分析师对于模型优化的投入比较清楚，比如，需要什么技术、什么思路，具体如何优化，大概需要多少资源配合等，在对这些优化的投入进行综合考虑后，再对比预计优化后的提升效果大概有多大，两者权衡之后，即可判断出是否有必要继续优化。当然，这里的权衡和比较需要数据分析师本身有较好的分析功底和丰富的项目经验，所谓运筹帷幄之中，决胜千里之外，这种预判的能力是高级数据分析师应该也必须具备的技术能力和功底。

7.4　模型效果评价的主要指标体系

模型的评价指标和评价体系是建模过程中的一个重要环节，不同类型的项目、不同类型的模型有各自的评价指标和体系。在 7.2 节我们也提到，从第 8 章一直到第 13 章将针对不同类型的模型分别进行详述，包括相应的技术、思路、应用、技巧，当然也包括相应的评价体系和指标，所以本节不再重复。本节将重点介绍关于目标变量是二元变量（即是与否，1 与 0）的分类（预测）模型的评价体系和评价指标。之所以在这里强调目标变量是二元变量的分类（预测）模型（Binary Models），主要是因为在数据化运营实践场景中，大量的模型属于二元变量的分类（预测）模型，比如预测用户是否响应运营活动、预测用户是否会流失、预测用户是否在最近 1 个月内会购买某产品等；而且，这类二元变量的分类（预测）模型相比于其他类型的模型来说有更多的评价维度和评价指标，也更繁杂。

7.4.1　评价模型准确度和精度的系列指标

在介绍系列指标之前，先明确以下 4 个基本的定义：

❑True Positive（TP）：指模型预测为正（1）的，并且实际上也的确是正（1）的观察对象的数量。

❑True Negative（TN）：指模型预测为负（0）的，并且实际上也的确是负（0）的观察对象的数量。

❑False Positive（FP）：指模型预测为正（1）的，但是实际上是负（0）的观察对象的数量。

❑False Negative（FN）：指模型预测为负（0）的，但是实际上是正（1）的观察对象的数量。

上述 4 个基本定义可以用一个表格形式简单地体现，如表 7-1 所示。

基于上面的 4 个基本定义，可以延伸出下列评价指标：

❑Accuracy（正确率）：模型总体的正确率，是指模型能正确预测、识别 1 和 0 的对象数量与预测对象总数的比值，公式如下：

❑Error rate（错误率）：模型总体的错误率，是指模型错误预测、错误识别 1 和 0 观察对象的数量与预测对象总数的比值，也即 1 减去正确率的差，公式如下：

❑Sensitivity（灵敏性）：又叫击中率或真正率，模型正确识别为正（1）的对象占全部观察对象中实际为正（1）的对象数量的比值，公式如下：

❑Specificity（特效性）：又叫真负率，模型正确识别为负（0）的对象占全部观察对象中实际为负（0）的对象数量的比值，公式如下：

❑Precision（精度）：模型的精度是指模型正确识别为正（1）的对象占模型识别为正（1）的观察对象总数的比值，公式如下：

❑False Positive Rate（错正率）：又叫假正率，模型错误地识别为正（1）的对象数量占实际为负（0）的对象数量的比值，即 1 减去真负率 Specificity, 公式如下：

❑Negative Predictive Value（负元正确率）：模型正确识别为负（0）的对象数量占模型识别为负（0）的观察对象总数的比值，公式如下：

❑False Discovery Rate（正元错误率）：模型错误识别为正（1）的对象数量占模型识别为正（1）的观察对象总数的比值，公式如下：

可以很容易地发现，正确率是灵敏性和特效性的函数：

上述各种基本指标，从各个角度对模型的表现进行了评估，在实际业务应用场景中，可以有选择地采用其中某些指标（不一定全部采用），关键要看具体的项目背景和业务场景，针对其侧重点来选择。

另一方面，上述各种基本指标看上去很容易让人混淆，尤其是与业务方讨论这些指标时更是如此，而且这些指标虽然从各个不同角度对模型效果进行了评价，但指标之间是彼此分散的，因此使用起来需要人为地进行整合。

鉴于此，在实际业务应用中，数据分析师更多使用的是其他一些可帮助综合性判断的指标，这些就是 7.4.2～7.4.4 节将要介绍的 ROC 曲线、KS 值和 Lift 值。

7.4.2　ROC 曲线

ROC 曲线是一种有效比较（或对比）两个（或两个以上）二元分类模型（Binary Models）的可视工具，ROC（Receiver Operating Characteristic，接收者运行特征）曲线来源于信号检测理论，它显示了给定模型的灵敏性（Sensitivity）真正率与假正率（False Positive Rate）之间的比较评定。给定一个二元分类问题，我们通过对测试数据集的不同部分所显示的模型可以正确识别「1」实例的比例与模型将「0」实例错误地识别为「1」的比例进行分析，来比较不同模型的准确率的比较评定。真正率的增加是以假正率的增加为代价的，ROC 曲线下面的面积就是比较模型准确度的指标和依据。面积大的模型对应的模型准确度要高，也就是要择优应用的模型。面积越接近 0.5，对应的模型的准确率就越低。

图 7-1 是两个分类模型所对应的 ROC 曲线图，其横轴是假正率，其纵轴是真正率，该图同时显示了一条对角线。ROC 曲线离对角线越近，模型的准确率就越低。从排序后的最高「正」概率的观察值开始，随着概率从高到低逐渐下降，相应的观察群体里真正的「正」群体则会逐渐减少，而假「正」真「负」的群体则会逐渐增多，ROC 曲线也从开始的陡峭变为逐渐水平了。图中最上面的曲线所代表的神经网络模型（Neural）的准确率就要高于其下面的曲线所代表的逻辑回归模型（Reg）的准确率。

要绘制 ROC 曲线，首先要对模型所做的判断即对应的数据做排序，把经过模型判断后的观察值预测为正（1）的概率从高到低进行排序（最前面的应该是模型判断最可能为「正」的观察值），ROC 曲线的纵轴（垂直轴）表示真正率（模型正确判断为正的数量占实际为正的数量的比值），ROC 曲线的横轴（水平轴）表示假正率（模型错误判断为正的数量占实际为负的数量的比值）。具体绘制时，要从左下角开始，在此真正率和假正率都为 0，按照刚才概率从高到低的顺序，依次针对每个观察值实际的「正」或「负」进行 ROC 图形的绘制，如果它是真正的「正」，则在 ROC 曲线上向上移动并绘制一个点；如果它是真正的「负」，则在 ROC 曲线上向右移动并绘制一个点。对于每个观察值都重复这个过程（按照预测为「正」的概率从高到低的顺序来绘制），每次对实际上为「正」的在 ROC 曲线上向上移动一个点，对实际为「负」的在 ROC 曲线向右移动一个点 [1]。当然了，很多数据挖掘软件包已经可以自动实现对 ROC 曲线的展示了，所以更多的时候只是需要知道其中的原理，并且知道如何评价具体模型的 ROC 曲线就可以了。

图　7-1　两个分类模型的 ROC 曲线

[1] JiaweiHan，MichelineKamber. 数据挖掘概念与技术 [M].2 版。范明，孟小峰，译。北京：机械工业出版社，2006.

7.4.3　KS 值

KS 值也是比较常用的一种判断二元分类（预测）模型准确度的方法，该方法来源于统计学中的 Kolmogorov-Smirnov Test。KS 值在评价二元分类模型的预测能力时，主要体现在：如果 KS 值越大，表示模型能够将正（1）、负（0）客户区分开来的程度越大，模型预测的准确性也就越高。通常来讲，KS 大于 0.2 就表示模型有比较好的预测准确性了。

如何绘制 KS 曲线呢？其操作步骤如下：

1）将测试集里所有的观察对象经过模型打分预测出各自为正（1）的概率，然后将这个概率的值按照从高到低的顺序排序（排在最前面的当然是模型预测其为正（1）的概率最大的观察对象），如图 7-2 所示。

图　7-2　KS 曲线绘制步骤 1）示意图

2）分别计算（从高到低）每个概率数值分数所对应的实际上为正（1）、负（0）的观察对象的累计值，以及它们分别占全体总数，实际正（1）或负（0）的总数量的百分比，如图 7-3 所示。

图　7-3　KS 曲线绘制步骤 2）示意图

3）将这两种累计的百分比与评分分数绘制在同一张图上，得到 KS 曲线，如图 7-4 所示。

图　7-4　KS 曲线绘制步骤 3）示意图

4）各分数对应下累计的、真正的正（1）观察对象的百分比与累计的、真正的负（0）观察对象的百分比之差的最大值就是 KS 值。在本示范中，KS 值为 46.7%，如图 7-5 所示。

图　7-5　KS 曲线绘制步骤 4）示意图

7.4.4　Lift 值

虽然前几节分享了不同的评价指标和方法，但是在数据挖掘建模的业务实践中，用得最多的评价模型方法其实是 Lift 值，它直观、通俗易懂，容易为业务方理解，更重要的是这种方法可以根据业务需要的不同，直接显示对应不同目标群体规模（不同数量规模）的模型效果，方便业务应用时挑选最恰当的受众群体规模。比如，挑选打分人群里预测分数最高的 10% 的人群，还是 20% 的人群，或者是 40% 的人群等。

Lift 值是如何计算的呢？我们知道，二元分类（预测）模型在具体的业务场景中，都有一个 Random Rate，所谓 Random Rate，是指在不使用模型的时候，基于已有业务效果的正比例，也就是不使用模型之前「正」的实际观察对象在总体观察对象中的占比，这个占比也称作「正」事件的随机响应概率。如果经过建模，有了一个不错的预测模型，那么这个模型就可以比较有效锁定（正确地分类出、预测出大多数的「正」的观察对象）群体了，所谓「有效」是指在预测概率的数值从高到低的排序中，排名靠前的观察值中，真正的「正」观察值在累计的总观察值里的占比应该是高于 Random Rate 的。

举例来说，某二元分类（预测）模型针对 10 000 名潜在用户打分（预测其购买某产品的可能性），Random Rate 为 9%，即其中有 900 人会实际购买该产品，将这 10 000 名用户经过模型打分后所得的（购买某产品可能性）概率分数从高到低进行排序，如果排名前 10% 的用户，即 1000 名概率最高的用户里实际购买产品的用户数量为 600 人，那么与 Random Rate 相比较，可得出排名前 10% 的用户其实际购买率的 Lift 值为 6.67。

或

上述两种算法，得到的结果都是 6.67，两种算法的思路有什么区别？为什么它们可以殊途同归？感兴趣的读者可以自己进行揣摩和思考。

上述两种算法，引出了跟 Lift 相关且在模型评估中也常常用到的两个评价指标，分别是响应率（% Response）和捕获率（% Captured Response），这两个指标反映的是与 Lift 基本相同的意思，都是评估模型的效果和效率，但是它们比 Lift 更加直观，更加容易理解，因此在实践中，尤其是在与业务方交流、沟通模型效果评价时）经常采用。

对 % Response 和 % Captured Response 的应用，也如 Lift 的应用一样，首先要把经过模型预测后的观察对象按照预测概率的分数从高到低进行排序，然后对这些排序后的观察对象按照均等的数量划分成 10 个区间，或者 20 个区间，每个区间里观察对象的数量一致（概率分数的顺序不变），这样各个区间可以被命名为排序最高的前 10% 的对象、排序最高的前 20% 的对象等。

响应率是指上述经过概率分数排序后的某区间段或累计区间观察对象中，属于正（1）的观察对象占该区间或该累计区间总体观察对象数量的百分比。很明显，响应率越大，说明在该区间或该累计区间模型的预测准确度越高，如图 7-6 所示。

图　7-6　模型响应率曲线

从图 7-6 可以发现，最上面的一条线是神经网络模型的响应率曲线，在概率得分从高到低排序的前 10% 的观察对象中，有 70% 是实际上属于正（1）的；前 20% 的观察对象中，有将近 63% 是实际上属于正（1）的，在后面的观察对象也可以依次找出对应的响应率。

捕获率是指上述经过概率分数排序后的某区间段或累计区间的观察对象中，属于正（1）的观察对象占全体观察对象中属于正（1）的总数的百分比。捕获率顾名思义就是某区间或累计区间模型可以抓住的正（1）的观察对象占总体，正（1）的观察对象的比例，如图 7-7 所示。

从图 7-7 可以看出，最上面的一条线是神经网络模型的捕获率曲线，在概率得分从高到低排序的前 10% 的观察对象中，实际是正（1）的观察对象占全部正（1）总体数量的近 25%；前 20% 的观察对象中，实际是正（1）的观察对象占全部正（1）总体数量的近 44%。

图　7-7　模型捕获率曲线

7.4.5　模型稳定性的评估

到目前为止，本章对于模型评估的内容都是侧重于模型本身的精度、准确度、效果、效率等的总结和分享。其实，对于模型的评估主要是从两个方面来进行考虑的，一方面就是模型的精度、准确度、效果、效率等，如前面所介绍的内容，另一方面就是对模型稳定性的评估。一个模型无论多么准确，多么有效，如果其表现不稳定，也是无法投入业务落地应用的。

一个模型搭建完成后，即使它在训练集和验证集里表现都令人满意，也并不能说现在这个模型就可以投入业务应用了，我们仍然有相当的理由怀疑模型在面对新的数据时是否也能有稳定的表现。这个怀疑的理由是充分的，也是必要的，因为不能排除模型过拟合的情况产生，也不能排除不同时间窗口的业务背景会产生重大变化，包括模型此刻的表现还有一点偶然的成分等因素，都有理由要我们对模型的稳定性进行进一步评估。

考察稳定性最好的办法就是抽取另外一个时间段（时间窗口）的数据，最好是最新时间的数据，通过模型对这些新数据、新对象进行预测（打分），然后与实际情况进行比较（参考本章前面所介绍的关于模型准确度、效果、效率的评估指标和方法），并且跟模型在测试集和验证集里的表现相比较，看模型是否稳定，其效果衰减的幅度是否可以接受，如果条件许可，最好用几个不同时间窗口的数据分别进行观察比较，多比较、多测试才有说服力。



