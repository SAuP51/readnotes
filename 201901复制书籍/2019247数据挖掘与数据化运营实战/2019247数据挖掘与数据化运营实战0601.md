
# 06 数据挖掘项目完整应用案例演示

举一隅，不以三隅反，则不复也。

——《论语·述而》

6.1　项目背景和业务分析需求的提出

6.2　数据分析师参与需求讨论

6.3　制定需求分析框架和分析计划

6.4　抽取样本数据、熟悉数据、数据清洗和摸底

6.5　按计划初步搭建挖掘模型

6.6　与业务方讨论模型的初步结论，提出新的思路和模型优化方案

6.7　按优化方案重新抽取样本并建模，提炼结论并验证模型

6.8　完成分析报告和落地应用建议

6.9　制定具体的落地应用方案和评估方案

6.10　业务方实施落地应用方案并跟踪、评估效果

6.11　落地应用方案在实际效果评估后，不断修正完善

6.12　不同运营方案的评估、总结和反馈

6.13　项目应用后的总结和反思

数据挖掘是科学，也是艺术，或者说一半是科学，一半是艺术。所谓科学，是指数据挖掘的算法、流程和分析技术的应用是科学的、严谨的；所谓艺术，是指在具体的分析过程中，融入了分析师的创新思维、主观的判断和取舍，尤其表现在挖掘思路的推敲和衍生变量的创建等方面。

本章将以一个完整的数据挖掘项目为例来进行分享和跟踪，包括从业务需求的提出到落地应用反馈的全过程，一方面揭示数据挖掘全过程中所有环节的顺序、内容和相应的关键目标，另一方面从科学和艺术两个方面来具体阐释数据挖掘中各个步骤的特点和价值。

事物的发展很少是一帆风顺的，更多的时候充斥着反复曲折，呈螺旋前进状态，只要每一次的反复和曲折都能够有所提升和突破，那么离成功就会越来越近了。本章的案例也真实地反映了商业实战中的数据挖掘是如何在曲折反复中逐步前进的。完成一个好的模型，达成一个满意的业务应用结果，这只是数据分析师分内的任务和工作职责；而自觉主动地从项目中总结、提升自己，从挫折中发现自己的不足，从而积极改进、完善，更应该成为数据分析师的态度和专业理念。

通过本章的案例，希望向有缘的读者传递以下几个方面的信息：

❑数据挖掘实战中的流程会有一些基本的顺序，按着流程进行挖掘是数据分析严谨性的体现。

❑数据挖掘和模型搭建只是数据化运营中的一个环节，数据化运营是跨团队跨专业的协同作业，数据挖掘模型和结论只有在落地应用的业务场景中才能得到检验，才能体现出价值。从这个角度来说，没有落地应用的数据分析和数据挖掘还不是严格意义上的「完成」。

❑落地应用中的运营方案对模型的应用效果影响极大，所以数据分析师不仅要熟悉数据分析和模型搭建，还要熟悉与运营相关的业务技能，这也是数据挖掘和数据化运营中复合型技能的要求。

鉴于对企业商业机密的考量，本章的项目描述中对于大部分数据都做了有意识的修改和处理，所以案例中的数据已经不能代表企业的真实数据特征了，特此说明。

6.1　项目背景和业务分析需求的提出

某互联网公司「免费会员运营团队」的主要工作内容就是不断培养和提升免费会员的成熟度和电子商务专业度，以便在条件具备的时候可以适时将部分优质的免费会员提升为付费会员，成为付费会员后将可以享受到更多的专业服务，并且可使电子商务技能升级，从而有助于他们从电子商务中获得更大的利益。

按照该运营团队既定的客户分层思路，他们所负责的免费会员按照活跃度来划分可分为高活跃度、中活跃度和低活跃度 3 类群体，活跃度划分的指标主要是 30 天之内登录网站的次数，以及某核心入口 30 天以来的 PV 量。需要强调的是，活跃度划分的这两大核心指标是另外一个项目得出的结论，因涉及企业的商业机密，本书对此不做过多的阐述和数据罗列，读者只需要记住该项目的活跃度划分有这两个指标就可以了。

高活跃度的免费用户一直是该运营团队的重点客户群体，高活跃度群体的付费转化率也一直是最高的，且转化数量也是最多的。但是，困扰运营方的一个重要问题是，高活跃度用户的流失率比较大，有相当比例的高活跃度免费用户在短时间里会从高活跃度跌落到中、低活跃度群体里。

面对这种业务困境，运营方希望数据分析团队能通过数据分析和数据挖掘建模的方法，提前锁定最可能流失的高活跃度用户，这样可以方便运营团队有的放矢针对这些「高危」用户群采取挽留措施，从而可以有效降低他们的流失率和流失数量。

6.2　数据分析师参与需求讨论

接到业务方的初步分析需求之后，数据分析师针对该潜在的项目与相关运营方一起进行了需求讨论。

在数据化运营的商业实战中，这类讨论的主要目的如下：

❑针对需求收集相关的背景数据和指标，与业务方一起熟悉背景中的相关业务逻辑，并收集业务方对需求的相关建议、看法，这些信息对于需求的确认和思路的规划乃至后期的分析都是至关重要的。

❑从数据分析的专业角度评价初步的业务分析需求是否合理，是否可行。尽管说业务方对于业务需求最有发言权，对业务最了解、最敏感，但是从数据化运营的商业实践中来看，业务方提出的分析需求并不是每一个都是合理的，都是可行的。在某些情况下，某些分析需求本身就是「伪命题」；又或者说在具体的场景下，某些分析需求暂时无法进行，比如数据储备不足、样本量太少等。

在本需求的讨论阶段，数据分析师与相关业务团队进行了多次有针对性的讨论，并参与到他们的业务工作流程和实施中，因此对需求有了一定程度的了解和熟悉，并且从数据分析的专业角度对数据的范围、样本有了大致的了解，在此基础上决定接受业务方的分析需求。这样，流程就可以往下进行了。

6.3　制定需求分析框架和分析计划

在本阶段，针对前面对业务的初步了解和需求背景的分析，数据分析师制订了初步的分析框架和分析计划。

分析框架的主要内容如下：

❑分析需求转化成数据分析项目中目标变量的定义。具体到本案例，高活跃度免费用户的流失是这样定义的，在某个时间点（A 点）用户是满足高活跃度用户标准要求的（属于高活跃度用户群体），随后过 A 点 7 天，也就是 1 周之后，这 1 周也是配合运营的时间节奏来确定的，该用户从高活跃度群体跌落到中级甚至是最低级的活跃度群体里，并且在过 A 点 14 天，即 2 周之后仍然没有回到高活跃度标准的，就定义为高活跃度免费用户的流失群体。数据分析师在给出这个初步定义时，要强调上述高活跃度用户的流失定义只是当前的初步定义，随着后期进行数据抽取，并与业务方进一步讨论，有了更深入的分析后，上述流失的定义是可以修改和完善的，修改和完善的最终目的是为了数据分析和挖掘的工作能最有效地支持业务应用，并提升业务工作效率。

❑分析思路的大致描述。具体到本案例，分析思路是通过搭建分类模型来比较准确且有效地来提前锁定有可能流失的用户群体。

❑分析样本的数据抽取规则。关于数据抽取的规则，限于企业的商业机密，不能分享太多，基本上是指根据上面目标变量的定义，选择一个适当的时间窗口，然后抽取一定的样本数据。

❑潜在分析变量（模型输入变量）的大致圈定和罗列。经过前期与业务方的调研和沟通，数据分析师和业务方已经大致圈定了相关变量，即从业务经验判断和以往的分析工作中，提炼整理出来的大约 63 个原始变量，具体见表 6-1。因涉及企业的商业隐私，这里就不具体说明各变量的中文含义了，总而言之，是从业务经验的角度大致罗列了这些似乎对目标变量的预测有意义的相关变量。

❑分析过程中的项目风险思考和主要的应对策略。具体到本案例，项目风险思考主要包括模型效果不好的可能性，即有可能分类模型的思路被证明是不好的，也有可能是模型效果不好，或者准确度不高，或者模型不稳定。是否有相应的分析对策来部分弥补，如果分类模型的思路被证明是行不通的，可以退而求其次进行流失用户的群体特征细分，或者重新定义流失用户等。

❑项目的落地应用价值分析和展望。具体到本案例，则主要集中在 3 个方面：模型投入应用后提前锁定有高流失风险的高活跃度用户群体，从而可以使运营方有针对性地开展挽留、服务等运营工作；可以将建模过程中发现的有价值的、最可能影响流失的重要字段和指标选择性地提供给运营方，用于制定运营方案和策略的依据和参考；针对影响流失的核心指标和字段，可以提供给相关业务方，以作为进行客户关系管理的依据和参考线索。

分析计划主要是指分析过程中时间节点的安排和相应的分析进度的设置，具体可见以下示例，见表 6-2。

6.4　抽取样本数据、熟悉数据、数据清洗和摸底

本阶段的主要内容包括：根据前期讨论的分析思路和建模思路，以及初步圈定的分析字段（分析变量）编写代码，从数据仓库中提取分析、建模所需的样本数据；通过对样本数据的熟悉和摸底，找到无效数据、脏数据、错误数据等，并且对样本数据中存在的这些明显的数据质量问题进行清洗、剔除、转换，同时视具体的业务场景和项目需求，决定是否产生衍生变量，以及怎样衍生等。

在互联网行业，由于业务发展迅猛，产品日新月异，不断在优化或换代，且相关的存储方案和战略方向在不断修改和调整，所有这些因素都导致了数据仓库的数据存储或多或少都存在这样或那样的漏洞、缺憾、偏差，而且直接导致了具体抽取的分析样本数据中不可避免地存在无效数据、脏数据、错误数据等有问题的数据。对于这些数据问题，在本环节不仅要将其明确找出来，还要应用具体的技术手段来加以应对。具体针对本项目的数据质量来说，本阶段有下列主要的发现和应对策略：

❑通过对原始样本数据和原始字段的摸底、排查，发现有些字段缺失值高达 50% 以上，经过研究发现这些缺失是数据仓库存储过程中的记录缺失，或者是由于产品优化后的业务逻辑更改所造成的，这些问题虽然可以向相关的数据仓库接口人反映，但是对于本项目来说已经无法回滚所需的真实数据了，对这些数据我们采取直接删除的措施。

❑通过输入变量之间的相关性分析，找出潜在共线性问题的相关输入变量，对于高度线性相关的变量只保留一个。

❑在数据仓库的数据回滚过程中造成了某些字段的严重不符合逻辑或明显自相矛盾，比如用户最近 30 天登录网站次数为 0，其最近 30 天发布产品信息的天数不为 0。针对类似的严重不符合逻辑的数据问题，要提请数据仓库重新回滚数据，直到数据正确为止。

经过处理，即删除严重缺失数据、数据仓库重新回滚明显矛盾的数据、对高度相关性的部分数据的有取有舍，在本阶段结束时共保留了 36 个比较有意义的字段、变量和相应数据。

关于数据清洗的主要注意事项和常用技术，在第 8 章中会有比较详细的介绍和分析。

6.5　按计划初步搭建挖掘模型

对数据进行初步的摸底和清洗之后，就进入初步搭建挖掘模型阶段了。在该阶段，包括以下 3 个主要的工作内容：

❑进一步筛选模型的输入变量。最终进入模型的输入变量应遵循「少而精」的总原则，该总原则一方面是为了提高模型的稳定性，另一方面也是为了有效提升模型的预测精度。关于如何筛选模型的输入变量，在 8.6 节、9.3.3 节、第 10 章中会有比较详细、深入的分析和讨论，有兴趣的读者可以参考上述章节详细了解。

❑尝试不同的挖掘算法和分析方法，并比较不同方案的效果、效率和稳定性。关于模型的比较和优化，7.4 节有比较详细的整理和总结，有兴趣的读者可以参考阅读。

❑整理经过模型挑选出来的与目标变量的预测最相关的一系列核心输入变量，将其作为与业务方讨论落地应用时的参考和建议。

具体针对本项目实践来说，本阶段在通过不同算法的尝试和对结果的比较中，发现神经网络搭建的模型相对来说准确度更高、效率更高，如图 6-1 所示。

图　6-1　不同算法的模型效果（响应率）比较

从图 6-1 可以看出：通过神经网络模型得到的分数最高的前 10% 的用户中，流失率高达 44% 左右，而样本的整体流失率在 10.1% 左右；得分最高的前 20% 的用户中，流失率高达 29%；得分最高的前 30% 的用户中，流失率高达 24%。

通过逻辑回归模型得到的分数最高的前 10% 的用户中，流失率高达 41% 左右；得分最高的前 20% 的用户中，流失率高达 27%；得分最高的前 30% 用户中，流失率高达 23%。

通过对上述的模型效果的比较，大致可以认为，目前的神经网络模型相对于其他模型而言，有更高的预测效果，可以更多地有效锁定有流失风险的用户。

6.6　与业务方讨论模型的初步结论，提出新的思路和模型优化方案

在本阶段，需要整理模型的初步报告、结论，以及对主要预测字段进行提炼，还要通过与业务方沟通和分享，在此基础上讨论出模型的可能优化方向，并对落地应用的方案进行讨论，同时罗列出注意事项。

具体针对本项目而言，除了上面提到的模型比较之外，还对核心自变量进行了整理提炼，并进行了权重排序，如图 6-2 所示。

图　6-2　核心自变量的提炼

针对目前模型的表现和后期的落地应用场景，数据分析师就下列事项与运营方交换了意见，其中沟通和讨论的主要内容如下：

❑对建模时给出的流失用户的定义要进行后续新数据的跟踪，看该定义是否合理，是否表现稳定，是否符合业务运营的需求。

❑在后期的落地应用中，针对模型所判断出来的流失风险最大的用户群，可以考虑进行更加深入的分析，以找出运营的抓手和进一步的细分特征，其中所涉及的技术包括聚类技术、特征阀值的设定等。

❑模型落地应用后的效果跟踪也非常关键，主要包括：对于模型的稳定性要结合新的数据来验证，要考虑如何评价运营的挽留效果，如何设置运营组和对照组，如何进行客观公正公平的评价（包括模型效果的评价和运营效果的评价等）。

❑模型的优化要遵循资源合理应用的总原则。关于模型的优化和限度，第 7 章有详细的分享和讨论，在此不再过多地扩展讲解。

❑细分建模也是提升模型效果的一种有效手段。具体针对本项目而言，即开通了 WinPort 的会员，其流失率 7%；未开通 Win Port 的会员，其流失率高达 15%。那么，针对这两类群体分别建模，有可能会提升模型的预测效果和效率。

❑在项目实践过程中，业务团队的直觉和建议有时候会有「一字千金」的价值，所以要鼓励业务方积极参与模型的讨论和建议。

❑预测模型的搭建和完善也跟网站分析一样，遵循着「持续优化，永无止境」的规律。

在上述讨论、交流的基础上，业务团队也提出了很多有价值的建议和意见，在此不一一列举了。但是当数据分析师对截止到当前的进度和成果进行反思时，突然发现了一个以前没有想到、但有可能会非常严重的漏洞。截止到目前为止，无论是数据分析师，还是业务团队都没有考虑到是否有可能从当初高活跃度客户的定义里直接推测出是否有流失的可能性。当初高活跃度的定义主要是依据用户在某入口页面的 30 天 PV 量是否超过相应的行业平均值来给出的，那么我们有理由推测，虽然用户在该入口页面的 30 天 PV 量大于相应行业的平均值，但是超过的幅度不大，只是超过行业平均值的 10%，这样的用户是否更加容易流失呢？这种猜测看上去有道理，但是当初都没有想到。如果这个猜测被验证是正确的，并且效果比上述的预测模型还好，那么这个预测模型就没有意义了。

在将这个重要的想法及时跟业务方进行沟通后，得到了业务方的理解和支持，那么接下来就要验证该猜想了。首先要增加衍生变量，围绕上述猜想增添了下列衍生变量，主要是衡量用户跟行业平均值的差值和比例，具体衍生变量如图 6-3 所示。

图　6-3　模型优化时新增的衍生变量一览表

6.7　按优化方案重新抽取样本并建模，提炼结论并验证模型

在上述优化方案和新增衍生变量的基础上，重新抽取样本，一方面验证之前的重要猜想；另一方面尝试搭建新的模型提升预测效果。

在随后的数据验证中，虽然之前的猜想不成立，但是通过增加新的衍生变量，重新搭建的预测模型的效果明显要比之前的模型效果好，如图 6-4 所示。

图　6-4　增添衍生变量后新的模型效果提升明显

从图 6-4 可以看出，增加了新的衍生变量之后，模型的整体预测效果和效率相比于前期的模型有了明显的提升和改善，具体数据如下。

通过神经网络模型得到的分数最高的前 10% 的用户中，流失率高达 47% 左右，而样本的整体流失率在 10.1% 左右；得分最高的前 20% 的用户中，流失率高达 34%；得分最高的前 30% 的用户中，流失率高达 27%。

通过决策树模型得到的分数最高的前 10% 的用户中，流失率高达 45% 左右；得分最高的前 20% 的用户中，流失率高达 33%；得分最高的前 30% 用户中，流失率高达 26%。

相应的，逻辑回归模型的效果也比之前，没有考虑这些衍生变量时有明显提升，对此读者可以自己对比、评价。

在对上述的模型效果进行比较后，初步可以认为，目前的神经网络模型相比于其他模型而言，有更好的预测效果，可以更多地有效锁定有流失风险的用户。

模型建好了，还不能马上提交给业务方进行落地应用，还必须用最新的实际数据来验证模型的稳定性。如果通过相关验证得知模型的稳定性非常好，那无论对模型的效果，还是对项目应用的前景，就都有比较充足的底气了。

6.8　完成分析报告和落地应用建议

在上述模型优化和验证的基础上，提交给业务方一份详细完整的项目结论和应用建议，包括以下内容：

❑模型的预测效果和效率，以及在最新的实际数据中验证模型的结果，即模型的稳定性。

❑通过模型整理出来的可以作为运营参考的重要自变量及相应的特征、规律。

❑数据分析师根据模型效果和效率数据提出的落地应用的分层建议，以及相应的运营建议，其包括：预测模型打分应用基础上进一步的客户特征分层、相应细分群体运营通道的选择、运营文案的主题或噱头、运营引导的方向和目的、对照组与运营组的设置、效果监控的方案等。

6.9　制定具体的落地应用方案和评估方案

经过与业务方的讨论，最终的运营方案确定为如下内容。

鉴于在打分靠前的 Top30% 的用户里，模型可以有效圈定大约 75% 的流失用户，业务方决定将这群得分最高的 Top30% 用户作为运营的重点群体。在该重点群体中抽取 5% 样本作为对照组，不做任何运营触碰，用于后期对运营组的效果进行比较；该重点群体的剩余 95% 则作为运营组，进行个性化的运营。并且根据业务方提出的一些抓手对作为运营组的群体进行了进一步的细分。共分成 6 个细分群体，每个细分群体有一个明确的抓手（特征）可以进行针对性的运营方案的设计和执行。举例来说，其中一个细分群体的特点是开通了 WP 产品但是还没有升级，相应的运营文案的主题就是您的 WP 还没有自测评分，评分系统是为您量身订做的测评工具，帮您发现 WP 中的不足，并提供改进建议，建议您即刻升级使用，升级可以一键完成，并且是完全免费的。

运营的通道以电子邮件传递为主，以即时通信工具 IM 为辅。

6.10　业务方实施落地应用方案并跟踪、评估效果

按照上述的运营和监控方案对运营组和对照组进行分层的精细化运营，一周后效果结论出来了，效果结论是从以下两方面来测量的。

❑预测模型的稳定性评测。根据对照组的模型来进行验证，经验证，模型的稳定性非常好，与当初模型拟合时的稳定性完全一致，得分最高的 30% 用户群里，可以有效覆盖 75% 的流失用户。

❑运营效果，即流失客户的挽留效果的评测。6 个细分群体的运营组与未作运营触碰的对照组相比，没有流失率上的差别，换句话说，本次运营没有达到挽留客户，降低流失率的目的。

根据对邮件运营方式每个环节的完成率进行分析，有充足的理由可以认为电子邮件通道的打开率和行动率非常低。总体的运营效果非常差，如图 6-5 所示。

图　6-5　第一次运营的效果评估图

面对该模型落地应用后的首次实战评估效果不佳，业务方和数据分析师一起讨论了原因并寻找突破口。当时会议主要的焦点如下：

❑从电子邮件运营的效果来看，邮件运营组相比于对照组没有实质性的流失降低，个别组甚至流失率高于对照组。同时，电子邮件运营的打开率和行动率都非常低，是运营文案的问题？还是运营通道即电子邮件的问题？或者是其他的问题呢？

❑从 IM 运营的效果看，除了个别细分组的效果好些外，大部分的效果也跟对照组没有区别，是否是文案和运营策略需要调整……

❑接下来的运营策略是什么？

6.11　落地应用方案在实际效果评估后，不断修正完善


通过对第一次运营效果的评估和反思，大家基本认为问题主要出在以下两方面，也是接下来需要改进的方面。

❑运营通道的选择从以电子邮件为主，转向以即时通信工具 IM 为主。

❑在预测模型打分圈定核心流失群体的基础上，修改进一步的细分方案。更改细分的抓手，由于涉及企业隐私，细节在此从略。

从预测模型的稳定性监控来看，模型本身非常稳定，没有任何问题，可以放心使用。

做了这些调整和改进后，重新用模型打分并采用新的运营方案，主要是修改了运营通道和运营抓手。

6.12　不同运营方案的评估、总结和反馈

通过监控新运营方案的执行情况，得知此次达到了比较满意的运营效果，运营组的流失挽留效果相比对照组而言有了明显的好转，并且预测模型的稳定性仍然非常好，真是「一分耕耘一分收获」，如图 6-6 所示。

图　6-6　第二次运营的效果评估

从图 6-6 中可以看出，控制组的流失率为 35.7%，而 8 个运营组中的 7 个相比控制组而言其流失率都有不同程度的下降，其中，下降最显著的是「名方案 1」的运营组，其流失率降为 23.06%。

6.13　项目应用后的总结和反思

经过不断的方案完善和严格科学的效果监控，本项目的后期落地应用环节在不断优化后，越来越突出在建模基础上的数据化运营所拥有的高效、精准的优势。

这次比较成功地用结果数据说话的项目应用，在坚定了业务方「以数据分析挖掘为基础的数据化运营」的信心，同时也生动地教育了相关的数据分析师「完美的分析结论和模型搭建只是数据化运营万里长征的第一步」，要想模型真正推动业务的效率和效益，模型落地应用的环节更加关键、更加重要、更加复杂。

正如本项目所经历的那样，再好的模型，如果没有合适的运营通道、合适的运营文案、合适的运营资源配合，也是无法达成最终的商业目的的。